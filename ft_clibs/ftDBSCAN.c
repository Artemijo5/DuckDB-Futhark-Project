// Generated by Futhark 0.26.0 (prerelease - include info below when reporting bugs).
// git: 1de4f0c (Fri Jan 24 11:10:52 2025 +0100)
// Compiled with GHC 9.4.8.

// We need to define _GNU_SOURCE before
// _any_ headers files are imported to get
// the usage statistics of a thread (i.e. have RUSAGE_THREAD) on GNU/Linux
// https://manpages.courier-mta.org/htmlman2/getrusage.2.html
#ifndef _GNU_SOURCE // Avoid possible double-definition warning.
#define _GNU_SOURCE
#endif

#ifdef __clang__
#pragma clang diagnostic ignored "-Wunused-function"
#pragma clang diagnostic ignored "-Wunused-variable"
#pragma clang diagnostic ignored "-Wunused-const-variable"
#pragma clang diagnostic ignored "-Wparentheses"
#pragma clang diagnostic ignored "-Wunused-label"
#pragma clang diagnostic ignored "-Wunused-but-set-variable"
#elif __GNUC__
#pragma GCC diagnostic ignored "-Wunused-function"
#pragma GCC diagnostic ignored "-Wunused-variable"
#pragma GCC diagnostic ignored "-Wunused-const-variable"
#pragma GCC diagnostic ignored "-Wparentheses"
#pragma GCC diagnostic ignored "-Wunused-label"
#pragma GCC diagnostic ignored "-Wunused-but-set-variable"
#endif

// Headers
#include <stdint.h>
#include <stddef.h>
#include <stdbool.h>
#include <stdio.h>
#include <float.h>

#include <cuda.h>
#include <cuda_runtime.h>
#include <nvrtc.h>

#ifdef __cplusplus
extern "C" {
#endif

// Initialisation
struct futhark_context_config;
struct futhark_context_config *futhark_context_config_new(void);
void futhark_context_config_free(struct futhark_context_config *cfg);
int futhark_context_config_set_tuning_param(struct futhark_context_config *cfg, const char *param_name, size_t new_value);
struct futhark_context;
struct futhark_context *futhark_context_new(struct futhark_context_config *cfg);
void futhark_context_free(struct futhark_context *cfg);
void futhark_context_config_set_default_thread_block_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_grid_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_group_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_num_groups(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_tile_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_reg_tile_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_registers(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_cache(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_threshold(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_unified_memory(struct futhark_context_config *cfg, int flag);
void futhark_context_config_add_nvrtc_option(struct futhark_context_config *cfg, const char *opt);
void futhark_context_config_set_device(struct futhark_context_config *cfg, const char *s);
const char *futhark_context_config_get_program(struct futhark_context_config *cfg);
void futhark_context_config_set_program(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_dump_ptx_to(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_load_ptx_from(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_set_debugging(struct futhark_context_config *cfg, int flag);
void futhark_context_config_set_profiling(struct futhark_context_config *cfg, int flag);
void futhark_context_config_set_logging(struct futhark_context_config *cfg, int flag);
int futhark_get_tuning_param_count(void);
const char *futhark_get_tuning_param_name(int);
const char *futhark_get_tuning_param_class(int);

// Arrays
struct futhark_f32_2d;
struct futhark_f32_2d *futhark_new_f32_2d(struct futhark_context *ctx, const float *data, int64_t dim0, int64_t dim1);
struct futhark_f32_2d *futhark_new_raw_f32_2d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0, int64_t dim1);
int futhark_free_f32_2d(struct futhark_context *ctx, struct futhark_f32_2d *arr);
int futhark_values_f32_2d(struct futhark_context *ctx, struct futhark_f32_2d *arr, float *data);
int futhark_index_f32_2d(struct futhark_context *ctx, float *out, struct futhark_f32_2d *arr, int64_t i0, int64_t i1);
CUdeviceptr futhark_values_raw_f32_2d(struct futhark_context *ctx, struct futhark_f32_2d *arr);
const int64_t *futhark_shape_f32_2d(struct futhark_context *ctx, struct futhark_f32_2d *arr);
struct futhark_f64_2d;
struct futhark_f64_2d *futhark_new_f64_2d(struct futhark_context *ctx, const double *data, int64_t dim0, int64_t dim1);
struct futhark_f64_2d *futhark_new_raw_f64_2d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0, int64_t dim1);
int futhark_free_f64_2d(struct futhark_context *ctx, struct futhark_f64_2d *arr);
int futhark_values_f64_2d(struct futhark_context *ctx, struct futhark_f64_2d *arr, double *data);
int futhark_index_f64_2d(struct futhark_context *ctx, double *out, struct futhark_f64_2d *arr, int64_t i0, int64_t i1);
CUdeviceptr futhark_values_raw_f64_2d(struct futhark_context *ctx, struct futhark_f64_2d *arr);
const int64_t *futhark_shape_f64_2d(struct futhark_context *ctx, struct futhark_f64_2d *arr);
struct futhark_i64_1d;
struct futhark_i64_1d *futhark_new_i64_1d(struct futhark_context *ctx, const int64_t *data, int64_t dim0);
struct futhark_i64_1d *futhark_new_raw_i64_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0);
int futhark_free_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr);
int futhark_values_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr, int64_t *data);
int futhark_index_i64_1d(struct futhark_context *ctx, int64_t *out, struct futhark_i64_1d *arr, int64_t i0);
CUdeviceptr futhark_values_raw_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr);
const int64_t *futhark_shape_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr);

// Opaque values
struct futhark_opaque_core_cluster_double;
struct futhark_opaque_core_cluster_float;
int futhark_free_opaque_core_cluster_double(struct futhark_context *ctx, struct futhark_opaque_core_cluster_double *obj);
int futhark_store_opaque_core_cluster_double(struct futhark_context *ctx, const struct futhark_opaque_core_cluster_double *obj, void **p, size_t *n);
struct futhark_opaque_core_cluster_double *futhark_restore_opaque_core_cluster_double(struct futhark_context *ctx, const void *p);
int futhark_project_opaque_core_cluster_double_core_ids(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_core_cluster_double *obj);
int futhark_project_opaque_core_cluster_double_core_pts(struct futhark_context *ctx, struct futhark_f64_2d **out, const struct futhark_opaque_core_cluster_double *obj);
int futhark_project_opaque_core_cluster_double_len(struct futhark_context *ctx, int64_t *out, const struct futhark_opaque_core_cluster_double *obj);
int futhark_new_opaque_core_cluster_double(struct futhark_context *ctx, struct futhark_opaque_core_cluster_double **out, const struct futhark_i64_1d *f_core_ids, const struct futhark_f64_2d *f_core_pts, const int64_t f_len);
int futhark_free_opaque_core_cluster_float(struct futhark_context *ctx, struct futhark_opaque_core_cluster_float *obj);
int futhark_store_opaque_core_cluster_float(struct futhark_context *ctx, const struct futhark_opaque_core_cluster_float *obj, void **p, size_t *n);
struct futhark_opaque_core_cluster_float *futhark_restore_opaque_core_cluster_float(struct futhark_context *ctx, const void *p);
int futhark_project_opaque_core_cluster_float_core_ids(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_core_cluster_float *obj);
int futhark_project_opaque_core_cluster_float_core_pts(struct futhark_context *ctx, struct futhark_f32_2d **out, const struct futhark_opaque_core_cluster_float *obj);
int futhark_project_opaque_core_cluster_float_len(struct futhark_context *ctx, int64_t *out, const struct futhark_opaque_core_cluster_float *obj);
int futhark_new_opaque_core_cluster_float(struct futhark_context *ctx, struct futhark_opaque_core_cluster_float **out, const struct futhark_i64_1d *f_core_ids, const struct futhark_f32_2d *f_core_pts, const int64_t f_len);

// Entry points
int futhark_entry_ftDBSCAN_double(struct futhark_context *ctx, struct futhark_i64_1d **out0, const struct futhark_f64_2d *in0, const double in1, const int64_t in2, const int64_t in3, const int64_t in4);
int futhark_entry_ftDBSCAN_float(struct futhark_context *ctx, struct futhark_i64_1d **out0, const struct futhark_f32_2d *in0, const float in1, const int64_t in2, const int64_t in3, const int64_t in4);
int futhark_entry_ftDBSCAN_star_double(struct futhark_context *ctx, struct futhark_opaque_core_cluster_double **out0, const struct futhark_f64_2d *in0, const double in1, const int64_t in2, const int64_t in3, const int64_t in4);
int futhark_entry_ftDBSCAN_star_float(struct futhark_context *ctx, struct futhark_opaque_core_cluster_float **out0, const struct futhark_f32_2d *in0, const float in1, const int64_t in2, const int64_t in3, const int64_t in4);

// Miscellaneous
int futhark_context_sync(struct futhark_context *ctx);
void futhark_context_config_set_cache_file(struct futhark_context_config *cfg, const char *f);
char *futhark_context_get_error(struct futhark_context *ctx);
void futhark_context_set_logging_file(struct futhark_context *ctx, FILE *f);
void futhark_context_pause_profiling(struct futhark_context *ctx);
void futhark_context_unpause_profiling(struct futhark_context *ctx);
char *futhark_context_report(struct futhark_context *ctx);
int futhark_context_clear_caches(struct futhark_context *ctx);
#define FUTHARK_BACKEND_cuda
#define FUTHARK_SUCCESS 0
#define FUTHARK_PROGRAM_ERROR 2
#define FUTHARK_OUT_OF_MEMORY 3

#ifdef __cplusplus
}
#endif

#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <math.h>
#include <stdint.h>
// If NDEBUG is set, the assert() macro will do nothing. Since Futhark
// (unfortunately) makes use of assert() for error detection (and even some
// side effects), we want to avoid that.
#undef NDEBUG
#include <assert.h>
#include <stdarg.h>
#define SCALAR_FUN_ATTR static inline
// Start of util.h.
//
// Various helper functions that are useful in all generated C code.

#include <errno.h>
#include <string.h>

static const char *fut_progname = "(embedded Futhark)";

static void futhark_panic(int eval, const char *fmt, ...) __attribute__((noreturn));
static char* msgprintf(const char *s, ...);
static void* slurp_file(const char *filename, size_t *size);
static int dump_file(const char *file, const void *buf, size_t n);
struct str_builder;
static void str_builder_init(struct str_builder *b);
static void str_builder(struct str_builder *b, const char *s, ...);
static char *strclone(const char *str);

static void futhark_panic(int eval, const char *fmt, ...) {
  va_list ap;
  va_start(ap, fmt);
  fprintf(stderr, "%s: ", fut_progname);
  vfprintf(stderr, fmt, ap);
  va_end(ap);
  exit(eval);
}

// For generating arbitrary-sized error messages.  It is the callers
// responsibility to free the buffer at some point.
static char* msgprintf(const char *s, ...) {
  va_list vl;
  va_start(vl, s);
  size_t needed = 1 + (size_t)vsnprintf(NULL, 0, s, vl);
  char *buffer = (char*) malloc(needed);
  va_start(vl, s); // Must re-init.
  vsnprintf(buffer, needed, s, vl);
  return buffer;
}

static inline void check_err(int errval, int sets_errno, const char *fun, int line,
                             const char *msg, ...) {
  if (errval) {
    char errnum[10];

    va_list vl;
    va_start(vl, msg);

    fprintf(stderr, "ERROR: ");
    vfprintf(stderr, msg, vl);
    fprintf(stderr, " in %s() at line %d with error code %s\n",
            fun, line,
            sets_errno ? strerror(errno) : errnum);
    exit(errval);
  }
}

#define CHECK_ERR(err, ...) check_err(err, 0, __func__, __LINE__, __VA_ARGS__)
#define CHECK_ERRNO(err, ...) check_err(err, 1, __func__, __LINE__, __VA_ARGS__)

// Read the rest of an open file into a NUL-terminated string; returns
// NULL on error.
static void* fslurp_file(FILE *f, size_t *size) {
  long start = ftell(f);
  fseek(f, 0, SEEK_END);
  long src_size = ftell(f)-start;
  fseek(f, start, SEEK_SET);
  unsigned char *s = (unsigned char*) malloc((size_t)src_size + 1);
  if (fread(s, 1, (size_t)src_size, f) != (size_t)src_size) {
    free(s);
    s = NULL;
  } else {
    s[src_size] = '\0';
  }

  if (size) {
    *size = (size_t)src_size;
  }

  return s;
}

// Read a file into a NUL-terminated string; returns NULL on error.
static void* slurp_file(const char *filename, size_t *size) {
  FILE *f = fopen(filename, "rb"); // To avoid Windows messing with linebreaks.
  if (f == NULL) return NULL;
  unsigned char *s = fslurp_file(f, size);
  fclose(f);
  return s;
}

// Dump 'n' bytes from 'buf' into the file at the designated location.
// Returns 0 on success.
static int dump_file(const char *file, const void *buf, size_t n) {
  FILE *f = fopen(file, "w");

  if (f == NULL) {
    return 1;
  }

  if (fwrite(buf, sizeof(char), n, f) != n) {
    return 1;
  }

  if (fclose(f) != 0) {
    return 1;
  }

  return 0;
}

struct str_builder {
  char *str;
  size_t capacity; // Size of buffer.
  size_t used; // Bytes used, *not* including final zero.
};

static void str_builder_init(struct str_builder *b) {
  b->capacity = 10;
  b->used = 0;
  b->str = malloc(b->capacity);
  b->str[0] = 0;
}

static void str_builder(struct str_builder *b, const char *s, ...) {
  va_list vl;
  va_start(vl, s);
  size_t needed = (size_t)vsnprintf(NULL, 0, s, vl);

  while (b->capacity < b->used + needed + 1) {
    b->capacity *= 2;
    b->str = realloc(b->str, b->capacity);
  }

  va_start(vl, s); // Must re-init.
  vsnprintf(b->str+b->used, b->capacity-b->used, s, vl);
  b->used += needed;
}

static void str_builder_str(struct str_builder *b, const char *s) {
  size_t needed = strlen(s);
  if (b->capacity < b->used + needed + 1) {
    b->capacity *= 2;
    b->str = realloc(b->str, b->capacity);
  }
  strcpy(b->str+b->used, s);
  b->used += needed;
}

static void str_builder_char(struct str_builder *b, char c) {
  size_t needed = 1;
  if (b->capacity < b->used + needed + 1) {
    b->capacity *= 2;
    b->str = realloc(b->str, b->capacity);
  }
  b->str[b->used] = c;
  b->str[b->used+1] = 0;
  b->used += needed;
}

static void str_builder_json_str(struct str_builder* sb, const char* s) {
  str_builder_char(sb, '"');
  for (int j = 0; s[j]; j++) {
    char c = s[j];
    switch (c) {
    case '\n':
      str_builder_str(sb, "\\n");
      break;
    case '"':
      str_builder_str(sb, "\\\"");
      break;
    default:
      str_builder_char(sb, c);
    }
  }
  str_builder_char(sb, '"');
}

static char *strclone(const char *str) {
  size_t size = strlen(str) + 1;
  char *copy = (char*) malloc(size);
  if (copy == NULL) {
    return NULL;
  }

  memcpy(copy, str, size);
  return copy;
}

// Assumes NULL-terminated.
static char *strconcat(const char *src_fragments[]) {
  size_t src_len = 0;
  const char **p;

  for (p = src_fragments; *p; p++) {
    src_len += strlen(*p);
  }

  char *src = (char*) malloc(src_len + 1);
  size_t n = 0;
  for (p = src_fragments; *p; p++) {
    strcpy(src + n, *p);
    n += strlen(*p);
  }

  return src;
}

// End of util.h.
// Start of cache.h

#define CACHE_HASH_SIZE 8 // In 32-bit words.

struct cache_hash {
  uint32_t hash[CACHE_HASH_SIZE];
};

// Initialise a blank cache.
static void cache_hash_init(struct cache_hash *c);

// Hash some bytes and add them to the accumulated hash.
static void cache_hash(struct cache_hash *out, const char *in, size_t n);

// Try to restore cache contents from a file with the given name.
// Assumes the cache is invalid if it contains the given hash.
// Allocates memory and reads the cache conents, which is returned in
// *buf with size *buflen.  If the cache is successfully loaded, this
// function returns 0.  Otherwise it returns nonzero.  Errno is set if
// the failure to load the cache is due to anything except invalid
// cache conents.  Note that failing to restore the cache is not
// necessarily a problem: it might just be invalid or not created yet.
static int cache_restore(const char *fname, const struct cache_hash *hash,
                         unsigned char **buf, size_t *buflen);

// Store cache contents in the given file, with the given hash.
static int cache_store(const char *fname, const struct cache_hash *hash,
                       const unsigned char *buf, size_t buflen);

// Now for the implementation.

static void cache_hash_init(struct cache_hash *c) {
  memset(c->hash, 0, CACHE_HASH_SIZE * sizeof(uint32_t));
}

static void cache_hash(struct cache_hash *out, const char *in, size_t n) {
  // Adaptation of djb2 for larger output size by storing intermediate
  // states.
  uint32_t hash = 5381;
  for (size_t i = 0; i < n; i++) {
    hash = ((hash << 5) + hash) + in[i];
    out->hash[i % CACHE_HASH_SIZE] ^= hash;
  }
}

#define CACHE_HEADER_SIZE 8
static const char cache_header[CACHE_HEADER_SIZE] = "FUTHARK\0";

static int cache_restore(const char *fname, const struct cache_hash *hash,
                         unsigned char **buf, size_t *buflen) {
  FILE *f = fopen(fname, "rb");

  if (f == NULL) {
    return 1;
  }

  char f_header[CACHE_HEADER_SIZE];

  if (fread(f_header, sizeof(char), CACHE_HEADER_SIZE, f) != CACHE_HEADER_SIZE) {
    goto error;
  }

  if (memcmp(f_header, cache_header, CACHE_HEADER_SIZE) != 0) {
    goto error;
  }

  if (fseek(f, 0, SEEK_END) != 0) {
    goto error;
  }
  int64_t f_size = (int64_t)ftell(f);
  if (fseek(f, CACHE_HEADER_SIZE, SEEK_SET) != 0) {
    goto error;
  }

  int64_t expected_size;

  if (fread(&expected_size, sizeof(int64_t), 1, f) != 1) {
    goto error;
  }

  if (f_size != expected_size) {
    errno = 0;
    goto error;
  }

  int32_t f_hash[CACHE_HASH_SIZE];

  if (fread(f_hash, sizeof(int32_t), CACHE_HASH_SIZE, f) != CACHE_HASH_SIZE) {
    goto error;
  }

  if (memcmp(f_hash, hash->hash, CACHE_HASH_SIZE) != 0) {
    errno = 0;
    goto error;
  }

  *buflen = f_size - CACHE_HEADER_SIZE - sizeof(int64_t) - CACHE_HASH_SIZE*sizeof(int32_t);
  *buf = malloc(*buflen);
  if (fread(*buf, sizeof(char), *buflen, f) != *buflen) {
    free(*buf);
    goto error;
  }

  fclose(f);

  return 0;

 error:
  fclose(f);
  return 1;
}

static int cache_store(const char *fname, const struct cache_hash *hash,
                       const unsigned char *buf, size_t buflen) {
  FILE *f = fopen(fname, "wb");

  if (f == NULL) {
    return 1;
  }

  if (fwrite(cache_header, CACHE_HEADER_SIZE, 1, f) != 1) {
    goto error;
  }

  int64_t size = CACHE_HEADER_SIZE + sizeof(int64_t) + CACHE_HASH_SIZE*sizeof(int32_t) + buflen;

  if (fwrite(&size, sizeof(size), 1, f) != 1) {
    goto error;
  }

  if (fwrite(hash->hash, sizeof(int32_t), CACHE_HASH_SIZE, f) != CACHE_HASH_SIZE) {
    goto error;
  }

  if (fwrite(buf, sizeof(unsigned char), buflen, f) != buflen) {
    goto error;
  }

  fclose(f);

  return 0;

 error:
  fclose(f);
  return 1;
}

// End of cache.h
// Start of half.h.

// Conversion functions are from http://half.sourceforge.net/, but
// translated to C.
//
// Copyright (c) 2012-2021 Christian Rau
//
// Permission is hereby granted, free of charge, to any person obtaining a copy
// of this software and associated documentation files (the "Software"), to deal
// in the Software without restriction, including without limitation the rights
// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
// copies of the Software, and to permit persons to whom the Software is
// furnished to do so, subject to the following conditions:
//
// The above copyright notice and this permission notice shall be included in
// all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
// THE SOFTWARE.

#ifndef __OPENCL_VERSION__
#define __constant
#endif

__constant static const uint16_t base_table[512] = {
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0001, 0x0002, 0x0004, 0x0008, 0x0010, 0x0020, 0x0040, 0x0080, 0x0100,
  0x0200, 0x0400, 0x0800, 0x0C00, 0x1000, 0x1400, 0x1800, 0x1C00, 0x2000, 0x2400, 0x2800, 0x2C00, 0x3000, 0x3400, 0x3800, 0x3C00,
  0x4000, 0x4400, 0x4800, 0x4C00, 0x5000, 0x5400, 0x5800, 0x5C00, 0x6000, 0x6400, 0x6800, 0x6C00, 0x7000, 0x7400, 0x7800, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8001, 0x8002, 0x8004, 0x8008, 0x8010, 0x8020, 0x8040, 0x8080, 0x8100,
  0x8200, 0x8400, 0x8800, 0x8C00, 0x9000, 0x9400, 0x9800, 0x9C00, 0xA000, 0xA400, 0xA800, 0xAC00, 0xB000, 0xB400, 0xB800, 0xBC00,
  0xC000, 0xC400, 0xC800, 0xCC00, 0xD000, 0xD400, 0xD800, 0xDC00, 0xE000, 0xE400, 0xE800, 0xEC00, 0xF000, 0xF400, 0xF800, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00 };

__constant static const unsigned char shift_table[512] = {
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13 };

__constant static const uint32_t mantissa_table[2048] = {
  0x00000000, 0x33800000, 0x34000000, 0x34400000, 0x34800000, 0x34A00000, 0x34C00000, 0x34E00000, 0x35000000, 0x35100000, 0x35200000, 0x35300000, 0x35400000, 0x35500000, 0x35600000, 0x35700000,
  0x35800000, 0x35880000, 0x35900000, 0x35980000, 0x35A00000, 0x35A80000, 0x35B00000, 0x35B80000, 0x35C00000, 0x35C80000, 0x35D00000, 0x35D80000, 0x35E00000, 0x35E80000, 0x35F00000, 0x35F80000,
  0x36000000, 0x36040000, 0x36080000, 0x360C0000, 0x36100000, 0x36140000, 0x36180000, 0x361C0000, 0x36200000, 0x36240000, 0x36280000, 0x362C0000, 0x36300000, 0x36340000, 0x36380000, 0x363C0000,
  0x36400000, 0x36440000, 0x36480000, 0x364C0000, 0x36500000, 0x36540000, 0x36580000, 0x365C0000, 0x36600000, 0x36640000, 0x36680000, 0x366C0000, 0x36700000, 0x36740000, 0x36780000, 0x367C0000,
  0x36800000, 0x36820000, 0x36840000, 0x36860000, 0x36880000, 0x368A0000, 0x368C0000, 0x368E0000, 0x36900000, 0x36920000, 0x36940000, 0x36960000, 0x36980000, 0x369A0000, 0x369C0000, 0x369E0000,
  0x36A00000, 0x36A20000, 0x36A40000, 0x36A60000, 0x36A80000, 0x36AA0000, 0x36AC0000, 0x36AE0000, 0x36B00000, 0x36B20000, 0x36B40000, 0x36B60000, 0x36B80000, 0x36BA0000, 0x36BC0000, 0x36BE0000,
  0x36C00000, 0x36C20000, 0x36C40000, 0x36C60000, 0x36C80000, 0x36CA0000, 0x36CC0000, 0x36CE0000, 0x36D00000, 0x36D20000, 0x36D40000, 0x36D60000, 0x36D80000, 0x36DA0000, 0x36DC0000, 0x36DE0000,
  0x36E00000, 0x36E20000, 0x36E40000, 0x36E60000, 0x36E80000, 0x36EA0000, 0x36EC0000, 0x36EE0000, 0x36F00000, 0x36F20000, 0x36F40000, 0x36F60000, 0x36F80000, 0x36FA0000, 0x36FC0000, 0x36FE0000,
  0x37000000, 0x37010000, 0x37020000, 0x37030000, 0x37040000, 0x37050000, 0x37060000, 0x37070000, 0x37080000, 0x37090000, 0x370A0000, 0x370B0000, 0x370C0000, 0x370D0000, 0x370E0000, 0x370F0000,
  0x37100000, 0x37110000, 0x37120000, 0x37130000, 0x37140000, 0x37150000, 0x37160000, 0x37170000, 0x37180000, 0x37190000, 0x371A0000, 0x371B0000, 0x371C0000, 0x371D0000, 0x371E0000, 0x371F0000,
  0x37200000, 0x37210000, 0x37220000, 0x37230000, 0x37240000, 0x37250000, 0x37260000, 0x37270000, 0x37280000, 0x37290000, 0x372A0000, 0x372B0000, 0x372C0000, 0x372D0000, 0x372E0000, 0x372F0000,
  0x37300000, 0x37310000, 0x37320000, 0x37330000, 0x37340000, 0x37350000, 0x37360000, 0x37370000, 0x37380000, 0x37390000, 0x373A0000, 0x373B0000, 0x373C0000, 0x373D0000, 0x373E0000, 0x373F0000,
  0x37400000, 0x37410000, 0x37420000, 0x37430000, 0x37440000, 0x37450000, 0x37460000, 0x37470000, 0x37480000, 0x37490000, 0x374A0000, 0x374B0000, 0x374C0000, 0x374D0000, 0x374E0000, 0x374F0000,
  0x37500000, 0x37510000, 0x37520000, 0x37530000, 0x37540000, 0x37550000, 0x37560000, 0x37570000, 0x37580000, 0x37590000, 0x375A0000, 0x375B0000, 0x375C0000, 0x375D0000, 0x375E0000, 0x375F0000,
  0x37600000, 0x37610000, 0x37620000, 0x37630000, 0x37640000, 0x37650000, 0x37660000, 0x37670000, 0x37680000, 0x37690000, 0x376A0000, 0x376B0000, 0x376C0000, 0x376D0000, 0x376E0000, 0x376F0000,
  0x37700000, 0x37710000, 0x37720000, 0x37730000, 0x37740000, 0x37750000, 0x37760000, 0x37770000, 0x37780000, 0x37790000, 0x377A0000, 0x377B0000, 0x377C0000, 0x377D0000, 0x377E0000, 0x377F0000,
  0x37800000, 0x37808000, 0x37810000, 0x37818000, 0x37820000, 0x37828000, 0x37830000, 0x37838000, 0x37840000, 0x37848000, 0x37850000, 0x37858000, 0x37860000, 0x37868000, 0x37870000, 0x37878000,
  0x37880000, 0x37888000, 0x37890000, 0x37898000, 0x378A0000, 0x378A8000, 0x378B0000, 0x378B8000, 0x378C0000, 0x378C8000, 0x378D0000, 0x378D8000, 0x378E0000, 0x378E8000, 0x378F0000, 0x378F8000,
  0x37900000, 0x37908000, 0x37910000, 0x37918000, 0x37920000, 0x37928000, 0x37930000, 0x37938000, 0x37940000, 0x37948000, 0x37950000, 0x37958000, 0x37960000, 0x37968000, 0x37970000, 0x37978000,
  0x37980000, 0x37988000, 0x37990000, 0x37998000, 0x379A0000, 0x379A8000, 0x379B0000, 0x379B8000, 0x379C0000, 0x379C8000, 0x379D0000, 0x379D8000, 0x379E0000, 0x379E8000, 0x379F0000, 0x379F8000,
  0x37A00000, 0x37A08000, 0x37A10000, 0x37A18000, 0x37A20000, 0x37A28000, 0x37A30000, 0x37A38000, 0x37A40000, 0x37A48000, 0x37A50000, 0x37A58000, 0x37A60000, 0x37A68000, 0x37A70000, 0x37A78000,
  0x37A80000, 0x37A88000, 0x37A90000, 0x37A98000, 0x37AA0000, 0x37AA8000, 0x37AB0000, 0x37AB8000, 0x37AC0000, 0x37AC8000, 0x37AD0000, 0x37AD8000, 0x37AE0000, 0x37AE8000, 0x37AF0000, 0x37AF8000,
  0x37B00000, 0x37B08000, 0x37B10000, 0x37B18000, 0x37B20000, 0x37B28000, 0x37B30000, 0x37B38000, 0x37B40000, 0x37B48000, 0x37B50000, 0x37B58000, 0x37B60000, 0x37B68000, 0x37B70000, 0x37B78000,
  0x37B80000, 0x37B88000, 0x37B90000, 0x37B98000, 0x37BA0000, 0x37BA8000, 0x37BB0000, 0x37BB8000, 0x37BC0000, 0x37BC8000, 0x37BD0000, 0x37BD8000, 0x37BE0000, 0x37BE8000, 0x37BF0000, 0x37BF8000,
  0x37C00000, 0x37C08000, 0x37C10000, 0x37C18000, 0x37C20000, 0x37C28000, 0x37C30000, 0x37C38000, 0x37C40000, 0x37C48000, 0x37C50000, 0x37C58000, 0x37C60000, 0x37C68000, 0x37C70000, 0x37C78000,
  0x37C80000, 0x37C88000, 0x37C90000, 0x37C98000, 0x37CA0000, 0x37CA8000, 0x37CB0000, 0x37CB8000, 0x37CC0000, 0x37CC8000, 0x37CD0000, 0x37CD8000, 0x37CE0000, 0x37CE8000, 0x37CF0000, 0x37CF8000,
  0x37D00000, 0x37D08000, 0x37D10000, 0x37D18000, 0x37D20000, 0x37D28000, 0x37D30000, 0x37D38000, 0x37D40000, 0x37D48000, 0x37D50000, 0x37D58000, 0x37D60000, 0x37D68000, 0x37D70000, 0x37D78000,
  0x37D80000, 0x37D88000, 0x37D90000, 0x37D98000, 0x37DA0000, 0x37DA8000, 0x37DB0000, 0x37DB8000, 0x37DC0000, 0x37DC8000, 0x37DD0000, 0x37DD8000, 0x37DE0000, 0x37DE8000, 0x37DF0000, 0x37DF8000,
  0x37E00000, 0x37E08000, 0x37E10000, 0x37E18000, 0x37E20000, 0x37E28000, 0x37E30000, 0x37E38000, 0x37E40000, 0x37E48000, 0x37E50000, 0x37E58000, 0x37E60000, 0x37E68000, 0x37E70000, 0x37E78000,
  0x37E80000, 0x37E88000, 0x37E90000, 0x37E98000, 0x37EA0000, 0x37EA8000, 0x37EB0000, 0x37EB8000, 0x37EC0000, 0x37EC8000, 0x37ED0000, 0x37ED8000, 0x37EE0000, 0x37EE8000, 0x37EF0000, 0x37EF8000,
  0x37F00000, 0x37F08000, 0x37F10000, 0x37F18000, 0x37F20000, 0x37F28000, 0x37F30000, 0x37F38000, 0x37F40000, 0x37F48000, 0x37F50000, 0x37F58000, 0x37F60000, 0x37F68000, 0x37F70000, 0x37F78000,
  0x37F80000, 0x37F88000, 0x37F90000, 0x37F98000, 0x37FA0000, 0x37FA8000, 0x37FB0000, 0x37FB8000, 0x37FC0000, 0x37FC8000, 0x37FD0000, 0x37FD8000, 0x37FE0000, 0x37FE8000, 0x37FF0000, 0x37FF8000,
  0x38000000, 0x38004000, 0x38008000, 0x3800C000, 0x38010000, 0x38014000, 0x38018000, 0x3801C000, 0x38020000, 0x38024000, 0x38028000, 0x3802C000, 0x38030000, 0x38034000, 0x38038000, 0x3803C000,
  0x38040000, 0x38044000, 0x38048000, 0x3804C000, 0x38050000, 0x38054000, 0x38058000, 0x3805C000, 0x38060000, 0x38064000, 0x38068000, 0x3806C000, 0x38070000, 0x38074000, 0x38078000, 0x3807C000,
  0x38080000, 0x38084000, 0x38088000, 0x3808C000, 0x38090000, 0x38094000, 0x38098000, 0x3809C000, 0x380A0000, 0x380A4000, 0x380A8000, 0x380AC000, 0x380B0000, 0x380B4000, 0x380B8000, 0x380BC000,
  0x380C0000, 0x380C4000, 0x380C8000, 0x380CC000, 0x380D0000, 0x380D4000, 0x380D8000, 0x380DC000, 0x380E0000, 0x380E4000, 0x380E8000, 0x380EC000, 0x380F0000, 0x380F4000, 0x380F8000, 0x380FC000,
  0x38100000, 0x38104000, 0x38108000, 0x3810C000, 0x38110000, 0x38114000, 0x38118000, 0x3811C000, 0x38120000, 0x38124000, 0x38128000, 0x3812C000, 0x38130000, 0x38134000, 0x38138000, 0x3813C000,
  0x38140000, 0x38144000, 0x38148000, 0x3814C000, 0x38150000, 0x38154000, 0x38158000, 0x3815C000, 0x38160000, 0x38164000, 0x38168000, 0x3816C000, 0x38170000, 0x38174000, 0x38178000, 0x3817C000,
  0x38180000, 0x38184000, 0x38188000, 0x3818C000, 0x38190000, 0x38194000, 0x38198000, 0x3819C000, 0x381A0000, 0x381A4000, 0x381A8000, 0x381AC000, 0x381B0000, 0x381B4000, 0x381B8000, 0x381BC000,
  0x381C0000, 0x381C4000, 0x381C8000, 0x381CC000, 0x381D0000, 0x381D4000, 0x381D8000, 0x381DC000, 0x381E0000, 0x381E4000, 0x381E8000, 0x381EC000, 0x381F0000, 0x381F4000, 0x381F8000, 0x381FC000,
  0x38200000, 0x38204000, 0x38208000, 0x3820C000, 0x38210000, 0x38214000, 0x38218000, 0x3821C000, 0x38220000, 0x38224000, 0x38228000, 0x3822C000, 0x38230000, 0x38234000, 0x38238000, 0x3823C000,
  0x38240000, 0x38244000, 0x38248000, 0x3824C000, 0x38250000, 0x38254000, 0x38258000, 0x3825C000, 0x38260000, 0x38264000, 0x38268000, 0x3826C000, 0x38270000, 0x38274000, 0x38278000, 0x3827C000,
  0x38280000, 0x38284000, 0x38288000, 0x3828C000, 0x38290000, 0x38294000, 0x38298000, 0x3829C000, 0x382A0000, 0x382A4000, 0x382A8000, 0x382AC000, 0x382B0000, 0x382B4000, 0x382B8000, 0x382BC000,
  0x382C0000, 0x382C4000, 0x382C8000, 0x382CC000, 0x382D0000, 0x382D4000, 0x382D8000, 0x382DC000, 0x382E0000, 0x382E4000, 0x382E8000, 0x382EC000, 0x382F0000, 0x382F4000, 0x382F8000, 0x382FC000,
  0x38300000, 0x38304000, 0x38308000, 0x3830C000, 0x38310000, 0x38314000, 0x38318000, 0x3831C000, 0x38320000, 0x38324000, 0x38328000, 0x3832C000, 0x38330000, 0x38334000, 0x38338000, 0x3833C000,
  0x38340000, 0x38344000, 0x38348000, 0x3834C000, 0x38350000, 0x38354000, 0x38358000, 0x3835C000, 0x38360000, 0x38364000, 0x38368000, 0x3836C000, 0x38370000, 0x38374000, 0x38378000, 0x3837C000,
  0x38380000, 0x38384000, 0x38388000, 0x3838C000, 0x38390000, 0x38394000, 0x38398000, 0x3839C000, 0x383A0000, 0x383A4000, 0x383A8000, 0x383AC000, 0x383B0000, 0x383B4000, 0x383B8000, 0x383BC000,
  0x383C0000, 0x383C4000, 0x383C8000, 0x383CC000, 0x383D0000, 0x383D4000, 0x383D8000, 0x383DC000, 0x383E0000, 0x383E4000, 0x383E8000, 0x383EC000, 0x383F0000, 0x383F4000, 0x383F8000, 0x383FC000,
  0x38400000, 0x38404000, 0x38408000, 0x3840C000, 0x38410000, 0x38414000, 0x38418000, 0x3841C000, 0x38420000, 0x38424000, 0x38428000, 0x3842C000, 0x38430000, 0x38434000, 0x38438000, 0x3843C000,
  0x38440000, 0x38444000, 0x38448000, 0x3844C000, 0x38450000, 0x38454000, 0x38458000, 0x3845C000, 0x38460000, 0x38464000, 0x38468000, 0x3846C000, 0x38470000, 0x38474000, 0x38478000, 0x3847C000,
  0x38480000, 0x38484000, 0x38488000, 0x3848C000, 0x38490000, 0x38494000, 0x38498000, 0x3849C000, 0x384A0000, 0x384A4000, 0x384A8000, 0x384AC000, 0x384B0000, 0x384B4000, 0x384B8000, 0x384BC000,
  0x384C0000, 0x384C4000, 0x384C8000, 0x384CC000, 0x384D0000, 0x384D4000, 0x384D8000, 0x384DC000, 0x384E0000, 0x384E4000, 0x384E8000, 0x384EC000, 0x384F0000, 0x384F4000, 0x384F8000, 0x384FC000,
  0x38500000, 0x38504000, 0x38508000, 0x3850C000, 0x38510000, 0x38514000, 0x38518000, 0x3851C000, 0x38520000, 0x38524000, 0x38528000, 0x3852C000, 0x38530000, 0x38534000, 0x38538000, 0x3853C000,
  0x38540000, 0x38544000, 0x38548000, 0x3854C000, 0x38550000, 0x38554000, 0x38558000, 0x3855C000, 0x38560000, 0x38564000, 0x38568000, 0x3856C000, 0x38570000, 0x38574000, 0x38578000, 0x3857C000,
  0x38580000, 0x38584000, 0x38588000, 0x3858C000, 0x38590000, 0x38594000, 0x38598000, 0x3859C000, 0x385A0000, 0x385A4000, 0x385A8000, 0x385AC000, 0x385B0000, 0x385B4000, 0x385B8000, 0x385BC000,
  0x385C0000, 0x385C4000, 0x385C8000, 0x385CC000, 0x385D0000, 0x385D4000, 0x385D8000, 0x385DC000, 0x385E0000, 0x385E4000, 0x385E8000, 0x385EC000, 0x385F0000, 0x385F4000, 0x385F8000, 0x385FC000,
  0x38600000, 0x38604000, 0x38608000, 0x3860C000, 0x38610000, 0x38614000, 0x38618000, 0x3861C000, 0x38620000, 0x38624000, 0x38628000, 0x3862C000, 0x38630000, 0x38634000, 0x38638000, 0x3863C000,
  0x38640000, 0x38644000, 0x38648000, 0x3864C000, 0x38650000, 0x38654000, 0x38658000, 0x3865C000, 0x38660000, 0x38664000, 0x38668000, 0x3866C000, 0x38670000, 0x38674000, 0x38678000, 0x3867C000,
  0x38680000, 0x38684000, 0x38688000, 0x3868C000, 0x38690000, 0x38694000, 0x38698000, 0x3869C000, 0x386A0000, 0x386A4000, 0x386A8000, 0x386AC000, 0x386B0000, 0x386B4000, 0x386B8000, 0x386BC000,
  0x386C0000, 0x386C4000, 0x386C8000, 0x386CC000, 0x386D0000, 0x386D4000, 0x386D8000, 0x386DC000, 0x386E0000, 0x386E4000, 0x386E8000, 0x386EC000, 0x386F0000, 0x386F4000, 0x386F8000, 0x386FC000,
  0x38700000, 0x38704000, 0x38708000, 0x3870C000, 0x38710000, 0x38714000, 0x38718000, 0x3871C000, 0x38720000, 0x38724000, 0x38728000, 0x3872C000, 0x38730000, 0x38734000, 0x38738000, 0x3873C000,
  0x38740000, 0x38744000, 0x38748000, 0x3874C000, 0x38750000, 0x38754000, 0x38758000, 0x3875C000, 0x38760000, 0x38764000, 0x38768000, 0x3876C000, 0x38770000, 0x38774000, 0x38778000, 0x3877C000,
  0x38780000, 0x38784000, 0x38788000, 0x3878C000, 0x38790000, 0x38794000, 0x38798000, 0x3879C000, 0x387A0000, 0x387A4000, 0x387A8000, 0x387AC000, 0x387B0000, 0x387B4000, 0x387B8000, 0x387BC000,
  0x387C0000, 0x387C4000, 0x387C8000, 0x387CC000, 0x387D0000, 0x387D4000, 0x387D8000, 0x387DC000, 0x387E0000, 0x387E4000, 0x387E8000, 0x387EC000, 0x387F0000, 0x387F4000, 0x387F8000, 0x387FC000,
  0x38000000, 0x38002000, 0x38004000, 0x38006000, 0x38008000, 0x3800A000, 0x3800C000, 0x3800E000, 0x38010000, 0x38012000, 0x38014000, 0x38016000, 0x38018000, 0x3801A000, 0x3801C000, 0x3801E000,
  0x38020000, 0x38022000, 0x38024000, 0x38026000, 0x38028000, 0x3802A000, 0x3802C000, 0x3802E000, 0x38030000, 0x38032000, 0x38034000, 0x38036000, 0x38038000, 0x3803A000, 0x3803C000, 0x3803E000,
  0x38040000, 0x38042000, 0x38044000, 0x38046000, 0x38048000, 0x3804A000, 0x3804C000, 0x3804E000, 0x38050000, 0x38052000, 0x38054000, 0x38056000, 0x38058000, 0x3805A000, 0x3805C000, 0x3805E000,
  0x38060000, 0x38062000, 0x38064000, 0x38066000, 0x38068000, 0x3806A000, 0x3806C000, 0x3806E000, 0x38070000, 0x38072000, 0x38074000, 0x38076000, 0x38078000, 0x3807A000, 0x3807C000, 0x3807E000,
  0x38080000, 0x38082000, 0x38084000, 0x38086000, 0x38088000, 0x3808A000, 0x3808C000, 0x3808E000, 0x38090000, 0x38092000, 0x38094000, 0x38096000, 0x38098000, 0x3809A000, 0x3809C000, 0x3809E000,
  0x380A0000, 0x380A2000, 0x380A4000, 0x380A6000, 0x380A8000, 0x380AA000, 0x380AC000, 0x380AE000, 0x380B0000, 0x380B2000, 0x380B4000, 0x380B6000, 0x380B8000, 0x380BA000, 0x380BC000, 0x380BE000,
  0x380C0000, 0x380C2000, 0x380C4000, 0x380C6000, 0x380C8000, 0x380CA000, 0x380CC000, 0x380CE000, 0x380D0000, 0x380D2000, 0x380D4000, 0x380D6000, 0x380D8000, 0x380DA000, 0x380DC000, 0x380DE000,
  0x380E0000, 0x380E2000, 0x380E4000, 0x380E6000, 0x380E8000, 0x380EA000, 0x380EC000, 0x380EE000, 0x380F0000, 0x380F2000, 0x380F4000, 0x380F6000, 0x380F8000, 0x380FA000, 0x380FC000, 0x380FE000,
  0x38100000, 0x38102000, 0x38104000, 0x38106000, 0x38108000, 0x3810A000, 0x3810C000, 0x3810E000, 0x38110000, 0x38112000, 0x38114000, 0x38116000, 0x38118000, 0x3811A000, 0x3811C000, 0x3811E000,
  0x38120000, 0x38122000, 0x38124000, 0x38126000, 0x38128000, 0x3812A000, 0x3812C000, 0x3812E000, 0x38130000, 0x38132000, 0x38134000, 0x38136000, 0x38138000, 0x3813A000, 0x3813C000, 0x3813E000,
  0x38140000, 0x38142000, 0x38144000, 0x38146000, 0x38148000, 0x3814A000, 0x3814C000, 0x3814E000, 0x38150000, 0x38152000, 0x38154000, 0x38156000, 0x38158000, 0x3815A000, 0x3815C000, 0x3815E000,
  0x38160000, 0x38162000, 0x38164000, 0x38166000, 0x38168000, 0x3816A000, 0x3816C000, 0x3816E000, 0x38170000, 0x38172000, 0x38174000, 0x38176000, 0x38178000, 0x3817A000, 0x3817C000, 0x3817E000,
  0x38180000, 0x38182000, 0x38184000, 0x38186000, 0x38188000, 0x3818A000, 0x3818C000, 0x3818E000, 0x38190000, 0x38192000, 0x38194000, 0x38196000, 0x38198000, 0x3819A000, 0x3819C000, 0x3819E000,
  0x381A0000, 0x381A2000, 0x381A4000, 0x381A6000, 0x381A8000, 0x381AA000, 0x381AC000, 0x381AE000, 0x381B0000, 0x381B2000, 0x381B4000, 0x381B6000, 0x381B8000, 0x381BA000, 0x381BC000, 0x381BE000,
  0x381C0000, 0x381C2000, 0x381C4000, 0x381C6000, 0x381C8000, 0x381CA000, 0x381CC000, 0x381CE000, 0x381D0000, 0x381D2000, 0x381D4000, 0x381D6000, 0x381D8000, 0x381DA000, 0x381DC000, 0x381DE000,
  0x381E0000, 0x381E2000, 0x381E4000, 0x381E6000, 0x381E8000, 0x381EA000, 0x381EC000, 0x381EE000, 0x381F0000, 0x381F2000, 0x381F4000, 0x381F6000, 0x381F8000, 0x381FA000, 0x381FC000, 0x381FE000,
  0x38200000, 0x38202000, 0x38204000, 0x38206000, 0x38208000, 0x3820A000, 0x3820C000, 0x3820E000, 0x38210000, 0x38212000, 0x38214000, 0x38216000, 0x38218000, 0x3821A000, 0x3821C000, 0x3821E000,
  0x38220000, 0x38222000, 0x38224000, 0x38226000, 0x38228000, 0x3822A000, 0x3822C000, 0x3822E000, 0x38230000, 0x38232000, 0x38234000, 0x38236000, 0x38238000, 0x3823A000, 0x3823C000, 0x3823E000,
  0x38240000, 0x38242000, 0x38244000, 0x38246000, 0x38248000, 0x3824A000, 0x3824C000, 0x3824E000, 0x38250000, 0x38252000, 0x38254000, 0x38256000, 0x38258000, 0x3825A000, 0x3825C000, 0x3825E000,
  0x38260000, 0x38262000, 0x38264000, 0x38266000, 0x38268000, 0x3826A000, 0x3826C000, 0x3826E000, 0x38270000, 0x38272000, 0x38274000, 0x38276000, 0x38278000, 0x3827A000, 0x3827C000, 0x3827E000,
  0x38280000, 0x38282000, 0x38284000, 0x38286000, 0x38288000, 0x3828A000, 0x3828C000, 0x3828E000, 0x38290000, 0x38292000, 0x38294000, 0x38296000, 0x38298000, 0x3829A000, 0x3829C000, 0x3829E000,
  0x382A0000, 0x382A2000, 0x382A4000, 0x382A6000, 0x382A8000, 0x382AA000, 0x382AC000, 0x382AE000, 0x382B0000, 0x382B2000, 0x382B4000, 0x382B6000, 0x382B8000, 0x382BA000, 0x382BC000, 0x382BE000,
  0x382C0000, 0x382C2000, 0x382C4000, 0x382C6000, 0x382C8000, 0x382CA000, 0x382CC000, 0x382CE000, 0x382D0000, 0x382D2000, 0x382D4000, 0x382D6000, 0x382D8000, 0x382DA000, 0x382DC000, 0x382DE000,
  0x382E0000, 0x382E2000, 0x382E4000, 0x382E6000, 0x382E8000, 0x382EA000, 0x382EC000, 0x382EE000, 0x382F0000, 0x382F2000, 0x382F4000, 0x382F6000, 0x382F8000, 0x382FA000, 0x382FC000, 0x382FE000,
  0x38300000, 0x38302000, 0x38304000, 0x38306000, 0x38308000, 0x3830A000, 0x3830C000, 0x3830E000, 0x38310000, 0x38312000, 0x38314000, 0x38316000, 0x38318000, 0x3831A000, 0x3831C000, 0x3831E000,
  0x38320000, 0x38322000, 0x38324000, 0x38326000, 0x38328000, 0x3832A000, 0x3832C000, 0x3832E000, 0x38330000, 0x38332000, 0x38334000, 0x38336000, 0x38338000, 0x3833A000, 0x3833C000, 0x3833E000,
  0x38340000, 0x38342000, 0x38344000, 0x38346000, 0x38348000, 0x3834A000, 0x3834C000, 0x3834E000, 0x38350000, 0x38352000, 0x38354000, 0x38356000, 0x38358000, 0x3835A000, 0x3835C000, 0x3835E000,
  0x38360000, 0x38362000, 0x38364000, 0x38366000, 0x38368000, 0x3836A000, 0x3836C000, 0x3836E000, 0x38370000, 0x38372000, 0x38374000, 0x38376000, 0x38378000, 0x3837A000, 0x3837C000, 0x3837E000,
  0x38380000, 0x38382000, 0x38384000, 0x38386000, 0x38388000, 0x3838A000, 0x3838C000, 0x3838E000, 0x38390000, 0x38392000, 0x38394000, 0x38396000, 0x38398000, 0x3839A000, 0x3839C000, 0x3839E000,
  0x383A0000, 0x383A2000, 0x383A4000, 0x383A6000, 0x383A8000, 0x383AA000, 0x383AC000, 0x383AE000, 0x383B0000, 0x383B2000, 0x383B4000, 0x383B6000, 0x383B8000, 0x383BA000, 0x383BC000, 0x383BE000,
  0x383C0000, 0x383C2000, 0x383C4000, 0x383C6000, 0x383C8000, 0x383CA000, 0x383CC000, 0x383CE000, 0x383D0000, 0x383D2000, 0x383D4000, 0x383D6000, 0x383D8000, 0x383DA000, 0x383DC000, 0x383DE000,
  0x383E0000, 0x383E2000, 0x383E4000, 0x383E6000, 0x383E8000, 0x383EA000, 0x383EC000, 0x383EE000, 0x383F0000, 0x383F2000, 0x383F4000, 0x383F6000, 0x383F8000, 0x383FA000, 0x383FC000, 0x383FE000,
  0x38400000, 0x38402000, 0x38404000, 0x38406000, 0x38408000, 0x3840A000, 0x3840C000, 0x3840E000, 0x38410000, 0x38412000, 0x38414000, 0x38416000, 0x38418000, 0x3841A000, 0x3841C000, 0x3841E000,
  0x38420000, 0x38422000, 0x38424000, 0x38426000, 0x38428000, 0x3842A000, 0x3842C000, 0x3842E000, 0x38430000, 0x38432000, 0x38434000, 0x38436000, 0x38438000, 0x3843A000, 0x3843C000, 0x3843E000,
  0x38440000, 0x38442000, 0x38444000, 0x38446000, 0x38448000, 0x3844A000, 0x3844C000, 0x3844E000, 0x38450000, 0x38452000, 0x38454000, 0x38456000, 0x38458000, 0x3845A000, 0x3845C000, 0x3845E000,
  0x38460000, 0x38462000, 0x38464000, 0x38466000, 0x38468000, 0x3846A000, 0x3846C000, 0x3846E000, 0x38470000, 0x38472000, 0x38474000, 0x38476000, 0x38478000, 0x3847A000, 0x3847C000, 0x3847E000,
  0x38480000, 0x38482000, 0x38484000, 0x38486000, 0x38488000, 0x3848A000, 0x3848C000, 0x3848E000, 0x38490000, 0x38492000, 0x38494000, 0x38496000, 0x38498000, 0x3849A000, 0x3849C000, 0x3849E000,
  0x384A0000, 0x384A2000, 0x384A4000, 0x384A6000, 0x384A8000, 0x384AA000, 0x384AC000, 0x384AE000, 0x384B0000, 0x384B2000, 0x384B4000, 0x384B6000, 0x384B8000, 0x384BA000, 0x384BC000, 0x384BE000,
  0x384C0000, 0x384C2000, 0x384C4000, 0x384C6000, 0x384C8000, 0x384CA000, 0x384CC000, 0x384CE000, 0x384D0000, 0x384D2000, 0x384D4000, 0x384D6000, 0x384D8000, 0x384DA000, 0x384DC000, 0x384DE000,
  0x384E0000, 0x384E2000, 0x384E4000, 0x384E6000, 0x384E8000, 0x384EA000, 0x384EC000, 0x384EE000, 0x384F0000, 0x384F2000, 0x384F4000, 0x384F6000, 0x384F8000, 0x384FA000, 0x384FC000, 0x384FE000,
  0x38500000, 0x38502000, 0x38504000, 0x38506000, 0x38508000, 0x3850A000, 0x3850C000, 0x3850E000, 0x38510000, 0x38512000, 0x38514000, 0x38516000, 0x38518000, 0x3851A000, 0x3851C000, 0x3851E000,
  0x38520000, 0x38522000, 0x38524000, 0x38526000, 0x38528000, 0x3852A000, 0x3852C000, 0x3852E000, 0x38530000, 0x38532000, 0x38534000, 0x38536000, 0x38538000, 0x3853A000, 0x3853C000, 0x3853E000,
  0x38540000, 0x38542000, 0x38544000, 0x38546000, 0x38548000, 0x3854A000, 0x3854C000, 0x3854E000, 0x38550000, 0x38552000, 0x38554000, 0x38556000, 0x38558000, 0x3855A000, 0x3855C000, 0x3855E000,
  0x38560000, 0x38562000, 0x38564000, 0x38566000, 0x38568000, 0x3856A000, 0x3856C000, 0x3856E000, 0x38570000, 0x38572000, 0x38574000, 0x38576000, 0x38578000, 0x3857A000, 0x3857C000, 0x3857E000,
  0x38580000, 0x38582000, 0x38584000, 0x38586000, 0x38588000, 0x3858A000, 0x3858C000, 0x3858E000, 0x38590000, 0x38592000, 0x38594000, 0x38596000, 0x38598000, 0x3859A000, 0x3859C000, 0x3859E000,
  0x385A0000, 0x385A2000, 0x385A4000, 0x385A6000, 0x385A8000, 0x385AA000, 0x385AC000, 0x385AE000, 0x385B0000, 0x385B2000, 0x385B4000, 0x385B6000, 0x385B8000, 0x385BA000, 0x385BC000, 0x385BE000,
  0x385C0000, 0x385C2000, 0x385C4000, 0x385C6000, 0x385C8000, 0x385CA000, 0x385CC000, 0x385CE000, 0x385D0000, 0x385D2000, 0x385D4000, 0x385D6000, 0x385D8000, 0x385DA000, 0x385DC000, 0x385DE000,
  0x385E0000, 0x385E2000, 0x385E4000, 0x385E6000, 0x385E8000, 0x385EA000, 0x385EC000, 0x385EE000, 0x385F0000, 0x385F2000, 0x385F4000, 0x385F6000, 0x385F8000, 0x385FA000, 0x385FC000, 0x385FE000,
  0x38600000, 0x38602000, 0x38604000, 0x38606000, 0x38608000, 0x3860A000, 0x3860C000, 0x3860E000, 0x38610000, 0x38612000, 0x38614000, 0x38616000, 0x38618000, 0x3861A000, 0x3861C000, 0x3861E000,
  0x38620000, 0x38622000, 0x38624000, 0x38626000, 0x38628000, 0x3862A000, 0x3862C000, 0x3862E000, 0x38630000, 0x38632000, 0x38634000, 0x38636000, 0x38638000, 0x3863A000, 0x3863C000, 0x3863E000,
  0x38640000, 0x38642000, 0x38644000, 0x38646000, 0x38648000, 0x3864A000, 0x3864C000, 0x3864E000, 0x38650000, 0x38652000, 0x38654000, 0x38656000, 0x38658000, 0x3865A000, 0x3865C000, 0x3865E000,
  0x38660000, 0x38662000, 0x38664000, 0x38666000, 0x38668000, 0x3866A000, 0x3866C000, 0x3866E000, 0x38670000, 0x38672000, 0x38674000, 0x38676000, 0x38678000, 0x3867A000, 0x3867C000, 0x3867E000,
  0x38680000, 0x38682000, 0x38684000, 0x38686000, 0x38688000, 0x3868A000, 0x3868C000, 0x3868E000, 0x38690000, 0x38692000, 0x38694000, 0x38696000, 0x38698000, 0x3869A000, 0x3869C000, 0x3869E000,
  0x386A0000, 0x386A2000, 0x386A4000, 0x386A6000, 0x386A8000, 0x386AA000, 0x386AC000, 0x386AE000, 0x386B0000, 0x386B2000, 0x386B4000, 0x386B6000, 0x386B8000, 0x386BA000, 0x386BC000, 0x386BE000,
  0x386C0000, 0x386C2000, 0x386C4000, 0x386C6000, 0x386C8000, 0x386CA000, 0x386CC000, 0x386CE000, 0x386D0000, 0x386D2000, 0x386D4000, 0x386D6000, 0x386D8000, 0x386DA000, 0x386DC000, 0x386DE000,
  0x386E0000, 0x386E2000, 0x386E4000, 0x386E6000, 0x386E8000, 0x386EA000, 0x386EC000, 0x386EE000, 0x386F0000, 0x386F2000, 0x386F4000, 0x386F6000, 0x386F8000, 0x386FA000, 0x386FC000, 0x386FE000,
  0x38700000, 0x38702000, 0x38704000, 0x38706000, 0x38708000, 0x3870A000, 0x3870C000, 0x3870E000, 0x38710000, 0x38712000, 0x38714000, 0x38716000, 0x38718000, 0x3871A000, 0x3871C000, 0x3871E000,
  0x38720000, 0x38722000, 0x38724000, 0x38726000, 0x38728000, 0x3872A000, 0x3872C000, 0x3872E000, 0x38730000, 0x38732000, 0x38734000, 0x38736000, 0x38738000, 0x3873A000, 0x3873C000, 0x3873E000,
  0x38740000, 0x38742000, 0x38744000, 0x38746000, 0x38748000, 0x3874A000, 0x3874C000, 0x3874E000, 0x38750000, 0x38752000, 0x38754000, 0x38756000, 0x38758000, 0x3875A000, 0x3875C000, 0x3875E000,
  0x38760000, 0x38762000, 0x38764000, 0x38766000, 0x38768000, 0x3876A000, 0x3876C000, 0x3876E000, 0x38770000, 0x38772000, 0x38774000, 0x38776000, 0x38778000, 0x3877A000, 0x3877C000, 0x3877E000,
  0x38780000, 0x38782000, 0x38784000, 0x38786000, 0x38788000, 0x3878A000, 0x3878C000, 0x3878E000, 0x38790000, 0x38792000, 0x38794000, 0x38796000, 0x38798000, 0x3879A000, 0x3879C000, 0x3879E000,
  0x387A0000, 0x387A2000, 0x387A4000, 0x387A6000, 0x387A8000, 0x387AA000, 0x387AC000, 0x387AE000, 0x387B0000, 0x387B2000, 0x387B4000, 0x387B6000, 0x387B8000, 0x387BA000, 0x387BC000, 0x387BE000,
  0x387C0000, 0x387C2000, 0x387C4000, 0x387C6000, 0x387C8000, 0x387CA000, 0x387CC000, 0x387CE000, 0x387D0000, 0x387D2000, 0x387D4000, 0x387D6000, 0x387D8000, 0x387DA000, 0x387DC000, 0x387DE000,
  0x387E0000, 0x387E2000, 0x387E4000, 0x387E6000, 0x387E8000, 0x387EA000, 0x387EC000, 0x387EE000, 0x387F0000, 0x387F2000, 0x387F4000, 0x387F6000, 0x387F8000, 0x387FA000, 0x387FC000, 0x387FE000 };
__constant static const uint32_t exponent_table[64] = {
  0x00000000, 0x00800000, 0x01000000, 0x01800000, 0x02000000, 0x02800000, 0x03000000, 0x03800000, 0x04000000, 0x04800000, 0x05000000, 0x05800000, 0x06000000, 0x06800000, 0x07000000, 0x07800000,
  0x08000000, 0x08800000, 0x09000000, 0x09800000, 0x0A000000, 0x0A800000, 0x0B000000, 0x0B800000, 0x0C000000, 0x0C800000, 0x0D000000, 0x0D800000, 0x0E000000, 0x0E800000, 0x0F000000, 0x47800000,
  0x80000000, 0x80800000, 0x81000000, 0x81800000, 0x82000000, 0x82800000, 0x83000000, 0x83800000, 0x84000000, 0x84800000, 0x85000000, 0x85800000, 0x86000000, 0x86800000, 0x87000000, 0x87800000,
  0x88000000, 0x88800000, 0x89000000, 0x89800000, 0x8A000000, 0x8A800000, 0x8B000000, 0x8B800000, 0x8C000000, 0x8C800000, 0x8D000000, 0x8D800000, 0x8E000000, 0x8E800000, 0x8F000000, 0xC7800000 };
__constant static const unsigned short offset_table[64] = {
  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024,
  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024 };

SCALAR_FUN_ATTR uint16_t float2halfbits(float value) {
  union { float x; uint32_t y; } u;
  u.x = value;
  uint32_t bits = u.y;

  uint16_t hbits = base_table[bits>>23] + (uint16_t)((bits&0x7FFFFF)>>shift_table[bits>>23]);;

  return hbits;
}

SCALAR_FUN_ATTR float halfbits2float(uint16_t value) {
  uint32_t bits = mantissa_table[offset_table[value>>10]+(value&0x3FF)] + exponent_table[value>>10];

  union { uint32_t x; float y; } u;
  u.x = bits;
  return u.y;
}

SCALAR_FUN_ATTR uint16_t halfbitsnextafter(uint16_t from, uint16_t to) {
  int fabs = from & 0x7FFF, tabs = to & 0x7FFF;
  if(fabs > 0x7C00 || tabs > 0x7C00) {
    return ((from&0x7FFF)>0x7C00) ? (from|0x200) : (to|0x200);
  }
  if(from == to || !(fabs|tabs)) {
    return to;
  }
  if(!fabs) {
    return (to&0x8000)+1;
  }
  unsigned int out =
    from +
    (((from>>15)^(unsigned int)((from^(0x8000|(0x8000-(from>>15))))<(to^(0x8000|(0x8000-(to>>15))))))<<1)
    - 1;
  return out;
}

// End of half.h.
// Start of timing.h.

// The function get_wall_time() returns the wall time in microseconds
// (with an unspecified offset).

#ifdef _WIN32

#include <windows.h>

static int64_t get_wall_time(void) {
  LARGE_INTEGER time,freq;
  assert(QueryPerformanceFrequency(&freq));
  assert(QueryPerformanceCounter(&time));
  return ((double)time.QuadPart / freq.QuadPart) * 1000000;
}

static int64_t get_wall_time_ns(void) {
  return get_wall_time() * 1000;
}

#else
// Assuming POSIX

#include <time.h>
#include <sys/time.h>

static int64_t get_wall_time(void) {
  struct timeval time;
  assert(gettimeofday(&time,NULL) == 0);
  return time.tv_sec * 1000000 + time.tv_usec;
}

static int64_t get_wall_time_ns(void) {
  struct timespec time;
  assert(clock_gettime(CLOCK_REALTIME, &time) == 0);
  return time.tv_sec * 1000000000 + time.tv_nsec;
}

#endif

// End of timing.h.
// Start of lock.h.

// A very simple cross-platform implementation of locks.  Uses
// pthreads on Unix and some Windows thing there.  Futhark's
// host-level code is not multithreaded, but user code may be, so we
// need some mechanism for ensuring atomic access to API functions.
// This is that mechanism.  It is not exposed to user code at all, so
// we do not have to worry about name collisions.

#ifdef _WIN32

typedef HANDLE lock_t;

static void create_lock(lock_t *lock) {
  *lock = CreateMutex(NULL,  // Default security attributes.
                      FALSE, // Initially unlocked.
                      NULL); // Unnamed.
}

static void lock_lock(lock_t *lock) {
  assert(WaitForSingleObject(*lock, INFINITE) == WAIT_OBJECT_0);
}

static void lock_unlock(lock_t *lock) {
  assert(ReleaseMutex(*lock));
}

static void free_lock(lock_t *lock) {
  CloseHandle(*lock);
}

#else
// Assuming POSIX

#include <pthread.h>

typedef pthread_mutex_t lock_t;

static void create_lock(lock_t *lock) {
  int r = pthread_mutex_init(lock, NULL);
  assert(r == 0);
}

static void lock_lock(lock_t *lock) {
  int r = pthread_mutex_lock(lock);
  assert(r == 0);
}

static void lock_unlock(lock_t *lock) {
  int r = pthread_mutex_unlock(lock);
  assert(r == 0);
}

static void free_lock(lock_t *lock) {
  // Nothing to do for pthreads.
  (void)lock;
}

#endif

// End of lock.h.
// Start of free_list.h.

typedef uintptr_t fl_mem;

// An entry in the free list.  May be invalid, to avoid having to
// deallocate entries as soon as they are removed.  There is also a
// tag, to help with memory reuse.
struct free_list_entry {
  size_t size;
  fl_mem mem;
  const char *tag;
  unsigned char valid;
};

struct free_list {
  struct free_list_entry *entries; // Pointer to entries.
  int capacity;                    // Number of entries.
  int used;                        // Number of valid entries.
  lock_t lock;                     // Thread safety.
};

static void free_list_init(struct free_list *l) {
  l->capacity = 30; // Picked arbitrarily.
  l->used = 0;
  l->entries = (struct free_list_entry*) malloc(sizeof(struct free_list_entry) * l->capacity);
  for (int i = 0; i < l->capacity; i++) {
    l->entries[i].valid = 0;
  }
  create_lock(&l->lock);
}

// Remove invalid entries from the free list.
static void free_list_pack(struct free_list *l) {
  lock_lock(&l->lock);
  int p = 0;
  for (int i = 0; i < l->capacity; i++) {
    if (l->entries[i].valid) {
      l->entries[p] = l->entries[i];
      if (i > p) {
        l->entries[i].valid = 0;
      }
      p++;
    }
  }

  // Now p is the number of used elements.  We don't want it to go
  // less than the default capacity (although in practice it's OK as
  // long as it doesn't become 1).
  if (p < 30) {
    p = 30;
  }
  l->entries = realloc(l->entries, p * sizeof(struct free_list_entry));
  l->capacity = p;
  lock_unlock(&l->lock);
}

static void free_list_destroy(struct free_list *l) {
  assert(l->used == 0);
  free(l->entries);
  free_lock(&l->lock);
}

// Not part of the interface, so no locking.
static int free_list_find_invalid(struct free_list *l) {
  int i;
  for (i = 0; i < l->capacity; i++) {
    if (!l->entries[i].valid) {
      break;
    }
  }
  return i;
}

static void free_list_insert(struct free_list *l, size_t size, fl_mem mem, const char *tag) {
  lock_lock(&l->lock);
  int i = free_list_find_invalid(l);

  if (i == l->capacity) {
    // List is full; so we have to grow it.
    int new_capacity = l->capacity * 2 * sizeof(struct free_list_entry);
    l->entries = realloc(l->entries, new_capacity);
    for (int j = 0; j < l->capacity; j++) {
      l->entries[j+l->capacity].valid = 0;
    }
    l->capacity *= 2;
  }

  // Now 'i' points to the first invalid entry.
  l->entries[i].valid = 1;
  l->entries[i].size = size;
  l->entries[i].mem = mem;
  l->entries[i].tag = tag;

  l->used++;
  lock_unlock(&l->lock);
}

// Determine whether this entry in the free list is acceptable for
// satisfying the request.  Not public, so no locking.
static bool free_list_acceptable(size_t size, const char* tag, struct free_list_entry *entry) {
  // We check not just the hard requirement (is the entry acceptable
  // and big enough?) but also put a cap on how much wasted space
  // (internal fragmentation) we allow.  This is necessarily a
  // heuristic, and a crude one.

  if (!entry->valid) {
    return false;
  }

  if (size > entry->size) {
    return false;
  }

  // We know the block fits.  Now the question is whether it is too
  // big.  Our policy is as follows:
  //
  // 1) We don't care about wasted space below 4096 bytes (to avoid
  // churn in tiny allocations).
  //
  // 2) If the tag matches, we allow _any_ amount of wasted space.
  //
  // 3) Otherwise we allow up to 50% wasted space.

  if (entry->size < 4096) {
    return true;
  }

  if (entry->tag == tag) {
    return true;
  }

  if (entry->size < size * 2) {
    return true;
  }

  return false;
}

// Find and remove a memory block of the indicated tag, or if that
// does not exist, another memory block with exactly the desired size.
// Returns 0 on success.
static int free_list_find(struct free_list *l, size_t size, const char *tag,
                          size_t *size_out, fl_mem *mem_out) {
  lock_lock(&l->lock);
  int size_match = -1;
  int i;
  int ret = 1;
  for (i = 0; i < l->capacity; i++) {
    if (free_list_acceptable(size, tag, &l->entries[i]) &&
        (size_match < 0 || l->entries[i].size < l->entries[size_match].size)) {
      // If this entry is valid, has sufficient size, and is smaller than the
      // best entry found so far, use this entry.
      size_match = i;
    }
  }

  if (size_match >= 0) {
    l->entries[size_match].valid = 0;
    *size_out = l->entries[size_match].size;
    *mem_out = l->entries[size_match].mem;
    l->used--;
    ret = 0;
  }
  lock_unlock(&l->lock);
  return ret;
}

// Remove the first block in the free list.  Returns 0 if a block was
// removed, and nonzero if the free list was already empty.
static int free_list_first(struct free_list *l, fl_mem *mem_out) {
  lock_lock(&l->lock);
  int ret = 1;
  for (int i = 0; i < l->capacity; i++) {
    if (l->entries[i].valid) {
      l->entries[i].valid = 0;
      *mem_out = l->entries[i].mem;
      l->used--;
      ret = 0;
      break;
    }
  }
  lock_unlock(&l->lock);
  return ret;
}

// End of free_list.h.
// Start of event_list.h

typedef int (*event_report_fn)(struct str_builder*, void*);

struct event {
  void* data;
  event_report_fn f;
  const char* name;
  char *description;
};

struct event_list {
  struct event *events;
  int num_events;
  int capacity;
};

static void event_list_init(struct event_list *l) {
  l->capacity = 100;
  l->num_events = 0;
  l->events = calloc(l->capacity, sizeof(struct event));
}

static void event_list_free(struct event_list *l) {
  free(l->events);
}

static void add_event_to_list(struct event_list *l,
                              const char* name,
                              char* description,
                              void* data,
                              event_report_fn f) {
  if (l->num_events == l->capacity) {
    l->capacity *= 2;
    l->events = realloc(l->events, l->capacity * sizeof(struct event));
  }
  l->events[l->num_events].name = name;
  l->events[l->num_events].description = description;
  l->events[l->num_events].data = data;
  l->events[l->num_events].f = f;
  l->num_events++;
}

static int report_events_in_list(struct event_list *l,
                                 struct str_builder* sb) {
  int ret = 0;
  for (int i = 0; i < l->num_events; i++) {
    if (i != 0) {
      str_builder_str(sb, ",");
    }
    str_builder_str(sb, "{\"name\":");
    str_builder_json_str(sb, l->events[i].name);
    str_builder_str(sb, ",\"description\":");
    str_builder_json_str(sb, l->events[i].description);
    free(l->events[i].description);
    if (l->events[i].f(sb, l->events[i].data) != 0) {
      ret = 1;
      break;
    }
    str_builder(sb, "}");
  }
  event_list_free(l);
  event_list_init(l);
  return ret;
}

// End of event_list.h

#ifdef _MSC_VER
#define inline __inline
#endif
#include <string.h>
#include <string.h>
#include <errno.h>
#include <assert.h>
#include <ctype.h>


#include <cuda.h>
#include <cuda_runtime.h>
#include <nvrtc.h>


#define FUTHARK_F64_ENABLED

// Start of scalar.h.

// Implementation of the primitive scalar operations.  Very
// repetitive.  This code is inserted directly into both CUDA and
// OpenCL programs, as well as the CPU code, so it has some #ifdefs to
// work everywhere.  Some operations are defined as macros because
// this allows us to use them as constant expressions in things like
// array sizes and static initialisers.

// Some of the #ifdefs are because OpenCL uses type-generic functions
// for some operations (e.g. sqrt), while C and CUDA sensibly use
// distinct functions for different precisions (e.g. sqrtf() and
// sqrt()).  This is quite annoying.  Due to C's unfortunate casting
// rules, it is also really easy to accidentally implement
// floating-point functions in the wrong precision, so be careful.

// Double-precision definitions are only included if the preprocessor
// macro FUTHARK_F64_ENABLED is set.

SCALAR_FUN_ATTR int32_t futrts_to_bits32(float x);
SCALAR_FUN_ATTR float futrts_from_bits32(int32_t x);

SCALAR_FUN_ATTR uint8_t add8(uint8_t x, uint8_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint16_t add16(uint16_t x, uint16_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint32_t add32(uint32_t x, uint32_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint64_t add64(uint64_t x, uint64_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint8_t sub8(uint8_t x, uint8_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint16_t sub16(uint16_t x, uint16_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint32_t sub32(uint32_t x, uint32_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint64_t sub64(uint64_t x, uint64_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint8_t mul8(uint8_t x, uint8_t y) {
  return x * y;
}

SCALAR_FUN_ATTR uint16_t mul16(uint16_t x, uint16_t y) {
  return x * y;
}

SCALAR_FUN_ATTR uint32_t mul32(uint32_t x, uint32_t y) {
  return x * y;
}

SCALAR_FUN_ATTR uint64_t mul64(uint64_t x, uint64_t y) {
  return x * y;
}

#if ISPC

SCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {
  // This strange pattern is used to prevent the ISPC compiler from
  // causing SIGFPEs and bogus results on divisions where inactive lanes
  // have 0-valued divisors. It ensures that any inactive lane instead
  // has a divisor of 1. https://github.com/ispc/ispc/issues/2292
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return x / ys;
}

SCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return x / ys;
}

SCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return x % ys;
}

SCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int8_t q = x / ys;
  int8_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int16_t q = x / ys;
  int16_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  int32_t q = x / ys;
  int32_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int64_t q = x / ys;
  int64_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {
  return sdiv8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {
  return sdiv16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {
  return sdiv32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {
  return sdiv64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int8_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int16_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int32_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int64_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : sdiv8(x, y);
}

SCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : sdiv16(x, y);
}

SCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : sdiv32(x, y);
}

SCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : sdiv64(x, y);
}

SCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {
  return sdiv_safe8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {
  return sdiv_safe16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {
  return sdiv_safe32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {
  return sdiv_safe64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : smod8(x, y);
}

SCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : smod16(x, y);
}

SCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : smod32(x, y);
}

SCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : smod64(x, y);
}

SCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

#else

SCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {
  int8_t q = x / y;
  int8_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {
  int16_t q = x / y;
  int16_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {
  int32_t q = x / y;
  int32_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {
  int64_t q = x / y;
  int64_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {
  return sdiv8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {
  return sdiv16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {
  return sdiv32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {
  return sdiv64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {
  int8_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {
  int16_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {
  int32_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {
  int64_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : sdiv8(x, y);
}

SCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : sdiv16(x, y);
}

SCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : sdiv32(x, y);
}

SCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : sdiv64(x, y);
}

SCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {
  return sdiv_safe8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {
  return sdiv_safe16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {
  return sdiv_safe32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {
  return sdiv_safe64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : smod8(x, y);
}

SCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : smod16(x, y);
}

SCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : smod32(x, y);
}

SCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : smod64(x, y);
}

SCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : x % y;
}

#endif

SCALAR_FUN_ATTR int8_t smin8(int8_t x, int8_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int16_t smin16(int16_t x, int16_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int32_t smin32(int32_t x, int32_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int64_t smin64(int64_t x, int64_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint8_t umin8(uint8_t x, uint8_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint16_t umin16(uint16_t x, uint16_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint32_t umin32(uint32_t x, uint32_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint64_t umin64(uint64_t x, uint64_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int8_t smax8(int8_t x, int8_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR int16_t smax16(int16_t x, int16_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR int32_t smax32(int32_t x, int32_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR int64_t smax64(int64_t x, int64_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint8_t umax8(uint8_t x, uint8_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint16_t umax16(uint16_t x, uint16_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint32_t umax32(uint32_t x, uint32_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint64_t umax64(uint64_t x, uint64_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint8_t shl8(uint8_t x, uint8_t y) {
  return (uint8_t)(x << y);
}

SCALAR_FUN_ATTR uint16_t shl16(uint16_t x, uint16_t y) {
  return (uint16_t)(x << y);
}

SCALAR_FUN_ATTR uint32_t shl32(uint32_t x, uint32_t y) {
  return x << y;
}

SCALAR_FUN_ATTR uint64_t shl64(uint64_t x, uint64_t y) {
  return x << y;
}

SCALAR_FUN_ATTR uint8_t lshr8(uint8_t x, uint8_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint16_t lshr16(uint16_t x, uint16_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint32_t lshr32(uint32_t x, uint32_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint64_t lshr64(uint64_t x, uint64_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int8_t ashr8(int8_t x, int8_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int16_t ashr16(int16_t x, int16_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int32_t ashr32(int32_t x, int32_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int64_t ashr64(int64_t x, int64_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint8_t and8(uint8_t x, uint8_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint16_t and16(uint16_t x, uint16_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint32_t and32(uint32_t x, uint32_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint64_t and64(uint64_t x, uint64_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint8_t or8(uint8_t x, uint8_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint16_t or16(uint16_t x, uint16_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint32_t or32(uint32_t x, uint32_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint64_t or64(uint64_t x, uint64_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint8_t xor8(uint8_t x, uint8_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR uint16_t xor16(uint16_t x, uint16_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR uint32_t xor32(uint32_t x, uint32_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR uint64_t xor64(uint64_t x, uint64_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR bool ult8(uint8_t x, uint8_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ult16(uint16_t x, uint16_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ult32(uint32_t x, uint32_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ult64(uint64_t x, uint64_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ule8(uint8_t x, uint8_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool ule16(uint16_t x, uint16_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool ule32(uint32_t x, uint32_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool ule64(uint64_t x, uint64_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool slt8(int8_t x, int8_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool slt16(int16_t x, int16_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool slt32(int32_t x, int32_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool slt64(int64_t x, int64_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool sle8(int8_t x, int8_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool sle16(int16_t x, int16_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool sle32(int32_t x, int32_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool sle64(int64_t x, int64_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR uint8_t pow8(uint8_t x, uint8_t y) {
  uint8_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint16_t pow16(uint16_t x, uint16_t y) {
  uint16_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint32_t pow32(uint32_t x, uint32_t y) {
  uint32_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint64_t pow64(uint64_t x, uint64_t y) {
  uint64_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR bool itob_i8_bool(int8_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR bool itob_i16_bool(int16_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR bool itob_i32_bool(int32_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR bool itob_i64_bool(int64_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR int8_t btoi_bool_i8(bool x) {
  return x;
}

SCALAR_FUN_ATTR int16_t btoi_bool_i16(bool x) {
  return x;
}

SCALAR_FUN_ATTR int32_t btoi_bool_i32(bool x) {
  return x;
}

SCALAR_FUN_ATTR int64_t btoi_bool_i64(bool x) {
  return x;
}

#define sext_i8_i8(x) ((int8_t) (int8_t) (x))
#define sext_i8_i16(x) ((int16_t) (int8_t) (x))
#define sext_i8_i32(x) ((int32_t) (int8_t) (x))
#define sext_i8_i64(x) ((int64_t) (int8_t) (x))
#define sext_i16_i8(x) ((int8_t) (int16_t) (x))
#define sext_i16_i16(x) ((int16_t) (int16_t) (x))
#define sext_i16_i32(x) ((int32_t) (int16_t) (x))
#define sext_i16_i64(x) ((int64_t) (int16_t) (x))
#define sext_i32_i8(x) ((int8_t) (int32_t) (x))
#define sext_i32_i16(x) ((int16_t) (int32_t) (x))
#define sext_i32_i32(x) ((int32_t) (int32_t) (x))
#define sext_i32_i64(x) ((int64_t) (int32_t) (x))
#define sext_i64_i8(x) ((int8_t) (int64_t) (x))
#define sext_i64_i16(x) ((int16_t) (int64_t) (x))
#define sext_i64_i32(x) ((int32_t) (int64_t) (x))
#define sext_i64_i64(x) ((int64_t) (int64_t) (x))
#define zext_i8_i8(x) ((int8_t) (uint8_t) (x))
#define zext_i8_i16(x) ((int16_t) (uint8_t) (x))
#define zext_i8_i32(x) ((int32_t) (uint8_t) (x))
#define zext_i8_i64(x) ((int64_t) (uint8_t) (x))
#define zext_i16_i8(x) ((int8_t) (uint16_t) (x))
#define zext_i16_i16(x) ((int16_t) (uint16_t) (x))
#define zext_i16_i32(x) ((int32_t) (uint16_t) (x))
#define zext_i16_i64(x) ((int64_t) (uint16_t) (x))
#define zext_i32_i8(x) ((int8_t) (uint32_t) (x))
#define zext_i32_i16(x) ((int16_t) (uint32_t) (x))
#define zext_i32_i32(x) ((int32_t) (uint32_t) (x))
#define zext_i32_i64(x) ((int64_t) (uint32_t) (x))
#define zext_i64_i8(x) ((int8_t) (uint64_t) (x))
#define zext_i64_i16(x) ((int16_t) (uint64_t) (x))
#define zext_i64_i32(x) ((int32_t) (uint64_t) (x))
#define zext_i64_i64(x) ((int64_t) (uint64_t) (x))

SCALAR_FUN_ATTR int8_t abs8(int8_t x) {
  return (int8_t)abs(x);
}

SCALAR_FUN_ATTR int16_t abs16(int16_t x) {
  return (int16_t)abs(x);
}

SCALAR_FUN_ATTR int32_t abs32(int32_t x) {
  return abs(x);
}

SCALAR_FUN_ATTR int64_t abs64(int64_t x) {
#if defined(__OPENCL_VERSION__) || defined(ISPC)
  return abs(x);
#else
  return llabs(x);
#endif
}

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {
  return popcount(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {
  return popcount(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {
  return popcount(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {
  return popcount(x);
}
#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {
  return __popc(zext_i8_i32(x));
}

SCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {
  return __popc(zext_i16_i32(x));
}

SCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {
  return __popc(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {
  return __popcll(x);
}

#else // Not OpenCL or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_popc8(uint8_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc16(uint16_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc32(uint32_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc64(uint64_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR uint8_t  futrts_umul_hi8 ( uint8_t a,  uint8_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint8_t  futrts_smul_hi8 ( int8_t a,  int8_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return mul_hi(a, b); }
#elif defined(__CUDA_ARCH__)
SCALAR_FUN_ATTR  uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return __umulhi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return __umul64hi(a, b); }
SCALAR_FUN_ATTR  uint8_t futrts_smul_hi8 ( int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return __mulhi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return __mul64hi(a, b); }
#elif ISPC
SCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) {
  uint64_t ah = a >> 32;
  uint64_t al = a & 0xffffffff;
  uint64_t bh = b >> 32;
  uint64_t bl = b & 0xffffffff;

  uint64_t p1 = al * bl;
  uint64_t p2 = al * bh;
  uint64_t p3 = ah * bl;
  uint64_t p4 = ah * bh;

  uint64_t p1h = p1 >> 32;
  uint64_t p2h = p2 >> 32;
  uint64_t p3h = p3 >> 32;
  uint64_t p2l = p2 & 0xffffffff;
  uint64_t p3l = p3 & 0xffffffff;

  uint64_t l = p1h + p2l + p3l;
  uint64_t m = (p2 >> 32) + (p3 >> 32);
  uint64_t h = (l >> 32) + m + p4;

  return h;
}
SCALAR_FUN_ATTR  int8_t futrts_smul_hi8 ( int8_t a,  int8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) {
  uint64_t ah = a >> 32;
  uint64_t al = a & 0xffffffff;
  uint64_t bh = b >> 32;
  uint64_t bl = b & 0xffffffff;

  uint64_t p1 =  al * bl;
  int64_t  p2 = al * bh;
  int64_t  p3 = ah * bl;
  uint64_t p4 =  ah * bh;

  uint64_t p1h = p1 >> 32;
  uint64_t p2h = p2 >> 32;
  uint64_t p3h = p3 >> 32;
  uint64_t p2l = p2 & 0xffffffff;
  uint64_t p3l = p3 & 0xffffffff;

  uint64_t l = p1h + p2l + p3l;
  uint64_t m = (p2 >> 32) + (p3 >> 32);
  uint64_t h = (l >> 32) + m + p4;

  return h;
}

#else // Not OpenCL, ISPC, or CUDA, but plain C.
SCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return ((__uint128_t)a) * ((__uint128_t)b) >> 64; }
SCALAR_FUN_ATTR int8_t futrts_smul_hi8(int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }
SCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }
SCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((int64_t)a) * ((int64_t)b) >> 32; }
SCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) { return ((__int128_t)a) * ((__int128_t)b) >> 64; }
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR  uint8_t futrts_umad_hi8 ( uint8_t a,  uint8_t b,  uint8_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR  uint8_t futrts_smad_hi8( int8_t a,  int8_t b,   int8_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return mad_hi(a, b, c); }
#else // Not OpenCL

SCALAR_FUN_ATTR  uint8_t futrts_umad_hi8( uint8_t a,  uint8_t b,  uint8_t c) { return futrts_umul_hi8(a, b) + c; }
SCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return futrts_umul_hi16(a, b) + c; }
SCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return futrts_umul_hi32(a, b) + c; }
SCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return futrts_umul_hi64(a, b) + c; }
SCALAR_FUN_ATTR  uint8_t futrts_smad_hi8 ( int8_t a,  int8_t b,  int8_t c) { return futrts_smul_hi8(a, b) + c; }
SCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return futrts_smul_hi16(a, b) + c; }
SCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return futrts_smul_hi32(a, b) + c; }
SCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return futrts_smul_hi64(a, b) + c; }
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return clz(x);
}

#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return __clz(zext_i8_i32(x)) - 24;
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return __clz(zext_i16_i32(x)) - 16;
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return __clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return __clzll(x);
}

#elif ISPC

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return count_leading_zeros((int32_t)(uint8_t)x)-24;
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return count_leading_zeros((int32_t)(uint16_t)x)-16;
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return count_leading_zeros(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return count_leading_zeros(x);
}

#else // Not OpenCL, ISPC or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return x == 0 ? 8 : __builtin_clz((uint32_t)zext_i8_i32(x)) - 24;
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return x == 0 ? 16 : __builtin_clz((uint32_t)zext_i16_i32(x)) - 16;
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return x == 0 ? 32 : __builtin_clz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return x == 0 ? 64 : __builtin_clzll((uint64_t)x);
}
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  int i = 0;
  for (; i < 8 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  int i = 0;
  for (; i < 16 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  int i = 0;
  for (; i < 32 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  int i = 0;
  for (; i < 64 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  int y = __ffs(x);
  return y == 0 ? 8 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  int y = __ffs(x);
  return y == 0 ? 16 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  int y = __ffs(x);
  return y == 0 ? 32 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  int y = __ffsll(x);
  return y == 0 ? 64 : y - 1;
}

#elif ISPC

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  return x == 0 ? 8 : count_trailing_zeros((int32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  return x == 0 ? 16 : count_trailing_zeros((int32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  return count_trailing_zeros(x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  return count_trailing_zeros(x);
}

#else // Not OpenCL or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  return x == 0 ? 8 : __builtin_ctz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  return x == 0 ? 16 : __builtin_ctz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  return x == 0 ? 32 : __builtin_ctz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  return x == 0 ? 64 : __builtin_ctzll((uint64_t)x);
}
#endif

SCALAR_FUN_ATTR float fdiv32(float x, float y) {
  return x / y;
}

SCALAR_FUN_ATTR float fadd32(float x, float y) {
  return x + y;
}

SCALAR_FUN_ATTR float fsub32(float x, float y) {
  return x - y;
}

SCALAR_FUN_ATTR float fmul32(float x, float y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt32(float x, float y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple32(float x, float y) {
  return x <= y;
}

SCALAR_FUN_ATTR float sitofp_i8_f32(int8_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float sitofp_i16_f32(int16_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float sitofp_i32_f32(int32_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float sitofp_i64_f32(int64_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i8_f32(uint8_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i16_f32(uint16_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i32_f32(uint32_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i64_f32(uint64_t x) {
  return (float) x;
}

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR float fabs32(float x) {
  return fabs(x);
}

SCALAR_FUN_ATTR float fmax32(float x, float y) {
  return fmax(x, y);
}

SCALAR_FUN_ATTR float fmin32(float x, float y) {
  return fmin(x, y);
}

SCALAR_FUN_ATTR float fpow32(float x, float y) {
  return pow(x, y);
}

#elif ISPC

SCALAR_FUN_ATTR float fabs32(float x) {
  return abs(x);
}

SCALAR_FUN_ATTR float fmax32(float x, float y) {
  return isnan(x) ? y : isnan(y) ? x : max(x, y);
}

SCALAR_FUN_ATTR float fmin32(float x, float y) {
  return isnan(x) ? y : isnan(y) ? x : min(x, y);
}

SCALAR_FUN_ATTR float fpow32(float a, float b) {
  float ret;
  foreach_active (i) {
      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));
      ret = insert(ret, i, r);
  }
  return ret;
}

#else // Not OpenCL, but CUDA or plain C.

SCALAR_FUN_ATTR float fabs32(float x) {
  return fabsf(x);
}

SCALAR_FUN_ATTR float fmax32(float x, float y) {
  return fmaxf(x, y);
}

SCALAR_FUN_ATTR float fmin32(float x, float y) {
  return fminf(x, y);
}

SCALAR_FUN_ATTR float fpow32(float x, float y) {
  return powf(x, y);
}
#endif

SCALAR_FUN_ATTR bool futrts_isnan32(float x) {
  return isnan(x);
}

#if ISPC

SCALAR_FUN_ATTR bool futrts_isinf32(float x) {
  return !isnan(x) && isnan(x - x);
}

SCALAR_FUN_ATTR bool futrts_isfinite32(float x) {
  return !isnan(x) && !futrts_isinf32(x);
}

#else

SCALAR_FUN_ATTR bool futrts_isinf32(float x) {
  return isinf(x);
}

#endif

SCALAR_FUN_ATTR int8_t fptosi_f32_i8(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f32_i16(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f32_i32(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f32_i64(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int64_t) x;
  };
}

SCALAR_FUN_ATTR uint8_t fptoui_f32_i8(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f32_i16(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f32_i32(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f32_i64(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f32_bool(float x) {
  return x != 0;
}

SCALAR_FUN_ATTR float btof_bool_f32(bool x) {
  return x ? 1 : 0;
}

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR float futrts_log32(float x) {
  return log(x);
}

SCALAR_FUN_ATTR float futrts_log2_32(float x) {
  return log2(x);
}

SCALAR_FUN_ATTR float futrts_log10_32(float x) {
  return log10(x);
}

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  return log1p(x);
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) {
  return sqrt(x);
}

SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  return cbrt(x);
}

SCALAR_FUN_ATTR float futrts_exp32(float x) {
  return exp(x);
}

SCALAR_FUN_ATTR float futrts_cos32(float x) {
  return cos(x);
}

SCALAR_FUN_ATTR float futrts_sin32(float x) {
  return sin(x);
}

SCALAR_FUN_ATTR float futrts_tan32(float x) {
  return tan(x);
}

SCALAR_FUN_ATTR float futrts_acos32(float x) {
  return acos(x);
}

SCALAR_FUN_ATTR float futrts_asin32(float x) {
  return asin(x);
}

SCALAR_FUN_ATTR float futrts_atan32(float x) {
  return atan(x);
}

SCALAR_FUN_ATTR float futrts_cosh32(float x) {
  return cosh(x);
}

SCALAR_FUN_ATTR float futrts_sinh32(float x) {
  return sinh(x);
}

SCALAR_FUN_ATTR float futrts_tanh32(float x) {
  return tanh(x);
}

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  return acosh(x);
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  return asinh(x);
}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  return atanh(x);
}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {
  return atan2(x, y);
}

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  return hypot(x, y);
}

SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  return tgamma(x);
}

SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  return lgamma(x);
}

SCALAR_FUN_ATTR float futrts_erf32(float x) {
  return erf(x);
}

SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  return erfc(x);
}

SCALAR_FUN_ATTR float fmod32(float x, float y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR float futrts_round32(float x) {
  return rint(x);
}

SCALAR_FUN_ATTR float futrts_floor32(float x) {
  return floor(x);
}

SCALAR_FUN_ATTR float futrts_ceil32(float x) {
  return ceil(x);
}

SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  return nextafter(x, y);
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return mix(v0, v1, t);
}

SCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {
  return ldexp(x, y);
}

SCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {
  return copysign(x, y);
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return mad(a, b, c);
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return fma(a, b, c);
}

#elif ISPC

SCALAR_FUN_ATTR float futrts_log32(float x) {
  return futrts_isfinite32(x) || (futrts_isinf32(x) && x < 0)? log(x) : x;
}

SCALAR_FUN_ATTR float futrts_log2_32(float x) {
  return futrts_log32(x) / log(2.0f);
}

SCALAR_FUN_ATTR float futrts_log10_32(float x) {
  return futrts_log32(x) / log(10.0f);
}

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  if(x == -1.0f || (futrts_isinf32(x) && x > 0.0f)) return x / 0.0f;
  float y = 1.0f + x;
  float z = y - 1.0f;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) {
  return sqrt(x);
}

extern "C" unmasked uniform float cbrtf(uniform float);
SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = cbrtf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float futrts_exp32(float x) {
  return exp(x);
}

SCALAR_FUN_ATTR float futrts_cos32(float x) {
  return cos(x);
}

SCALAR_FUN_ATTR float futrts_sin32(float x) {
  return sin(x);
}

SCALAR_FUN_ATTR float futrts_tan32(float x) {
  return tan(x);
}

SCALAR_FUN_ATTR float futrts_acos32(float x) {
  return acos(x);
}

SCALAR_FUN_ATTR float futrts_asin32(float x) {
  return asin(x);
}

SCALAR_FUN_ATTR float futrts_atan32(float x) {
  return atan(x);
}

SCALAR_FUN_ATTR float futrts_cosh32(float x) {
  return (exp(x)+exp(-x)) / 2.0f;
}

SCALAR_FUN_ATTR float futrts_sinh32(float x) {
  return (exp(x)-exp(-x)) / 2.0f;
}

SCALAR_FUN_ATTR float futrts_tanh32(float x) {
  return futrts_sinh32(x)/futrts_cosh32(x);
}

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  float f = x+sqrt(x*x-1);
  if(futrts_isfinite32(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  float f = x+sqrt(x*x+1);
  if(futrts_isfinite32(f)) return log(f);
  return f;

}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  float f = (1+x)/(1-x);
  if(futrts_isfinite32(f)) return log(f)/2.0f;
  return f;

}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {
  return (x == 0.0f && y == 0.0f) ? 0.0f : atan2(x, y);
}

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  if (futrts_isfinite32(x) && futrts_isfinite32(y)) {
    x = abs(x);
    y = abs(y);
    float a;
    float b;
    if (x >= y){
        a = x;
        b = y;
    } else {
        a = y;
        b = x;
    }
    if(b == 0){
      return a;
    }

    int e;
    float an;
    float bn;
    an = frexp (a, &e);
    bn = ldexp (b, - e);
    float cn;
    cn = sqrt (an * an + bn * bn);
    return ldexp (cn, e);
  } else {
    if (futrts_isinf32(x) || futrts_isinf32(y)) return INFINITY;
    else return x + y;
  }

}

extern "C" unmasked uniform float tgammaf(uniform float x);
SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = tgammaf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float lgammaf(uniform float x);
SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = lgammaf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float erff(uniform float x);
SCALAR_FUN_ATTR float futrts_erf32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = erff(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float erfcf(uniform float x);
SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = erfcf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float fmod32(float x, float y) {
  return x - y * trunc(x/y);
}

SCALAR_FUN_ATTR float futrts_round32(float x) {
  return round(x);
}

SCALAR_FUN_ATTR float futrts_floor32(float x) {
  return floor(x);
}

SCALAR_FUN_ATTR float futrts_ceil32(float x) {
  return ceil(x);
}

extern "C" unmasked uniform float nextafterf(uniform float x, uniform float y);
SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  float res;
  foreach_active (i) {
    uniform float r = nextafterf(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {
  return x * pow((double)2.0, (double)y);
}

SCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {
  int32_t xb = futrts_to_bits32(x);
  int32_t yb = futrts_to_bits32(y);
  return futrts_from_bits32((xb & ~(1<<31)) | (yb & (1<<31)));
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return a * b + c;
}

#else // Not OpenCL or ISPC, but CUDA or plain C.

SCALAR_FUN_ATTR float futrts_log32(float x) {
  return logf(x);
}

SCALAR_FUN_ATTR float futrts_log2_32(float x) {
  return log2f(x);
}

SCALAR_FUN_ATTR float futrts_log10_32(float x) {
  return log10f(x);
}

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  return log1pf(x);
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) {
  return sqrtf(x);
}

SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  return cbrtf(x);
}

SCALAR_FUN_ATTR float futrts_exp32(float x) {
  return expf(x);
}

SCALAR_FUN_ATTR float futrts_cos32(float x) {
  return cosf(x);
}

SCALAR_FUN_ATTR float futrts_sin32(float x) {
  return sinf(x);
}

SCALAR_FUN_ATTR float futrts_tan32(float x) {
  return tanf(x);
}

SCALAR_FUN_ATTR float futrts_acos32(float x) {
  return acosf(x);
}

SCALAR_FUN_ATTR float futrts_asin32(float x) {
  return asinf(x);
}

SCALAR_FUN_ATTR float futrts_atan32(float x) {
  return atanf(x);
}

SCALAR_FUN_ATTR float futrts_cosh32(float x) {
  return coshf(x);
}

SCALAR_FUN_ATTR float futrts_sinh32(float x) {
  return sinhf(x);
}

SCALAR_FUN_ATTR float futrts_tanh32(float x) {
  return tanhf(x);
}

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  return acoshf(x);
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  return asinhf(x);
}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  return atanhf(x);
}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {
  return atan2f(x, y);
}

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  return hypotf(x, y);
}

SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  return tgammaf(x);
}

SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  return lgammaf(x);
}

SCALAR_FUN_ATTR float futrts_erf32(float x) {
  return erff(x);
}

SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  return erfcf(x);
}

SCALAR_FUN_ATTR float fmod32(float x, float y) {
  return fmodf(x, y);
}

SCALAR_FUN_ATTR float futrts_round32(float x) {
  return rintf(x);
}

SCALAR_FUN_ATTR float futrts_floor32(float x) {
  return floorf(x);
}

SCALAR_FUN_ATTR float futrts_ceil32(float x) {
  return ceilf(x);
}

SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  return nextafterf(x, y);
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {
  return ldexpf(x, y);
}

SCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {
  return copysignf(x, y);
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return fmaf(a, b, c);
}
#endif

#if ISPC
SCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {
  return intbits(x);
}

SCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {
  return floatbits(x);
}
#else
SCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {
  union {
    float f;
    int32_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {
  union {
    int32_t f;
    float t;
  } p;

  p.f = x;
  return p.t;
}
#endif

SCALAR_FUN_ATTR float fsignum32(float x) {
  return futrts_isnan32(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);
}

#ifdef FUTHARK_F64_ENABLED

SCALAR_FUN_ATTR double futrts_from_bits64(int64_t x);
SCALAR_FUN_ATTR int64_t futrts_to_bits64(double x);

#if ISPC
SCALAR_FUN_ATTR bool futrts_isinf64(float x) {
  return !isnan(x) && isnan(x - x);
}

SCALAR_FUN_ATTR bool futrts_isfinite64(float x) {
  return !isnan(x) && !futrts_isinf64(x);
}

SCALAR_FUN_ATTR double fdiv64(double x, double y) {
  return x / y;
}

SCALAR_FUN_ATTR double fadd64(double x, double y) {
  return x + y;
}

SCALAR_FUN_ATTR double fsub64(double x, double y) {
  return x - y;
}

SCALAR_FUN_ATTR double fmul64(double x, double y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt64(double x, double y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple64(double x, double y) {
  return x <= y;
}

SCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double fabs64(double x) {
  return abs(x);
}

SCALAR_FUN_ATTR double fmax64(double x, double y) {
  return isnan(x) ? y : isnan(y) ? x : max(x, y);
}

SCALAR_FUN_ATTR double fmin64(double x, double y) {
  return isnan(x) ? y : isnan(y) ? x : min(x, y);
}

SCALAR_FUN_ATTR double fpow64(double a, double b) {
  float ret;
  foreach_active (i) {
      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));
      ret = insert(ret, i, r);
  }
  return ret;
}

SCALAR_FUN_ATTR double futrts_log64(double x) {
  return futrts_isfinite64(x) || (futrts_isinf64(x) && x < 0)? log(x) : x;
}

SCALAR_FUN_ATTR double futrts_log2_64(double x) {
  return futrts_log64(x)/log(2.0d);
}

SCALAR_FUN_ATTR double futrts_log10_64(double x) {
  return futrts_log64(x)/log(10.0d);
}

SCALAR_FUN_ATTR double futrts_log1p_64(double x) {
  if(x == -1.0d || (futrts_isinf64(x) && x > 0.0d)) return x / 0.0d;
  double y = 1.0d + x;
  double z = y - 1.0d;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR double futrts_sqrt64(double x) {
  return sqrt(x);
}

extern "C" unmasked uniform double cbrt(uniform double);
SCALAR_FUN_ATTR double futrts_cbrt64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = cbrtf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_exp64(double x) {
  return exp(x);
}

SCALAR_FUN_ATTR double futrts_cos64(double x) {
  return cos(x);
}

SCALAR_FUN_ATTR double futrts_sin64(double x) {
  return sin(x);
}

SCALAR_FUN_ATTR double futrts_tan64(double x) {
  return tan(x);
}

SCALAR_FUN_ATTR double futrts_acos64(double x) {
  return acos(x);
}

SCALAR_FUN_ATTR double futrts_asin64(double x) {
  return asin(x);
}

SCALAR_FUN_ATTR double futrts_atan64(double x) {
  return atan(x);
}

SCALAR_FUN_ATTR double futrts_cosh64(double x) {
  return (exp(x)+exp(-x)) / 2.0d;
}

SCALAR_FUN_ATTR double futrts_sinh64(double x) {
  return (exp(x)-exp(-x)) / 2.0d;
}

SCALAR_FUN_ATTR double futrts_tanh64(double x) {
  return futrts_sinh64(x)/futrts_cosh64(x);
}

SCALAR_FUN_ATTR double futrts_acosh64(double x) {
  double f = x+sqrt(x*x-1.0d);
  if(futrts_isfinite64(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR double futrts_asinh64(double x) {
  double f = x+sqrt(x*x+1.0d);
  if(futrts_isfinite64(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR double futrts_atanh64(double x) {
  double f = (1.0d+x)/(1.0d-x);
  if(futrts_isfinite64(f)) return log(f)/2.0d;
  return f;

}

SCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {
  return atan2(x, y);
}

extern "C" unmasked uniform double hypot(uniform double x, uniform double y);
SCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {
  double res;
  foreach_active (i) {
    uniform double r = hypot(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double tgamma(uniform double x);
SCALAR_FUN_ATTR double futrts_gamma64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = tgamma(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double lgamma(uniform double x);
SCALAR_FUN_ATTR double futrts_lgamma64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = lgamma(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double erf(uniform double x);
SCALAR_FUN_ATTR double futrts_erf64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = erf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double erfc(uniform double x);
SCALAR_FUN_ATTR double futrts_erfc64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = erfc(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {
  return a * b + c;
}

SCALAR_FUN_ATTR double futrts_round64(double x) {
  return round(x);
}

SCALAR_FUN_ATTR double futrts_ceil64(double x) {
  return ceil(x);
}

extern "C" unmasked uniform double nextafter(uniform float x, uniform double y);
SCALAR_FUN_ATTR float futrts_nextafter64(double x, double y) {
  double res;
  foreach_active (i) {
    uniform double r = nextafter(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_floor64(double x) {
  return floor(x);
}

SCALAR_FUN_ATTR bool futrts_isnan64(double x) {
  return isnan(x);
}

SCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int64_t) x;
  }
}

SCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f64_bool(double x) {
  return x != 0.0;
}

SCALAR_FUN_ATTR double btof_bool_f64(bool x) {
  return x ? 1.0 : 0.0;
}

SCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {
  int64_t res;
  foreach_active (i) {
    uniform double tmp = extract(x, i);
    uniform int64_t r = *((uniform int64_t* uniform)&tmp);
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {
  double res;
  foreach_active (i) {
    uniform int64_t tmp = extract(x, i);
    uniform double r = *((uniform double* uniform)&tmp);
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double fmod64(double x, double y) {
  return x - y * trunc(x/y);
}

SCALAR_FUN_ATTR double fsignum64(double x) {
  return futrts_isnan64(x) ? x : (x > 0 ? 1.0d : 0.0d) - (x < 0 ? 1.0d : 0.0d);
}

SCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {
  return x * pow((double)2.0, (double)y);
}

SCALAR_FUN_ATTR double futrts_copysign64(double x, double y) {
  int64_t xb = futrts_to_bits64(x);
  int64_t yb = futrts_to_bits64(y);
  return futrts_from_bits64((xb & ~(((int64_t)1)<<63)) | (yb & (((int64_t)1)<<63)));
}

SCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float fpconv_f32_f32(float x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f32_f64(float x) {
  return (double) x;
}

SCALAR_FUN_ATTR float fpconv_f64_f32(double x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f64_f64(double x) {
  return (double) x;
}

#else

SCALAR_FUN_ATTR double fdiv64(double x, double y) {
  return x / y;
}

SCALAR_FUN_ATTR double fadd64(double x, double y) {
  return x + y;
}

SCALAR_FUN_ATTR double fsub64(double x, double y) {
  return x - y;
}

SCALAR_FUN_ATTR double fmul64(double x, double y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt64(double x, double y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple64(double x, double y) {
  return x <= y;
}

SCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double fabs64(double x) {
  return fabs(x);
}

SCALAR_FUN_ATTR double fmax64(double x, double y) {
  return fmax(x, y);
}

SCALAR_FUN_ATTR double fmin64(double x, double y) {
  return fmin(x, y);
}

SCALAR_FUN_ATTR double fpow64(double x, double y) {
  return pow(x, y);
}

SCALAR_FUN_ATTR double futrts_log64(double x) {
  return log(x);
}

SCALAR_FUN_ATTR double futrts_log2_64(double x) {
  return log2(x);
}

SCALAR_FUN_ATTR double futrts_log10_64(double x) {
  return log10(x);
}

SCALAR_FUN_ATTR double futrts_log1p_64(double x) {
  return log1p(x);
}

SCALAR_FUN_ATTR double futrts_sqrt64(double x) {
  return sqrt(x);
}

SCALAR_FUN_ATTR double futrts_cbrt64(double x) {
  return cbrt(x);
}

SCALAR_FUN_ATTR double futrts_exp64(double x) {
  return exp(x);
}

SCALAR_FUN_ATTR double futrts_cos64(double x) {
  return cos(x);
}

SCALAR_FUN_ATTR double futrts_sin64(double x) {
  return sin(x);
}

SCALAR_FUN_ATTR double futrts_tan64(double x) {
  return tan(x);
}

SCALAR_FUN_ATTR double futrts_acos64(double x) {
  return acos(x);
}

SCALAR_FUN_ATTR double futrts_asin64(double x) {
  return asin(x);
}

SCALAR_FUN_ATTR double futrts_atan64(double x) {
  return atan(x);
}

SCALAR_FUN_ATTR double futrts_cosh64(double x) {
  return cosh(x);
}

SCALAR_FUN_ATTR double futrts_sinh64(double x) {
  return sinh(x);
}

SCALAR_FUN_ATTR double futrts_tanh64(double x) {
  return tanh(x);
}

SCALAR_FUN_ATTR double futrts_acosh64(double x) {
  return acosh(x);
}

SCALAR_FUN_ATTR double futrts_asinh64(double x) {
  return asinh(x);
}

SCALAR_FUN_ATTR double futrts_atanh64(double x) {
  return atanh(x);
}

SCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {
  return atan2(x, y);
}

SCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {
  return hypot(x, y);
}

SCALAR_FUN_ATTR double futrts_gamma64(double x) {
  return tgamma(x);
}

SCALAR_FUN_ATTR double futrts_lgamma64(double x) {
  return lgamma(x);
}

SCALAR_FUN_ATTR double futrts_erf64(double x) {
  return erf(x);
}

SCALAR_FUN_ATTR double futrts_erfc64(double x) {
  return erfc(x);
}

SCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {
  return fma(a, b, c);
}

SCALAR_FUN_ATTR double futrts_round64(double x) {
  return rint(x);
}

SCALAR_FUN_ATTR double futrts_ceil64(double x) {
  return ceil(x);
}

SCALAR_FUN_ATTR float futrts_nextafter64(float x, float y) {
  return nextafter(x, y);
}

SCALAR_FUN_ATTR double futrts_floor64(double x) {
  return floor(x);
}

SCALAR_FUN_ATTR bool futrts_isnan64(double x) {
  return isnan(x);
}

SCALAR_FUN_ATTR bool futrts_isinf64(double x) {
  return isinf(x);
}

SCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int64_t) x;
  }
}

SCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f64_bool(double x) {
  return x != 0;
}

SCALAR_FUN_ATTR double btof_bool_f64(bool x) {
  return x ? 1 : 0;
}

SCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {
  union {
    double f;
    int64_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {
  union {
    int64_t f;
    double t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR double fmod64(double x, double y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR double fsignum64(double x) {
  return futrts_isnan64(x) ? x : (x > 0) - (x < 0);
}

SCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {
#ifdef __OPENCL_VERSION__
  return mix(v0, v1, t);
#else
  return v0 + (v1 - v0) * t;
#endif
}

SCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {
  return ldexp(x, y);
}

SCALAR_FUN_ATTR float futrts_copysign64(double x, double y) {
  return copysign(x, y);
}

SCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {
#ifdef __OPENCL_VERSION__
  return mad(a, b, c);
#else
  return a * b + c;
#endif
}

SCALAR_FUN_ATTR float fpconv_f32_f32(float x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f32_f64(float x) {
  return (double) x;
}

SCALAR_FUN_ATTR float fpconv_f64_f32(double x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f64_f64(double x) {
  return (double) x;
}

#endif

#endif

// End of scalar.h.
// Start of scalar_f16.h.

// Half-precision is emulated if needed (e.g. in straight C) with the
// native type used if possible.  The emulation works by typedef'ing
// 'float' to 'f16', and then implementing all operations on single
// precision.  To cut down on duplication, we use the same code for
// those Futhark functions that require just operators or casts.  The
// in-memory representation for arrays will still be 16 bits even
// under emulation, so the compiler will have to be careful when
// generating reads or writes.

#if !defined(cl_khr_fp16) && !(defined(__CUDA_ARCH__) && __CUDA_ARCH__ >= 600) && !(defined(ISPC))
#define EMULATE_F16
#endif

#if !defined(EMULATE_F16) && defined(__OPENCL_VERSION__)
#pragma OPENCL EXTENSION cl_khr_fp16 : enable
#endif

#ifdef EMULATE_F16

// Note that the half-precision storage format is still 16 bits - the
// compiler will have to be real careful!
typedef float f16;

#elif ISPC
typedef float16 f16;

#else

#ifdef __CUDA_ARCH__
#include <cuda_fp16.h>
#endif

typedef half f16;

#endif

// Some of these functions convert to single precision because half
// precision versions are not available.

SCALAR_FUN_ATTR f16 fadd16(f16 x, f16 y) {
  return x + y;
}

SCALAR_FUN_ATTR f16 fsub16(f16 x, f16 y) {
  return x - y;
}

SCALAR_FUN_ATTR f16 fmul16(f16 x, f16 y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt16(f16 x, f16 y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple16(f16 x, f16 y) {
  return x <= y;
}

SCALAR_FUN_ATTR f16 sitofp_i8_f16(int8_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 sitofp_i16_f16(int16_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 sitofp_i32_f16(int32_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 sitofp_i64_f16(int64_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i8_f16(uint8_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i16_f16(uint16_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i32_f16(uint32_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i64_f16(uint64_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR int8_t fptosi_f16_i8(f16 x) {
  return (int8_t) (float) x;
}

SCALAR_FUN_ATTR int16_t fptosi_f16_i16(f16 x) {
  return (int16_t) x;
}

SCALAR_FUN_ATTR int32_t fptosi_f16_i32(f16 x) {
  return (int32_t) x;
}

SCALAR_FUN_ATTR int64_t fptosi_f16_i64(f16 x) {
  return (int64_t) x;
}

SCALAR_FUN_ATTR uint8_t fptoui_f16_i8(f16 x) {
  return (uint8_t) (float) x;
}

SCALAR_FUN_ATTR uint16_t fptoui_f16_i16(f16 x) {
  return (uint16_t) x;
}

SCALAR_FUN_ATTR uint32_t fptoui_f16_i32(f16 x) {
  return (uint32_t) x;
}

SCALAR_FUN_ATTR uint64_t fptoui_f16_i64(f16 x) {
  return (uint64_t) x;
}

SCALAR_FUN_ATTR bool ftob_f16_bool(f16 x) {
  return x != (f16)0;
}

SCALAR_FUN_ATTR f16 btof_bool_f16(bool x) {
  return x ? 1 : 0;
}

#ifndef EMULATE_F16
SCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {
  return isnan((float)x);
}

#ifdef __OPENCL_VERSION__

SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return fabs(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return fmax(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return fmin(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return pow(x, y);
}

#elif ISPC
SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return abs(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : max(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : min(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return pow(x, y);
}

#else // Assuming CUDA.

SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return fabsf(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return fmaxf(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return fminf(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return powf(x, y);
}
#endif

#if ISPC
SCALAR_FUN_ATTR bool futrts_isinf16(float x) {
  return !futrts_isnan16(x) && futrts_isnan16(x - x);
}
SCALAR_FUN_ATTR bool futrts_isfinite16(float x) {
  return !futrts_isnan16(x) && !futrts_isinf16(x);
}

#else

SCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {
  return isinf((float)x);
}
#endif

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return log(x);
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return log2(x);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return log10(x);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  return log1p(x);
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return sqrt(x);
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  return cbrt(x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return exp(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return cos(x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return sin(x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return tan(x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return acos(x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return asin(x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return atan(x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return cosh(x);
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return sinh(x);
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return tanh(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  return acosh(x);
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  return asinh(x);
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  return atanh(x);
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return atan2(x, y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return hypot(x, y);
}

SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  return tgamma(x);
}

SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  return lgamma(x);
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  return erf(x);
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  return erfc(x);
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return rint(x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return floor(x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return ceil(x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return nextafter(x, y);
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return mix(v0, v1, t);
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return ldexp(x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return copysign(x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return mad(a, b, c);
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return fma(a, b, c);
}
#elif ISPC

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return futrts_isfinite16(x) || (futrts_isinf16(x) && x < 0) ? log(x) : x;
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return futrts_log16(x) / log(2.0f16);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return futrts_log16(x) / log(10.0f16);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  if(x == -1.0f16 || (futrts_isinf16(x) && x > 0.0f16)) return x / 0.0f16;
  f16 y = 1.0f16 + x;
  f16 z = y - 1.0f16;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return (float16)sqrt((float)x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return exp(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return (float16)cos((float)x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return (float16)sin((float)x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return (float16)tan((float)x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return (float16)acos((float)x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return (float16)asin((float)x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return (float16)atan((float)x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return (exp(x)+exp(-x)) / 2.0f16;
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return (exp(x)-exp(-x)) / 2.0f16;
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return futrts_sinh16(x)/futrts_cosh16(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  float16 f = x+(float16)sqrt((float)(x*x-1));
  if(futrts_isfinite16(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  float16 f = x+(float16)sqrt((float)(x*x+1));
  if(futrts_isfinite16(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  float16 f = (1+x)/(1-x);
  if(futrts_isfinite16(f)) return log(f)/2.0f16;
  return f;
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return (float16)atan2((float)x, (float)y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return (float16)futrts_hypot32((float)x, (float)y);
}

extern "C" unmasked uniform float tgammaf(uniform float x);
SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  f16 res;
  foreach_active (i) {
    uniform f16 r = (f16)tgammaf(extract((float)x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float lgammaf(uniform float x);
SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  f16 res;
  foreach_active (i) {
    uniform f16 r = (f16)lgammaf(extract((float)x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  f16 res = (f16)futrts_cbrt32((float)x);
  return res;
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  f16 res = (f16)futrts_erf32((float)x);
  return res;
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  f16 res = (f16)futrts_erfc32((float)x);
  return res;
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return x - y * (float16)trunc((float) (x/y));
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return (float16)round((float)x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return (float16)floor((float)x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return (float16)ceil((float)x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return (float16)futrts_nextafter32((float)x, (float) y);
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return futrts_ldexp32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return futrts_copysign32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

#else // Assume CUDA.

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return hlog(x);
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return hlog2(x);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return hlog10(x);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  return (f16)log1pf((float)x);
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return hsqrt(x);
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  return cbrtf(x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return hexp(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return hcos(x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return hsin(x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return tanf(x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return acosf(x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return asinf(x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return atanf(x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return coshf(x);
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return sinhf(x);
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return tanhf(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  return acoshf(x);
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  return asinhf(x);
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  return atanhf(x);
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return atan2f(x, y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return hypotf(x, y);
}

SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  return tgammaf(x);
}

SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  return lgammaf(x);
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  return erff(x);
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  return erfcf(x);
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return fmodf(x, y);
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return rintf(x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return hfloor(x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return hceil(x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return __ushort_as_half(halfbitsnextafter(__half_as_ushort(x), __half_as_ushort(y)));
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return futrts_ldexp32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return futrts_copysign32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return fmaf(a, b, c);
}

#endif

// The CUDA __half type cannot be put in unions for some reason, so we
// use bespoke conversion functions instead.
#ifdef __CUDA_ARCH__
SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  return __half_as_ushort(x);
}
SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  return __ushort_as_half(x);
}
#elif ISPC

SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  varying int16_t y = *((varying int16_t * uniform)&x);
  return y;
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  varying f16 y = *((varying f16 * uniform)&x);
  return y;
}
#else
SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  union {
    f16 f;
    int16_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  union {
    int16_t f;
    f16 t;
  } p;

  p.f = x;
  return p.t;
}
#endif

#else // No native f16 - emulate.

SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return fabs32(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return fmax32(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return fmin32(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return fpow32(x, y);
}

SCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {
  return futrts_isnan32(x);
}

SCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {
  return futrts_isinf32(x);
}

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return futrts_log32(x);
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return futrts_log2_32(x);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return futrts_log10_32(x);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  return futrts_log1p_32(x);
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return futrts_sqrt32(x);
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  return futrts_cbrt32(x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return futrts_exp32(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return futrts_cos32(x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return futrts_sin32(x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return futrts_tan32(x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return futrts_acos32(x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return futrts_asin32(x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return futrts_atan32(x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return futrts_cosh32(x);
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return futrts_sinh32(x);
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return futrts_tanh32(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  return futrts_acosh32(x);
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  return futrts_asinh32(x);
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  return futrts_atanh32(x);
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return futrts_atan2_32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return futrts_hypot32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  return futrts_gamma32(x);
}

SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  return futrts_lgamma32(x);
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  return futrts_erf32(x);
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  return futrts_erfc32(x);
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return fmod32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return futrts_round32(x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return futrts_floor32(x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return futrts_ceil32(x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return halfbits2float(halfbitsnextafter(float2halfbits(x), float2halfbits(y)));
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return futrts_lerp32(v0, v1, t);
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return futrts_ldexp32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return futrts_copysign32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return futrts_mad32(a, b, c);
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return futrts_fma32(a, b, c);
}

// Even when we are using an OpenCL that does not support cl_khr_fp16,
// it must still support vload_half for actually creating a
// half-precision number, which can then be efficiently converted to a
// float.  Similarly for vstore_half.
#ifdef __OPENCL_VERSION__

SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  int16_t y;
  // Violating strict aliasing here.
  vstore_half((float)x, 0, (half*)&y);
  return y;
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  return (f16)vload_half(0, (half*)&x);
}

#else

SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  return (int16_t)float2halfbits(x);
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  return halfbits2float((uint16_t)x);
}

SCALAR_FUN_ATTR f16 fsignum16(f16 x) {
  return futrts_isnan16(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);
}

#endif

#endif

SCALAR_FUN_ATTR float fpconv_f16_f16(f16 x) {
  return x;
}

SCALAR_FUN_ATTR float fpconv_f16_f32(f16 x) {
  return x;
}

SCALAR_FUN_ATTR f16 fpconv_f32_f16(float x) {
  return (f16) x;
}

#ifdef FUTHARK_F64_ENABLED

SCALAR_FUN_ATTR double fpconv_f16_f64(f16 x) {
  return (double) x;
}

#if ISPC
SCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {
  return (f16) ((float)x);
}
#else
SCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {
  return (f16) x;
}
#endif
#endif


// End of scalar_f16.h.

// Start of context_prototypes.h
//
// Prototypes for the functions in context.h, or that will be called
// from those functions, that need to be available very early.

struct futhark_context_config;
struct futhark_context;

static void set_error(struct futhark_context* ctx, char *error);

// These are called in context/config new/free functions and contain
// shared setup.  They are generated by the compiler itself.
static int init_constants(struct futhark_context*);
static int free_constants(struct futhark_context*);
static void setup_program(struct futhark_context* ctx);
static void teardown_program(struct futhark_context *ctx);

// Allocate host memory.  Must be freed with host_free().
static void host_alloc(struct futhark_context* ctx, size_t size, const char* tag, size_t* size_out, void** mem_out);
// Allocate memory allocated with host_alloc().
static void host_free(struct futhark_context* ctx, size_t size, const char* tag, void* mem);

// Log that a copy has occurred.
static void log_copy(struct futhark_context* ctx,
                     const char *kind, int r,
                     int64_t dst_offset, int64_t dst_strides[r],
                     int64_t src_offset, int64_t src_strides[r],
                     int64_t shape[r]);

static void log_transpose(struct futhark_context* ctx,
                          int64_t k, int64_t m, int64_t n);

static bool lmad_map_tr(int64_t *num_arrays_out, int64_t *n_out, int64_t *m_out,
                        int r,
                        const int64_t dst_strides[r],
                        const int64_t src_strides[r],
                        const int64_t shape[r]);

static bool lmad_contiguous(int r, int64_t strides[r], int64_t shape[r]);

static bool lmad_memcpyable(int r,
                            int64_t dst_strides[r], int64_t src_strides[r], int64_t shape[r]);

static void add_event(struct futhark_context* ctx,
                      const char* name,
                      char* description,
                      void* data,
                      event_report_fn f);

// Functions that must be defined by the backend.
static void backend_context_config_setup(struct futhark_context_config* cfg);
static void backend_context_config_teardown(struct futhark_context_config* cfg);
static int backend_context_setup(struct futhark_context *ctx);
static void backend_context_teardown(struct futhark_context *ctx);

// End of of context_prototypes.h

struct memblock_device {
    int *references;
    CUdeviceptr mem;
    int64_t size;
    const char *desc;
};
struct memblock {
    int *references;
    unsigned char *mem;
    int64_t size;
    const char *desc;
};
struct constants {
    int dummy;
    struct memblock_device counters_mem_18763;
    struct memblock_device counters_mem_18765;
    struct memblock_device counters_mem_18789;
    struct memblock_device counters_mem_18825;
    struct memblock_device global_dynid_mem_18686;
    struct memblock_device global_dynid_mem_18892;
};
struct tuning_params {
    int dummy;
    int64_t *builtinzhiota_i64zitblock_sizze_18660;
    int64_t *builtinzhreplicate_i32zitblock_sizze_18774;
    int64_t *builtinzhreplicate_i64zitblock_sizze_18660;
    int64_t *builtinzhreplicate_i8zitblock_sizze_18877;
    int64_t *find_cluster_ids_6783zisegmap_tblock_sizze_16317;
    int64_t *find_cluster_ids_6783zisegmap_tblock_sizze_16438;
    int64_t *find_cluster_ids_6783zisegmap_tblock_sizze_16472;
    int64_t *find_cluster_ids_6783zisegmap_tblock_sizze_16617;
    int64_t *find_cluster_ids_6783zisegmap_tblock_sizze_16643;
    int64_t *find_cluster_ids_6783zisegred_num_tblocks_16410;
    int64_t *find_cluster_ids_6783zisegred_num_tblocks_16599;
    int64_t *find_cluster_ids_6783zisegred_tblock_sizze_16408;
    int64_t *find_cluster_ids_6783zisegred_tblock_sizze_16597;
    int64_t *find_cluster_ids_6783zisegscan_num_tblocks_16609;
    int64_t *find_cluster_ids_6783zisegscan_tblock_sizze_16607;
    int64_t *find_cluster_ids_6783zisuff_intra_par_1;
    int64_t *find_cluster_ids_6783zisuff_outer_par_0;
    int64_t *find_cluster_ids_6890zisegmap_tblock_sizze_16688;
    int64_t *find_cluster_ids_6890zisegmap_tblock_sizze_16809;
    int64_t *find_cluster_ids_6890zisegmap_tblock_sizze_16843;
    int64_t *find_cluster_ids_6890zisegmap_tblock_sizze_16988;
    int64_t *find_cluster_ids_6890zisegmap_tblock_sizze_17014;
    int64_t *find_cluster_ids_6890zisegred_num_tblocks_16781;
    int64_t *find_cluster_ids_6890zisegred_num_tblocks_16970;
    int64_t *find_cluster_ids_6890zisegred_tblock_sizze_16779;
    int64_t *find_cluster_ids_6890zisegred_tblock_sizze_16968;
    int64_t *find_cluster_ids_6890zisegscan_num_tblocks_16980;
    int64_t *find_cluster_ids_6890zisegscan_tblock_sizze_16978;
    int64_t *find_cluster_ids_6890zisuff_intra_par_1;
    int64_t *find_cluster_ids_6890zisuff_outer_par_0;
    int64_t *ftDBSCAN_doublezisegmap_tblock_sizze_17423;
    int64_t *ftDBSCAN_doublezisegmap_tblock_sizze_17450;
    int64_t *ftDBSCAN_doublezisegmap_tblock_sizze_17607;
    int64_t *ftDBSCAN_doublezisegmap_tblock_sizze_17637;
    int64_t *ftDBSCAN_doublezisegred_num_tblocks_17568;
    int64_t *ftDBSCAN_doublezisegred_tblock_sizze_17566;
    int64_t *ftDBSCAN_doublezisuff_intra_par_1;
    int64_t *ftDBSCAN_doublezisuff_outer_par_0;
    int64_t *ftDBSCAN_floatzisegmap_tblock_sizze_17050;
    int64_t *ftDBSCAN_floatzisegmap_tblock_sizze_17077;
    int64_t *ftDBSCAN_floatzisegmap_tblock_sizze_17234;
    int64_t *ftDBSCAN_floatzisegmap_tblock_sizze_17264;
    int64_t *ftDBSCAN_floatzisegred_num_tblocks_17195;
    int64_t *ftDBSCAN_floatzisegred_tblock_sizze_17193;
    int64_t *ftDBSCAN_floatzisuff_intra_par_1;
    int64_t *ftDBSCAN_floatzisuff_outer_par_0;
    int64_t *ftDBSCAN_star_doublezisegmap_tblock_sizze_16290;
    int64_t *ftDBSCAN_star_floatzisegmap_tblock_sizze_16272;
    int64_t *get_num_neighbours_6695zisegmap_tblock_sizze_17805;
    int64_t *get_num_neighbours_6695zisegmap_tblock_sizze_17893;
    int64_t *get_num_neighbours_6695zisegmap_tblock_sizze_17934;
    int64_t *get_num_neighbours_6695zisegmap_tblock_sizze_17966;
    int64_t *get_num_neighbours_6695zisegred_num_tblocks_17906;
    int64_t *get_num_neighbours_6695zisegred_tblock_sizze_17904;
    int64_t *get_num_neighbours_6695zisuff_intra_par_1;
    int64_t *get_num_neighbours_6695zisuff_outer_par_0;
    int64_t *get_num_neighbours_6842zisegmap_tblock_sizze_18106;
    int64_t *get_num_neighbours_6842zisegmap_tblock_sizze_18194;
    int64_t *get_num_neighbours_6842zisegmap_tblock_sizze_18235;
    int64_t *get_num_neighbours_6842zisegmap_tblock_sizze_18267;
    int64_t *get_num_neighbours_6842zisegred_num_tblocks_18207;
    int64_t *get_num_neighbours_6842zisegred_tblock_sizze_18205;
    int64_t *get_num_neighbours_6842zisuff_intra_par_1;
    int64_t *get_num_neighbours_6842zisuff_outer_par_0;
    int64_t *isolate_core_points_6732zisegmap_num_tblocks_16219;
    int64_t *isolate_core_points_6732zisegmap_tblock_sizze_16188;
    int64_t *isolate_core_points_6732zisegmap_tblock_sizze_16217;
    int64_t *isolate_core_points_6732zisegscan_num_tblocks_16178;
    int64_t *isolate_core_points_6732zisegscan_tblock_sizze_16176;
    int64_t *isolate_core_points_6871zisegmap_num_tblocks_16266;
    int64_t *isolate_core_points_6871zisegmap_tblock_sizze_16235;
    int64_t *isolate_core_points_6871zisegmap_tblock_sizze_16264;
    int64_t *isolate_core_points_6871zisegscan_num_tblocks_16225;
    int64_t *isolate_core_points_6871zisegscan_tblock_sizze_16223;
};
static const int num_tuning_params = 74;
static const char *tuning_param_names[] = {"builtin#iota_i64.tblock_size_18660", "builtin#replicate_i32.tblock_size_18774", "builtin#replicate_i64.tblock_size_18660", "builtin#replicate_i8.tblock_size_18877", "find_cluster_ids_6783.segmap_tblock_size_16317", "find_cluster_ids_6783.segmap_tblock_size_16438", "find_cluster_ids_6783.segmap_tblock_size_16472", "find_cluster_ids_6783.segmap_tblock_size_16617", "find_cluster_ids_6783.segmap_tblock_size_16643", "find_cluster_ids_6783.segred_num_tblocks_16410", "find_cluster_ids_6783.segred_num_tblocks_16599", "find_cluster_ids_6783.segred_tblock_size_16408", "find_cluster_ids_6783.segred_tblock_size_16597", "find_cluster_ids_6783.segscan_num_tblocks_16609", "find_cluster_ids_6783.segscan_tblock_size_16607", "find_cluster_ids_6783.suff_intra_par_1", "find_cluster_ids_6783.suff_outer_par_0", "find_cluster_ids_6890.segmap_tblock_size_16688", "find_cluster_ids_6890.segmap_tblock_size_16809", "find_cluster_ids_6890.segmap_tblock_size_16843", "find_cluster_ids_6890.segmap_tblock_size_16988", "find_cluster_ids_6890.segmap_tblock_size_17014", "find_cluster_ids_6890.segred_num_tblocks_16781", "find_cluster_ids_6890.segred_num_tblocks_16970", "find_cluster_ids_6890.segred_tblock_size_16779", "find_cluster_ids_6890.segred_tblock_size_16968", "find_cluster_ids_6890.segscan_num_tblocks_16980", "find_cluster_ids_6890.segscan_tblock_size_16978", "find_cluster_ids_6890.suff_intra_par_1", "find_cluster_ids_6890.suff_outer_par_0", "ftDBSCAN_double.segmap_tblock_size_17423", "ftDBSCAN_double.segmap_tblock_size_17450", "ftDBSCAN_double.segmap_tblock_size_17607", "ftDBSCAN_double.segmap_tblock_size_17637", "ftDBSCAN_double.segred_num_tblocks_17568", "ftDBSCAN_double.segred_tblock_size_17566", "ftDBSCAN_double.suff_intra_par_1", "ftDBSCAN_double.suff_outer_par_0", "ftDBSCAN_float.segmap_tblock_size_17050", "ftDBSCAN_float.segmap_tblock_size_17077", "ftDBSCAN_float.segmap_tblock_size_17234", "ftDBSCAN_float.segmap_tblock_size_17264", "ftDBSCAN_float.segred_num_tblocks_17195", "ftDBSCAN_float.segred_tblock_size_17193", "ftDBSCAN_float.suff_intra_par_1", "ftDBSCAN_float.suff_outer_par_0", "ftDBSCAN_star_double.segmap_tblock_size_16290", "ftDBSCAN_star_float.segmap_tblock_size_16272", "get_num_neighbours_6695.segmap_tblock_size_17805", "get_num_neighbours_6695.segmap_tblock_size_17893", "get_num_neighbours_6695.segmap_tblock_size_17934", "get_num_neighbours_6695.segmap_tblock_size_17966", "get_num_neighbours_6695.segred_num_tblocks_17906", "get_num_neighbours_6695.segred_tblock_size_17904", "get_num_neighbours_6695.suff_intra_par_1", "get_num_neighbours_6695.suff_outer_par_0", "get_num_neighbours_6842.segmap_tblock_size_18106", "get_num_neighbours_6842.segmap_tblock_size_18194", "get_num_neighbours_6842.segmap_tblock_size_18235", "get_num_neighbours_6842.segmap_tblock_size_18267", "get_num_neighbours_6842.segred_num_tblocks_18207", "get_num_neighbours_6842.segred_tblock_size_18205", "get_num_neighbours_6842.suff_intra_par_1", "get_num_neighbours_6842.suff_outer_par_0", "isolate_core_points_6732.segmap_num_tblocks_16219", "isolate_core_points_6732.segmap_tblock_size_16188", "isolate_core_points_6732.segmap_tblock_size_16217", "isolate_core_points_6732.segscan_num_tblocks_16178", "isolate_core_points_6732.segscan_tblock_size_16176", "isolate_core_points_6871.segmap_num_tblocks_16266", "isolate_core_points_6871.segmap_tblock_size_16235", "isolate_core_points_6871.segmap_tblock_size_16264", "isolate_core_points_6871.segscan_num_tblocks_16225", "isolate_core_points_6871.segscan_tblock_size_16223", NULL};
static const char *tuning_param_vars[] = {"builtinzhiota_i64zitblock_sizze_18660", "builtinzhreplicate_i32zitblock_sizze_18774", "builtinzhreplicate_i64zitblock_sizze_18660", "builtinzhreplicate_i8zitblock_sizze_18877", "find_cluster_ids_6783zisegmap_tblock_sizze_16317", "find_cluster_ids_6783zisegmap_tblock_sizze_16438", "find_cluster_ids_6783zisegmap_tblock_sizze_16472", "find_cluster_ids_6783zisegmap_tblock_sizze_16617", "find_cluster_ids_6783zisegmap_tblock_sizze_16643", "find_cluster_ids_6783zisegred_num_tblocks_16410", "find_cluster_ids_6783zisegred_num_tblocks_16599", "find_cluster_ids_6783zisegred_tblock_sizze_16408", "find_cluster_ids_6783zisegred_tblock_sizze_16597", "find_cluster_ids_6783zisegscan_num_tblocks_16609", "find_cluster_ids_6783zisegscan_tblock_sizze_16607", "find_cluster_ids_6783zisuff_intra_par_1", "find_cluster_ids_6783zisuff_outer_par_0", "find_cluster_ids_6890zisegmap_tblock_sizze_16688", "find_cluster_ids_6890zisegmap_tblock_sizze_16809", "find_cluster_ids_6890zisegmap_tblock_sizze_16843", "find_cluster_ids_6890zisegmap_tblock_sizze_16988", "find_cluster_ids_6890zisegmap_tblock_sizze_17014", "find_cluster_ids_6890zisegred_num_tblocks_16781", "find_cluster_ids_6890zisegred_num_tblocks_16970", "find_cluster_ids_6890zisegred_tblock_sizze_16779", "find_cluster_ids_6890zisegred_tblock_sizze_16968", "find_cluster_ids_6890zisegscan_num_tblocks_16980", "find_cluster_ids_6890zisegscan_tblock_sizze_16978", "find_cluster_ids_6890zisuff_intra_par_1", "find_cluster_ids_6890zisuff_outer_par_0", "ftDBSCAN_doublezisegmap_tblock_sizze_17423", "ftDBSCAN_doublezisegmap_tblock_sizze_17450", "ftDBSCAN_doublezisegmap_tblock_sizze_17607", "ftDBSCAN_doublezisegmap_tblock_sizze_17637", "ftDBSCAN_doublezisegred_num_tblocks_17568", "ftDBSCAN_doublezisegred_tblock_sizze_17566", "ftDBSCAN_doublezisuff_intra_par_1", "ftDBSCAN_doublezisuff_outer_par_0", "ftDBSCAN_floatzisegmap_tblock_sizze_17050", "ftDBSCAN_floatzisegmap_tblock_sizze_17077", "ftDBSCAN_floatzisegmap_tblock_sizze_17234", "ftDBSCAN_floatzisegmap_tblock_sizze_17264", "ftDBSCAN_floatzisegred_num_tblocks_17195", "ftDBSCAN_floatzisegred_tblock_sizze_17193", "ftDBSCAN_floatzisuff_intra_par_1", "ftDBSCAN_floatzisuff_outer_par_0", "ftDBSCAN_star_doublezisegmap_tblock_sizze_16290", "ftDBSCAN_star_floatzisegmap_tblock_sizze_16272", "get_num_neighbours_6695zisegmap_tblock_sizze_17805", "get_num_neighbours_6695zisegmap_tblock_sizze_17893", "get_num_neighbours_6695zisegmap_tblock_sizze_17934", "get_num_neighbours_6695zisegmap_tblock_sizze_17966", "get_num_neighbours_6695zisegred_num_tblocks_17906", "get_num_neighbours_6695zisegred_tblock_sizze_17904", "get_num_neighbours_6695zisuff_intra_par_1", "get_num_neighbours_6695zisuff_outer_par_0", "get_num_neighbours_6842zisegmap_tblock_sizze_18106", "get_num_neighbours_6842zisegmap_tblock_sizze_18194", "get_num_neighbours_6842zisegmap_tblock_sizze_18235", "get_num_neighbours_6842zisegmap_tblock_sizze_18267", "get_num_neighbours_6842zisegred_num_tblocks_18207", "get_num_neighbours_6842zisegred_tblock_sizze_18205", "get_num_neighbours_6842zisuff_intra_par_1", "get_num_neighbours_6842zisuff_outer_par_0", "isolate_core_points_6732zisegmap_num_tblocks_16219", "isolate_core_points_6732zisegmap_tblock_sizze_16188", "isolate_core_points_6732zisegmap_tblock_sizze_16217", "isolate_core_points_6732zisegscan_num_tblocks_16178", "isolate_core_points_6732zisegscan_tblock_sizze_16176", "isolate_core_points_6871zisegmap_num_tblocks_16266", "isolate_core_points_6871zisegmap_tblock_sizze_16235", "isolate_core_points_6871zisegmap_tblock_sizze_16264", "isolate_core_points_6871zisegscan_num_tblocks_16225", "isolate_core_points_6871zisegscan_tblock_sizze_16223", NULL};
static const char *tuning_param_classes[] = {"thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "grid_size", "thread_block_size", "threshold(32, !find_cluster_ids_6783.suff_outer_par_0)", "threshold(def, )", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "grid_size", "thread_block_size", "threshold(32, !find_cluster_ids_6890.suff_outer_par_0)", "threshold(def, )", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "thread_block_size", "threshold(32, !ftDBSCAN_double.suff_outer_par_0)", "threshold(def, )", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "thread_block_size", "threshold(32, !ftDBSCAN_float.suff_outer_par_0)", "threshold(def, )", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "thread_block_size", "threshold(32, !get_num_neighbours_6695.suff_outer_par_0)", "threshold(def, )", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "thread_block_size", "threshold(32, !get_num_neighbours_6842.suff_outer_par_0)", "threshold(def, )", "grid_size", "thread_block_size", "thread_block_size", "grid_size", "thread_block_size", "grid_size", "thread_block_size", "thread_block_size", "grid_size", "thread_block_size", NULL};
static int64_t tuning_param_defaults[] = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 32, 0, 0, 0, 0, 0, 0, 0, 32, 0, 0, 0, 0, 0, 0, 0, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 32, 0, 0, 0, 0, 0, 0, 0, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
static const int max_failure_args = 2;
static const int f64_required = 1;
static const char *gpu_program[] = {"#define FUTHARK_CUDA\n// start of prelude.cu\n\n#define SCALAR_FUN_ATTR __device__ static inline\n#define FUTHARK_FUN_ATTR __device__ static\n#define FUTHARK_F64_ENABLED\n\ntypedef char int8_t;\ntypedef short int16_t;\ntypedef int int32_t;\ntypedef long long int64_t;\ntypedef unsigned char uint8_t;\ntypedef unsigned short uint16_t;\ntypedef unsigned int uint32_t;\ntypedef unsigned long long uint64_t;\n\n#define __global\n#define __local\n#define __private\n#define __constant\n#define __write_only\n#define __read_only\n\nstatic inline __device__ int get_tblock_id(int d) {\n  switch (d) {\n  case 0: return blockIdx.x;\n  case 1: return blockIdx.y;\n  case 2: return blockIdx.z;\n  default: return 0;\n  }\n}\n\nstatic inline __device__ int get_num_tblocks(int d) {\n  switch(d) {\n  case 0: return gridDim.x;\n  case 1: return gridDim.y;\n  case 2: return gridDim.z;\n  default: return 0;\n  }\n}\n\nstatic inline __device__ int get_global_id(int d) {\n  switch (d) {\n    case 0: return threadIdx.x + blockIdx.x * blockDim.x;\n    case 1: return threadIdx.y + blockIdx.y * blockDim.y;\n    case 2: return threadIdx.z + blockIdx.z * blockDim.z;\n    default: return 0;\n  }\n}\n\nstatic inline __device__ int get_local_id(int d) {\n  switch (d) {\n    case 0: return threadIdx.x;\n    case 1: return threadIdx.y;\n    case 2: return threadIdx.z;\n    default: return 0;\n  }\n}\n\nstatic inline __device__ int get_local_size(int d) {\n  switch (d) {\n    case 0: return blockDim.x;\n    case 1: return blockDim.y;\n    case 2: return blockDim.z;\n    default: return 0;\n  }\n}\n\nstatic inline __device__ int get_global_size(int d) {\n  switch (d) {\n    case 0: return gridDim.x * blockDim.x;\n    case 1: return gridDim.y * blockDim.y;\n    case 2: return gridDim.z * blockDim.z;\n    default: return 0;\n  }\n}\n\n\n#define CLK_LOCAL_MEM_FENCE 1\n#define CLK_GLOBAL_MEM_FENCE 2\nstatic inline __device__ void barrier(int x) {\n  __syncthreads();\n}\nstatic inline __device__ void mem_fence_local() {\n  __threadfence_block();\n}\nstatic inline __device__ void mem_fence_global", "() {\n  __threadfence();\n}\n\nstatic inline __device__ void barrier_local() {\n  __syncthreads();\n}\n\n#define NAN (0.0/0.0)\n#define INFINITY (1.0/0.0)\nextern volatile __shared__ unsigned char shared_mem[];\n\n#define SHARED_MEM_PARAM\n#define FUTHARK_KERNEL extern \"C\" __global__ __launch_bounds__(MAX_THREADS_PER_BLOCK)\n#define FUTHARK_KERNEL_SIZED(a,b,c) extern \"C\" __global__ __launch_bounds__(a*b*c)\n\n// End of prelude.cu\n// Start of half.h.\n\n// Conversion functions are from http://half.sourceforge.net/, but\n// translated to C.\n//\n// Copyright (c) 2012-2021 Christian Rau\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in\n// all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n// THE SOFTWARE.\n\n#ifndef __OPENCL_VERSION__\n#define __constant\n#endif\n\n__constant static const uint16_t base_table[512] = {\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0", "000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0001, 0x0002, 0x0004, 0x0008, 0x0010, 0x0020, 0x0040, 0x0080, 0x0100,\n  0x0200, 0x0400, 0x0800, 0x0C00, 0x1000, 0x1400, 0x1800, 0x1C00, 0x2000, 0x2400, 0x2800, 0x2C00, 0x3000, 0x3400, 0x3800, 0x3C00,\n  0x4000, 0x4400, 0x4800, 0x4C00, 0x5000, 0x5400, 0x5800, 0x5C00, 0x6000, 0x6400, 0x6800, 0x6C00, 0x7000, 0x7400, 0x7800, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8",
                                    "000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8001, 0x8002, 0x8004, 0x8008, 0x8010, 0x8020, 0x8040, 0x8080, 0x8100,\n  0x8200, 0x8400, 0x8800, 0x8C00, 0x9000, 0x9400, 0x9800, 0x9C00, 0xA000, 0xA400, 0xA800, 0xAC00, 0xB000, 0xB400, 0xB800, 0xBC00,\n  0xC000, 0xC400, 0xC800, 0xCC00, 0xD000, 0xD400, 0xD800, 0xDC00, 0xE000, 0xE400, 0xE800, 0xEC00, 0xF000, 0xF400, 0xF800, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00 };\n\n__constant static const unsigned char shift_table[512] = {\n  24, 24, 24, 24, 24, 24,", " 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 2", "4, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13 };\n\n__constant static const uint32_t mantissa_table[2048] = {\n  0x00000000, 0x33800000, 0x34000000, 0x34400000, 0x34800000, 0x34A00000, 0x34C00000, 0x34E00000, 0x35000000, 0x35100000, 0x35200000, 0x35300000, 0x35400000, 0x35500000, 0x35600000, 0x35700000,\n  0x35800000, 0x35880000, 0x35900000, 0x35980000, 0x35A00000, 0x35A80000, 0x35B00000, 0x35B80000, 0x35C00000, 0x35C80000, 0x35D00000, 0x35D80000, 0x35E00000, 0x35E80000, 0x35F00000, 0x35F80000,\n  0x36000000, 0x36040000, 0x36080000, 0x360C0000, 0x36100000, 0x36140000, 0x36180000, 0x361C0000, 0x36200000, 0x36240000, 0x36280000, 0x362C0000, 0x36300000, 0x36340000, 0x36380000, 0x363C0000,\n  0x36400000, 0x36440000, 0x36480000, 0x364C0000, 0x36500000, 0x36540000, 0x36580000, 0x365C0000, 0x36600000, 0x36640000, 0x36680000, 0x366C0000, 0x36700000, 0x36740000, 0x36780000, 0x367C0000,\n  0x36800000, 0x36820000, 0x36840000, 0x36860000, 0x36880000, 0x368A0000, 0x368C0000, 0x368E0000, 0x36900000, 0x36920000, 0x36940000, 0x36960000, 0x36980000, 0x369A0000, 0x369C0000, 0x369E0000,\n  0x36A00000, 0x36A20000, 0x36A40000, 0x36A60000, 0x36A80000, 0x36AA0000, 0x36AC0000, 0x36AE0000, 0x36B00000, 0x36B20000, 0x36B40000, 0x36B60000, 0x36B80000, 0x36BA0000, 0x36BC0000, 0x36BE0000,\n  0x36C00000, 0x36C20000, 0x36C40000, 0x36C60000, 0x36C80000, 0x36CA0000, 0x36CC0000, 0x36CE0000, 0x36D00000, 0x36D20000, 0x36D40000, 0x36D60000, 0x36D80000, 0x36DA0000, 0x36DC0000, 0x36DE0000,\n  0x36E00000, 0x36E20000, 0x36E40000, 0x36E60000, 0x36E80000, 0x36EA0000, 0x36EC0000, 0x36EE0000, 0x36F00000, 0x36F20000, 0x36F40000, 0x36F60000, 0x36F80000, 0x36FA0000, 0x36FC0000, 0x36FE0000,\n  0x37000000, 0x37010000, 0x37020000, 0x37030000, 0x37040000, 0x37050000, 0x37060000, 0x37070000, 0x37080000, 0x37090000, 0x370A0000, 0x370B0000, 0x370C0000, 0x370D0000, 0x370E0000, 0x370F0000,\n  0x37100000, 0x37110000, 0x37120000, 0x37130000, 0x37140000, 0x37150000, 0x37160000, 0x37170000, 0x37180000, 0x37190000, 0x371A0000, 0x37",
                                    "1B0000, 0x371C0000, 0x371D0000, 0x371E0000, 0x371F0000,\n  0x37200000, 0x37210000, 0x37220000, 0x37230000, 0x37240000, 0x37250000, 0x37260000, 0x37270000, 0x37280000, 0x37290000, 0x372A0000, 0x372B0000, 0x372C0000, 0x372D0000, 0x372E0000, 0x372F0000,\n  0x37300000, 0x37310000, 0x37320000, 0x37330000, 0x37340000, 0x37350000, 0x37360000, 0x37370000, 0x37380000, 0x37390000, 0x373A0000, 0x373B0000, 0x373C0000, 0x373D0000, 0x373E0000, 0x373F0000,\n  0x37400000, 0x37410000, 0x37420000, 0x37430000, 0x37440000, 0x37450000, 0x37460000, 0x37470000, 0x37480000, 0x37490000, 0x374A0000, 0x374B0000, 0x374C0000, 0x374D0000, 0x374E0000, 0x374F0000,\n  0x37500000, 0x37510000, 0x37520000, 0x37530000, 0x37540000, 0x37550000, 0x37560000, 0x37570000, 0x37580000, 0x37590000, 0x375A0000, 0x375B0000, 0x375C0000, 0x375D0000, 0x375E0000, 0x375F0000,\n  0x37600000, 0x37610000, 0x37620000, 0x37630000, 0x37640000, 0x37650000, 0x37660000, 0x37670000, 0x37680000, 0x37690000, 0x376A0000, 0x376B0000, 0x376C0000, 0x376D0000, 0x376E0000, 0x376F0000,\n  0x37700000, 0x37710000, 0x37720000, 0x37730000, 0x37740000, 0x37750000, 0x37760000, 0x37770000, 0x37780000, 0x37790000, 0x377A0000, 0x377B0000, 0x377C0000, 0x377D0000, 0x377E0000, 0x377F0000,\n  0x37800000, 0x37808000, 0x37810000, 0x37818000, 0x37820000, 0x37828000, 0x37830000, 0x37838000, 0x37840000, 0x37848000, 0x37850000, 0x37858000, 0x37860000, 0x37868000, 0x37870000, 0x37878000,\n  0x37880000, 0x37888000, 0x37890000, 0x37898000, 0x378A0000, 0x378A8000, 0x378B0000, 0x378B8000, 0x378C0000, 0x378C8000, 0x378D0000, 0x378D8000, 0x378E0000, 0x378E8000, 0x378F0000, 0x378F8000,\n  0x37900000, 0x37908000, 0x37910000, 0x37918000, 0x37920000, 0x37928000, 0x37930000, 0x37938000, 0x37940000, 0x37948000, 0x37950000, 0x37958000, 0x37960000, 0x37968000, 0x37970000, 0x37978000,\n  0x37980000, 0x37988000, 0x37990000, 0x37998000, 0x379A0000, 0x379A8000, 0x379B0000, 0x379B8000, 0x379C0000, 0x379C8000, 0x379D0000, 0x379D8000, 0x379E0000, 0x379E8000, 0x379F0000, 0x379F8000,\n  0x", "37A00000, 0x37A08000, 0x37A10000, 0x37A18000, 0x37A20000, 0x37A28000, 0x37A30000, 0x37A38000, 0x37A40000, 0x37A48000, 0x37A50000, 0x37A58000, 0x37A60000, 0x37A68000, 0x37A70000, 0x37A78000,\n  0x37A80000, 0x37A88000, 0x37A90000, 0x37A98000, 0x37AA0000, 0x37AA8000, 0x37AB0000, 0x37AB8000, 0x37AC0000, 0x37AC8000, 0x37AD0000, 0x37AD8000, 0x37AE0000, 0x37AE8000, 0x37AF0000, 0x37AF8000,\n  0x37B00000, 0x37B08000, 0x37B10000, 0x37B18000, 0x37B20000, 0x37B28000, 0x37B30000, 0x37B38000, 0x37B40000, 0x37B48000, 0x37B50000, 0x37B58000, 0x37B60000, 0x37B68000, 0x37B70000, 0x37B78000,\n  0x37B80000, 0x37B88000, 0x37B90000, 0x37B98000, 0x37BA0000, 0x37BA8000, 0x37BB0000, 0x37BB8000, 0x37BC0000, 0x37BC8000, 0x37BD0000, 0x37BD8000, 0x37BE0000, 0x37BE8000, 0x37BF0000, 0x37BF8000,\n  0x37C00000, 0x37C08000, 0x37C10000, 0x37C18000, 0x37C20000, 0x37C28000, 0x37C30000, 0x37C38000, 0x37C40000, 0x37C48000, 0x37C50000, 0x37C58000, 0x37C60000, 0x37C68000, 0x37C70000, 0x37C78000,\n  0x37C80000, 0x37C88000, 0x37C90000, 0x37C98000, 0x37CA0000, 0x37CA8000, 0x37CB0000, 0x37CB8000, 0x37CC0000, 0x37CC8000, 0x37CD0000, 0x37CD8000, 0x37CE0000, 0x37CE8000, 0x37CF0000, 0x37CF8000,\n  0x37D00000, 0x37D08000, 0x37D10000, 0x37D18000, 0x37D20000, 0x37D28000, 0x37D30000, 0x37D38000, 0x37D40000, 0x37D48000, 0x37D50000, 0x37D58000, 0x37D60000, 0x37D68000, 0x37D70000, 0x37D78000,\n  0x37D80000, 0x37D88000, 0x37D90000, 0x37D98000, 0x37DA0000, 0x37DA8000, 0x37DB0000, 0x37DB8000, 0x37DC0000, 0x37DC8000, 0x37DD0000, 0x37DD8000, 0x37DE0000, 0x37DE8000, 0x37DF0000, 0x37DF8000,\n  0x37E00000, 0x37E08000, 0x37E10000, 0x37E18000, 0x37E20000, 0x37E28000, 0x37E30000, 0x37E38000, 0x37E40000, 0x37E48000, 0x37E50000, 0x37E58000, 0x37E60000, 0x37E68000, 0x37E70000, 0x37E78000,\n  0x37E80000, 0x37E88000, 0x37E90000, 0x37E98000, 0x37EA0000, 0x37EA8000, 0x37EB0000, 0x37EB8000, 0x37EC0000, 0x37EC8000, 0x37ED0000, 0x37ED8000, 0x37EE0000, 0x37EE8000, 0x37EF0000, 0x37EF8000,\n  0x37F00000, 0x37F08000, 0x37F10000, 0x37F18000, 0x37F20000, 0x", "37F28000, 0x37F30000, 0x37F38000, 0x37F40000, 0x37F48000, 0x37F50000, 0x37F58000, 0x37F60000, 0x37F68000, 0x37F70000, 0x37F78000,\n  0x37F80000, 0x37F88000, 0x37F90000, 0x37F98000, 0x37FA0000, 0x37FA8000, 0x37FB0000, 0x37FB8000, 0x37FC0000, 0x37FC8000, 0x37FD0000, 0x37FD8000, 0x37FE0000, 0x37FE8000, 0x37FF0000, 0x37FF8000,\n  0x38000000, 0x38004000, 0x38008000, 0x3800C000, 0x38010000, 0x38014000, 0x38018000, 0x3801C000, 0x38020000, 0x38024000, 0x38028000, 0x3802C000, 0x38030000, 0x38034000, 0x38038000, 0x3803C000,\n  0x38040000, 0x38044000, 0x38048000, 0x3804C000, 0x38050000, 0x38054000, 0x38058000, 0x3805C000, 0x38060000, 0x38064000, 0x38068000, 0x3806C000, 0x38070000, 0x38074000, 0x38078000, 0x3807C000,\n  0x38080000, 0x38084000, 0x38088000, 0x3808C000, 0x38090000, 0x38094000, 0x38098000, 0x3809C000, 0x380A0000, 0x380A4000, 0x380A8000, 0x380AC000, 0x380B0000, 0x380B4000, 0x380B8000, 0x380BC000,\n  0x380C0000, 0x380C4000, 0x380C8000, 0x380CC000, 0x380D0000, 0x380D4000, 0x380D8000, 0x380DC000, 0x380E0000, 0x380E4000, 0x380E8000, 0x380EC000, 0x380F0000, 0x380F4000, 0x380F8000, 0x380FC000,\n  0x38100000, 0x38104000, 0x38108000, 0x3810C000, 0x38110000, 0x38114000, 0x38118000, 0x3811C000, 0x38120000, 0x38124000, 0x38128000, 0x3812C000, 0x38130000, 0x38134000, 0x38138000, 0x3813C000,\n  0x38140000, 0x38144000, 0x38148000, 0x3814C000, 0x38150000, 0x38154000, 0x38158000, 0x3815C000, 0x38160000, 0x38164000, 0x38168000, 0x3816C000, 0x38170000, 0x38174000, 0x38178000, 0x3817C000,\n  0x38180000, 0x38184000, 0x38188000, 0x3818C000, 0x38190000, 0x38194000, 0x38198000, 0x3819C000, 0x381A0000, 0x381A4000, 0x381A8000, 0x381AC000, 0x381B0000, 0x381B4000, 0x381B8000, 0x381BC000,\n  0x381C0000, 0x381C4000, 0x381C8000, 0x381CC000, 0x381D0000, 0x381D4000, 0x381D8000, 0x381DC000, 0x381E0000, 0x381E4000, 0x381E8000, 0x381EC000, 0x381F0000, 0x381F4000, 0x381F8000, 0x381FC000,\n  0x38200000, 0x38204000, 0x38208000, 0x3820C000, 0x38210000, 0x38214000, 0x38218000, 0x3821C000, 0x38220000, 0x38224000, 0x",
                                    "38228000, 0x3822C000, 0x38230000, 0x38234000, 0x38238000, 0x3823C000,\n  0x38240000, 0x38244000, 0x38248000, 0x3824C000, 0x38250000, 0x38254000, 0x38258000, 0x3825C000, 0x38260000, 0x38264000, 0x38268000, 0x3826C000, 0x38270000, 0x38274000, 0x38278000, 0x3827C000,\n  0x38280000, 0x38284000, 0x38288000, 0x3828C000, 0x38290000, 0x38294000, 0x38298000, 0x3829C000, 0x382A0000, 0x382A4000, 0x382A8000, 0x382AC000, 0x382B0000, 0x382B4000, 0x382B8000, 0x382BC000,\n  0x382C0000, 0x382C4000, 0x382C8000, 0x382CC000, 0x382D0000, 0x382D4000, 0x382D8000, 0x382DC000, 0x382E0000, 0x382E4000, 0x382E8000, 0x382EC000, 0x382F0000, 0x382F4000, 0x382F8000, 0x382FC000,\n  0x38300000, 0x38304000, 0x38308000, 0x3830C000, 0x38310000, 0x38314000, 0x38318000, 0x3831C000, 0x38320000, 0x38324000, 0x38328000, 0x3832C000, 0x38330000, 0x38334000, 0x38338000, 0x3833C000,\n  0x38340000, 0x38344000, 0x38348000, 0x3834C000, 0x38350000, 0x38354000, 0x38358000, 0x3835C000, 0x38360000, 0x38364000, 0x38368000, 0x3836C000, 0x38370000, 0x38374000, 0x38378000, 0x3837C000,\n  0x38380000, 0x38384000, 0x38388000, 0x3838C000, 0x38390000, 0x38394000, 0x38398000, 0x3839C000, 0x383A0000, 0x383A4000, 0x383A8000, 0x383AC000, 0x383B0000, 0x383B4000, 0x383B8000, 0x383BC000,\n  0x383C0000, 0x383C4000, 0x383C8000, 0x383CC000, 0x383D0000, 0x383D4000, 0x383D8000, 0x383DC000, 0x383E0000, 0x383E4000, 0x383E8000, 0x383EC000, 0x383F0000, 0x383F4000, 0x383F8000, 0x383FC000,\n  0x38400000, 0x38404000, 0x38408000, 0x3840C000, 0x38410000, 0x38414000, 0x38418000, 0x3841C000, 0x38420000, 0x38424000, 0x38428000, 0x3842C000, 0x38430000, 0x38434000, 0x38438000, 0x3843C000,\n  0x38440000, 0x38444000, 0x38448000, 0x3844C000, 0x38450000, 0x38454000, 0x38458000, 0x3845C000, 0x38460000, 0x38464000, 0x38468000, 0x3846C000, 0x38470000, 0x38474000, 0x38478000, 0x3847C000,\n  0x38480000, 0x38484000, 0x38488000, 0x3848C000, 0x38490000, 0x38494000, 0x38498000, 0x3849C000, 0x384A0000, 0x384A4000, 0x384A8000, 0x384AC000, 0x384B0000, 0x384B4000, 0x384B8000, 0x", "384BC000,\n  0x384C0000, 0x384C4000, 0x384C8000, 0x384CC000, 0x384D0000, 0x384D4000, 0x384D8000, 0x384DC000, 0x384E0000, 0x384E4000, 0x384E8000, 0x384EC000, 0x384F0000, 0x384F4000, 0x384F8000, 0x384FC000,\n  0x38500000, 0x38504000, 0x38508000, 0x3850C000, 0x38510000, 0x38514000, 0x38518000, 0x3851C000, 0x38520000, 0x38524000, 0x38528000, 0x3852C000, 0x38530000, 0x38534000, 0x38538000, 0x3853C000,\n  0x38540000, 0x38544000, 0x38548000, 0x3854C000, 0x38550000, 0x38554000, 0x38558000, 0x3855C000, 0x38560000, 0x38564000, 0x38568000, 0x3856C000, 0x38570000, 0x38574000, 0x38578000, 0x3857C000,\n  0x38580000, 0x38584000, 0x38588000, 0x3858C000, 0x38590000, 0x38594000, 0x38598000, 0x3859C000, 0x385A0000, 0x385A4000, 0x385A8000, 0x385AC000, 0x385B0000, 0x385B4000, 0x385B8000, 0x385BC000,\n  0x385C0000, 0x385C4000, 0x385C8000, 0x385CC000, 0x385D0000, 0x385D4000, 0x385D8000, 0x385DC000, 0x385E0000, 0x385E4000, 0x385E8000, 0x385EC000, 0x385F0000, 0x385F4000, 0x385F8000, 0x385FC000,\n  0x38600000, 0x38604000, 0x38608000, 0x3860C000, 0x38610000, 0x38614000, 0x38618000, 0x3861C000, 0x38620000, 0x38624000, 0x38628000, 0x3862C000, 0x38630000, 0x38634000, 0x38638000, 0x3863C000,\n  0x38640000, 0x38644000, 0x38648000, 0x3864C000, 0x38650000, 0x38654000, 0x38658000, 0x3865C000, 0x38660000, 0x38664000, 0x38668000, 0x3866C000, 0x38670000, 0x38674000, 0x38678000, 0x3867C000,\n  0x38680000, 0x38684000, 0x38688000, 0x3868C000, 0x38690000, 0x38694000, 0x38698000, 0x3869C000, 0x386A0000, 0x386A4000, 0x386A8000, 0x386AC000, 0x386B0000, 0x386B4000, 0x386B8000, 0x386BC000,\n  0x386C0000, 0x386C4000, 0x386C8000, 0x386CC000, 0x386D0000, 0x386D4000, 0x386D8000, 0x386DC000, 0x386E0000, 0x386E4000, 0x386E8000, 0x386EC000, 0x386F0000, 0x386F4000, 0x386F8000, 0x386FC000,\n  0x38700000, 0x38704000, 0x38708000, 0x3870C000, 0x38710000, 0x38714000, 0x38718000, 0x3871C000, 0x38720000, 0x38724000, 0x38728000, 0x3872C000, 0x38730000, 0x38734000, 0x38738000, 0x3873C000,\n  0x38740000, 0x38744000, 0x38748000, 0x3874C000, ", "0x38750000, 0x38754000, 0x38758000, 0x3875C000, 0x38760000, 0x38764000, 0x38768000, 0x3876C000, 0x38770000, 0x38774000, 0x38778000, 0x3877C000,\n  0x38780000, 0x38784000, 0x38788000, 0x3878C000, 0x38790000, 0x38794000, 0x38798000, 0x3879C000, 0x387A0000, 0x387A4000, 0x387A8000, 0x387AC000, 0x387B0000, 0x387B4000, 0x387B8000, 0x387BC000,\n  0x387C0000, 0x387C4000, 0x387C8000, 0x387CC000, 0x387D0000, 0x387D4000, 0x387D8000, 0x387DC000, 0x387E0000, 0x387E4000, 0x387E8000, 0x387EC000, 0x387F0000, 0x387F4000, 0x387F8000, 0x387FC000,\n  0x38000000, 0x38002000, 0x38004000, 0x38006000, 0x38008000, 0x3800A000, 0x3800C000, 0x3800E000, 0x38010000, 0x38012000, 0x38014000, 0x38016000, 0x38018000, 0x3801A000, 0x3801C000, 0x3801E000,\n  0x38020000, 0x38022000, 0x38024000, 0x38026000, 0x38028000, 0x3802A000, 0x3802C000, 0x3802E000, 0x38030000, 0x38032000, 0x38034000, 0x38036000, 0x38038000, 0x3803A000, 0x3803C000, 0x3803E000,\n  0x38040000, 0x38042000, 0x38044000, 0x38046000, 0x38048000, 0x3804A000, 0x3804C000, 0x3804E000, 0x38050000, 0x38052000, 0x38054000, 0x38056000, 0x38058000, 0x3805A000, 0x3805C000, 0x3805E000,\n  0x38060000, 0x38062000, 0x38064000, 0x38066000, 0x38068000, 0x3806A000, 0x3806C000, 0x3806E000, 0x38070000, 0x38072000, 0x38074000, 0x38076000, 0x38078000, 0x3807A000, 0x3807C000, 0x3807E000,\n  0x38080000, 0x38082000, 0x38084000, 0x38086000, 0x38088000, 0x3808A000, 0x3808C000, 0x3808E000, 0x38090000, 0x38092000, 0x38094000, 0x38096000, 0x38098000, 0x3809A000, 0x3809C000, 0x3809E000,\n  0x380A0000, 0x380A2000, 0x380A4000, 0x380A6000, 0x380A8000, 0x380AA000, 0x380AC000, 0x380AE000, 0x380B0000, 0x380B2000, 0x380B4000, 0x380B6000, 0x380B8000, 0x380BA000, 0x380BC000, 0x380BE000,\n  0x380C0000, 0x380C2000, 0x380C4000, 0x380C6000, 0x380C8000, 0x380CA000, 0x380CC000, 0x380CE000, 0x380D0000, 0x380D2000, 0x380D4000, 0x380D6000, 0x380D8000, 0x380DA000, 0x380DC000, 0x380DE000,\n  0x380E0000, 0x380E2000, 0x380E4000, 0x380E6000, 0x380E8000, 0x380EA000, 0x380EC000, 0x380EE000, 0x380F0000, ",
                                    "0x380F2000, 0x380F4000, 0x380F6000, 0x380F8000, 0x380FA000, 0x380FC000, 0x380FE000,\n  0x38100000, 0x38102000, 0x38104000, 0x38106000, 0x38108000, 0x3810A000, 0x3810C000, 0x3810E000, 0x38110000, 0x38112000, 0x38114000, 0x38116000, 0x38118000, 0x3811A000, 0x3811C000, 0x3811E000,\n  0x38120000, 0x38122000, 0x38124000, 0x38126000, 0x38128000, 0x3812A000, 0x3812C000, 0x3812E000, 0x38130000, 0x38132000, 0x38134000, 0x38136000, 0x38138000, 0x3813A000, 0x3813C000, 0x3813E000,\n  0x38140000, 0x38142000, 0x38144000, 0x38146000, 0x38148000, 0x3814A000, 0x3814C000, 0x3814E000, 0x38150000, 0x38152000, 0x38154000, 0x38156000, 0x38158000, 0x3815A000, 0x3815C000, 0x3815E000,\n  0x38160000, 0x38162000, 0x38164000, 0x38166000, 0x38168000, 0x3816A000, 0x3816C000, 0x3816E000, 0x38170000, 0x38172000, 0x38174000, 0x38176000, 0x38178000, 0x3817A000, 0x3817C000, 0x3817E000,\n  0x38180000, 0x38182000, 0x38184000, 0x38186000, 0x38188000, 0x3818A000, 0x3818C000, 0x3818E000, 0x38190000, 0x38192000, 0x38194000, 0x38196000, 0x38198000, 0x3819A000, 0x3819C000, 0x3819E000,\n  0x381A0000, 0x381A2000, 0x381A4000, 0x381A6000, 0x381A8000, 0x381AA000, 0x381AC000, 0x381AE000, 0x381B0000, 0x381B2000, 0x381B4000, 0x381B6000, 0x381B8000, 0x381BA000, 0x381BC000, 0x381BE000,\n  0x381C0000, 0x381C2000, 0x381C4000, 0x381C6000, 0x381C8000, 0x381CA000, 0x381CC000, 0x381CE000, 0x381D0000, 0x381D2000, 0x381D4000, 0x381D6000, 0x381D8000, 0x381DA000, 0x381DC000, 0x381DE000,\n  0x381E0000, 0x381E2000, 0x381E4000, 0x381E6000, 0x381E8000, 0x381EA000, 0x381EC000, 0x381EE000, 0x381F0000, 0x381F2000, 0x381F4000, 0x381F6000, 0x381F8000, 0x381FA000, 0x381FC000, 0x381FE000,\n  0x38200000, 0x38202000, 0x38204000, 0x38206000, 0x38208000, 0x3820A000, 0x3820C000, 0x3820E000, 0x38210000, 0x38212000, 0x38214000, 0x38216000, 0x38218000, 0x3821A000, 0x3821C000, 0x3821E000,\n  0x38220000, 0x38222000, 0x38224000, 0x38226000, 0x38228000, 0x3822A000, 0x3822C000, 0x3822E000, 0x38230000, 0x38232000, 0x38234000, 0x38236000, 0x38238000, 0x3823A000, ", "0x3823C000, 0x3823E000,\n  0x38240000, 0x38242000, 0x38244000, 0x38246000, 0x38248000, 0x3824A000, 0x3824C000, 0x3824E000, 0x38250000, 0x38252000, 0x38254000, 0x38256000, 0x38258000, 0x3825A000, 0x3825C000, 0x3825E000,\n  0x38260000, 0x38262000, 0x38264000, 0x38266000, 0x38268000, 0x3826A000, 0x3826C000, 0x3826E000, 0x38270000, 0x38272000, 0x38274000, 0x38276000, 0x38278000, 0x3827A000, 0x3827C000, 0x3827E000,\n  0x38280000, 0x38282000, 0x38284000, 0x38286000, 0x38288000, 0x3828A000, 0x3828C000, 0x3828E000, 0x38290000, 0x38292000, 0x38294000, 0x38296000, 0x38298000, 0x3829A000, 0x3829C000, 0x3829E000,\n  0x382A0000, 0x382A2000, 0x382A4000, 0x382A6000, 0x382A8000, 0x382AA000, 0x382AC000, 0x382AE000, 0x382B0000, 0x382B2000, 0x382B4000, 0x382B6000, 0x382B8000, 0x382BA000, 0x382BC000, 0x382BE000,\n  0x382C0000, 0x382C2000, 0x382C4000, 0x382C6000, 0x382C8000, 0x382CA000, 0x382CC000, 0x382CE000, 0x382D0000, 0x382D2000, 0x382D4000, 0x382D6000, 0x382D8000, 0x382DA000, 0x382DC000, 0x382DE000,\n  0x382E0000, 0x382E2000, 0x382E4000, 0x382E6000, 0x382E8000, 0x382EA000, 0x382EC000, 0x382EE000, 0x382F0000, 0x382F2000, 0x382F4000, 0x382F6000, 0x382F8000, 0x382FA000, 0x382FC000, 0x382FE000,\n  0x38300000, 0x38302000, 0x38304000, 0x38306000, 0x38308000, 0x3830A000, 0x3830C000, 0x3830E000, 0x38310000, 0x38312000, 0x38314000, 0x38316000, 0x38318000, 0x3831A000, 0x3831C000, 0x3831E000,\n  0x38320000, 0x38322000, 0x38324000, 0x38326000, 0x38328000, 0x3832A000, 0x3832C000, 0x3832E000, 0x38330000, 0x38332000, 0x38334000, 0x38336000, 0x38338000, 0x3833A000, 0x3833C000, 0x3833E000,\n  0x38340000, 0x38342000, 0x38344000, 0x38346000, 0x38348000, 0x3834A000, 0x3834C000, 0x3834E000, 0x38350000, 0x38352000, 0x38354000, 0x38356000, 0x38358000, 0x3835A000, 0x3835C000, 0x3835E000,\n  0x38360000, 0x38362000, 0x38364000, 0x38366000, 0x38368000, 0x3836A000, 0x3836C000, 0x3836E000, 0x38370000, 0x38372000, 0x38374000, 0x38376000, 0x38378000, 0x3837A000, 0x3837C000, 0x3837E000,\n  0x38380000, 0x38382000, 0x38384000", ", 0x38386000, 0x38388000, 0x3838A000, 0x3838C000, 0x3838E000, 0x38390000, 0x38392000, 0x38394000, 0x38396000, 0x38398000, 0x3839A000, 0x3839C000, 0x3839E000,\n  0x383A0000, 0x383A2000, 0x383A4000, 0x383A6000, 0x383A8000, 0x383AA000, 0x383AC000, 0x383AE000, 0x383B0000, 0x383B2000, 0x383B4000, 0x383B6000, 0x383B8000, 0x383BA000, 0x383BC000, 0x383BE000,\n  0x383C0000, 0x383C2000, 0x383C4000, 0x383C6000, 0x383C8000, 0x383CA000, 0x383CC000, 0x383CE000, 0x383D0000, 0x383D2000, 0x383D4000, 0x383D6000, 0x383D8000, 0x383DA000, 0x383DC000, 0x383DE000,\n  0x383E0000, 0x383E2000, 0x383E4000, 0x383E6000, 0x383E8000, 0x383EA000, 0x383EC000, 0x383EE000, 0x383F0000, 0x383F2000, 0x383F4000, 0x383F6000, 0x383F8000, 0x383FA000, 0x383FC000, 0x383FE000,\n  0x38400000, 0x38402000, 0x38404000, 0x38406000, 0x38408000, 0x3840A000, 0x3840C000, 0x3840E000, 0x38410000, 0x38412000, 0x38414000, 0x38416000, 0x38418000, 0x3841A000, 0x3841C000, 0x3841E000,\n  0x38420000, 0x38422000, 0x38424000, 0x38426000, 0x38428000, 0x3842A000, 0x3842C000, 0x3842E000, 0x38430000, 0x38432000, 0x38434000, 0x38436000, 0x38438000, 0x3843A000, 0x3843C000, 0x3843E000,\n  0x38440000, 0x38442000, 0x38444000, 0x38446000, 0x38448000, 0x3844A000, 0x3844C000, 0x3844E000, 0x38450000, 0x38452000, 0x38454000, 0x38456000, 0x38458000, 0x3845A000, 0x3845C000, 0x3845E000,\n  0x38460000, 0x38462000, 0x38464000, 0x38466000, 0x38468000, 0x3846A000, 0x3846C000, 0x3846E000, 0x38470000, 0x38472000, 0x38474000, 0x38476000, 0x38478000, 0x3847A000, 0x3847C000, 0x3847E000,\n  0x38480000, 0x38482000, 0x38484000, 0x38486000, 0x38488000, 0x3848A000, 0x3848C000, 0x3848E000, 0x38490000, 0x38492000, 0x38494000, 0x38496000, 0x38498000, 0x3849A000, 0x3849C000, 0x3849E000,\n  0x384A0000, 0x384A2000, 0x384A4000, 0x384A6000, 0x384A8000, 0x384AA000, 0x384AC000, 0x384AE000, 0x384B0000, 0x384B2000, 0x384B4000, 0x384B6000, 0x384B8000, 0x384BA000, 0x384BC000, 0x384BE000,\n  0x384C0000, 0x384C2000, 0x384C4000, 0x384C6000, 0x384C8000, 0x384CA000, 0x384CC000, 0x384CE000",
                                    ", 0x384D0000, 0x384D2000, 0x384D4000, 0x384D6000, 0x384D8000, 0x384DA000, 0x384DC000, 0x384DE000,\n  0x384E0000, 0x384E2000, 0x384E4000, 0x384E6000, 0x384E8000, 0x384EA000, 0x384EC000, 0x384EE000, 0x384F0000, 0x384F2000, 0x384F4000, 0x384F6000, 0x384F8000, 0x384FA000, 0x384FC000, 0x384FE000,\n  0x38500000, 0x38502000, 0x38504000, 0x38506000, 0x38508000, 0x3850A000, 0x3850C000, 0x3850E000, 0x38510000, 0x38512000, 0x38514000, 0x38516000, 0x38518000, 0x3851A000, 0x3851C000, 0x3851E000,\n  0x38520000, 0x38522000, 0x38524000, 0x38526000, 0x38528000, 0x3852A000, 0x3852C000, 0x3852E000, 0x38530000, 0x38532000, 0x38534000, 0x38536000, 0x38538000, 0x3853A000, 0x3853C000, 0x3853E000,\n  0x38540000, 0x38542000, 0x38544000, 0x38546000, 0x38548000, 0x3854A000, 0x3854C000, 0x3854E000, 0x38550000, 0x38552000, 0x38554000, 0x38556000, 0x38558000, 0x3855A000, 0x3855C000, 0x3855E000,\n  0x38560000, 0x38562000, 0x38564000, 0x38566000, 0x38568000, 0x3856A000, 0x3856C000, 0x3856E000, 0x38570000, 0x38572000, 0x38574000, 0x38576000, 0x38578000, 0x3857A000, 0x3857C000, 0x3857E000,\n  0x38580000, 0x38582000, 0x38584000, 0x38586000, 0x38588000, 0x3858A000, 0x3858C000, 0x3858E000, 0x38590000, 0x38592000, 0x38594000, 0x38596000, 0x38598000, 0x3859A000, 0x3859C000, 0x3859E000,\n  0x385A0000, 0x385A2000, 0x385A4000, 0x385A6000, 0x385A8000, 0x385AA000, 0x385AC000, 0x385AE000, 0x385B0000, 0x385B2000, 0x385B4000, 0x385B6000, 0x385B8000, 0x385BA000, 0x385BC000, 0x385BE000,\n  0x385C0000, 0x385C2000, 0x385C4000, 0x385C6000, 0x385C8000, 0x385CA000, 0x385CC000, 0x385CE000, 0x385D0000, 0x385D2000, 0x385D4000, 0x385D6000, 0x385D8000, 0x385DA000, 0x385DC000, 0x385DE000,\n  0x385E0000, 0x385E2000, 0x385E4000, 0x385E6000, 0x385E8000, 0x385EA000, 0x385EC000, 0x385EE000, 0x385F0000, 0x385F2000, 0x385F4000, 0x385F6000, 0x385F8000, 0x385FA000, 0x385FC000, 0x385FE000,\n  0x38600000, 0x38602000, 0x38604000, 0x38606000, 0x38608000, 0x3860A000, 0x3860C000, 0x3860E000, 0x38610000, 0x38612000, 0x38614000, 0x38616000, 0x38618000", ", 0x3861A000, 0x3861C000, 0x3861E000,\n  0x38620000, 0x38622000, 0x38624000, 0x38626000, 0x38628000, 0x3862A000, 0x3862C000, 0x3862E000, 0x38630000, 0x38632000, 0x38634000, 0x38636000, 0x38638000, 0x3863A000, 0x3863C000, 0x3863E000,\n  0x38640000, 0x38642000, 0x38644000, 0x38646000, 0x38648000, 0x3864A000, 0x3864C000, 0x3864E000, 0x38650000, 0x38652000, 0x38654000, 0x38656000, 0x38658000, 0x3865A000, 0x3865C000, 0x3865E000,\n  0x38660000, 0x38662000, 0x38664000, 0x38666000, 0x38668000, 0x3866A000, 0x3866C000, 0x3866E000, 0x38670000, 0x38672000, 0x38674000, 0x38676000, 0x38678000, 0x3867A000, 0x3867C000, 0x3867E000,\n  0x38680000, 0x38682000, 0x38684000, 0x38686000, 0x38688000, 0x3868A000, 0x3868C000, 0x3868E000, 0x38690000, 0x38692000, 0x38694000, 0x38696000, 0x38698000, 0x3869A000, 0x3869C000, 0x3869E000,\n  0x386A0000, 0x386A2000, 0x386A4000, 0x386A6000, 0x386A8000, 0x386AA000, 0x386AC000, 0x386AE000, 0x386B0000, 0x386B2000, 0x386B4000, 0x386B6000, 0x386B8000, 0x386BA000, 0x386BC000, 0x386BE000,\n  0x386C0000, 0x386C2000, 0x386C4000, 0x386C6000, 0x386C8000, 0x386CA000, 0x386CC000, 0x386CE000, 0x386D0000, 0x386D2000, 0x386D4000, 0x386D6000, 0x386D8000, 0x386DA000, 0x386DC000, 0x386DE000,\n  0x386E0000, 0x386E2000, 0x386E4000, 0x386E6000, 0x386E8000, 0x386EA000, 0x386EC000, 0x386EE000, 0x386F0000, 0x386F2000, 0x386F4000, 0x386F6000, 0x386F8000, 0x386FA000, 0x386FC000, 0x386FE000,\n  0x38700000, 0x38702000, 0x38704000, 0x38706000, 0x38708000, 0x3870A000, 0x3870C000, 0x3870E000, 0x38710000, 0x38712000, 0x38714000, 0x38716000, 0x38718000, 0x3871A000, 0x3871C000, 0x3871E000,\n  0x38720000, 0x38722000, 0x38724000, 0x38726000, 0x38728000, 0x3872A000, 0x3872C000, 0x3872E000, 0x38730000, 0x38732000, 0x38734000, 0x38736000, 0x38738000, 0x3873A000, 0x3873C000, 0x3873E000,\n  0x38740000, 0x38742000, 0x38744000, 0x38746000, 0x38748000, 0x3874A000, 0x3874C000, 0x3874E000, 0x38750000, 0x38752000, 0x38754000, 0x38756000, 0x38758000, 0x3875A000, 0x3875C000, 0x3875E000,\n  0x38760000, 0x387620", "00, 0x38764000, 0x38766000, 0x38768000, 0x3876A000, 0x3876C000, 0x3876E000, 0x38770000, 0x38772000, 0x38774000, 0x38776000, 0x38778000, 0x3877A000, 0x3877C000, 0x3877E000,\n  0x38780000, 0x38782000, 0x38784000, 0x38786000, 0x38788000, 0x3878A000, 0x3878C000, 0x3878E000, 0x38790000, 0x38792000, 0x38794000, 0x38796000, 0x38798000, 0x3879A000, 0x3879C000, 0x3879E000,\n  0x387A0000, 0x387A2000, 0x387A4000, 0x387A6000, 0x387A8000, 0x387AA000, 0x387AC000, 0x387AE000, 0x387B0000, 0x387B2000, 0x387B4000, 0x387B6000, 0x387B8000, 0x387BA000, 0x387BC000, 0x387BE000,\n  0x387C0000, 0x387C2000, 0x387C4000, 0x387C6000, 0x387C8000, 0x387CA000, 0x387CC000, 0x387CE000, 0x387D0000, 0x387D2000, 0x387D4000, 0x387D6000, 0x387D8000, 0x387DA000, 0x387DC000, 0x387DE000,\n  0x387E0000, 0x387E2000, 0x387E4000, 0x387E6000, 0x387E8000, 0x387EA000, 0x387EC000, 0x387EE000, 0x387F0000, 0x387F2000, 0x387F4000, 0x387F6000, 0x387F8000, 0x387FA000, 0x387FC000, 0x387FE000 };\n__constant static const uint32_t exponent_table[64] = {\n  0x00000000, 0x00800000, 0x01000000, 0x01800000, 0x02000000, 0x02800000, 0x03000000, 0x03800000, 0x04000000, 0x04800000, 0x05000000, 0x05800000, 0x06000000, 0x06800000, 0x07000000, 0x07800000,\n  0x08000000, 0x08800000, 0x09000000, 0x09800000, 0x0A000000, 0x0A800000, 0x0B000000, 0x0B800000, 0x0C000000, 0x0C800000, 0x0D000000, 0x0D800000, 0x0E000000, 0x0E800000, 0x0F000000, 0x47800000,\n  0x80000000, 0x80800000, 0x81000000, 0x81800000, 0x82000000, 0x82800000, 0x83000000, 0x83800000, 0x84000000, 0x84800000, 0x85000000, 0x85800000, 0x86000000, 0x86800000, 0x87000000, 0x87800000,\n  0x88000000, 0x88800000, 0x89000000, 0x89800000, 0x8A000000, 0x8A800000, 0x8B000000, 0x8B800000, 0x8C000000, 0x8C800000, 0x8D000000, 0x8D800000, 0x8E000000, 0x8E800000, 0x8F000000, 0xC7800000 };\n__constant static const unsigned short offset_table[64] = {\n  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1",
                                    "024, 1024, 1024, 1024, 1024, 1024,\n  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024 };\n\nSCALAR_FUN_ATTR uint16_t float2halfbits(float value) {\n  union { float x; uint32_t y; } u;\n  u.x = value;\n  uint32_t bits = u.y;\n\n  uint16_t hbits = base_table[bits>>23] + (uint16_t)((bits&0x7FFFFF)>>shift_table[bits>>23]);;\n\n  return hbits;\n}\n\nSCALAR_FUN_ATTR float halfbits2float(uint16_t value) {\n  uint32_t bits = mantissa_table[offset_table[value>>10]+(value&0x3FF)] + exponent_table[value>>10];\n\n  union { uint32_t x; float y; } u;\n  u.x = bits;\n  return u.y;\n}\n\nSCALAR_FUN_ATTR uint16_t halfbitsnextafter(uint16_t from, uint16_t to) {\n  int fabs = from & 0x7FFF, tabs = to & 0x7FFF;\n  if(fabs > 0x7C00 || tabs > 0x7C00) {\n    return ((from&0x7FFF)>0x7C00) ? (from|0x200) : (to|0x200);\n  }\n  if(from == to || !(fabs|tabs)) {\n    return to;\n  }\n  if(!fabs) {\n    return (to&0x8000)+1;\n  }\n  unsigned int out =\n    from +\n    (((from>>15)^(unsigned int)((from^(0x8000|(0x8000-(from>>15))))<(to^(0x8000|(0x8000-(to>>15))))))<<1)\n    - 1;\n  return out;\n}\n\n// End of half.h.\n// Start of scalar.h.\n\n// Implementation of the primitive scalar operations.  Very\n// repetitive.  This code is inserted directly into both CUDA and\n// OpenCL programs, as well as the CPU code, so it has some #ifdefs to\n// work everywhere.  Some operations are defined as macros because\n// this allows us to use them as constant expressions in things like\n// array sizes and static initialisers.\n\n// Some of the #ifdefs are because OpenCL uses type-generic functions\n// for some operations (e.g. sqrt), while C and CUDA sensibly use\n// distinct functions for different precisions (e.g. sqrtf() and\n// sqrt()).  This is quite annoying.  Due to C's unfortunate casting\n// rules, it is also really easy to accidentally implement\n// floating-point functions in the wrong precision, so be careful.\n\n/", "/ Double-precision definitions are only included if the preprocessor\n// macro FUTHARK_F64_ENABLED is set.\n\nSCALAR_FUN_ATTR int32_t futrts_to_bits32(float x);\nSCALAR_FUN_ATTR float futrts_from_bits32(int32_t x);\n\nSCALAR_FUN_ATTR uint8_t add8(uint8_t x, uint8_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint16_t add16(uint16_t x, uint16_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint32_t add32(uint32_t x, uint32_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint64_t add64(uint64_t x, uint64_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint8_t sub8(uint8_t x, uint8_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint16_t sub16(uint16_t x, uint16_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint32_t sub32(uint32_t x, uint32_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint64_t sub64(uint64_t x, uint64_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint8_t mul8(uint8_t x, uint8_t y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR uint16_t mul16(uint16_t x, uint16_t y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR uint32_t mul32(uint32_t x, uint32_t y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR uint64_t mul64(uint64_t x, uint64_t y) {\n  return x * y;\n}\n\n#if ISPC\n\nSCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {\n  // This strange pattern is used to prevent the ISPC compiler from\n  // causing SIGFPEs and bogus results on divisions where inactive lanes\n  // have 0-valued divisors. It ensures that any inactive lane instead\n  // has a divisor of 1. https://github.com/ispc/ispc/issues/2292\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {\n  uint", "8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALA",
                                    "R_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int8_t q = x / ys;\n  int8_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int16_t q = x / ys;\n  int16_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  int32_t q = x / ys;\n  int32_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int64_t q = x / ys;\n  int64_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {\n  return sdiv8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {\n  return sdiv16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y)", " {\n  return sdiv32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {\n  return sdiv64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int8_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int16_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int32_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int64_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : sdiv8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : sdiv16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : sdiv32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : sdiv64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {\n  return sdiv_safe8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {\n  return sdiv_safe16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {\n  return sdiv_safe32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {\n  return sdiv_safe64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : smod8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : smod16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) ", "{\n  return y == 0 ? 0 : smod32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : smod64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  ",
                                    "foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\n#else\n\nSCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {\n  return", " y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {\n  int8_t q = x / y;\n  int8_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {\n  int16_t q = x / y;\n  int16_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {\n  int32_t q = x / y;\n  int32_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {\n  int64_t q = x / y;\n  int64_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {\n  return sdiv8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {\n  return sdiv16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {\n  return sdiv32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {\n  return sdiv64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {\n  int8_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {\n  int16_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {\n  int32_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {\n  int64_t r = ", "x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : sdiv8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : sdiv16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : sdiv32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : sdiv64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {\n  return sdiv_safe8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {\n  return sdiv_safe16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {\n  return sdiv_safe32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {\n  return sdiv_safe64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : smod8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : smod16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : smod32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : smod64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t ",
                                    "y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\n#endif\n\nSCALAR_FUN_ATTR int8_t smin8(int8_t x, int8_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int16_t smin16(int16_t x, int16_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int32_t smin32(int32_t x, int32_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int64_t smin64(int64_t x, int64_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint8_t umin8(uint8_t x, uint8_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint16_t umin16(uint16_t x, uint16_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint32_t umin32(uint32_t x, uint32_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint64_t umin64(uint64_t x, uint64_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int8_t smax8(int8_t x, int8_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR int16_t smax16(int16_t x, int16_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR int32_t smax32(int32_t x, int32_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR int64_t smax64(int64_t x, int64_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint8_t umax8(uint8_t x, uint8_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint16_t umax16(uint16_t x, uint16_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint32_t umax32(uint32_t x, uint32_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint64_t umax64(uint64_t x, uint64_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint8_t shl8(uint8_t x, uint8_t y) {\n  return (uint8_t)(x << y);\n}\n\nS", "CALAR_FUN_ATTR uint16_t shl16(uint16_t x, uint16_t y) {\n  return (uint16_t)(x << y);\n}\n\nSCALAR_FUN_ATTR uint32_t shl32(uint32_t x, uint32_t y) {\n  return x << y;\n}\n\nSCALAR_FUN_ATTR uint64_t shl64(uint64_t x, uint64_t y) {\n  return x << y;\n}\n\nSCALAR_FUN_ATTR uint8_t lshr8(uint8_t x, uint8_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint16_t lshr16(uint16_t x, uint16_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint32_t lshr32(uint32_t x, uint32_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint64_t lshr64(uint64_t x, uint64_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int8_t ashr8(int8_t x, int8_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int16_t ashr16(int16_t x, int16_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int32_t ashr32(int32_t x, int32_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int64_t ashr64(int64_t x, int64_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint8_t and8(uint8_t x, uint8_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint16_t and16(uint16_t x, uint16_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint32_t and32(uint32_t x, uint32_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint64_t and64(uint64_t x, uint64_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint8_t or8(uint8_t x, uint8_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint16_t or16(uint16_t x, uint16_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint32_t or32(uint32_t x, uint32_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint64_t or64(uint64_t x, uint64_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint8_t xor8(uint8_t x, uint8_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR uint16_t xor16(uint16_t x, uint16_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR uint32_t xor32(uint32_t x, uint32_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR uint64_t xor64(uint64_t x, uint64_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR bool ult8(uint8_t x, uint8_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ult16(uint16_t x, uint16_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ult32(uint32_t x, uint32_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ult64(uint64_t x, uint64", "_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ule8(uint8_t x, uint8_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool ule16(uint16_t x, uint16_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool ule32(uint32_t x, uint32_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool ule64(uint64_t x, uint64_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool slt8(int8_t x, int8_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool slt16(int16_t x, int16_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool slt32(int32_t x, int32_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool slt64(int64_t x, int64_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool sle8(int8_t x, int8_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool sle16(int16_t x, int16_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool sle32(int32_t x, int32_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool sle64(int64_t x, int64_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR uint8_t pow8(uint8_t x, uint8_t y) {\n  uint8_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uint16_t pow16(uint16_t x, uint16_t y) {\n  uint16_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uint32_t pow32(uint32_t x, uint32_t y) {\n  uint32_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uint64_t pow64(uint64_t x, uint64_t y) {\n  uint64_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR bool itob_i8_bool(int8_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR bool itob_i16_bool(int16_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR bool itob_i32_bool(int32_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR bool itob_i64_bool(int64_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR int8_t btoi_bool_i8(bool x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR int16_t btoi_bool_i16(bool x",
                                    ") {\n  return x;\n}\n\nSCALAR_FUN_ATTR int32_t btoi_bool_i32(bool x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR int64_t btoi_bool_i64(bool x) {\n  return x;\n}\n\n#define sext_i8_i8(x) ((int8_t) (int8_t) (x))\n#define sext_i8_i16(x) ((int16_t) (int8_t) (x))\n#define sext_i8_i32(x) ((int32_t) (int8_t) (x))\n#define sext_i8_i64(x) ((int64_t) (int8_t) (x))\n#define sext_i16_i8(x) ((int8_t) (int16_t) (x))\n#define sext_i16_i16(x) ((int16_t) (int16_t) (x))\n#define sext_i16_i32(x) ((int32_t) (int16_t) (x))\n#define sext_i16_i64(x) ((int64_t) (int16_t) (x))\n#define sext_i32_i8(x) ((int8_t) (int32_t) (x))\n#define sext_i32_i16(x) ((int16_t) (int32_t) (x))\n#define sext_i32_i32(x) ((int32_t) (int32_t) (x))\n#define sext_i32_i64(x) ((int64_t) (int32_t) (x))\n#define sext_i64_i8(x) ((int8_t) (int64_t) (x))\n#define sext_i64_i16(x) ((int16_t) (int64_t) (x))\n#define sext_i64_i32(x) ((int32_t) (int64_t) (x))\n#define sext_i64_i64(x) ((int64_t) (int64_t) (x))\n#define zext_i8_i8(x) ((int8_t) (uint8_t) (x))\n#define zext_i8_i16(x) ((int16_t) (uint8_t) (x))\n#define zext_i8_i32(x) ((int32_t) (uint8_t) (x))\n#define zext_i8_i64(x) ((int64_t) (uint8_t) (x))\n#define zext_i16_i8(x) ((int8_t) (uint16_t) (x))\n#define zext_i16_i16(x) ((int16_t) (uint16_t) (x))\n#define zext_i16_i32(x) ((int32_t) (uint16_t) (x))\n#define zext_i16_i64(x) ((int64_t) (uint16_t) (x))\n#define zext_i32_i8(x) ((int8_t) (uint32_t) (x))\n#define zext_i32_i16(x) ((int16_t) (uint32_t) (x))\n#define zext_i32_i32(x) ((int32_t) (uint32_t) (x))\n#define zext_i32_i64(x) ((int64_t) (uint32_t) (x))\n#define zext_i64_i8(x) ((int8_t) (uint64_t) (x))\n#define zext_i64_i16(x) ((int16_t) (uint64_t) (x))\n#define zext_i64_i32(x) ((int32_t) (uint64_t) (x))\n#define zext_i64_i64(x) ((int64_t) (uint64_t) (x))\n\nSCALAR_FUN_ATTR int8_t abs8(int8_t x) {\n  return (int8_t)abs(x);\n}\n\nSCALAR_FUN_ATTR int16_t abs16(int16_t x) {\n  return (int16_t)abs(x);\n}\n\nSCALAR_FUN_ATTR int32_t abs32(int32_t x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR int64_t abs64(int64_t x) {\n#if defined(__OPENCL_VER", "SION__) || defined(ISPC)\n  return abs(x);\n#else\n  return llabs(x);\n#endif\n}\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {\n  return popcount(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {\n  return popcount(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {\n  return popcount(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {\n  return popcount(x);\n}\n#elif defined(__CUDA_ARCH__)\n\nSCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {\n  return __popc(zext_i8_i32(x));\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {\n  return __popc(zext_i16_i32(x));\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {\n  return __popc(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {\n  return __popcll(x);\n}\n\n#else // Not OpenCL or CUDA, but plain C.\n\nSCALAR_FUN_ATTR int32_t futrts_popc8(uint8_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc16(uint16_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc32(uint32_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc64(uint64_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR uint8_t  futrts_umul_hi8 ( uint8_t a,  uint8_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint8_t  futrts_smul_hi8 ( int8_t a,  int8_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return m", "ul_hi(a, b); }\n#elif defined(__CUDA_ARCH__)\nSCALAR_FUN_ATTR  uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return __umulhi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return __umul64hi(a, b); }\nSCALAR_FUN_ATTR  uint8_t futrts_smul_hi8 ( int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return __mulhi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return __mul64hi(a, b); }\n#elif ISPC\nSCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) {\n  uint64_t ah = a >> 32;\n  uint64_t al = a & 0xffffffff;\n  uint64_t bh = b >> 32;\n  uint64_t bl = b & 0xffffffff;\n\n  uint64_t p1 = al * bl;\n  uint64_t p2 = al * bh;\n  uint64_t p3 = ah * bl;\n  uint64_t p4 = ah * bh;\n\n  uint64_t p1h = p1 >> 32;\n  uint64_t p2h = p2 >> 32;\n  uint64_t p3h = p3 >> 32;\n  uint64_t p2l = p2 & 0xffffffff;\n  uint64_t p3l = p3 & 0xffffffff;\n\n  uint64_t l = p1h + p2l + p3l;\n  uint64_t m = (p2 >> 32) + (p3 >> 32);\n  uint64_t h = (l >> 32) + m + p4;\n\n  return h;\n}\nSCALAR_FUN_ATTR  int8_t futrts_smul_hi8 ( int8_t a,  int8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR int",
                                    "32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nSCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) {\n  uint64_t ah = a >> 32;\n  uint64_t al = a & 0xffffffff;\n  uint64_t bh = b >> 32;\n  uint64_t bl = b & 0xffffffff;\n\n  uint64_t p1 =  al * bl;\n  int64_t  p2 = al * bh;\n  int64_t  p3 = ah * bl;\n  uint64_t p4 =  ah * bh;\n\n  uint64_t p1h = p1 >> 32;\n  uint64_t p2h = p2 >> 32;\n  uint64_t p3h = p3 >> 32;\n  uint64_t p2l = p2 & 0xffffffff;\n  uint64_t p3l = p3 & 0xffffffff;\n\n  uint64_t l = p1h + p2l + p3l;\n  uint64_t m = (p2 >> 32) + (p3 >> 32);\n  uint64_t h = (l >> 32) + m + p4;\n\n  return h;\n}\n\n#else // Not OpenCL, ISPC, or CUDA, but plain C.\nSCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return ((__uint128_t)a) * ((__uint128_t)b) >> 64; }\nSCALAR_FUN_ATTR int8_t futrts_smul_hi8(int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }\nSCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }\nSCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((int64_t)a) * ((int64_t)b) >> 32; }\nSCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) { return ((__int128_t)a) * ((__int128_t)b) >> 64; }\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR  uint8_t futrts_umad_hi8 ( uint8_t a,  uint8_t b,  uint8_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t ", "a, uint64_t b, uint64_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR  uint8_t futrts_smad_hi8( int8_t a,  int8_t b,   int8_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return mad_hi(a, b, c); }\n#else // Not OpenCL\n\nSCALAR_FUN_ATTR  uint8_t futrts_umad_hi8( uint8_t a,  uint8_t b,  uint8_t c) { return futrts_umul_hi8(a, b) + c; }\nSCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return futrts_umul_hi16(a, b) + c; }\nSCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return futrts_umul_hi32(a, b) + c; }\nSCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return futrts_umul_hi64(a, b) + c; }\nSCALAR_FUN_ATTR  uint8_t futrts_smad_hi8 ( int8_t a,  int8_t b,  int8_t c) { return futrts_smul_hi8(a, b) + c; }\nSCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return futrts_smul_hi16(a, b) + c; }\nSCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return futrts_smul_hi32(a, b) + c; }\nSCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return futrts_smul_hi64(a, b) + c; }\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  return clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return clz(x);\n}\n\n#elif defined(__CUDA_ARCH__)\n\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return __clz(zext_i8_i32(x)) - 24;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return __clz(zext_i16_i32(x)) - 16;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  retur", "n __clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return __clzll(x);\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return count_leading_zeros((int32_t)(uint8_t)x)-24;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return count_leading_zeros((int32_t)(uint16_t)x)-16;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  return count_leading_zeros(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return count_leading_zeros(x);\n}\n\n#else // Not OpenCL, ISPC or CUDA, but plain C.\n\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return x == 0 ? 8 : __builtin_clz((uint32_t)zext_i8_i32(x)) - 24;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return x == 0 ? 16 : __builtin_clz((uint32_t)zext_i16_i32(x)) - 16;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  return x == 0 ? 32 : __builtin_clz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return x == 0 ? 64 : __builtin_clzll((uint64_t)x);\n}\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  int i = 0;\n  for (; i < 8 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  int i = 0;\n  for (; i < 16 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  int i = 0;\n  for (; i < 32 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  int i = 0;\n  for (; i < 64 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\n#elif defined(__CUDA_ARCH__)\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 8 : y - 1;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 16 : y - 1;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 32 : y - 1;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  int y = __ffsll(x);\n  return y == 0 ? 64 : y - 1",
                                    ";\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  return x == 0 ? 8 : count_trailing_zeros((int32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  return x == 0 ? 16 : count_trailing_zeros((int32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  return count_trailing_zeros(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  return count_trailing_zeros(x);\n}\n\n#else // Not OpenCL or CUDA, but plain C.\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  return x == 0 ? 8 : __builtin_ctz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  return x == 0 ? 16 : __builtin_ctz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  return x == 0 ? 32 : __builtin_ctz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  return x == 0 ? 64 : __builtin_ctzll((uint64_t)x);\n}\n#endif\n\nSCALAR_FUN_ATTR float fdiv32(float x, float y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR float fadd32(float x, float y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR float fsub32(float x, float y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR float fmul32(float x, float y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt32(float x, float y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple32(float x, float y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR float sitofp_i8_f32(int8_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float sitofp_i16_f32(int16_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float sitofp_i32_f32(int32_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float sitofp_i64_f32(int64_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i8_f32(uint8_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i16_f32(uint16_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i32_f32(uint32_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i64_f32(uint64_t x) {\n  return (float) x;\n}\n\n#ifdef __OPENCL_VERSION__\nSCALAR_FUN_ATTR float fabs32(float x) {\n  return fabs(x);\n}\n\nSCALAR_FUN_ATTR float fmax32(float x, f", "loat y) {\n  return fmax(x, y);\n}\n\nSCALAR_FUN_ATTR float fmin32(float x, float y) {\n  return fmin(x, y);\n}\n\nSCALAR_FUN_ATTR float fpow32(float x, float y) {\n  return pow(x, y);\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR float fabs32(float x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR float fmax32(float x, float y) {\n  return isnan(x) ? y : isnan(y) ? x : max(x, y);\n}\n\nSCALAR_FUN_ATTR float fmin32(float x, float y) {\n  return isnan(x) ? y : isnan(y) ? x : min(x, y);\n}\n\nSCALAR_FUN_ATTR float fpow32(float a, float b) {\n  float ret;\n  foreach_active (i) {\n      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));\n      ret = insert(ret, i, r);\n  }\n  return ret;\n}\n\n#else // Not OpenCL, but CUDA or plain C.\n\nSCALAR_FUN_ATTR float fabs32(float x) {\n  return fabsf(x);\n}\n\nSCALAR_FUN_ATTR float fmax32(float x, float y) {\n  return fmaxf(x, y);\n}\n\nSCALAR_FUN_ATTR float fmin32(float x, float y) {\n  return fminf(x, y);\n}\n\nSCALAR_FUN_ATTR float fpow32(float x, float y) {\n  return powf(x, y);\n}\n#endif\n\nSCALAR_FUN_ATTR bool futrts_isnan32(float x) {\n  return isnan(x);\n}\n\n#if ISPC\n\nSCALAR_FUN_ATTR bool futrts_isinf32(float x) {\n  return !isnan(x) && isnan(x - x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isfinite32(float x) {\n  return !isnan(x) && !futrts_isinf32(x);\n}\n\n#else\n\nSCALAR_FUN_ATTR bool futrts_isinf32(float x) {\n  return isinf(x);\n}\n\n#endif\n\nSCALAR_FUN_ATTR int8_t fptosi_f32_i8(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f32_i16(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f32_i32(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f32_i64(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  };\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f32_i8(float x) {", "\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f32_i16(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f32_i32(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f32_i64(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR bool ftob_f32_bool(float x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR float btof_bool_f32(bool x) {\n  return x ? 1 : 0;\n}\n\n#ifdef __OPENCL_VERSION__\nSCALAR_FUN_ATTR float futrts_log32(float x) {\n  return log(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log2_32(float x) {\n  return log2(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log10_32(float x) {\n  return log10(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log1p_32(float x) {\n  return log1p(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sqrt32(float x) {\n  return sqrt(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cbrt32(float x) {\n  return cbrt(x);\n}\n\nSCALAR_FUN_ATTR float futrts_exp32(float x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cos32(float x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sin32(float x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tan32(float x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acos32(float x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asin32(float x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan32(float x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cosh32(float x) {\n  return cosh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sinh32(float x) {\n  return sinh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tanh32(float x) {\n  return tanh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acosh32(float x) {\n  return acosh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asinh32(float x) {\n  return asinh(x);\n}\n\nSC",
                                    "ALAR_FUN_ATTR float futrts_atanh32(float x) {\n  return atanh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {\n  return atan2(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {\n  return hypot(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_gamma32(float x) {\n  return tgamma(x);\n}\n\nSCALAR_FUN_ATTR float futrts_lgamma32(float x) {\n  return lgamma(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erf32(float x) {\n  return erf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erfc32(float x) {\n  return erfc(x);\n}\n\nSCALAR_FUN_ATTR float fmod32(float x, float y) {\n  return fmod(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_round32(float x) {\n  return rint(x);\n}\n\nSCALAR_FUN_ATTR float futrts_floor32(float x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR float futrts_ceil32(float x) {\n  return ceil(x);\n}\n\nSCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {\n  return nextafter(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {\n  return mix(v0, v1, t);\n}\n\nSCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {\n  return ldexp(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {\n  return copysign(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {\n  return mad(a, b, c);\n}\n\nSCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {\n  return fma(a, b, c);\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR float futrts_log32(float x) {\n  return futrts_isfinite32(x) || (futrts_isinf32(x) && x < 0)? log(x) : x;\n}\n\nSCALAR_FUN_ATTR float futrts_log2_32(float x) {\n  return futrts_log32(x) / log(2.0f);\n}\n\nSCALAR_FUN_ATTR float futrts_log10_32(float x) {\n  return futrts_log32(x) / log(10.0f);\n}\n\nSCALAR_FUN_ATTR float futrts_log1p_32(float x) {\n  if(x == -1.0f || (futrts_isinf32(x) && x > 0.0f)) return x / 0.0f;\n  float y = 1.0f + x;\n  float z = y - 1.0f;\n  return log(y) - (z-x)/y;\n}\n\nSCALAR_FUN_ATTR float futrts_sqrt32(float x) {\n  return sqrt(x);\n}\n\nextern \"C\" unmasked uniform float cbrtf(uniform float);\nSCALAR_FUN_ATTR float futrts_cbrt32(float", " x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = cbrtf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR float futrts_exp32(float x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cos32(float x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sin32(float x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tan32(float x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acos32(float x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asin32(float x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan32(float x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cosh32(float x) {\n  return (exp(x)+exp(-x)) / 2.0f;\n}\n\nSCALAR_FUN_ATTR float futrts_sinh32(float x) {\n  return (exp(x)-exp(-x)) / 2.0f;\n}\n\nSCALAR_FUN_ATTR float futrts_tanh32(float x) {\n  return futrts_sinh32(x)/futrts_cosh32(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acosh32(float x) {\n  float f = x+sqrt(x*x-1);\n  if(futrts_isfinite32(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR float futrts_asinh32(float x) {\n  float f = x+sqrt(x*x+1);\n  if(futrts_isfinite32(f)) return log(f);\n  return f;\n\n}\n\nSCALAR_FUN_ATTR float futrts_atanh32(float x) {\n  float f = (1+x)/(1-x);\n  if(futrts_isfinite32(f)) return log(f)/2.0f;\n  return f;\n\n}\n\nSCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {\n  return (x == 0.0f && y == 0.0f) ? 0.0f : atan2(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {\n  if (futrts_isfinite32(x) && futrts_isfinite32(y)) {\n    x = abs(x);\n    y = abs(y);\n    float a;\n    float b;\n    if (x >= y){\n        a = x;\n        b = y;\n    } else {\n        a = y;\n        b = x;\n    }\n    if(b == 0){\n      return a;\n    }\n\n    int e;\n    float an;\n    float bn;\n    an = frexp (a, &e);\n    bn = ldexp (b, - e);\n    float cn;\n    cn = sqrt (an * an + bn * bn);\n    return ldexp (cn, e);\n  } else {\n    if (futrts_isinf32(x) || futrts_isinf32(y)) return INFINITY;\n    else return x + y;\n  }\n\n}\n\nextern \"C\" unmasked uniform float tgammaf(", "uniform float x);\nSCALAR_FUN_ATTR float futrts_gamma32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = tgammaf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float lgammaf(uniform float x);\nSCALAR_FUN_ATTR float futrts_lgamma32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = lgammaf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float erff(uniform float x);\nSCALAR_FUN_ATTR float futrts_erf32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = erff(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float erfcf(uniform float x);\nSCALAR_FUN_ATTR float futrts_erfc32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = erfcf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR float fmod32(float x, float y) {\n  return x - y * trunc(x/y);\n}\n\nSCALAR_FUN_ATTR float futrts_round32(float x) {\n  return round(x);\n}\n\nSCALAR_FUN_ATTR float futrts_floor32(float x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR float futrts_ceil32(float x) {\n  return ceil(x);\n}\n\nextern \"C\" unmasked uniform float nextafterf(uniform float x, uniform float y);\nSCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {\n  float res;\n  foreach_active (i) {\n    uniform float r = nextafterf(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {\n  return x * pow((double)2.0, (double)y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {\n  int32_t xb = futrts_to_bits32(x);\n  int32_t yb = futrts_to_bits32(y);\n  return futrts_from_bits32((xb & ~(1<<31)) | (yb & (1<<31)));\n}\n\nSCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR float futr",
                                    "ts_fma32(float a, float b, float c) {\n  return a * b + c;\n}\n\n#else // Not OpenCL or ISPC, but CUDA or plain C.\n\nSCALAR_FUN_ATTR float futrts_log32(float x) {\n  return logf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log2_32(float x) {\n  return log2f(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log10_32(float x) {\n  return log10f(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log1p_32(float x) {\n  return log1pf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sqrt32(float x) {\n  return sqrtf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cbrt32(float x) {\n  return cbrtf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_exp32(float x) {\n  return expf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cos32(float x) {\n  return cosf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sin32(float x) {\n  return sinf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tan32(float x) {\n  return tanf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acos32(float x) {\n  return acosf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asin32(float x) {\n  return asinf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan32(float x) {\n  return atanf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cosh32(float x) {\n  return coshf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sinh32(float x) {\n  return sinhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tanh32(float x) {\n  return tanhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acosh32(float x) {\n  return acoshf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asinh32(float x) {\n  return asinhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atanh32(float x) {\n  return atanhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {\n  return atan2f(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {\n  return hypotf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_gamma32(float x) {\n  return tgammaf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_lgamma32(float x) {\n  return lgammaf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erf32(float x) {\n  return erff(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erfc32(float x) {\n  return erfcf(x);\n}\n\nSCALAR_FUN_ATTR float fmod32(float x, float y) {\n  return fmodf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_round32(float x) {\n  re", "turn rintf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_floor32(float x) {\n  return floorf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_ceil32(float x) {\n  return ceilf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {\n  return nextafterf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {\n  return ldexpf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {\n  return copysignf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {\n  return fmaf(a, b, c);\n}\n#endif\n\n#if ISPC\nSCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {\n  return intbits(x);\n}\n\nSCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {\n  return floatbits(x);\n}\n#else\nSCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {\n  union {\n    float f;\n    int32_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {\n  union {\n    int32_t f;\n    float t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n#endif\n\nSCALAR_FUN_ATTR float fsignum32(float x) {\n  return futrts_isnan32(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nSCALAR_FUN_ATTR double futrts_from_bits64(int64_t x);\nSCALAR_FUN_ATTR int64_t futrts_to_bits64(double x);\n\n#if ISPC\nSCALAR_FUN_ATTR bool futrts_isinf64(float x) {\n  return !isnan(x) && isnan(x - x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isfinite64(float x) {\n  return !isnan(x) && !futrts_isinf64(x);\n}\n\nSCALAR_FUN_ATTR double fdiv64(double x, double y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR double fadd64(double x, double y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR double fsub64(double x, double y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR double fmul64(double x, double y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt64(double x, double y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple64(double x, double y) {\n  return x <= y;\n}", "\n\nSCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double fabs64(double x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR double fmax64(double x, double y) {\n  return isnan(x) ? y : isnan(y) ? x : max(x, y);\n}\n\nSCALAR_FUN_ATTR double fmin64(double x, double y) {\n  return isnan(x) ? y : isnan(y) ? x : min(x, y);\n}\n\nSCALAR_FUN_ATTR double fpow64(double a, double b) {\n  float ret;\n  foreach_active (i) {\n      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));\n      ret = insert(ret, i, r);\n  }\n  return ret;\n}\n\nSCALAR_FUN_ATTR double futrts_log64(double x) {\n  return futrts_isfinite64(x) || (futrts_isinf64(x) && x < 0)? log(x) : x;\n}\n\nSCALAR_FUN_ATTR double futrts_log2_64(double x) {\n  return futrts_log64(x)/log(2.0d);\n}\n\nSCALAR_FUN_ATTR double futrts_log10_64(double x) {\n  return futrts_log64(x)/log(10.0d);\n}\n\nSCALAR_FUN_ATTR double futrts_log1p_64(double x) {\n  if(x == -1.0d || (futrts_isinf64(x) && x > 0.0d)) return x / 0.0d;\n  double y = 1.0d + x;\n  double z = y - 1.0d;\n  return log(y) - (z-x)/y;\n}\n\nSCALAR_FUN_ATTR double futrts_sqrt64(double x) {\n  return sqrt(x);\n}\n\nextern \"C\" unmasked uniform double cbrt(uniform double);\nSCALAR_FUN_ATTR double futrts_cbrt64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = cbrtf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_exp64(double x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cos64(dou",
                                    "ble x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sin64(double x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_tan64(double x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acos64(double x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_asin64(double x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atan64(double x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cosh64(double x) {\n  return (exp(x)+exp(-x)) / 2.0d;\n}\n\nSCALAR_FUN_ATTR double futrts_sinh64(double x) {\n  return (exp(x)-exp(-x)) / 2.0d;\n}\n\nSCALAR_FUN_ATTR double futrts_tanh64(double x) {\n  return futrts_sinh64(x)/futrts_cosh64(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acosh64(double x) {\n  double f = x+sqrt(x*x-1.0d);\n  if(futrts_isfinite64(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR double futrts_asinh64(double x) {\n  double f = x+sqrt(x*x+1.0d);\n  if(futrts_isfinite64(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR double futrts_atanh64(double x) {\n  double f = (1.0d+x)/(1.0d-x);\n  if(futrts_isfinite64(f)) return log(f)/2.0d;\n  return f;\n\n}\n\nSCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {\n  return atan2(x, y);\n}\n\nextern \"C\" unmasked uniform double hypot(uniform double x, uniform double y);\nSCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {\n  double res;\n  foreach_active (i) {\n    uniform double r = hypot(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double tgamma(uniform double x);\nSCALAR_FUN_ATTR double futrts_gamma64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = tgamma(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double lgamma(uniform double x);\nSCALAR_FUN_ATTR double futrts_lgamma64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = lgamma(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double erf(uniform double x);\nSCALAR_FUN_ATTR do", "uble futrts_erf64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = erf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double erfc(uniform double x);\nSCALAR_FUN_ATTR double futrts_erfc64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = erfc(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR double futrts_round64(double x) {\n  return round(x);\n}\n\nSCALAR_FUN_ATTR double futrts_ceil64(double x) {\n  return ceil(x);\n}\n\nextern \"C\" unmasked uniform double nextafter(uniform float x, uniform double y);\nSCALAR_FUN_ATTR float futrts_nextafter64(double x, double y) {\n  double res;\n  foreach_active (i) {\n    uniform double r = nextafter(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_floor64(double x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isnan64(double x) {\n  return isnan(x);\n}\n\nSCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int", "16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR bool ftob_f64_bool(double x) {\n  return x != 0.0;\n}\n\nSCALAR_FUN_ATTR double btof_bool_f64(bool x) {\n  return x ? 1.0 : 0.0;\n}\n\nSCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {\n  int64_t res;\n  foreach_active (i) {\n    uniform double tmp = extract(x, i);\n    uniform int64_t r = *((uniform int64_t* uniform)&tmp);\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {\n  double res;\n  foreach_active (i) {\n    uniform int64_t tmp = extract(x, i);\n    uniform double r = *((uniform double* uniform)&tmp);\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double fmod64(double x, double y) {\n  return x - y * trunc(x/y);\n}\n\nSCALAR_FUN_ATTR double fsignum64(double x) {\n  return futrts_isnan64(x) ? x : (x > 0 ? 1.0d : 0.0d) - (x < 0 ? 1.0d : 0.0d);\n}\n\nSCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {\n  return x * pow((double)2.0, (double)y);\n}\n\nSCALAR_FUN_ATTR double futrts_copysign64(double x, double y) {\n  int64_t xb = futrts_to_bits64(x);\n  int64_t yb = futrts_to_bits64(y);\n  return futrts_from_bits64((xb & ~(((int64_t)1)<<63)) | (yb & (((int64_t)1)<<63)));\n}\n\nSCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR float fpconv_f32_f32(float x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f32_f64(float x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR float fpconv_f64_f32(double x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f64_f64(double x) {\n  return (double) x;\n}\n\n#e",
                                    "lse\n\nSCALAR_FUN_ATTR double fdiv64(double x, double y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR double fadd64(double x, double y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR double fsub64(double x, double y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR double fmul64(double x, double y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt64(double x, double y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple64(double x, double y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double fabs64(double x) {\n  return fabs(x);\n}\n\nSCALAR_FUN_ATTR double fmax64(double x, double y) {\n  return fmax(x, y);\n}\n\nSCALAR_FUN_ATTR double fmin64(double x, double y) {\n  return fmin(x, y);\n}\n\nSCALAR_FUN_ATTR double fpow64(double x, double y) {\n  return pow(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_log64(double x) {\n  return log(x);\n}\n\nSCALAR_FUN_ATTR double futrts_log2_64(double x) {\n  return log2(x);\n}\n\nSCALAR_FUN_ATTR double futrts_log10_64(double x) {\n  return log10(x);\n}\n\nSCALAR_FUN_ATTR double futrts_log1p_64(double x) {\n  return log1p(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sqrt64(double x) {\n  return sqrt(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cbrt64(double x) {\n  return cbrt(x);\n}\n\nSCALAR_FUN_ATTR double futrts_exp64(double x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cos64(double x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sin64(double x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_tan64(double x) {\n  r", "eturn tan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acos64(double x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_asin64(double x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atan64(double x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cosh64(double x) {\n  return cosh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sinh64(double x) {\n  return sinh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_tanh64(double x) {\n  return tanh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acosh64(double x) {\n  return acosh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_asinh64(double x) {\n  return asinh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atanh64(double x) {\n  return atanh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {\n  return atan2(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {\n  return hypot(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_gamma64(double x) {\n  return tgamma(x);\n}\n\nSCALAR_FUN_ATTR double futrts_lgamma64(double x) {\n  return lgamma(x);\n}\n\nSCALAR_FUN_ATTR double futrts_erf64(double x) {\n  return erf(x);\n}\n\nSCALAR_FUN_ATTR double futrts_erfc64(double x) {\n  return erfc(x);\n}\n\nSCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {\n  return fma(a, b, c);\n}\n\nSCALAR_FUN_ATTR double futrts_round64(double x) {\n  return rint(x);\n}\n\nSCALAR_FUN_ATTR double futrts_ceil64(double x) {\n  return ceil(x);\n}\n\nSCALAR_FUN_ATTR float futrts_nextafter64(float x, float y) {\n  return nextafter(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_floor64(double x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isnan64(double x) {\n  return isnan(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isinf64(double x) {\n  return isinf(x);\n}\n\nSCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x", ") {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR bool ftob_f64_bool(double x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR double btof_bool_f64(bool x) {\n  return x ? 1 : 0;\n}\n\nSCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {\n  union {\n    double f;\n    int64_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {\n  union {\n    int64_t f;\n    double t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR double fmod64(double x, double y) {\n  return fmod(x, y);\n}\n\nSCALAR_FUN_ATTR double fsignum64(double x) {\n  return futrts_isnan64(x) ? x : (x > 0) - (x < 0);\n}\n\nSCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {\n#ifdef __OPENCL_VERSION__\n  return mix(v0, v1, t);\n#else\n  return v0 + (v1 - v0) * t;\n#endif\n}\n\nSCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {\n  return ldexp(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign64(double x, double y) {\n  return copysign(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {\n#ifdef __OPENCL_VERSION__\n  return mad(a, b, c);\n#else\n  return a * b + c;\n#endif\n}\n\nSCALAR",
                                    "_FUN_ATTR float fpconv_f32_f32(float x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f32_f64(float x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR float fpconv_f64_f32(double x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f64_f64(double x) {\n  return (double) x;\n}\n\n#endif\n\n#endif\n\n// End of scalar.h.\n// Start of scalar_f16.h.\n\n// Half-precision is emulated if needed (e.g. in straight C) with the\n// native type used if possible.  The emulation works by typedef'ing\n// 'float' to 'f16', and then implementing all operations on single\n// precision.  To cut down on duplication, we use the same code for\n// those Futhark functions that require just operators or casts.  The\n// in-memory representation for arrays will still be 16 bits even\n// under emulation, so the compiler will have to be careful when\n// generating reads or writes.\n\n#if !defined(cl_khr_fp16) && !(defined(__CUDA_ARCH__) && __CUDA_ARCH__ >= 600) && !(defined(ISPC))\n#define EMULATE_F16\n#endif\n\n#if !defined(EMULATE_F16) && defined(__OPENCL_VERSION__)\n#pragma OPENCL EXTENSION cl_khr_fp16 : enable\n#endif\n\n#ifdef EMULATE_F16\n\n// Note that the half-precision storage format is still 16 bits - the\n// compiler will have to be real careful!\ntypedef float f16;\n\n#elif ISPC\ntypedef float16 f16;\n\n#else\n\n#ifdef __CUDA_ARCH__\n#include <cuda_fp16.h>\n#endif\n\ntypedef half f16;\n\n#endif\n\n// Some of these functions convert to single precision because half\n// precision versions are not available.\n\nSCALAR_FUN_ATTR f16 fadd16(f16 x, f16 y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR f16 fsub16(f16 x, f16 y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR f16 fmul16(f16 x, f16 y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt16(f16 x, f16 y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple16(f16 x, f16 y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR f16 sitofp_i8_f16(int8_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 sitofp_i16_f16(int16_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 sitofp_i32_f16(int32_t x) {\n  return (f16) x;\n}\n\nSCALAR", "_FUN_ATTR f16 sitofp_i64_f16(int64_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i8_f16(uint8_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i16_f16(uint16_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i32_f16(uint32_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i64_f16(uint64_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR int8_t fptosi_f16_i8(f16 x) {\n  return (int8_t) (float) x;\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f16_i16(f16 x) {\n  return (int16_t) x;\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f16_i32(f16 x) {\n  return (int32_t) x;\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f16_i64(f16 x) {\n  return (int64_t) x;\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f16_i8(f16 x) {\n  return (uint8_t) (float) x;\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f16_i16(f16 x) {\n  return (uint16_t) x;\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f16_i32(f16 x) {\n  return (uint32_t) x;\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f16_i64(f16 x) {\n  return (uint64_t) x;\n}\n\nSCALAR_FUN_ATTR bool ftob_f16_bool(f16 x) {\n  return x != (f16)0;\n}\n\nSCALAR_FUN_ATTR f16 btof_bool_f16(bool x) {\n  return x ? 1 : 0;\n}\n\n#ifndef EMULATE_F16\nSCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {\n  return isnan((float)x);\n}\n\n#ifdef __OPENCL_VERSION__\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return fabs(x);\n}\n\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return fmax(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {\n  return fmin(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return pow(x, y);\n}\n\n#elif ISPC\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : max(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {\n  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : min(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return pow(x, y);\n}\n\n#else // Assuming CUDA.\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return fabsf(x);\n}\n\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return fmaxf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 ", "x, f16 y) {\n  return fminf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return powf(x, y);\n}\n#endif\n\n#if ISPC\nSCALAR_FUN_ATTR bool futrts_isinf16(float x) {\n  return !futrts_isnan16(x) && futrts_isnan16(x - x);\n}\nSCALAR_FUN_ATTR bool futrts_isfinite16(float x) {\n  return !futrts_isnan16(x) && !futrts_isinf16(x);\n}\n\n#else\n\nSCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {\n  return isinf((float)x);\n}\n#endif\n\n#ifdef __OPENCL_VERSION__\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return log(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return log2(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return log10(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  return log1p(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return sqrt(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  return cbrt(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  return cosh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return sinh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return tanh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  return acosh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  return asinh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  return atanh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return atan2(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return hypot(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {\n  return tgamma(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  return lgamma(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  return e",
                                    "rf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  return erfc(x);\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return fmod(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return rint(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return ceil(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {\n  return nextafter(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return mix(v0, v1, t);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return ldexp(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return copysign(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return mad(a, b, c);\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return fma(a, b, c);\n}\n#elif ISPC\n\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return futrts_isfinite16(x) || (futrts_isinf16(x) && x < 0) ? log(x) : x;\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return futrts_log16(x) / log(2.0f16);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return futrts_log16(x) / log(10.0f16);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  if(x == -1.0f16 || (futrts_isinf16(x) && x > 0.0f16)) return x / 0.0f16;\n  f16 y = 1.0f16 + x;\n  f16 z = y - 1.0f16;\n  return log(y) - (z-x)/y;\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return (float16)sqrt((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return (float16)cos((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return (float16)sin((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return (float16)tan((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return (float16)acos((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return (float16)asin((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return (float16)atan((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  retu", "rn (exp(x)+exp(-x)) / 2.0f16;\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return (exp(x)-exp(-x)) / 2.0f16;\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return futrts_sinh16(x)/futrts_cosh16(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  float16 f = x+(float16)sqrt((float)(x*x-1));\n  if(futrts_isfinite16(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  float16 f = x+(float16)sqrt((float)(x*x+1));\n  if(futrts_isfinite16(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  float16 f = (1+x)/(1-x);\n  if(futrts_isfinite16(f)) return log(f)/2.0f16;\n  return f;\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return (float16)atan2((float)x, (float)y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return (float16)futrts_hypot32((float)x, (float)y);\n}\n\nextern \"C\" unmasked uniform float tgammaf(uniform float x);\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {\n  f16 res;\n  foreach_active (i) {\n    uniform f16 r = (f16)tgammaf(extract((float)x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float lgammaf(uniform float x);\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  f16 res;\n  foreach_active (i) {\n    uniform f16 r = (f16)lgammaf(extract((float)x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  f16 res = (f16)futrts_cbrt32((float)x);\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  f16 res = (f16)futrts_erf32((float)x);\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  f16 res = (f16)futrts_erfc32((float)x);\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return x - y * (float16)trunc((float) (x/y));\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return (float16)round((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return (float16)floor((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return (float16)ceil((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrt", "s_nextafter16(f16 x, f16 y) {\n  return (float16)futrts_nextafter32((float)x, (float) y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return futrts_ldexp32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return futrts_copysign32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\n#else // Assume CUDA.\n\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return hlog(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return hlog2(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return hlog10(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  return (f16)log1pf((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return hsqrt(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  return cbrtf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return hexp(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return hcos(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return hsin(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return tanf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return acosf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return asinf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return atanf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  return coshf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return sinhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return tanhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  return acoshf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  return asinhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  return atanhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return atan2f(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return hypotf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_gamma16(f1",
                                    "6 x) {\n  return tgammaf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  return lgammaf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  return erff(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  return erfcf(x);\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return fmodf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return rintf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return hfloor(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return hceil(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {\n  return __ushort_as_half(halfbitsnextafter(__half_as_ushort(x), __half_as_ushort(y)));\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return futrts_ldexp32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return futrts_copysign32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return fmaf(a, b, c);\n}\n\n#endif\n\n// The CUDA __half type cannot be put in unions for some reason, so we\n// use bespoke conversion functions instead.\n#ifdef __CUDA_ARCH__\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  return __half_as_ushort(x);\n}\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  return __ushort_as_half(x);\n}\n#elif ISPC\n\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  varying int16_t y = *((varying int16_t * uniform)&x);\n  return y;\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  varying f16 y = *((varying f16 * uniform)&x);\n  return y;\n}\n#else\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  union {\n    f16 f;\n    int16_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  union {\n    int16_t f;\n    f16 t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n#endif\n\n#else // No native f16 - emulate.\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return fabs32(x);\n}\n\nSC", "ALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return fmax32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {\n  return fmin32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return fpow32(x, y);\n}\n\nSCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {\n  return futrts_isnan32(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {\n  return futrts_isinf32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return futrts_log32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return futrts_log2_32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return futrts_log10_32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  return futrts_log1p_32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return futrts_sqrt32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  return futrts_cbrt32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return futrts_exp32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return futrts_cos32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return futrts_sin32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return futrts_tan32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return futrts_acos32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return futrts_asin32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return futrts_atan32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  return futrts_cosh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return futrts_sinh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return futrts_tanh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  return futrts_acosh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  return futrts_asinh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  return futrts_atanh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return futrts_atan2_32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return futrts_hypot32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {\n  return futrts_gamma32(x);\n}\n\nSCA", "LAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  return futrts_lgamma32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  return futrts_erf32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  return futrts_erfc32(x);\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return fmod32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return futrts_round32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return futrts_floor32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return futrts_ceil32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {\n  return halfbits2float(halfbitsnextafter(float2halfbits(x), float2halfbits(y)));\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return futrts_lerp32(v0, v1, t);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return futrts_ldexp32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return futrts_copysign32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return futrts_mad32(a, b, c);\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return futrts_fma32(a, b, c);\n}\n\n// Even when we are using an OpenCL that does not support cl_khr_fp16,\n// it must still support vload_half for actually creating a\n// half-precision number, which can then be efficiently converted to a\n// float.  Similarly for vstore_half.\n#ifdef __OPENCL_VERSION__\n\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  int16_t y;\n  // Violating strict aliasing here.\n  vstore_half((float)x, 0, (half*)&y);\n  return y;\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  return (f16)vload_half(0, (half*)&x);\n}\n\n#else\n\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  return (int16_t)float2halfbits(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  return halfbits2float((uint16_t)x);\n}\n\nSCALAR_FUN_ATTR f16 fsignum16(f16 x) {\n  return futrts_isnan16(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);\n}\n\n#endif\n\n#endif\n\nSCALAR_FUN_ATTR float fpconv_f16_f16(f16 x) {\n  retu",
                                    "rn x;\n}\n\nSCALAR_FUN_ATTR float fpconv_f16_f32(f16 x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR f16 fpconv_f32_f16(float x) {\n  return (f16) x;\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nSCALAR_FUN_ATTR double fpconv_f16_f64(f16 x) {\n  return (double) x;\n}\n\n#if ISPC\nSCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {\n  return (f16) ((float)x);\n}\n#else\nSCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {\n  return (f16) x;\n}\n#endif\n#endif\n\n\n// End of scalar_f16.h.\n// Start of atomics.h\n\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_global(volatile __global int32_t *p,\n                                                         int32_t cmp, int32_t val);\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_shared(volatile __local int32_t *p,\n                                                        int32_t cmp, int32_t val);\nSCALAR_FUN_ATTR int32_t atomic_add_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_add_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR float atomic_fadd_f32_global(volatile __global float *p, float x);\nSCALAR_FUN_ATTR float atomic_fadd_f32_shared(volatile __local float *p, float x);\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_global(volatile __global uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_shared(volatile __local uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_global(volatile __global uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_shared(volatile __local uint32", "_t *p, uint32_t x);\nSCALAR_FUN_ATTR int32_t atomic_and_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_and_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_or_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_or_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_shared(volatile __local int32_t *p, int32_t x);\n\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_global(volatile __global int32_t *p,\n                                                         int32_t cmp, int32_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((int32_t*)p, cmp, val);\n#else\n  return atomic_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_shared(volatile __local int32_t *p,\n                                                        int32_t cmp, int32_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((int32_t*)p, cmp, val);\n#else\n  return atomic_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_add_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((int32_t*)p, x);\n#else\n  return atomic_add(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_add_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((int32_t*)p, x);\n#el", "se\n  return atomic_add(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR float atomic_fadd_f32_global(volatile __global float *p, float x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((float*)p, x);\n  // On OpenCL, use technique from\n  // https://pipinspace.github.io/blog/atomic-float-addition-in-opencl.html\n#elif defined(cl_nv_pragma_unroll)\n  // use hardware-supported atomic addition on Nvidia GPUs with inline\n  // PTX assembly\n  float ret;\n  asm volatile(\"atom.global.add.f32 %0,[%1],%2;\":\"=f\"(ret):\"l\"(p),\"f\"(x):\"memory\");\n  return ret;\n#elif defined(__opencl_c_ext_fp32_global_atomic_add)\n  // use hardware-supported atomic addition on some Intel GPUs\n  return atomic_fetch_add_explicit((volatile __global atomic_float*)p,\n                                   x,\n                                   memory_order_relaxed);\n#elif __has_builtin(__builtin_amdgcn_global_atomic_fadd_f32)\n  // use hardware-supported atomic addition on some AMD GPUs\n  return __builtin_amdgcn_global_atomic_fadd_f32(p, x);\n#else\n  // fallback emulation:\n  // https://forums.developer.nvidia.com/t/atomicadd-float-float-atomicmul-float-float/14639/5\n  float old = x;\n  float ret;\n  while ((old=atomic_xchg(p, ret=atomic_xchg(p, 0.0f)+old))!=0.0f);\n  return ret;\n#endif\n}\n\nSCALAR_FUN_ATTR float atomic_fadd_f32_shared(volatile __local float *p, float x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((float*)p, x);\n#else\n  union { int32_t i; float f; } old;\n  union { int32_t i; float f; } assumed;\n  old.f = *p;\n  do {\n    assumed.f = old.f;\n    old.f = old.f + x;\n    old.i = atomic_cmpxchg_i32_shared((volatile __local int32_t*)p, assumed.i, old.i);\n  } while (assumed.i != old.i);\n  return old.f;\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((int32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_shared(volatile",
                                    " __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((int32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((int32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((int32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_global(volatile __global uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_shared(volatile __local uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_global(volatile __global uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_shared(volatile __local uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_and_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((int32_t*)p, x);\n#else\n  return atomic_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_and_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((int32_t*)p, x);\n#else\n  return atomic_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_or_i32_global(volatile __global int32_t *p, ", "int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((int32_t*)p, x);\n#else\n  return atomic_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_or_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((int32_t*)p, x);\n#else\n  return atomic_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\n// Start of 64 bit atomics\n\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP) || defined(cl_khr_int64_base_atomics) && defined(cl_khr_int64_extended_atomics)\n\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_global(volatile __global int64_t *p,\n                                                         int64_t cmp, int64_t val);\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_shared(volatile __local int64_t *p,\n                                                        int64_t cmp, int64_t val);\nSCALAR_FUN_ATTR int64_t atomic_add_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_add_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR uint", "64_t atomic_umax_i64_global(volatile __global uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_shared(volatile __local uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_global(volatile __global uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_shared(volatile __local uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR int64_t atomic_and_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_and_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_or_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_or_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_shared(volatile __local int64_t *p, int64_t x);\n\n#ifdef FUTHARK_F64_ENABLED\nSCALAR_FUN_ATTR double atomic_fadd_f64_global(volatile __global double *p, double x);\nSCALAR_FUN_ATTR double atomic_fadd_f64_shared(volatile __local double *p, double x);\n#endif\n\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_global(volatile __global int64_t *p,\n                                                         int64_t cmp, int64_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((uint64_t*)p, cmp, val);\n#else\n  return atom_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_shared(volatile __local int64_t *p,\n                                                        int64_t cmp, int64_t val) {\n#if defined(F",
                                    "UTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((uint64_t*)p, cmp, val);\n#else\n  return atom_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_add_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((uint64_t*)p, x);\n#else\n  return atom_add(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_add_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((uint64_t*)p, x);\n#else\n  return atom_add(p, x);\n#endif\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nSCALAR_FUN_ATTR double atomic_fadd_f64_global(volatile __global double *p, double x) {\n#if defined(FUTHARK_CUDA) && __CUDA_ARCH__ >= 600 || defined(FUTHARK_HIP)\n  return atomicAdd((double*)p, x);\n  // On OpenCL, use technique from\n  // https://pipinspace.github.io/blog/atomic-float-addition-in-opencl.html\n#elif defined(cl_nv_pragma_unroll)\n  // use hardware-supported atomic addition on Nvidia GPUs with inline\n  // PTX assembly\n  double ret;\n  asm volatile(\"atom.global.add.f64 %0,[%1],%2;\":\"=d\"(ret):\"l\"(p),\"d\"(x):\"memory\");\n  return ret;\n#elif __has_builtin(__builtin_amdgcn_global_atomic_fadd_f64)\n  // use hardware-supported atomic addition on some AMD GPUs\n  return __builtin_amdgcn_global_atomic_fadd_f64(p, x);\n#else\n  // fallback emulation:\n  // https://forums.developer.nvidia.com/t/atomicadd-float-float-atomicmul-float-float/14639/5\n  union {int64_t i; double f;} old;\n  union {int64_t i; double f;} ret;\n  old.f = x;\n  while (1) {\n    ret.i = atom_xchg((volatile __global int64_t*)p, (int64_t)0);\n    ret.f += old.f;\n    old.i = atom_xchg((volatile __global int64_t*)p, ret.i);\n    if (old.i == 0) {\n      break;\n    }\n  }\n  return ret.f;\n#endif\n}\n\nSCALAR_FUN_ATTR double atomic_fadd_f64_shared(volatile __local double *p, double x) {\n#if defined(FUTHARK_CUDA) && __CUDA_ARCH__ >= 600 || defined(FUTHARK_HIP)\n  return atomicAdd((double*)p, x);\n#else\n  union { int64_t i; double f; } old;\n  u", "nion { int64_t i; double f; } assumed;\n  old.f = *p;\n  do {\n    assumed.f = old.f;\n    old.f = old.f + x;\n    old.i = atomic_cmpxchg_i64_shared((volatile __local int64_t*)p, assumed.i, old.i);\n  } while (assumed.i != old.i);\n  return old.f;\n#endif\n}\n\n#endif\n\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMax((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smax64(old, x);\n    old = atomic_cmpxchg_i64_global((volatile __global int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMax((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smax64(old, x);\n    old = atomic_cmpxchg_i64_shared((volatile __local int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMin((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smin64(old, x);\n    old = atomic_cmpxchg_i64_global((volatile __global int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMin((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do ", "{\n    assumed = old;\n    old = smin64(old, x);\n    old = atomic_cmpxchg_i64_shared((volatile __local int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_global(volatile __global uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint64_t*)p, x);\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_shared(volatile __local uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint64_t*)p, x);\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_global(volatile __global uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint64_t*)p, x);\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_shared(volatile __local uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint64_t*)p, x);\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_and_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((uint64_t*)p, x);\n#else\n  return atom_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_and_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((uint64_t*)p, x);\n#else\n  return atom_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_or_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((uint64_t*)p, x);\n#else\n  return atom_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_or_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((uint64_t*)p, x);\n#else\n  return atom_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_global(v",
                                    "olatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\n#endif // defined(FUTHARK_CUDA) || defined(FUTHARK_HIP) || defined(cl_khr_int64_base_atomics) && defined(cl_khr_int64_extended_atomics)\n\n// End of atomics.h\n// Start of transpose.cl\n\n#define GEN_TRANSPOSE_KERNELS(NAME, ELEM_TYPE)                          \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*2, TR_TILE_DIM/TR_ELEMS_PER_THREAD, 1)\\\nvoid map_transpose_##NAME(SHARED_MEM_PARAM                              \\\n                          __global ELEM_TYPE *dst_mem,                  \\\n                          int64_t dst_offset,                           \\\n                          __global ELEM_TYPE *src_mem,                  \\\n                          int64_t src_offset,                           \\\n                          int32_t num_arrays,                           \\\n                          int32_t x_elems,                              \\\n                          int32_t y_elems,                              \\\n                          int32_t mulx,                                 \\\n                          int32_t muly,                                 \\\n                          int32_t repeat_1,                             \\\n                          int32_t repeat_2) {                           \\\n  (void)mulx; (void)muly;                                               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_g", "lobal_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t x_index = global_id_0;                                    \\\n      int32_t y_index = tblock_id_1 * TR_TILE_DIM + get_local_id(1);    \\\n      if (x_index < x_elems) {                                          \\\n        for (int32_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int32_t index_i = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * x_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < y_elems) { \\\n            block[(get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * (TR_TILE_DIM+1) + \\\n                  get_local_id(0)] =                                    \\\n              src_mem[idata_offset + index_i];                          \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_TILE_DIM + get_local_id(0);            \\\n      y_index = tblock_id_0 * TR_TILE_DIM + get_local_id(1);            \\\n      if (x_index < y_elems) {                                          \\\n        for (int32_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int32_t index_out = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * y_elems + x_index; \\\n          if (y_in", "dex + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < x_elems) { \\\n            dst_mem[(odata_offset + index_out)] =                       \\\n              block[get_local_id(0) * (TR_TILE_DIM+1) +                 \\\n                    get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)]; \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM, TR_BLOCK_DIM, 1)                     \\\nvoid map_transpose_##NAME##_low_height(SHARED_MEM_PARAM                 \\\n                                                __global ELEM_TYPE *dst_mem, \\\n                                                int64_t dst_offset,     \\\n                                                __global ELEM_TYPE *src_mem, \\\n                                                int64_t src_offset,     \\\n                                                int32_t num_arrays,     \\\n                                                int32_t x_elems,        \\\n                                                int32_t y_elems,        \\\n                                                int32_t mulx,           \\\n                                                int32_t muly,           \\\n                                                int32_t repeat_1,       \\\n ",
                                    "                                               int32_t repeat_2) {     \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t x_index =                                                 \\\n        tblock_id_0 * TR_BLOCK_DIM * mulx +                             \\\n        get_local_id(0) +                                               \\\n        get_local_id(1)%mulx * TR_BLOCK_DIM;                            \\\n      int32_t y_index = tblock_id_1 * TR_BLOCK_DIM + get_local_id(1)/mulx; \\\n      int32_t index_in = y_index * x_elems + x_index;                   \\\n      if (x_index < x_elems && y_index < y_elems) {                     \\\n        block[get_local_id(1) * (TR_BLOCK_DIM+1) + get_local_id(0)] =   \\\n          src_mem[idata_offset + index_in];                             \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_BLOCK_DIM + get_local_id(0)/mulx;      \\\n      y_index =                                                         \\\n        tblock_id_0 * TR_BLOCK_DIM * mulx +                             \\\n", "        get_local_id(1) +                                               \\\n        (get_local_id(0)%mulx) * TR_BLOCK_DIM;                          \\\n      int32_t index_out = y_index * y_elems + x_index;                  \\\n      if (x_index < y_elems && y_index < x_elems) {                     \\\n        dst_mem[odata_offset + index_out] =                             \\\n          block[get_local_id(0) * (TR_BLOCK_DIM+1) + get_local_id(1)];  \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM, TR_BLOCK_DIM, 1)                     \\\nvoid map_transpose_##NAME##_low_width(SHARED_MEM_PARAM                  \\\n                                      __global ELEM_TYPE *dst_mem,      \\\n                                      int64_t dst_offset,               \\\n                                      __global ELEM_TYPE *src_mem,      \\\n                                      int64_t src_offset,               \\\n                                      int32_t num_arrays,               \\\n                                      int32_t x_elems,                  \\\n                                      int32_t y_elems,                  \\\n                                      int32_t mulx,                     \\\n                                      int32_t muly,                     \\\n                                      int32_t repeat_1,                 \\\n  ", "                                    int32_t repeat_2) {               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t x_index = tblock_id_0 * TR_BLOCK_DIM + get_local_id(0)/muly; \\\n      int32_t y_index =                                                 \\\n        tblock_id_1 * TR_BLOCK_DIM * muly +                             \\\n        get_local_id(1) + (get_local_id(0)%muly) * TR_BLOCK_DIM;        \\\n      int32_t index_in = y_index * x_elems + x_index;                   \\\n      if (x_index < x_elems && y_index < y_elems) {                     \\\n        block[get_local_id(1) * (TR_BLOCK_DIM+1) + get_local_id(0)] =   \\\n          src_mem[idata_offset + index_in];                             \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_BLOCK_DIM * muly +                     \\\n        get_local_id(0) + (get_local_id(1)%muly) * TR_BLOCK_DIM;        \\\n      y_index = tblock_id_0 * TR_BLOCK_DIM + get_local_id(1)/muly;      \\\n      int32_t index_out = y_index * y_elems + x_index;                  \\\n ",
                                    "     if (x_index < y_elems && y_index < x_elems) {                     \\\n        dst_mem[odata_offset + index_out] =                             \\\n          block[get_local_id(0) * (TR_BLOCK_DIM+1) + get_local_id(1)];  \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_num_tblocks(2) * get_local_size(2);            \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_num_tblocks(1) * get_local_size(1);              \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*TR_BLOCK_DIM, 1, 1)                   \\\nvoid map_transpose_##NAME##_small(SHARED_MEM_PARAM                       \\\n                                  __global ELEM_TYPE *dst_mem,          \\\n                                  int64_t dst_offset,                   \\\n                                  __global ELEM_TYPE *src_mem,          \\\n                                  int64_t src_offset,                   \\\n                                  int32_t num_arrays,                   \\\n                                  int32_t x_elems,                      \\\n                                  int32_t y_elems,                      \\\n                                  int32_t mulx,                         \\\n                                  int32_t muly,                         \\\n                                  int32_t repeat_1,                     \\\n                                  int32_t repeat_2) {                   \\\n  (void)mulx; (void)muly;                                               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  ", "int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = global_id_0/(y_elems * x_elems) * y_elems * x_elems; \\\n      int32_t x_index = (global_id_0 % (y_elems * x_elems))/y_elems;    \\\n      int32_t y_index = global_id_0%y_elems;                            \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t index_in = y_index * x_elems + x_index;                   \\\n      int32_t index_out = x_index * y_elems + y_index;                  \\\n      if (global_id_0 < x_elems * y_elems * num_arrays) {               \\\n        dst_mem[odata_offset + index_out] = src_mem[idata_offset + index_in]; \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*2, TR_TILE_DIM/TR_ELEMS_", "PER_THREAD, 1)\\\nvoid map_transpose_##NAME##_large(SHARED_MEM_PARAM                      \\\n                                  __global ELEM_TYPE *dst_mem,          \\\n                                  int64_t dst_offset,                   \\\n                                  __global ELEM_TYPE *src_mem,          \\\n                                  int64_t src_offset,                   \\\n                                  int64_t num_arrays,                   \\\n                                  int64_t x_elems,                      \\\n                                  int64_t y_elems,                      \\\n                                  int64_t mulx,                         \\\n                                  int64_t muly,                         \\\n                                  int32_t repeat_1,                     \\\n                                  int32_t repeat_2) {                   \\\n  (void)mulx; (void)muly;                                               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;             \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int64_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int64_t odata_offset = dst_offset + our_array_offset;             \\\n      int64_t idata_offset = src_offset + our_array_offset;             \\\n      int64_t x_index = global_id_0;                                    \\\n      int64_t y_index = tblock_id_1 * TR_TILE_DIM + get_loc",
                                    "al_id(1);    \\\n      if (x_index < x_elems) {                                          \\\n        for (int64_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int64_t index_i = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * x_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < y_elems) { \\\n            block[(get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * (TR_TILE_DIM+1) + \\\n                  get_local_id(0)] =                                    \\\n              src_mem[idata_offset + index_i];                          \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_TILE_DIM + get_local_id(0);            \\\n      y_index = tblock_id_0 * TR_TILE_DIM + get_local_id(1);            \\\n      if (x_index < y_elems) {                                          \\\n        for (int64_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int64_t index_out = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * y_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < x_elems) { \\\n            dst_mem[(odata_offset + index_out)] =                       \\\n              block[get_local_id(0) * (TR_TILE_DIM+1) +                 \\\n                    get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)]; \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                      ", "                             \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n\nGEN_TRANSPOSE_KERNELS(1b, uint8_t)\nGEN_TRANSPOSE_KERNELS(2b, uint16_t)\nGEN_TRANSPOSE_KERNELS(4b, uint32_t)\nGEN_TRANSPOSE_KERNELS(8b, uint64_t)\n\n// End of transpose.cl\n// Start of copy.cl\n\n#define GEN_COPY_KERNEL(NAME, ELEM_TYPE) \\\nFUTHARK_KERNEL void lmad_copy_##NAME(SHARED_MEM_PARAM                   \\\n                               __global ELEM_TYPE *dst_mem,             \\\n                               int64_t dst_offset,                      \\\n                               __global ELEM_TYPE *src_mem,             \\\n                               int64_t src_offset,                      \\\n                               int64_t n,                               \\\n                               int r,                                   \\\n                               int64_t shape0, int64_t dst_stride0, int64_t src_stride0, \\\n                               int64_t shape1, int64_t dst_stride1, int64_t src_stride1, \\\n                               int64_t shape2, int64_t dst_stride2, int64_t src_stride2, \\\n                               int64_t shape3, int64_t dst_stride3, int64_t src_stride3, \\\n                               int64_t shape4, int64_t dst_stride4, int64_t src_stride4, \\\n                               int64_t shape5, int64_t dst_stride5, int64_t src_stride5, \\\n                               int64_t shape6, int64_t dst_stride6, int64_t src_stride6, \\\n                               int64_t shape7, int64_t dst_stride7, int64_t src_stride7) { \\\n  int64_t gtid = get_global_id(0);                                      \\\n  int64_t remainder = gtid;                                             \\\n                                             ", "                           \\\n  if (gtid >= n) {                                                      \\\n    return;                                                             \\\n  }                                                                     \\\n                                                                        \\\n  if (r > 0) {                                                          \\\n    int64_t i = remainder % shape0;                                     \\\n    dst_offset += i * dst_stride0;                                      \\\n    src_offset += i * src_stride0;                                      \\\n    remainder /= shape0;                                                \\\n  }                                                                     \\\n  if (r > 1) {                                                          \\\n    int64_t i = remainder % shape1;                                     \\\n    dst_offset += i * dst_stride1;                                      \\\n    src_offset += i * src_stride1;                                      \\\n    remainder /= shape1;                                                \\\n  }                                                                     \\\n  if (r > 2) {                                                          \\\n    int64_t i = remainder % shape2;                                     \\\n    dst_offset += i * dst_stride2;                                      \\\n    src_offset += i * src_stride2;                                      \\\n    remainder /= shape2;                                                \\\n  }                                                                     \\\n  if (r > 3) {                                                          \\\n    int64_t i = remainder % shape3;                                     \\\n    dst_offset += i * dst_stride3;                                      \\\n    src_offset += i * src_stride3;                                      \\\n    remainder /= shape3;                       ",
                                    "                         \\\n  }                                                                     \\\n  if (r > 4) {                                                          \\\n    int64_t i = remainder % shape4;                                     \\\n    dst_offset += i * dst_stride4;                                      \\\n    src_offset += i * src_stride4;                                      \\\n    remainder /= shape4;                                                \\\n  }                                                                     \\\n  if (r > 5) {                                                          \\\n    int64_t i = remainder % shape5;                                     \\\n    dst_offset += i * dst_stride5;                                      \\\n    src_offset += i * src_stride5;                                      \\\n    remainder /= shape5;                                                \\\n  }                                                                     \\\n  if (r > 6) {                                                          \\\n    int64_t i = remainder % shape6;                                     \\\n    dst_offset += i * dst_stride6;                                      \\\n    src_offset += i * src_stride6;                                      \\\n    remainder /= shape6;                                                \\\n  }                                                                     \\\n  if (r > 7) {                                                          \\\n    int64_t i = remainder % shape7;                                     \\\n    dst_offset += i * dst_stride7;                                      \\\n    src_offset += i * src_stride7;                                      \\\n    remainder /= shape7;                                                \\\n  }                                                                     \\\n                                                                        \\\n  dst_mem[dst_offset] = src_mem[src_offset];     ", "                       \\\n}\n\nGEN_COPY_KERNEL(1b, uint8_t)\nGEN_COPY_KERNEL(2b, uint16_t)\nGEN_COPY_KERNEL(4b, uint32_t)\nGEN_COPY_KERNEL(8b, uint64_t)\n\n// End of copy.cl\n\n\n\nFUTHARK_KERNEL\nvoid builtinzhiota_i64ziiota_i64_18656(int64_t n_18652, int64_t x_18653, int64_t s_18654, int64_t virt_num_tblocks_18661, int64_t num_tblocks_18662, __global unsigned char *mem_18651)\n{\n    int32_t iota_ltid_18657;\n    int32_t tblock_sizze_18659;\n    int32_t iota_gid_18658;\n    int32_t iota_gtid_18656;\n    int32_t phys_tblock_id_18663;\n    int32_t iterations_18664;\n    \n    iota_ltid_18657 = get_local_id(0);\n    tblock_sizze_18659 = get_local_size(0);\n    iota_gid_18658 = get_tblock_id(0);\n    iota_gtid_18656 = iota_gid_18658 * tblock_sizze_18659 + iota_ltid_18657;\n    phys_tblock_id_18663 = get_tblock_id(0);\n    iterations_18664 = sdiv_up32(sext_i64_i32(virt_num_tblocks_18661) - phys_tblock_id_18663, sext_i64_i32(num_tblocks_18662));\n    for (int32_t i_18665 = 0; i_18665 < iterations_18664; i_18665++) {\n        int32_t virt_tblock_id_18666;\n        int64_t global_tid_18667;\n        \n        virt_tblock_id_18666 = phys_tblock_id_18663 + i_18665 * sext_i64_i32(num_tblocks_18662);\n        global_tid_18667 = sext_i32_i64(virt_tblock_id_18666) * sext_i32_i64(tblock_sizze_18659) + sext_i32_i64(iota_ltid_18657);\n        if (slt64(global_tid_18667, n_18652)) {\n            ((__global int64_t *) mem_18651)[global_tid_18667] = add64(mul64(global_tid_18667, s_18654), x_18653);\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_i32zireplicate_18770(int64_t num_elems_18766, int32_t val_18767, int64_t replicate_n_18769, int64_t virt_num_tblocks_18775, int64_t num_tblocks_18776, __global unsigned char *mem_18765)\n{\n    int32_t replicate_ltid_18771;\n    int32_t tblock_sizze_18773;\n    int32_t replicate_gid_18772;\n    int32_t replicate_gtid_18770;\n    int32_t phys_tblock_id_18777;\n    int32_t iterations_18778", ";\n    \n    replicate_ltid_18771 = get_local_id(0);\n    tblock_sizze_18773 = get_local_size(0);\n    replicate_gid_18772 = get_tblock_id(0);\n    replicate_gtid_18770 = replicate_gid_18772 * tblock_sizze_18773 + replicate_ltid_18771;\n    phys_tblock_id_18777 = get_tblock_id(0);\n    iterations_18778 = sdiv_up32(sext_i64_i32(virt_num_tblocks_18775) - phys_tblock_id_18777, sext_i64_i32(num_tblocks_18776));\n    for (int32_t i_18779 = 0; i_18779 < iterations_18778; i_18779++) {\n        int32_t virt_tblock_id_18780;\n        int64_t global_tid_18781;\n        int64_t slice_18783;\n        int64_t rep_i_18782;\n        int64_t remnant_18784;\n        \n        virt_tblock_id_18780 = phys_tblock_id_18777 + i_18779 * sext_i64_i32(num_tblocks_18776);\n        global_tid_18781 = sext_i32_i64(virt_tblock_id_18780) * sext_i32_i64(tblock_sizze_18773) + sext_i32_i64(replicate_ltid_18771);\n        slice_18783 = num_elems_18766;\n        rep_i_18782 = global_tid_18781;\n        remnant_18784 = global_tid_18781 - rep_i_18782;\n        if (slt64(global_tid_18781, replicate_n_18769)) {\n            ((__global int32_t *) mem_18765)[rep_i_18782] = val_18767;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_i64zireplicate_18656(int64_t num_elems_18652, int64_t val_18653, int64_t replicate_n_18655, int64_t virt_num_tblocks_18661, int64_t num_tblocks_18662, __global unsigned char *mem_18651)\n{\n    int32_t replicate_ltid_18657;\n    int32_t tblock_sizze_18659;\n    int32_t replicate_gid_18658;\n    int32_t replicate_gtid_18656;\n    int32_t phys_tblock_id_18663;\n    int32_t iterations_18664;\n    \n    replicate_ltid_18657 = get_local_id(0);\n    tblock_sizze_18659 = get_local_size(0);\n    replicate_gid_18658 = get_tblock_id(0);\n    replicate_gtid_18656 = replicate_gid_18658 * tblock_sizze_18659 + replicate_ltid_18657;\n    phys_tblock_id_18663 = get_tblock_id(0);\n    iterations_18664 = sdiv_up32(sext_i64_i32(virt_num",
                                    "_tblocks_18661) - phys_tblock_id_18663, sext_i64_i32(num_tblocks_18662));\n    for (int32_t i_18665 = 0; i_18665 < iterations_18664; i_18665++) {\n        int32_t virt_tblock_id_18666;\n        int64_t global_tid_18667;\n        int64_t slice_18669;\n        int64_t rep_i_18668;\n        int64_t remnant_18670;\n        \n        virt_tblock_id_18666 = phys_tblock_id_18663 + i_18665 * sext_i64_i32(num_tblocks_18662);\n        global_tid_18667 = sext_i32_i64(virt_tblock_id_18666) * sext_i32_i64(tblock_sizze_18659) + sext_i32_i64(replicate_ltid_18657);\n        slice_18669 = num_elems_18652;\n        rep_i_18668 = global_tid_18667;\n        remnant_18670 = global_tid_18667 - rep_i_18668;\n        if (slt64(global_tid_18667, replicate_n_18655)) {\n            ((__global int64_t *) mem_18651)[rep_i_18668] = val_18653;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_i8zireplicate_18873(int64_t num_elems_18869, int8_t val_18870, int64_t replicate_n_18872, int64_t virt_num_tblocks_18878, int64_t num_tblocks_18879, __global unsigned char *mem_18868)\n{\n    int32_t replicate_ltid_18874;\n    int32_t tblock_sizze_18876;\n    int32_t replicate_gid_18875;\n    int32_t replicate_gtid_18873;\n    int32_t phys_tblock_id_18880;\n    int32_t iterations_18881;\n    \n    replicate_ltid_18874 = get_local_id(0);\n    tblock_sizze_18876 = get_local_size(0);\n    replicate_gid_18875 = get_tblock_id(0);\n    replicate_gtid_18873 = replicate_gid_18875 * tblock_sizze_18876 + replicate_ltid_18874;\n    phys_tblock_id_18880 = get_tblock_id(0);\n    iterations_18881 = sdiv_up32(sext_i64_i32(virt_num_tblocks_18878) - phys_tblock_id_18880, sext_i64_i32(num_tblocks_18879));\n    for (int32_t i_18882 = 0; i_18882 < iterations_18881; i_18882++) {\n        int32_t virt_tblock_id_18883;\n        int64_t global_tid_18884;\n        int64_t slice_18886;\n        int64_t rep_i_18885;\n        int64_t remnant_18887;\n        \n        virt_tblo", "ck_id_18883 = phys_tblock_id_18880 + i_18882 * sext_i64_i32(num_tblocks_18879);\n        global_tid_18884 = sext_i32_i64(virt_tblock_id_18883) * sext_i32_i64(tblock_sizze_18876) + sext_i32_i64(replicate_ltid_18874);\n        slice_18886 = num_elems_18869;\n        rep_i_18885 = global_tid_18884;\n        remnant_18887 = global_tid_18884 - rep_i_18885;\n        if (slt64(global_tid_18884, replicate_n_18872)) {\n            ((__global int8_t *) mem_18868)[rep_i_18885] = val_18870;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL_SIZED(find_cluster_ids_6783zisegmap_16348_dim1, 1, 1)\nvoid find_cluster_ids_6783zisegmap_16348(__global int *global_failure, int64_t n_12449, int64_t dim_12450, float eps_12452, int64_t inf_12480, int64_t j_m_i_12491, int64_t num_threads_18528, __global unsigned char *core_dat_mem_18419, __global unsigned char *mem_param_18427, __global unsigned char *mem_18479, __global unsigned char *mem_18490, __global unsigned char *color_18526)\n{\n    #define segmap_tblock_sizze_16344 (find_cluster_ids_6783zisegmap_16348zisegmap_tblock_sizze_16344)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18677;\n    int32_t tblock_sizze_18680;\n    int32_t wave_sizze_18679;\n    int32_t block_id_18678;\n    int32_t global_tid_18676;\n    int64_t phys_tid_16348;\n    int64_t global_tid_18681;\n    int64_t slice_18682;\n    int64_t gtid_16347;\n    int64_t remnant_18683;\n    \n    local_tid_18677 = get_local_id(0);\n    tblock_sizze_18680 = get_local_size(0);\n    wave_sizze_18679 = LOCKSTEP_WIDTH;\n    block_id_18678 = get_tblock_id(0);\n    global_tid_18676 = block_id_18678 * tblock_sizze_18680 + local_tid_18677;\n    phys_tid_16348 = sext_i32_i64(global_tid_18676);\n    global_tid_18681 = sext_i32_i64(block_id_18678) * segmap_tblock_sizze_16344 + sext_i32_i64(local_tid_18677);\n    slice_18682 = j_m_i_12491;\n    gtid_16347 = global_tid_18681;\n    remnant_18683 = global_tid_18681 - gtid_1634", "7;\n    if (slt64(gtid_16347, j_m_i_12491)) {\n        int64_t slice_18401;\n        int64_t eta_p_16349;\n        int64_t defunc_0_reduce_res_16351;\n        int64_t redout_18406;\n        \n        slice_18401 = inf_12480 + gtid_16347;\n        eta_p_16349 = ((__global int64_t *) mem_param_18427)[slice_18401];\n        redout_18406 = (int64_t) 9223372036854775807;\n        for (int64_t i_18407 = 0; i_18407 < n_12449; i_18407++) {\n            float defunc_0_f_res_16359;\n            float acc_16361;\n            float sqrt_res_16364;\n            bool zlze_res_16365;\n            int64_t lifted_lambda_res_16366;\n            int64_t min_res_16369;\n            int64_t redout_tmp_18684;\n            \n            for (int64_t i_18410 = 0; i_18410 < dim_12450; i_18410++) {\n                float eta_p_16355;\n                float eta_p_16356;\n                float zm_res_16357;\n                float zt_res_16358;\n                \n                eta_p_16355 = ((__global float *) mem_18479)[slice_18401 + i_18410 * n_12449];\n                eta_p_16356 = ((__global float *) core_dat_mem_18419)[i_18407 * dim_12450 + i_18410];\n                zm_res_16357 = eta_p_16355 - eta_p_16356;\n                zt_res_16358 = zm_res_16357 * zm_res_16357;\n                ((__global float *) color_18526)[phys_tid_16348 + i_18410 * num_threads_18528] = zt_res_16358;\n            }\n            acc_16361 = 0.0F;\n            for (int64_t i_16360 = 0; i_16360 < dim_12450; i_16360++) {\n                float b_16362;\n                float zp_res_16363;\n                float acc_tmp_18686;\n                \n                b_16362 = ((__global float *) color_18526)[phys_tid_16348 + i_16360 * num_threads_18528];\n                zp_res_16363 = acc_16361 + b_16362;\n                acc_tmp_18686 = zp_res_16363;\n                acc_16361 = acc_tmp_18686;\n            }\n            defunc_0_f_res_16359 = acc_16361;\n            sqrt_res_16364 = futrts_sqrt32(defunc_0_f_res_16359);\n            zlze_res_16365 = sqrt_res_16",
                                    "364 <= eps_12452;\n            if (zlze_res_16365) {\n                int64_t eta_p_16353 = ((__global int64_t *) mem_param_18427)[i_18407];\n                \n                lifted_lambda_res_16366 = eta_p_16353;\n            } else {\n                lifted_lambda_res_16366 = eta_p_16349;\n            }\n            min_res_16369 = smin64(lifted_lambda_res_16366, redout_18406);\n            redout_tmp_18684 = min_res_16369;\n            redout_18406 = redout_tmp_18684;\n        }\n        defunc_0_reduce_res_16351 = redout_18406;\n        ((__global int64_t *) mem_18490)[gtid_16347] = defunc_0_reduce_res_16351;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_16344\n}\nFUTHARK_KERNEL_SIZED(find_cluster_ids_6783zisegmap_16554_dim1, 1, 1)\nvoid find_cluster_ids_6783zisegmap_16554(__global int *global_failure, int64_t n_12449, int64_t dim_12450, int64_t inf_12480, int64_t j_m_i_12491, __global unsigned char *core_dat_mem_18419, __global unsigned char *mem_18432)\n{\n    #define segmap_tblock_sizze_16548 (find_cluster_ids_6783zisegmap_16554zisegmap_tblock_sizze_16548)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18707;\n    int32_t tblock_sizze_18710;\n    int32_t wave_sizze_18709;\n    int32_t block_id_18708;\n    int32_t global_tid_18706;\n    int64_t phys_tid_16554;\n    int64_t global_tid_18711;\n    int64_t slice_18712;\n    int64_t slice_18713;\n    int64_t slice_18714;\n    int64_t gtid_16551;\n    int64_t remnant_18715;\n    int64_t gtid_16552;\n    int64_t remnant_18716;\n    int64_t gtid_16553;\n    int64_t remnant_18717;\n    \n    local_tid_18707 = get_local_id(0);\n    tblock_sizze_18710 = get_local_size(0);\n    wave_sizze_18709 = LOCKSTEP_WIDTH;\n    block_id_18708 = get_tblock_id(0);\n    global_tid_18706 = block_id_18708 * tblock_sizze_18710 + local_tid_18707;\n    phys_tid_16554 = sext_i32_i64(global_tid_18706);\n    global_tid_18711 = sext_i32_i64(block_id_18708) * segmap_tblock_sizze_16548 + sext_i32_i64(local_tid_18707);\n    slice_18712 = dim_", "12450;\n    slice_18713 = n_12449 * slice_18712;\n    slice_18714 = j_m_i_12491 * slice_18713;\n    gtid_16551 = squot64(global_tid_18711, slice_18713);\n    remnant_18715 = global_tid_18711 - gtid_16551 * slice_18713;\n    gtid_16552 = squot64(remnant_18715, slice_18712);\n    remnant_18716 = remnant_18715 - gtid_16552 * slice_18712;\n    gtid_16553 = remnant_18716;\n    remnant_18717 = remnant_18716 - gtid_16553;\n    if ((slt64(gtid_16551, j_m_i_12491) && slt64(gtid_16552, n_12449)) && slt64(gtid_16553, dim_12450)) {\n        int64_t slice_18405;\n        float eta_p_16555;\n        float eta_p_16556;\n        float zm_res_16557;\n        float zt_res_16558;\n        \n        slice_18405 = inf_12480 + gtid_16551;\n        eta_p_16555 = ((__global float *) core_dat_mem_18419)[slice_18405 * dim_12450 + gtid_16553];\n        eta_p_16556 = ((__global float *) core_dat_mem_18419)[gtid_16552 * dim_12450 + gtid_16553];\n        zm_res_16557 = eta_p_16555 - eta_p_16556;\n        zt_res_16558 = zm_res_16557 * zm_res_16557;\n        ((__global float *) mem_18432)[gtid_16551 * (dim_12450 * n_12449) + gtid_16552 * dim_12450 + gtid_16553] = zt_res_16558;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_16548\n}\nFUTHARK_KERNEL_SIZED(find_cluster_ids_6783zisegmap_16567_dim1, 1, 1)\nvoid find_cluster_ids_6783zisegmap_16567(__global int *global_failure, int64_t n_12449, int64_t dim_12450, float eps_12452, int64_t inf_12480, int64_t j_m_i_12491, __global unsigned char *mem_param_18427, __global unsigned char *mem_18449, __global unsigned char *mem_18453)\n{\n    #define segmap_tblock_sizze_16562 (find_cluster_ids_6783zisegmap_16567zisegmap_tblock_sizze_16562)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18720;\n    int32_t tblock_sizze_18723;\n    int32_t wave_sizze_18722;\n    int32_t block_id_18721;\n    int32_t global_tid_18719;\n    int64_t phys_tid_16567;\n    int64_t global_tid_18724;\n    int64_t slice_18725;\n    int64_t slice_18726;\n    int64_t gtid_16565;\n   ", " int64_t remnant_18727;\n    int64_t gtid_16566;\n    int64_t remnant_18728;\n    \n    local_tid_18720 = get_local_id(0);\n    tblock_sizze_18723 = get_local_size(0);\n    wave_sizze_18722 = LOCKSTEP_WIDTH;\n    block_id_18721 = get_tblock_id(0);\n    global_tid_18719 = block_id_18721 * tblock_sizze_18723 + local_tid_18720;\n    phys_tid_16567 = sext_i32_i64(global_tid_18719);\n    global_tid_18724 = sext_i32_i64(block_id_18721) * segmap_tblock_sizze_16562 + sext_i32_i64(local_tid_18720);\n    slice_18725 = n_12449;\n    slice_18726 = j_m_i_12491 * slice_18725;\n    gtid_16565 = squot64(global_tid_18724, slice_18725);\n    remnant_18727 = global_tid_18724 - gtid_16565 * slice_18725;\n    gtid_16566 = remnant_18727;\n    remnant_18728 = remnant_18727 - gtid_16566;\n    if (slt64(gtid_16565, j_m_i_12491) && slt64(gtid_16566, n_12449)) {\n        int64_t slice_18404;\n        float defunc_0_f_res_16571;\n        float acc_16573;\n        float sqrt_res_16576;\n        bool zlze_res_16577;\n        int64_t lifted_lambda_res_16578;\n        \n        slice_18404 = inf_12480 + gtid_16565;\n        acc_16573 = 0.0F;\n        for (int64_t i_16572 = 0; i_16572 < dim_12450; i_16572++) {\n            float b_16574;\n            float zp_res_16575;\n            float acc_tmp_18729;\n            \n            b_16574 = ((__global float *) mem_18449)[gtid_16565 * n_12449 + gtid_16566 + i_16572 * (n_12449 * j_m_i_12491)];\n            zp_res_16575 = acc_16573 + b_16574;\n            acc_tmp_18729 = zp_res_16575;\n            acc_16573 = acc_tmp_18729;\n        }\n        defunc_0_f_res_16571 = acc_16573;\n        sqrt_res_16576 = futrts_sqrt32(defunc_0_f_res_16571);\n        zlze_res_16577 = sqrt_res_16576 <= eps_12452;\n        if (zlze_res_16577) {\n            int64_t eta_p_16569 = ((__global int64_t *) mem_param_18427)[gtid_16566];\n            \n            lifted_lambda_res_16578 = eta_p_16569;\n        } else {\n            int64_t eta_p_16568 = ((__global int64_t *) mem_param_18427)[slice_18404];\n            \n      ",
                                    "      lifted_lambda_res_16578 = eta_p_16568;\n        }\n        ((__global int64_t *) mem_18453)[gtid_16565 * n_12449 + gtid_16566] = lifted_lambda_res_16578;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_16562\n}\nFUTHARK_KERNEL_SIZED(find_cluster_ids_6783zisegmap_16633_dim1, 1, 1)\nvoid find_cluster_ids_6783zisegmap_16633(__global int *global_failure, int64_t n_12449, __global unsigned char *mem_18504, __global unsigned char *mem_18507)\n{\n    #define segmap_tblock_sizze_16629 (find_cluster_ids_6783zisegmap_16633zisegmap_tblock_sizze_16629)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18983;\n    int32_t tblock_sizze_18986;\n    int32_t wave_sizze_18985;\n    int32_t block_id_18984;\n    int32_t global_tid_18982;\n    int64_t phys_tid_16633;\n    int64_t global_tid_18987;\n    int64_t slice_18988;\n    int64_t gtid_16632;\n    int64_t remnant_18989;\n    \n    local_tid_18983 = get_local_id(0);\n    tblock_sizze_18986 = get_local_size(0);\n    wave_sizze_18985 = LOCKSTEP_WIDTH;\n    block_id_18984 = get_tblock_id(0);\n    global_tid_18982 = block_id_18984 * tblock_sizze_18986 + local_tid_18983;\n    phys_tid_16633 = sext_i32_i64(global_tid_18982);\n    global_tid_18987 = sext_i32_i64(block_id_18984) * segmap_tblock_sizze_16629 + sext_i32_i64(local_tid_18983);\n    slice_18988 = n_12449;\n    gtid_16632 = global_tid_18987;\n    remnant_18989 = global_tid_18987 - gtid_16632;\n    if (slt64(gtid_16632, n_12449)) {\n        int64_t zv_lhs_16635;\n        int64_t tmp_16636;\n        bool cond_16638;\n        int64_t lifted_lambda_res_16639;\n        \n        zv_lhs_16635 = add64((int64_t) -1, gtid_16632);\n        tmp_16636 = smod64(zv_lhs_16635, n_12449);\n        cond_16638 = gtid_16632 == (int64_t) 0;\n        if (cond_16638) {\n            lifted_lambda_res_16639 = (int64_t) 0;\n        } else {\n            int64_t lifted_lambda_res_16637 = ((__global int64_t *) mem_18504)[tmp_16636];\n            \n            lifted_lambda_res_16639 = lifted_lambda_res_1", "6637;\n        }\n        ((__global int64_t *) mem_18507)[gtid_16632] = lifted_lambda_res_16639;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_16629\n}\nFUTHARK_KERNEL_SIZED(find_cluster_ids_6783zisegmap_16664_dim1, 1, 1)\nvoid find_cluster_ids_6783zisegmap_16664(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t n_12449, int64_t inf_15653, int64_t min_res_15655, __global unsigned char *ext_mem_18501, __global unsigned char *mem_18507, __global unsigned char *mem_param_18512, __global unsigned char *mem_18515)\n{\n    #define segmap_tblock_sizze_16660 (find_cluster_ids_6783zisegmap_16664zisegmap_tblock_sizze_16660)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_19014;\n    int32_t tblock_sizze_19017;\n    int32_t wave_sizze_19016;\n    int32_t block_id_19015;\n    int32_t global_tid_19013;\n    int64_t phys_tid_16664;\n    int64_t global_tid_19018;\n    int64_t slice_19019;\n    int64_t gtid_16663;\n    int64_t remnant_19020;\n    \n    local_tid_19014 = get_local_id(0);\n    tblock_sizze_19017 = get_local_size(0);\n    wave_sizze_19016 = LOCKSTEP_WIDTH;\n    block_id_19015 = get_tblock_id(0);\n    global_tid_19013 = block_id_19015 * tblock_sizze_19017 + local_tid_19014;\n    phys_tid_16664 = sext_i32_i64(global_tid_19013);\n    global_tid_19018 = sext_i32_i64(block_id_19015) * segmap_tblock_sizze_16660 + sext_i32_i64(local_tid_19014);\n    slice_19019 = n_12449;\n    gtid_16663 = global_tid_19018;\n    remnant_19020 = global_tid_19018 - gtid_16663;\n    if (slt64(gtid_16663, n_12449)) {\n        int64_t eta_p_16665;\n        bool cond_16667;\n        bool cond_t_res_16668;\n        bool x_16669;\n        int64_t lifted_lambda_res_16670;\n        \n        eta_p_16665 = ((__global int64_t *) ext_mem_18501)[gtid_16663];\n        cond_16667 = sle64(inf_15653, eta_p_16665);\n        cond_t_res_16668 = slt64(eta_p_16665, min_res_15655);\n        x_16669 = cond_16667 && cond_t_res_16668;\n        if (x_16669) {\n ", "           bool x_16671;\n            bool y_16672;\n            bool bounds_check_16673;\n            bool index_certs_16674;\n            int64_t lifted_lambda_res_t_res_16675;\n            \n            x_16671 = sle64((int64_t) 0, eta_p_16665);\n            y_16672 = slt64(eta_p_16665, n_12449);\n            bounds_check_16673 = x_16671 && y_16672;\n            if (!bounds_check_16673) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 0) == -1) {\n                        global_failure_args[0] = (int64_t) eta_p_16665;\n                        global_failure_args[1] = (int64_t) n_12449;\n                        ;\n                    }\n                    return;\n                }\n            }\n            lifted_lambda_res_t_res_16675 = ((__global int64_t *) mem_18507)[eta_p_16665];\n            lifted_lambda_res_16670 = lifted_lambda_res_t_res_16675;\n        } else {\n            int64_t eta_p_16666 = ((__global int64_t *) mem_param_18512)[gtid_16663];\n            \n            lifted_lambda_res_16670 = eta_p_16666;\n        }\n        ((__global int64_t *) mem_18515)[gtid_16663] = lifted_lambda_res_16670;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_16660\n}\nFUTHARK_KERNEL\nvoid find_cluster_ids_6783zisegmap_intrablock_16377(__global int *global_failure, int64_t n_12449, int64_t dim_12450, float eps_12452, int64_t inf_12480, int64_t j_m_i_12491, int64_t ctx_18544, __global unsigned char *core_dat_mem_18419, __global unsigned char *mem_param_18427, __global unsigned char *mem_18467, __global unsigned char *color_18527)\n{\n    volatile __local unsigned char *red_arr_mem_18699_backing_0 = &shared_mem[0];\n    const int64_t red_arr_mem_18699_backing_0_offset = 0 + ((int64_t) 8 * n_12449 + srem64((int64_t) 8 - srem64((int64_t) 8 * n_12449, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18690;\n    int32_t tblock_sizze_18693;\n    int32_t wave_sizze_18692;\n    int32_t blo",
                                    "ck_id_18691;\n    int32_t global_tid_18689;\n    int64_t phys_tblock_id_16377;\n    int64_t slice_18695;\n    int64_t ltid_pre_18694;\n    int64_t remnant_18696;\n    int64_t slice_18697;\n    int64_t gtid_16376;\n    int64_t remnant_18698;\n    int64_t slice_18403;\n    int64_t eta_p_16378;\n    int64_t binop_x_18542;\n    int64_t defunc_0_reduce_res_16381;\n    int64_t phys_tid_16383;\n    __local unsigned char *red_arr_mem_18699;\n    int64_t gtid_16382;\n    int64_t ctx_18543;\n    float defunc_0_f_res_16394;\n    float acc_16396;\n    float sqrt_res_16399;\n    bool zlze_res_16400;\n    int64_t lifted_lambda_res_16401;\n    int32_t offset_18703;\n    int32_t skip_waves_18704;\n    int64_t eta_p_16384;\n    int64_t eta_p_16385;\n    \n    local_tid_18690 = get_local_id(0);\n    tblock_sizze_18693 = get_local_size(0);\n    wave_sizze_18692 = LOCKSTEP_WIDTH;\n    block_id_18691 = get_tblock_id(0);\n    global_tid_18689 = block_id_18691 * tblock_sizze_18693 + local_tid_18690;\n    phys_tblock_id_16377 = sext_i32_i64(block_id_18691);\n    slice_18695 = n_12449;\n    ltid_pre_18694 = sext_i32_i64(local_tid_18690);\n    remnant_18696 = sext_i32_i64(local_tid_18690) - ltid_pre_18694;\n    slice_18697 = j_m_i_12491;\n    gtid_16376 = sext_i32_i64(block_id_18691);\n    remnant_18698 = sext_i32_i64(block_id_18691) - gtid_16376;\n    slice_18403 = inf_12480 + gtid_16376;\n    eta_p_16378 = ((__global int64_t *) mem_param_18427)[slice_18403];\n    binop_x_18542 = n_12449 * phys_tblock_id_16377;\n    phys_tid_16383 = sext_i32_i64(local_tid_18690);\n    red_arr_mem_18699 = (__local unsigned char *) red_arr_mem_18699_backing_0;\n    gtid_16382 = sext_i32_i64(sext_i64_i32(ltid_pre_18694));\n    ctx_18543 = phys_tid_16383 + binop_x_18542;\n    for (int64_t i_18414 = 0; i_18414 < dim_12450; i_18414++) {\n        float eta_p_16390;\n        float eta_p_16391;\n        float zm_res_16392;\n        float zt_res_16393;\n        \n        eta_p_16390 = ((__global float *) core_dat_mem_18419)[slice_18403 * dim_12450 + i_18414];\n        ", "eta_p_16391 = ((__global float *) core_dat_mem_18419)[gtid_16382 * dim_12450 + i_18414];\n        zm_res_16392 = eta_p_16390 - eta_p_16391;\n        zt_res_16393 = zm_res_16392 * zm_res_16392;\n        ((__global float *) color_18527)[ctx_18543 + i_18414 * ctx_18544] = zt_res_16393;\n    }\n    acc_16396 = 0.0F;\n    for (int64_t i_16395 = 0; i_16395 < dim_12450; i_16395++) {\n        float b_16397;\n        float zp_res_16398;\n        float acc_tmp_18702;\n        \n        b_16397 = ((__global float *) color_18527)[ctx_18543 + i_16395 * ctx_18544];\n        zp_res_16398 = acc_16396 + b_16397;\n        acc_tmp_18702 = zp_res_16398;\n        acc_16396 = acc_tmp_18702;\n    }\n    defunc_0_f_res_16394 = acc_16396;\n    sqrt_res_16399 = futrts_sqrt32(defunc_0_f_res_16394);\n    zlze_res_16400 = sqrt_res_16399 <= eps_12452;\n    if (zlze_res_16400) {\n        int64_t eta_p_16388 = ((__global int64_t *) mem_param_18427)[gtid_16382];\n        \n        lifted_lambda_res_16401 = eta_p_16388;\n    } else {\n        lifted_lambda_res_16401 = eta_p_16378;\n    }\n    ((__local int64_t *) red_arr_mem_18699)[gtid_16382] = lifted_lambda_res_16401;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    skip_waves_18704 = 1;\n    offset_18703 = 0;\n    // participating threads read initial accumulator\n    {\n        if (slt32(local_tid_18690, sext_i64_i32(n_12449))) {\n            eta_p_16384 = ((__local int64_t *) red_arr_mem_18699)[sext_i32_i64(local_tid_18690 + offset_18703)];\n        }\n    }\n    offset_18703 = 1;\n    while (slt32(offset_18703, wave_sizze_18692)) {\n        if (slt32(local_tid_18690 + offset_18703, sext_i64_i32(n_12449)) && ((local_tid_18690 - squot32(local_tid_18690, wave_sizze_18692) * wave_sizze_18692) & (2 * offset_18703 - 1)) == 0) {\n            // read array element\n            {\n                eta_p_16385 = ((volatile __local int64_t *) red_arr_mem_18699)[sext_i32_i64(local_tid_18690 + offset_18703)];\n            }\n            // apply reduction operation\n            {\n                int64_t min_r", "es_16386 = smin64(eta_p_16384, eta_p_16385);\n                \n                eta_p_16384 = min_res_16386;\n            }\n            // write result of operation\n            {\n                ((volatile __local int64_t *) red_arr_mem_18699)[sext_i32_i64(local_tid_18690)] = eta_p_16384;\n            }\n        }\n        offset_18703 *= 2;\n    }\n    while (slt32(skip_waves_18704, squot32(sext_i64_i32(n_12449) + wave_sizze_18692 - 1, wave_sizze_18692))) {\n        barrier(CLK_LOCAL_MEM_FENCE);\n        offset_18703 = skip_waves_18704 * wave_sizze_18692;\n        if (slt32(local_tid_18690 + offset_18703, sext_i64_i32(n_12449)) && ((local_tid_18690 - squot32(local_tid_18690, wave_sizze_18692) * wave_sizze_18692) == 0 && (squot32(local_tid_18690, wave_sizze_18692) & (2 * skip_waves_18704 - 1)) == 0)) {\n            // read array element\n            {\n                eta_p_16385 = ((__local int64_t *) red_arr_mem_18699)[sext_i32_i64(local_tid_18690 + offset_18703)];\n            }\n            // apply reduction operation\n            {\n                int64_t min_res_16386 = smin64(eta_p_16384, eta_p_16385);\n                \n                eta_p_16384 = min_res_16386;\n            }\n            // write result of operation\n            {\n                ((__local int64_t *) red_arr_mem_18699)[sext_i32_i64(local_tid_18690)] = eta_p_16384;\n            }\n        }\n        skip_waves_18704 *= 2;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // Save result of reduction.\n    {\n        defunc_0_reduce_res_16381 = ((__local int64_t *) red_arr_mem_18699)[(int64_t) 0];\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    if (local_tid_18690 == 0) {\n        ((__global int64_t *) mem_18467)[gtid_16376] = defunc_0_reduce_res_16381;\n    }\n    \n  error_4:\n    return;\n}\nFUTHARK_KERNEL_SIZED(find_cluster_ids_6783zisegred_large_16588_dim1, 1, 1)\nvoid find_cluster_ids_6783zisegred_large_16588(__global int *global_failure, int64_t n_12449, int64_t j_m_i_12491, int64_t num_tblock",
                                    "s_16583, int64_t blocks_per_segment_18759, int64_t q_18760, int64_t num_virtblocks_18761, int64_t threads_per_segment_18762, __global unsigned char *mem_18453, __global unsigned char *mem_18456, __global unsigned char *segred_tmp_mem_18763, __global unsigned char *counters_mem_18765)\n{\n    #define segred_tblock_sizze_16582 (find_cluster_ids_6783zisegred_large_16588zisegred_tblock_sizze_16582)\n    #define chunk_sizze_18730 (find_cluster_ids_6783zisegred_large_16588zichunk_sizze_18730)\n    \n    volatile __local unsigned char *sync_arr_mem_18794_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_18794_backing_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i64_mem_18792_backing_0 = &shared_mem[sync_arr_mem_18794_backing_1_offset];\n    const int64_t red_arr_i64_mem_18792_backing_0_offset = sync_arr_mem_18794_backing_1_offset + ((int64_t) 8 * segred_tblock_sizze_16582 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_16582, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18788;\n    int32_t tblock_sizze_18791;\n    int32_t wave_sizze_18790;\n    int32_t block_id_18789;\n    int32_t global_tid_18787;\n    int64_t phys_tid_16588;\n    __local unsigned char *red_arr_i64_mem_18792;\n    __local unsigned char *sync_arr_mem_18794;\n    int32_t phys_tblock_id_18796;\n    int32_t iterations_18797;\n    \n    local_tid_18788 = get_local_id(0);\n    tblock_sizze_18791 = get_local_size(0);\n    wave_sizze_18790 = LOCKSTEP_WIDTH;\n    block_id_18789 = get_tblock_id(0);\n    global_tid_18787 = block_id_18789 * tblock_sizze_18791 + local_tid_18788;\n    phys_tid_16588 = sext_i32_i64(global_tid_18787);\n    red_arr_i64_mem_18792 = (__local unsigned char *) red_arr_i64_mem_18792_backing_0;\n    sync_arr_mem_18794 = (__local unsigned char *) sync_arr_mem_18794_backing_1;\n    phys_tblock_id_18796 = get_tblock_id(0);\n    iterations_18797 = sdiv_up32(sext_i64_i32(num_virtblocks_18761) - phys_tblock_id_18796, sext_i", "64_i32(num_tblocks_16583));\n    for (int32_t i_18798 = 0; i_18798 < iterations_18797; i_18798++) {\n        int32_t virt_tblock_id_18799;\n        int64_t flat_segment_id_18800;\n        int64_t global_tid_18801;\n        int64_t slice_18802;\n        int64_t gtid_16586;\n        int64_t remnant_18803;\n        int64_t gtid_16587;\n        int64_t eta_p_block_res_acc_18804;\n        int64_t eta_p_16589;\n        int64_t eta_p_16590;\n        int64_t tblock_id_in_segment_18808;\n        int64_t block_base_offset_18809;\n        int32_t offset_18812;\n        int32_t skip_waves_18813;\n        int64_t eta_p_18805;\n        int64_t eta_p_18806;\n        \n        virt_tblock_id_18799 = phys_tblock_id_18796 + i_18798 * sext_i64_i32(num_tblocks_16583);\n        flat_segment_id_18800 = squot64(sext_i32_i64(virt_tblock_id_18799), blocks_per_segment_18759);\n        global_tid_18801 = srem64(sext_i32_i64(virt_tblock_id_18799) * segred_tblock_sizze_16582 + sext_i32_i64(local_tid_18788), threads_per_segment_18762);\n        slice_18802 = j_m_i_12491;\n        gtid_16586 = flat_segment_id_18800;\n        remnant_18803 = flat_segment_id_18800 - gtid_16586;\n        // ne-initialise the outer (per-block) accumulator(s)\n        {\n            eta_p_block_res_acc_18804 = (int64_t) 9223372036854775807;\n        }\n        tblock_id_in_segment_18808 = squot64(global_tid_18801, segred_tblock_sizze_16582);\n        block_base_offset_18809 = tblock_id_in_segment_18808 * q_18760 * segred_tblock_sizze_16582;\n        for (int64_t i_18810 = 0; i_18810 < q_18760; i_18810++) {\n            int64_t block_offset_18811 = block_base_offset_18809 + i_18810 * segred_tblock_sizze_16582;\n            \n            gtid_16587 = global_tid_18801 + threads_per_segment_18762 * i_18810;\n            if (slt64(gtid_16587, n_12449)) {\n                // apply map function(s)\n                {\n                    // apply map function\n                    {\n                        int64_t x_16593 = ((__global int64_t *) mem_18453)[gtid_165", "86 * n_12449 + gtid_16587];\n                        \n                        // load accumulator(s)\n                        {\n                            eta_p_16589 = eta_p_block_res_acc_18804;\n                        }\n                        // load next value(s)\n                        {\n                            eta_p_16590 = x_16593;\n                        }\n                        // apply reduction operator(s)\n                        {\n                            int64_t min_res_16591 = smin64(eta_p_16589, eta_p_16590);\n                            \n                            // store in accumulator(s)\n                            {\n                                eta_p_block_res_acc_18804 = min_res_16591;\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // store accs. prims go in lmem; non-prims in params (in global mem)\n        {\n            ((__local int64_t *) red_arr_i64_mem_18792)[sext_i32_i64(local_tid_18788)] = eta_p_block_res_acc_18804;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        skip_waves_18813 = 1;\n        offset_18812 = 0;\n        // participating threads read initial accumulator\n        {\n            if (slt32(local_tid_18788, sext_i64_i32(segred_tblock_sizze_16582))) {\n                eta_p_18805 = ((__local int64_t *) red_arr_i64_mem_18792)[sext_i32_i64(local_tid_18788 + offset_18812)];\n            }\n        }\n        offset_18812 = 1;\n        while (slt32(offset_18812, wave_sizze_18790)) {\n            if (slt32(local_tid_18788 + offset_18812, sext_i64_i32(segred_tblock_sizze_16582)) && ((local_tid_18788 - squot32(local_tid_18788, wave_sizze_18790) * wave_sizze_18790) & (2 * offset_18812 - 1)) == 0) {\n                // read array element\n                {\n                    eta_p_18806 = ((volatile __local int64_t *) red_arr_i64_mem_18792)[sext_i32_i64(local_tid_18788 + offset_18812)];\n                }\n        ",
                                    "        // apply reduction operation\n                {\n                    int64_t min_res_18807 = smin64(eta_p_18805, eta_p_18806);\n                    \n                    eta_p_18805 = min_res_18807;\n                }\n                // write result of operation\n                {\n                    ((volatile __local int64_t *) red_arr_i64_mem_18792)[sext_i32_i64(local_tid_18788)] = eta_p_18805;\n                }\n            }\n            offset_18812 *= 2;\n        }\n        while (slt32(skip_waves_18813, squot32(sext_i64_i32(segred_tblock_sizze_16582) + wave_sizze_18790 - 1, wave_sizze_18790))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_18812 = skip_waves_18813 * wave_sizze_18790;\n            if (slt32(local_tid_18788 + offset_18812, sext_i64_i32(segred_tblock_sizze_16582)) && ((local_tid_18788 - squot32(local_tid_18788, wave_sizze_18790) * wave_sizze_18790) == 0 && (squot32(local_tid_18788, wave_sizze_18790) & (2 * skip_waves_18813 - 1)) == 0)) {\n                // read array element\n                {\n                    eta_p_18806 = ((__local int64_t *) red_arr_i64_mem_18792)[sext_i32_i64(local_tid_18788 + offset_18812)];\n                }\n                // apply reduction operation\n                {\n                    int64_t min_res_18807 = smin64(eta_p_18805, eta_p_18806);\n                    \n                    eta_p_18805 = min_res_18807;\n                }\n                // write result of operation\n                {\n                    ((__local int64_t *) red_arr_i64_mem_18792)[sext_i32_i64(local_tid_18788)] = eta_p_18805;\n                }\n            }\n            skip_waves_18813 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // thread 0 updates per-block acc(s); rest reset to ne\n        {\n            if (sext_i32_i64(local_tid_18788) == (int64_t) 0) {\n                eta_p_block_res_acc_18804 = eta_p_18805;\n            } else {\n                eta_p_block_res_acc_18804 = ", "(int64_t) 9223372036854775807;\n            }\n        }\n        if (blocks_per_segment_18759 == (int64_t) 1) {\n            // first thread in block saves final result to memory\n            {\n                if (local_tid_18788 == 0) {\n                    ((__global int64_t *) mem_18456)[gtid_16586] = eta_p_block_res_acc_18804;\n                }\n            }\n        } else {\n            int32_t old_counter_18814;\n            bool is_last_block_18815;\n            \n            // first thread in block saves block result to global memory\n            {\n                if (local_tid_18788 == 0) {\n                    ((__global int64_t *) segred_tmp_mem_18763)[sext_i32_i64(virt_tblock_id_18799)] = eta_p_block_res_acc_18804;\n                    mem_fence_global();\n                    old_counter_18814 = atomic_add_i32_global(&((volatile __global int *) counters_mem_18765)[srem64(flat_segment_id_18800, (int64_t) 20480)], (int) 1);\n                    ((__local bool *) sync_arr_mem_18794)[(int64_t) 0] = old_counter_18814 == sext_i64_i32(blocks_per_segment_18759 - (int64_t) 1);\n                }\n            }\n            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n            is_last_block_18815 = ((__local bool *) sync_arr_mem_18794)[(int64_t) 0];\n            if (is_last_block_18815) {\n                if (local_tid_18788 == 0) {\n                    old_counter_18814 = atomic_add_i32_global(&((volatile __global int *) counters_mem_18765)[srem64(flat_segment_id_18800, (int64_t) 20480)], (int) sext_i64_i32((int64_t) 0 - blocks_per_segment_18759));\n                }\n                // read in the per-block-results\n                {\n                    int64_t read_per_thread_18816 = sdiv_up64(blocks_per_segment_18759, segred_tblock_sizze_16582);\n                    \n                    eta_p_16589 = (int64_t) 9223372036854775807;\n                    for (int64_t i_18817 = 0; i_18817 < read_per_thread_18816; i_18817++) {\n                        int64_t block_res_id_18818 ", "= sext_i32_i64(local_tid_18788) * read_per_thread_18816 + i_18817;\n                        int64_t index_of_block_res_18819 = flat_segment_id_18800 * blocks_per_segment_18759 + block_res_id_18818;\n                        \n                        if (slt64(block_res_id_18818, blocks_per_segment_18759)) {\n                            eta_p_16590 = ((__global int64_t *) segred_tmp_mem_18763)[index_of_block_res_18819];\n                            \n                            int64_t min_res_16591 = smin64(eta_p_16589, eta_p_16590);\n                            \n                            eta_p_16589 = min_res_16591;\n                        }\n                    }\n                }\n                ((__local int64_t *) red_arr_i64_mem_18792)[sext_i32_i64(local_tid_18788)] = eta_p_16589;\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // reduce the per-block results\n                {\n                    int32_t offset_18820;\n                    int32_t skip_waves_18821 = 1;\n                    int64_t eta_p_18805;\n                    int64_t eta_p_18806;\n                    \n                    offset_18820 = 0;\n                    // participating threads read initial accumulator\n                    {\n                        if (slt32(local_tid_18788, sext_i64_i32(segred_tblock_sizze_16582))) {\n                            eta_p_18805 = ((__local int64_t *) red_arr_i64_mem_18792)[sext_i32_i64(local_tid_18788 + offset_18820)];\n                        }\n                    }\n                    offset_18820 = 1;\n                    while (slt32(offset_18820, wave_sizze_18790)) {\n                        if (slt32(local_tid_18788 + offset_18820, sext_i64_i32(segred_tblock_sizze_16582)) && ((local_tid_18788 - squot32(local_tid_18788, wave_sizze_18790) * wave_sizze_18790) & (2 * offset_18820 - 1)) == 0) {\n                            // read array element\n                            {\n                                eta_p_18806 = ((volatile __local int64_t *) red_arr",
                                    "_i64_mem_18792)[sext_i32_i64(local_tid_18788 + offset_18820)];\n                            }\n                            // apply reduction operation\n                            {\n                                int64_t min_res_18807 = smin64(eta_p_18805, eta_p_18806);\n                                \n                                eta_p_18805 = min_res_18807;\n                            }\n                            // write result of operation\n                            {\n                                ((volatile __local int64_t *) red_arr_i64_mem_18792)[sext_i32_i64(local_tid_18788)] = eta_p_18805;\n                            }\n                        }\n                        offset_18820 *= 2;\n                    }\n                    while (slt32(skip_waves_18821, squot32(sext_i64_i32(segred_tblock_sizze_16582) + wave_sizze_18790 - 1, wave_sizze_18790))) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                        offset_18820 = skip_waves_18821 * wave_sizze_18790;\n                        if (slt32(local_tid_18788 + offset_18820, sext_i64_i32(segred_tblock_sizze_16582)) && ((local_tid_18788 - squot32(local_tid_18788, wave_sizze_18790) * wave_sizze_18790) == 0 && (squot32(local_tid_18788, wave_sizze_18790) & (2 * skip_waves_18821 - 1)) == 0)) {\n                            // read array element\n                            {\n                                eta_p_18806 = ((__local int64_t *) red_arr_i64_mem_18792)[sext_i32_i64(local_tid_18788 + offset_18820)];\n                            }\n                            // apply reduction operation\n                            {\n                                int64_t min_res_18807 = smin64(eta_p_18805, eta_p_18806);\n                                \n                                eta_p_18805 = min_res_18807;\n                            }\n                            // write result of operation\n                            {\n                                ((__local int64_t *) red_arr_i64_mem_1879", "2)[sext_i32_i64(local_tid_18788)] = eta_p_18805;\n                            }\n                        }\n                        skip_waves_18821 *= 2;\n                    }\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                    // and back to memory with the final result\n                    {\n                        if (local_tid_18788 == 0) {\n                            ((__global int64_t *) mem_18456)[gtid_16586] = eta_p_18805;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_6:\n    return;\n    #undef segred_tblock_sizze_16582\n    #undef chunk_sizze_18730\n}\nFUTHARK_KERNEL_SIZED(find_cluster_ids_6783zisegred_nonseg_16605_dim1, 1, 1)\nvoid find_cluster_ids_6783zisegred_nonseg_16605(__global int *global_failure, int64_t n_12449, int64_t num_tblocks_16600, int64_t num_threads_18829, __global unsigned char *mem_param_18424, __global unsigned char *ext_mem_18496, __global unsigned char *mem_18498, __global unsigned char *counters_mem_18825, __global unsigned char *segred_tmp_mem_18827)\n{\n    #define segred_tblock_sizze_16598 (find_cluster_ids_6783zisegred_nonseg_16605zisegred_tblock_sizze_16598)\n    #define chunk_sizze_18824 (find_cluster_ids_6783zisegred_nonseg_16605zichunk_sizze_18824)\n    \n    volatile __local unsigned char *sync_arr_mem_18837_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_18837_backing_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_bool_mem_18835_backing_0 = &shared_mem[sync_arr_mem_18837_backing_1_offset];\n    const int64_t red_arr_bool_mem_18835_backing_0_offset = sync_arr_mem_18837_backing_1_offset + (segred_tblock_sizze_16598 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_16598, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18831;\n    int32_t tblock_sizze_18834;\n    int32_t wave_sizze_18833;\n    int32_t block_id_18832;\n   ", " int32_t global_tid_18830;\n    int64_t phys_tid_16605;\n    __local unsigned char *red_arr_bool_mem_18835;\n    __local unsigned char *sync_arr_mem_18837;\n    int64_t dummy_16603;\n    int64_t gtid_16604;\n    int64_t q_18839;\n    bool eta_p_block_res_acc_18840;\n    bool eta_p_15586;\n    bool eta_p_15587;\n    int64_t tblock_id_in_segment_18844;\n    int64_t block_base_offset_18845;\n    int32_t offset_18848;\n    int32_t skip_waves_18849;\n    bool eta_p_18841;\n    bool eta_p_18842;\n    int32_t old_counter_18850;\n    bool is_last_block_18851;\n    \n    local_tid_18831 = get_local_id(0);\n    tblock_sizze_18834 = get_local_size(0);\n    wave_sizze_18833 = LOCKSTEP_WIDTH;\n    block_id_18832 = get_tblock_id(0);\n    global_tid_18830 = block_id_18832 * tblock_sizze_18834 + local_tid_18831;\n    phys_tid_16605 = sext_i32_i64(global_tid_18830);\n    red_arr_bool_mem_18835 = (__local unsigned char *) red_arr_bool_mem_18835_backing_0;\n    sync_arr_mem_18837 = (__local unsigned char *) sync_arr_mem_18837_backing_1;\n    dummy_16603 = (int64_t) 0;\n    gtid_16604 = (int64_t) 0;\n    q_18839 = sdiv_up64(n_12449, sext_i32_i64(sext_i64_i32(segred_tblock_sizze_16598 * num_tblocks_16600)) * chunk_sizze_18824);\n    // ne-initialise the outer (per-block) accumulator(s)\n    {\n        eta_p_block_res_acc_18840 = 1;\n    }\n    tblock_id_in_segment_18844 = squot64(phys_tid_16605, segred_tblock_sizze_16598);\n    block_base_offset_18845 = tblock_id_in_segment_18844 * q_18839 * segred_tblock_sizze_16598;\n    for (int64_t i_18846 = 0; i_18846 < q_18839; i_18846++) {\n        int64_t block_offset_18847 = block_base_offset_18845 + i_18846 * segred_tblock_sizze_16598;\n        \n        gtid_16604 = phys_tid_16605 + num_threads_18829 * i_18846;\n        if (slt64(gtid_16604, n_12449)) {\n            // apply map function(s)\n            {\n                // apply map function\n                {\n                    int64_t eta_p_16098 = ((__global int64_t *) mem_param_18424)[gtid_16604];\n                    int64_t eta",
                                    "_p_16099 = ((__global int64_t *) ext_mem_18496)[gtid_16604];\n                    bool defunc_0_f_res_16100 = eta_p_16098 == eta_p_16099;\n                    \n                    // load accumulator(s)\n                    {\n                        eta_p_15586 = eta_p_block_res_acc_18840;\n                    }\n                    // load next value(s)\n                    {\n                        eta_p_15587 = defunc_0_f_res_16100;\n                    }\n                    // apply reduction operator(s)\n                    {\n                        bool x_15588 = eta_p_15586 && eta_p_15587;\n                        \n                        // store in accumulator(s)\n                        {\n                            eta_p_block_res_acc_18840 = x_15588;\n                        }\n                    }\n                }\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // store accs. prims go in lmem; non-prims in params (in global mem)\n    {\n        ((__local bool *) red_arr_bool_mem_18835)[sext_i32_i64(local_tid_18831)] = eta_p_block_res_acc_18840;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    skip_waves_18849 = 1;\n    offset_18848 = 0;\n    // participating threads read initial accumulator\n    {\n        if (slt32(local_tid_18831, sext_i64_i32(segred_tblock_sizze_16598))) {\n            eta_p_18841 = ((__local bool *) red_arr_bool_mem_18835)[sext_i32_i64(local_tid_18831 + offset_18848)];\n        }\n    }\n    offset_18848 = 1;\n    while (slt32(offset_18848, wave_sizze_18833)) {\n        if (slt32(local_tid_18831 + offset_18848, sext_i64_i32(segred_tblock_sizze_16598)) && ((local_tid_18831 - squot32(local_tid_18831, wave_sizze_18833) * wave_sizze_18833) & (2 * offset_18848 - 1)) == 0) {\n            // read array element\n            {\n                eta_p_18842 = ((volatile __local bool *) red_arr_bool_mem_18835)[sext_i32_i64(local_tid_18831 + offset_18848)];\n            }\n            // apply reduction operation\n            {\n                bool x_18843 =", " eta_p_18841 && eta_p_18842;\n                \n                eta_p_18841 = x_18843;\n            }\n            // write result of operation\n            {\n                ((volatile __local bool *) red_arr_bool_mem_18835)[sext_i32_i64(local_tid_18831)] = eta_p_18841;\n            }\n        }\n        offset_18848 *= 2;\n    }\n    while (slt32(skip_waves_18849, squot32(sext_i64_i32(segred_tblock_sizze_16598) + wave_sizze_18833 - 1, wave_sizze_18833))) {\n        barrier(CLK_LOCAL_MEM_FENCE);\n        offset_18848 = skip_waves_18849 * wave_sizze_18833;\n        if (slt32(local_tid_18831 + offset_18848, sext_i64_i32(segred_tblock_sizze_16598)) && ((local_tid_18831 - squot32(local_tid_18831, wave_sizze_18833) * wave_sizze_18833) == 0 && (squot32(local_tid_18831, wave_sizze_18833) & (2 * skip_waves_18849 - 1)) == 0)) {\n            // read array element\n            {\n                eta_p_18842 = ((__local bool *) red_arr_bool_mem_18835)[sext_i32_i64(local_tid_18831 + offset_18848)];\n            }\n            // apply reduction operation\n            {\n                bool x_18843 = eta_p_18841 && eta_p_18842;\n                \n                eta_p_18841 = x_18843;\n            }\n            // write result of operation\n            {\n                ((__local bool *) red_arr_bool_mem_18835)[sext_i32_i64(local_tid_18831)] = eta_p_18841;\n            }\n        }\n        skip_waves_18849 *= 2;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // thread 0 updates per-block acc(s); rest reset to ne\n    {\n        if (sext_i32_i64(local_tid_18831) == (int64_t) 0) {\n            eta_p_block_res_acc_18840 = eta_p_18841;\n        } else {\n            eta_p_block_res_acc_18840 = 1;\n        }\n    }\n    // first thread in block saves block result to global memory\n    {\n        if (local_tid_18831 == 0) {\n            ((__global bool *) segred_tmp_mem_18827)[sext_i32_i64(block_id_18832)] = eta_p_block_res_acc_18840;\n            mem_fence_global();\n            old_counter", "_18850 = atomic_add_i32_global(&((volatile __global int *) counters_mem_18825)[(int64_t) 0], (int) 1);\n            ((__local bool *) sync_arr_mem_18837)[(int64_t) 0] = old_counter_18850 == sext_i64_i32(num_tblocks_16600 - (int64_t) 1);\n        }\n    }\n    barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    is_last_block_18851 = ((__local bool *) sync_arr_mem_18837)[(int64_t) 0];\n    if (is_last_block_18851) {\n        if (local_tid_18831 == 0) {\n            old_counter_18850 = atomic_add_i32_global(&((volatile __global int *) counters_mem_18825)[(int64_t) 0], (int) sext_i64_i32((int64_t) 0 - num_tblocks_16600));\n        }\n        // read in the per-block-results\n        {\n            int64_t read_per_thread_18852 = sdiv_up64(num_tblocks_16600, segred_tblock_sizze_16598);\n            \n            eta_p_15586 = 1;\n            for (int64_t i_18853 = 0; i_18853 < read_per_thread_18852; i_18853++) {\n                int64_t block_res_id_18854 = sext_i32_i64(local_tid_18831) * read_per_thread_18852 + i_18853;\n                int64_t index_of_block_res_18855 = block_res_id_18854;\n                \n                if (slt64(block_res_id_18854, num_tblocks_16600)) {\n                    eta_p_15587 = ((__global bool *) segred_tmp_mem_18827)[index_of_block_res_18855];\n                    \n                    bool x_15588 = eta_p_15586 && eta_p_15587;\n                    \n                    eta_p_15586 = x_15588;\n                }\n            }\n        }\n        ((__local bool *) red_arr_bool_mem_18835)[sext_i32_i64(local_tid_18831)] = eta_p_15586;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // reduce the per-block results\n        {\n            int32_t offset_18856;\n            int32_t skip_waves_18857 = 1;\n            bool eta_p_18841;\n            bool eta_p_18842;\n            \n            offset_18856 = 0;\n            // participating threads read initial accumulator\n            {\n                if (slt32(local_tid_18831, sext_i64_i32(segred_tblock_sizze_16598))) {\n    ",
                                    "                eta_p_18841 = ((__local bool *) red_arr_bool_mem_18835)[sext_i32_i64(local_tid_18831 + offset_18856)];\n                }\n            }\n            offset_18856 = 1;\n            while (slt32(offset_18856, wave_sizze_18833)) {\n                if (slt32(local_tid_18831 + offset_18856, sext_i64_i32(segred_tblock_sizze_16598)) && ((local_tid_18831 - squot32(local_tid_18831, wave_sizze_18833) * wave_sizze_18833) & (2 * offset_18856 - 1)) == 0) {\n                    // read array element\n                    {\n                        eta_p_18842 = ((volatile __local bool *) red_arr_bool_mem_18835)[sext_i32_i64(local_tid_18831 + offset_18856)];\n                    }\n                    // apply reduction operation\n                    {\n                        bool x_18843 = eta_p_18841 && eta_p_18842;\n                        \n                        eta_p_18841 = x_18843;\n                    }\n                    // write result of operation\n                    {\n                        ((volatile __local bool *) red_arr_bool_mem_18835)[sext_i32_i64(local_tid_18831)] = eta_p_18841;\n                    }\n                }\n                offset_18856 *= 2;\n            }\n            while (slt32(skip_waves_18857, squot32(sext_i64_i32(segred_tblock_sizze_16598) + wave_sizze_18833 - 1, wave_sizze_18833))) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                offset_18856 = skip_waves_18857 * wave_sizze_18833;\n                if (slt32(local_tid_18831 + offset_18856, sext_i64_i32(segred_tblock_sizze_16598)) && ((local_tid_18831 - squot32(local_tid_18831, wave_sizze_18833) * wave_sizze_18833) == 0 && (squot32(local_tid_18831, wave_sizze_18833) & (2 * skip_waves_18857 - 1)) == 0)) {\n                    // read array element\n                    {\n                        eta_p_18842 = ((__local bool *) red_arr_bool_mem_18835)[sext_i32_i64(local_tid_18831 + offset_18856)];\n                    }\n                    // apply reduction operation\n                ", "    {\n                        bool x_18843 = eta_p_18841 && eta_p_18842;\n                        \n                        eta_p_18841 = x_18843;\n                    }\n                    // write result of operation\n                    {\n                        ((__local bool *) red_arr_bool_mem_18835)[sext_i32_i64(local_tid_18831)] = eta_p_18841;\n                    }\n                }\n                skip_waves_18857 *= 2;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // and back to memory with the final result\n            {\n                if (local_tid_18831 == 0) {\n                    ((__global bool *) mem_18498)[(int64_t) 0] = eta_p_18841;\n                }\n            }\n        }\n    }\n    \n  error_5:\n    return;\n    #undef segred_tblock_sizze_16598\n    #undef chunk_sizze_18824\n}\nFUTHARK_KERNEL_SIZED(find_cluster_ids_6783zisegred_small_16588_dim1, 1, 1)\nvoid find_cluster_ids_6783zisegred_small_16588(__global int *global_failure, int64_t n_12449, int64_t j_m_i_12491, int64_t num_tblocks_16583, int64_t segment_sizze_nonzzero_18731, __global unsigned char *mem_18453, __global unsigned char *mem_18456)\n{\n    #define segred_tblock_sizze_16582 (find_cluster_ids_6783zisegred_small_16588zisegred_tblock_sizze_16582)\n    \n    volatile __local unsigned char *red_arr_i64_mem_18738_backing_0 = &shared_mem[0];\n    const int64_t red_arr_i64_mem_18738_backing_0_offset = 0 + ((int64_t) 8 * segred_tblock_sizze_16582 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_16582, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18734;\n    int32_t tblock_sizze_18737;\n    int32_t wave_sizze_18736;\n    int32_t block_id_18735;\n    int32_t global_tid_18733;\n    int64_t phys_tid_16588;\n    __local unsigned char *red_arr_i64_mem_18738;\n    int32_t phys_tblock_id_18740;\n    int32_t iterations_18741;\n    \n    local_tid_18734 = get_local_id(0);\n    tblock_sizze_18737 = get_local_size(0);\n    wave_sizz", "e_18736 = LOCKSTEP_WIDTH;\n    block_id_18735 = get_tblock_id(0);\n    global_tid_18733 = block_id_18735 * tblock_sizze_18737 + local_tid_18734;\n    phys_tid_16588 = sext_i32_i64(global_tid_18733);\n    red_arr_i64_mem_18738 = (__local unsigned char *) red_arr_i64_mem_18738_backing_0;\n    phys_tblock_id_18740 = get_tblock_id(0);\n    iterations_18741 = sdiv_up32(sext_i64_i32(sdiv_up64(j_m_i_12491, squot64(segred_tblock_sizze_16582, segment_sizze_nonzzero_18731))) - phys_tblock_id_18740, sext_i64_i32(num_tblocks_16583));\n    for (int32_t i_18742 = 0; i_18742 < iterations_18741; i_18742++) {\n        int32_t virt_tblock_id_18743;\n        int64_t slice_18744;\n        int64_t gtid_16586;\n        int64_t remnant_18745;\n        int64_t gtid_16587;\n        \n        virt_tblock_id_18743 = phys_tblock_id_18740 + i_18742 * sext_i64_i32(num_tblocks_16583);\n        slice_18744 = j_m_i_12491;\n        gtid_16586 = squot64(sext_i32_i64(local_tid_18734), segment_sizze_nonzzero_18731) + sext_i32_i64(virt_tblock_id_18743) * squot64(segred_tblock_sizze_16582, segment_sizze_nonzzero_18731);\n        remnant_18745 = squot64(sext_i32_i64(local_tid_18734), segment_sizze_nonzzero_18731) + sext_i32_i64(virt_tblock_id_18743) * squot64(segred_tblock_sizze_16582, segment_sizze_nonzzero_18731) - gtid_16586;\n        gtid_16587 = srem64(sext_i32_i64(local_tid_18734), n_12449);\n        // apply map function if in bounds\n        {\n            if (slt64((int64_t) 0, n_12449) && (slt64(gtid_16586, j_m_i_12491) && slt64(sext_i32_i64(local_tid_18734), n_12449 * squot64(segred_tblock_sizze_16582, segment_sizze_nonzzero_18731)))) {\n                // apply map function\n                {\n                    int64_t x_16593 = ((__global int64_t *) mem_18453)[gtid_16586 * n_12449 + gtid_16587];\n                    \n                    // save results to be reduced\n                    {\n                        ((__local int64_t *) red_arr_i64_mem_18738)[sext_i32_i64(local_tid_18734)] = x_16593;\n                   ",
                                    " }\n                }\n            } else {\n                ((__local int64_t *) red_arr_i64_mem_18738)[sext_i32_i64(local_tid_18734)] = (int64_t) 9223372036854775807;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (slt64((int64_t) 0, n_12449)) {\n            // perform segmented scan to imitate reduction\n            {\n                int64_t eta_p_16589;\n                int64_t eta_p_16590;\n                int64_t eta_p_18746;\n                int64_t eta_p_18747;\n                bool ltid_in_bounds_18749 = slt64(sext_i32_i64(local_tid_18734), n_12449 * squot64(segred_tblock_sizze_16582, segment_sizze_nonzzero_18731));\n                int32_t skip_threads_18750;\n                \n                // read input for in-block scan\n                {\n                    if (ltid_in_bounds_18749) {\n                        eta_p_16590 = ((volatile __local int64_t *) red_arr_i64_mem_18738)[sext_i32_i64(local_tid_18734)];\n                        if ((local_tid_18734 - squot32(local_tid_18734, 32) * 32) == 0) {\n                            eta_p_16589 = eta_p_16590;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_18750 = 1;\n                    while (slt32(skip_threads_18750, 32)) {\n                        bool thread_active_18751 = sle32(skip_threads_18750, local_tid_18734 - squot32(local_tid_18734, 32) * 32) && ltid_in_bounds_18749;\n                        \n                        if (thread_active_18751) {\n                            // read operands\n                            {\n                                eta_p_16589 = ((volatile __local int64_t *) red_arr_i64_mem_18738)[sext_i32_i64(local_tid_18734) - sext_i32_i64(skip_threads_18750)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            bool inactive_18752 = slt64(", "srem64(sext_i32_i64(local_tid_18734), n_12449), sext_i32_i64(local_tid_18734) - sext_i32_i64(local_tid_18734 - skip_threads_18750));\n                            \n                            if (thread_active_18751 && inactive_18752) {\n                                eta_p_16589 = eta_p_16590;\n                            }\n                            if (thread_active_18751) {\n                                if (!inactive_18752) {\n                                    int64_t min_res_16591 = smin64(eta_p_16589, eta_p_16590);\n                                    \n                                    eta_p_16589 = min_res_16591;\n                                }\n                            }\n                        }\n                        if (sle32(wave_sizze_18736, skip_threads_18750)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_18751) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) red_arr_i64_mem_18738)[sext_i32_i64(local_tid_18734)] = eta_p_16589;\n                                eta_p_16590 = eta_p_16589;\n                            }\n                        }\n                        if (sle32(wave_sizze_18736, skip_threads_18750)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_18750 *= 2;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // last thread of block 'i' writes its result to offset 'i'\n                {\n                    if ((local_tid_18734 - squot32(local_tid_18734, 32) * 32) == 31 && ltid_in_bounds_18749) {\n                        ((volatile __local int64_t *) red_arr_i64_mem_18738)[sext_i32_i64(squot32(local_tid_18734, 32))] = eta_p_16589;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // scan the f", "irst block, after which offset 'i' contains carry-in for block 'i+1'\n                {\n                    int32_t skip_threads_18753;\n                    \n                    // read input for in-block scan\n                    {\n                        if (squot32(local_tid_18734, 32) == 0 && ltid_in_bounds_18749) {\n                            eta_p_18747 = ((volatile __local int64_t *) red_arr_i64_mem_18738)[sext_i32_i64(local_tid_18734)];\n                            if ((local_tid_18734 - squot32(local_tid_18734, 32) * 32) == 0) {\n                                eta_p_18746 = eta_p_18747;\n                            }\n                        }\n                    }\n                    // in-block scan (hopefully no barriers needed)\n                    {\n                        skip_threads_18753 = 1;\n                        while (slt32(skip_threads_18753, 32)) {\n                            bool thread_active_18754 = sle32(skip_threads_18753, local_tid_18734 - squot32(local_tid_18734, 32) * 32) && (squot32(local_tid_18734, 32) == 0 && ltid_in_bounds_18749);\n                            \n                            if (thread_active_18754) {\n                                // read operands\n                                {\n                                    eta_p_18746 = ((volatile __local int64_t *) red_arr_i64_mem_18738)[sext_i32_i64(local_tid_18734) - sext_i32_i64(skip_threads_18753)];\n                                }\n                            }\n                            // perform operation\n                            {\n                                bool inactive_18755 = slt64(srem64(sext_i32_i64(local_tid_18734 * 32 + 32 - 1), n_12449), sext_i32_i64(local_tid_18734 * 32 + 32 - 1) - sext_i32_i64((local_tid_18734 - skip_threads_18753) * 32 + 32 - 1));\n                                \n                                if (thread_active_18754 && inactive_18755) {\n                                    eta_p_18746 = eta_p_18747;\n                                }",
                                    "\n                                if (thread_active_18754) {\n                                    if (!inactive_18755) {\n                                        int64_t min_res_18748 = smin64(eta_p_18746, eta_p_18747);\n                                        \n                                        eta_p_18746 = min_res_18748;\n                                    }\n                                }\n                            }\n                            if (sle32(wave_sizze_18736, skip_threads_18753)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            if (thread_active_18754) {\n                                // write result\n                                {\n                                    ((volatile __local int64_t *) red_arr_i64_mem_18738)[sext_i32_i64(local_tid_18734)] = eta_p_18746;\n                                    eta_p_18747 = eta_p_18746;\n                                }\n                            }\n                            if (sle32(wave_sizze_18736, skip_threads_18753)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            skip_threads_18753 *= 2;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                \n                bool no_carry_in_18756 = squot32(local_tid_18734, 32) == 0 || !ltid_in_bounds_18749;\n                \n                // carry-in for every block except the first\n                {\n                    // read operands\n                    {\n                        if (!no_carry_in_18756) {\n                            eta_p_16590 = eta_p_16589;\n                            eta_p_16589 = ((__local int64_t *) red_arr_i64_mem_18738)[sext_i32_i64(squot32(local_tid_18734, 32)) - (int64_t) 1];\n                        }\n                    }\n                    // perform operation\n                    {\n                        bool in", "active_18757 = slt64(srem64(sext_i32_i64(local_tid_18734), n_12449), sext_i32_i64(local_tid_18734) - sext_i32_i64(squot32(local_tid_18734, 32) * 32 - 1));\n                        \n                        if (!no_carry_in_18756) {\n                            if (inactive_18757) {\n                                eta_p_16589 = eta_p_16590;\n                            }\n                        }\n                        if (!no_carry_in_18756) {\n                            if (!inactive_18757) {\n                                int64_t min_res_16591 = smin64(eta_p_16589, eta_p_16590);\n                                \n                                eta_p_16589 = min_res_16591;\n                            }\n                        }\n                    }\n                    // write final result\n                    {\n                        if (!no_carry_in_18756) {\n                            ((__local int64_t *) red_arr_i64_mem_18738)[sext_i32_i64(local_tid_18734)] = eta_p_16589;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // restore correct values for first block\n                {\n                    if (squot32(local_tid_18734, 32) == 0 && ltid_in_bounds_18749) {\n                        ((__local int64_t *) red_arr_i64_mem_18738)[sext_i32_i64(local_tid_18734)] = eta_p_16590;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // save final values of segments\n        {\n            if (slt64(sext_i32_i64(virt_tblock_id_18743) * squot64(segred_tblock_sizze_16582, segment_sizze_nonzzero_18731) + sext_i32_i64(local_tid_18734), j_m_i_12491) && slt64(sext_i32_i64(local_tid_18734), squot64(segred_tblock_sizze_16582, segment_sizze_nonzzero_18731))) {\n                int64_t tmp_18758 = ((__local int64_t *) red_arr_i64_mem_18738)[(sext_i32_i64(local_tid_18734) + (int64_t) 1) * segment_sizze_non", "zzero_18731 - (int64_t) 1];\n                \n                ((__global int64_t *) mem_18456)[sext_i32_i64(virt_tblock_id_18743) * squot64(segred_tblock_sizze_16582, segment_sizze_nonzzero_18731) + sext_i32_i64(local_tid_18734)] = tmp_18758;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_3:\n    return;\n    #undef segred_tblock_sizze_16582\n}\nFUTHARK_KERNEL_SIZED(find_cluster_ids_6783zisegscan_16613_dim1, 1, 1)\nvoid find_cluster_ids_6783zisegscan_16613(__global int *global_failure, int64_t n_12449, int64_t num_tblocks_16610, int64_t num_virt_blocks_18864, int64_t num_virt_threads_18865, __global unsigned char *ext_mem_18501, __global unsigned char *mem_18504, __global unsigned char *status_flags_mem_18866, __global unsigned char *aggregates_mem_18888, __global unsigned char *incprefixes_mem_18890, __global unsigned char *global_dynid_mem_18892)\n{\n    #define segscan_tblock_sizze_16608 (find_cluster_ids_6783zisegscan_16613zisegscan_tblock_sizze_16608)\n    #define chunk_sizze_18863 (find_cluster_ids_6783zisegscan_16613zichunk_sizze_18863)\n    \n    volatile __local unsigned char *local_mem_18902_backing_0 = &shared_mem[0];\n    const int64_t local_mem_18902_backing_0_offset = 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_16608), chunk_sizze_18863 * segscan_tblock_sizze_16608 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_16608), chunk_sizze_18863 * segscan_tblock_sizze_16608 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18895;\n    int32_t tblock_sizze_18898;\n    int32_t wave_sizze_18897;\n    int32_t block_id_18896;\n    int32_t global_tid_18894;\n    int64_t phys_tid_16613;\n    int32_t chunk_sizze_32b_18899;\n    int64_t byte_offsets_18900;\n    int64_t warp_byte_offset_18901;\n    __local unsigned char *local_mem_18902;\n   ",
                                    " int64_t trans_arr_len_18903;\n    int64_t phys_block_id_18909;\n    int64_t virtloop_bound_18910;\n    \n    local_tid_18895 = get_local_id(0);\n    tblock_sizze_18898 = get_local_size(0);\n    wave_sizze_18897 = LOCKSTEP_WIDTH;\n    block_id_18896 = get_tblock_id(0);\n    global_tid_18894 = block_id_18896 * tblock_sizze_18898 + local_tid_18895;\n    phys_tid_16613 = sext_i32_i64(global_tid_18894);\n    chunk_sizze_32b_18899 = sext_i64_i32(chunk_sizze_18863);\n    byte_offsets_18900 = segscan_tblock_sizze_16608 * (int64_t) 8;\n    warp_byte_offset_18901 = (int64_t) 288;\n    // Allocate reusable shared memory\n    { }\n    local_mem_18902 = (__local unsigned char *) local_mem_18902_backing_0;\n    trans_arr_len_18903 = chunk_sizze_18863 * segscan_tblock_sizze_16608;\n    phys_block_id_18909 = get_tblock_id(0);\n    virtloop_bound_18910 = sdiv_up64(num_virt_blocks_18864 - phys_block_id_18909, num_tblocks_16610);\n    for (int64_t virtloop_i_18911 = 0; virtloop_i_18911 < virtloop_bound_18910; virtloop_i_18911++) {\n        int64_t dynamic_id_18912;\n        int64_t block_offset_18913;\n        int64_t sgm_idx_18914;\n        int32_t boundary_18915;\n        int32_t segsizze_compact_18916;\n        int64_t private_mem_18917[chunk_sizze_18863];\n        int64_t thd_offset_18919;\n        int64_t acc_18935;\n        int64_t prefix_18945;\n        bool block_new_sgm_18946;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_18895 == 0) {\n                dynamic_id_18912 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_18892)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_18902)[(int64_t) 0] = dynamic_id_18912;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_18912 == num_virt_blocks_18864 - (int64_t) 1) {\n                       ", " ((__global int32_t *) global_dynid_mem_18892)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_18912 = ((__local int32_t *) local_mem_18902)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_18913 = dynamic_id_18912 * chunk_sizze_18863 * segscan_tblock_sizze_16608;\n        sgm_idx_18914 = smod64(block_offset_18913, n_12449);\n        boundary_18915 = sext_i64_i32(smin64(chunk_sizze_18863 * segscan_tblock_sizze_16608, n_12449 - sgm_idx_18914));\n        segsizze_compact_18916 = sext_i64_i32(smin64(chunk_sizze_18863 * segscan_tblock_sizze_16608, n_12449));\n        thd_offset_18919 = block_offset_18913 + sext_i32_i64(local_tid_18895);\n        // Load and map\n        {\n            for (int64_t i_18920 = 0; i_18920 < chunk_sizze_18863; i_18920++) {\n                int64_t virt_tid_18921 = thd_offset_18919 + i_18920 * segscan_tblock_sizze_16608;\n                int64_t slice_18922 = n_12449;\n                int64_t gtid_16612 = virt_tid_18921;\n                int64_t remnant_18923 = virt_tid_18921 - gtid_16612;\n                \n                if (slt64(virt_tid_18921, n_12449)) {\n                    int64_t eta_p_16092 = ((__global int64_t *) ext_mem_18501)[gtid_16612];\n                    bool defunc_0_f_res_16093 = gtid_16612 == eta_p_16092;\n                    int64_t lifted_lambda_res_16095 = btoi_bool_i64(defunc_0_f_res_16093);\n                    \n                    private_mem_18917[i_18920] = lifted_lambda_res_16095;\n                } else {\n                    private_mem_18917[i_18920] = (int64_t) 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_18924 = 0; i_18924 < chunk_sizze_18863; i_18924++) {\n                int64_t sharedIdx_18925 = sext_i32_i64(local_tid_18895) + i_18924 * segscan_tblock_sizze_16608;\n                int64_t tmp_18926 = priva", "te_mem_18917[i_18924];\n                \n                ((__local int64_t *) local_mem_18902)[sharedIdx_18925] = tmp_18926;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_18927 = 0; i_18927 < chunk_sizze_18863; i_18927++) {\n                int64_t sharedIdx_18928 = sext_i32_i64(local_tid_18895) * chunk_sizze_18863 + i_18927;\n                int64_t tmp_18929 = ((__local int64_t *) local_mem_18902)[sharedIdx_18928];\n                \n                private_mem_18917[i_18927] = tmp_18929;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_18930 = 0; i_18930 < chunk_sizze_18863 - (int64_t) 1; i_18930++) {\n                int64_t eta_p_15681;\n                int64_t eta_p_15682;\n                \n                eta_p_15681 = private_mem_18917[i_18930];\n                eta_p_15682 = private_mem_18917[i_18930 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_15683 = add64(eta_p_15681, eta_p_15682);\n                \n                private_mem_18917[i_18930 + (int64_t) 1] = defunc_0_op_res_15683;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_18931 = private_mem_18917[chunk_sizze_18863 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_18902)[sext_i32_i64(local_tid_18895)] = tmp_18931;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_18932;\n            int64_t eta_p_18933;\n            int64_t eta_p_18936;\n            int64_t eta_p_18937;\n            bool ltid_in_bounds_18939 = slt64(sext_i32_i64(local_tid_18895), num_virt_threads_18865);\n            int32_t skip_threads_18940;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_18939) {\n                    eta_p_18933 = ((volatile __local int64_t *) local_mem_18902)[sext_i32_i64(lo",
                                    "cal_tid_18895)];\n                    if ((local_tid_18895 - squot32(local_tid_18895, 32) * 32) == 0) {\n                        eta_p_18932 = eta_p_18933;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_18940 = 1;\n                while (slt32(skip_threads_18940, 32)) {\n                    bool thread_active_18941 = sle32(skip_threads_18940, local_tid_18895 - squot32(local_tid_18895, 32) * 32) && ltid_in_bounds_18939;\n                    \n                    if (thread_active_18941) {\n                        // read operands\n                        {\n                            eta_p_18932 = ((volatile __local int64_t *) local_mem_18902)[sext_i32_i64(local_tid_18895) - sext_i32_i64(skip_threads_18940)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_18941) {\n                            int64_t defunc_0_op_res_18934 = add64(eta_p_18932, eta_p_18933);\n                            \n                            eta_p_18932 = defunc_0_op_res_18934;\n                        }\n                    }\n                    if (sle32(wave_sizze_18897, skip_threads_18940)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_18941) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_18902)[sext_i32_i64(local_tid_18895)] = eta_p_18932;\n                            eta_p_18933 = eta_p_18932;\n                        }\n                    }\n                    if (sle32(wave_sizze_18897, skip_threads_18940)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_18940 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of blo", "ck 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_18895 - squot32(local_tid_18895, 32) * 32) == 31 && ltid_in_bounds_18939) {\n                    ((volatile __local int64_t *) local_mem_18902)[sext_i32_i64(squot32(local_tid_18895, 32))] = eta_p_18932;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_18942;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_18895, 32) == 0 && ltid_in_bounds_18939) {\n                        eta_p_18937 = ((volatile __local int64_t *) local_mem_18902)[sext_i32_i64(local_tid_18895)];\n                        if ((local_tid_18895 - squot32(local_tid_18895, 32) * 32) == 0) {\n                            eta_p_18936 = eta_p_18937;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_18942 = 1;\n                    while (slt32(skip_threads_18942, 32)) {\n                        bool thread_active_18943 = sle32(skip_threads_18942, local_tid_18895 - squot32(local_tid_18895, 32) * 32) && (squot32(local_tid_18895, 32) == 0 && ltid_in_bounds_18939);\n                        \n                        if (thread_active_18943) {\n                            // read operands\n                            {\n                                eta_p_18936 = ((volatile __local int64_t *) local_mem_18902)[sext_i32_i64(local_tid_18895) - sext_i32_i64(skip_threads_18942)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_18943) {\n                                int64_t defunc_0_op_res_18938 = add64(eta_p_18936, eta_p_18937);\n                      ", "          \n                                eta_p_18936 = defunc_0_op_res_18938;\n                            }\n                        }\n                        if (sle32(wave_sizze_18897, skip_threads_18942)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_18943) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_18902)[sext_i32_i64(local_tid_18895)] = eta_p_18936;\n                                eta_p_18937 = eta_p_18936;\n                            }\n                        }\n                        if (sle32(wave_sizze_18897, skip_threads_18942)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_18942 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_18944 = squot32(local_tid_18895, 32) == 0 || !ltid_in_bounds_18939;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_18944) {\n                        eta_p_18933 = eta_p_18932;\n                        eta_p_18932 = ((__local int64_t *) local_mem_18902)[sext_i32_i64(squot32(local_tid_18895, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_18944) {\n                        int64_t defunc_0_op_res_18934 = add64(eta_p_18932, eta_p_18933);\n                        \n                        eta_p_18932 = defunc_0_op_res_18934;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_18944) {\n                        ((__local int64_t *) local_mem_18902)[sext_i32_i64(local_tid_18895)] = eta_p_",
                                    "18932;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_18895, 32) == 0 && ltid_in_bounds_18939) {\n                    ((__local int64_t *) local_mem_18902)[sext_i32_i64(local_tid_18895)] = eta_p_18933;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_18895 == 0) {\n                acc_18935 = ((__local int64_t *) local_mem_18902)[segscan_tblock_sizze_16608 - (int64_t) 1];\n            } else {\n                acc_18935 = ((__local int64_t *) local_mem_18902)[sext_i32_i64(local_tid_18895) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_18945 = (int64_t) 0;\n        block_new_sgm_18946 = sgm_idx_18914 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_18946 && local_tid_18895 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_18890)[dynamic_id_18912] = acc_18935;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_18866)[dynamic_id_18912] = (int8_t) 2;\n                acc_18935 = (int64_t) 0;\n            }\n            if (!block_new_sgm_18946 && slt32(local_tid_18895, wave_sizze_18897)) {\n                if (local_tid_18895 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_18888)[dynamic_id_18912] = acc_18935;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_18866)[dynamic_id_18912] = (int8_t) 1;\n                    \n                    int8_t tmp_18947 = ((volatile __global int8_t *) status_flags_mem_18866)[dynamic_id_18912 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_18902)[(int64_t) 0] = tmp_18947;\n                }\n                mem_fence_local()", ";\n                \n                int8_t status_18948 = ((__local int8_t *) local_mem_18902)[(int64_t) 0];\n                \n                if (status_18948 == (int8_t) 2) {\n                    if (local_tid_18895 == 0) {\n                        prefix_18945 = ((volatile __global int64_t *) incprefixes_mem_18890)[dynamic_id_18912 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_18949 = sext_i64_i32(dynamic_id_18912 - sext_i32_i64(wave_sizze_18897));\n                    \n                    while (slt32(wave_sizze_18897 * -1, readOffset_18949)) {\n                        int32_t read_i_18950 = readOffset_18949 + local_tid_18895;\n                        int64_t aggr_18951 = (int64_t) 0;\n                        int8_t flag_18952 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_18950)) {\n                            flag_18952 = ((volatile __global int8_t *) status_flags_mem_18866)[sext_i32_i64(read_i_18950)];\n                            if (flag_18952 == (int8_t) 2) {\n                                aggr_18951 = ((volatile __global int64_t *) incprefixes_mem_18890)[sext_i32_i64(read_i_18950)];\n                            } else if (flag_18952 == (int8_t) 1) {\n                                aggr_18951 = ((volatile __global int64_t *) aggregates_mem_18888)[sext_i32_i64(read_i_18950)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_18902)[(int64_t) 4 + sext_i32_i64(local_tid_18895)] = aggr_18951;\n                        ((__local int8_t *) local_mem_18902)[sext_i32_i64(local_tid_18895)] = flag_18952;\n                        flag_18952 = ((__local int8_t *) local_mem_18902)[sext_i32_i64(wave_sizze_18897) - (int64_t) 1];\n                        if (slt8(flag_18952, (int8_t) 2)) {\n                            int8_t flg_x_18956;\n                            int8_t flg_y_18957;\n                            int64_t eta_p_18953;\n   ", "                         int64_t eta_p_18954;\n                            int32_t skip_threads_18958;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_18957 = ((volatile __local int8_t *) local_mem_18902)[sext_i32_i64(local_tid_18895)];\n                                eta_p_18954 = ((volatile __local int64_t *) local_mem_18902)[(int64_t) 4 + sext_i32_i64(local_tid_18895)];\n                                if ((local_tid_18895 - squot32(local_tid_18895, 32) * 32) == 0) {\n                                    eta_p_18953 = eta_p_18954;\n                                    flg_x_18956 = flg_y_18957;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_18958 = 1;\n                                while (slt32(skip_threads_18958, 32)) {\n                                    if (sle32(skip_threads_18958, local_tid_18895 - squot32(local_tid_18895, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_18956 = ((volatile __local int8_t *) local_mem_18902)[sext_i32_i64(local_tid_18895) - sext_i32_i64(skip_threads_18958)];\n                                            eta_p_18953 = ((volatile __local int64_t *) local_mem_18902)[(int64_t) 4 + (sext_i32_i64(local_tid_18895) - sext_i32_i64(skip_threads_18958))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_18957 == (int8_t) 2 || flg_y_18957 == (int8_t) 0) {\n                                                flg_x_18956 = flg_y_18957;\n                                                eta_p_18953 = eta_p_18954;\n             ",
                                    "                               } else {\n                                                int64_t defunc_0_op_res_18955 = add64(eta_p_18953, eta_p_18954);\n                                                \n                                                eta_p_18953 = defunc_0_op_res_18955;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_18902)[sext_i32_i64(local_tid_18895)] = flg_x_18956;\n                                            flg_y_18957 = flg_x_18956;\n                                            ((volatile __local int64_t *) local_mem_18902)[(int64_t) 4 + sext_i32_i64(local_tid_18895)] = eta_p_18953;\n                                            eta_p_18954 = eta_p_18953;\n                                        }\n                                    }\n                                    skip_threads_18958 *= 2;\n                                }\n                            }\n                        }\n                        flag_18952 = ((__local int8_t *) local_mem_18902)[sext_i32_i64(wave_sizze_18897) - (int64_t) 1];\n                        aggr_18951 = ((__local int64_t *) local_mem_18902)[(int64_t) 4 + (sext_i32_i64(wave_sizze_18897) - (int64_t) 1)];\n                        if (flag_18952 == (int8_t) 2) {\n                            readOffset_18949 = wave_sizze_18897 * -1;\n                        } else if (flag_18952 == (int8_t) 1) {\n                            readOffset_18949 -= wave_sizze_18897;\n                        }\n                        if (slt8((int8_t) 0, flag_18952)) {\n                            int64_t eta_p_18959 = aggr_18951;\n                            int64_t eta_p_18960 = prefix_18945;\n                            int64_t defunc_0_op_res_18961 = add64(eta_p_18959, eta_p_18960);\n                            \n                   ", "         prefix_18945 = defunc_0_op_res_18961;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_18895 == 0) {\n                    if (boundary_18915 == sext_i64_i32(segscan_tblock_sizze_16608 * chunk_sizze_18863)) {\n                        int64_t eta_p_18962 = prefix_18945;\n                        int64_t eta_p_18963 = acc_18935;\n                        int64_t defunc_0_op_res_18964 = add64(eta_p_18962, eta_p_18963);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_18890)[dynamic_id_18912] = defunc_0_op_res_18964;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_18866)[dynamic_id_18912] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_18902)[(int64_t) 4] = prefix_18945;\n                    acc_18935 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_18912 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_18945 = ((__local int64_t *) local_mem_18902)[(int64_t) 4];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_18965;\n            int64_t eta_p_18966;\n            int64_t eta_p_18968 = prefix_18945;\n            int64_t eta_p_18969 = acc_18935;\n            \n            if (slt32(local_tid_18895 * chunk_sizze_32b_18899, boundary_18915) && !block_new_sgm_18946) {\n                int64_t defunc_0_op_res_18970 = add64(eta_p_18968, eta_p_18969);\n                \n                eta_p_18965 = defunc_0_op_res_18970;\n            } else {\n                eta_p_18965 = acc_18935;\n            }\n            \n            int32_t stopping_point_18971 = segsizze_compact_18916 - srem32(local_tid_18895 * chunk_sizze_32b_18899 - 1 + segsizze_compact_18916 - boundary_18915, segsizze_compact_18916);\n    ", "        \n            for (int64_t i_18972 = 0; i_18972 < chunk_sizze_18863; i_18972++) {\n                if (slt32(sext_i64_i32(i_18972), stopping_point_18971 - 1)) {\n                    eta_p_18966 = private_mem_18917[i_18972];\n                    \n                    int64_t defunc_0_op_res_18967 = add64(eta_p_18965, eta_p_18966);\n                    \n                    private_mem_18917[i_18972] = defunc_0_op_res_18967;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_18973 = 0; i_18973 < chunk_sizze_18863; i_18973++) {\n                int64_t sharedIdx_18974 = sext_i32_i64(local_tid_18895) * chunk_sizze_18863 + i_18973;\n                int64_t tmp_18975 = private_mem_18917[i_18973];\n                \n                ((__local int64_t *) local_mem_18902)[sharedIdx_18974] = tmp_18975;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_18976 = 0; i_18976 < chunk_sizze_18863; i_18976++) {\n                int64_t flat_idx_18977 = thd_offset_18919 + i_18976 * segscan_tblock_sizze_16608;\n                int64_t slice_18978 = n_12449;\n                int64_t gtid_16612 = flat_idx_18977;\n                int64_t remnant_18979 = flat_idx_18977 - gtid_16612;\n                \n                if (slt64(flat_idx_18977, n_12449)) {\n                    int64_t tmp_18980 = ((__local int64_t *) local_mem_18902)[flat_idx_18977 - block_offset_18913];\n                    \n                    ((__global int64_t *) mem_18504)[gtid_16612] = tmp_18980;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_16608\n    #undef chunk_sizze_18863\n}\nFUTHARK_KERNEL_SIZED(find_cluster_ids_6890zisegmap_16719_dim1, 1, 1)\nvoid find_cluster_ids_6890zisegmap_16719(__global int *global_failure, int64_t n_14507, int64_t dim_14508, double eps_14510, int64_t inf_14538,",
                                    " int64_t j_m_i_14549, int64_t num_threads_18548, __global unsigned char *core_dat_mem_18419, __global unsigned char *mem_param_18427, __global unsigned char *mem_18479, __global unsigned char *mem_18490, __global unsigned char *color_18526)\n{\n    #define segmap_tblock_sizze_16715 (find_cluster_ids_6890zisegmap_16719zisegmap_tblock_sizze_16715)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18677;\n    int32_t tblock_sizze_18680;\n    int32_t wave_sizze_18679;\n    int32_t block_id_18678;\n    int32_t global_tid_18676;\n    int64_t phys_tid_16719;\n    int64_t global_tid_18681;\n    int64_t slice_18682;\n    int64_t gtid_16718;\n    int64_t remnant_18683;\n    \n    local_tid_18677 = get_local_id(0);\n    tblock_sizze_18680 = get_local_size(0);\n    wave_sizze_18679 = LOCKSTEP_WIDTH;\n    block_id_18678 = get_tblock_id(0);\n    global_tid_18676 = block_id_18678 * tblock_sizze_18680 + local_tid_18677;\n    phys_tid_16719 = sext_i32_i64(global_tid_18676);\n    global_tid_18681 = sext_i32_i64(block_id_18678) * segmap_tblock_sizze_16715 + sext_i32_i64(local_tid_18677);\n    slice_18682 = j_m_i_14549;\n    gtid_16718 = global_tid_18681;\n    remnant_18683 = global_tid_18681 - gtid_16718;\n    if (slt64(gtid_16718, j_m_i_14549)) {\n        int64_t slice_18401;\n        int64_t eta_p_16720;\n        int64_t defunc_0_reduce_res_16722;\n        int64_t redout_18406;\n        \n        slice_18401 = inf_14538 + gtid_16718;\n        eta_p_16720 = ((__global int64_t *) mem_param_18427)[slice_18401];\n        redout_18406 = (int64_t) 9223372036854775807;\n        for (int64_t i_18407 = 0; i_18407 < n_14507; i_18407++) {\n            double defunc_0_f_res_16730;\n            double acc_16732;\n            double sqrt_res_16735;\n            bool zlze_res_16736;\n            int64_t lifted_lambda_res_16737;\n            int64_t min_res_16740;\n            int64_t redout_tmp_18684;\n            \n            for (int64_t i_18410 = 0; i_18410 < dim_14508; i_18410++) {\n                double eta_p", "_16726;\n                double eta_p_16727;\n                double zm_res_16728;\n                double zt_res_16729;\n                \n                eta_p_16726 = ((__global double *) mem_18479)[slice_18401 + i_18410 * n_14507];\n                eta_p_16727 = ((__global double *) core_dat_mem_18419)[i_18407 * dim_14508 + i_18410];\n                zm_res_16728 = eta_p_16726 - eta_p_16727;\n                zt_res_16729 = zm_res_16728 * zm_res_16728;\n                ((__global double *) color_18526)[phys_tid_16719 + i_18410 * num_threads_18548] = zt_res_16729;\n            }\n            acc_16732 = 0.0;\n            for (int64_t i_16731 = 0; i_16731 < dim_14508; i_16731++) {\n                double b_16733;\n                double zp_res_16734;\n                double acc_tmp_18686;\n                \n                b_16733 = ((__global double *) color_18526)[phys_tid_16719 + i_16731 * num_threads_18548];\n                zp_res_16734 = acc_16732 + b_16733;\n                acc_tmp_18686 = zp_res_16734;\n                acc_16732 = acc_tmp_18686;\n            }\n            defunc_0_f_res_16730 = acc_16732;\n            sqrt_res_16735 = futrts_sqrt64(defunc_0_f_res_16730);\n            zlze_res_16736 = sqrt_res_16735 <= eps_14510;\n            if (zlze_res_16736) {\n                int64_t eta_p_16724 = ((__global int64_t *) mem_param_18427)[i_18407];\n                \n                lifted_lambda_res_16737 = eta_p_16724;\n            } else {\n                lifted_lambda_res_16737 = eta_p_16720;\n            }\n            min_res_16740 = smin64(lifted_lambda_res_16737, redout_18406);\n            redout_tmp_18684 = min_res_16740;\n            redout_18406 = redout_tmp_18684;\n        }\n        defunc_0_reduce_res_16722 = redout_18406;\n        ((__global int64_t *) mem_18490)[gtid_16718] = defunc_0_reduce_res_16722;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_16715\n}\nFUTHARK_KERNEL_SIZED(find_cluster_ids_6890zisegmap_16925_dim1, 1, 1)\nvoid find_cluster_ids_6890zisegm", "ap_16925(__global int *global_failure, int64_t n_14507, int64_t dim_14508, int64_t inf_14538, int64_t j_m_i_14549, __global unsigned char *core_dat_mem_18419, __global unsigned char *mem_18432)\n{\n    #define segmap_tblock_sizze_16919 (find_cluster_ids_6890zisegmap_16925zisegmap_tblock_sizze_16919)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18707;\n    int32_t tblock_sizze_18710;\n    int32_t wave_sizze_18709;\n    int32_t block_id_18708;\n    int32_t global_tid_18706;\n    int64_t phys_tid_16925;\n    int64_t global_tid_18711;\n    int64_t slice_18712;\n    int64_t slice_18713;\n    int64_t slice_18714;\n    int64_t gtid_16922;\n    int64_t remnant_18715;\n    int64_t gtid_16923;\n    int64_t remnant_18716;\n    int64_t gtid_16924;\n    int64_t remnant_18717;\n    \n    local_tid_18707 = get_local_id(0);\n    tblock_sizze_18710 = get_local_size(0);\n    wave_sizze_18709 = LOCKSTEP_WIDTH;\n    block_id_18708 = get_tblock_id(0);\n    global_tid_18706 = block_id_18708 * tblock_sizze_18710 + local_tid_18707;\n    phys_tid_16925 = sext_i32_i64(global_tid_18706);\n    global_tid_18711 = sext_i32_i64(block_id_18708) * segmap_tblock_sizze_16919 + sext_i32_i64(local_tid_18707);\n    slice_18712 = dim_14508;\n    slice_18713 = n_14507 * slice_18712;\n    slice_18714 = j_m_i_14549 * slice_18713;\n    gtid_16922 = squot64(global_tid_18711, slice_18713);\n    remnant_18715 = global_tid_18711 - gtid_16922 * slice_18713;\n    gtid_16923 = squot64(remnant_18715, slice_18712);\n    remnant_18716 = remnant_18715 - gtid_16923 * slice_18712;\n    gtid_16924 = remnant_18716;\n    remnant_18717 = remnant_18716 - gtid_16924;\n    if ((slt64(gtid_16922, j_m_i_14549) && slt64(gtid_16923, n_14507)) && slt64(gtid_16924, dim_14508)) {\n        int64_t slice_18405;\n        double eta_p_16926;\n        double eta_p_16927;\n        double zm_res_16928;\n        double zt_res_16929;\n        \n        slice_18405 = inf_14538 + gtid_16922;\n        eta_p_16926 = ((__global double *) core_dat_mem_18419)[slice",
                                    "_18405 * dim_14508 + gtid_16924];\n        eta_p_16927 = ((__global double *) core_dat_mem_18419)[gtid_16923 * dim_14508 + gtid_16924];\n        zm_res_16928 = eta_p_16926 - eta_p_16927;\n        zt_res_16929 = zm_res_16928 * zm_res_16928;\n        ((__global double *) mem_18432)[gtid_16922 * (dim_14508 * n_14507) + gtid_16923 * dim_14508 + gtid_16924] = zt_res_16929;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_16919\n}\nFUTHARK_KERNEL_SIZED(find_cluster_ids_6890zisegmap_16938_dim1, 1, 1)\nvoid find_cluster_ids_6890zisegmap_16938(__global int *global_failure, int64_t n_14507, int64_t dim_14508, double eps_14510, int64_t inf_14538, int64_t j_m_i_14549, __global unsigned char *mem_param_18427, __global unsigned char *mem_18449, __global unsigned char *mem_18453)\n{\n    #define segmap_tblock_sizze_16933 (find_cluster_ids_6890zisegmap_16938zisegmap_tblock_sizze_16933)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18720;\n    int32_t tblock_sizze_18723;\n    int32_t wave_sizze_18722;\n    int32_t block_id_18721;\n    int32_t global_tid_18719;\n    int64_t phys_tid_16938;\n    int64_t global_tid_18724;\n    int64_t slice_18725;\n    int64_t slice_18726;\n    int64_t gtid_16936;\n    int64_t remnant_18727;\n    int64_t gtid_16937;\n    int64_t remnant_18728;\n    \n    local_tid_18720 = get_local_id(0);\n    tblock_sizze_18723 = get_local_size(0);\n    wave_sizze_18722 = LOCKSTEP_WIDTH;\n    block_id_18721 = get_tblock_id(0);\n    global_tid_18719 = block_id_18721 * tblock_sizze_18723 + local_tid_18720;\n    phys_tid_16938 = sext_i32_i64(global_tid_18719);\n    global_tid_18724 = sext_i32_i64(block_id_18721) * segmap_tblock_sizze_16933 + sext_i32_i64(local_tid_18720);\n    slice_18725 = n_14507;\n    slice_18726 = j_m_i_14549 * slice_18725;\n    gtid_16936 = squot64(global_tid_18724, slice_18725);\n    remnant_18727 = global_tid_18724 - gtid_16936 * slice_18725;\n    gtid_16937 = remnant_18727;\n    remnant_18728 = remnant_18727 - gtid_16937;\n    if (slt64(gt", "id_16936, j_m_i_14549) && slt64(gtid_16937, n_14507)) {\n        int64_t slice_18404;\n        double defunc_0_f_res_16942;\n        double acc_16944;\n        double sqrt_res_16947;\n        bool zlze_res_16948;\n        int64_t lifted_lambda_res_16949;\n        \n        slice_18404 = inf_14538 + gtid_16936;\n        acc_16944 = 0.0;\n        for (int64_t i_16943 = 0; i_16943 < dim_14508; i_16943++) {\n            double b_16945;\n            double zp_res_16946;\n            double acc_tmp_18729;\n            \n            b_16945 = ((__global double *) mem_18449)[gtid_16936 * n_14507 + gtid_16937 + i_16943 * (n_14507 * j_m_i_14549)];\n            zp_res_16946 = acc_16944 + b_16945;\n            acc_tmp_18729 = zp_res_16946;\n            acc_16944 = acc_tmp_18729;\n        }\n        defunc_0_f_res_16942 = acc_16944;\n        sqrt_res_16947 = futrts_sqrt64(defunc_0_f_res_16942);\n        zlze_res_16948 = sqrt_res_16947 <= eps_14510;\n        if (zlze_res_16948) {\n            int64_t eta_p_16940 = ((__global int64_t *) mem_param_18427)[gtid_16937];\n            \n            lifted_lambda_res_16949 = eta_p_16940;\n        } else {\n            int64_t eta_p_16939 = ((__global int64_t *) mem_param_18427)[slice_18404];\n            \n            lifted_lambda_res_16949 = eta_p_16939;\n        }\n        ((__global int64_t *) mem_18453)[gtid_16936 * n_14507 + gtid_16937] = lifted_lambda_res_16949;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_16933\n}\nFUTHARK_KERNEL_SIZED(find_cluster_ids_6890zisegmap_17004_dim1, 1, 1)\nvoid find_cluster_ids_6890zisegmap_17004(__global int *global_failure, int64_t n_14507, __global unsigned char *mem_18504, __global unsigned char *mem_18507)\n{\n    #define segmap_tblock_sizze_17000 (find_cluster_ids_6890zisegmap_17004zisegmap_tblock_sizze_17000)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18983;\n    int32_t tblock_sizze_18986;\n    int32_t wave_sizze_18985;\n    int32_t block_id_18984;\n    int32_t global_tid_18982;\n    in", "t64_t phys_tid_17004;\n    int64_t global_tid_18987;\n    int64_t slice_18988;\n    int64_t gtid_17003;\n    int64_t remnant_18989;\n    \n    local_tid_18983 = get_local_id(0);\n    tblock_sizze_18986 = get_local_size(0);\n    wave_sizze_18985 = LOCKSTEP_WIDTH;\n    block_id_18984 = get_tblock_id(0);\n    global_tid_18982 = block_id_18984 * tblock_sizze_18986 + local_tid_18983;\n    phys_tid_17004 = sext_i32_i64(global_tid_18982);\n    global_tid_18987 = sext_i32_i64(block_id_18984) * segmap_tblock_sizze_17000 + sext_i32_i64(local_tid_18983);\n    slice_18988 = n_14507;\n    gtid_17003 = global_tid_18987;\n    remnant_18989 = global_tid_18987 - gtid_17003;\n    if (slt64(gtid_17003, n_14507)) {\n        int64_t zv_lhs_17006;\n        int64_t tmp_17007;\n        bool cond_17009;\n        int64_t lifted_lambda_res_17010;\n        \n        zv_lhs_17006 = add64((int64_t) -1, gtid_17003);\n        tmp_17007 = smod64(zv_lhs_17006, n_14507);\n        cond_17009 = gtid_17003 == (int64_t) 0;\n        if (cond_17009) {\n            lifted_lambda_res_17010 = (int64_t) 0;\n        } else {\n            int64_t lifted_lambda_res_17008 = ((__global int64_t *) mem_18504)[tmp_17007];\n            \n            lifted_lambda_res_17010 = lifted_lambda_res_17008;\n        }\n        ((__global int64_t *) mem_18507)[gtid_17003] = lifted_lambda_res_17010;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_17000\n}\nFUTHARK_KERNEL_SIZED(find_cluster_ids_6890zisegmap_17035_dim1, 1, 1)\nvoid find_cluster_ids_6890zisegmap_17035(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t n_14507, int64_t inf_15653, int64_t min_res_15655, __global unsigned char *ext_mem_18501, __global unsigned char *mem_18507, __global unsigned char *mem_param_18512, __global unsigned char *mem_18515)\n{\n    #define segmap_tblock_sizze_17031 (find_cluster_ids_6890zisegmap_17035zisegmap_tblock_sizze_17031)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_19014;\n ",
                                    "   int32_t tblock_sizze_19017;\n    int32_t wave_sizze_19016;\n    int32_t block_id_19015;\n    int32_t global_tid_19013;\n    int64_t phys_tid_17035;\n    int64_t global_tid_19018;\n    int64_t slice_19019;\n    int64_t gtid_17034;\n    int64_t remnant_19020;\n    \n    local_tid_19014 = get_local_id(0);\n    tblock_sizze_19017 = get_local_size(0);\n    wave_sizze_19016 = LOCKSTEP_WIDTH;\n    block_id_19015 = get_tblock_id(0);\n    global_tid_19013 = block_id_19015 * tblock_sizze_19017 + local_tid_19014;\n    phys_tid_17035 = sext_i32_i64(global_tid_19013);\n    global_tid_19018 = sext_i32_i64(block_id_19015) * segmap_tblock_sizze_17031 + sext_i32_i64(local_tid_19014);\n    slice_19019 = n_14507;\n    gtid_17034 = global_tid_19018;\n    remnant_19020 = global_tid_19018 - gtid_17034;\n    if (slt64(gtid_17034, n_14507)) {\n        int64_t eta_p_17036;\n        bool cond_17038;\n        bool cond_t_res_17039;\n        bool x_17040;\n        int64_t lifted_lambda_res_17041;\n        \n        eta_p_17036 = ((__global int64_t *) ext_mem_18501)[gtid_17034];\n        cond_17038 = sle64(inf_15653, eta_p_17036);\n        cond_t_res_17039 = slt64(eta_p_17036, min_res_15655);\n        x_17040 = cond_17038 && cond_t_res_17039;\n        if (x_17040) {\n            bool x_17042;\n            bool y_17043;\n            bool bounds_check_17044;\n            bool index_certs_17045;\n            int64_t lifted_lambda_res_t_res_17046;\n            \n            x_17042 = sle64((int64_t) 0, eta_p_17036);\n            y_17043 = slt64(eta_p_17036, n_14507);\n            bounds_check_17044 = x_17042 && y_17043;\n            if (!bounds_check_17044) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 1) == -1) {\n                        global_failure_args[0] = (int64_t) eta_p_17036;\n                        global_failure_args[1] = (int64_t) n_14507;\n                        ;\n                    }\n                    return;\n                }\n            }\n            lifted_lambda_res_t_res", "_17046 = ((__global int64_t *) mem_18507)[eta_p_17036];\n            lifted_lambda_res_17041 = lifted_lambda_res_t_res_17046;\n        } else {\n            int64_t eta_p_17037 = ((__global int64_t *) mem_param_18512)[gtid_17034];\n            \n            lifted_lambda_res_17041 = eta_p_17037;\n        }\n        ((__global int64_t *) mem_18515)[gtid_17034] = lifted_lambda_res_17041;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_17031\n}\nFUTHARK_KERNEL\nvoid find_cluster_ids_6890zisegmap_intrablock_16748(__global int *global_failure, int64_t n_14507, int64_t dim_14508, double eps_14510, int64_t inf_14538, int64_t j_m_i_14549, int64_t ctx_18564, __global unsigned char *core_dat_mem_18419, __global unsigned char *mem_param_18427, __global unsigned char *mem_18467, __global unsigned char *color_18527)\n{\n    volatile __local unsigned char *red_arr_mem_18699_backing_0 = &shared_mem[0];\n    const int64_t red_arr_mem_18699_backing_0_offset = 0 + ((int64_t) 8 * n_14507 + srem64((int64_t) 8 - srem64((int64_t) 8 * n_14507, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18690;\n    int32_t tblock_sizze_18693;\n    int32_t wave_sizze_18692;\n    int32_t block_id_18691;\n    int32_t global_tid_18689;\n    int64_t phys_tblock_id_16748;\n    int64_t slice_18695;\n    int64_t ltid_pre_18694;\n    int64_t remnant_18696;\n    int64_t slice_18697;\n    int64_t gtid_16747;\n    int64_t remnant_18698;\n    int64_t slice_18403;\n    int64_t eta_p_16749;\n    int64_t binop_x_18562;\n    int64_t defunc_0_reduce_res_16752;\n    int64_t phys_tid_16754;\n    __local unsigned char *red_arr_mem_18699;\n    int64_t gtid_16753;\n    int64_t ctx_18563;\n    double defunc_0_f_res_16765;\n    double acc_16767;\n    double sqrt_res_16770;\n    bool zlze_res_16771;\n    int64_t lifted_lambda_res_16772;\n    int32_t offset_18703;\n    int32_t skip_waves_18704;\n    int64_t eta_p_16755;\n    int64_t eta_p_16756;\n    \n    local_tid_18690 = get_local_id(0);\n    ", "tblock_sizze_18693 = get_local_size(0);\n    wave_sizze_18692 = LOCKSTEP_WIDTH;\n    block_id_18691 = get_tblock_id(0);\n    global_tid_18689 = block_id_18691 * tblock_sizze_18693 + local_tid_18690;\n    phys_tblock_id_16748 = sext_i32_i64(block_id_18691);\n    slice_18695 = n_14507;\n    ltid_pre_18694 = sext_i32_i64(local_tid_18690);\n    remnant_18696 = sext_i32_i64(local_tid_18690) - ltid_pre_18694;\n    slice_18697 = j_m_i_14549;\n    gtid_16747 = sext_i32_i64(block_id_18691);\n    remnant_18698 = sext_i32_i64(block_id_18691) - gtid_16747;\n    slice_18403 = inf_14538 + gtid_16747;\n    eta_p_16749 = ((__global int64_t *) mem_param_18427)[slice_18403];\n    binop_x_18562 = n_14507 * phys_tblock_id_16748;\n    phys_tid_16754 = sext_i32_i64(local_tid_18690);\n    red_arr_mem_18699 = (__local unsigned char *) red_arr_mem_18699_backing_0;\n    gtid_16753 = sext_i32_i64(sext_i64_i32(ltid_pre_18694));\n    ctx_18563 = phys_tid_16754 + binop_x_18562;\n    for (int64_t i_18414 = 0; i_18414 < dim_14508; i_18414++) {\n        double eta_p_16761;\n        double eta_p_16762;\n        double zm_res_16763;\n        double zt_res_16764;\n        \n        eta_p_16761 = ((__global double *) core_dat_mem_18419)[slice_18403 * dim_14508 + i_18414];\n        eta_p_16762 = ((__global double *) core_dat_mem_18419)[gtid_16753 * dim_14508 + i_18414];\n        zm_res_16763 = eta_p_16761 - eta_p_16762;\n        zt_res_16764 = zm_res_16763 * zm_res_16763;\n        ((__global double *) color_18527)[ctx_18563 + i_18414 * ctx_18564] = zt_res_16764;\n    }\n    acc_16767 = 0.0;\n    for (int64_t i_16766 = 0; i_16766 < dim_14508; i_16766++) {\n        double b_16768;\n        double zp_res_16769;\n        double acc_tmp_18702;\n        \n        b_16768 = ((__global double *) color_18527)[ctx_18563 + i_16766 * ctx_18564];\n        zp_res_16769 = acc_16767 + b_16768;\n        acc_tmp_18702 = zp_res_16769;\n        acc_16767 = acc_tmp_18702;\n    }\n    defunc_0_f_res_16765 = acc_16767;\n    sqrt_res_16770 = futrts_sqrt64(defunc_0_f_r",
                                    "es_16765);\n    zlze_res_16771 = sqrt_res_16770 <= eps_14510;\n    if (zlze_res_16771) {\n        int64_t eta_p_16759 = ((__global int64_t *) mem_param_18427)[gtid_16753];\n        \n        lifted_lambda_res_16772 = eta_p_16759;\n    } else {\n        lifted_lambda_res_16772 = eta_p_16749;\n    }\n    ((__local int64_t *) red_arr_mem_18699)[gtid_16753] = lifted_lambda_res_16772;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    skip_waves_18704 = 1;\n    offset_18703 = 0;\n    // participating threads read initial accumulator\n    {\n        if (slt32(local_tid_18690, sext_i64_i32(n_14507))) {\n            eta_p_16755 = ((__local int64_t *) red_arr_mem_18699)[sext_i32_i64(local_tid_18690 + offset_18703)];\n        }\n    }\n    offset_18703 = 1;\n    while (slt32(offset_18703, wave_sizze_18692)) {\n        if (slt32(local_tid_18690 + offset_18703, sext_i64_i32(n_14507)) && ((local_tid_18690 - squot32(local_tid_18690, wave_sizze_18692) * wave_sizze_18692) & (2 * offset_18703 - 1)) == 0) {\n            // read array element\n            {\n                eta_p_16756 = ((volatile __local int64_t *) red_arr_mem_18699)[sext_i32_i64(local_tid_18690 + offset_18703)];\n            }\n            // apply reduction operation\n            {\n                int64_t min_res_16757 = smin64(eta_p_16755, eta_p_16756);\n                \n                eta_p_16755 = min_res_16757;\n            }\n            // write result of operation\n            {\n                ((volatile __local int64_t *) red_arr_mem_18699)[sext_i32_i64(local_tid_18690)] = eta_p_16755;\n            }\n        }\n        offset_18703 *= 2;\n    }\n    while (slt32(skip_waves_18704, squot32(sext_i64_i32(n_14507) + wave_sizze_18692 - 1, wave_sizze_18692))) {\n        barrier(CLK_LOCAL_MEM_FENCE);\n        offset_18703 = skip_waves_18704 * wave_sizze_18692;\n        if (slt32(local_tid_18690 + offset_18703, sext_i64_i32(n_14507)) && ((local_tid_18690 - squot32(local_tid_18690, wave_sizze_18692) * wave_sizze_18692) == 0 && (squot32(local_tid_18690, wave_sizz", "e_18692) & (2 * skip_waves_18704 - 1)) == 0)) {\n            // read array element\n            {\n                eta_p_16756 = ((__local int64_t *) red_arr_mem_18699)[sext_i32_i64(local_tid_18690 + offset_18703)];\n            }\n            // apply reduction operation\n            {\n                int64_t min_res_16757 = smin64(eta_p_16755, eta_p_16756);\n                \n                eta_p_16755 = min_res_16757;\n            }\n            // write result of operation\n            {\n                ((__local int64_t *) red_arr_mem_18699)[sext_i32_i64(local_tid_18690)] = eta_p_16755;\n            }\n        }\n        skip_waves_18704 *= 2;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // Save result of reduction.\n    {\n        defunc_0_reduce_res_16752 = ((__local int64_t *) red_arr_mem_18699)[(int64_t) 0];\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    if (local_tid_18690 == 0) {\n        ((__global int64_t *) mem_18467)[gtid_16747] = defunc_0_reduce_res_16752;\n    }\n    \n  error_4:\n    return;\n}\nFUTHARK_KERNEL_SIZED(find_cluster_ids_6890zisegred_large_16959_dim1, 1, 1)\nvoid find_cluster_ids_6890zisegred_large_16959(__global int *global_failure, int64_t n_14507, int64_t j_m_i_14549, int64_t num_tblocks_16954, int64_t blocks_per_segment_18759, int64_t q_18760, int64_t num_virtblocks_18761, int64_t threads_per_segment_18762, __global unsigned char *mem_18453, __global unsigned char *mem_18456, __global unsigned char *segred_tmp_mem_18763, __global unsigned char *counters_mem_18765)\n{\n    #define segred_tblock_sizze_16953 (find_cluster_ids_6890zisegred_large_16959zisegred_tblock_sizze_16953)\n    #define chunk_sizze_18730 (find_cluster_ids_6890zisegred_large_16959zichunk_sizze_18730)\n    \n    volatile __local unsigned char *sync_arr_mem_18794_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_18794_backing_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i64_mem_18792_backing_0 = &shared_mem[sync_arr_mem_18794_backing_1_offs", "et];\n    const int64_t red_arr_i64_mem_18792_backing_0_offset = sync_arr_mem_18794_backing_1_offset + ((int64_t) 8 * segred_tblock_sizze_16953 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_16953, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18788;\n    int32_t tblock_sizze_18791;\n    int32_t wave_sizze_18790;\n    int32_t block_id_18789;\n    int32_t global_tid_18787;\n    int64_t phys_tid_16959;\n    __local unsigned char *red_arr_i64_mem_18792;\n    __local unsigned char *sync_arr_mem_18794;\n    int32_t phys_tblock_id_18796;\n    int32_t iterations_18797;\n    \n    local_tid_18788 = get_local_id(0);\n    tblock_sizze_18791 = get_local_size(0);\n    wave_sizze_18790 = LOCKSTEP_WIDTH;\n    block_id_18789 = get_tblock_id(0);\n    global_tid_18787 = block_id_18789 * tblock_sizze_18791 + local_tid_18788;\n    phys_tid_16959 = sext_i32_i64(global_tid_18787);\n    red_arr_i64_mem_18792 = (__local unsigned char *) red_arr_i64_mem_18792_backing_0;\n    sync_arr_mem_18794 = (__local unsigned char *) sync_arr_mem_18794_backing_1;\n    phys_tblock_id_18796 = get_tblock_id(0);\n    iterations_18797 = sdiv_up32(sext_i64_i32(num_virtblocks_18761) - phys_tblock_id_18796, sext_i64_i32(num_tblocks_16954));\n    for (int32_t i_18798 = 0; i_18798 < iterations_18797; i_18798++) {\n        int32_t virt_tblock_id_18799;\n        int64_t flat_segment_id_18800;\n        int64_t global_tid_18801;\n        int64_t slice_18802;\n        int64_t gtid_16957;\n        int64_t remnant_18803;\n        int64_t gtid_16958;\n        int64_t eta_p_block_res_acc_18804;\n        int64_t eta_p_16960;\n        int64_t eta_p_16961;\n        int64_t tblock_id_in_segment_18808;\n        int64_t block_base_offset_18809;\n        int32_t offset_18812;\n        int32_t skip_waves_18813;\n        int64_t eta_p_18805;\n        int64_t eta_p_18806;\n        \n        virt_tblock_id_18799 = phys_tblock_id_18796 + i_18798 * sext_i64_i32(num_tblocks_16954);\n        flat_se",
                                    "gment_id_18800 = squot64(sext_i32_i64(virt_tblock_id_18799), blocks_per_segment_18759);\n        global_tid_18801 = srem64(sext_i32_i64(virt_tblock_id_18799) * segred_tblock_sizze_16953 + sext_i32_i64(local_tid_18788), threads_per_segment_18762);\n        slice_18802 = j_m_i_14549;\n        gtid_16957 = flat_segment_id_18800;\n        remnant_18803 = flat_segment_id_18800 - gtid_16957;\n        // ne-initialise the outer (per-block) accumulator(s)\n        {\n            eta_p_block_res_acc_18804 = (int64_t) 9223372036854775807;\n        }\n        tblock_id_in_segment_18808 = squot64(global_tid_18801, segred_tblock_sizze_16953);\n        block_base_offset_18809 = tblock_id_in_segment_18808 * q_18760 * segred_tblock_sizze_16953;\n        for (int64_t i_18810 = 0; i_18810 < q_18760; i_18810++) {\n            int64_t block_offset_18811 = block_base_offset_18809 + i_18810 * segred_tblock_sizze_16953;\n            \n            gtid_16958 = global_tid_18801 + threads_per_segment_18762 * i_18810;\n            if (slt64(gtid_16958, n_14507)) {\n                // apply map function(s)\n                {\n                    // apply map function\n                    {\n                        int64_t x_16964 = ((__global int64_t *) mem_18453)[gtid_16957 * n_14507 + gtid_16958];\n                        \n                        // load accumulator(s)\n                        {\n                            eta_p_16960 = eta_p_block_res_acc_18804;\n                        }\n                        // load next value(s)\n                        {\n                            eta_p_16961 = x_16964;\n                        }\n                        // apply reduction operator(s)\n                        {\n                            int64_t min_res_16962 = smin64(eta_p_16960, eta_p_16961);\n                            \n                            // store in accumulator(s)\n                            {\n                                eta_p_block_res_acc_18804 = min_res_16962;\n                            }", "\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // store accs. prims go in lmem; non-prims in params (in global mem)\n        {\n            ((__local int64_t *) red_arr_i64_mem_18792)[sext_i32_i64(local_tid_18788)] = eta_p_block_res_acc_18804;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        skip_waves_18813 = 1;\n        offset_18812 = 0;\n        // participating threads read initial accumulator\n        {\n            if (slt32(local_tid_18788, sext_i64_i32(segred_tblock_sizze_16953))) {\n                eta_p_18805 = ((__local int64_t *) red_arr_i64_mem_18792)[sext_i32_i64(local_tid_18788 + offset_18812)];\n            }\n        }\n        offset_18812 = 1;\n        while (slt32(offset_18812, wave_sizze_18790)) {\n            if (slt32(local_tid_18788 + offset_18812, sext_i64_i32(segred_tblock_sizze_16953)) && ((local_tid_18788 - squot32(local_tid_18788, wave_sizze_18790) * wave_sizze_18790) & (2 * offset_18812 - 1)) == 0) {\n                // read array element\n                {\n                    eta_p_18806 = ((volatile __local int64_t *) red_arr_i64_mem_18792)[sext_i32_i64(local_tid_18788 + offset_18812)];\n                }\n                // apply reduction operation\n                {\n                    int64_t min_res_18807 = smin64(eta_p_18805, eta_p_18806);\n                    \n                    eta_p_18805 = min_res_18807;\n                }\n                // write result of operation\n                {\n                    ((volatile __local int64_t *) red_arr_i64_mem_18792)[sext_i32_i64(local_tid_18788)] = eta_p_18805;\n                }\n            }\n            offset_18812 *= 2;\n        }\n        while (slt32(skip_waves_18813, squot32(sext_i64_i32(segred_tblock_sizze_16953) + wave_sizze_18790 - 1, wave_sizze_18790))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_18812 = skip_waves_18813 * wave_sizze_18790;\n            if (slt32(local_tid_18788 + ", "offset_18812, sext_i64_i32(segred_tblock_sizze_16953)) && ((local_tid_18788 - squot32(local_tid_18788, wave_sizze_18790) * wave_sizze_18790) == 0 && (squot32(local_tid_18788, wave_sizze_18790) & (2 * skip_waves_18813 - 1)) == 0)) {\n                // read array element\n                {\n                    eta_p_18806 = ((__local int64_t *) red_arr_i64_mem_18792)[sext_i32_i64(local_tid_18788 + offset_18812)];\n                }\n                // apply reduction operation\n                {\n                    int64_t min_res_18807 = smin64(eta_p_18805, eta_p_18806);\n                    \n                    eta_p_18805 = min_res_18807;\n                }\n                // write result of operation\n                {\n                    ((__local int64_t *) red_arr_i64_mem_18792)[sext_i32_i64(local_tid_18788)] = eta_p_18805;\n                }\n            }\n            skip_waves_18813 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // thread 0 updates per-block acc(s); rest reset to ne\n        {\n            if (sext_i32_i64(local_tid_18788) == (int64_t) 0) {\n                eta_p_block_res_acc_18804 = eta_p_18805;\n            } else {\n                eta_p_block_res_acc_18804 = (int64_t) 9223372036854775807;\n            }\n        }\n        if (blocks_per_segment_18759 == (int64_t) 1) {\n            // first thread in block saves final result to memory\n            {\n                if (local_tid_18788 == 0) {\n                    ((__global int64_t *) mem_18456)[gtid_16957] = eta_p_block_res_acc_18804;\n                }\n            }\n        } else {\n            int32_t old_counter_18814;\n            bool is_last_block_18815;\n            \n            // first thread in block saves block result to global memory\n            {\n                if (local_tid_18788 == 0) {\n                    ((__global int64_t *) segred_tmp_mem_18763)[sext_i32_i64(virt_tblock_id_18799)] = eta_p_block_res_acc_18804;\n                    mem_fenc",
                                    "e_global();\n                    old_counter_18814 = atomic_add_i32_global(&((volatile __global int *) counters_mem_18765)[srem64(flat_segment_id_18800, (int64_t) 20480)], (int) 1);\n                    ((__local bool *) sync_arr_mem_18794)[(int64_t) 0] = old_counter_18814 == sext_i64_i32(blocks_per_segment_18759 - (int64_t) 1);\n                }\n            }\n            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n            is_last_block_18815 = ((__local bool *) sync_arr_mem_18794)[(int64_t) 0];\n            if (is_last_block_18815) {\n                if (local_tid_18788 == 0) {\n                    old_counter_18814 = atomic_add_i32_global(&((volatile __global int *) counters_mem_18765)[srem64(flat_segment_id_18800, (int64_t) 20480)], (int) sext_i64_i32((int64_t) 0 - blocks_per_segment_18759));\n                }\n                // read in the per-block-results\n                {\n                    int64_t read_per_thread_18816 = sdiv_up64(blocks_per_segment_18759, segred_tblock_sizze_16953);\n                    \n                    eta_p_16960 = (int64_t) 9223372036854775807;\n                    for (int64_t i_18817 = 0; i_18817 < read_per_thread_18816; i_18817++) {\n                        int64_t block_res_id_18818 = sext_i32_i64(local_tid_18788) * read_per_thread_18816 + i_18817;\n                        int64_t index_of_block_res_18819 = flat_segment_id_18800 * blocks_per_segment_18759 + block_res_id_18818;\n                        \n                        if (slt64(block_res_id_18818, blocks_per_segment_18759)) {\n                            eta_p_16961 = ((__global int64_t *) segred_tmp_mem_18763)[index_of_block_res_18819];\n                            \n                            int64_t min_res_16962 = smin64(eta_p_16960, eta_p_16961);\n                            \n                            eta_p_16960 = min_res_16962;\n                        }\n                    }\n                }\n                ((__local int64_t *) red_arr_i64_mem_18792)[sext_i32_i", "64(local_tid_18788)] = eta_p_16960;\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // reduce the per-block results\n                {\n                    int32_t offset_18820;\n                    int32_t skip_waves_18821 = 1;\n                    int64_t eta_p_18805;\n                    int64_t eta_p_18806;\n                    \n                    offset_18820 = 0;\n                    // participating threads read initial accumulator\n                    {\n                        if (slt32(local_tid_18788, sext_i64_i32(segred_tblock_sizze_16953))) {\n                            eta_p_18805 = ((__local int64_t *) red_arr_i64_mem_18792)[sext_i32_i64(local_tid_18788 + offset_18820)];\n                        }\n                    }\n                    offset_18820 = 1;\n                    while (slt32(offset_18820, wave_sizze_18790)) {\n                        if (slt32(local_tid_18788 + offset_18820, sext_i64_i32(segred_tblock_sizze_16953)) && ((local_tid_18788 - squot32(local_tid_18788, wave_sizze_18790) * wave_sizze_18790) & (2 * offset_18820 - 1)) == 0) {\n                            // read array element\n                            {\n                                eta_p_18806 = ((volatile __local int64_t *) red_arr_i64_mem_18792)[sext_i32_i64(local_tid_18788 + offset_18820)];\n                            }\n                            // apply reduction operation\n                            {\n                                int64_t min_res_18807 = smin64(eta_p_18805, eta_p_18806);\n                                \n                                eta_p_18805 = min_res_18807;\n                            }\n                            // write result of operation\n                            {\n                                ((volatile __local int64_t *) red_arr_i64_mem_18792)[sext_i32_i64(local_tid_18788)] = eta_p_18805;\n                            }\n                        }\n                        offset_18820 *= 2;\n                    }\n                    wh", "ile (slt32(skip_waves_18821, squot32(sext_i64_i32(segred_tblock_sizze_16953) + wave_sizze_18790 - 1, wave_sizze_18790))) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                        offset_18820 = skip_waves_18821 * wave_sizze_18790;\n                        if (slt32(local_tid_18788 + offset_18820, sext_i64_i32(segred_tblock_sizze_16953)) && ((local_tid_18788 - squot32(local_tid_18788, wave_sizze_18790) * wave_sizze_18790) == 0 && (squot32(local_tid_18788, wave_sizze_18790) & (2 * skip_waves_18821 - 1)) == 0)) {\n                            // read array element\n                            {\n                                eta_p_18806 = ((__local int64_t *) red_arr_i64_mem_18792)[sext_i32_i64(local_tid_18788 + offset_18820)];\n                            }\n                            // apply reduction operation\n                            {\n                                int64_t min_res_18807 = smin64(eta_p_18805, eta_p_18806);\n                                \n                                eta_p_18805 = min_res_18807;\n                            }\n                            // write result of operation\n                            {\n                                ((__local int64_t *) red_arr_i64_mem_18792)[sext_i32_i64(local_tid_18788)] = eta_p_18805;\n                            }\n                        }\n                        skip_waves_18821 *= 2;\n                    }\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                    // and back to memory with the final result\n                    {\n                        if (local_tid_18788 == 0) {\n                            ((__global int64_t *) mem_18456)[gtid_16957] = eta_p_18805;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_6:\n    return;\n    #undef segred_tblock_sizze_16953\n    #undef chunk_sizze_18730\n}\nFUTHARK_KERNEL_SIZED(find_cluster_ids_6890zisegred_n",
                                    "onseg_16976_dim1, 1, 1)\nvoid find_cluster_ids_6890zisegred_nonseg_16976(__global int *global_failure, int64_t n_14507, int64_t num_tblocks_16971, int64_t num_threads_18829, __global unsigned char *mem_param_18424, __global unsigned char *ext_mem_18496, __global unsigned char *mem_18498, __global unsigned char *counters_mem_18825, __global unsigned char *segred_tmp_mem_18827)\n{\n    #define segred_tblock_sizze_16969 (find_cluster_ids_6890zisegred_nonseg_16976zisegred_tblock_sizze_16969)\n    #define chunk_sizze_18824 (find_cluster_ids_6890zisegred_nonseg_16976zichunk_sizze_18824)\n    \n    volatile __local unsigned char *sync_arr_mem_18837_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_18837_backing_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_bool_mem_18835_backing_0 = &shared_mem[sync_arr_mem_18837_backing_1_offset];\n    const int64_t red_arr_bool_mem_18835_backing_0_offset = sync_arr_mem_18837_backing_1_offset + (segred_tblock_sizze_16969 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_16969, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18831;\n    int32_t tblock_sizze_18834;\n    int32_t wave_sizze_18833;\n    int32_t block_id_18832;\n    int32_t global_tid_18830;\n    int64_t phys_tid_16976;\n    __local unsigned char *red_arr_bool_mem_18835;\n    __local unsigned char *sync_arr_mem_18837;\n    int64_t dummy_16974;\n    int64_t gtid_16975;\n    int64_t q_18839;\n    bool eta_p_block_res_acc_18840;\n    bool eta_p_15586;\n    bool eta_p_15587;\n    int64_t tblock_id_in_segment_18844;\n    int64_t block_base_offset_18845;\n    int32_t offset_18848;\n    int32_t skip_waves_18849;\n    bool eta_p_18841;\n    bool eta_p_18842;\n    int32_t old_counter_18850;\n    bool is_last_block_18851;\n    \n    local_tid_18831 = get_local_id(0);\n    tblock_sizze_18834 = get_local_size(0);\n    wave_sizze_18833 = LOCKSTEP_WIDTH;\n    block_id_18832 = get_tblock_id(0);\n    global_tid_18830 = block_id_18832 * tblock_s", "izze_18834 + local_tid_18831;\n    phys_tid_16976 = sext_i32_i64(global_tid_18830);\n    red_arr_bool_mem_18835 = (__local unsigned char *) red_arr_bool_mem_18835_backing_0;\n    sync_arr_mem_18837 = (__local unsigned char *) sync_arr_mem_18837_backing_1;\n    dummy_16974 = (int64_t) 0;\n    gtid_16975 = (int64_t) 0;\n    q_18839 = sdiv_up64(n_14507, sext_i32_i64(sext_i64_i32(segred_tblock_sizze_16969 * num_tblocks_16971)) * chunk_sizze_18824);\n    // ne-initialise the outer (per-block) accumulator(s)\n    {\n        eta_p_block_res_acc_18840 = 1;\n    }\n    tblock_id_in_segment_18844 = squot64(phys_tid_16976, segred_tblock_sizze_16969);\n    block_base_offset_18845 = tblock_id_in_segment_18844 * q_18839 * segred_tblock_sizze_16969;\n    for (int64_t i_18846 = 0; i_18846 < q_18839; i_18846++) {\n        int64_t block_offset_18847 = block_base_offset_18845 + i_18846 * segred_tblock_sizze_16969;\n        \n        gtid_16975 = phys_tid_16976 + num_threads_18829 * i_18846;\n        if (slt64(gtid_16975, n_14507)) {\n            // apply map function(s)\n            {\n                // apply map function\n                {\n                    int64_t eta_p_16098 = ((__global int64_t *) mem_param_18424)[gtid_16975];\n                    int64_t eta_p_16099 = ((__global int64_t *) ext_mem_18496)[gtid_16975];\n                    bool defunc_0_f_res_16100 = eta_p_16098 == eta_p_16099;\n                    \n                    // load accumulator(s)\n                    {\n                        eta_p_15586 = eta_p_block_res_acc_18840;\n                    }\n                    // load next value(s)\n                    {\n                        eta_p_15587 = defunc_0_f_res_16100;\n                    }\n                    // apply reduction operator(s)\n                    {\n                        bool x_15588 = eta_p_15586 && eta_p_15587;\n                        \n                        // store in accumulator(s)\n                        {\n                            eta_p_block_res_acc_18840 = x", "_15588;\n                        }\n                    }\n                }\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // store accs. prims go in lmem; non-prims in params (in global mem)\n    {\n        ((__local bool *) red_arr_bool_mem_18835)[sext_i32_i64(local_tid_18831)] = eta_p_block_res_acc_18840;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    skip_waves_18849 = 1;\n    offset_18848 = 0;\n    // participating threads read initial accumulator\n    {\n        if (slt32(local_tid_18831, sext_i64_i32(segred_tblock_sizze_16969))) {\n            eta_p_18841 = ((__local bool *) red_arr_bool_mem_18835)[sext_i32_i64(local_tid_18831 + offset_18848)];\n        }\n    }\n    offset_18848 = 1;\n    while (slt32(offset_18848, wave_sizze_18833)) {\n        if (slt32(local_tid_18831 + offset_18848, sext_i64_i32(segred_tblock_sizze_16969)) && ((local_tid_18831 - squot32(local_tid_18831, wave_sizze_18833) * wave_sizze_18833) & (2 * offset_18848 - 1)) == 0) {\n            // read array element\n            {\n                eta_p_18842 = ((volatile __local bool *) red_arr_bool_mem_18835)[sext_i32_i64(local_tid_18831 + offset_18848)];\n            }\n            // apply reduction operation\n            {\n                bool x_18843 = eta_p_18841 && eta_p_18842;\n                \n                eta_p_18841 = x_18843;\n            }\n            // write result of operation\n            {\n                ((volatile __local bool *) red_arr_bool_mem_18835)[sext_i32_i64(local_tid_18831)] = eta_p_18841;\n            }\n        }\n        offset_18848 *= 2;\n    }\n    while (slt32(skip_waves_18849, squot32(sext_i64_i32(segred_tblock_sizze_16969) + wave_sizze_18833 - 1, wave_sizze_18833))) {\n        barrier(CLK_LOCAL_MEM_FENCE);\n        offset_18848 = skip_waves_18849 * wave_sizze_18833;\n        if (slt32(local_tid_18831 + offset_18848, sext_i64_i32(segred_tblock_sizze_16969)) && ((local_tid_18831 - squot32(local_tid_18831, wave_sizze_18833) * wave_sizze_18833) == 0 && (squot32(local_tid_",
                                    "18831, wave_sizze_18833) & (2 * skip_waves_18849 - 1)) == 0)) {\n            // read array element\n            {\n                eta_p_18842 = ((__local bool *) red_arr_bool_mem_18835)[sext_i32_i64(local_tid_18831 + offset_18848)];\n            }\n            // apply reduction operation\n            {\n                bool x_18843 = eta_p_18841 && eta_p_18842;\n                \n                eta_p_18841 = x_18843;\n            }\n            // write result of operation\n            {\n                ((__local bool *) red_arr_bool_mem_18835)[sext_i32_i64(local_tid_18831)] = eta_p_18841;\n            }\n        }\n        skip_waves_18849 *= 2;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // thread 0 updates per-block acc(s); rest reset to ne\n    {\n        if (sext_i32_i64(local_tid_18831) == (int64_t) 0) {\n            eta_p_block_res_acc_18840 = eta_p_18841;\n        } else {\n            eta_p_block_res_acc_18840 = 1;\n        }\n    }\n    // first thread in block saves block result to global memory\n    {\n        if (local_tid_18831 == 0) {\n            ((__global bool *) segred_tmp_mem_18827)[sext_i32_i64(block_id_18832)] = eta_p_block_res_acc_18840;\n            mem_fence_global();\n            old_counter_18850 = atomic_add_i32_global(&((volatile __global int *) counters_mem_18825)[(int64_t) 0], (int) 1);\n            ((__local bool *) sync_arr_mem_18837)[(int64_t) 0] = old_counter_18850 == sext_i64_i32(num_tblocks_16971 - (int64_t) 1);\n        }\n    }\n    barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    is_last_block_18851 = ((__local bool *) sync_arr_mem_18837)[(int64_t) 0];\n    if (is_last_block_18851) {\n        if (local_tid_18831 == 0) {\n            old_counter_18850 = atomic_add_i32_global(&((volatile __global int *) counters_mem_18825)[(int64_t) 0], (int) sext_i64_i32((int64_t) 0 - num_tblocks_16971));\n        }\n        // read in the per-block-results\n        {\n            int64_t read_per_thread_18852 = sdiv_up64(num_tblocks_1697", "1, segred_tblock_sizze_16969);\n            \n            eta_p_15586 = 1;\n            for (int64_t i_18853 = 0; i_18853 < read_per_thread_18852; i_18853++) {\n                int64_t block_res_id_18854 = sext_i32_i64(local_tid_18831) * read_per_thread_18852 + i_18853;\n                int64_t index_of_block_res_18855 = block_res_id_18854;\n                \n                if (slt64(block_res_id_18854, num_tblocks_16971)) {\n                    eta_p_15587 = ((__global bool *) segred_tmp_mem_18827)[index_of_block_res_18855];\n                    \n                    bool x_15588 = eta_p_15586 && eta_p_15587;\n                    \n                    eta_p_15586 = x_15588;\n                }\n            }\n        }\n        ((__local bool *) red_arr_bool_mem_18835)[sext_i32_i64(local_tid_18831)] = eta_p_15586;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // reduce the per-block results\n        {\n            int32_t offset_18856;\n            int32_t skip_waves_18857 = 1;\n            bool eta_p_18841;\n            bool eta_p_18842;\n            \n            offset_18856 = 0;\n            // participating threads read initial accumulator\n            {\n                if (slt32(local_tid_18831, sext_i64_i32(segred_tblock_sizze_16969))) {\n                    eta_p_18841 = ((__local bool *) red_arr_bool_mem_18835)[sext_i32_i64(local_tid_18831 + offset_18856)];\n                }\n            }\n            offset_18856 = 1;\n            while (slt32(offset_18856, wave_sizze_18833)) {\n                if (slt32(local_tid_18831 + offset_18856, sext_i64_i32(segred_tblock_sizze_16969)) && ((local_tid_18831 - squot32(local_tid_18831, wave_sizze_18833) * wave_sizze_18833) & (2 * offset_18856 - 1)) == 0) {\n                    // read array element\n                    {\n                        eta_p_18842 = ((volatile __local bool *) red_arr_bool_mem_18835)[sext_i32_i64(local_tid_18831 + offset_18856)];\n                    }\n                    // apply reduction operation\n                    {\n  ", "                      bool x_18843 = eta_p_18841 && eta_p_18842;\n                        \n                        eta_p_18841 = x_18843;\n                    }\n                    // write result of operation\n                    {\n                        ((volatile __local bool *) red_arr_bool_mem_18835)[sext_i32_i64(local_tid_18831)] = eta_p_18841;\n                    }\n                }\n                offset_18856 *= 2;\n            }\n            while (slt32(skip_waves_18857, squot32(sext_i64_i32(segred_tblock_sizze_16969) + wave_sizze_18833 - 1, wave_sizze_18833))) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                offset_18856 = skip_waves_18857 * wave_sizze_18833;\n                if (slt32(local_tid_18831 + offset_18856, sext_i64_i32(segred_tblock_sizze_16969)) && ((local_tid_18831 - squot32(local_tid_18831, wave_sizze_18833) * wave_sizze_18833) == 0 && (squot32(local_tid_18831, wave_sizze_18833) & (2 * skip_waves_18857 - 1)) == 0)) {\n                    // read array element\n                    {\n                        eta_p_18842 = ((__local bool *) red_arr_bool_mem_18835)[sext_i32_i64(local_tid_18831 + offset_18856)];\n                    }\n                    // apply reduction operation\n                    {\n                        bool x_18843 = eta_p_18841 && eta_p_18842;\n                        \n                        eta_p_18841 = x_18843;\n                    }\n                    // write result of operation\n                    {\n                        ((__local bool *) red_arr_bool_mem_18835)[sext_i32_i64(local_tid_18831)] = eta_p_18841;\n                    }\n                }\n                skip_waves_18857 *= 2;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // and back to memory with the final result\n            {\n                if (local_tid_18831 == 0) {\n                    ((__global bool *) mem_18498)[(int64_t) 0] = eta_p_18841;\n                }\n            }\n        }\n    }\n    \n  error_5:\n    return;\n  ",
                                    "  #undef segred_tblock_sizze_16969\n    #undef chunk_sizze_18824\n}\nFUTHARK_KERNEL_SIZED(find_cluster_ids_6890zisegred_small_16959_dim1, 1, 1)\nvoid find_cluster_ids_6890zisegred_small_16959(__global int *global_failure, int64_t n_14507, int64_t j_m_i_14549, int64_t num_tblocks_16954, int64_t segment_sizze_nonzzero_18731, __global unsigned char *mem_18453, __global unsigned char *mem_18456)\n{\n    #define segred_tblock_sizze_16953 (find_cluster_ids_6890zisegred_small_16959zisegred_tblock_sizze_16953)\n    \n    volatile __local unsigned char *red_arr_i64_mem_18738_backing_0 = &shared_mem[0];\n    const int64_t red_arr_i64_mem_18738_backing_0_offset = 0 + ((int64_t) 8 * segred_tblock_sizze_16953 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_16953, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18734;\n    int32_t tblock_sizze_18737;\n    int32_t wave_sizze_18736;\n    int32_t block_id_18735;\n    int32_t global_tid_18733;\n    int64_t phys_tid_16959;\n    __local unsigned char *red_arr_i64_mem_18738;\n    int32_t phys_tblock_id_18740;\n    int32_t iterations_18741;\n    \n    local_tid_18734 = get_local_id(0);\n    tblock_sizze_18737 = get_local_size(0);\n    wave_sizze_18736 = LOCKSTEP_WIDTH;\n    block_id_18735 = get_tblock_id(0);\n    global_tid_18733 = block_id_18735 * tblock_sizze_18737 + local_tid_18734;\n    phys_tid_16959 = sext_i32_i64(global_tid_18733);\n    red_arr_i64_mem_18738 = (__local unsigned char *) red_arr_i64_mem_18738_backing_0;\n    phys_tblock_id_18740 = get_tblock_id(0);\n    iterations_18741 = sdiv_up32(sext_i64_i32(sdiv_up64(j_m_i_14549, squot64(segred_tblock_sizze_16953, segment_sizze_nonzzero_18731))) - phys_tblock_id_18740, sext_i64_i32(num_tblocks_16954));\n    for (int32_t i_18742 = 0; i_18742 < iterations_18741; i_18742++) {\n        int32_t virt_tblock_id_18743;\n        int64_t slice_18744;\n        int64_t gtid_16957;\n        int64_t remnant_18745;\n        int64_t gtid_16958;\n        ", "\n        virt_tblock_id_18743 = phys_tblock_id_18740 + i_18742 * sext_i64_i32(num_tblocks_16954);\n        slice_18744 = j_m_i_14549;\n        gtid_16957 = squot64(sext_i32_i64(local_tid_18734), segment_sizze_nonzzero_18731) + sext_i32_i64(virt_tblock_id_18743) * squot64(segred_tblock_sizze_16953, segment_sizze_nonzzero_18731);\n        remnant_18745 = squot64(sext_i32_i64(local_tid_18734), segment_sizze_nonzzero_18731) + sext_i32_i64(virt_tblock_id_18743) * squot64(segred_tblock_sizze_16953, segment_sizze_nonzzero_18731) - gtid_16957;\n        gtid_16958 = srem64(sext_i32_i64(local_tid_18734), n_14507);\n        // apply map function if in bounds\n        {\n            if (slt64((int64_t) 0, n_14507) && (slt64(gtid_16957, j_m_i_14549) && slt64(sext_i32_i64(local_tid_18734), n_14507 * squot64(segred_tblock_sizze_16953, segment_sizze_nonzzero_18731)))) {\n                // apply map function\n                {\n                    int64_t x_16964 = ((__global int64_t *) mem_18453)[gtid_16957 * n_14507 + gtid_16958];\n                    \n                    // save results to be reduced\n                    {\n                        ((__local int64_t *) red_arr_i64_mem_18738)[sext_i32_i64(local_tid_18734)] = x_16964;\n                    }\n                }\n            } else {\n                ((__local int64_t *) red_arr_i64_mem_18738)[sext_i32_i64(local_tid_18734)] = (int64_t) 9223372036854775807;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (slt64((int64_t) 0, n_14507)) {\n            // perform segmented scan to imitate reduction\n            {\n                int64_t eta_p_16960;\n                int64_t eta_p_16961;\n                int64_t eta_p_18746;\n                int64_t eta_p_18747;\n                bool ltid_in_bounds_18749 = slt64(sext_i32_i64(local_tid_18734), n_14507 * squot64(segred_tblock_sizze_16953, segment_sizze_nonzzero_18731));\n                int32_t skip_threads_18750;\n                \n                // read input for in-block s", "can\n                {\n                    if (ltid_in_bounds_18749) {\n                        eta_p_16961 = ((volatile __local int64_t *) red_arr_i64_mem_18738)[sext_i32_i64(local_tid_18734)];\n                        if ((local_tid_18734 - squot32(local_tid_18734, 32) * 32) == 0) {\n                            eta_p_16960 = eta_p_16961;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_18750 = 1;\n                    while (slt32(skip_threads_18750, 32)) {\n                        bool thread_active_18751 = sle32(skip_threads_18750, local_tid_18734 - squot32(local_tid_18734, 32) * 32) && ltid_in_bounds_18749;\n                        \n                        if (thread_active_18751) {\n                            // read operands\n                            {\n                                eta_p_16960 = ((volatile __local int64_t *) red_arr_i64_mem_18738)[sext_i32_i64(local_tid_18734) - sext_i32_i64(skip_threads_18750)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            bool inactive_18752 = slt64(srem64(sext_i32_i64(local_tid_18734), n_14507), sext_i32_i64(local_tid_18734) - sext_i32_i64(local_tid_18734 - skip_threads_18750));\n                            \n                            if (thread_active_18751 && inactive_18752) {\n                                eta_p_16960 = eta_p_16961;\n                            }\n                            if (thread_active_18751) {\n                                if (!inactive_18752) {\n                                    int64_t min_res_16962 = smin64(eta_p_16960, eta_p_16961);\n                                    \n                                    eta_p_16960 = min_res_16962;\n                                }\n                            }\n                        }\n                        if (sle32(w",
                                    "ave_sizze_18736, skip_threads_18750)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_18751) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) red_arr_i64_mem_18738)[sext_i32_i64(local_tid_18734)] = eta_p_16960;\n                                eta_p_16961 = eta_p_16960;\n                            }\n                        }\n                        if (sle32(wave_sizze_18736, skip_threads_18750)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_18750 *= 2;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // last thread of block 'i' writes its result to offset 'i'\n                {\n                    if ((local_tid_18734 - squot32(local_tid_18734, 32) * 32) == 31 && ltid_in_bounds_18749) {\n                        ((volatile __local int64_t *) red_arr_i64_mem_18738)[sext_i32_i64(squot32(local_tid_18734, 32))] = eta_p_16960;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n                {\n                    int32_t skip_threads_18753;\n                    \n                    // read input for in-block scan\n                    {\n                        if (squot32(local_tid_18734, 32) == 0 && ltid_in_bounds_18749) {\n                            eta_p_18747 = ((volatile __local int64_t *) red_arr_i64_mem_18738)[sext_i32_i64(local_tid_18734)];\n                            if ((local_tid_18734 - squot32(local_tid_18734, 32) * 32) == 0) {\n                                eta_p_18746 = eta_p_18747;\n                            }\n                        }\n                    }\n                    // in-block scan (hopefully no barriers needed)\n          ", "          {\n                        skip_threads_18753 = 1;\n                        while (slt32(skip_threads_18753, 32)) {\n                            bool thread_active_18754 = sle32(skip_threads_18753, local_tid_18734 - squot32(local_tid_18734, 32) * 32) && (squot32(local_tid_18734, 32) == 0 && ltid_in_bounds_18749);\n                            \n                            if (thread_active_18754) {\n                                // read operands\n                                {\n                                    eta_p_18746 = ((volatile __local int64_t *) red_arr_i64_mem_18738)[sext_i32_i64(local_tid_18734) - sext_i32_i64(skip_threads_18753)];\n                                }\n                            }\n                            // perform operation\n                            {\n                                bool inactive_18755 = slt64(srem64(sext_i32_i64(local_tid_18734 * 32 + 32 - 1), n_14507), sext_i32_i64(local_tid_18734 * 32 + 32 - 1) - sext_i32_i64((local_tid_18734 - skip_threads_18753) * 32 + 32 - 1));\n                                \n                                if (thread_active_18754 && inactive_18755) {\n                                    eta_p_18746 = eta_p_18747;\n                                }\n                                if (thread_active_18754) {\n                                    if (!inactive_18755) {\n                                        int64_t min_res_18748 = smin64(eta_p_18746, eta_p_18747);\n                                        \n                                        eta_p_18746 = min_res_18748;\n                                    }\n                                }\n                            }\n                            if (sle32(wave_sizze_18736, skip_threads_18753)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            if (thread_active_18754) {\n                                // write result\n                                {\n                  ", "                  ((volatile __local int64_t *) red_arr_i64_mem_18738)[sext_i32_i64(local_tid_18734)] = eta_p_18746;\n                                    eta_p_18747 = eta_p_18746;\n                                }\n                            }\n                            if (sle32(wave_sizze_18736, skip_threads_18753)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            skip_threads_18753 *= 2;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                \n                bool no_carry_in_18756 = squot32(local_tid_18734, 32) == 0 || !ltid_in_bounds_18749;\n                \n                // carry-in for every block except the first\n                {\n                    // read operands\n                    {\n                        if (!no_carry_in_18756) {\n                            eta_p_16961 = eta_p_16960;\n                            eta_p_16960 = ((__local int64_t *) red_arr_i64_mem_18738)[sext_i32_i64(squot32(local_tid_18734, 32)) - (int64_t) 1];\n                        }\n                    }\n                    // perform operation\n                    {\n                        bool inactive_18757 = slt64(srem64(sext_i32_i64(local_tid_18734), n_14507), sext_i32_i64(local_tid_18734) - sext_i32_i64(squot32(local_tid_18734, 32) * 32 - 1));\n                        \n                        if (!no_carry_in_18756) {\n                            if (inactive_18757) {\n                                eta_p_16960 = eta_p_16961;\n                            }\n                        }\n                        if (!no_carry_in_18756) {\n                            if (!inactive_18757) {\n                                int64_t min_res_16962 = smin64(eta_p_16960, eta_p_16961);\n                                \n                                eta_p_16960 = min_res_16962;\n                            }\n                        }\n                   ",
                                    " }\n                    // write final result\n                    {\n                        if (!no_carry_in_18756) {\n                            ((__local int64_t *) red_arr_i64_mem_18738)[sext_i32_i64(local_tid_18734)] = eta_p_16960;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // restore correct values for first block\n                {\n                    if (squot32(local_tid_18734, 32) == 0 && ltid_in_bounds_18749) {\n                        ((__local int64_t *) red_arr_i64_mem_18738)[sext_i32_i64(local_tid_18734)] = eta_p_16961;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // save final values of segments\n        {\n            if (slt64(sext_i32_i64(virt_tblock_id_18743) * squot64(segred_tblock_sizze_16953, segment_sizze_nonzzero_18731) + sext_i32_i64(local_tid_18734), j_m_i_14549) && slt64(sext_i32_i64(local_tid_18734), squot64(segred_tblock_sizze_16953, segment_sizze_nonzzero_18731))) {\n                int64_t tmp_18758 = ((__local int64_t *) red_arr_i64_mem_18738)[(sext_i32_i64(local_tid_18734) + (int64_t) 1) * segment_sizze_nonzzero_18731 - (int64_t) 1];\n                \n                ((__global int64_t *) mem_18456)[sext_i32_i64(virt_tblock_id_18743) * squot64(segred_tblock_sizze_16953, segment_sizze_nonzzero_18731) + sext_i32_i64(local_tid_18734)] = tmp_18758;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_3:\n    return;\n    #undef segred_tblock_sizze_16953\n}\nFUTHARK_KERNEL_SIZED(find_cluster_ids_6890zisegscan_16984_dim1, 1, 1)\nvoid find_cluster_ids_6890zisegscan_16984(__global int *global_failure, int64_t n_14507, int64_t num_tblocks_16981, int64_t num_virt_blocks_18864, int64_t num_virt_threads_18865, __global unsigned char *ext_mem_18501, __global unsigned char *mem_1", "8504, __global unsigned char *status_flags_mem_18866, __global unsigned char *aggregates_mem_18888, __global unsigned char *incprefixes_mem_18890, __global unsigned char *global_dynid_mem_18892)\n{\n    #define segscan_tblock_sizze_16979 (find_cluster_ids_6890zisegscan_16984zisegscan_tblock_sizze_16979)\n    #define chunk_sizze_18863 (find_cluster_ids_6890zisegscan_16984zichunk_sizze_18863)\n    \n    volatile __local unsigned char *local_mem_18902_backing_0 = &shared_mem[0];\n    const int64_t local_mem_18902_backing_0_offset = 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_16979), chunk_sizze_18863 * segscan_tblock_sizze_16979 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_16979), chunk_sizze_18863 * segscan_tblock_sizze_16979 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18895;\n    int32_t tblock_sizze_18898;\n    int32_t wave_sizze_18897;\n    int32_t block_id_18896;\n    int32_t global_tid_18894;\n    int64_t phys_tid_16984;\n    int32_t chunk_sizze_32b_18899;\n    int64_t byte_offsets_18900;\n    int64_t warp_byte_offset_18901;\n    __local unsigned char *local_mem_18902;\n    int64_t trans_arr_len_18903;\n    int64_t phys_block_id_18909;\n    int64_t virtloop_bound_18910;\n    \n    local_tid_18895 = get_local_id(0);\n    tblock_sizze_18898 = get_local_size(0);\n    wave_sizze_18897 = LOCKSTEP_WIDTH;\n    block_id_18896 = get_tblock_id(0);\n    global_tid_18894 = block_id_18896 * tblock_sizze_18898 + local_tid_18895;\n    phys_tid_16984 = sext_i32_i64(global_tid_18894);\n    chunk_sizze_32b_18899 = sext_i64_i32(chunk_sizze_18863);\n    byte_offsets_18900 = segscan_tblock_sizze_16979 * (int64_t) 8;\n    warp_byte_offset_18901 = (int64_t) 288;\n    // Allocate reusable shared memory\n    { }\n    local_mem_18902 = (__local unsigned char *) local_mem_18902_backing_0;\n    trans_arr_len_18903 = chunk_sizze_18863 * segscan_tblock_sizze_", "16979;\n    phys_block_id_18909 = get_tblock_id(0);\n    virtloop_bound_18910 = sdiv_up64(num_virt_blocks_18864 - phys_block_id_18909, num_tblocks_16981);\n    for (int64_t virtloop_i_18911 = 0; virtloop_i_18911 < virtloop_bound_18910; virtloop_i_18911++) {\n        int64_t dynamic_id_18912;\n        int64_t block_offset_18913;\n        int64_t sgm_idx_18914;\n        int32_t boundary_18915;\n        int32_t segsizze_compact_18916;\n        int64_t private_mem_18917[chunk_sizze_18863];\n        int64_t thd_offset_18919;\n        int64_t acc_18935;\n        int64_t prefix_18945;\n        bool block_new_sgm_18946;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_18895 == 0) {\n                dynamic_id_18912 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_18892)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_18902)[(int64_t) 0] = dynamic_id_18912;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_18912 == num_virt_blocks_18864 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_18892)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_18912 = ((__local int32_t *) local_mem_18902)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_18913 = dynamic_id_18912 * chunk_sizze_18863 * segscan_tblock_sizze_16979;\n        sgm_idx_18914 = smod64(block_offset_18913, n_14507);\n        boundary_18915 = sext_i64_i32(smin64(chunk_sizze_18863 * segscan_tblock_sizze_16979, n_14507 - sgm_idx_18914));\n        segsizze_compact_18916 = sext_i64_i32(smin64(chunk_sizze_18863 * segscan_tblock_sizze_16979, n_14507));\n        thd_offset_18919 = block_offset_18913 + sext_i32_i64(local_tid_18895);\n   ",
                                    "     // Load and map\n        {\n            for (int64_t i_18920 = 0; i_18920 < chunk_sizze_18863; i_18920++) {\n                int64_t virt_tid_18921 = thd_offset_18919 + i_18920 * segscan_tblock_sizze_16979;\n                int64_t slice_18922 = n_14507;\n                int64_t gtid_16983 = virt_tid_18921;\n                int64_t remnant_18923 = virt_tid_18921 - gtid_16983;\n                \n                if (slt64(virt_tid_18921, n_14507)) {\n                    int64_t eta_p_16092 = ((__global int64_t *) ext_mem_18501)[gtid_16983];\n                    bool defunc_0_f_res_16093 = gtid_16983 == eta_p_16092;\n                    int64_t lifted_lambda_res_16095 = btoi_bool_i64(defunc_0_f_res_16093);\n                    \n                    private_mem_18917[i_18920] = lifted_lambda_res_16095;\n                } else {\n                    private_mem_18917[i_18920] = (int64_t) 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_18924 = 0; i_18924 < chunk_sizze_18863; i_18924++) {\n                int64_t sharedIdx_18925 = sext_i32_i64(local_tid_18895) + i_18924 * segscan_tblock_sizze_16979;\n                int64_t tmp_18926 = private_mem_18917[i_18924];\n                \n                ((__local int64_t *) local_mem_18902)[sharedIdx_18925] = tmp_18926;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_18927 = 0; i_18927 < chunk_sizze_18863; i_18927++) {\n                int64_t sharedIdx_18928 = sext_i32_i64(local_tid_18895) * chunk_sizze_18863 + i_18927;\n                int64_t tmp_18929 = ((__local int64_t *) local_mem_18902)[sharedIdx_18928];\n                \n                private_mem_18917[i_18927] = tmp_18929;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_18930 = 0; i_18930 < chunk_sizze_18863 - (int64_t) 1; i_18930++) {\n                int64_t eta_p_", "15681;\n                int64_t eta_p_15682;\n                \n                eta_p_15681 = private_mem_18917[i_18930];\n                eta_p_15682 = private_mem_18917[i_18930 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_15683 = add64(eta_p_15681, eta_p_15682);\n                \n                private_mem_18917[i_18930 + (int64_t) 1] = defunc_0_op_res_15683;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_18931 = private_mem_18917[chunk_sizze_18863 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_18902)[sext_i32_i64(local_tid_18895)] = tmp_18931;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_18932;\n            int64_t eta_p_18933;\n            int64_t eta_p_18936;\n            int64_t eta_p_18937;\n            bool ltid_in_bounds_18939 = slt64(sext_i32_i64(local_tid_18895), num_virt_threads_18865);\n            int32_t skip_threads_18940;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_18939) {\n                    eta_p_18933 = ((volatile __local int64_t *) local_mem_18902)[sext_i32_i64(local_tid_18895)];\n                    if ((local_tid_18895 - squot32(local_tid_18895, 32) * 32) == 0) {\n                        eta_p_18932 = eta_p_18933;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_18940 = 1;\n                while (slt32(skip_threads_18940, 32)) {\n                    bool thread_active_18941 = sle32(skip_threads_18940, local_tid_18895 - squot32(local_tid_18895, 32) * 32) && ltid_in_bounds_18939;\n                    \n                    if (thread_active_18941) {\n                        // read operands\n                        {\n                            eta_p_18932 = ((volatile __local int64_t *) local_mem_18902)[se", "xt_i32_i64(local_tid_18895) - sext_i32_i64(skip_threads_18940)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_18941) {\n                            int64_t defunc_0_op_res_18934 = add64(eta_p_18932, eta_p_18933);\n                            \n                            eta_p_18932 = defunc_0_op_res_18934;\n                        }\n                    }\n                    if (sle32(wave_sizze_18897, skip_threads_18940)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_18941) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_18902)[sext_i32_i64(local_tid_18895)] = eta_p_18932;\n                            eta_p_18933 = eta_p_18932;\n                        }\n                    }\n                    if (sle32(wave_sizze_18897, skip_threads_18940)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_18940 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_18895 - squot32(local_tid_18895, 32) * 32) == 31 && ltid_in_bounds_18939) {\n                    ((volatile __local int64_t *) local_mem_18902)[sext_i32_i64(squot32(local_tid_18895, 32))] = eta_p_18932;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_18942;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_18895, 32) == 0 && ltid_in_bounds_18939) {\n                        eta_p_18937 = ((volatile __local int64_t *) local_m",
                                    "em_18902)[sext_i32_i64(local_tid_18895)];\n                        if ((local_tid_18895 - squot32(local_tid_18895, 32) * 32) == 0) {\n                            eta_p_18936 = eta_p_18937;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_18942 = 1;\n                    while (slt32(skip_threads_18942, 32)) {\n                        bool thread_active_18943 = sle32(skip_threads_18942, local_tid_18895 - squot32(local_tid_18895, 32) * 32) && (squot32(local_tid_18895, 32) == 0 && ltid_in_bounds_18939);\n                        \n                        if (thread_active_18943) {\n                            // read operands\n                            {\n                                eta_p_18936 = ((volatile __local int64_t *) local_mem_18902)[sext_i32_i64(local_tid_18895) - sext_i32_i64(skip_threads_18942)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_18943) {\n                                int64_t defunc_0_op_res_18938 = add64(eta_p_18936, eta_p_18937);\n                                \n                                eta_p_18936 = defunc_0_op_res_18938;\n                            }\n                        }\n                        if (sle32(wave_sizze_18897, skip_threads_18942)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_18943) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_18902)[sext_i32_i64(local_tid_18895)] = eta_p_18936;\n                                eta_p_18937 = eta_p_18936;\n                            }\n                        }\n                        if (sle32(wave_sizze_18897, skip_threads_18942)) {\n                    ", "        barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_18942 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_18944 = squot32(local_tid_18895, 32) == 0 || !ltid_in_bounds_18939;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_18944) {\n                        eta_p_18933 = eta_p_18932;\n                        eta_p_18932 = ((__local int64_t *) local_mem_18902)[sext_i32_i64(squot32(local_tid_18895, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_18944) {\n                        int64_t defunc_0_op_res_18934 = add64(eta_p_18932, eta_p_18933);\n                        \n                        eta_p_18932 = defunc_0_op_res_18934;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_18944) {\n                        ((__local int64_t *) local_mem_18902)[sext_i32_i64(local_tid_18895)] = eta_p_18932;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_18895, 32) == 0 && ltid_in_bounds_18939) {\n                    ((__local int64_t *) local_mem_18902)[sext_i32_i64(local_tid_18895)] = eta_p_18933;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_18895 == 0) {\n                acc_18935 = ((__local int64_t *) local_mem_18902)[segscan_tblock_sizze_16979 - (int64_t) 1];\n            } else {\n                acc_18935 = ((__local int64_t *) local_mem_18902)[sext_i32_i64(local_tid_18895) - (int64_t) 1];\n ", "           }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_18945 = (int64_t) 0;\n        block_new_sgm_18946 = sgm_idx_18914 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_18946 && local_tid_18895 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_18890)[dynamic_id_18912] = acc_18935;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_18866)[dynamic_id_18912] = (int8_t) 2;\n                acc_18935 = (int64_t) 0;\n            }\n            if (!block_new_sgm_18946 && slt32(local_tid_18895, wave_sizze_18897)) {\n                if (local_tid_18895 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_18888)[dynamic_id_18912] = acc_18935;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_18866)[dynamic_id_18912] = (int8_t) 1;\n                    \n                    int8_t tmp_18947 = ((volatile __global int8_t *) status_flags_mem_18866)[dynamic_id_18912 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_18902)[(int64_t) 0] = tmp_18947;\n                }\n                mem_fence_local();\n                \n                int8_t status_18948 = ((__local int8_t *) local_mem_18902)[(int64_t) 0];\n                \n                if (status_18948 == (int8_t) 2) {\n                    if (local_tid_18895 == 0) {\n                        prefix_18945 = ((volatile __global int64_t *) incprefixes_mem_18890)[dynamic_id_18912 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_18949 = sext_i64_i32(dynamic_id_18912 - sext_i32_i64(wave_sizze_18897));\n                    \n                    while (slt32(wave_sizze_18897 * -1, readOffset_18949)) {\n                        int32_t read_i_18950 = readOffset_18949 + local_tid_18895;\n                        int64_t aggr_18951 = (int64_t) 0;\n        ",
                                    "                int8_t flag_18952 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_18950)) {\n                            flag_18952 = ((volatile __global int8_t *) status_flags_mem_18866)[sext_i32_i64(read_i_18950)];\n                            if (flag_18952 == (int8_t) 2) {\n                                aggr_18951 = ((volatile __global int64_t *) incprefixes_mem_18890)[sext_i32_i64(read_i_18950)];\n                            } else if (flag_18952 == (int8_t) 1) {\n                                aggr_18951 = ((volatile __global int64_t *) aggregates_mem_18888)[sext_i32_i64(read_i_18950)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_18902)[(int64_t) 4 + sext_i32_i64(local_tid_18895)] = aggr_18951;\n                        ((__local int8_t *) local_mem_18902)[sext_i32_i64(local_tid_18895)] = flag_18952;\n                        flag_18952 = ((__local int8_t *) local_mem_18902)[sext_i32_i64(wave_sizze_18897) - (int64_t) 1];\n                        if (slt8(flag_18952, (int8_t) 2)) {\n                            int8_t flg_x_18956;\n                            int8_t flg_y_18957;\n                            int64_t eta_p_18953;\n                            int64_t eta_p_18954;\n                            int32_t skip_threads_18958;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_18957 = ((volatile __local int8_t *) local_mem_18902)[sext_i32_i64(local_tid_18895)];\n                                eta_p_18954 = ((volatile __local int64_t *) local_mem_18902)[(int64_t) 4 + sext_i32_i64(local_tid_18895)];\n                                if ((local_tid_18895 - squot32(local_tid_18895, 32) * 32) == 0) {\n                                    eta_p_18953 = eta_p_18954;\n                                    flg_x_18956 = flg_y_18957;\n                                }\n             ", "               }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_18958 = 1;\n                                while (slt32(skip_threads_18958, 32)) {\n                                    if (sle32(skip_threads_18958, local_tid_18895 - squot32(local_tid_18895, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_18956 = ((volatile __local int8_t *) local_mem_18902)[sext_i32_i64(local_tid_18895) - sext_i32_i64(skip_threads_18958)];\n                                            eta_p_18953 = ((volatile __local int64_t *) local_mem_18902)[(int64_t) 4 + (sext_i32_i64(local_tid_18895) - sext_i32_i64(skip_threads_18958))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_18957 == (int8_t) 2 || flg_y_18957 == (int8_t) 0) {\n                                                flg_x_18956 = flg_y_18957;\n                                                eta_p_18953 = eta_p_18954;\n                                            } else {\n                                                int64_t defunc_0_op_res_18955 = add64(eta_p_18953, eta_p_18954);\n                                                \n                                                eta_p_18953 = defunc_0_op_res_18955;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_18902)[sext_i32_i64(local_tid_18895)] = flg_x_18956;\n                                            flg_y_18957 = flg_x_18956;\n                                            ((volatile __local int64_t *) l", "ocal_mem_18902)[(int64_t) 4 + sext_i32_i64(local_tid_18895)] = eta_p_18953;\n                                            eta_p_18954 = eta_p_18953;\n                                        }\n                                    }\n                                    skip_threads_18958 *= 2;\n                                }\n                            }\n                        }\n                        flag_18952 = ((__local int8_t *) local_mem_18902)[sext_i32_i64(wave_sizze_18897) - (int64_t) 1];\n                        aggr_18951 = ((__local int64_t *) local_mem_18902)[(int64_t) 4 + (sext_i32_i64(wave_sizze_18897) - (int64_t) 1)];\n                        if (flag_18952 == (int8_t) 2) {\n                            readOffset_18949 = wave_sizze_18897 * -1;\n                        } else if (flag_18952 == (int8_t) 1) {\n                            readOffset_18949 -= wave_sizze_18897;\n                        }\n                        if (slt8((int8_t) 0, flag_18952)) {\n                            int64_t eta_p_18959 = aggr_18951;\n                            int64_t eta_p_18960 = prefix_18945;\n                            int64_t defunc_0_op_res_18961 = add64(eta_p_18959, eta_p_18960);\n                            \n                            prefix_18945 = defunc_0_op_res_18961;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_18895 == 0) {\n                    if (boundary_18915 == sext_i64_i32(segscan_tblock_sizze_16979 * chunk_sizze_18863)) {\n                        int64_t eta_p_18962 = prefix_18945;\n                        int64_t eta_p_18963 = acc_18935;\n                        int64_t defunc_0_op_res_18964 = add64(eta_p_18962, eta_p_18963);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_18890)[dynamic_id_18912] = defunc_0_op_res_18964;\n                        mem_fence_global();\n                        ((volatile __global int8_t *)",
                                    " status_flags_mem_18866)[dynamic_id_18912] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_18902)[(int64_t) 4] = prefix_18945;\n                    acc_18935 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_18912 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_18945 = ((__local int64_t *) local_mem_18902)[(int64_t) 4];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_18965;\n            int64_t eta_p_18966;\n            int64_t eta_p_18968 = prefix_18945;\n            int64_t eta_p_18969 = acc_18935;\n            \n            if (slt32(local_tid_18895 * chunk_sizze_32b_18899, boundary_18915) && !block_new_sgm_18946) {\n                int64_t defunc_0_op_res_18970 = add64(eta_p_18968, eta_p_18969);\n                \n                eta_p_18965 = defunc_0_op_res_18970;\n            } else {\n                eta_p_18965 = acc_18935;\n            }\n            \n            int32_t stopping_point_18971 = segsizze_compact_18916 - srem32(local_tid_18895 * chunk_sizze_32b_18899 - 1 + segsizze_compact_18916 - boundary_18915, segsizze_compact_18916);\n            \n            for (int64_t i_18972 = 0; i_18972 < chunk_sizze_18863; i_18972++) {\n                if (slt32(sext_i64_i32(i_18972), stopping_point_18971 - 1)) {\n                    eta_p_18966 = private_mem_18917[i_18972];\n                    \n                    int64_t defunc_0_op_res_18967 = add64(eta_p_18965, eta_p_18966);\n                    \n                    private_mem_18917[i_18972] = defunc_0_op_res_18967;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_18973 = 0; i_18973 < chunk_sizze_18863; i_18973++) {\n                int64_t sharedIdx_18974 = sext_i32_i64(local_tid_18895) * chunk_sizze_18863 + i_18973;\n        ", "        int64_t tmp_18975 = private_mem_18917[i_18973];\n                \n                ((__local int64_t *) local_mem_18902)[sharedIdx_18974] = tmp_18975;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_18976 = 0; i_18976 < chunk_sizze_18863; i_18976++) {\n                int64_t flat_idx_18977 = thd_offset_18919 + i_18976 * segscan_tblock_sizze_16979;\n                int64_t slice_18978 = n_14507;\n                int64_t gtid_16983 = flat_idx_18977;\n                int64_t remnant_18979 = flat_idx_18977 - gtid_16983;\n                \n                if (slt64(flat_idx_18977, n_14507)) {\n                    int64_t tmp_18980 = ((__local int64_t *) local_mem_18902)[flat_idx_18977 - block_offset_18913];\n                    \n                    ((__global int64_t *) mem_18504)[gtid_16983] = tmp_18980;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_16979\n    #undef chunk_sizze_18863\n}\nFUTHARK_KERNEL_SIZED(ftDBSCAN_doublezisegmap_17435_dim1, 1, 1)\nvoid ftDBSCAN_doublezisegmap_17435(__global int *global_failure, int64_t nz2080U_15177, int64_t minPts_15181, __global unsigned char *ext_mem_18420, __global unsigned char *mem_18422)\n{\n    #define segmap_tblock_sizze_17431 (ftDBSCAN_doublezisegmap_17435zisegmap_tblock_sizze_17431)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18653;\n    int32_t tblock_sizze_18656;\n    int32_t wave_sizze_18655;\n    int32_t block_id_18654;\n    int32_t global_tid_18652;\n    int64_t phys_tid_17435;\n    int64_t global_tid_18657;\n    int64_t slice_18658;\n    int64_t gtid_17434;\n    int64_t remnant_18659;\n    \n    local_tid_18653 = get_local_id(0);\n    tblock_sizze_18656 = get_local_size(0);\n    wave_sizze_18655 = LOCKSTEP_WIDTH;\n    block_id_18654 = get_tblock_id(0);\n    global_tid_18652 = block_id_18654 * tblock_sizze_18656 + local_tid_18653;\n    phys_tid_17435 = sext_i32_i64(global_ti", "d_18652);\n    global_tid_18657 = sext_i32_i64(block_id_18654) * segmap_tblock_sizze_17431 + sext_i32_i64(local_tid_18653);\n    slice_18658 = nz2080U_15177;\n    gtid_17434 = global_tid_18657;\n    remnant_18659 = global_tid_18657 - gtid_17434;\n    if (slt64(gtid_17434, nz2080U_15177)) {\n        int64_t eta_p_17436;\n        bool lifted_lambda_res_17437;\n        \n        eta_p_17436 = ((__global int64_t *) ext_mem_18420)[gtid_17434];\n        lifted_lambda_res_17437 = sle64(minPts_15181, eta_p_17436);\n        ((__global bool *) mem_18422)[gtid_17434] = lifted_lambda_res_17437;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_17431\n}\nFUTHARK_KERNEL_SIZED(ftDBSCAN_doublezisegmap_17488_dim1, 1, 1)\nvoid ftDBSCAN_doublezisegmap_17488(__global int *global_failure, int64_t dimz2081U_15178, double eps_15180, int64_t corePts_15993, int64_t inf_16016, int64_t dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, int64_t num_threads_18588, __global unsigned char *dat_mem_18419, __global unsigned char *ext_mem_18423, __global unsigned char *ext_mem_18424, __global unsigned char *mem_18426, __global unsigned char *color_18526)\n{\n    #define segmap_tblock_sizze_17484 (ftDBSCAN_doublezisegmap_17488zisegmap_tblock_sizze_17484)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18684;\n    int32_t tblock_sizze_18687;\n    int32_t wave_sizze_18686;\n    int32_t block_id_18685;\n    int32_t global_tid_18683;\n    int64_t phys_tid_17488;\n    int64_t global_tid_18688;\n    int64_t slice_18689;\n    int64_t gtid_17487;\n    int64_t remnant_18690;\n    \n    local_tid_18684 = get_local_id(0);\n    tblock_sizze_18687 = get_local_size(0);\n    wave_sizze_18686 = LOCKSTEP_WIDTH;\n    block_id_18685 = get_tblock_id(0);\n    global_tid_18683 = block_id_18685 * tblock_sizze_18687 + local_tid_18684;\n    phys_tid_17488 = sext_i32_i64(global_tid_18683);\n    global_tid_18688 = sext_i32_i64(block_id_18685) * segmap_tblock_sizze_17484 + sext_i32_i64(local_tid_18684);\n    slice_18689 = dzlz7bUZL",
                                    "zmZRz20Usupz20Uinfz7dUzg_16019;\n    gtid_17487 = global_tid_18688;\n    remnant_18690 = global_tid_18688 - gtid_17487;\n    if (slt64(gtid_17487, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019)) {\n        int64_t slice_18395;\n        int64_t defunc_0_f_res_17490;\n        double defunc_0_f_res_17491;\n        int64_t redout_18406;\n        double redout_18407;\n        \n        slice_18395 = inf_16016 + gtid_17487;\n        redout_18406 = (int64_t) -1;\n        redout_18407 = INFINITY;\n        for (int64_t i_18408 = 0; i_18408 < corePts_15993; i_18408++) {\n            double defunc_0_f_res_17499;\n            double acc_17501;\n            double sqrt_res_17504;\n            bool zg_res_17509;\n            bool zg_res_17510;\n            bool x_17511;\n            int64_t lifted_lambda_res_17512;\n            double lifted_lambda_res_17513;\n            int64_t redout_tmp_18691;\n            double redout_tmp_18692;\n            \n            for (int64_t i_18411 = 0; i_18411 < dimz2081U_15178; i_18411++) {\n                double eta_p_17495;\n                double eta_p_17496;\n                double zm_res_17497;\n                double zt_res_17498;\n                \n                eta_p_17495 = ((__global double *) dat_mem_18419)[slice_18395 * dimz2081U_15178 + i_18411];\n                eta_p_17496 = ((__global double *) ext_mem_18423)[i_18408 * dimz2081U_15178 + i_18411];\n                zm_res_17497 = eta_p_17495 - eta_p_17496;\n                zt_res_17498 = zm_res_17497 * zm_res_17497;\n                ((__global double *) color_18526)[phys_tid_17488 + i_18411 * num_threads_18588] = zt_res_17498;\n            }\n            acc_17501 = 0.0;\n            for (int64_t i_17500 = 0; i_17500 < dimz2081U_15178; i_17500++) {\n                double b_17502;\n                double zp_res_17503;\n                double acc_tmp_18694;\n                \n                b_17502 = ((__global double *) color_18526)[phys_tid_17488 + i_17500 * num_threads_18588];\n                zp_res_17503 = acc_17501 + b_1", "7502;\n                acc_tmp_18694 = zp_res_17503;\n                acc_17501 = acc_tmp_18694;\n            }\n            defunc_0_f_res_17499 = acc_17501;\n            sqrt_res_17504 = futrts_sqrt64(defunc_0_f_res_17499);\n            zg_res_17509 = eps_15180 < redout_18407;\n            zg_res_17510 = eps_15180 < sqrt_res_17504;\n            x_17511 = zg_res_17509 && zg_res_17510;\n            if (x_17511) {\n                lifted_lambda_res_17512 = (int64_t) -1;\n                lifted_lambda_res_17513 = INFINITY;\n            } else {\n                bool zl_res_17514;\n                int64_t lifted_lambda_res_f_res_17515;\n                double lifted_lambda_res_f_res_17516;\n                \n                zl_res_17514 = redout_18407 < sqrt_res_17504;\n                if (zl_res_17514) {\n                    lifted_lambda_res_f_res_17515 = redout_18406;\n                } else {\n                    int64_t x_17493 = ((__global int64_t *) ext_mem_18424)[i_18408];\n                    \n                    lifted_lambda_res_f_res_17515 = x_17493;\n                }\n                if (zl_res_17514) {\n                    lifted_lambda_res_f_res_17516 = redout_18407;\n                } else {\n                    lifted_lambda_res_f_res_17516 = sqrt_res_17504;\n                }\n                lifted_lambda_res_17512 = lifted_lambda_res_f_res_17515;\n                lifted_lambda_res_17513 = lifted_lambda_res_f_res_17516;\n            }\n            redout_tmp_18691 = lifted_lambda_res_17512;\n            redout_tmp_18692 = lifted_lambda_res_17513;\n            redout_18406 = redout_tmp_18691;\n            redout_18407 = redout_tmp_18692;\n        }\n        defunc_0_f_res_17490 = redout_18406;\n        defunc_0_f_res_17491 = redout_18407;\n        ((__global int64_t *) mem_18426)[inf_16016 + gtid_17487] = defunc_0_f_res_17490;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_17484\n}\nFUTHARK_KERNEL_SIZED(ftDBSCAN_doublezisegmap_17742_dim1, 1, 1)\nvoid ftDBSCAN_doublezisegmap", "_17742(__global int *global_failure, int64_t dimz2081U_15178, int64_t corePts_15993, int64_t inf_16016, int64_t dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, __global unsigned char *dat_mem_18419, __global unsigned char *ext_mem_18423, __global unsigned char *mem_18434)\n{\n    #define segmap_tblock_sizze_17736 (ftDBSCAN_doublezisegmap_17742zisegmap_tblock_sizze_17736)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18717;\n    int32_t tblock_sizze_18720;\n    int32_t wave_sizze_18719;\n    int32_t block_id_18718;\n    int32_t global_tid_18716;\n    int64_t phys_tid_17742;\n    int64_t global_tid_18721;\n    int64_t slice_18722;\n    int64_t slice_18723;\n    int64_t slice_18724;\n    int64_t gtid_17739;\n    int64_t remnant_18725;\n    int64_t gtid_17740;\n    int64_t remnant_18726;\n    int64_t gtid_17741;\n    int64_t remnant_18727;\n    \n    local_tid_18717 = get_local_id(0);\n    tblock_sizze_18720 = get_local_size(0);\n    wave_sizze_18719 = LOCKSTEP_WIDTH;\n    block_id_18718 = get_tblock_id(0);\n    global_tid_18716 = block_id_18718 * tblock_sizze_18720 + local_tid_18717;\n    phys_tid_17742 = sext_i32_i64(global_tid_18716);\n    global_tid_18721 = sext_i32_i64(block_id_18718) * segmap_tblock_sizze_17736 + sext_i32_i64(local_tid_18717);\n    slice_18722 = dimz2081U_15178;\n    slice_18723 = corePts_15993 * slice_18722;\n    slice_18724 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019 * slice_18723;\n    gtid_17739 = squot64(global_tid_18721, slice_18723);\n    remnant_18725 = global_tid_18721 - gtid_17739 * slice_18723;\n    gtid_17740 = squot64(remnant_18725, slice_18722);\n    remnant_18726 = remnant_18725 - gtid_17740 * slice_18722;\n    gtid_17741 = remnant_18726;\n    remnant_18727 = remnant_18726 - gtid_17741;\n    if ((slt64(gtid_17739, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019) && slt64(gtid_17740, corePts_15993)) && slt64(gtid_17741, dimz2081U_15178)) {\n        int64_t slice_18397;\n        double eta_p_17743;\n        double eta_p_17744;\n        double zm_res_17745;\n      ",
                                    "  double zt_res_17746;\n        \n        slice_18397 = inf_16016 + gtid_17739;\n        eta_p_17743 = ((__global double *) dat_mem_18419)[slice_18397 * dimz2081U_15178 + gtid_17741];\n        eta_p_17744 = ((__global double *) ext_mem_18423)[gtid_17740 * dimz2081U_15178 + gtid_17741];\n        zm_res_17745 = eta_p_17743 - eta_p_17744;\n        zt_res_17746 = zm_res_17745 * zm_res_17745;\n        ((__global double *) mem_18434)[gtid_17739 * (dimz2081U_15178 * corePts_15993) + gtid_17740 * dimz2081U_15178 + gtid_17741] = zt_res_17746;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_17736\n}\nFUTHARK_KERNEL_SIZED(ftDBSCAN_doublezisegmap_17755_dim1, 1, 1)\nvoid ftDBSCAN_doublezisegmap_17755(__global int *global_failure, int64_t dimz2081U_15178, int64_t corePts_15993, int64_t dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, __global unsigned char *mem_18451, __global unsigned char *mem_18455)\n{\n    #define segmap_tblock_sizze_17750 (ftDBSCAN_doublezisegmap_17755zisegmap_tblock_sizze_17750)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18730;\n    int32_t tblock_sizze_18733;\n    int32_t wave_sizze_18732;\n    int32_t block_id_18731;\n    int32_t global_tid_18729;\n    int64_t phys_tid_17755;\n    int64_t global_tid_18734;\n    int64_t slice_18735;\n    int64_t slice_18736;\n    int64_t gtid_17753;\n    int64_t remnant_18737;\n    int64_t gtid_17754;\n    int64_t remnant_18738;\n    \n    local_tid_18730 = get_local_id(0);\n    tblock_sizze_18733 = get_local_size(0);\n    wave_sizze_18732 = LOCKSTEP_WIDTH;\n    block_id_18731 = get_tblock_id(0);\n    global_tid_18729 = block_id_18731 * tblock_sizze_18733 + local_tid_18730;\n    phys_tid_17755 = sext_i32_i64(global_tid_18729);\n    global_tid_18734 = sext_i32_i64(block_id_18731) * segmap_tblock_sizze_17750 + sext_i32_i64(local_tid_18730);\n    slice_18735 = corePts_15993;\n    slice_18736 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019 * slice_18735;\n    gtid_17753 = squot64(global_tid_18734, slice_18735);\n    remnant_18737", " = global_tid_18734 - gtid_17753 * slice_18735;\n    gtid_17754 = remnant_18737;\n    remnant_18738 = remnant_18737 - gtid_17754;\n    if (slt64(gtid_17753, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019) && slt64(gtid_17754, corePts_15993)) {\n        double defunc_0_f_res_17757;\n        double acc_17759;\n        double sqrt_res_17762;\n        \n        acc_17759 = 0.0;\n        for (int64_t i_17758 = 0; i_17758 < dimz2081U_15178; i_17758++) {\n            double b_17760;\n            double zp_res_17761;\n            double acc_tmp_18739;\n            \n            b_17760 = ((__global double *) mem_18451)[gtid_17753 * corePts_15993 + gtid_17754 + i_17758 * (corePts_15993 * dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019)];\n            zp_res_17761 = acc_17759 + b_17760;\n            acc_tmp_18739 = zp_res_17761;\n            acc_17759 = acc_tmp_18739;\n        }\n        defunc_0_f_res_17757 = acc_17759;\n        sqrt_res_17762 = futrts_sqrt64(defunc_0_f_res_17757);\n        ((__global double *) mem_18455)[gtid_17753 * corePts_15993 + gtid_17754] = sqrt_res_17762;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_17750\n}\nFUTHARK_KERNEL\nvoid ftDBSCAN_doublezisegmap_intrablock_17524(__global int *global_failure, int64_t dimz2081U_15178, double eps_15180, int64_t corePts_15993, int64_t inf_16016, int64_t dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, int64_t ctx_18604, __global unsigned char *dat_mem_18419, __global unsigned char *ext_mem_18423, __global unsigned char *ext_mem_18424, __global unsigned char *mem_18426, __global unsigned char *color_18527)\n{\n    volatile __local unsigned char *red_arr_mem_18709_backing_1 = &shared_mem[0];\n    const int64_t red_arr_mem_18709_backing_1_offset = 0 + ((int64_t) 8 * corePts_15993 + srem64((int64_t) 8 - srem64((int64_t) 8 * corePts_15993, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *red_arr_mem_18707_backing_0 = &shared_mem[red_arr_mem_18709_backing_1_offset];\n    const int64_t red_arr_mem_18707_backing_0_offset = red_arr_mem_", "18709_backing_1_offset + ((int64_t) 8 * corePts_15993 + srem64((int64_t) 8 - srem64((int64_t) 8 * corePts_15993, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18698;\n    int32_t tblock_sizze_18701;\n    int32_t wave_sizze_18700;\n    int32_t block_id_18699;\n    int32_t global_tid_18697;\n    int64_t phys_tblock_id_17524;\n    int64_t slice_18703;\n    int64_t ltid_pre_18702;\n    int64_t remnant_18704;\n    int64_t slice_18705;\n    int64_t gtid_17523;\n    int64_t remnant_18706;\n    int64_t slice_18396;\n    int64_t binop_x_18602;\n    int64_t defunc_0_f_res_17527;\n    double defunc_0_f_res_17528;\n    int64_t phys_tid_17530;\n    __local unsigned char *red_arr_mem_18707;\n    __local unsigned char *red_arr_mem_18709;\n    int64_t gtid_17529;\n    int64_t x_17544;\n    int64_t ctx_18603;\n    double defunc_0_f_res_17550;\n    double acc_17552;\n    double sqrt_res_17555;\n    int32_t offset_18713;\n    int32_t skip_waves_18714;\n    int64_t eta_p_17531;\n    double eta_p_17532;\n    int64_t eta_p_17533;\n    double eta_p_17534;\n    \n    local_tid_18698 = get_local_id(0);\n    tblock_sizze_18701 = get_local_size(0);\n    wave_sizze_18700 = LOCKSTEP_WIDTH;\n    block_id_18699 = get_tblock_id(0);\n    global_tid_18697 = block_id_18699 * tblock_sizze_18701 + local_tid_18698;\n    phys_tblock_id_17524 = sext_i32_i64(block_id_18699);\n    slice_18703 = corePts_15993;\n    ltid_pre_18702 = sext_i32_i64(local_tid_18698);\n    remnant_18704 = sext_i32_i64(local_tid_18698) - ltid_pre_18702;\n    slice_18705 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019;\n    gtid_17523 = sext_i32_i64(block_id_18699);\n    remnant_18706 = sext_i32_i64(block_id_18699) - gtid_17523;\n    slice_18396 = inf_16016 + gtid_17523;\n    binop_x_18602 = corePts_15993 * phys_tblock_id_17524;\n    phys_tid_17530 = sext_i32_i64(local_tid_18698);\n    red_arr_mem_18707 = (__local unsigned char *) red_arr_mem_18707_backing_0;\n    red_arr_mem_18709 = (__local unsigned char *) red_arr_mem_1870",
                                    "9_backing_1;\n    gtid_17529 = sext_i32_i64(sext_i64_i32(ltid_pre_18702));\n    x_17544 = ((__global int64_t *) ext_mem_18424)[gtid_17529];\n    ctx_18603 = phys_tid_17530 + binop_x_18602;\n    for (int64_t i_18415 = 0; i_18415 < dimz2081U_15178; i_18415++) {\n        double eta_p_17546;\n        double eta_p_17547;\n        double zm_res_17548;\n        double zt_res_17549;\n        \n        eta_p_17546 = ((__global double *) dat_mem_18419)[slice_18396 * dimz2081U_15178 + i_18415];\n        eta_p_17547 = ((__global double *) ext_mem_18423)[gtid_17529 * dimz2081U_15178 + i_18415];\n        zm_res_17548 = eta_p_17546 - eta_p_17547;\n        zt_res_17549 = zm_res_17548 * zm_res_17548;\n        ((__global double *) color_18527)[ctx_18603 + i_18415 * ctx_18604] = zt_res_17549;\n    }\n    acc_17552 = 0.0;\n    for (int64_t i_17551 = 0; i_17551 < dimz2081U_15178; i_17551++) {\n        double b_17553;\n        double zp_res_17554;\n        double acc_tmp_18712;\n        \n        b_17553 = ((__global double *) color_18527)[ctx_18603 + i_17551 * ctx_18604];\n        zp_res_17554 = acc_17552 + b_17553;\n        acc_tmp_18712 = zp_res_17554;\n        acc_17552 = acc_tmp_18712;\n    }\n    defunc_0_f_res_17550 = acc_17552;\n    sqrt_res_17555 = futrts_sqrt64(defunc_0_f_res_17550);\n    ((__local int64_t *) red_arr_mem_18707)[gtid_17529] = x_17544;\n    ((__local double *) red_arr_mem_18709)[gtid_17529] = sqrt_res_17555;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    skip_waves_18714 = 1;\n    offset_18713 = 0;\n    // participating threads read initial accumulator\n    {\n        if (slt32(local_tid_18698, sext_i64_i32(corePts_15993))) {\n            eta_p_17531 = ((__local int64_t *) red_arr_mem_18707)[sext_i32_i64(local_tid_18698 + offset_18713)];\n            eta_p_17532 = ((__local double *) red_arr_mem_18709)[sext_i32_i64(local_tid_18698 + offset_18713)];\n        }\n    }\n    offset_18713 = 1;\n    while (slt32(offset_18713, wave_sizze_18700)) {\n        if (slt32(local_tid_18698 + offset_18713, sext_i64_i32(corePts_", "15993)) && ((local_tid_18698 - squot32(local_tid_18698, wave_sizze_18700) * wave_sizze_18700) & (2 * offset_18713 - 1)) == 0) {\n            // read array element\n            {\n                eta_p_17533 = ((volatile __local int64_t *) red_arr_mem_18707)[sext_i32_i64(local_tid_18698 + offset_18713)];\n                eta_p_17534 = ((volatile __local double *) red_arr_mem_18709)[sext_i32_i64(local_tid_18698 + offset_18713)];\n            }\n            // apply reduction operation\n            {\n                bool zg_res_17535 = eps_15180 < eta_p_17532;\n                bool zg_res_17536 = eps_15180 < eta_p_17534;\n                bool x_17537 = zg_res_17535 && zg_res_17536;\n                int64_t lifted_lambda_res_17538;\n                double lifted_lambda_res_17539;\n                \n                if (x_17537) {\n                    lifted_lambda_res_17538 = (int64_t) -1;\n                    lifted_lambda_res_17539 = INFINITY;\n                } else {\n                    bool zl_res_17540 = eta_p_17532 < eta_p_17534;\n                    int64_t lifted_lambda_res_f_res_17541;\n                    \n                    if (zl_res_17540) {\n                        lifted_lambda_res_f_res_17541 = eta_p_17531;\n                    } else {\n                        lifted_lambda_res_f_res_17541 = eta_p_17533;\n                    }\n                    \n                    double lifted_lambda_res_f_res_17542;\n                    \n                    if (zl_res_17540) {\n                        lifted_lambda_res_f_res_17542 = eta_p_17532;\n                    } else {\n                        lifted_lambda_res_f_res_17542 = eta_p_17534;\n                    }\n                    lifted_lambda_res_17538 = lifted_lambda_res_f_res_17541;\n                    lifted_lambda_res_17539 = lifted_lambda_res_f_res_17542;\n                }\n                eta_p_17531 = lifted_lambda_res_17538;\n                eta_p_17532 = lifted_lambda_res_17539;\n            }\n            // write result of ope", "ration\n            {\n                ((volatile __local int64_t *) red_arr_mem_18707)[sext_i32_i64(local_tid_18698)] = eta_p_17531;\n                ((volatile __local double *) red_arr_mem_18709)[sext_i32_i64(local_tid_18698)] = eta_p_17532;\n            }\n        }\n        offset_18713 *= 2;\n    }\n    while (slt32(skip_waves_18714, squot32(sext_i64_i32(corePts_15993) + wave_sizze_18700 - 1, wave_sizze_18700))) {\n        barrier(CLK_LOCAL_MEM_FENCE);\n        offset_18713 = skip_waves_18714 * wave_sizze_18700;\n        if (slt32(local_tid_18698 + offset_18713, sext_i64_i32(corePts_15993)) && ((local_tid_18698 - squot32(local_tid_18698, wave_sizze_18700) * wave_sizze_18700) == 0 && (squot32(local_tid_18698, wave_sizze_18700) & (2 * skip_waves_18714 - 1)) == 0)) {\n            // read array element\n            {\n                eta_p_17533 = ((__local int64_t *) red_arr_mem_18707)[sext_i32_i64(local_tid_18698 + offset_18713)];\n                eta_p_17534 = ((__local double *) red_arr_mem_18709)[sext_i32_i64(local_tid_18698 + offset_18713)];\n            }\n            // apply reduction operation\n            {\n                bool zg_res_17535 = eps_15180 < eta_p_17532;\n                bool zg_res_17536 = eps_15180 < eta_p_17534;\n                bool x_17537 = zg_res_17535 && zg_res_17536;\n                int64_t lifted_lambda_res_17538;\n                double lifted_lambda_res_17539;\n                \n                if (x_17537) {\n                    lifted_lambda_res_17538 = (int64_t) -1;\n                    lifted_lambda_res_17539 = INFINITY;\n                } else {\n                    bool zl_res_17540 = eta_p_17532 < eta_p_17534;\n                    int64_t lifted_lambda_res_f_res_17541;\n                    \n                    if (zl_res_17540) {\n                        lifted_lambda_res_f_res_17541 = eta_p_17531;\n                    } else {\n                        lifted_lambda_res_f_res_17541 = eta_p_17533;\n                    }\n                    \n              ",
                                    "      double lifted_lambda_res_f_res_17542;\n                    \n                    if (zl_res_17540) {\n                        lifted_lambda_res_f_res_17542 = eta_p_17532;\n                    } else {\n                        lifted_lambda_res_f_res_17542 = eta_p_17534;\n                    }\n                    lifted_lambda_res_17538 = lifted_lambda_res_f_res_17541;\n                    lifted_lambda_res_17539 = lifted_lambda_res_f_res_17542;\n                }\n                eta_p_17531 = lifted_lambda_res_17538;\n                eta_p_17532 = lifted_lambda_res_17539;\n            }\n            // write result of operation\n            {\n                ((__local int64_t *) red_arr_mem_18707)[sext_i32_i64(local_tid_18698)] = eta_p_17531;\n                ((__local double *) red_arr_mem_18709)[sext_i32_i64(local_tid_18698)] = eta_p_17532;\n            }\n        }\n        skip_waves_18714 *= 2;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // Save result of reduction.\n    {\n        defunc_0_f_res_17527 = ((__local int64_t *) red_arr_mem_18707)[(int64_t) 0];\n        defunc_0_f_res_17528 = ((__local double *) red_arr_mem_18709)[(int64_t) 0];\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    if (local_tid_18698 == 0) {\n        ((__global int64_t *) mem_18426)[inf_16016 + gtid_17523] = defunc_0_f_res_17527;\n    }\n    \n  error_4:\n    return;\n}\nFUTHARK_KERNEL_SIZED(ftDBSCAN_doublezisegred_large_17774_dim1, 1, 1)\nvoid ftDBSCAN_doublezisegred_large_17774(__global int *global_failure, double eps_15180, int64_t corePts_15993, int64_t inf_16016, int64_t dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, int64_t num_tblocks_17768, int64_t blocks_per_segment_18781, int64_t q_18782, int64_t num_virtblocks_18783, int64_t threads_per_segment_18784, __global unsigned char *ext_mem_18424, __global unsigned char *mem_18426, __global unsigned char *mem_18455, __global unsigned char *mem_18460, __global unsigned char *segred_tmp_mem_18785, __global unsigned char *segred_tmp_m", "em_18787, __global unsigned char *counters_mem_18789)\n{\n    #define segred_tblock_sizze_17767 (ftDBSCAN_doublezisegred_large_17774zisegred_tblock_sizze_17767)\n    #define chunk_sizze_18740 (ftDBSCAN_doublezisegred_large_17774zichunk_sizze_18740)\n    \n    volatile __local unsigned char *sync_arr_mem_18820_backing_2 = &shared_mem[0];\n    const int64_t sync_arr_mem_18820_backing_2_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_f64_mem_18818_backing_1 = &shared_mem[sync_arr_mem_18820_backing_2_offset];\n    const int64_t red_arr_f64_mem_18818_backing_1_offset = sync_arr_mem_18820_backing_2_offset + ((int64_t) 8 * segred_tblock_sizze_17767 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_17767, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *red_arr_i64_mem_18816_backing_0 = &shared_mem[red_arr_f64_mem_18818_backing_1_offset];\n    const int64_t red_arr_i64_mem_18816_backing_0_offset = red_arr_f64_mem_18818_backing_1_offset + ((int64_t) 8 * segred_tblock_sizze_17767 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_17767, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18812;\n    int32_t tblock_sizze_18815;\n    int32_t wave_sizze_18814;\n    int32_t block_id_18813;\n    int32_t global_tid_18811;\n    int64_t phys_tid_17774;\n    __local unsigned char *red_arr_i64_mem_18816;\n    __local unsigned char *red_arr_f64_mem_18818;\n    __local unsigned char *sync_arr_mem_18820;\n    int32_t phys_tblock_id_18822;\n    int32_t iterations_18823;\n    \n    local_tid_18812 = get_local_id(0);\n    tblock_sizze_18815 = get_local_size(0);\n    wave_sizze_18814 = LOCKSTEP_WIDTH;\n    block_id_18813 = get_tblock_id(0);\n    global_tid_18811 = block_id_18813 * tblock_sizze_18815 + local_tid_18812;\n    phys_tid_17774 = sext_i32_i64(global_tid_18811);\n    red_arr_i64_mem_18816 = (__local unsigned char *) red_arr_i64_mem_18816_backing_0;\n    red_arr_f64_mem_18818 = (__local unsigned char *)", " red_arr_f64_mem_18818_backing_1;\n    sync_arr_mem_18820 = (__local unsigned char *) sync_arr_mem_18820_backing_2;\n    phys_tblock_id_18822 = get_tblock_id(0);\n    iterations_18823 = sdiv_up32(sext_i64_i32(num_virtblocks_18783) - phys_tblock_id_18822, sext_i64_i32(num_tblocks_17768));\n    for (int32_t i_18824 = 0; i_18824 < iterations_18823; i_18824++) {\n        int32_t virt_tblock_id_18825;\n        int64_t flat_segment_id_18826;\n        int64_t global_tid_18827;\n        int64_t slice_18828;\n        int64_t gtid_17772;\n        int64_t remnant_18829;\n        int64_t gtid_17773;\n        int64_t eta_p_block_res_acc_18830;\n        double eta_p_block_res_acc_18831;\n        int64_t eta_p_17775;\n        double eta_p_17776;\n        int64_t eta_p_17777;\n        double eta_p_17778;\n        int64_t tblock_id_in_segment_18844;\n        int64_t block_base_offset_18845;\n        int32_t offset_18848;\n        int32_t skip_waves_18849;\n        int64_t eta_p_18832;\n        double eta_p_18833;\n        int64_t eta_p_18834;\n        double eta_p_18835;\n        \n        virt_tblock_id_18825 = phys_tblock_id_18822 + i_18824 * sext_i64_i32(num_tblocks_17768);\n        flat_segment_id_18826 = squot64(sext_i32_i64(virt_tblock_id_18825), blocks_per_segment_18781);\n        global_tid_18827 = srem64(sext_i32_i64(virt_tblock_id_18825) * segred_tblock_sizze_17767 + sext_i32_i64(local_tid_18812), threads_per_segment_18784);\n        slice_18828 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019;\n        gtid_17772 = flat_segment_id_18826;\n        remnant_18829 = flat_segment_id_18826 - gtid_17772;\n        // ne-initialise the outer (per-block) accumulator(s)\n        {\n            eta_p_block_res_acc_18830 = (int64_t) -1;\n            eta_p_block_res_acc_18831 = INFINITY;\n        }\n        tblock_id_in_segment_18844 = squot64(global_tid_18827, segred_tblock_sizze_17767);\n        block_base_offset_18845 = tblock_id_in_segment_18844 * q_18782 * segred_tblock_sizze_17767;\n        for (int64_t i_18846 = 0; i_18846 <",
                                    " q_18782; i_18846++) {\n            int64_t block_offset_18847 = block_base_offset_18845 + i_18846 * segred_tblock_sizze_17767;\n            \n            gtid_17773 = global_tid_18827 + threads_per_segment_18784 * i_18846;\n            if (slt64(gtid_17773, corePts_15993)) {\n                // apply map function(s)\n                {\n                    // apply map function\n                    {\n                        int64_t x_17789 = ((__global int64_t *) ext_mem_18424)[gtid_17773];\n                        double x_17790 = ((__global double *) mem_18455)[gtid_17772 * corePts_15993 + gtid_17773];\n                        \n                        // load accumulator(s)\n                        {\n                            eta_p_17775 = eta_p_block_res_acc_18830;\n                            eta_p_17776 = eta_p_block_res_acc_18831;\n                        }\n                        // load next value(s)\n                        {\n                            eta_p_17777 = x_17789;\n                            eta_p_17778 = x_17790;\n                        }\n                        // apply reduction operator(s)\n                        {\n                            bool zg_res_17779 = eps_15180 < eta_p_17776;\n                            bool zg_res_17780 = eps_15180 < eta_p_17778;\n                            bool x_17781 = zg_res_17779 && zg_res_17780;\n                            int64_t lifted_lambda_res_17782;\n                            double lifted_lambda_res_17783;\n                            \n                            if (x_17781) {\n                                lifted_lambda_res_17782 = (int64_t) -1;\n                                lifted_lambda_res_17783 = INFINITY;\n                            } else {\n                                bool zl_res_17784 = eta_p_17776 < eta_p_17778;\n                                int64_t lifted_lambda_res_f_res_17785;\n                                \n                                if (zl_res_17784) {\n                              ", "      lifted_lambda_res_f_res_17785 = eta_p_17775;\n                                } else {\n                                    lifted_lambda_res_f_res_17785 = eta_p_17777;\n                                }\n                                \n                                double lifted_lambda_res_f_res_17786;\n                                \n                                if (zl_res_17784) {\n                                    lifted_lambda_res_f_res_17786 = eta_p_17776;\n                                } else {\n                                    lifted_lambda_res_f_res_17786 = eta_p_17778;\n                                }\n                                lifted_lambda_res_17782 = lifted_lambda_res_f_res_17785;\n                                lifted_lambda_res_17783 = lifted_lambda_res_f_res_17786;\n                            }\n                            // store in accumulator(s)\n                            {\n                                eta_p_block_res_acc_18830 = lifted_lambda_res_17782;\n                                eta_p_block_res_acc_18831 = lifted_lambda_res_17783;\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // store accs. prims go in lmem; non-prims in params (in global mem)\n        {\n            ((__local int64_t *) red_arr_i64_mem_18816)[sext_i32_i64(local_tid_18812)] = eta_p_block_res_acc_18830;\n            ((__local double *) red_arr_f64_mem_18818)[sext_i32_i64(local_tid_18812)] = eta_p_block_res_acc_18831;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        skip_waves_18849 = 1;\n        offset_18848 = 0;\n        // participating threads read initial accumulator\n        {\n            if (slt32(local_tid_18812, sext_i64_i32(segred_tblock_sizze_17767))) {\n                eta_p_18832 = ((__local int64_t *) red_arr_i64_mem_18816)[sext_i32_i64(local_tid_18812 + offset_18848)];\n                eta_p_18833 = ((__local double *) red", "_arr_f64_mem_18818)[sext_i32_i64(local_tid_18812 + offset_18848)];\n            }\n        }\n        offset_18848 = 1;\n        while (slt32(offset_18848, wave_sizze_18814)) {\n            if (slt32(local_tid_18812 + offset_18848, sext_i64_i32(segred_tblock_sizze_17767)) && ((local_tid_18812 - squot32(local_tid_18812, wave_sizze_18814) * wave_sizze_18814) & (2 * offset_18848 - 1)) == 0) {\n                // read array element\n                {\n                    eta_p_18834 = ((volatile __local int64_t *) red_arr_i64_mem_18816)[sext_i32_i64(local_tid_18812 + offset_18848)];\n                    eta_p_18835 = ((volatile __local double *) red_arr_f64_mem_18818)[sext_i32_i64(local_tid_18812 + offset_18848)];\n                }\n                // apply reduction operation\n                {\n                    bool zg_res_18836 = eps_15180 < eta_p_18833;\n                    bool zg_res_18837 = eps_15180 < eta_p_18835;\n                    bool x_18838 = zg_res_18836 && zg_res_18837;\n                    int64_t lifted_lambda_res_18839;\n                    double lifted_lambda_res_18840;\n                    \n                    if (x_18838) {\n                        lifted_lambda_res_18839 = (int64_t) -1;\n                        lifted_lambda_res_18840 = INFINITY;\n                    } else {\n                        bool zl_res_18841 = eta_p_18833 < eta_p_18835;\n                        int64_t lifted_lambda_res_f_res_18842;\n                        \n                        if (zl_res_18841) {\n                            lifted_lambda_res_f_res_18842 = eta_p_18832;\n                        } else {\n                            lifted_lambda_res_f_res_18842 = eta_p_18834;\n                        }\n                        \n                        double lifted_lambda_res_f_res_18843;\n                        \n                        if (zl_res_18841) {\n                            lifted_lambda_res_f_res_18843 = eta_p_18833;\n                        } else {\n                            l",
                                    "ifted_lambda_res_f_res_18843 = eta_p_18835;\n                        }\n                        lifted_lambda_res_18839 = lifted_lambda_res_f_res_18842;\n                        lifted_lambda_res_18840 = lifted_lambda_res_f_res_18843;\n                    }\n                    eta_p_18832 = lifted_lambda_res_18839;\n                    eta_p_18833 = lifted_lambda_res_18840;\n                }\n                // write result of operation\n                {\n                    ((volatile __local int64_t *) red_arr_i64_mem_18816)[sext_i32_i64(local_tid_18812)] = eta_p_18832;\n                    ((volatile __local double *) red_arr_f64_mem_18818)[sext_i32_i64(local_tid_18812)] = eta_p_18833;\n                }\n            }\n            offset_18848 *= 2;\n        }\n        while (slt32(skip_waves_18849, squot32(sext_i64_i32(segred_tblock_sizze_17767) + wave_sizze_18814 - 1, wave_sizze_18814))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_18848 = skip_waves_18849 * wave_sizze_18814;\n            if (slt32(local_tid_18812 + offset_18848, sext_i64_i32(segred_tblock_sizze_17767)) && ((local_tid_18812 - squot32(local_tid_18812, wave_sizze_18814) * wave_sizze_18814) == 0 && (squot32(local_tid_18812, wave_sizze_18814) & (2 * skip_waves_18849 - 1)) == 0)) {\n                // read array element\n                {\n                    eta_p_18834 = ((__local int64_t *) red_arr_i64_mem_18816)[sext_i32_i64(local_tid_18812 + offset_18848)];\n                    eta_p_18835 = ((__local double *) red_arr_f64_mem_18818)[sext_i32_i64(local_tid_18812 + offset_18848)];\n                }\n                // apply reduction operation\n                {\n                    bool zg_res_18836 = eps_15180 < eta_p_18833;\n                    bool zg_res_18837 = eps_15180 < eta_p_18835;\n                    bool x_18838 = zg_res_18836 && zg_res_18837;\n                    int64_t lifted_lambda_res_18839;\n                    double lifted_lambda_res_18840;\n                    \n                   ", " if (x_18838) {\n                        lifted_lambda_res_18839 = (int64_t) -1;\n                        lifted_lambda_res_18840 = INFINITY;\n                    } else {\n                        bool zl_res_18841 = eta_p_18833 < eta_p_18835;\n                        int64_t lifted_lambda_res_f_res_18842;\n                        \n                        if (zl_res_18841) {\n                            lifted_lambda_res_f_res_18842 = eta_p_18832;\n                        } else {\n                            lifted_lambda_res_f_res_18842 = eta_p_18834;\n                        }\n                        \n                        double lifted_lambda_res_f_res_18843;\n                        \n                        if (zl_res_18841) {\n                            lifted_lambda_res_f_res_18843 = eta_p_18833;\n                        } else {\n                            lifted_lambda_res_f_res_18843 = eta_p_18835;\n                        }\n                        lifted_lambda_res_18839 = lifted_lambda_res_f_res_18842;\n                        lifted_lambda_res_18840 = lifted_lambda_res_f_res_18843;\n                    }\n                    eta_p_18832 = lifted_lambda_res_18839;\n                    eta_p_18833 = lifted_lambda_res_18840;\n                }\n                // write result of operation\n                {\n                    ((__local int64_t *) red_arr_i64_mem_18816)[sext_i32_i64(local_tid_18812)] = eta_p_18832;\n                    ((__local double *) red_arr_f64_mem_18818)[sext_i32_i64(local_tid_18812)] = eta_p_18833;\n                }\n            }\n            skip_waves_18849 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // thread 0 updates per-block acc(s); rest reset to ne\n        {\n            if (sext_i32_i64(local_tid_18812) == (int64_t) 0) {\n                eta_p_block_res_acc_18830 = eta_p_18832;\n                eta_p_block_res_acc_18831 = eta_p_18833;\n            } else {\n                eta_p_block_res_acc", "_18830 = (int64_t) -1;\n                eta_p_block_res_acc_18831 = INFINITY;\n            }\n        }\n        if (blocks_per_segment_18781 == (int64_t) 1) {\n            // first thread in block saves final result to memory\n            {\n                if (local_tid_18812 == 0) {\n                    ((__global int64_t *) mem_18426)[inf_16016 + gtid_17772] = eta_p_block_res_acc_18830;\n                    ((__global double *) mem_18460)[gtid_17772] = eta_p_block_res_acc_18831;\n                }\n            }\n        } else {\n            int32_t old_counter_18850;\n            bool is_last_block_18851;\n            \n            // first thread in block saves block result to global memory\n            {\n                if (local_tid_18812 == 0) {\n                    ((__global int64_t *) segred_tmp_mem_18785)[sext_i32_i64(virt_tblock_id_18825)] = eta_p_block_res_acc_18830;\n                    mem_fence_global();\n                    ((__global double *) segred_tmp_mem_18787)[sext_i32_i64(virt_tblock_id_18825)] = eta_p_block_res_acc_18831;\n                    mem_fence_global();\n                    old_counter_18850 = atomic_add_i32_global(&((volatile __global int *) counters_mem_18789)[srem64(flat_segment_id_18826, (int64_t) 20480)], (int) 1);\n                    ((__local bool *) sync_arr_mem_18820)[(int64_t) 0] = old_counter_18850 == sext_i64_i32(blocks_per_segment_18781 - (int64_t) 1);\n                }\n            }\n            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n            is_last_block_18851 = ((__local bool *) sync_arr_mem_18820)[(int64_t) 0];\n            if (is_last_block_18851) {\n                if (local_tid_18812 == 0) {\n                    old_counter_18850 = atomic_add_i32_global(&((volatile __global int *) counters_mem_18789)[srem64(flat_segment_id_18826, (int64_t) 20480)], (int) sext_i64_i32((int64_t) 0 - blocks_per_segment_18781));\n                }\n                // read in the per-block-results\n                {\n                    int64_",
                                    "t read_per_thread_18852 = sdiv_up64(blocks_per_segment_18781, segred_tblock_sizze_17767);\n                    \n                    eta_p_17775 = (int64_t) -1;\n                    eta_p_17776 = INFINITY;\n                    for (int64_t i_18853 = 0; i_18853 < read_per_thread_18852; i_18853++) {\n                        int64_t block_res_id_18854 = sext_i32_i64(local_tid_18812) * read_per_thread_18852 + i_18853;\n                        int64_t index_of_block_res_18855 = flat_segment_id_18826 * blocks_per_segment_18781 + block_res_id_18854;\n                        \n                        if (slt64(block_res_id_18854, blocks_per_segment_18781)) {\n                            eta_p_17777 = ((__global int64_t *) segred_tmp_mem_18785)[index_of_block_res_18855];\n                            eta_p_17778 = ((__global double *) segred_tmp_mem_18787)[index_of_block_res_18855];\n                            \n                            bool zg_res_17779 = eps_15180 < eta_p_17776;\n                            bool zg_res_17780 = eps_15180 < eta_p_17778;\n                            bool x_17781 = zg_res_17779 && zg_res_17780;\n                            int64_t lifted_lambda_res_17782;\n                            double lifted_lambda_res_17783;\n                            \n                            if (x_17781) {\n                                lifted_lambda_res_17782 = (int64_t) -1;\n                                lifted_lambda_res_17783 = INFINITY;\n                            } else {\n                                bool zl_res_17784 = eta_p_17776 < eta_p_17778;\n                                int64_t lifted_lambda_res_f_res_17785;\n                                \n                                if (zl_res_17784) {\n                                    lifted_lambda_res_f_res_17785 = eta_p_17775;\n                                } else {\n                                    lifted_lambda_res_f_res_17785 = eta_p_17777;\n                                }\n                                \n ", "                               double lifted_lambda_res_f_res_17786;\n                                \n                                if (zl_res_17784) {\n                                    lifted_lambda_res_f_res_17786 = eta_p_17776;\n                                } else {\n                                    lifted_lambda_res_f_res_17786 = eta_p_17778;\n                                }\n                                lifted_lambda_res_17782 = lifted_lambda_res_f_res_17785;\n                                lifted_lambda_res_17783 = lifted_lambda_res_f_res_17786;\n                            }\n                            eta_p_17775 = lifted_lambda_res_17782;\n                            eta_p_17776 = lifted_lambda_res_17783;\n                        }\n                    }\n                }\n                ((__local int64_t *) red_arr_i64_mem_18816)[sext_i32_i64(local_tid_18812)] = eta_p_17775;\n                ((__local double *) red_arr_f64_mem_18818)[sext_i32_i64(local_tid_18812)] = eta_p_17776;\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // reduce the per-block results\n                {\n                    int32_t offset_18856;\n                    int32_t skip_waves_18857 = 1;\n                    int64_t eta_p_18832;\n                    double eta_p_18833;\n                    int64_t eta_p_18834;\n                    double eta_p_18835;\n                    \n                    offset_18856 = 0;\n                    // participating threads read initial accumulator\n                    {\n                        if (slt32(local_tid_18812, sext_i64_i32(segred_tblock_sizze_17767))) {\n                            eta_p_18832 = ((__local int64_t *) red_arr_i64_mem_18816)[sext_i32_i64(local_tid_18812 + offset_18856)];\n                            eta_p_18833 = ((__local double *) red_arr_f64_mem_18818)[sext_i32_i64(local_tid_18812 + offset_18856)];\n                        }\n                    }\n                    offset_18856 = 1;\n                    while (", "slt32(offset_18856, wave_sizze_18814)) {\n                        if (slt32(local_tid_18812 + offset_18856, sext_i64_i32(segred_tblock_sizze_17767)) && ((local_tid_18812 - squot32(local_tid_18812, wave_sizze_18814) * wave_sizze_18814) & (2 * offset_18856 - 1)) == 0) {\n                            // read array element\n                            {\n                                eta_p_18834 = ((volatile __local int64_t *) red_arr_i64_mem_18816)[sext_i32_i64(local_tid_18812 + offset_18856)];\n                                eta_p_18835 = ((volatile __local double *) red_arr_f64_mem_18818)[sext_i32_i64(local_tid_18812 + offset_18856)];\n                            }\n                            // apply reduction operation\n                            {\n                                bool zg_res_18836 = eps_15180 < eta_p_18833;\n                                bool zg_res_18837 = eps_15180 < eta_p_18835;\n                                bool x_18838 = zg_res_18836 && zg_res_18837;\n                                int64_t lifted_lambda_res_18839;\n                                double lifted_lambda_res_18840;\n                                \n                                if (x_18838) {\n                                    lifted_lambda_res_18839 = (int64_t) -1;\n                                    lifted_lambda_res_18840 = INFINITY;\n                                } else {\n                                    bool zl_res_18841 = eta_p_18833 < eta_p_18835;\n                                    int64_t lifted_lambda_res_f_res_18842;\n                                    \n                                    if (zl_res_18841) {\n                                        lifted_lambda_res_f_res_18842 = eta_p_18832;\n                                    } else {\n                                        lifted_lambda_res_f_res_18842 = eta_p_18834;\n                                    }\n                                    \n                                    double lifted_lambda_res_f_res_18843;\n",
                                    "                                    \n                                    if (zl_res_18841) {\n                                        lifted_lambda_res_f_res_18843 = eta_p_18833;\n                                    } else {\n                                        lifted_lambda_res_f_res_18843 = eta_p_18835;\n                                    }\n                                    lifted_lambda_res_18839 = lifted_lambda_res_f_res_18842;\n                                    lifted_lambda_res_18840 = lifted_lambda_res_f_res_18843;\n                                }\n                                eta_p_18832 = lifted_lambda_res_18839;\n                                eta_p_18833 = lifted_lambda_res_18840;\n                            }\n                            // write result of operation\n                            {\n                                ((volatile __local int64_t *) red_arr_i64_mem_18816)[sext_i32_i64(local_tid_18812)] = eta_p_18832;\n                                ((volatile __local double *) red_arr_f64_mem_18818)[sext_i32_i64(local_tid_18812)] = eta_p_18833;\n                            }\n                        }\n                        offset_18856 *= 2;\n                    }\n                    while (slt32(skip_waves_18857, squot32(sext_i64_i32(segred_tblock_sizze_17767) + wave_sizze_18814 - 1, wave_sizze_18814))) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                        offset_18856 = skip_waves_18857 * wave_sizze_18814;\n                        if (slt32(local_tid_18812 + offset_18856, sext_i64_i32(segred_tblock_sizze_17767)) && ((local_tid_18812 - squot32(local_tid_18812, wave_sizze_18814) * wave_sizze_18814) == 0 && (squot32(local_tid_18812, wave_sizze_18814) & (2 * skip_waves_18857 - 1)) == 0)) {\n                            // read array element\n                            {\n                                eta_p_18834 = ((__local int64_t *) red_arr_i64_mem_18816)[sext_i32_i64(local_tid_18812 + offset_18856)];\n                 ", "               eta_p_18835 = ((__local double *) red_arr_f64_mem_18818)[sext_i32_i64(local_tid_18812 + offset_18856)];\n                            }\n                            // apply reduction operation\n                            {\n                                bool zg_res_18836 = eps_15180 < eta_p_18833;\n                                bool zg_res_18837 = eps_15180 < eta_p_18835;\n                                bool x_18838 = zg_res_18836 && zg_res_18837;\n                                int64_t lifted_lambda_res_18839;\n                                double lifted_lambda_res_18840;\n                                \n                                if (x_18838) {\n                                    lifted_lambda_res_18839 = (int64_t) -1;\n                                    lifted_lambda_res_18840 = INFINITY;\n                                } else {\n                                    bool zl_res_18841 = eta_p_18833 < eta_p_18835;\n                                    int64_t lifted_lambda_res_f_res_18842;\n                                    \n                                    if (zl_res_18841) {\n                                        lifted_lambda_res_f_res_18842 = eta_p_18832;\n                                    } else {\n                                        lifted_lambda_res_f_res_18842 = eta_p_18834;\n                                    }\n                                    \n                                    double lifted_lambda_res_f_res_18843;\n                                    \n                                    if (zl_res_18841) {\n                                        lifted_lambda_res_f_res_18843 = eta_p_18833;\n                                    } else {\n                                        lifted_lambda_res_f_res_18843 = eta_p_18835;\n                                    }\n                                    lifted_lambda_res_18839 = lifted_lambda_res_f_res_18842;\n                                    lifted_lambda_res_18840 = lifted_lambda_res_f", "_res_18843;\n                                }\n                                eta_p_18832 = lifted_lambda_res_18839;\n                                eta_p_18833 = lifted_lambda_res_18840;\n                            }\n                            // write result of operation\n                            {\n                                ((__local int64_t *) red_arr_i64_mem_18816)[sext_i32_i64(local_tid_18812)] = eta_p_18832;\n                                ((__local double *) red_arr_f64_mem_18818)[sext_i32_i64(local_tid_18812)] = eta_p_18833;\n                            }\n                        }\n                        skip_waves_18857 *= 2;\n                    }\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                    // and back to memory with the final result\n                    {\n                        if (local_tid_18812 == 0) {\n                            ((__global int64_t *) mem_18426)[inf_16016 + gtid_17772] = eta_p_18832;\n                            ((__global double *) mem_18460)[gtid_17772] = eta_p_18833;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_6:\n    return;\n    #undef segred_tblock_sizze_17767\n    #undef chunk_sizze_18740\n}\nFUTHARK_KERNEL_SIZED(ftDBSCAN_doublezisegred_small_17774_dim1, 1, 1)\nvoid ftDBSCAN_doublezisegred_small_17774(__global int *global_failure, double eps_15180, int64_t corePts_15993, int64_t inf_16016, int64_t dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, int64_t num_tblocks_17768, int64_t segment_sizze_nonzzero_18741, __global unsigned char *ext_mem_18424, __global unsigned char *mem_18426, __global unsigned char *mem_18455, __global unsigned char *mem_18460)\n{\n    #define segred_tblock_sizze_17767 (ftDBSCAN_doublezisegred_small_17774zisegred_tblock_sizze_17767)\n    \n    volatile __local unsigned char *red_arr_f64_mem_18750_backing_1 = &shared_mem[0];\n    const int64_t red_arr_f64_mem_18750_backi",
                                    "ng_1_offset = 0 + ((int64_t) 8 * segred_tblock_sizze_17767 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_17767, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *red_arr_i64_mem_18748_backing_0 = &shared_mem[red_arr_f64_mem_18750_backing_1_offset];\n    const int64_t red_arr_i64_mem_18748_backing_0_offset = red_arr_f64_mem_18750_backing_1_offset + ((int64_t) 8 * segred_tblock_sizze_17767 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_17767, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18744;\n    int32_t tblock_sizze_18747;\n    int32_t wave_sizze_18746;\n    int32_t block_id_18745;\n    int32_t global_tid_18743;\n    int64_t phys_tid_17774;\n    __local unsigned char *red_arr_i64_mem_18748;\n    __local unsigned char *red_arr_f64_mem_18750;\n    int32_t phys_tblock_id_18752;\n    int32_t iterations_18753;\n    \n    local_tid_18744 = get_local_id(0);\n    tblock_sizze_18747 = get_local_size(0);\n    wave_sizze_18746 = LOCKSTEP_WIDTH;\n    block_id_18745 = get_tblock_id(0);\n    global_tid_18743 = block_id_18745 * tblock_sizze_18747 + local_tid_18744;\n    phys_tid_17774 = sext_i32_i64(global_tid_18743);\n    red_arr_i64_mem_18748 = (__local unsigned char *) red_arr_i64_mem_18748_backing_0;\n    red_arr_f64_mem_18750 = (__local unsigned char *) red_arr_f64_mem_18750_backing_1;\n    phys_tblock_id_18752 = get_tblock_id(0);\n    iterations_18753 = sdiv_up32(sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, squot64(segred_tblock_sizze_17767, segment_sizze_nonzzero_18741))) - phys_tblock_id_18752, sext_i64_i32(num_tblocks_17768));\n    for (int32_t i_18754 = 0; i_18754 < iterations_18753; i_18754++) {\n        int32_t virt_tblock_id_18755;\n        int64_t slice_18756;\n        int64_t gtid_17772;\n        int64_t remnant_18757;\n        int64_t gtid_17773;\n        \n        virt_tblock_id_18755 = phys_tblock_id_18752 + i_18754 * sext_i64_i32(num_tblocks_17768);\n        sli", "ce_18756 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019;\n        gtid_17772 = squot64(sext_i32_i64(local_tid_18744), segment_sizze_nonzzero_18741) + sext_i32_i64(virt_tblock_id_18755) * squot64(segred_tblock_sizze_17767, segment_sizze_nonzzero_18741);\n        remnant_18757 = squot64(sext_i32_i64(local_tid_18744), segment_sizze_nonzzero_18741) + sext_i32_i64(virt_tblock_id_18755) * squot64(segred_tblock_sizze_17767, segment_sizze_nonzzero_18741) - gtid_17772;\n        gtid_17773 = srem64(sext_i32_i64(local_tid_18744), corePts_15993);\n        // apply map function if in bounds\n        {\n            if (slt64((int64_t) 0, corePts_15993) && (slt64(gtid_17772, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019) && slt64(sext_i32_i64(local_tid_18744), corePts_15993 * squot64(segred_tblock_sizze_17767, segment_sizze_nonzzero_18741)))) {\n                // apply map function\n                {\n                    int64_t x_17789 = ((__global int64_t *) ext_mem_18424)[gtid_17773];\n                    double x_17790 = ((__global double *) mem_18455)[gtid_17772 * corePts_15993 + gtid_17773];\n                    \n                    // save results to be reduced\n                    {\n                        ((__local int64_t *) red_arr_i64_mem_18748)[sext_i32_i64(local_tid_18744)] = x_17789;\n                        ((__local double *) red_arr_f64_mem_18750)[sext_i32_i64(local_tid_18744)] = x_17790;\n                    }\n                }\n            } else {\n                ((__local int64_t *) red_arr_i64_mem_18748)[sext_i32_i64(local_tid_18744)] = (int64_t) -1;\n                ((__local double *) red_arr_f64_mem_18750)[sext_i32_i64(local_tid_18744)] = INFINITY;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (slt64((int64_t) 0, corePts_15993)) {\n            // perform segmented scan to imitate reduction\n            {\n                int64_t eta_p_17775;\n                double eta_p_17776;\n                int64_t eta_p_17777;\n                double eta_p_17778;\n        ", "        int64_t eta_p_18758;\n                double eta_p_18759;\n                int64_t eta_p_18760;\n                double eta_p_18761;\n                bool ltid_in_bounds_18770 = slt64(sext_i32_i64(local_tid_18744), corePts_15993 * squot64(segred_tblock_sizze_17767, segment_sizze_nonzzero_18741));\n                int32_t skip_threads_18771;\n                \n                // read input for in-block scan\n                {\n                    if (ltid_in_bounds_18770) {\n                        eta_p_17777 = ((volatile __local int64_t *) red_arr_i64_mem_18748)[sext_i32_i64(local_tid_18744)];\n                        eta_p_17778 = ((volatile __local double *) red_arr_f64_mem_18750)[sext_i32_i64(local_tid_18744)];\n                        if ((local_tid_18744 - squot32(local_tid_18744, 32) * 32) == 0) {\n                            eta_p_17775 = eta_p_17777;\n                            eta_p_17776 = eta_p_17778;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_18771 = 1;\n                    while (slt32(skip_threads_18771, 32)) {\n                        bool thread_active_18772 = sle32(skip_threads_18771, local_tid_18744 - squot32(local_tid_18744, 32) * 32) && ltid_in_bounds_18770;\n                        \n                        if (thread_active_18772) {\n                            // read operands\n                            {\n                                eta_p_17775 = ((volatile __local int64_t *) red_arr_i64_mem_18748)[sext_i32_i64(local_tid_18744) - sext_i32_i64(skip_threads_18771)];\n                                eta_p_17776 = ((volatile __local double *) red_arr_f64_mem_18750)[sext_i32_i64(local_tid_18744) - sext_i32_i64(skip_threads_18771)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            bool inactive_18773 = slt64(srem64",
                                    "(sext_i32_i64(local_tid_18744), corePts_15993), sext_i32_i64(local_tid_18744) - sext_i32_i64(local_tid_18744 - skip_threads_18771));\n                            \n                            if (thread_active_18772 && inactive_18773) {\n                                eta_p_17775 = eta_p_17777;\n                                eta_p_17776 = eta_p_17778;\n                            }\n                            if (thread_active_18772) {\n                                if (!inactive_18773) {\n                                    bool zg_res_17779 = eps_15180 < eta_p_17776;\n                                    bool zg_res_17780 = eps_15180 < eta_p_17778;\n                                    bool x_17781 = zg_res_17779 && zg_res_17780;\n                                    int64_t lifted_lambda_res_17782;\n                                    double lifted_lambda_res_17783;\n                                    \n                                    if (x_17781) {\n                                        lifted_lambda_res_17782 = (int64_t) -1;\n                                        lifted_lambda_res_17783 = INFINITY;\n                                    } else {\n                                        bool zl_res_17784 = eta_p_17776 < eta_p_17778;\n                                        int64_t lifted_lambda_res_f_res_17785;\n                                        \n                                        if (zl_res_17784) {\n                                            lifted_lambda_res_f_res_17785 = eta_p_17775;\n                                        } else {\n                                            lifted_lambda_res_f_res_17785 = eta_p_17777;\n                                        }\n                                        \n                                        double lifted_lambda_res_f_res_17786;\n                                        \n                                        if (zl_res_17784) {\n                                            lifted_lambda_res_f_res_17786 = eta_p_", "17776;\n                                        } else {\n                                            lifted_lambda_res_f_res_17786 = eta_p_17778;\n                                        }\n                                        lifted_lambda_res_17782 = lifted_lambda_res_f_res_17785;\n                                        lifted_lambda_res_17783 = lifted_lambda_res_f_res_17786;\n                                    }\n                                    eta_p_17775 = lifted_lambda_res_17782;\n                                    eta_p_17776 = lifted_lambda_res_17783;\n                                }\n                            }\n                        }\n                        if (sle32(wave_sizze_18746, skip_threads_18771)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_18772) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) red_arr_i64_mem_18748)[sext_i32_i64(local_tid_18744)] = eta_p_17775;\n                                eta_p_17777 = eta_p_17775;\n                                ((volatile __local double *) red_arr_f64_mem_18750)[sext_i32_i64(local_tid_18744)] = eta_p_17776;\n                                eta_p_17778 = eta_p_17776;\n                            }\n                        }\n                        if (sle32(wave_sizze_18746, skip_threads_18771)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_18771 *= 2;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // last thread of block 'i' writes its result to offset 'i'\n                {\n                    if ((local_tid_18744 - squot32(local_tid_18744, 32) * 32) == 31 && ltid_in_bounds_18770) {\n                        ((volatile __local int64_t *) red_arr_i64_mem_18748)[sext_i32_i64(squot32(local_tid_18744, 32))] = ", "eta_p_17775;\n                        ((volatile __local double *) red_arr_f64_mem_18750)[sext_i32_i64(squot32(local_tid_18744, 32))] = eta_p_17776;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n                {\n                    int32_t skip_threads_18774;\n                    \n                    // read input for in-block scan\n                    {\n                        if (squot32(local_tid_18744, 32) == 0 && ltid_in_bounds_18770) {\n                            eta_p_18760 = ((volatile __local int64_t *) red_arr_i64_mem_18748)[sext_i32_i64(local_tid_18744)];\n                            eta_p_18761 = ((volatile __local double *) red_arr_f64_mem_18750)[sext_i32_i64(local_tid_18744)];\n                            if ((local_tid_18744 - squot32(local_tid_18744, 32) * 32) == 0) {\n                                eta_p_18758 = eta_p_18760;\n                                eta_p_18759 = eta_p_18761;\n                            }\n                        }\n                    }\n                    // in-block scan (hopefully no barriers needed)\n                    {\n                        skip_threads_18774 = 1;\n                        while (slt32(skip_threads_18774, 32)) {\n                            bool thread_active_18775 = sle32(skip_threads_18774, local_tid_18744 - squot32(local_tid_18744, 32) * 32) && (squot32(local_tid_18744, 32) == 0 && ltid_in_bounds_18770);\n                            \n                            if (thread_active_18775) {\n                                // read operands\n                                {\n                                    eta_p_18758 = ((volatile __local int64_t *) red_arr_i64_mem_18748)[sext_i32_i64(local_tid_18744) - sext_i32_i64(skip_threads_18774)];\n                                    eta_p_18759 = ((volatile __local double *) red_arr_f64_mem_18750)[sext_i32_i64(local_tid_18744) - sext",
                                    "_i32_i64(skip_threads_18774)];\n                                }\n                            }\n                            // perform operation\n                            {\n                                bool inactive_18776 = slt64(srem64(sext_i32_i64(local_tid_18744 * 32 + 32 - 1), corePts_15993), sext_i32_i64(local_tid_18744 * 32 + 32 - 1) - sext_i32_i64((local_tid_18744 - skip_threads_18774) * 32 + 32 - 1));\n                                \n                                if (thread_active_18775 && inactive_18776) {\n                                    eta_p_18758 = eta_p_18760;\n                                    eta_p_18759 = eta_p_18761;\n                                }\n                                if (thread_active_18775) {\n                                    if (!inactive_18776) {\n                                        bool zg_res_18762 = eps_15180 < eta_p_18759;\n                                        bool zg_res_18763 = eps_15180 < eta_p_18761;\n                                        bool x_18764 = zg_res_18762 && zg_res_18763;\n                                        int64_t lifted_lambda_res_18765;\n                                        double lifted_lambda_res_18766;\n                                        \n                                        if (x_18764) {\n                                            lifted_lambda_res_18765 = (int64_t) -1;\n                                            lifted_lambda_res_18766 = INFINITY;\n                                        } else {\n                                            bool zl_res_18767 = eta_p_18759 < eta_p_18761;\n                                            int64_t lifted_lambda_res_f_res_18768;\n                                            \n                                            if (zl_res_18767) {\n                                                lifted_lambda_res_f_res_18768 = eta_p_18758;\n                                            } else {\n                                                lifted_la", "mbda_res_f_res_18768 = eta_p_18760;\n                                            }\n                                            \n                                            double lifted_lambda_res_f_res_18769;\n                                            \n                                            if (zl_res_18767) {\n                                                lifted_lambda_res_f_res_18769 = eta_p_18759;\n                                            } else {\n                                                lifted_lambda_res_f_res_18769 = eta_p_18761;\n                                            }\n                                            lifted_lambda_res_18765 = lifted_lambda_res_f_res_18768;\n                                            lifted_lambda_res_18766 = lifted_lambda_res_f_res_18769;\n                                        }\n                                        eta_p_18758 = lifted_lambda_res_18765;\n                                        eta_p_18759 = lifted_lambda_res_18766;\n                                    }\n                                }\n                            }\n                            if (sle32(wave_sizze_18746, skip_threads_18774)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            if (thread_active_18775) {\n                                // write result\n                                {\n                                    ((volatile __local int64_t *) red_arr_i64_mem_18748)[sext_i32_i64(local_tid_18744)] = eta_p_18758;\n                                    eta_p_18760 = eta_p_18758;\n                                    ((volatile __local double *) red_arr_f64_mem_18750)[sext_i32_i64(local_tid_18744)] = eta_p_18759;\n                                    eta_p_18761 = eta_p_18759;\n                                }\n                            }\n                            if (sle32(wave_sizze_18746, skip_threads_18774)) {\n                                barrier(CLK_LOC", "AL_MEM_FENCE);\n                            }\n                            skip_threads_18774 *= 2;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                \n                bool no_carry_in_18777 = squot32(local_tid_18744, 32) == 0 || !ltid_in_bounds_18770;\n                \n                // carry-in for every block except the first\n                {\n                    // read operands\n                    {\n                        if (!no_carry_in_18777) {\n                            eta_p_17777 = eta_p_17775;\n                            eta_p_17778 = eta_p_17776;\n                            eta_p_17775 = ((__local int64_t *) red_arr_i64_mem_18748)[sext_i32_i64(squot32(local_tid_18744, 32)) - (int64_t) 1];\n                            eta_p_17776 = ((__local double *) red_arr_f64_mem_18750)[sext_i32_i64(squot32(local_tid_18744, 32)) - (int64_t) 1];\n                        }\n                    }\n                    // perform operation\n                    {\n                        bool inactive_18778 = slt64(srem64(sext_i32_i64(local_tid_18744), corePts_15993), sext_i32_i64(local_tid_18744) - sext_i32_i64(squot32(local_tid_18744, 32) * 32 - 1));\n                        \n                        if (!no_carry_in_18777) {\n                            if (inactive_18778) {\n                                eta_p_17775 = eta_p_17777;\n                                eta_p_17776 = eta_p_17778;\n                            }\n                        }\n                        if (!no_carry_in_18777) {\n                            if (!inactive_18778) {\n                                bool zg_res_17779 = eps_15180 < eta_p_17776;\n                                bool zg_res_17780 = eps_15180 < eta_p_17778;\n                                bool x_17781 = zg_res_17779 && zg_res_17780;\n                                int64_t lifted_lambda_res_17782;\n                                double lifted_lambda_res_17783;\n     ",
                                    "                           \n                                if (x_17781) {\n                                    lifted_lambda_res_17782 = (int64_t) -1;\n                                    lifted_lambda_res_17783 = INFINITY;\n                                } else {\n                                    bool zl_res_17784 = eta_p_17776 < eta_p_17778;\n                                    int64_t lifted_lambda_res_f_res_17785;\n                                    \n                                    if (zl_res_17784) {\n                                        lifted_lambda_res_f_res_17785 = eta_p_17775;\n                                    } else {\n                                        lifted_lambda_res_f_res_17785 = eta_p_17777;\n                                    }\n                                    \n                                    double lifted_lambda_res_f_res_17786;\n                                    \n                                    if (zl_res_17784) {\n                                        lifted_lambda_res_f_res_17786 = eta_p_17776;\n                                    } else {\n                                        lifted_lambda_res_f_res_17786 = eta_p_17778;\n                                    }\n                                    lifted_lambda_res_17782 = lifted_lambda_res_f_res_17785;\n                                    lifted_lambda_res_17783 = lifted_lambda_res_f_res_17786;\n                                }\n                                eta_p_17775 = lifted_lambda_res_17782;\n                                eta_p_17776 = lifted_lambda_res_17783;\n                            }\n                        }\n                    }\n                    // write final result\n                    {\n                        if (!no_carry_in_18777) {\n                            ((__local int64_t *) red_arr_i64_mem_18748)[sext_i32_i64(local_tid_18744)] = eta_p_17775;\n                            ((__local double *) red_arr_f64_mem_18750)[sext_i32_i64(local_tid_18744)] =", " eta_p_17776;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // restore correct values for first block\n                {\n                    if (squot32(local_tid_18744, 32) == 0 && ltid_in_bounds_18770) {\n                        ((__local int64_t *) red_arr_i64_mem_18748)[sext_i32_i64(local_tid_18744)] = eta_p_17777;\n                        ((__local double *) red_arr_f64_mem_18750)[sext_i32_i64(local_tid_18744)] = eta_p_17778;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // save final values of segments\n        {\n            if (slt64(sext_i32_i64(virt_tblock_id_18755) * squot64(segred_tblock_sizze_17767, segment_sizze_nonzzero_18741) + sext_i32_i64(local_tid_18744), dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019) && slt64(sext_i32_i64(local_tid_18744), squot64(segred_tblock_sizze_17767, segment_sizze_nonzzero_18741))) {\n                int64_t tmp_18779 = ((__local int64_t *) red_arr_i64_mem_18748)[(sext_i32_i64(local_tid_18744) + (int64_t) 1) * segment_sizze_nonzzero_18741 - (int64_t) 1];\n                \n                ((__global int64_t *) mem_18426)[inf_16016 + (sext_i32_i64(virt_tblock_id_18755) * squot64(segred_tblock_sizze_17767, segment_sizze_nonzzero_18741) + sext_i32_i64(local_tid_18744))] = tmp_18779;\n                \n                double tmp_18780 = ((__local double *) red_arr_f64_mem_18750)[(sext_i32_i64(local_tid_18744) + (int64_t) 1) * segment_sizze_nonzzero_18741 - (int64_t) 1];\n                \n                ((__global double *) mem_18460)[sext_i32_i64(virt_tblock_id_18755) * squot64(segred_tblock_sizze_17767, segment_sizze_nonzzero_18741) + sext_i32_i64(local_tid_18744)] = tmp_18780;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_3:\n    return;\n    #undef segred_tbl", "ock_sizze_17767\n}\nFUTHARK_KERNEL_SIZED(ftDBSCAN_floatzisegmap_17062_dim1, 1, 1)\nvoid ftDBSCAN_floatzisegmap_17062(__global int *global_failure, int64_t nz2080U_13119, int64_t minPts_13123, __global unsigned char *ext_mem_18420, __global unsigned char *mem_18422)\n{\n    #define segmap_tblock_sizze_17058 (ftDBSCAN_floatzisegmap_17062zisegmap_tblock_sizze_17058)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18653;\n    int32_t tblock_sizze_18656;\n    int32_t wave_sizze_18655;\n    int32_t block_id_18654;\n    int32_t global_tid_18652;\n    int64_t phys_tid_17062;\n    int64_t global_tid_18657;\n    int64_t slice_18658;\n    int64_t gtid_17061;\n    int64_t remnant_18659;\n    \n    local_tid_18653 = get_local_id(0);\n    tblock_sizze_18656 = get_local_size(0);\n    wave_sizze_18655 = LOCKSTEP_WIDTH;\n    block_id_18654 = get_tblock_id(0);\n    global_tid_18652 = block_id_18654 * tblock_sizze_18656 + local_tid_18653;\n    phys_tid_17062 = sext_i32_i64(global_tid_18652);\n    global_tid_18657 = sext_i32_i64(block_id_18654) * segmap_tblock_sizze_17058 + sext_i32_i64(local_tid_18653);\n    slice_18658 = nz2080U_13119;\n    gtid_17061 = global_tid_18657;\n    remnant_18659 = global_tid_18657 - gtid_17061;\n    if (slt64(gtid_17061, nz2080U_13119)) {\n        int64_t eta_p_17063;\n        bool lifted_lambda_res_17064;\n        \n        eta_p_17063 = ((__global int64_t *) ext_mem_18420)[gtid_17061];\n        lifted_lambda_res_17064 = sle64(minPts_13123, eta_p_17063);\n        ((__global bool *) mem_18422)[gtid_17061] = lifted_lambda_res_17064;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_17058\n}\nFUTHARK_KERNEL_SIZED(ftDBSCAN_floatzisegmap_17115_dim1, 1, 1)\nvoid ftDBSCAN_floatzisegmap_17115(__global int *global_failure, int64_t dimz2081U_13120, float eps_13122, int64_t corePts_15993, int64_t inf_16016, int64_t dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, int64_t num_threads_18568, __global unsigned char *dat_mem_18419, __global unsigned char *ext_mem_18423, __",
                                    "global unsigned char *ext_mem_18424, __global unsigned char *mem_18426, __global unsigned char *color_18526)\n{\n    #define segmap_tblock_sizze_17111 (ftDBSCAN_floatzisegmap_17115zisegmap_tblock_sizze_17111)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18684;\n    int32_t tblock_sizze_18687;\n    int32_t wave_sizze_18686;\n    int32_t block_id_18685;\n    int32_t global_tid_18683;\n    int64_t phys_tid_17115;\n    int64_t global_tid_18688;\n    int64_t slice_18689;\n    int64_t gtid_17114;\n    int64_t remnant_18690;\n    \n    local_tid_18684 = get_local_id(0);\n    tblock_sizze_18687 = get_local_size(0);\n    wave_sizze_18686 = LOCKSTEP_WIDTH;\n    block_id_18685 = get_tblock_id(0);\n    global_tid_18683 = block_id_18685 * tblock_sizze_18687 + local_tid_18684;\n    phys_tid_17115 = sext_i32_i64(global_tid_18683);\n    global_tid_18688 = sext_i32_i64(block_id_18685) * segmap_tblock_sizze_17111 + sext_i32_i64(local_tid_18684);\n    slice_18689 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019;\n    gtid_17114 = global_tid_18688;\n    remnant_18690 = global_tid_18688 - gtid_17114;\n    if (slt64(gtid_17114, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019)) {\n        int64_t slice_18395;\n        int64_t defunc_0_f_res_17117;\n        float defunc_0_f_res_17118;\n        int64_t redout_18406;\n        float redout_18407;\n        \n        slice_18395 = inf_16016 + gtid_17114;\n        redout_18406 = (int64_t) -1;\n        redout_18407 = INFINITY;\n        for (int64_t i_18408 = 0; i_18408 < corePts_15993; i_18408++) {\n            float defunc_0_f_res_17126;\n            float acc_17128;\n            float sqrt_res_17131;\n            bool zg_res_17136;\n            bool zg_res_17137;\n            bool x_17138;\n            int64_t lifted_lambda_res_17139;\n            float lifted_lambda_res_17140;\n            int64_t redout_tmp_18691;\n            float redout_tmp_18692;\n            \n            for (int64_t i_18411 = 0; i_18411 < dimz2081U_13120; i_18411++) {\n                float eta_p_1712", "2;\n                float eta_p_17123;\n                float zm_res_17124;\n                float zt_res_17125;\n                \n                eta_p_17122 = ((__global float *) dat_mem_18419)[slice_18395 * dimz2081U_13120 + i_18411];\n                eta_p_17123 = ((__global float *) ext_mem_18423)[i_18408 * dimz2081U_13120 + i_18411];\n                zm_res_17124 = eta_p_17122 - eta_p_17123;\n                zt_res_17125 = zm_res_17124 * zm_res_17124;\n                ((__global float *) color_18526)[phys_tid_17115 + i_18411 * num_threads_18568] = zt_res_17125;\n            }\n            acc_17128 = 0.0F;\n            for (int64_t i_17127 = 0; i_17127 < dimz2081U_13120; i_17127++) {\n                float b_17129;\n                float zp_res_17130;\n                float acc_tmp_18694;\n                \n                b_17129 = ((__global float *) color_18526)[phys_tid_17115 + i_17127 * num_threads_18568];\n                zp_res_17130 = acc_17128 + b_17129;\n                acc_tmp_18694 = zp_res_17130;\n                acc_17128 = acc_tmp_18694;\n            }\n            defunc_0_f_res_17126 = acc_17128;\n            sqrt_res_17131 = futrts_sqrt32(defunc_0_f_res_17126);\n            zg_res_17136 = eps_13122 < redout_18407;\n            zg_res_17137 = eps_13122 < sqrt_res_17131;\n            x_17138 = zg_res_17136 && zg_res_17137;\n            if (x_17138) {\n                lifted_lambda_res_17139 = (int64_t) -1;\n                lifted_lambda_res_17140 = INFINITY;\n            } else {\n                bool zl_res_17141;\n                int64_t lifted_lambda_res_f_res_17142;\n                float lifted_lambda_res_f_res_17143;\n                \n                zl_res_17141 = redout_18407 < sqrt_res_17131;\n                if (zl_res_17141) {\n                    lifted_lambda_res_f_res_17142 = redout_18406;\n                } else {\n                    int64_t x_17120 = ((__global int64_t *) ext_mem_18424)[i_18408];\n                    \n                    lifted_lambda_res_f_res_171", "42 = x_17120;\n                }\n                if (zl_res_17141) {\n                    lifted_lambda_res_f_res_17143 = redout_18407;\n                } else {\n                    lifted_lambda_res_f_res_17143 = sqrt_res_17131;\n                }\n                lifted_lambda_res_17139 = lifted_lambda_res_f_res_17142;\n                lifted_lambda_res_17140 = lifted_lambda_res_f_res_17143;\n            }\n            redout_tmp_18691 = lifted_lambda_res_17139;\n            redout_tmp_18692 = lifted_lambda_res_17140;\n            redout_18406 = redout_tmp_18691;\n            redout_18407 = redout_tmp_18692;\n        }\n        defunc_0_f_res_17117 = redout_18406;\n        defunc_0_f_res_17118 = redout_18407;\n        ((__global int64_t *) mem_18426)[inf_16016 + gtid_17114] = defunc_0_f_res_17117;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_17111\n}\nFUTHARK_KERNEL_SIZED(ftDBSCAN_floatzisegmap_17369_dim1, 1, 1)\nvoid ftDBSCAN_floatzisegmap_17369(__global int *global_failure, int64_t dimz2081U_13120, int64_t corePts_15993, int64_t inf_16016, int64_t dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, __global unsigned char *dat_mem_18419, __global unsigned char *ext_mem_18423, __global unsigned char *mem_18434)\n{\n    #define segmap_tblock_sizze_17363 (ftDBSCAN_floatzisegmap_17369zisegmap_tblock_sizze_17363)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18717;\n    int32_t tblock_sizze_18720;\n    int32_t wave_sizze_18719;\n    int32_t block_id_18718;\n    int32_t global_tid_18716;\n    int64_t phys_tid_17369;\n    int64_t global_tid_18721;\n    int64_t slice_18722;\n    int64_t slice_18723;\n    int64_t slice_18724;\n    int64_t gtid_17366;\n    int64_t remnant_18725;\n    int64_t gtid_17367;\n    int64_t remnant_18726;\n    int64_t gtid_17368;\n    int64_t remnant_18727;\n    \n    local_tid_18717 = get_local_id(0);\n    tblock_sizze_18720 = get_local_size(0);\n    wave_sizze_18719 = LOCKSTEP_WIDTH;\n    block_id_18718 = get_tblock_id(0);\n    global_tid_18716 = blo",
                                    "ck_id_18718 * tblock_sizze_18720 + local_tid_18717;\n    phys_tid_17369 = sext_i32_i64(global_tid_18716);\n    global_tid_18721 = sext_i32_i64(block_id_18718) * segmap_tblock_sizze_17363 + sext_i32_i64(local_tid_18717);\n    slice_18722 = dimz2081U_13120;\n    slice_18723 = corePts_15993 * slice_18722;\n    slice_18724 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019 * slice_18723;\n    gtid_17366 = squot64(global_tid_18721, slice_18723);\n    remnant_18725 = global_tid_18721 - gtid_17366 * slice_18723;\n    gtid_17367 = squot64(remnant_18725, slice_18722);\n    remnant_18726 = remnant_18725 - gtid_17367 * slice_18722;\n    gtid_17368 = remnant_18726;\n    remnant_18727 = remnant_18726 - gtid_17368;\n    if ((slt64(gtid_17366, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019) && slt64(gtid_17367, corePts_15993)) && slt64(gtid_17368, dimz2081U_13120)) {\n        int64_t slice_18397;\n        float eta_p_17370;\n        float eta_p_17371;\n        float zm_res_17372;\n        float zt_res_17373;\n        \n        slice_18397 = inf_16016 + gtid_17366;\n        eta_p_17370 = ((__global float *) dat_mem_18419)[slice_18397 * dimz2081U_13120 + gtid_17368];\n        eta_p_17371 = ((__global float *) ext_mem_18423)[gtid_17367 * dimz2081U_13120 + gtid_17368];\n        zm_res_17372 = eta_p_17370 - eta_p_17371;\n        zt_res_17373 = zm_res_17372 * zm_res_17372;\n        ((__global float *) mem_18434)[gtid_17366 * (dimz2081U_13120 * corePts_15993) + gtid_17367 * dimz2081U_13120 + gtid_17368] = zt_res_17373;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_17363\n}\nFUTHARK_KERNEL_SIZED(ftDBSCAN_floatzisegmap_17382_dim1, 1, 1)\nvoid ftDBSCAN_floatzisegmap_17382(__global int *global_failure, int64_t dimz2081U_13120, int64_t corePts_15993, int64_t dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, __global unsigned char *mem_18451, __global unsigned char *mem_18455)\n{\n    #define segmap_tblock_sizze_17377 (ftDBSCAN_floatzisegmap_17382zisegmap_tblock_sizze_17377)\n    if (*global_failure >= 0)\n        return;\n    \n  ", "  int32_t local_tid_18730;\n    int32_t tblock_sizze_18733;\n    int32_t wave_sizze_18732;\n    int32_t block_id_18731;\n    int32_t global_tid_18729;\n    int64_t phys_tid_17382;\n    int64_t global_tid_18734;\n    int64_t slice_18735;\n    int64_t slice_18736;\n    int64_t gtid_17380;\n    int64_t remnant_18737;\n    int64_t gtid_17381;\n    int64_t remnant_18738;\n    \n    local_tid_18730 = get_local_id(0);\n    tblock_sizze_18733 = get_local_size(0);\n    wave_sizze_18732 = LOCKSTEP_WIDTH;\n    block_id_18731 = get_tblock_id(0);\n    global_tid_18729 = block_id_18731 * tblock_sizze_18733 + local_tid_18730;\n    phys_tid_17382 = sext_i32_i64(global_tid_18729);\n    global_tid_18734 = sext_i32_i64(block_id_18731) * segmap_tblock_sizze_17377 + sext_i32_i64(local_tid_18730);\n    slice_18735 = corePts_15993;\n    slice_18736 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019 * slice_18735;\n    gtid_17380 = squot64(global_tid_18734, slice_18735);\n    remnant_18737 = global_tid_18734 - gtid_17380 * slice_18735;\n    gtid_17381 = remnant_18737;\n    remnant_18738 = remnant_18737 - gtid_17381;\n    if (slt64(gtid_17380, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019) && slt64(gtid_17381, corePts_15993)) {\n        float defunc_0_f_res_17384;\n        float acc_17386;\n        float sqrt_res_17389;\n        \n        acc_17386 = 0.0F;\n        for (int64_t i_17385 = 0; i_17385 < dimz2081U_13120; i_17385++) {\n            float b_17387;\n            float zp_res_17388;\n            float acc_tmp_18739;\n            \n            b_17387 = ((__global float *) mem_18451)[gtid_17380 * corePts_15993 + gtid_17381 + i_17385 * (corePts_15993 * dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019)];\n            zp_res_17388 = acc_17386 + b_17387;\n            acc_tmp_18739 = zp_res_17388;\n            acc_17386 = acc_tmp_18739;\n        }\n        defunc_0_f_res_17384 = acc_17386;\n        sqrt_res_17389 = futrts_sqrt32(defunc_0_f_res_17384);\n        ((__global float *) mem_18455)[gtid_17380 * corePts_15993 + gtid_17381] = sqrt_res_17389;\n    }\n  ", "  \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_17377\n}\nFUTHARK_KERNEL\nvoid ftDBSCAN_floatzisegmap_intrablock_17151(__global int *global_failure, int64_t dimz2081U_13120, float eps_13122, int64_t corePts_15993, int64_t inf_16016, int64_t dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, int64_t ctx_18584, __global unsigned char *dat_mem_18419, __global unsigned char *ext_mem_18423, __global unsigned char *ext_mem_18424, __global unsigned char *mem_18426, __global unsigned char *color_18527)\n{\n    volatile __local unsigned char *red_arr_mem_18709_backing_1 = &shared_mem[0];\n    const int64_t red_arr_mem_18709_backing_1_offset = 0 + ((int64_t) 4 * corePts_15993 + srem64((int64_t) 8 - srem64((int64_t) 4 * corePts_15993, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *red_arr_mem_18707_backing_0 = &shared_mem[red_arr_mem_18709_backing_1_offset];\n    const int64_t red_arr_mem_18707_backing_0_offset = red_arr_mem_18709_backing_1_offset + ((int64_t) 8 * corePts_15993 + srem64((int64_t) 8 - srem64((int64_t) 8 * corePts_15993, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18698;\n    int32_t tblock_sizze_18701;\n    int32_t wave_sizze_18700;\n    int32_t block_id_18699;\n    int32_t global_tid_18697;\n    int64_t phys_tblock_id_17151;\n    int64_t slice_18703;\n    int64_t ltid_pre_18702;\n    int64_t remnant_18704;\n    int64_t slice_18705;\n    int64_t gtid_17150;\n    int64_t remnant_18706;\n    int64_t slice_18396;\n    int64_t binop_x_18582;\n    int64_t defunc_0_f_res_17154;\n    float defunc_0_f_res_17155;\n    int64_t phys_tid_17157;\n    __local unsigned char *red_arr_mem_18707;\n    __local unsigned char *red_arr_mem_18709;\n    int64_t gtid_17156;\n    int64_t x_17171;\n    int64_t ctx_18583;\n    float defunc_0_f_res_17177;\n    float acc_17179;\n    float sqrt_res_17182;\n    int32_t offset_18713;\n    int32_t skip_waves_18714;\n    int64_t eta_p_17158;\n    float eta_p_17159;\n    int64_t eta_p_17160;\n    float e",
                                    "ta_p_17161;\n    \n    local_tid_18698 = get_local_id(0);\n    tblock_sizze_18701 = get_local_size(0);\n    wave_sizze_18700 = LOCKSTEP_WIDTH;\n    block_id_18699 = get_tblock_id(0);\n    global_tid_18697 = block_id_18699 * tblock_sizze_18701 + local_tid_18698;\n    phys_tblock_id_17151 = sext_i32_i64(block_id_18699);\n    slice_18703 = corePts_15993;\n    ltid_pre_18702 = sext_i32_i64(local_tid_18698);\n    remnant_18704 = sext_i32_i64(local_tid_18698) - ltid_pre_18702;\n    slice_18705 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019;\n    gtid_17150 = sext_i32_i64(block_id_18699);\n    remnant_18706 = sext_i32_i64(block_id_18699) - gtid_17150;\n    slice_18396 = inf_16016 + gtid_17150;\n    binop_x_18582 = corePts_15993 * phys_tblock_id_17151;\n    phys_tid_17157 = sext_i32_i64(local_tid_18698);\n    red_arr_mem_18707 = (__local unsigned char *) red_arr_mem_18707_backing_0;\n    red_arr_mem_18709 = (__local unsigned char *) red_arr_mem_18709_backing_1;\n    gtid_17156 = sext_i32_i64(sext_i64_i32(ltid_pre_18702));\n    x_17171 = ((__global int64_t *) ext_mem_18424)[gtid_17156];\n    ctx_18583 = phys_tid_17157 + binop_x_18582;\n    for (int64_t i_18415 = 0; i_18415 < dimz2081U_13120; i_18415++) {\n        float eta_p_17173;\n        float eta_p_17174;\n        float zm_res_17175;\n        float zt_res_17176;\n        \n        eta_p_17173 = ((__global float *) dat_mem_18419)[slice_18396 * dimz2081U_13120 + i_18415];\n        eta_p_17174 = ((__global float *) ext_mem_18423)[gtid_17156 * dimz2081U_13120 + i_18415];\n        zm_res_17175 = eta_p_17173 - eta_p_17174;\n        zt_res_17176 = zm_res_17175 * zm_res_17175;\n        ((__global float *) color_18527)[ctx_18583 + i_18415 * ctx_18584] = zt_res_17176;\n    }\n    acc_17179 = 0.0F;\n    for (int64_t i_17178 = 0; i_17178 < dimz2081U_13120; i_17178++) {\n        float b_17180;\n        float zp_res_17181;\n        float acc_tmp_18712;\n        \n        b_17180 = ((__global float *) color_18527)[ctx_18583 + i_17178 * ctx_18584];\n        zp_res_17181 = acc_17179", " + b_17180;\n        acc_tmp_18712 = zp_res_17181;\n        acc_17179 = acc_tmp_18712;\n    }\n    defunc_0_f_res_17177 = acc_17179;\n    sqrt_res_17182 = futrts_sqrt32(defunc_0_f_res_17177);\n    ((__local int64_t *) red_arr_mem_18707)[gtid_17156] = x_17171;\n    ((__local float *) red_arr_mem_18709)[gtid_17156] = sqrt_res_17182;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    skip_waves_18714 = 1;\n    offset_18713 = 0;\n    // participating threads read initial accumulator\n    {\n        if (slt32(local_tid_18698, sext_i64_i32(corePts_15993))) {\n            eta_p_17158 = ((__local int64_t *) red_arr_mem_18707)[sext_i32_i64(local_tid_18698 + offset_18713)];\n            eta_p_17159 = ((__local float *) red_arr_mem_18709)[sext_i32_i64(local_tid_18698 + offset_18713)];\n        }\n    }\n    offset_18713 = 1;\n    while (slt32(offset_18713, wave_sizze_18700)) {\n        if (slt32(local_tid_18698 + offset_18713, sext_i64_i32(corePts_15993)) && ((local_tid_18698 - squot32(local_tid_18698, wave_sizze_18700) * wave_sizze_18700) & (2 * offset_18713 - 1)) == 0) {\n            // read array element\n            {\n                eta_p_17160 = ((volatile __local int64_t *) red_arr_mem_18707)[sext_i32_i64(local_tid_18698 + offset_18713)];\n                eta_p_17161 = ((volatile __local float *) red_arr_mem_18709)[sext_i32_i64(local_tid_18698 + offset_18713)];\n            }\n            // apply reduction operation\n            {\n                bool zg_res_17162 = eps_13122 < eta_p_17159;\n                bool zg_res_17163 = eps_13122 < eta_p_17161;\n                bool x_17164 = zg_res_17162 && zg_res_17163;\n                int64_t lifted_lambda_res_17165;\n                float lifted_lambda_res_17166;\n                \n                if (x_17164) {\n                    lifted_lambda_res_17165 = (int64_t) -1;\n                    lifted_lambda_res_17166 = INFINITY;\n                } else {\n                    bool zl_res_17167 = eta_p_17159 < eta_p_17161;\n                    int64_t lifted_lambda_res_f_re", "s_17168;\n                    \n                    if (zl_res_17167) {\n                        lifted_lambda_res_f_res_17168 = eta_p_17158;\n                    } else {\n                        lifted_lambda_res_f_res_17168 = eta_p_17160;\n                    }\n                    \n                    float lifted_lambda_res_f_res_17169;\n                    \n                    if (zl_res_17167) {\n                        lifted_lambda_res_f_res_17169 = eta_p_17159;\n                    } else {\n                        lifted_lambda_res_f_res_17169 = eta_p_17161;\n                    }\n                    lifted_lambda_res_17165 = lifted_lambda_res_f_res_17168;\n                    lifted_lambda_res_17166 = lifted_lambda_res_f_res_17169;\n                }\n                eta_p_17158 = lifted_lambda_res_17165;\n                eta_p_17159 = lifted_lambda_res_17166;\n            }\n            // write result of operation\n            {\n                ((volatile __local int64_t *) red_arr_mem_18707)[sext_i32_i64(local_tid_18698)] = eta_p_17158;\n                ((volatile __local float *) red_arr_mem_18709)[sext_i32_i64(local_tid_18698)] = eta_p_17159;\n            }\n        }\n        offset_18713 *= 2;\n    }\n    while (slt32(skip_waves_18714, squot32(sext_i64_i32(corePts_15993) + wave_sizze_18700 - 1, wave_sizze_18700))) {\n        barrier(CLK_LOCAL_MEM_FENCE);\n        offset_18713 = skip_waves_18714 * wave_sizze_18700;\n        if (slt32(local_tid_18698 + offset_18713, sext_i64_i32(corePts_15993)) && ((local_tid_18698 - squot32(local_tid_18698, wave_sizze_18700) * wave_sizze_18700) == 0 && (squot32(local_tid_18698, wave_sizze_18700) & (2 * skip_waves_18714 - 1)) == 0)) {\n            // read array element\n            {\n                eta_p_17160 = ((__local int64_t *) red_arr_mem_18707)[sext_i32_i64(local_tid_18698 + offset_18713)];\n                eta_p_17161 = ((__local float *) red_arr_mem_18709)[sext_i32_i64(local_tid_18698 + offset_18713)];\n            }\n            // apply",
                                    " reduction operation\n            {\n                bool zg_res_17162 = eps_13122 < eta_p_17159;\n                bool zg_res_17163 = eps_13122 < eta_p_17161;\n                bool x_17164 = zg_res_17162 && zg_res_17163;\n                int64_t lifted_lambda_res_17165;\n                float lifted_lambda_res_17166;\n                \n                if (x_17164) {\n                    lifted_lambda_res_17165 = (int64_t) -1;\n                    lifted_lambda_res_17166 = INFINITY;\n                } else {\n                    bool zl_res_17167 = eta_p_17159 < eta_p_17161;\n                    int64_t lifted_lambda_res_f_res_17168;\n                    \n                    if (zl_res_17167) {\n                        lifted_lambda_res_f_res_17168 = eta_p_17158;\n                    } else {\n                        lifted_lambda_res_f_res_17168 = eta_p_17160;\n                    }\n                    \n                    float lifted_lambda_res_f_res_17169;\n                    \n                    if (zl_res_17167) {\n                        lifted_lambda_res_f_res_17169 = eta_p_17159;\n                    } else {\n                        lifted_lambda_res_f_res_17169 = eta_p_17161;\n                    }\n                    lifted_lambda_res_17165 = lifted_lambda_res_f_res_17168;\n                    lifted_lambda_res_17166 = lifted_lambda_res_f_res_17169;\n                }\n                eta_p_17158 = lifted_lambda_res_17165;\n                eta_p_17159 = lifted_lambda_res_17166;\n            }\n            // write result of operation\n            {\n                ((__local int64_t *) red_arr_mem_18707)[sext_i32_i64(local_tid_18698)] = eta_p_17158;\n                ((__local float *) red_arr_mem_18709)[sext_i32_i64(local_tid_18698)] = eta_p_17159;\n            }\n        }\n        skip_waves_18714 *= 2;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // Save result of reduction.\n    {\n        defunc_0_f_res_17154 = ((__local int64_t *) red_arr_mem_18707)[(", "int64_t) 0];\n        defunc_0_f_res_17155 = ((__local float *) red_arr_mem_18709)[(int64_t) 0];\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    if (local_tid_18698 == 0) {\n        ((__global int64_t *) mem_18426)[inf_16016 + gtid_17150] = defunc_0_f_res_17154;\n    }\n    \n  error_4:\n    return;\n}\nFUTHARK_KERNEL_SIZED(ftDBSCAN_floatzisegred_large_17401_dim1, 1, 1)\nvoid ftDBSCAN_floatzisegred_large_17401(__global int *global_failure, float eps_13122, int64_t corePts_15993, int64_t inf_16016, int64_t dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, int64_t num_tblocks_17395, int64_t blocks_per_segment_18781, int64_t q_18782, int64_t num_virtblocks_18783, int64_t threads_per_segment_18784, __global unsigned char *ext_mem_18424, __global unsigned char *mem_18426, __global unsigned char *mem_18455, __global unsigned char *mem_18460, __global unsigned char *segred_tmp_mem_18785, __global unsigned char *segred_tmp_mem_18787, __global unsigned char *counters_mem_18789)\n{\n    #define segred_tblock_sizze_17394 (ftDBSCAN_floatzisegred_large_17401zisegred_tblock_sizze_17394)\n    #define chunk_sizze_18740 (ftDBSCAN_floatzisegred_large_17401zichunk_sizze_18740)\n    \n    volatile __local unsigned char *sync_arr_mem_18820_backing_2 = &shared_mem[0];\n    const int64_t sync_arr_mem_18820_backing_2_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_f32_mem_18818_backing_1 = &shared_mem[sync_arr_mem_18820_backing_2_offset];\n    const int64_t red_arr_f32_mem_18818_backing_1_offset = sync_arr_mem_18820_backing_2_offset + ((int64_t) 4 * segred_tblock_sizze_17394 + srem64((int64_t) 8 - srem64((int64_t) 4 * segred_tblock_sizze_17394, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *red_arr_i64_mem_18816_backing_0 = &shared_mem[red_arr_f32_mem_18818_backing_1_offset];\n    const int64_t red_arr_i64_mem_18816_backing_0_offset = red_arr_f32_mem_18818_backing_1_offset + ((int64_t) 8 * segred_tblock_sizze_17394 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_17394, (int", "64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18812;\n    int32_t tblock_sizze_18815;\n    int32_t wave_sizze_18814;\n    int32_t block_id_18813;\n    int32_t global_tid_18811;\n    int64_t phys_tid_17401;\n    __local unsigned char *red_arr_i64_mem_18816;\n    __local unsigned char *red_arr_f32_mem_18818;\n    __local unsigned char *sync_arr_mem_18820;\n    int32_t phys_tblock_id_18822;\n    int32_t iterations_18823;\n    \n    local_tid_18812 = get_local_id(0);\n    tblock_sizze_18815 = get_local_size(0);\n    wave_sizze_18814 = LOCKSTEP_WIDTH;\n    block_id_18813 = get_tblock_id(0);\n    global_tid_18811 = block_id_18813 * tblock_sizze_18815 + local_tid_18812;\n    phys_tid_17401 = sext_i32_i64(global_tid_18811);\n    red_arr_i64_mem_18816 = (__local unsigned char *) red_arr_i64_mem_18816_backing_0;\n    red_arr_f32_mem_18818 = (__local unsigned char *) red_arr_f32_mem_18818_backing_1;\n    sync_arr_mem_18820 = (__local unsigned char *) sync_arr_mem_18820_backing_2;\n    phys_tblock_id_18822 = get_tblock_id(0);\n    iterations_18823 = sdiv_up32(sext_i64_i32(num_virtblocks_18783) - phys_tblock_id_18822, sext_i64_i32(num_tblocks_17395));\n    for (int32_t i_18824 = 0; i_18824 < iterations_18823; i_18824++) {\n        int32_t virt_tblock_id_18825;\n        int64_t flat_segment_id_18826;\n        int64_t global_tid_18827;\n        int64_t slice_18828;\n        int64_t gtid_17399;\n        int64_t remnant_18829;\n        int64_t gtid_17400;\n        int64_t eta_p_block_res_acc_18830;\n        float eta_p_block_res_acc_18831;\n        int64_t eta_p_17402;\n        float eta_p_17403;\n        int64_t eta_p_17404;\n        float eta_p_17405;\n        int64_t tblock_id_in_segment_18844;\n        int64_t block_base_offset_18845;\n        int32_t offset_18848;\n        int32_t skip_waves_18849;\n        int64_t eta_p_18832;\n        float eta_p_18833;\n        int64_t eta_p_18834;\n        float eta_p_18835;\n        \n        virt_tblock_id_18825 = phys_tblock_i",
                                    "d_18822 + i_18824 * sext_i64_i32(num_tblocks_17395);\n        flat_segment_id_18826 = squot64(sext_i32_i64(virt_tblock_id_18825), blocks_per_segment_18781);\n        global_tid_18827 = srem64(sext_i32_i64(virt_tblock_id_18825) * segred_tblock_sizze_17394 + sext_i32_i64(local_tid_18812), threads_per_segment_18784);\n        slice_18828 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019;\n        gtid_17399 = flat_segment_id_18826;\n        remnant_18829 = flat_segment_id_18826 - gtid_17399;\n        // ne-initialise the outer (per-block) accumulator(s)\n        {\n            eta_p_block_res_acc_18830 = (int64_t) -1;\n            eta_p_block_res_acc_18831 = INFINITY;\n        }\n        tblock_id_in_segment_18844 = squot64(global_tid_18827, segred_tblock_sizze_17394);\n        block_base_offset_18845 = tblock_id_in_segment_18844 * q_18782 * segred_tblock_sizze_17394;\n        for (int64_t i_18846 = 0; i_18846 < q_18782; i_18846++) {\n            int64_t block_offset_18847 = block_base_offset_18845 + i_18846 * segred_tblock_sizze_17394;\n            \n            gtid_17400 = global_tid_18827 + threads_per_segment_18784 * i_18846;\n            if (slt64(gtid_17400, corePts_15993)) {\n                // apply map function(s)\n                {\n                    // apply map function\n                    {\n                        int64_t x_17416 = ((__global int64_t *) ext_mem_18424)[gtid_17400];\n                        float x_17417 = ((__global float *) mem_18455)[gtid_17399 * corePts_15993 + gtid_17400];\n                        \n                        // load accumulator(s)\n                        {\n                            eta_p_17402 = eta_p_block_res_acc_18830;\n                            eta_p_17403 = eta_p_block_res_acc_18831;\n                        }\n                        // load next value(s)\n                        {\n                            eta_p_17404 = x_17416;\n                            eta_p_17405 = x_17417;\n                        }\n                        // apply red", "uction operator(s)\n                        {\n                            bool zg_res_17406 = eps_13122 < eta_p_17403;\n                            bool zg_res_17407 = eps_13122 < eta_p_17405;\n                            bool x_17408 = zg_res_17406 && zg_res_17407;\n                            int64_t lifted_lambda_res_17409;\n                            float lifted_lambda_res_17410;\n                            \n                            if (x_17408) {\n                                lifted_lambda_res_17409 = (int64_t) -1;\n                                lifted_lambda_res_17410 = INFINITY;\n                            } else {\n                                bool zl_res_17411 = eta_p_17403 < eta_p_17405;\n                                int64_t lifted_lambda_res_f_res_17412;\n                                \n                                if (zl_res_17411) {\n                                    lifted_lambda_res_f_res_17412 = eta_p_17402;\n                                } else {\n                                    lifted_lambda_res_f_res_17412 = eta_p_17404;\n                                }\n                                \n                                float lifted_lambda_res_f_res_17413;\n                                \n                                if (zl_res_17411) {\n                                    lifted_lambda_res_f_res_17413 = eta_p_17403;\n                                } else {\n                                    lifted_lambda_res_f_res_17413 = eta_p_17405;\n                                }\n                                lifted_lambda_res_17409 = lifted_lambda_res_f_res_17412;\n                                lifted_lambda_res_17410 = lifted_lambda_res_f_res_17413;\n                            }\n                            // store in accumulator(s)\n                            {\n                                eta_p_block_res_acc_18830 = lifted_lambda_res_17409;\n                                eta_p_block_res_acc_18831 = lifted_lambda_res_17410;\n        ", "                    }\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // store accs. prims go in lmem; non-prims in params (in global mem)\n        {\n            ((__local int64_t *) red_arr_i64_mem_18816)[sext_i32_i64(local_tid_18812)] = eta_p_block_res_acc_18830;\n            ((__local float *) red_arr_f32_mem_18818)[sext_i32_i64(local_tid_18812)] = eta_p_block_res_acc_18831;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        skip_waves_18849 = 1;\n        offset_18848 = 0;\n        // participating threads read initial accumulator\n        {\n            if (slt32(local_tid_18812, sext_i64_i32(segred_tblock_sizze_17394))) {\n                eta_p_18832 = ((__local int64_t *) red_arr_i64_mem_18816)[sext_i32_i64(local_tid_18812 + offset_18848)];\n                eta_p_18833 = ((__local float *) red_arr_f32_mem_18818)[sext_i32_i64(local_tid_18812 + offset_18848)];\n            }\n        }\n        offset_18848 = 1;\n        while (slt32(offset_18848, wave_sizze_18814)) {\n            if (slt32(local_tid_18812 + offset_18848, sext_i64_i32(segred_tblock_sizze_17394)) && ((local_tid_18812 - squot32(local_tid_18812, wave_sizze_18814) * wave_sizze_18814) & (2 * offset_18848 - 1)) == 0) {\n                // read array element\n                {\n                    eta_p_18834 = ((volatile __local int64_t *) red_arr_i64_mem_18816)[sext_i32_i64(local_tid_18812 + offset_18848)];\n                    eta_p_18835 = ((volatile __local float *) red_arr_f32_mem_18818)[sext_i32_i64(local_tid_18812 + offset_18848)];\n                }\n                // apply reduction operation\n                {\n                    bool zg_res_18836 = eps_13122 < eta_p_18833;\n                    bool zg_res_18837 = eps_13122 < eta_p_18835;\n                    bool x_18838 = zg_res_18836 && zg_res_18837;\n                    int64_t lifted_lambda_res_18839;\n                    float lifted_lambda_res_18840;\n               ",
                                    "     \n                    if (x_18838) {\n                        lifted_lambda_res_18839 = (int64_t) -1;\n                        lifted_lambda_res_18840 = INFINITY;\n                    } else {\n                        bool zl_res_18841 = eta_p_18833 < eta_p_18835;\n                        int64_t lifted_lambda_res_f_res_18842;\n                        \n                        if (zl_res_18841) {\n                            lifted_lambda_res_f_res_18842 = eta_p_18832;\n                        } else {\n                            lifted_lambda_res_f_res_18842 = eta_p_18834;\n                        }\n                        \n                        float lifted_lambda_res_f_res_18843;\n                        \n                        if (zl_res_18841) {\n                            lifted_lambda_res_f_res_18843 = eta_p_18833;\n                        } else {\n                            lifted_lambda_res_f_res_18843 = eta_p_18835;\n                        }\n                        lifted_lambda_res_18839 = lifted_lambda_res_f_res_18842;\n                        lifted_lambda_res_18840 = lifted_lambda_res_f_res_18843;\n                    }\n                    eta_p_18832 = lifted_lambda_res_18839;\n                    eta_p_18833 = lifted_lambda_res_18840;\n                }\n                // write result of operation\n                {\n                    ((volatile __local int64_t *) red_arr_i64_mem_18816)[sext_i32_i64(local_tid_18812)] = eta_p_18832;\n                    ((volatile __local float *) red_arr_f32_mem_18818)[sext_i32_i64(local_tid_18812)] = eta_p_18833;\n                }\n            }\n            offset_18848 *= 2;\n        }\n        while (slt32(skip_waves_18849, squot32(sext_i64_i32(segred_tblock_sizze_17394) + wave_sizze_18814 - 1, wave_sizze_18814))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_18848 = skip_waves_18849 * wave_sizze_18814;\n            if (slt32(local_tid_18812 + offset_18848, sext_i64_i32(segred_tblock_sizze_17394)) && ((local_t", "id_18812 - squot32(local_tid_18812, wave_sizze_18814) * wave_sizze_18814) == 0 && (squot32(local_tid_18812, wave_sizze_18814) & (2 * skip_waves_18849 - 1)) == 0)) {\n                // read array element\n                {\n                    eta_p_18834 = ((__local int64_t *) red_arr_i64_mem_18816)[sext_i32_i64(local_tid_18812 + offset_18848)];\n                    eta_p_18835 = ((__local float *) red_arr_f32_mem_18818)[sext_i32_i64(local_tid_18812 + offset_18848)];\n                }\n                // apply reduction operation\n                {\n                    bool zg_res_18836 = eps_13122 < eta_p_18833;\n                    bool zg_res_18837 = eps_13122 < eta_p_18835;\n                    bool x_18838 = zg_res_18836 && zg_res_18837;\n                    int64_t lifted_lambda_res_18839;\n                    float lifted_lambda_res_18840;\n                    \n                    if (x_18838) {\n                        lifted_lambda_res_18839 = (int64_t) -1;\n                        lifted_lambda_res_18840 = INFINITY;\n                    } else {\n                        bool zl_res_18841 = eta_p_18833 < eta_p_18835;\n                        int64_t lifted_lambda_res_f_res_18842;\n                        \n                        if (zl_res_18841) {\n                            lifted_lambda_res_f_res_18842 = eta_p_18832;\n                        } else {\n                            lifted_lambda_res_f_res_18842 = eta_p_18834;\n                        }\n                        \n                        float lifted_lambda_res_f_res_18843;\n                        \n                        if (zl_res_18841) {\n                            lifted_lambda_res_f_res_18843 = eta_p_18833;\n                        } else {\n                            lifted_lambda_res_f_res_18843 = eta_p_18835;\n                        }\n                        lifted_lambda_res_18839 = lifted_lambda_res_f_res_18842;\n                        lifted_lambda_res_18840 = lifted_lambda_res_f_res_18843;\n            ", "        }\n                    eta_p_18832 = lifted_lambda_res_18839;\n                    eta_p_18833 = lifted_lambda_res_18840;\n                }\n                // write result of operation\n                {\n                    ((__local int64_t *) red_arr_i64_mem_18816)[sext_i32_i64(local_tid_18812)] = eta_p_18832;\n                    ((__local float *) red_arr_f32_mem_18818)[sext_i32_i64(local_tid_18812)] = eta_p_18833;\n                }\n            }\n            skip_waves_18849 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // thread 0 updates per-block acc(s); rest reset to ne\n        {\n            if (sext_i32_i64(local_tid_18812) == (int64_t) 0) {\n                eta_p_block_res_acc_18830 = eta_p_18832;\n                eta_p_block_res_acc_18831 = eta_p_18833;\n            } else {\n                eta_p_block_res_acc_18830 = (int64_t) -1;\n                eta_p_block_res_acc_18831 = INFINITY;\n            }\n        }\n        if (blocks_per_segment_18781 == (int64_t) 1) {\n            // first thread in block saves final result to memory\n            {\n                if (local_tid_18812 == 0) {\n                    ((__global int64_t *) mem_18426)[inf_16016 + gtid_17399] = eta_p_block_res_acc_18830;\n                    ((__global float *) mem_18460)[gtid_17399] = eta_p_block_res_acc_18831;\n                }\n            }\n        } else {\n            int32_t old_counter_18850;\n            bool is_last_block_18851;\n            \n            // first thread in block saves block result to global memory\n            {\n                if (local_tid_18812 == 0) {\n                    ((__global int64_t *) segred_tmp_mem_18785)[sext_i32_i64(virt_tblock_id_18825)] = eta_p_block_res_acc_18830;\n                    mem_fence_global();\n                    ((__global float *) segred_tmp_mem_18787)[sext_i32_i64(virt_tblock_id_18825)] = eta_p_block_res_acc_18831;\n                    mem_fence_global();\n                    old_count",
                                    "er_18850 = atomic_add_i32_global(&((volatile __global int *) counters_mem_18789)[srem64(flat_segment_id_18826, (int64_t) 20480)], (int) 1);\n                    ((__local bool *) sync_arr_mem_18820)[(int64_t) 0] = old_counter_18850 == sext_i64_i32(blocks_per_segment_18781 - (int64_t) 1);\n                }\n            }\n            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n            is_last_block_18851 = ((__local bool *) sync_arr_mem_18820)[(int64_t) 0];\n            if (is_last_block_18851) {\n                if (local_tid_18812 == 0) {\n                    old_counter_18850 = atomic_add_i32_global(&((volatile __global int *) counters_mem_18789)[srem64(flat_segment_id_18826, (int64_t) 20480)], (int) sext_i64_i32((int64_t) 0 - blocks_per_segment_18781));\n                }\n                // read in the per-block-results\n                {\n                    int64_t read_per_thread_18852 = sdiv_up64(blocks_per_segment_18781, segred_tblock_sizze_17394);\n                    \n                    eta_p_17402 = (int64_t) -1;\n                    eta_p_17403 = INFINITY;\n                    for (int64_t i_18853 = 0; i_18853 < read_per_thread_18852; i_18853++) {\n                        int64_t block_res_id_18854 = sext_i32_i64(local_tid_18812) * read_per_thread_18852 + i_18853;\n                        int64_t index_of_block_res_18855 = flat_segment_id_18826 * blocks_per_segment_18781 + block_res_id_18854;\n                        \n                        if (slt64(block_res_id_18854, blocks_per_segment_18781)) {\n                            eta_p_17404 = ((__global int64_t *) segred_tmp_mem_18785)[index_of_block_res_18855];\n                            eta_p_17405 = ((__global float *) segred_tmp_mem_18787)[index_of_block_res_18855];\n                            \n                            bool zg_res_17406 = eps_13122 < eta_p_17403;\n                            bool zg_res_17407 = eps_13122 < eta_p_17405;\n                            bool x_17408 = zg_res_17406 && zg_res", "_17407;\n                            int64_t lifted_lambda_res_17409;\n                            float lifted_lambda_res_17410;\n                            \n                            if (x_17408) {\n                                lifted_lambda_res_17409 = (int64_t) -1;\n                                lifted_lambda_res_17410 = INFINITY;\n                            } else {\n                                bool zl_res_17411 = eta_p_17403 < eta_p_17405;\n                                int64_t lifted_lambda_res_f_res_17412;\n                                \n                                if (zl_res_17411) {\n                                    lifted_lambda_res_f_res_17412 = eta_p_17402;\n                                } else {\n                                    lifted_lambda_res_f_res_17412 = eta_p_17404;\n                                }\n                                \n                                float lifted_lambda_res_f_res_17413;\n                                \n                                if (zl_res_17411) {\n                                    lifted_lambda_res_f_res_17413 = eta_p_17403;\n                                } else {\n                                    lifted_lambda_res_f_res_17413 = eta_p_17405;\n                                }\n                                lifted_lambda_res_17409 = lifted_lambda_res_f_res_17412;\n                                lifted_lambda_res_17410 = lifted_lambda_res_f_res_17413;\n                            }\n                            eta_p_17402 = lifted_lambda_res_17409;\n                            eta_p_17403 = lifted_lambda_res_17410;\n                        }\n                    }\n                }\n                ((__local int64_t *) red_arr_i64_mem_18816)[sext_i32_i64(local_tid_18812)] = eta_p_17402;\n                ((__local float *) red_arr_f32_mem_18818)[sext_i32_i64(local_tid_18812)] = eta_p_17403;\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // reduce the per-block results\n               ", " {\n                    int32_t offset_18856;\n                    int32_t skip_waves_18857 = 1;\n                    int64_t eta_p_18832;\n                    float eta_p_18833;\n                    int64_t eta_p_18834;\n                    float eta_p_18835;\n                    \n                    offset_18856 = 0;\n                    // participating threads read initial accumulator\n                    {\n                        if (slt32(local_tid_18812, sext_i64_i32(segred_tblock_sizze_17394))) {\n                            eta_p_18832 = ((__local int64_t *) red_arr_i64_mem_18816)[sext_i32_i64(local_tid_18812 + offset_18856)];\n                            eta_p_18833 = ((__local float *) red_arr_f32_mem_18818)[sext_i32_i64(local_tid_18812 + offset_18856)];\n                        }\n                    }\n                    offset_18856 = 1;\n                    while (slt32(offset_18856, wave_sizze_18814)) {\n                        if (slt32(local_tid_18812 + offset_18856, sext_i64_i32(segred_tblock_sizze_17394)) && ((local_tid_18812 - squot32(local_tid_18812, wave_sizze_18814) * wave_sizze_18814) & (2 * offset_18856 - 1)) == 0) {\n                            // read array element\n                            {\n                                eta_p_18834 = ((volatile __local int64_t *) red_arr_i64_mem_18816)[sext_i32_i64(local_tid_18812 + offset_18856)];\n                                eta_p_18835 = ((volatile __local float *) red_arr_f32_mem_18818)[sext_i32_i64(local_tid_18812 + offset_18856)];\n                            }\n                            // apply reduction operation\n                            {\n                                bool zg_res_18836 = eps_13122 < eta_p_18833;\n                                bool zg_res_18837 = eps_13122 < eta_p_18835;\n                                bool x_18838 = zg_res_18836 && zg_res_18837;\n                                int64_t lifted_lambda_res_18839;\n                                float lifted_lambda_res_18840;\n        ",
                                    "                        \n                                if (x_18838) {\n                                    lifted_lambda_res_18839 = (int64_t) -1;\n                                    lifted_lambda_res_18840 = INFINITY;\n                                } else {\n                                    bool zl_res_18841 = eta_p_18833 < eta_p_18835;\n                                    int64_t lifted_lambda_res_f_res_18842;\n                                    \n                                    if (zl_res_18841) {\n                                        lifted_lambda_res_f_res_18842 = eta_p_18832;\n                                    } else {\n                                        lifted_lambda_res_f_res_18842 = eta_p_18834;\n                                    }\n                                    \n                                    float lifted_lambda_res_f_res_18843;\n                                    \n                                    if (zl_res_18841) {\n                                        lifted_lambda_res_f_res_18843 = eta_p_18833;\n                                    } else {\n                                        lifted_lambda_res_f_res_18843 = eta_p_18835;\n                                    }\n                                    lifted_lambda_res_18839 = lifted_lambda_res_f_res_18842;\n                                    lifted_lambda_res_18840 = lifted_lambda_res_f_res_18843;\n                                }\n                                eta_p_18832 = lifted_lambda_res_18839;\n                                eta_p_18833 = lifted_lambda_res_18840;\n                            }\n                            // write result of operation\n                            {\n                                ((volatile __local int64_t *) red_arr_i64_mem_18816)[sext_i32_i64(local_tid_18812)] = eta_p_18832;\n                                ((volatile __local float *) red_arr_f32_mem_18818)[sext_i32_i64(local_tid_18812)] = eta_p_18833;\n                            }\n          ", "              }\n                        offset_18856 *= 2;\n                    }\n                    while (slt32(skip_waves_18857, squot32(sext_i64_i32(segred_tblock_sizze_17394) + wave_sizze_18814 - 1, wave_sizze_18814))) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                        offset_18856 = skip_waves_18857 * wave_sizze_18814;\n                        if (slt32(local_tid_18812 + offset_18856, sext_i64_i32(segred_tblock_sizze_17394)) && ((local_tid_18812 - squot32(local_tid_18812, wave_sizze_18814) * wave_sizze_18814) == 0 && (squot32(local_tid_18812, wave_sizze_18814) & (2 * skip_waves_18857 - 1)) == 0)) {\n                            // read array element\n                            {\n                                eta_p_18834 = ((__local int64_t *) red_arr_i64_mem_18816)[sext_i32_i64(local_tid_18812 + offset_18856)];\n                                eta_p_18835 = ((__local float *) red_arr_f32_mem_18818)[sext_i32_i64(local_tid_18812 + offset_18856)];\n                            }\n                            // apply reduction operation\n                            {\n                                bool zg_res_18836 = eps_13122 < eta_p_18833;\n                                bool zg_res_18837 = eps_13122 < eta_p_18835;\n                                bool x_18838 = zg_res_18836 && zg_res_18837;\n                                int64_t lifted_lambda_res_18839;\n                                float lifted_lambda_res_18840;\n                                \n                                if (x_18838) {\n                                    lifted_lambda_res_18839 = (int64_t) -1;\n                                    lifted_lambda_res_18840 = INFINITY;\n                                } else {\n                                    bool zl_res_18841 = eta_p_18833 < eta_p_18835;\n                                    int64_t lifted_lambda_res_f_res_18842;\n                                    \n                                    if (zl_res_18841) {\n            ", "                            lifted_lambda_res_f_res_18842 = eta_p_18832;\n                                    } else {\n                                        lifted_lambda_res_f_res_18842 = eta_p_18834;\n                                    }\n                                    \n                                    float lifted_lambda_res_f_res_18843;\n                                    \n                                    if (zl_res_18841) {\n                                        lifted_lambda_res_f_res_18843 = eta_p_18833;\n                                    } else {\n                                        lifted_lambda_res_f_res_18843 = eta_p_18835;\n                                    }\n                                    lifted_lambda_res_18839 = lifted_lambda_res_f_res_18842;\n                                    lifted_lambda_res_18840 = lifted_lambda_res_f_res_18843;\n                                }\n                                eta_p_18832 = lifted_lambda_res_18839;\n                                eta_p_18833 = lifted_lambda_res_18840;\n                            }\n                            // write result of operation\n                            {\n                                ((__local int64_t *) red_arr_i64_mem_18816)[sext_i32_i64(local_tid_18812)] = eta_p_18832;\n                                ((__local float *) red_arr_f32_mem_18818)[sext_i32_i64(local_tid_18812)] = eta_p_18833;\n                            }\n                        }\n                        skip_waves_18857 *= 2;\n                    }\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                    // and back to memory with the final result\n                    {\n                        if (local_tid_18812 == 0) {\n                            ((__global int64_t *) mem_18426)[inf_16016 + gtid_17399] = eta_p_18832;\n                            ((__global float *) mem_18460)[gtid_17399] = eta_p_18833;\n                        }\n                    }\n                }\n            }\n   ",
                                    "     }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_6:\n    return;\n    #undef segred_tblock_sizze_17394\n    #undef chunk_sizze_18740\n}\nFUTHARK_KERNEL_SIZED(ftDBSCAN_floatzisegred_small_17401_dim1, 1, 1)\nvoid ftDBSCAN_floatzisegred_small_17401(__global int *global_failure, float eps_13122, int64_t corePts_15993, int64_t inf_16016, int64_t dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, int64_t num_tblocks_17395, int64_t segment_sizze_nonzzero_18741, __global unsigned char *ext_mem_18424, __global unsigned char *mem_18426, __global unsigned char *mem_18455, __global unsigned char *mem_18460)\n{\n    #define segred_tblock_sizze_17394 (ftDBSCAN_floatzisegred_small_17401zisegred_tblock_sizze_17394)\n    \n    volatile __local unsigned char *red_arr_f32_mem_18750_backing_1 = &shared_mem[0];\n    const int64_t red_arr_f32_mem_18750_backing_1_offset = 0 + ((int64_t) 4 * segred_tblock_sizze_17394 + srem64((int64_t) 8 - srem64((int64_t) 4 * segred_tblock_sizze_17394, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *red_arr_i64_mem_18748_backing_0 = &shared_mem[red_arr_f32_mem_18750_backing_1_offset];\n    const int64_t red_arr_i64_mem_18748_backing_0_offset = red_arr_f32_mem_18750_backing_1_offset + ((int64_t) 8 * segred_tblock_sizze_17394 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_17394, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18744;\n    int32_t tblock_sizze_18747;\n    int32_t wave_sizze_18746;\n    int32_t block_id_18745;\n    int32_t global_tid_18743;\n    int64_t phys_tid_17401;\n    __local unsigned char *red_arr_i64_mem_18748;\n    __local unsigned char *red_arr_f32_mem_18750;\n    int32_t phys_tblock_id_18752;\n    int32_t iterations_18753;\n    \n    local_tid_18744 = get_local_id(0);\n    tblock_sizze_18747 = get_local_size(0);\n    wave_sizze_18746 = LOCKSTEP_WIDTH;\n    block_id_18745 = get_tblock_id(0);\n    global_tid_18743 = block_id_18745 * tblock_si", "zze_18747 + local_tid_18744;\n    phys_tid_17401 = sext_i32_i64(global_tid_18743);\n    red_arr_i64_mem_18748 = (__local unsigned char *) red_arr_i64_mem_18748_backing_0;\n    red_arr_f32_mem_18750 = (__local unsigned char *) red_arr_f32_mem_18750_backing_1;\n    phys_tblock_id_18752 = get_tblock_id(0);\n    iterations_18753 = sdiv_up32(sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, squot64(segred_tblock_sizze_17394, segment_sizze_nonzzero_18741))) - phys_tblock_id_18752, sext_i64_i32(num_tblocks_17395));\n    for (int32_t i_18754 = 0; i_18754 < iterations_18753; i_18754++) {\n        int32_t virt_tblock_id_18755;\n        int64_t slice_18756;\n        int64_t gtid_17399;\n        int64_t remnant_18757;\n        int64_t gtid_17400;\n        \n        virt_tblock_id_18755 = phys_tblock_id_18752 + i_18754 * sext_i64_i32(num_tblocks_17395);\n        slice_18756 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019;\n        gtid_17399 = squot64(sext_i32_i64(local_tid_18744), segment_sizze_nonzzero_18741) + sext_i32_i64(virt_tblock_id_18755) * squot64(segred_tblock_sizze_17394, segment_sizze_nonzzero_18741);\n        remnant_18757 = squot64(sext_i32_i64(local_tid_18744), segment_sizze_nonzzero_18741) + sext_i32_i64(virt_tblock_id_18755) * squot64(segred_tblock_sizze_17394, segment_sizze_nonzzero_18741) - gtid_17399;\n        gtid_17400 = srem64(sext_i32_i64(local_tid_18744), corePts_15993);\n        // apply map function if in bounds\n        {\n            if (slt64((int64_t) 0, corePts_15993) && (slt64(gtid_17399, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019) && slt64(sext_i32_i64(local_tid_18744), corePts_15993 * squot64(segred_tblock_sizze_17394, segment_sizze_nonzzero_18741)))) {\n                // apply map function\n                {\n                    int64_t x_17416 = ((__global int64_t *) ext_mem_18424)[gtid_17400];\n                    float x_17417 = ((__global float *) mem_18455)[gtid_17399 * corePts_15993 + gtid_17400];\n                    \n                    // save results ", "to be reduced\n                    {\n                        ((__local int64_t *) red_arr_i64_mem_18748)[sext_i32_i64(local_tid_18744)] = x_17416;\n                        ((__local float *) red_arr_f32_mem_18750)[sext_i32_i64(local_tid_18744)] = x_17417;\n                    }\n                }\n            } else {\n                ((__local int64_t *) red_arr_i64_mem_18748)[sext_i32_i64(local_tid_18744)] = (int64_t) -1;\n                ((__local float *) red_arr_f32_mem_18750)[sext_i32_i64(local_tid_18744)] = INFINITY;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (slt64((int64_t) 0, corePts_15993)) {\n            // perform segmented scan to imitate reduction\n            {\n                int64_t eta_p_17402;\n                float eta_p_17403;\n                int64_t eta_p_17404;\n                float eta_p_17405;\n                int64_t eta_p_18758;\n                float eta_p_18759;\n                int64_t eta_p_18760;\n                float eta_p_18761;\n                bool ltid_in_bounds_18770 = slt64(sext_i32_i64(local_tid_18744), corePts_15993 * squot64(segred_tblock_sizze_17394, segment_sizze_nonzzero_18741));\n                int32_t skip_threads_18771;\n                \n                // read input for in-block scan\n                {\n                    if (ltid_in_bounds_18770) {\n                        eta_p_17404 = ((volatile __local int64_t *) red_arr_i64_mem_18748)[sext_i32_i64(local_tid_18744)];\n                        eta_p_17405 = ((volatile __local float *) red_arr_f32_mem_18750)[sext_i32_i64(local_tid_18744)];\n                        if ((local_tid_18744 - squot32(local_tid_18744, 32) * 32) == 0) {\n                            eta_p_17402 = eta_p_17404;\n                            eta_p_17403 = eta_p_17405;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_18771 = 1;\n                    while (slt",
                                    "32(skip_threads_18771, 32)) {\n                        bool thread_active_18772 = sle32(skip_threads_18771, local_tid_18744 - squot32(local_tid_18744, 32) * 32) && ltid_in_bounds_18770;\n                        \n                        if (thread_active_18772) {\n                            // read operands\n                            {\n                                eta_p_17402 = ((volatile __local int64_t *) red_arr_i64_mem_18748)[sext_i32_i64(local_tid_18744) - sext_i32_i64(skip_threads_18771)];\n                                eta_p_17403 = ((volatile __local float *) red_arr_f32_mem_18750)[sext_i32_i64(local_tid_18744) - sext_i32_i64(skip_threads_18771)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            bool inactive_18773 = slt64(srem64(sext_i32_i64(local_tid_18744), corePts_15993), sext_i32_i64(local_tid_18744) - sext_i32_i64(local_tid_18744 - skip_threads_18771));\n                            \n                            if (thread_active_18772 && inactive_18773) {\n                                eta_p_17402 = eta_p_17404;\n                                eta_p_17403 = eta_p_17405;\n                            }\n                            if (thread_active_18772) {\n                                if (!inactive_18773) {\n                                    bool zg_res_17406 = eps_13122 < eta_p_17403;\n                                    bool zg_res_17407 = eps_13122 < eta_p_17405;\n                                    bool x_17408 = zg_res_17406 && zg_res_17407;\n                                    int64_t lifted_lambda_res_17409;\n                                    float lifted_lambda_res_17410;\n                                    \n                                    if (x_17408) {\n                                        lifted_lambda_res_17409 = (int64_t) -1;\n                                        lifted_lambda_res_17410 = INFINITY;\n                             ", "       } else {\n                                        bool zl_res_17411 = eta_p_17403 < eta_p_17405;\n                                        int64_t lifted_lambda_res_f_res_17412;\n                                        \n                                        if (zl_res_17411) {\n                                            lifted_lambda_res_f_res_17412 = eta_p_17402;\n                                        } else {\n                                            lifted_lambda_res_f_res_17412 = eta_p_17404;\n                                        }\n                                        \n                                        float lifted_lambda_res_f_res_17413;\n                                        \n                                        if (zl_res_17411) {\n                                            lifted_lambda_res_f_res_17413 = eta_p_17403;\n                                        } else {\n                                            lifted_lambda_res_f_res_17413 = eta_p_17405;\n                                        }\n                                        lifted_lambda_res_17409 = lifted_lambda_res_f_res_17412;\n                                        lifted_lambda_res_17410 = lifted_lambda_res_f_res_17413;\n                                    }\n                                    eta_p_17402 = lifted_lambda_res_17409;\n                                    eta_p_17403 = lifted_lambda_res_17410;\n                                }\n                            }\n                        }\n                        if (sle32(wave_sizze_18746, skip_threads_18771)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_18772) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) red_arr_i64_mem_18748)[sext_i32_i64(local_tid_18744)] = eta_p_17402;\n                                eta_p_17404 = eta_p_17402;\n              ", "                  ((volatile __local float *) red_arr_f32_mem_18750)[sext_i32_i64(local_tid_18744)] = eta_p_17403;\n                                eta_p_17405 = eta_p_17403;\n                            }\n                        }\n                        if (sle32(wave_sizze_18746, skip_threads_18771)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_18771 *= 2;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // last thread of block 'i' writes its result to offset 'i'\n                {\n                    if ((local_tid_18744 - squot32(local_tid_18744, 32) * 32) == 31 && ltid_in_bounds_18770) {\n                        ((volatile __local int64_t *) red_arr_i64_mem_18748)[sext_i32_i64(squot32(local_tid_18744, 32))] = eta_p_17402;\n                        ((volatile __local float *) red_arr_f32_mem_18750)[sext_i32_i64(squot32(local_tid_18744, 32))] = eta_p_17403;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n                {\n                    int32_t skip_threads_18774;\n                    \n                    // read input for in-block scan\n                    {\n                        if (squot32(local_tid_18744, 32) == 0 && ltid_in_bounds_18770) {\n                            eta_p_18760 = ((volatile __local int64_t *) red_arr_i64_mem_18748)[sext_i32_i64(local_tid_18744)];\n                            eta_p_18761 = ((volatile __local float *) red_arr_f32_mem_18750)[sext_i32_i64(local_tid_18744)];\n                            if ((local_tid_18744 - squot32(local_tid_18744, 32) * 32) == 0) {\n                                eta_p_18758 = eta_p_18760;\n                                eta_p_18759 = eta_p_18761;\n                            }\n                        }\n                    }\n                    // in",
                                    "-block scan (hopefully no barriers needed)\n                    {\n                        skip_threads_18774 = 1;\n                        while (slt32(skip_threads_18774, 32)) {\n                            bool thread_active_18775 = sle32(skip_threads_18774, local_tid_18744 - squot32(local_tid_18744, 32) * 32) && (squot32(local_tid_18744, 32) == 0 && ltid_in_bounds_18770);\n                            \n                            if (thread_active_18775) {\n                                // read operands\n                                {\n                                    eta_p_18758 = ((volatile __local int64_t *) red_arr_i64_mem_18748)[sext_i32_i64(local_tid_18744) - sext_i32_i64(skip_threads_18774)];\n                                    eta_p_18759 = ((volatile __local float *) red_arr_f32_mem_18750)[sext_i32_i64(local_tid_18744) - sext_i32_i64(skip_threads_18774)];\n                                }\n                            }\n                            // perform operation\n                            {\n                                bool inactive_18776 = slt64(srem64(sext_i32_i64(local_tid_18744 * 32 + 32 - 1), corePts_15993), sext_i32_i64(local_tid_18744 * 32 + 32 - 1) - sext_i32_i64((local_tid_18744 - skip_threads_18774) * 32 + 32 - 1));\n                                \n                                if (thread_active_18775 && inactive_18776) {\n                                    eta_p_18758 = eta_p_18760;\n                                    eta_p_18759 = eta_p_18761;\n                                }\n                                if (thread_active_18775) {\n                                    if (!inactive_18776) {\n                                        bool zg_res_18762 = eps_13122 < eta_p_18759;\n                                        bool zg_res_18763 = eps_13122 < eta_p_18761;\n                                        bool x_18764 = zg_res_18762 && zg_res_18763;\n                                        int64_t lifted_lambda_res_18765;\n                  ", "                      float lifted_lambda_res_18766;\n                                        \n                                        if (x_18764) {\n                                            lifted_lambda_res_18765 = (int64_t) -1;\n                                            lifted_lambda_res_18766 = INFINITY;\n                                        } else {\n                                            bool zl_res_18767 = eta_p_18759 < eta_p_18761;\n                                            int64_t lifted_lambda_res_f_res_18768;\n                                            \n                                            if (zl_res_18767) {\n                                                lifted_lambda_res_f_res_18768 = eta_p_18758;\n                                            } else {\n                                                lifted_lambda_res_f_res_18768 = eta_p_18760;\n                                            }\n                                            \n                                            float lifted_lambda_res_f_res_18769;\n                                            \n                                            if (zl_res_18767) {\n                                                lifted_lambda_res_f_res_18769 = eta_p_18759;\n                                            } else {\n                                                lifted_lambda_res_f_res_18769 = eta_p_18761;\n                                            }\n                                            lifted_lambda_res_18765 = lifted_lambda_res_f_res_18768;\n                                            lifted_lambda_res_18766 = lifted_lambda_res_f_res_18769;\n                                        }\n                                        eta_p_18758 = lifted_lambda_res_18765;\n                                        eta_p_18759 = lifted_lambda_res_18766;\n                                    }\n                                }\n                            }\n                            if (sle32(wave_siz", "ze_18746, skip_threads_18774)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            if (thread_active_18775) {\n                                // write result\n                                {\n                                    ((volatile __local int64_t *) red_arr_i64_mem_18748)[sext_i32_i64(local_tid_18744)] = eta_p_18758;\n                                    eta_p_18760 = eta_p_18758;\n                                    ((volatile __local float *) red_arr_f32_mem_18750)[sext_i32_i64(local_tid_18744)] = eta_p_18759;\n                                    eta_p_18761 = eta_p_18759;\n                                }\n                            }\n                            if (sle32(wave_sizze_18746, skip_threads_18774)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            skip_threads_18774 *= 2;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                \n                bool no_carry_in_18777 = squot32(local_tid_18744, 32) == 0 || !ltid_in_bounds_18770;\n                \n                // carry-in for every block except the first\n                {\n                    // read operands\n                    {\n                        if (!no_carry_in_18777) {\n                            eta_p_17404 = eta_p_17402;\n                            eta_p_17405 = eta_p_17403;\n                            eta_p_17402 = ((__local int64_t *) red_arr_i64_mem_18748)[sext_i32_i64(squot32(local_tid_18744, 32)) - (int64_t) 1];\n                            eta_p_17403 = ((__local float *) red_arr_f32_mem_18750)[sext_i32_i64(squot32(local_tid_18744, 32)) - (int64_t) 1];\n                        }\n                    }\n                    // perform operation\n                    {\n                        bool inactive_18778 = slt64(srem64(sext_i32_i64(local_tid_18744), corePts_15993), sext_i",
                                    "32_i64(local_tid_18744) - sext_i32_i64(squot32(local_tid_18744, 32) * 32 - 1));\n                        \n                        if (!no_carry_in_18777) {\n                            if (inactive_18778) {\n                                eta_p_17402 = eta_p_17404;\n                                eta_p_17403 = eta_p_17405;\n                            }\n                        }\n                        if (!no_carry_in_18777) {\n                            if (!inactive_18778) {\n                                bool zg_res_17406 = eps_13122 < eta_p_17403;\n                                bool zg_res_17407 = eps_13122 < eta_p_17405;\n                                bool x_17408 = zg_res_17406 && zg_res_17407;\n                                int64_t lifted_lambda_res_17409;\n                                float lifted_lambda_res_17410;\n                                \n                                if (x_17408) {\n                                    lifted_lambda_res_17409 = (int64_t) -1;\n                                    lifted_lambda_res_17410 = INFINITY;\n                                } else {\n                                    bool zl_res_17411 = eta_p_17403 < eta_p_17405;\n                                    int64_t lifted_lambda_res_f_res_17412;\n                                    \n                                    if (zl_res_17411) {\n                                        lifted_lambda_res_f_res_17412 = eta_p_17402;\n                                    } else {\n                                        lifted_lambda_res_f_res_17412 = eta_p_17404;\n                                    }\n                                    \n                                    float lifted_lambda_res_f_res_17413;\n                                    \n                                    if (zl_res_17411) {\n                                        lifted_lambda_res_f_res_17413 = eta_p_17403;\n                                    } else {\n                                        lifted_lambda_r", "es_f_res_17413 = eta_p_17405;\n                                    }\n                                    lifted_lambda_res_17409 = lifted_lambda_res_f_res_17412;\n                                    lifted_lambda_res_17410 = lifted_lambda_res_f_res_17413;\n                                }\n                                eta_p_17402 = lifted_lambda_res_17409;\n                                eta_p_17403 = lifted_lambda_res_17410;\n                            }\n                        }\n                    }\n                    // write final result\n                    {\n                        if (!no_carry_in_18777) {\n                            ((__local int64_t *) red_arr_i64_mem_18748)[sext_i32_i64(local_tid_18744)] = eta_p_17402;\n                            ((__local float *) red_arr_f32_mem_18750)[sext_i32_i64(local_tid_18744)] = eta_p_17403;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // restore correct values for first block\n                {\n                    if (squot32(local_tid_18744, 32) == 0 && ltid_in_bounds_18770) {\n                        ((__local int64_t *) red_arr_i64_mem_18748)[sext_i32_i64(local_tid_18744)] = eta_p_17404;\n                        ((__local float *) red_arr_f32_mem_18750)[sext_i32_i64(local_tid_18744)] = eta_p_17405;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // save final values of segments\n        {\n            if (slt64(sext_i32_i64(virt_tblock_id_18755) * squot64(segred_tblock_sizze_17394, segment_sizze_nonzzero_18741) + sext_i32_i64(local_tid_18744), dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019) && slt64(sext_i32_i64(local_tid_18744), squot64(segred_tblock_sizze_17394, segment_sizze_nonzzero_18741))) {\n                int64_t tmp_18779 = ((__local int64_t *) red_arr_i64_mem_18748)[(sext_i32_i64(local_tid_18744) + (int64_t) 1) * segment_siz", "ze_nonzzero_18741 - (int64_t) 1];\n                \n                ((__global int64_t *) mem_18426)[inf_16016 + (sext_i32_i64(virt_tblock_id_18755) * squot64(segred_tblock_sizze_17394, segment_sizze_nonzzero_18741) + sext_i32_i64(local_tid_18744))] = tmp_18779;\n                \n                float tmp_18780 = ((__local float *) red_arr_f32_mem_18750)[(sext_i32_i64(local_tid_18744) + (int64_t) 1) * segment_sizze_nonzzero_18741 - (int64_t) 1];\n                \n                ((__global float *) mem_18460)[sext_i32_i64(virt_tblock_id_18755) * squot64(segred_tblock_sizze_17394, segment_sizze_nonzzero_18741) + sext_i32_i64(local_tid_18744)] = tmp_18780;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_3:\n    return;\n    #undef segred_tblock_sizze_17394\n}\nFUTHARK_KERNEL_SIZED(ftDBSCAN_star_doublezisegmap_16302_dim1, 1, 1)\nvoid ftDBSCAN_star_doublezisegmap_16302(__global int *global_failure, int64_t nz2085U_15337, int64_t minPts_15340, __global unsigned char *ext_mem_18420, __global unsigned char *mem_18422)\n{\n    #define segmap_tblock_sizze_16298 (ftDBSCAN_star_doublezisegmap_16302zisegmap_tblock_sizze_16298)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18656;\n    int32_t tblock_sizze_18659;\n    int32_t wave_sizze_18658;\n    int32_t block_id_18657;\n    int32_t global_tid_18655;\n    int64_t phys_tid_16302;\n    int64_t global_tid_18660;\n    int64_t slice_18661;\n    int64_t gtid_16301;\n    int64_t remnant_18662;\n    \n    local_tid_18656 = get_local_id(0);\n    tblock_sizze_18659 = get_local_size(0);\n    wave_sizze_18658 = LOCKSTEP_WIDTH;\n    block_id_18657 = get_tblock_id(0);\n    global_tid_18655 = block_id_18657 * tblock_sizze_18659 + local_tid_18656;\n    phys_tid_16302 = sext_i32_i64(global_tid_18655);\n    global_tid_18660 = sext_i32_i64(block_id_18657) * segmap_tblock_sizze_16298 + sext_i32_i64(local_tid_18656);\n    slice_18661 = nz2085U_15337;\n    gt",
                                    "id_16301 = global_tid_18660;\n    remnant_18662 = global_tid_18660 - gtid_16301;\n    if (slt64(gtid_16301, nz2085U_15337)) {\n        int64_t eta_p_16303;\n        bool lifted_lambda_res_16304;\n        \n        eta_p_16303 = ((__global int64_t *) ext_mem_18420)[gtid_16301];\n        lifted_lambda_res_16304 = sle64(minPts_15340, eta_p_16303);\n        ((__global bool *) mem_18422)[gtid_16301] = lifted_lambda_res_16304;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_16298\n}\nFUTHARK_KERNEL_SIZED(ftDBSCAN_star_floatzisegmap_16284_dim1, 1, 1)\nvoid ftDBSCAN_star_floatzisegmap_16284(__global int *global_failure, int64_t nz2085U_15256, int64_t minPts_15259, __global unsigned char *ext_mem_18420, __global unsigned char *mem_18422)\n{\n    #define segmap_tblock_sizze_16280 (ftDBSCAN_star_floatzisegmap_16284zisegmap_tblock_sizze_16280)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18656;\n    int32_t tblock_sizze_18659;\n    int32_t wave_sizze_18658;\n    int32_t block_id_18657;\n    int32_t global_tid_18655;\n    int64_t phys_tid_16284;\n    int64_t global_tid_18660;\n    int64_t slice_18661;\n    int64_t gtid_16283;\n    int64_t remnant_18662;\n    \n    local_tid_18656 = get_local_id(0);\n    tblock_sizze_18659 = get_local_size(0);\n    wave_sizze_18658 = LOCKSTEP_WIDTH;\n    block_id_18657 = get_tblock_id(0);\n    global_tid_18655 = block_id_18657 * tblock_sizze_18659 + local_tid_18656;\n    phys_tid_16284 = sext_i32_i64(global_tid_18655);\n    global_tid_18660 = sext_i32_i64(block_id_18657) * segmap_tblock_sizze_16280 + sext_i32_i64(local_tid_18656);\n    slice_18661 = nz2085U_15256;\n    gtid_16283 = global_tid_18660;\n    remnant_18662 = global_tid_18660 - gtid_16283;\n    if (slt64(gtid_16283, nz2085U_15256)) {\n        int64_t eta_p_16285;\n        bool lifted_lambda_res_16286;\n        \n        eta_p_16285 = ((__global int64_t *) ext_mem_18420)[gtid_16283];\n        lifted_lambda_res_16286 = sle64(minPts_15259, eta_p_16285);\n        ((__global bool *) me", "m_18422)[gtid_16283] = lifted_lambda_res_16286;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_16280\n}\nFUTHARK_KERNEL_SIZED(get_num_neighbours_6695zisegmap_17835_dim1, 1, 1)\nvoid get_num_neighbours_6695zisegmap_17835(__global int *global_failure, int64_t n_11127, int64_t dim_11128, float eps_11130, int64_t inf_11148, int64_t dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154, int64_t num_threads_18608, __global unsigned char *dat_mem_18419, __global unsigned char *mem_18421, __global unsigned char *mem_18479, __global unsigned char *color_18526)\n{\n    #define segmap_tblock_sizze_17831 (get_num_neighbours_6695zisegmap_17835zisegmap_tblock_sizze_17831)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18675;\n    int32_t tblock_sizze_18678;\n    int32_t wave_sizze_18677;\n    int32_t block_id_18676;\n    int32_t global_tid_18674;\n    int64_t phys_tid_17835;\n    int64_t global_tid_18679;\n    int64_t slice_18680;\n    int64_t gtid_17834;\n    int64_t remnant_18681;\n    \n    local_tid_18675 = get_local_id(0);\n    tblock_sizze_18678 = get_local_size(0);\n    wave_sizze_18677 = LOCKSTEP_WIDTH;\n    block_id_18676 = get_tblock_id(0);\n    global_tid_18674 = block_id_18676 * tblock_sizze_18678 + local_tid_18675;\n    phys_tid_17835 = sext_i32_i64(global_tid_18674);\n    global_tid_18679 = sext_i32_i64(block_id_18676) * segmap_tblock_sizze_17831 + sext_i32_i64(local_tid_18675);\n    slice_18680 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154;\n    gtid_17834 = global_tid_18679;\n    remnant_18681 = global_tid_18679 - gtid_17834;\n    if (slt64(gtid_17834, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154)) {\n        int64_t slice_18395;\n        int64_t defunc_res_17837;\n        int64_t redout_18406;\n        int64_t lifted_lambda_res_17855;\n        \n        slice_18395 = inf_11148 + gtid_17834;\n        redout_18406 = (int64_t) 0;\n        for (int64_t i_18407 = 0; i_18407 < n_11127; i_18407++) {\n            float defunc_0_f_res_17844;\n            float acc_17846;\n            flo", "at sqrt_res_17849;\n            bool zlze_res_17850;\n            int64_t bool_res_17851;\n            int64_t zp_res_17854;\n            int64_t redout_tmp_18682;\n            \n            for (int64_t i_18410 = 0; i_18410 < dim_11128; i_18410++) {\n                float eta_p_17840;\n                float eta_p_17841;\n                float zm_res_17842;\n                float zt_res_17843;\n                \n                eta_p_17840 = ((__global float *) mem_18479)[slice_18395 + i_18410 * n_11127];\n                eta_p_17841 = ((__global float *) dat_mem_18419)[i_18407 * dim_11128 + i_18410];\n                zm_res_17842 = eta_p_17840 - eta_p_17841;\n                zt_res_17843 = zm_res_17842 * zm_res_17842;\n                ((__global float *) color_18526)[phys_tid_17835 + i_18410 * num_threads_18608] = zt_res_17843;\n            }\n            acc_17846 = 0.0F;\n            for (int64_t i_17845 = 0; i_17845 < dim_11128; i_17845++) {\n                float b_17847;\n                float zp_res_17848;\n                float acc_tmp_18684;\n                \n                b_17847 = ((__global float *) color_18526)[phys_tid_17835 + i_17845 * num_threads_18608];\n                zp_res_17848 = acc_17846 + b_17847;\n                acc_tmp_18684 = zp_res_17848;\n                acc_17846 = acc_tmp_18684;\n            }\n            defunc_0_f_res_17844 = acc_17846;\n            sqrt_res_17849 = futrts_sqrt32(defunc_0_f_res_17844);\n            zlze_res_17850 = sqrt_res_17849 <= eps_11130;\n            bool_res_17851 = btoi_bool_i64(zlze_res_17850);\n            zp_res_17854 = add64(bool_res_17851, redout_18406);\n            redout_tmp_18682 = zp_res_17854;\n            redout_18406 = redout_tmp_18682;\n        }\n        defunc_res_17837 = redout_18406;\n        lifted_lambda_res_17855 = sub64(defunc_res_17837, (int64_t) 1);\n        ((__global int64_t *) mem_18421)[inf_11148 + gtid_17834] = lifted_lambda_res_17855;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_17831\n}\nFUTHA",
                                    "RK_KERNEL_SIZED(get_num_neighbours_6695zisegmap_18046_dim1, 1, 1)\nvoid get_num_neighbours_6695zisegmap_18046(__global int *global_failure, int64_t n_11127, int64_t dim_11128, int64_t inf_11148, int64_t dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154, __global unsigned char *dat_mem_18419, __global unsigned char *mem_18429)\n{\n    #define segmap_tblock_sizze_18040 (get_num_neighbours_6695zisegmap_18046zisegmap_tblock_sizze_18040)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18705;\n    int32_t tblock_sizze_18708;\n    int32_t wave_sizze_18707;\n    int32_t block_id_18706;\n    int32_t global_tid_18704;\n    int64_t phys_tid_18046;\n    int64_t global_tid_18709;\n    int64_t slice_18710;\n    int64_t slice_18711;\n    int64_t slice_18712;\n    int64_t gtid_18043;\n    int64_t remnant_18713;\n    int64_t gtid_18044;\n    int64_t remnant_18714;\n    int64_t gtid_18045;\n    int64_t remnant_18715;\n    \n    local_tid_18705 = get_local_id(0);\n    tblock_sizze_18708 = get_local_size(0);\n    wave_sizze_18707 = LOCKSTEP_WIDTH;\n    block_id_18706 = get_tblock_id(0);\n    global_tid_18704 = block_id_18706 * tblock_sizze_18708 + local_tid_18705;\n    phys_tid_18046 = sext_i32_i64(global_tid_18704);\n    global_tid_18709 = sext_i32_i64(block_id_18706) * segmap_tblock_sizze_18040 + sext_i32_i64(local_tid_18705);\n    slice_18710 = dim_11128;\n    slice_18711 = n_11127 * slice_18710;\n    slice_18712 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154 * slice_18711;\n    gtid_18043 = squot64(global_tid_18709, slice_18711);\n    remnant_18713 = global_tid_18709 - gtid_18043 * slice_18711;\n    gtid_18044 = squot64(remnant_18713, slice_18710);\n    remnant_18714 = remnant_18713 - gtid_18044 * slice_18710;\n    gtid_18045 = remnant_18714;\n    remnant_18715 = remnant_18714 - gtid_18045;\n    if ((slt64(gtid_18043, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154) && slt64(gtid_18044, n_11127)) && slt64(gtid_18045, dim_11128)) {\n        int64_t slice_18397;\n        float eta_p_18047;\n        float eta_p_18048;\n  ", "      float zm_res_18049;\n        float zt_res_18050;\n        \n        slice_18397 = inf_11148 + gtid_18043;\n        eta_p_18047 = ((__global float *) dat_mem_18419)[slice_18397 * dim_11128 + gtid_18045];\n        eta_p_18048 = ((__global float *) dat_mem_18419)[gtid_18044 * dim_11128 + gtid_18045];\n        zm_res_18049 = eta_p_18047 - eta_p_18048;\n        zt_res_18050 = zm_res_18049 * zm_res_18049;\n        ((__global float *) mem_18429)[gtid_18043 * (dim_11128 * n_11127) + gtid_18044 * dim_11128 + gtid_18045] = zt_res_18050;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_18040\n}\nFUTHARK_KERNEL_SIZED(get_num_neighbours_6695zisegmap_18059_dim1, 1, 1)\nvoid get_num_neighbours_6695zisegmap_18059(__global int *global_failure, int64_t n_11127, int64_t dim_11128, float eps_11130, int64_t dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154, __global unsigned char *mem_18446, __global unsigned char *mem_18450)\n{\n    #define segmap_tblock_sizze_18054 (get_num_neighbours_6695zisegmap_18059zisegmap_tblock_sizze_18054)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18718;\n    int32_t tblock_sizze_18721;\n    int32_t wave_sizze_18720;\n    int32_t block_id_18719;\n    int32_t global_tid_18717;\n    int64_t phys_tid_18059;\n    int64_t global_tid_18722;\n    int64_t slice_18723;\n    int64_t slice_18724;\n    int64_t gtid_18057;\n    int64_t remnant_18725;\n    int64_t gtid_18058;\n    int64_t remnant_18726;\n    \n    local_tid_18718 = get_local_id(0);\n    tblock_sizze_18721 = get_local_size(0);\n    wave_sizze_18720 = LOCKSTEP_WIDTH;\n    block_id_18719 = get_tblock_id(0);\n    global_tid_18717 = block_id_18719 * tblock_sizze_18721 + local_tid_18718;\n    phys_tid_18059 = sext_i32_i64(global_tid_18717);\n    global_tid_18722 = sext_i32_i64(block_id_18719) * segmap_tblock_sizze_18054 + sext_i32_i64(local_tid_18718);\n    slice_18723 = n_11127;\n    slice_18724 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154 * slice_18723;\n    gtid_18057 = squot64(global_tid_18722, slice_1872", "3);\n    remnant_18725 = global_tid_18722 - gtid_18057 * slice_18723;\n    gtid_18058 = remnant_18725;\n    remnant_18726 = remnant_18725 - gtid_18058;\n    if (slt64(gtid_18057, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154) && slt64(gtid_18058, n_11127)) {\n        float defunc_0_f_res_18061;\n        float acc_18063;\n        float sqrt_res_18066;\n        bool zlze_res_18067;\n        int64_t bool_res_18068;\n        \n        acc_18063 = 0.0F;\n        for (int64_t i_18062 = 0; i_18062 < dim_11128; i_18062++) {\n            float b_18064;\n            float zp_res_18065;\n            float acc_tmp_18727;\n            \n            b_18064 = ((__global float *) mem_18446)[gtid_18057 * n_11127 + gtid_18058 + i_18062 * (n_11127 * dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154)];\n            zp_res_18065 = acc_18063 + b_18064;\n            acc_tmp_18727 = zp_res_18065;\n            acc_18063 = acc_tmp_18727;\n        }\n        defunc_0_f_res_18061 = acc_18063;\n        sqrt_res_18066 = futrts_sqrt32(defunc_0_f_res_18061);\n        zlze_res_18067 = sqrt_res_18066 <= eps_11130;\n        bool_res_18068 = btoi_bool_i64(zlze_res_18067);\n        ((__global int64_t *) mem_18450)[gtid_18057 * n_11127 + gtid_18058] = bool_res_18068;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_18054\n}\nFUTHARK_KERNEL_SIZED(get_num_neighbours_6695zisegmap_18089_dim1, 1, 1)\nvoid get_num_neighbours_6695zisegmap_18089(__global int *global_failure, int64_t inf_11148, int64_t dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154, __global unsigned char *mem_18421)\n{\n    #define segmap_tblock_sizze_18085 (get_num_neighbours_6695zisegmap_18089zisegmap_tblock_sizze_18085)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18822;\n    int32_t tblock_sizze_18825;\n    int32_t wave_sizze_18824;\n    int32_t block_id_18823;\n    int32_t global_tid_18821;\n    int64_t phys_tid_18089;\n    int64_t global_tid_18826;\n    int64_t slice_18827;\n    int64_t gtid_18088;\n    int64_t remnant_18828;\n    \n    local_tid_18822 = get",
                                    "_local_id(0);\n    tblock_sizze_18825 = get_local_size(0);\n    wave_sizze_18824 = LOCKSTEP_WIDTH;\n    block_id_18823 = get_tblock_id(0);\n    global_tid_18821 = block_id_18823 * tblock_sizze_18825 + local_tid_18822;\n    phys_tid_18089 = sext_i32_i64(global_tid_18821);\n    global_tid_18826 = sext_i32_i64(block_id_18823) * segmap_tblock_sizze_18085 + sext_i32_i64(local_tid_18822);\n    slice_18827 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154;\n    gtid_18088 = global_tid_18826;\n    remnant_18828 = global_tid_18826 - gtid_18088;\n    if (slt64(gtid_18088, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154)) {\n        int64_t defunc_res_18090;\n        int64_t lifted_lambda_res_18091;\n        \n        defunc_res_18090 = ((__global int64_t *) mem_18421)[inf_11148 + gtid_18088];\n        lifted_lambda_res_18091 = sub64(defunc_res_18090, (int64_t) 1);\n        ((__global int64_t *) mem_18421)[inf_11148 + gtid_18088] = lifted_lambda_res_18091;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_18085\n}\nFUTHARK_KERNEL\nvoid get_num_neighbours_6695zisegmap_intrablock_17863(__global int *global_failure, int64_t n_11127, int64_t dim_11128, float eps_11130, int64_t inf_11148, int64_t dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154, int64_t ctx_18624, __global unsigned char *dat_mem_18419, __global unsigned char *mem_18421, __global unsigned char *color_18527)\n{\n    volatile __local unsigned char *red_arr_mem_18697_backing_0 = &shared_mem[0];\n    const int64_t red_arr_mem_18697_backing_0_offset = 0 + ((int64_t) 8 * n_11127 + srem64((int64_t) 8 - srem64((int64_t) 8 * n_11127, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18688;\n    int32_t tblock_sizze_18691;\n    int32_t wave_sizze_18690;\n    int32_t block_id_18689;\n    int32_t global_tid_18687;\n    int64_t phys_tblock_id_17863;\n    int64_t slice_18693;\n    int64_t ltid_pre_18692;\n    int64_t remnant_18694;\n    int64_t slice_18695;\n    int64_t gtid_17862;\n    int64_t remnant_18696;\n    in", "t64_t slice_18396;\n    int64_t binop_x_18622;\n    int64_t defunc_res_17866;\n    int64_t phys_tid_17868;\n    __local unsigned char *red_arr_mem_18697;\n    int64_t gtid_17867;\n    int64_t ctx_18623;\n    float defunc_0_f_res_17878;\n    float acc_17880;\n    float sqrt_res_17883;\n    bool zlze_res_17884;\n    int64_t bool_res_17885;\n    int32_t offset_18701;\n    int32_t skip_waves_18702;\n    int64_t eta_p_17869;\n    int64_t eta_p_17870;\n    int64_t lifted_lambda_res_17886;\n    \n    local_tid_18688 = get_local_id(0);\n    tblock_sizze_18691 = get_local_size(0);\n    wave_sizze_18690 = LOCKSTEP_WIDTH;\n    block_id_18689 = get_tblock_id(0);\n    global_tid_18687 = block_id_18689 * tblock_sizze_18691 + local_tid_18688;\n    phys_tblock_id_17863 = sext_i32_i64(block_id_18689);\n    slice_18693 = n_11127;\n    ltid_pre_18692 = sext_i32_i64(local_tid_18688);\n    remnant_18694 = sext_i32_i64(local_tid_18688) - ltid_pre_18692;\n    slice_18695 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154;\n    gtid_17862 = sext_i32_i64(block_id_18689);\n    remnant_18696 = sext_i32_i64(block_id_18689) - gtid_17862;\n    slice_18396 = inf_11148 + gtid_17862;\n    binop_x_18622 = n_11127 * phys_tblock_id_17863;\n    phys_tid_17868 = sext_i32_i64(local_tid_18688);\n    red_arr_mem_18697 = (__local unsigned char *) red_arr_mem_18697_backing_0;\n    gtid_17867 = sext_i32_i64(sext_i64_i32(ltid_pre_18692));\n    ctx_18623 = phys_tid_17868 + binop_x_18622;\n    for (int64_t i_18414 = 0; i_18414 < dim_11128; i_18414++) {\n        float eta_p_17874;\n        float eta_p_17875;\n        float zm_res_17876;\n        float zt_res_17877;\n        \n        eta_p_17874 = ((__global float *) dat_mem_18419)[slice_18396 * dim_11128 + i_18414];\n        eta_p_17875 = ((__global float *) dat_mem_18419)[gtid_17867 * dim_11128 + i_18414];\n        zm_res_17876 = eta_p_17874 - eta_p_17875;\n        zt_res_17877 = zm_res_17876 * zm_res_17876;\n        ((__global float *) color_18527)[ctx_18623 + i_18414 * ctx_18624] = zt_res_17877;\n    }\n    acc_178", "80 = 0.0F;\n    for (int64_t i_17879 = 0; i_17879 < dim_11128; i_17879++) {\n        float b_17881;\n        float zp_res_17882;\n        float acc_tmp_18700;\n        \n        b_17881 = ((__global float *) color_18527)[ctx_18623 + i_17879 * ctx_18624];\n        zp_res_17882 = acc_17880 + b_17881;\n        acc_tmp_18700 = zp_res_17882;\n        acc_17880 = acc_tmp_18700;\n    }\n    defunc_0_f_res_17878 = acc_17880;\n    sqrt_res_17883 = futrts_sqrt32(defunc_0_f_res_17878);\n    zlze_res_17884 = sqrt_res_17883 <= eps_11130;\n    bool_res_17885 = btoi_bool_i64(zlze_res_17884);\n    ((__local int64_t *) red_arr_mem_18697)[gtid_17867] = bool_res_17885;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    skip_waves_18702 = 1;\n    offset_18701 = 0;\n    // participating threads read initial accumulator\n    {\n        if (slt32(local_tid_18688, sext_i64_i32(n_11127))) {\n            eta_p_17869 = ((__local int64_t *) red_arr_mem_18697)[sext_i32_i64(local_tid_18688 + offset_18701)];\n        }\n    }\n    offset_18701 = 1;\n    while (slt32(offset_18701, wave_sizze_18690)) {\n        if (slt32(local_tid_18688 + offset_18701, sext_i64_i32(n_11127)) && ((local_tid_18688 - squot32(local_tid_18688, wave_sizze_18690) * wave_sizze_18690) & (2 * offset_18701 - 1)) == 0) {\n            // read array element\n            {\n                eta_p_17870 = ((volatile __local int64_t *) red_arr_mem_18697)[sext_i32_i64(local_tid_18688 + offset_18701)];\n            }\n            // apply reduction operation\n            {\n                int64_t zp_res_17871 = add64(eta_p_17869, eta_p_17870);\n                \n                eta_p_17869 = zp_res_17871;\n            }\n            // write result of operation\n            {\n                ((volatile __local int64_t *) red_arr_mem_18697)[sext_i32_i64(local_tid_18688)] = eta_p_17869;\n            }\n        }\n        offset_18701 *= 2;\n    }\n    while (slt32(skip_waves_18702, squot32(sext_i64_i32(n_11127) + wave_sizze_18690 - 1, wave_sizze_18690))) {\n        barrier(CLK_LOCAL_MEM_FEN",
                                    "CE);\n        offset_18701 = skip_waves_18702 * wave_sizze_18690;\n        if (slt32(local_tid_18688 + offset_18701, sext_i64_i32(n_11127)) && ((local_tid_18688 - squot32(local_tid_18688, wave_sizze_18690) * wave_sizze_18690) == 0 && (squot32(local_tid_18688, wave_sizze_18690) & (2 * skip_waves_18702 - 1)) == 0)) {\n            // read array element\n            {\n                eta_p_17870 = ((__local int64_t *) red_arr_mem_18697)[sext_i32_i64(local_tid_18688 + offset_18701)];\n            }\n            // apply reduction operation\n            {\n                int64_t zp_res_17871 = add64(eta_p_17869, eta_p_17870);\n                \n                eta_p_17869 = zp_res_17871;\n            }\n            // write result of operation\n            {\n                ((__local int64_t *) red_arr_mem_18697)[sext_i32_i64(local_tid_18688)] = eta_p_17869;\n            }\n        }\n        skip_waves_18702 *= 2;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // Save result of reduction.\n    {\n        defunc_res_17866 = ((__local int64_t *) red_arr_mem_18697)[(int64_t) 0];\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    lifted_lambda_res_17886 = sub64(defunc_res_17866, (int64_t) 1);\n    if (local_tid_18688 == 0) {\n        ((__global int64_t *) mem_18421)[inf_11148 + gtid_17862] = lifted_lambda_res_17886;\n    }\n    \n  error_4:\n    return;\n}\nFUTHARK_KERNEL_SIZED(get_num_neighbours_6695zisegred_large_18078_dim1, 1, 1)\nvoid get_num_neighbours_6695zisegred_large_18078(__global int *global_failure, int64_t n_11127, int64_t inf_11148, int64_t dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154, int64_t num_tblocks_18073, int64_t blocks_per_segment_18757, int64_t q_18758, int64_t num_virtblocks_18759, int64_t threads_per_segment_18760, __global unsigned char *mem_18421, __global unsigned char *mem_18450, __global unsigned char *segred_tmp_mem_18761, __global unsigned char *counters_mem_18763)\n{\n    #define segred_tblock_sizze_18072 (get_num_neighbours_6695zisegred_large_18078zi", "segred_tblock_sizze_18072)\n    #define chunk_sizze_18728 (get_num_neighbours_6695zisegred_large_18078zichunk_sizze_18728)\n    \n    volatile __local unsigned char *sync_arr_mem_18792_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_18792_backing_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i64_mem_18790_backing_0 = &shared_mem[sync_arr_mem_18792_backing_1_offset];\n    const int64_t red_arr_i64_mem_18790_backing_0_offset = sync_arr_mem_18792_backing_1_offset + ((int64_t) 8 * segred_tblock_sizze_18072 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_18072, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18786;\n    int32_t tblock_sizze_18789;\n    int32_t wave_sizze_18788;\n    int32_t block_id_18787;\n    int32_t global_tid_18785;\n    int64_t phys_tid_18078;\n    __local unsigned char *red_arr_i64_mem_18790;\n    __local unsigned char *sync_arr_mem_18792;\n    int32_t phys_tblock_id_18794;\n    int32_t iterations_18795;\n    \n    local_tid_18786 = get_local_id(0);\n    tblock_sizze_18789 = get_local_size(0);\n    wave_sizze_18788 = LOCKSTEP_WIDTH;\n    block_id_18787 = get_tblock_id(0);\n    global_tid_18785 = block_id_18787 * tblock_sizze_18789 + local_tid_18786;\n    phys_tid_18078 = sext_i32_i64(global_tid_18785);\n    red_arr_i64_mem_18790 = (__local unsigned char *) red_arr_i64_mem_18790_backing_0;\n    sync_arr_mem_18792 = (__local unsigned char *) sync_arr_mem_18792_backing_1;\n    phys_tblock_id_18794 = get_tblock_id(0);\n    iterations_18795 = sdiv_up32(sext_i64_i32(num_virtblocks_18759) - phys_tblock_id_18794, sext_i64_i32(num_tblocks_18073));\n    for (int32_t i_18796 = 0; i_18796 < iterations_18795; i_18796++) {\n        int32_t virt_tblock_id_18797;\n        int64_t flat_segment_id_18798;\n        int64_t global_tid_18799;\n        int64_t slice_18800;\n        int64_t gtid_18076;\n        int64_t remnant_18801;\n        int64_t gtid_18077;\n        int64_t eta_p_block_res_acc_18802", ";\n        int64_t eta_p_18079;\n        int64_t eta_p_18080;\n        int64_t tblock_id_in_segment_18806;\n        int64_t block_base_offset_18807;\n        int32_t offset_18810;\n        int32_t skip_waves_18811;\n        int64_t eta_p_18803;\n        int64_t eta_p_18804;\n        \n        virt_tblock_id_18797 = phys_tblock_id_18794 + i_18796 * sext_i64_i32(num_tblocks_18073);\n        flat_segment_id_18798 = squot64(sext_i32_i64(virt_tblock_id_18797), blocks_per_segment_18757);\n        global_tid_18799 = srem64(sext_i32_i64(virt_tblock_id_18797) * segred_tblock_sizze_18072 + sext_i32_i64(local_tid_18786), threads_per_segment_18760);\n        slice_18800 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154;\n        gtid_18076 = flat_segment_id_18798;\n        remnant_18801 = flat_segment_id_18798 - gtid_18076;\n        // ne-initialise the outer (per-block) accumulator(s)\n        {\n            eta_p_block_res_acc_18802 = (int64_t) 0;\n        }\n        tblock_id_in_segment_18806 = squot64(global_tid_18799, segred_tblock_sizze_18072);\n        block_base_offset_18807 = tblock_id_in_segment_18806 * q_18758 * segred_tblock_sizze_18072;\n        for (int64_t i_18808 = 0; i_18808 < q_18758; i_18808++) {\n            int64_t block_offset_18809 = block_base_offset_18807 + i_18808 * segred_tblock_sizze_18072;\n            \n            gtid_18077 = global_tid_18799 + threads_per_segment_18760 * i_18808;\n            if (slt64(gtid_18077, n_11127)) {\n                // apply map function(s)\n                {\n                    // apply map function\n                    {\n                        int64_t x_18083 = ((__global int64_t *) mem_18450)[gtid_18076 * n_11127 + gtid_18077];\n                        \n                        // load accumulator(s)\n                        {\n                            eta_p_18079 = eta_p_block_res_acc_18802;\n                        }\n                        // load next value(s)\n                        {\n                            eta_p_18080 = x_18083;\n             ",
                                    "           }\n                        // apply reduction operator(s)\n                        {\n                            int64_t zp_res_18081 = add64(eta_p_18079, eta_p_18080);\n                            \n                            // store in accumulator(s)\n                            {\n                                eta_p_block_res_acc_18802 = zp_res_18081;\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // store accs. prims go in lmem; non-prims in params (in global mem)\n        {\n            ((__local int64_t *) red_arr_i64_mem_18790)[sext_i32_i64(local_tid_18786)] = eta_p_block_res_acc_18802;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        skip_waves_18811 = 1;\n        offset_18810 = 0;\n        // participating threads read initial accumulator\n        {\n            if (slt32(local_tid_18786, sext_i64_i32(segred_tblock_sizze_18072))) {\n                eta_p_18803 = ((__local int64_t *) red_arr_i64_mem_18790)[sext_i32_i64(local_tid_18786 + offset_18810)];\n            }\n        }\n        offset_18810 = 1;\n        while (slt32(offset_18810, wave_sizze_18788)) {\n            if (slt32(local_tid_18786 + offset_18810, sext_i64_i32(segred_tblock_sizze_18072)) && ((local_tid_18786 - squot32(local_tid_18786, wave_sizze_18788) * wave_sizze_18788) & (2 * offset_18810 - 1)) == 0) {\n                // read array element\n                {\n                    eta_p_18804 = ((volatile __local int64_t *) red_arr_i64_mem_18790)[sext_i32_i64(local_tid_18786 + offset_18810)];\n                }\n                // apply reduction operation\n                {\n                    int64_t zp_res_18805 = add64(eta_p_18803, eta_p_18804);\n                    \n                    eta_p_18803 = zp_res_18805;\n                }\n                // write result of operation\n                {\n                    ((volatile __local int64_t *) red_arr_i64_mem_18790)[sext_i", "32_i64(local_tid_18786)] = eta_p_18803;\n                }\n            }\n            offset_18810 *= 2;\n        }\n        while (slt32(skip_waves_18811, squot32(sext_i64_i32(segred_tblock_sizze_18072) + wave_sizze_18788 - 1, wave_sizze_18788))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_18810 = skip_waves_18811 * wave_sizze_18788;\n            if (slt32(local_tid_18786 + offset_18810, sext_i64_i32(segred_tblock_sizze_18072)) && ((local_tid_18786 - squot32(local_tid_18786, wave_sizze_18788) * wave_sizze_18788) == 0 && (squot32(local_tid_18786, wave_sizze_18788) & (2 * skip_waves_18811 - 1)) == 0)) {\n                // read array element\n                {\n                    eta_p_18804 = ((__local int64_t *) red_arr_i64_mem_18790)[sext_i32_i64(local_tid_18786 + offset_18810)];\n                }\n                // apply reduction operation\n                {\n                    int64_t zp_res_18805 = add64(eta_p_18803, eta_p_18804);\n                    \n                    eta_p_18803 = zp_res_18805;\n                }\n                // write result of operation\n                {\n                    ((__local int64_t *) red_arr_i64_mem_18790)[sext_i32_i64(local_tid_18786)] = eta_p_18803;\n                }\n            }\n            skip_waves_18811 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // thread 0 updates per-block acc(s); rest reset to ne\n        {\n            if (sext_i32_i64(local_tid_18786) == (int64_t) 0) {\n                eta_p_block_res_acc_18802 = eta_p_18803;\n            } else {\n                eta_p_block_res_acc_18802 = (int64_t) 0;\n            }\n        }\n        if (blocks_per_segment_18757 == (int64_t) 1) {\n            // first thread in block saves final result to memory\n            {\n                if (local_tid_18786 == 0) {\n                    ((__global int64_t *) mem_18421)[inf_11148 + gtid_18076] = eta_p_block_res_acc_18802;\n                }\n            }\n        } el", "se {\n            int32_t old_counter_18812;\n            bool is_last_block_18813;\n            \n            // first thread in block saves block result to global memory\n            {\n                if (local_tid_18786 == 0) {\n                    ((__global int64_t *) segred_tmp_mem_18761)[sext_i32_i64(virt_tblock_id_18797)] = eta_p_block_res_acc_18802;\n                    mem_fence_global();\n                    old_counter_18812 = atomic_add_i32_global(&((volatile __global int *) counters_mem_18763)[srem64(flat_segment_id_18798, (int64_t) 20480)], (int) 1);\n                    ((__local bool *) sync_arr_mem_18792)[(int64_t) 0] = old_counter_18812 == sext_i64_i32(blocks_per_segment_18757 - (int64_t) 1);\n                }\n            }\n            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n            is_last_block_18813 = ((__local bool *) sync_arr_mem_18792)[(int64_t) 0];\n            if (is_last_block_18813) {\n                if (local_tid_18786 == 0) {\n                    old_counter_18812 = atomic_add_i32_global(&((volatile __global int *) counters_mem_18763)[srem64(flat_segment_id_18798, (int64_t) 20480)], (int) sext_i64_i32((int64_t) 0 - blocks_per_segment_18757));\n                }\n                // read in the per-block-results\n                {\n                    int64_t read_per_thread_18814 = sdiv_up64(blocks_per_segment_18757, segred_tblock_sizze_18072);\n                    \n                    eta_p_18079 = (int64_t) 0;\n                    for (int64_t i_18815 = 0; i_18815 < read_per_thread_18814; i_18815++) {\n                        int64_t block_res_id_18816 = sext_i32_i64(local_tid_18786) * read_per_thread_18814 + i_18815;\n                        int64_t index_of_block_res_18817 = flat_segment_id_18798 * blocks_per_segment_18757 + block_res_id_18816;\n                        \n                        if (slt64(block_res_id_18816, blocks_per_segment_18757)) {\n                            eta_p_18080 = ((__global int64_t *) segred_tmp_mem_18761)",
                                    "[index_of_block_res_18817];\n                            \n                            int64_t zp_res_18081 = add64(eta_p_18079, eta_p_18080);\n                            \n                            eta_p_18079 = zp_res_18081;\n                        }\n                    }\n                }\n                ((__local int64_t *) red_arr_i64_mem_18790)[sext_i32_i64(local_tid_18786)] = eta_p_18079;\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // reduce the per-block results\n                {\n                    int32_t offset_18818;\n                    int32_t skip_waves_18819 = 1;\n                    int64_t eta_p_18803;\n                    int64_t eta_p_18804;\n                    \n                    offset_18818 = 0;\n                    // participating threads read initial accumulator\n                    {\n                        if (slt32(local_tid_18786, sext_i64_i32(segred_tblock_sizze_18072))) {\n                            eta_p_18803 = ((__local int64_t *) red_arr_i64_mem_18790)[sext_i32_i64(local_tid_18786 + offset_18818)];\n                        }\n                    }\n                    offset_18818 = 1;\n                    while (slt32(offset_18818, wave_sizze_18788)) {\n                        if (slt32(local_tid_18786 + offset_18818, sext_i64_i32(segred_tblock_sizze_18072)) && ((local_tid_18786 - squot32(local_tid_18786, wave_sizze_18788) * wave_sizze_18788) & (2 * offset_18818 - 1)) == 0) {\n                            // read array element\n                            {\n                                eta_p_18804 = ((volatile __local int64_t *) red_arr_i64_mem_18790)[sext_i32_i64(local_tid_18786 + offset_18818)];\n                            }\n                            // apply reduction operation\n                            {\n                                int64_t zp_res_18805 = add64(eta_p_18803, eta_p_18804);\n                                \n                                eta_p_18803 = zp_res_18805;\n                            }\n  ", "                          // write result of operation\n                            {\n                                ((volatile __local int64_t *) red_arr_i64_mem_18790)[sext_i32_i64(local_tid_18786)] = eta_p_18803;\n                            }\n                        }\n                        offset_18818 *= 2;\n                    }\n                    while (slt32(skip_waves_18819, squot32(sext_i64_i32(segred_tblock_sizze_18072) + wave_sizze_18788 - 1, wave_sizze_18788))) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                        offset_18818 = skip_waves_18819 * wave_sizze_18788;\n                        if (slt32(local_tid_18786 + offset_18818, sext_i64_i32(segred_tblock_sizze_18072)) && ((local_tid_18786 - squot32(local_tid_18786, wave_sizze_18788) * wave_sizze_18788) == 0 && (squot32(local_tid_18786, wave_sizze_18788) & (2 * skip_waves_18819 - 1)) == 0)) {\n                            // read array element\n                            {\n                                eta_p_18804 = ((__local int64_t *) red_arr_i64_mem_18790)[sext_i32_i64(local_tid_18786 + offset_18818)];\n                            }\n                            // apply reduction operation\n                            {\n                                int64_t zp_res_18805 = add64(eta_p_18803, eta_p_18804);\n                                \n                                eta_p_18803 = zp_res_18805;\n                            }\n                            // write result of operation\n                            {\n                                ((__local int64_t *) red_arr_i64_mem_18790)[sext_i32_i64(local_tid_18786)] = eta_p_18803;\n                            }\n                        }\n                        skip_waves_18819 *= 2;\n                    }\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                    // and back to memory with the final result\n                    {\n                        if (local_tid_18786 == 0) {\n                            ((__globa", "l int64_t *) mem_18421)[inf_11148 + gtid_18076] = eta_p_18803;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_6:\n    return;\n    #undef segred_tblock_sizze_18072\n    #undef chunk_sizze_18728\n}\nFUTHARK_KERNEL_SIZED(get_num_neighbours_6695zisegred_small_18078_dim1, 1, 1)\nvoid get_num_neighbours_6695zisegred_small_18078(__global int *global_failure, int64_t n_11127, int64_t inf_11148, int64_t dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154, int64_t num_tblocks_18073, int64_t segment_sizze_nonzzero_18729, __global unsigned char *mem_18421, __global unsigned char *mem_18450)\n{\n    #define segred_tblock_sizze_18072 (get_num_neighbours_6695zisegred_small_18078zisegred_tblock_sizze_18072)\n    \n    volatile __local unsigned char *red_arr_i64_mem_18736_backing_0 = &shared_mem[0];\n    const int64_t red_arr_i64_mem_18736_backing_0_offset = 0 + ((int64_t) 8 * segred_tblock_sizze_18072 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_18072, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18732;\n    int32_t tblock_sizze_18735;\n    int32_t wave_sizze_18734;\n    int32_t block_id_18733;\n    int32_t global_tid_18731;\n    int64_t phys_tid_18078;\n    __local unsigned char *red_arr_i64_mem_18736;\n    int32_t phys_tblock_id_18738;\n    int32_t iterations_18739;\n    \n    local_tid_18732 = get_local_id(0);\n    tblock_sizze_18735 = get_local_size(0);\n    wave_sizze_18734 = LOCKSTEP_WIDTH;\n    block_id_18733 = get_tblock_id(0);\n    global_tid_18731 = block_id_18733 * tblock_sizze_18735 + local_tid_18732;\n    phys_tid_18078 = sext_i32_i64(global_tid_18731);\n    red_arr_i64_mem_18736 = (__local unsigned char *) red_arr_i64_mem_18736_backing_0;\n    phys_tblock_id_18738 = get_tblock_id(0);\n    iterations_18739 = sdiv_up32(sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154, squot64(segred_tblock_sizze",
                                    "_18072, segment_sizze_nonzzero_18729))) - phys_tblock_id_18738, sext_i64_i32(num_tblocks_18073));\n    for (int32_t i_18740 = 0; i_18740 < iterations_18739; i_18740++) {\n        int32_t virt_tblock_id_18741;\n        int64_t slice_18742;\n        int64_t gtid_18076;\n        int64_t remnant_18743;\n        int64_t gtid_18077;\n        \n        virt_tblock_id_18741 = phys_tblock_id_18738 + i_18740 * sext_i64_i32(num_tblocks_18073);\n        slice_18742 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154;\n        gtid_18076 = squot64(sext_i32_i64(local_tid_18732), segment_sizze_nonzzero_18729) + sext_i32_i64(virt_tblock_id_18741) * squot64(segred_tblock_sizze_18072, segment_sizze_nonzzero_18729);\n        remnant_18743 = squot64(sext_i32_i64(local_tid_18732), segment_sizze_nonzzero_18729) + sext_i32_i64(virt_tblock_id_18741) * squot64(segred_tblock_sizze_18072, segment_sizze_nonzzero_18729) - gtid_18076;\n        gtid_18077 = srem64(sext_i32_i64(local_tid_18732), n_11127);\n        // apply map function if in bounds\n        {\n            if (slt64((int64_t) 0, n_11127) && (slt64(gtid_18076, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154) && slt64(sext_i32_i64(local_tid_18732), n_11127 * squot64(segred_tblock_sizze_18072, segment_sizze_nonzzero_18729)))) {\n                // apply map function\n                {\n                    int64_t x_18083 = ((__global int64_t *) mem_18450)[gtid_18076 * n_11127 + gtid_18077];\n                    \n                    // save results to be reduced\n                    {\n                        ((__local int64_t *) red_arr_i64_mem_18736)[sext_i32_i64(local_tid_18732)] = x_18083;\n                    }\n                }\n            } else {\n                ((__local int64_t *) red_arr_i64_mem_18736)[sext_i32_i64(local_tid_18732)] = (int64_t) 0;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (slt64((int64_t) 0, n_11127)) {\n            // perform segmented scan to imitate reduction\n            {\n                int64_t eta_p_18079;\n     ", "           int64_t eta_p_18080;\n                int64_t eta_p_18744;\n                int64_t eta_p_18745;\n                bool ltid_in_bounds_18747 = slt64(sext_i32_i64(local_tid_18732), n_11127 * squot64(segred_tblock_sizze_18072, segment_sizze_nonzzero_18729));\n                int32_t skip_threads_18748;\n                \n                // read input for in-block scan\n                {\n                    if (ltid_in_bounds_18747) {\n                        eta_p_18080 = ((volatile __local int64_t *) red_arr_i64_mem_18736)[sext_i32_i64(local_tid_18732)];\n                        if ((local_tid_18732 - squot32(local_tid_18732, 32) * 32) == 0) {\n                            eta_p_18079 = eta_p_18080;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_18748 = 1;\n                    while (slt32(skip_threads_18748, 32)) {\n                        bool thread_active_18749 = sle32(skip_threads_18748, local_tid_18732 - squot32(local_tid_18732, 32) * 32) && ltid_in_bounds_18747;\n                        \n                        if (thread_active_18749) {\n                            // read operands\n                            {\n                                eta_p_18079 = ((volatile __local int64_t *) red_arr_i64_mem_18736)[sext_i32_i64(local_tid_18732) - sext_i32_i64(skip_threads_18748)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            bool inactive_18750 = slt64(srem64(sext_i32_i64(local_tid_18732), n_11127), sext_i32_i64(local_tid_18732) - sext_i32_i64(local_tid_18732 - skip_threads_18748));\n                            \n                            if (thread_active_18749 && inactive_18750) {\n                                eta_p_18079 = eta_p_18080;\n                            }\n                            if (thread_active_18749) {\n       ", "                         if (!inactive_18750) {\n                                    int64_t zp_res_18081 = add64(eta_p_18079, eta_p_18080);\n                                    \n                                    eta_p_18079 = zp_res_18081;\n                                }\n                            }\n                        }\n                        if (sle32(wave_sizze_18734, skip_threads_18748)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_18749) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) red_arr_i64_mem_18736)[sext_i32_i64(local_tid_18732)] = eta_p_18079;\n                                eta_p_18080 = eta_p_18079;\n                            }\n                        }\n                        if (sle32(wave_sizze_18734, skip_threads_18748)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_18748 *= 2;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // last thread of block 'i' writes its result to offset 'i'\n                {\n                    if ((local_tid_18732 - squot32(local_tid_18732, 32) * 32) == 31 && ltid_in_bounds_18747) {\n                        ((volatile __local int64_t *) red_arr_i64_mem_18736)[sext_i32_i64(squot32(local_tid_18732, 32))] = eta_p_18079;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n                {\n                    int32_t skip_threads_18751;\n                    \n                    // read input for in-block scan\n                    {\n                        if (squot32(local_tid_18732, 32) == 0 && ltid_in_bounds_18747) {\n                            eta_p_18745 = ((volatile __local int64_t *",
                                    ") red_arr_i64_mem_18736)[sext_i32_i64(local_tid_18732)];\n                            if ((local_tid_18732 - squot32(local_tid_18732, 32) * 32) == 0) {\n                                eta_p_18744 = eta_p_18745;\n                            }\n                        }\n                    }\n                    // in-block scan (hopefully no barriers needed)\n                    {\n                        skip_threads_18751 = 1;\n                        while (slt32(skip_threads_18751, 32)) {\n                            bool thread_active_18752 = sle32(skip_threads_18751, local_tid_18732 - squot32(local_tid_18732, 32) * 32) && (squot32(local_tid_18732, 32) == 0 && ltid_in_bounds_18747);\n                            \n                            if (thread_active_18752) {\n                                // read operands\n                                {\n                                    eta_p_18744 = ((volatile __local int64_t *) red_arr_i64_mem_18736)[sext_i32_i64(local_tid_18732) - sext_i32_i64(skip_threads_18751)];\n                                }\n                            }\n                            // perform operation\n                            {\n                                bool inactive_18753 = slt64(srem64(sext_i32_i64(local_tid_18732 * 32 + 32 - 1), n_11127), sext_i32_i64(local_tid_18732 * 32 + 32 - 1) - sext_i32_i64((local_tid_18732 - skip_threads_18751) * 32 + 32 - 1));\n                                \n                                if (thread_active_18752 && inactive_18753) {\n                                    eta_p_18744 = eta_p_18745;\n                                }\n                                if (thread_active_18752) {\n                                    if (!inactive_18753) {\n                                        int64_t zp_res_18746 = add64(eta_p_18744, eta_p_18745);\n                                        \n                                        eta_p_18744 = zp_res_18746;\n                                    }\n                           ", "     }\n                            }\n                            if (sle32(wave_sizze_18734, skip_threads_18751)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            if (thread_active_18752) {\n                                // write result\n                                {\n                                    ((volatile __local int64_t *) red_arr_i64_mem_18736)[sext_i32_i64(local_tid_18732)] = eta_p_18744;\n                                    eta_p_18745 = eta_p_18744;\n                                }\n                            }\n                            if (sle32(wave_sizze_18734, skip_threads_18751)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            skip_threads_18751 *= 2;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                \n                bool no_carry_in_18754 = squot32(local_tid_18732, 32) == 0 || !ltid_in_bounds_18747;\n                \n                // carry-in for every block except the first\n                {\n                    // read operands\n                    {\n                        if (!no_carry_in_18754) {\n                            eta_p_18080 = eta_p_18079;\n                            eta_p_18079 = ((__local int64_t *) red_arr_i64_mem_18736)[sext_i32_i64(squot32(local_tid_18732, 32)) - (int64_t) 1];\n                        }\n                    }\n                    // perform operation\n                    {\n                        bool inactive_18755 = slt64(srem64(sext_i32_i64(local_tid_18732), n_11127), sext_i32_i64(local_tid_18732) - sext_i32_i64(squot32(local_tid_18732, 32) * 32 - 1));\n                        \n                        if (!no_carry_in_18754) {\n                            if (inactive_18755) {\n                                eta_p_18079 = eta_p_18080;\n                            }\n                       ", " }\n                        if (!no_carry_in_18754) {\n                            if (!inactive_18755) {\n                                int64_t zp_res_18081 = add64(eta_p_18079, eta_p_18080);\n                                \n                                eta_p_18079 = zp_res_18081;\n                            }\n                        }\n                    }\n                    // write final result\n                    {\n                        if (!no_carry_in_18754) {\n                            ((__local int64_t *) red_arr_i64_mem_18736)[sext_i32_i64(local_tid_18732)] = eta_p_18079;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // restore correct values for first block\n                {\n                    if (squot32(local_tid_18732, 32) == 0 && ltid_in_bounds_18747) {\n                        ((__local int64_t *) red_arr_i64_mem_18736)[sext_i32_i64(local_tid_18732)] = eta_p_18080;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // save final values of segments\n        {\n            if (slt64(sext_i32_i64(virt_tblock_id_18741) * squot64(segred_tblock_sizze_18072, segment_sizze_nonzzero_18729) + sext_i32_i64(local_tid_18732), dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154) && slt64(sext_i32_i64(local_tid_18732), squot64(segred_tblock_sizze_18072, segment_sizze_nonzzero_18729))) {\n                int64_t tmp_18756 = ((__local int64_t *) red_arr_i64_mem_18736)[(sext_i32_i64(local_tid_18732) + (int64_t) 1) * segment_sizze_nonzzero_18729 - (int64_t) 1];\n                \n                ((__global int64_t *) mem_18421)[inf_11148 + (sext_i32_i64(virt_tblock_id_18741) * squot64(segred_tblock_sizze_18072, segment_sizze_nonzzero_18729) + sext_i32_i64(local_tid_18732))] = tmp_18756;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_",
                                    "MEM_FENCE);\n    }\n    \n  error_3:\n    return;\n    #undef segred_tblock_sizze_18072\n}\nFUTHARK_KERNEL_SIZED(get_num_neighbours_6842zisegmap_18136_dim1, 1, 1)\nvoid get_num_neighbours_6842zisegmap_18136(__global int *global_failure, int64_t n_13491, int64_t dim_13492, double eps_13494, int64_t inf_13512, int64_t dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518, int64_t num_threads_18628, __global unsigned char *dat_mem_18419, __global unsigned char *mem_18421, __global unsigned char *mem_18479, __global unsigned char *color_18526)\n{\n    #define segmap_tblock_sizze_18132 (get_num_neighbours_6842zisegmap_18136zisegmap_tblock_sizze_18132)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18675;\n    int32_t tblock_sizze_18678;\n    int32_t wave_sizze_18677;\n    int32_t block_id_18676;\n    int32_t global_tid_18674;\n    int64_t phys_tid_18136;\n    int64_t global_tid_18679;\n    int64_t slice_18680;\n    int64_t gtid_18135;\n    int64_t remnant_18681;\n    \n    local_tid_18675 = get_local_id(0);\n    tblock_sizze_18678 = get_local_size(0);\n    wave_sizze_18677 = LOCKSTEP_WIDTH;\n    block_id_18676 = get_tblock_id(0);\n    global_tid_18674 = block_id_18676 * tblock_sizze_18678 + local_tid_18675;\n    phys_tid_18136 = sext_i32_i64(global_tid_18674);\n    global_tid_18679 = sext_i32_i64(block_id_18676) * segmap_tblock_sizze_18132 + sext_i32_i64(local_tid_18675);\n    slice_18680 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518;\n    gtid_18135 = global_tid_18679;\n    remnant_18681 = global_tid_18679 - gtid_18135;\n    if (slt64(gtid_18135, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518)) {\n        int64_t slice_18395;\n        int64_t defunc_res_18138;\n        int64_t redout_18406;\n        int64_t lifted_lambda_res_18156;\n        \n        slice_18395 = inf_13512 + gtid_18135;\n        redout_18406 = (int64_t) 0;\n        for (int64_t i_18407 = 0; i_18407 < n_13491; i_18407++) {\n            double defunc_0_f_res_18145;\n            double acc_18147;\n            double sqrt_res_18150;\n            b", "ool zlze_res_18151;\n            int64_t bool_res_18152;\n            int64_t zp_res_18155;\n            int64_t redout_tmp_18682;\n            \n            for (int64_t i_18410 = 0; i_18410 < dim_13492; i_18410++) {\n                double eta_p_18141;\n                double eta_p_18142;\n                double zm_res_18143;\n                double zt_res_18144;\n                \n                eta_p_18141 = ((__global double *) mem_18479)[slice_18395 + i_18410 * n_13491];\n                eta_p_18142 = ((__global double *) dat_mem_18419)[i_18407 * dim_13492 + i_18410];\n                zm_res_18143 = eta_p_18141 - eta_p_18142;\n                zt_res_18144 = zm_res_18143 * zm_res_18143;\n                ((__global double *) color_18526)[phys_tid_18136 + i_18410 * num_threads_18628] = zt_res_18144;\n            }\n            acc_18147 = 0.0;\n            for (int64_t i_18146 = 0; i_18146 < dim_13492; i_18146++) {\n                double b_18148;\n                double zp_res_18149;\n                double acc_tmp_18684;\n                \n                b_18148 = ((__global double *) color_18526)[phys_tid_18136 + i_18146 * num_threads_18628];\n                zp_res_18149 = acc_18147 + b_18148;\n                acc_tmp_18684 = zp_res_18149;\n                acc_18147 = acc_tmp_18684;\n            }\n            defunc_0_f_res_18145 = acc_18147;\n            sqrt_res_18150 = futrts_sqrt64(defunc_0_f_res_18145);\n            zlze_res_18151 = sqrt_res_18150 <= eps_13494;\n            bool_res_18152 = btoi_bool_i64(zlze_res_18151);\n            zp_res_18155 = add64(bool_res_18152, redout_18406);\n            redout_tmp_18682 = zp_res_18155;\n            redout_18406 = redout_tmp_18682;\n        }\n        defunc_res_18138 = redout_18406;\n        lifted_lambda_res_18156 = sub64(defunc_res_18138, (int64_t) 1);\n        ((__global int64_t *) mem_18421)[inf_13512 + gtid_18135] = lifted_lambda_res_18156;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_18132\n}\nFUTHARK_KERNEL_SIZED(get_nu", "m_neighbours_6842zisegmap_18347_dim1, 1, 1)\nvoid get_num_neighbours_6842zisegmap_18347(__global int *global_failure, int64_t n_13491, int64_t dim_13492, int64_t inf_13512, int64_t dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518, __global unsigned char *dat_mem_18419, __global unsigned char *mem_18429)\n{\n    #define segmap_tblock_sizze_18341 (get_num_neighbours_6842zisegmap_18347zisegmap_tblock_sizze_18341)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18705;\n    int32_t tblock_sizze_18708;\n    int32_t wave_sizze_18707;\n    int32_t block_id_18706;\n    int32_t global_tid_18704;\n    int64_t phys_tid_18347;\n    int64_t global_tid_18709;\n    int64_t slice_18710;\n    int64_t slice_18711;\n    int64_t slice_18712;\n    int64_t gtid_18344;\n    int64_t remnant_18713;\n    int64_t gtid_18345;\n    int64_t remnant_18714;\n    int64_t gtid_18346;\n    int64_t remnant_18715;\n    \n    local_tid_18705 = get_local_id(0);\n    tblock_sizze_18708 = get_local_size(0);\n    wave_sizze_18707 = LOCKSTEP_WIDTH;\n    block_id_18706 = get_tblock_id(0);\n    global_tid_18704 = block_id_18706 * tblock_sizze_18708 + local_tid_18705;\n    phys_tid_18347 = sext_i32_i64(global_tid_18704);\n    global_tid_18709 = sext_i32_i64(block_id_18706) * segmap_tblock_sizze_18341 + sext_i32_i64(local_tid_18705);\n    slice_18710 = dim_13492;\n    slice_18711 = n_13491 * slice_18710;\n    slice_18712 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518 * slice_18711;\n    gtid_18344 = squot64(global_tid_18709, slice_18711);\n    remnant_18713 = global_tid_18709 - gtid_18344 * slice_18711;\n    gtid_18345 = squot64(remnant_18713, slice_18710);\n    remnant_18714 = remnant_18713 - gtid_18345 * slice_18710;\n    gtid_18346 = remnant_18714;\n    remnant_18715 = remnant_18714 - gtid_18346;\n    if ((slt64(gtid_18344, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518) && slt64(gtid_18345, n_13491)) && slt64(gtid_18346, dim_13492)) {\n        int64_t slice_18397;\n        double eta_p_18348;\n        double eta_p_18349;\n        double zm_res_",
                                    "18350;\n        double zt_res_18351;\n        \n        slice_18397 = inf_13512 + gtid_18344;\n        eta_p_18348 = ((__global double *) dat_mem_18419)[slice_18397 * dim_13492 + gtid_18346];\n        eta_p_18349 = ((__global double *) dat_mem_18419)[gtid_18345 * dim_13492 + gtid_18346];\n        zm_res_18350 = eta_p_18348 - eta_p_18349;\n        zt_res_18351 = zm_res_18350 * zm_res_18350;\n        ((__global double *) mem_18429)[gtid_18344 * (dim_13492 * n_13491) + gtid_18345 * dim_13492 + gtid_18346] = zt_res_18351;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_18341\n}\nFUTHARK_KERNEL_SIZED(get_num_neighbours_6842zisegmap_18360_dim1, 1, 1)\nvoid get_num_neighbours_6842zisegmap_18360(__global int *global_failure, int64_t n_13491, int64_t dim_13492, double eps_13494, int64_t dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518, __global unsigned char *mem_18446, __global unsigned char *mem_18450)\n{\n    #define segmap_tblock_sizze_18355 (get_num_neighbours_6842zisegmap_18360zisegmap_tblock_sizze_18355)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18718;\n    int32_t tblock_sizze_18721;\n    int32_t wave_sizze_18720;\n    int32_t block_id_18719;\n    int32_t global_tid_18717;\n    int64_t phys_tid_18360;\n    int64_t global_tid_18722;\n    int64_t slice_18723;\n    int64_t slice_18724;\n    int64_t gtid_18358;\n    int64_t remnant_18725;\n    int64_t gtid_18359;\n    int64_t remnant_18726;\n    \n    local_tid_18718 = get_local_id(0);\n    tblock_sizze_18721 = get_local_size(0);\n    wave_sizze_18720 = LOCKSTEP_WIDTH;\n    block_id_18719 = get_tblock_id(0);\n    global_tid_18717 = block_id_18719 * tblock_sizze_18721 + local_tid_18718;\n    phys_tid_18360 = sext_i32_i64(global_tid_18717);\n    global_tid_18722 = sext_i32_i64(block_id_18719) * segmap_tblock_sizze_18355 + sext_i32_i64(local_tid_18718);\n    slice_18723 = n_13491;\n    slice_18724 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518 * slice_18723;\n    gtid_18358 = squot64(global_tid_18722, slice_18723);\n    remnan", "t_18725 = global_tid_18722 - gtid_18358 * slice_18723;\n    gtid_18359 = remnant_18725;\n    remnant_18726 = remnant_18725 - gtid_18359;\n    if (slt64(gtid_18358, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518) && slt64(gtid_18359, n_13491)) {\n        double defunc_0_f_res_18362;\n        double acc_18364;\n        double sqrt_res_18367;\n        bool zlze_res_18368;\n        int64_t bool_res_18369;\n        \n        acc_18364 = 0.0;\n        for (int64_t i_18363 = 0; i_18363 < dim_13492; i_18363++) {\n            double b_18365;\n            double zp_res_18366;\n            double acc_tmp_18727;\n            \n            b_18365 = ((__global double *) mem_18446)[gtid_18358 * n_13491 + gtid_18359 + i_18363 * (n_13491 * dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518)];\n            zp_res_18366 = acc_18364 + b_18365;\n            acc_tmp_18727 = zp_res_18366;\n            acc_18364 = acc_tmp_18727;\n        }\n        defunc_0_f_res_18362 = acc_18364;\n        sqrt_res_18367 = futrts_sqrt64(defunc_0_f_res_18362);\n        zlze_res_18368 = sqrt_res_18367 <= eps_13494;\n        bool_res_18369 = btoi_bool_i64(zlze_res_18368);\n        ((__global int64_t *) mem_18450)[gtid_18358 * n_13491 + gtid_18359] = bool_res_18369;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_18355\n}\nFUTHARK_KERNEL_SIZED(get_num_neighbours_6842zisegmap_18390_dim1, 1, 1)\nvoid get_num_neighbours_6842zisegmap_18390(__global int *global_failure, int64_t inf_13512, int64_t dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518, __global unsigned char *mem_18421)\n{\n    #define segmap_tblock_sizze_18386 (get_num_neighbours_6842zisegmap_18390zisegmap_tblock_sizze_18386)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18822;\n    int32_t tblock_sizze_18825;\n    int32_t wave_sizze_18824;\n    int32_t block_id_18823;\n    int32_t global_tid_18821;\n    int64_t phys_tid_18390;\n    int64_t global_tid_18826;\n    int64_t slice_18827;\n    int64_t gtid_18389;\n    int64_t remnant_18828;\n    \n    local_tid_18822 = get_local_i", "d(0);\n    tblock_sizze_18825 = get_local_size(0);\n    wave_sizze_18824 = LOCKSTEP_WIDTH;\n    block_id_18823 = get_tblock_id(0);\n    global_tid_18821 = block_id_18823 * tblock_sizze_18825 + local_tid_18822;\n    phys_tid_18390 = sext_i32_i64(global_tid_18821);\n    global_tid_18826 = sext_i32_i64(block_id_18823) * segmap_tblock_sizze_18386 + sext_i32_i64(local_tid_18822);\n    slice_18827 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518;\n    gtid_18389 = global_tid_18826;\n    remnant_18828 = global_tid_18826 - gtid_18389;\n    if (slt64(gtid_18389, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518)) {\n        int64_t defunc_res_18391;\n        int64_t lifted_lambda_res_18392;\n        \n        defunc_res_18391 = ((__global int64_t *) mem_18421)[inf_13512 + gtid_18389];\n        lifted_lambda_res_18392 = sub64(defunc_res_18391, (int64_t) 1);\n        ((__global int64_t *) mem_18421)[inf_13512 + gtid_18389] = lifted_lambda_res_18392;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_18386\n}\nFUTHARK_KERNEL\nvoid get_num_neighbours_6842zisegmap_intrablock_18164(__global int *global_failure, int64_t n_13491, int64_t dim_13492, double eps_13494, int64_t inf_13512, int64_t dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518, int64_t ctx_18644, __global unsigned char *dat_mem_18419, __global unsigned char *mem_18421, __global unsigned char *color_18527)\n{\n    volatile __local unsigned char *red_arr_mem_18697_backing_0 = &shared_mem[0];\n    const int64_t red_arr_mem_18697_backing_0_offset = 0 + ((int64_t) 8 * n_13491 + srem64((int64_t) 8 - srem64((int64_t) 8 * n_13491, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18688;\n    int32_t tblock_sizze_18691;\n    int32_t wave_sizze_18690;\n    int32_t block_id_18689;\n    int32_t global_tid_18687;\n    int64_t phys_tblock_id_18164;\n    int64_t slice_18693;\n    int64_t ltid_pre_18692;\n    int64_t remnant_18694;\n    int64_t slice_18695;\n    int64_t gtid_18163;\n    int64_t remnant_18696;\n    int64_t s",
                                    "lice_18396;\n    int64_t binop_x_18642;\n    int64_t defunc_res_18167;\n    int64_t phys_tid_18169;\n    __local unsigned char *red_arr_mem_18697;\n    int64_t gtid_18168;\n    int64_t ctx_18643;\n    double defunc_0_f_res_18179;\n    double acc_18181;\n    double sqrt_res_18184;\n    bool zlze_res_18185;\n    int64_t bool_res_18186;\n    int32_t offset_18701;\n    int32_t skip_waves_18702;\n    int64_t eta_p_18170;\n    int64_t eta_p_18171;\n    int64_t lifted_lambda_res_18187;\n    \n    local_tid_18688 = get_local_id(0);\n    tblock_sizze_18691 = get_local_size(0);\n    wave_sizze_18690 = LOCKSTEP_WIDTH;\n    block_id_18689 = get_tblock_id(0);\n    global_tid_18687 = block_id_18689 * tblock_sizze_18691 + local_tid_18688;\n    phys_tblock_id_18164 = sext_i32_i64(block_id_18689);\n    slice_18693 = n_13491;\n    ltid_pre_18692 = sext_i32_i64(local_tid_18688);\n    remnant_18694 = sext_i32_i64(local_tid_18688) - ltid_pre_18692;\n    slice_18695 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518;\n    gtid_18163 = sext_i32_i64(block_id_18689);\n    remnant_18696 = sext_i32_i64(block_id_18689) - gtid_18163;\n    slice_18396 = inf_13512 + gtid_18163;\n    binop_x_18642 = n_13491 * phys_tblock_id_18164;\n    phys_tid_18169 = sext_i32_i64(local_tid_18688);\n    red_arr_mem_18697 = (__local unsigned char *) red_arr_mem_18697_backing_0;\n    gtid_18168 = sext_i32_i64(sext_i64_i32(ltid_pre_18692));\n    ctx_18643 = phys_tid_18169 + binop_x_18642;\n    for (int64_t i_18414 = 0; i_18414 < dim_13492; i_18414++) {\n        double eta_p_18175;\n        double eta_p_18176;\n        double zm_res_18177;\n        double zt_res_18178;\n        \n        eta_p_18175 = ((__global double *) dat_mem_18419)[slice_18396 * dim_13492 + i_18414];\n        eta_p_18176 = ((__global double *) dat_mem_18419)[gtid_18168 * dim_13492 + i_18414];\n        zm_res_18177 = eta_p_18175 - eta_p_18176;\n        zt_res_18178 = zm_res_18177 * zm_res_18177;\n        ((__global double *) color_18527)[ctx_18643 + i_18414 * ctx_18644] = zt_res_18178;\n    }\n    acc_", "18181 = 0.0;\n    for (int64_t i_18180 = 0; i_18180 < dim_13492; i_18180++) {\n        double b_18182;\n        double zp_res_18183;\n        double acc_tmp_18700;\n        \n        b_18182 = ((__global double *) color_18527)[ctx_18643 + i_18180 * ctx_18644];\n        zp_res_18183 = acc_18181 + b_18182;\n        acc_tmp_18700 = zp_res_18183;\n        acc_18181 = acc_tmp_18700;\n    }\n    defunc_0_f_res_18179 = acc_18181;\n    sqrt_res_18184 = futrts_sqrt64(defunc_0_f_res_18179);\n    zlze_res_18185 = sqrt_res_18184 <= eps_13494;\n    bool_res_18186 = btoi_bool_i64(zlze_res_18185);\n    ((__local int64_t *) red_arr_mem_18697)[gtid_18168] = bool_res_18186;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    skip_waves_18702 = 1;\n    offset_18701 = 0;\n    // participating threads read initial accumulator\n    {\n        if (slt32(local_tid_18688, sext_i64_i32(n_13491))) {\n            eta_p_18170 = ((__local int64_t *) red_arr_mem_18697)[sext_i32_i64(local_tid_18688 + offset_18701)];\n        }\n    }\n    offset_18701 = 1;\n    while (slt32(offset_18701, wave_sizze_18690)) {\n        if (slt32(local_tid_18688 + offset_18701, sext_i64_i32(n_13491)) && ((local_tid_18688 - squot32(local_tid_18688, wave_sizze_18690) * wave_sizze_18690) & (2 * offset_18701 - 1)) == 0) {\n            // read array element\n            {\n                eta_p_18171 = ((volatile __local int64_t *) red_arr_mem_18697)[sext_i32_i64(local_tid_18688 + offset_18701)];\n            }\n            // apply reduction operation\n            {\n                int64_t zp_res_18172 = add64(eta_p_18170, eta_p_18171);\n                \n                eta_p_18170 = zp_res_18172;\n            }\n            // write result of operation\n            {\n                ((volatile __local int64_t *) red_arr_mem_18697)[sext_i32_i64(local_tid_18688)] = eta_p_18170;\n            }\n        }\n        offset_18701 *= 2;\n    }\n    while (slt32(skip_waves_18702, squot32(sext_i64_i32(n_13491) + wave_sizze_18690 - 1, wave_sizze_18690))) {\n        barrier(CLK_LOCAL_M", "EM_FENCE);\n        offset_18701 = skip_waves_18702 * wave_sizze_18690;\n        if (slt32(local_tid_18688 + offset_18701, sext_i64_i32(n_13491)) && ((local_tid_18688 - squot32(local_tid_18688, wave_sizze_18690) * wave_sizze_18690) == 0 && (squot32(local_tid_18688, wave_sizze_18690) & (2 * skip_waves_18702 - 1)) == 0)) {\n            // read array element\n            {\n                eta_p_18171 = ((__local int64_t *) red_arr_mem_18697)[sext_i32_i64(local_tid_18688 + offset_18701)];\n            }\n            // apply reduction operation\n            {\n                int64_t zp_res_18172 = add64(eta_p_18170, eta_p_18171);\n                \n                eta_p_18170 = zp_res_18172;\n            }\n            // write result of operation\n            {\n                ((__local int64_t *) red_arr_mem_18697)[sext_i32_i64(local_tid_18688)] = eta_p_18170;\n            }\n        }\n        skip_waves_18702 *= 2;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // Save result of reduction.\n    {\n        defunc_res_18167 = ((__local int64_t *) red_arr_mem_18697)[(int64_t) 0];\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    lifted_lambda_res_18187 = sub64(defunc_res_18167, (int64_t) 1);\n    if (local_tid_18688 == 0) {\n        ((__global int64_t *) mem_18421)[inf_13512 + gtid_18163] = lifted_lambda_res_18187;\n    }\n    \n  error_4:\n    return;\n}\nFUTHARK_KERNEL_SIZED(get_num_neighbours_6842zisegred_large_18379_dim1, 1, 1)\nvoid get_num_neighbours_6842zisegred_large_18379(__global int *global_failure, int64_t n_13491, int64_t inf_13512, int64_t dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518, int64_t num_tblocks_18374, int64_t blocks_per_segment_18757, int64_t q_18758, int64_t num_virtblocks_18759, int64_t threads_per_segment_18760, __global unsigned char *mem_18421, __global unsigned char *mem_18450, __global unsigned char *segred_tmp_mem_18761, __global unsigned char *counters_mem_18763)\n{\n    #define segred_tblock_sizze_18373 (get_num_neighbours_6842zisegred_large_1",
                                    "8379zisegred_tblock_sizze_18373)\n    #define chunk_sizze_18728 (get_num_neighbours_6842zisegred_large_18379zichunk_sizze_18728)\n    \n    volatile __local unsigned char *sync_arr_mem_18792_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_18792_backing_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i64_mem_18790_backing_0 = &shared_mem[sync_arr_mem_18792_backing_1_offset];\n    const int64_t red_arr_i64_mem_18790_backing_0_offset = sync_arr_mem_18792_backing_1_offset + ((int64_t) 8 * segred_tblock_sizze_18373 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_18373, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18786;\n    int32_t tblock_sizze_18789;\n    int32_t wave_sizze_18788;\n    int32_t block_id_18787;\n    int32_t global_tid_18785;\n    int64_t phys_tid_18379;\n    __local unsigned char *red_arr_i64_mem_18790;\n    __local unsigned char *sync_arr_mem_18792;\n    int32_t phys_tblock_id_18794;\n    int32_t iterations_18795;\n    \n    local_tid_18786 = get_local_id(0);\n    tblock_sizze_18789 = get_local_size(0);\n    wave_sizze_18788 = LOCKSTEP_WIDTH;\n    block_id_18787 = get_tblock_id(0);\n    global_tid_18785 = block_id_18787 * tblock_sizze_18789 + local_tid_18786;\n    phys_tid_18379 = sext_i32_i64(global_tid_18785);\n    red_arr_i64_mem_18790 = (__local unsigned char *) red_arr_i64_mem_18790_backing_0;\n    sync_arr_mem_18792 = (__local unsigned char *) sync_arr_mem_18792_backing_1;\n    phys_tblock_id_18794 = get_tblock_id(0);\n    iterations_18795 = sdiv_up32(sext_i64_i32(num_virtblocks_18759) - phys_tblock_id_18794, sext_i64_i32(num_tblocks_18374));\n    for (int32_t i_18796 = 0; i_18796 < iterations_18795; i_18796++) {\n        int32_t virt_tblock_id_18797;\n        int64_t flat_segment_id_18798;\n        int64_t global_tid_18799;\n        int64_t slice_18800;\n        int64_t gtid_18377;\n        int64_t remnant_18801;\n        int64_t gtid_18378;\n        int64_t eta_p_block_res_acc", "_18802;\n        int64_t eta_p_18380;\n        int64_t eta_p_18381;\n        int64_t tblock_id_in_segment_18806;\n        int64_t block_base_offset_18807;\n        int32_t offset_18810;\n        int32_t skip_waves_18811;\n        int64_t eta_p_18803;\n        int64_t eta_p_18804;\n        \n        virt_tblock_id_18797 = phys_tblock_id_18794 + i_18796 * sext_i64_i32(num_tblocks_18374);\n        flat_segment_id_18798 = squot64(sext_i32_i64(virt_tblock_id_18797), blocks_per_segment_18757);\n        global_tid_18799 = srem64(sext_i32_i64(virt_tblock_id_18797) * segred_tblock_sizze_18373 + sext_i32_i64(local_tid_18786), threads_per_segment_18760);\n        slice_18800 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518;\n        gtid_18377 = flat_segment_id_18798;\n        remnant_18801 = flat_segment_id_18798 - gtid_18377;\n        // ne-initialise the outer (per-block) accumulator(s)\n        {\n            eta_p_block_res_acc_18802 = (int64_t) 0;\n        }\n        tblock_id_in_segment_18806 = squot64(global_tid_18799, segred_tblock_sizze_18373);\n        block_base_offset_18807 = tblock_id_in_segment_18806 * q_18758 * segred_tblock_sizze_18373;\n        for (int64_t i_18808 = 0; i_18808 < q_18758; i_18808++) {\n            int64_t block_offset_18809 = block_base_offset_18807 + i_18808 * segred_tblock_sizze_18373;\n            \n            gtid_18378 = global_tid_18799 + threads_per_segment_18760 * i_18808;\n            if (slt64(gtid_18378, n_13491)) {\n                // apply map function(s)\n                {\n                    // apply map function\n                    {\n                        int64_t x_18384 = ((__global int64_t *) mem_18450)[gtid_18377 * n_13491 + gtid_18378];\n                        \n                        // load accumulator(s)\n                        {\n                            eta_p_18380 = eta_p_block_res_acc_18802;\n                        }\n                        // load next value(s)\n                        {\n                            eta_p_18381 = x_18384;\n       ", "                 }\n                        // apply reduction operator(s)\n                        {\n                            int64_t zp_res_18382 = add64(eta_p_18380, eta_p_18381);\n                            \n                            // store in accumulator(s)\n                            {\n                                eta_p_block_res_acc_18802 = zp_res_18382;\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // store accs. prims go in lmem; non-prims in params (in global mem)\n        {\n            ((__local int64_t *) red_arr_i64_mem_18790)[sext_i32_i64(local_tid_18786)] = eta_p_block_res_acc_18802;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        skip_waves_18811 = 1;\n        offset_18810 = 0;\n        // participating threads read initial accumulator\n        {\n            if (slt32(local_tid_18786, sext_i64_i32(segred_tblock_sizze_18373))) {\n                eta_p_18803 = ((__local int64_t *) red_arr_i64_mem_18790)[sext_i32_i64(local_tid_18786 + offset_18810)];\n            }\n        }\n        offset_18810 = 1;\n        while (slt32(offset_18810, wave_sizze_18788)) {\n            if (slt32(local_tid_18786 + offset_18810, sext_i64_i32(segred_tblock_sizze_18373)) && ((local_tid_18786 - squot32(local_tid_18786, wave_sizze_18788) * wave_sizze_18788) & (2 * offset_18810 - 1)) == 0) {\n                // read array element\n                {\n                    eta_p_18804 = ((volatile __local int64_t *) red_arr_i64_mem_18790)[sext_i32_i64(local_tid_18786 + offset_18810)];\n                }\n                // apply reduction operation\n                {\n                    int64_t zp_res_18805 = add64(eta_p_18803, eta_p_18804);\n                    \n                    eta_p_18803 = zp_res_18805;\n                }\n                // write result of operation\n                {\n                    ((volatile __local int64_t *) red_arr_i64_mem_18790)[",
                                    "sext_i32_i64(local_tid_18786)] = eta_p_18803;\n                }\n            }\n            offset_18810 *= 2;\n        }\n        while (slt32(skip_waves_18811, squot32(sext_i64_i32(segred_tblock_sizze_18373) + wave_sizze_18788 - 1, wave_sizze_18788))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_18810 = skip_waves_18811 * wave_sizze_18788;\n            if (slt32(local_tid_18786 + offset_18810, sext_i64_i32(segred_tblock_sizze_18373)) && ((local_tid_18786 - squot32(local_tid_18786, wave_sizze_18788) * wave_sizze_18788) == 0 && (squot32(local_tid_18786, wave_sizze_18788) & (2 * skip_waves_18811 - 1)) == 0)) {\n                // read array element\n                {\n                    eta_p_18804 = ((__local int64_t *) red_arr_i64_mem_18790)[sext_i32_i64(local_tid_18786 + offset_18810)];\n                }\n                // apply reduction operation\n                {\n                    int64_t zp_res_18805 = add64(eta_p_18803, eta_p_18804);\n                    \n                    eta_p_18803 = zp_res_18805;\n                }\n                // write result of operation\n                {\n                    ((__local int64_t *) red_arr_i64_mem_18790)[sext_i32_i64(local_tid_18786)] = eta_p_18803;\n                }\n            }\n            skip_waves_18811 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // thread 0 updates per-block acc(s); rest reset to ne\n        {\n            if (sext_i32_i64(local_tid_18786) == (int64_t) 0) {\n                eta_p_block_res_acc_18802 = eta_p_18803;\n            } else {\n                eta_p_block_res_acc_18802 = (int64_t) 0;\n            }\n        }\n        if (blocks_per_segment_18757 == (int64_t) 1) {\n            // first thread in block saves final result to memory\n            {\n                if (local_tid_18786 == 0) {\n                    ((__global int64_t *) mem_18421)[inf_13512 + gtid_18377] = eta_p_block_res_acc_18802;\n                }\n            }\n      ", "  } else {\n            int32_t old_counter_18812;\n            bool is_last_block_18813;\n            \n            // first thread in block saves block result to global memory\n            {\n                if (local_tid_18786 == 0) {\n                    ((__global int64_t *) segred_tmp_mem_18761)[sext_i32_i64(virt_tblock_id_18797)] = eta_p_block_res_acc_18802;\n                    mem_fence_global();\n                    old_counter_18812 = atomic_add_i32_global(&((volatile __global int *) counters_mem_18763)[srem64(flat_segment_id_18798, (int64_t) 20480)], (int) 1);\n                    ((__local bool *) sync_arr_mem_18792)[(int64_t) 0] = old_counter_18812 == sext_i64_i32(blocks_per_segment_18757 - (int64_t) 1);\n                }\n            }\n            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n            is_last_block_18813 = ((__local bool *) sync_arr_mem_18792)[(int64_t) 0];\n            if (is_last_block_18813) {\n                if (local_tid_18786 == 0) {\n                    old_counter_18812 = atomic_add_i32_global(&((volatile __global int *) counters_mem_18763)[srem64(flat_segment_id_18798, (int64_t) 20480)], (int) sext_i64_i32((int64_t) 0 - blocks_per_segment_18757));\n                }\n                // read in the per-block-results\n                {\n                    int64_t read_per_thread_18814 = sdiv_up64(blocks_per_segment_18757, segred_tblock_sizze_18373);\n                    \n                    eta_p_18380 = (int64_t) 0;\n                    for (int64_t i_18815 = 0; i_18815 < read_per_thread_18814; i_18815++) {\n                        int64_t block_res_id_18816 = sext_i32_i64(local_tid_18786) * read_per_thread_18814 + i_18815;\n                        int64_t index_of_block_res_18817 = flat_segment_id_18798 * blocks_per_segment_18757 + block_res_id_18816;\n                        \n                        if (slt64(block_res_id_18816, blocks_per_segment_18757)) {\n                            eta_p_18381 = ((__global int64_t *) segred_tmp_mem_", "18761)[index_of_block_res_18817];\n                            \n                            int64_t zp_res_18382 = add64(eta_p_18380, eta_p_18381);\n                            \n                            eta_p_18380 = zp_res_18382;\n                        }\n                    }\n                }\n                ((__local int64_t *) red_arr_i64_mem_18790)[sext_i32_i64(local_tid_18786)] = eta_p_18380;\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // reduce the per-block results\n                {\n                    int32_t offset_18818;\n                    int32_t skip_waves_18819 = 1;\n                    int64_t eta_p_18803;\n                    int64_t eta_p_18804;\n                    \n                    offset_18818 = 0;\n                    // participating threads read initial accumulator\n                    {\n                        if (slt32(local_tid_18786, sext_i64_i32(segred_tblock_sizze_18373))) {\n                            eta_p_18803 = ((__local int64_t *) red_arr_i64_mem_18790)[sext_i32_i64(local_tid_18786 + offset_18818)];\n                        }\n                    }\n                    offset_18818 = 1;\n                    while (slt32(offset_18818, wave_sizze_18788)) {\n                        if (slt32(local_tid_18786 + offset_18818, sext_i64_i32(segred_tblock_sizze_18373)) && ((local_tid_18786 - squot32(local_tid_18786, wave_sizze_18788) * wave_sizze_18788) & (2 * offset_18818 - 1)) == 0) {\n                            // read array element\n                            {\n                                eta_p_18804 = ((volatile __local int64_t *) red_arr_i64_mem_18790)[sext_i32_i64(local_tid_18786 + offset_18818)];\n                            }\n                            // apply reduction operation\n                            {\n                                int64_t zp_res_18805 = add64(eta_p_18803, eta_p_18804);\n                                \n                                eta_p_18803 = zp_res_18805;\n                          ",
                                    "  }\n                            // write result of operation\n                            {\n                                ((volatile __local int64_t *) red_arr_i64_mem_18790)[sext_i32_i64(local_tid_18786)] = eta_p_18803;\n                            }\n                        }\n                        offset_18818 *= 2;\n                    }\n                    while (slt32(skip_waves_18819, squot32(sext_i64_i32(segred_tblock_sizze_18373) + wave_sizze_18788 - 1, wave_sizze_18788))) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                        offset_18818 = skip_waves_18819 * wave_sizze_18788;\n                        if (slt32(local_tid_18786 + offset_18818, sext_i64_i32(segred_tblock_sizze_18373)) && ((local_tid_18786 - squot32(local_tid_18786, wave_sizze_18788) * wave_sizze_18788) == 0 && (squot32(local_tid_18786, wave_sizze_18788) & (2 * skip_waves_18819 - 1)) == 0)) {\n                            // read array element\n                            {\n                                eta_p_18804 = ((__local int64_t *) red_arr_i64_mem_18790)[sext_i32_i64(local_tid_18786 + offset_18818)];\n                            }\n                            // apply reduction operation\n                            {\n                                int64_t zp_res_18805 = add64(eta_p_18803, eta_p_18804);\n                                \n                                eta_p_18803 = zp_res_18805;\n                            }\n                            // write result of operation\n                            {\n                                ((__local int64_t *) red_arr_i64_mem_18790)[sext_i32_i64(local_tid_18786)] = eta_p_18803;\n                            }\n                        }\n                        skip_waves_18819 *= 2;\n                    }\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                    // and back to memory with the final result\n                    {\n                        if (local_tid_18786 == 0) {\n                            ((_", "_global int64_t *) mem_18421)[inf_13512 + gtid_18377] = eta_p_18803;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_6:\n    return;\n    #undef segred_tblock_sizze_18373\n    #undef chunk_sizze_18728\n}\nFUTHARK_KERNEL_SIZED(get_num_neighbours_6842zisegred_small_18379_dim1, 1, 1)\nvoid get_num_neighbours_6842zisegred_small_18379(__global int *global_failure, int64_t n_13491, int64_t inf_13512, int64_t dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518, int64_t num_tblocks_18374, int64_t segment_sizze_nonzzero_18729, __global unsigned char *mem_18421, __global unsigned char *mem_18450)\n{\n    #define segred_tblock_sizze_18373 (get_num_neighbours_6842zisegred_small_18379zisegred_tblock_sizze_18373)\n    \n    volatile __local unsigned char *red_arr_i64_mem_18736_backing_0 = &shared_mem[0];\n    const int64_t red_arr_i64_mem_18736_backing_0_offset = 0 + ((int64_t) 8 * segred_tblock_sizze_18373 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_18373, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18732;\n    int32_t tblock_sizze_18735;\n    int32_t wave_sizze_18734;\n    int32_t block_id_18733;\n    int32_t global_tid_18731;\n    int64_t phys_tid_18379;\n    __local unsigned char *red_arr_i64_mem_18736;\n    int32_t phys_tblock_id_18738;\n    int32_t iterations_18739;\n    \n    local_tid_18732 = get_local_id(0);\n    tblock_sizze_18735 = get_local_size(0);\n    wave_sizze_18734 = LOCKSTEP_WIDTH;\n    block_id_18733 = get_tblock_id(0);\n    global_tid_18731 = block_id_18733 * tblock_sizze_18735 + local_tid_18732;\n    phys_tid_18379 = sext_i32_i64(global_tid_18731);\n    red_arr_i64_mem_18736 = (__local unsigned char *) red_arr_i64_mem_18736_backing_0;\n    phys_tblock_id_18738 = get_tblock_id(0);\n    iterations_18739 = sdiv_up32(sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518, squot64(segred_tblock", "_sizze_18373, segment_sizze_nonzzero_18729))) - phys_tblock_id_18738, sext_i64_i32(num_tblocks_18374));\n    for (int32_t i_18740 = 0; i_18740 < iterations_18739; i_18740++) {\n        int32_t virt_tblock_id_18741;\n        int64_t slice_18742;\n        int64_t gtid_18377;\n        int64_t remnant_18743;\n        int64_t gtid_18378;\n        \n        virt_tblock_id_18741 = phys_tblock_id_18738 + i_18740 * sext_i64_i32(num_tblocks_18374);\n        slice_18742 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518;\n        gtid_18377 = squot64(sext_i32_i64(local_tid_18732), segment_sizze_nonzzero_18729) + sext_i32_i64(virt_tblock_id_18741) * squot64(segred_tblock_sizze_18373, segment_sizze_nonzzero_18729);\n        remnant_18743 = squot64(sext_i32_i64(local_tid_18732), segment_sizze_nonzzero_18729) + sext_i32_i64(virt_tblock_id_18741) * squot64(segred_tblock_sizze_18373, segment_sizze_nonzzero_18729) - gtid_18377;\n        gtid_18378 = srem64(sext_i32_i64(local_tid_18732), n_13491);\n        // apply map function if in bounds\n        {\n            if (slt64((int64_t) 0, n_13491) && (slt64(gtid_18377, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518) && slt64(sext_i32_i64(local_tid_18732), n_13491 * squot64(segred_tblock_sizze_18373, segment_sizze_nonzzero_18729)))) {\n                // apply map function\n                {\n                    int64_t x_18384 = ((__global int64_t *) mem_18450)[gtid_18377 * n_13491 + gtid_18378];\n                    \n                    // save results to be reduced\n                    {\n                        ((__local int64_t *) red_arr_i64_mem_18736)[sext_i32_i64(local_tid_18732)] = x_18384;\n                    }\n                }\n            } else {\n                ((__local int64_t *) red_arr_i64_mem_18736)[sext_i32_i64(local_tid_18732)] = (int64_t) 0;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (slt64((int64_t) 0, n_13491)) {\n            // perform segmented scan to imitate reduction\n            {\n                int64_t eta_p_18380;",
                                    "\n                int64_t eta_p_18381;\n                int64_t eta_p_18744;\n                int64_t eta_p_18745;\n                bool ltid_in_bounds_18747 = slt64(sext_i32_i64(local_tid_18732), n_13491 * squot64(segred_tblock_sizze_18373, segment_sizze_nonzzero_18729));\n                int32_t skip_threads_18748;\n                \n                // read input for in-block scan\n                {\n                    if (ltid_in_bounds_18747) {\n                        eta_p_18381 = ((volatile __local int64_t *) red_arr_i64_mem_18736)[sext_i32_i64(local_tid_18732)];\n                        if ((local_tid_18732 - squot32(local_tid_18732, 32) * 32) == 0) {\n                            eta_p_18380 = eta_p_18381;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_18748 = 1;\n                    while (slt32(skip_threads_18748, 32)) {\n                        bool thread_active_18749 = sle32(skip_threads_18748, local_tid_18732 - squot32(local_tid_18732, 32) * 32) && ltid_in_bounds_18747;\n                        \n                        if (thread_active_18749) {\n                            // read operands\n                            {\n                                eta_p_18380 = ((volatile __local int64_t *) red_arr_i64_mem_18736)[sext_i32_i64(local_tid_18732) - sext_i32_i64(skip_threads_18748)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            bool inactive_18750 = slt64(srem64(sext_i32_i64(local_tid_18732), n_13491), sext_i32_i64(local_tid_18732) - sext_i32_i64(local_tid_18732 - skip_threads_18748));\n                            \n                            if (thread_active_18749 && inactive_18750) {\n                                eta_p_18380 = eta_p_18381;\n                            }\n                            if (thread_active_18749) {\n ", "                               if (!inactive_18750) {\n                                    int64_t zp_res_18382 = add64(eta_p_18380, eta_p_18381);\n                                    \n                                    eta_p_18380 = zp_res_18382;\n                                }\n                            }\n                        }\n                        if (sle32(wave_sizze_18734, skip_threads_18748)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_18749) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) red_arr_i64_mem_18736)[sext_i32_i64(local_tid_18732)] = eta_p_18380;\n                                eta_p_18381 = eta_p_18380;\n                            }\n                        }\n                        if (sle32(wave_sizze_18734, skip_threads_18748)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_18748 *= 2;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // last thread of block 'i' writes its result to offset 'i'\n                {\n                    if ((local_tid_18732 - squot32(local_tid_18732, 32) * 32) == 31 && ltid_in_bounds_18747) {\n                        ((volatile __local int64_t *) red_arr_i64_mem_18736)[sext_i32_i64(squot32(local_tid_18732, 32))] = eta_p_18380;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n                {\n                    int32_t skip_threads_18751;\n                    \n                    // read input for in-block scan\n                    {\n                        if (squot32(local_tid_18732, 32) == 0 && ltid_in_bounds_18747) {\n                            eta_p_18745 = ((volatile __local int", "64_t *) red_arr_i64_mem_18736)[sext_i32_i64(local_tid_18732)];\n                            if ((local_tid_18732 - squot32(local_tid_18732, 32) * 32) == 0) {\n                                eta_p_18744 = eta_p_18745;\n                            }\n                        }\n                    }\n                    // in-block scan (hopefully no barriers needed)\n                    {\n                        skip_threads_18751 = 1;\n                        while (slt32(skip_threads_18751, 32)) {\n                            bool thread_active_18752 = sle32(skip_threads_18751, local_tid_18732 - squot32(local_tid_18732, 32) * 32) && (squot32(local_tid_18732, 32) == 0 && ltid_in_bounds_18747);\n                            \n                            if (thread_active_18752) {\n                                // read operands\n                                {\n                                    eta_p_18744 = ((volatile __local int64_t *) red_arr_i64_mem_18736)[sext_i32_i64(local_tid_18732) - sext_i32_i64(skip_threads_18751)];\n                                }\n                            }\n                            // perform operation\n                            {\n                                bool inactive_18753 = slt64(srem64(sext_i32_i64(local_tid_18732 * 32 + 32 - 1), n_13491), sext_i32_i64(local_tid_18732 * 32 + 32 - 1) - sext_i32_i64((local_tid_18732 - skip_threads_18751) * 32 + 32 - 1));\n                                \n                                if (thread_active_18752 && inactive_18753) {\n                                    eta_p_18744 = eta_p_18745;\n                                }\n                                if (thread_active_18752) {\n                                    if (!inactive_18753) {\n                                        int64_t zp_res_18746 = add64(eta_p_18744, eta_p_18745);\n                                        \n                                        eta_p_18744 = zp_res_18746;\n                                    }\n                     ",
                                    "           }\n                            }\n                            if (sle32(wave_sizze_18734, skip_threads_18751)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            if (thread_active_18752) {\n                                // write result\n                                {\n                                    ((volatile __local int64_t *) red_arr_i64_mem_18736)[sext_i32_i64(local_tid_18732)] = eta_p_18744;\n                                    eta_p_18745 = eta_p_18744;\n                                }\n                            }\n                            if (sle32(wave_sizze_18734, skip_threads_18751)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            skip_threads_18751 *= 2;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                \n                bool no_carry_in_18754 = squot32(local_tid_18732, 32) == 0 || !ltid_in_bounds_18747;\n                \n                // carry-in for every block except the first\n                {\n                    // read operands\n                    {\n                        if (!no_carry_in_18754) {\n                            eta_p_18381 = eta_p_18380;\n                            eta_p_18380 = ((__local int64_t *) red_arr_i64_mem_18736)[sext_i32_i64(squot32(local_tid_18732, 32)) - (int64_t) 1];\n                        }\n                    }\n                    // perform operation\n                    {\n                        bool inactive_18755 = slt64(srem64(sext_i32_i64(local_tid_18732), n_13491), sext_i32_i64(local_tid_18732) - sext_i32_i64(squot32(local_tid_18732, 32) * 32 - 1));\n                        \n                        if (!no_carry_in_18754) {\n                            if (inactive_18755) {\n                                eta_p_18380 = eta_p_18381;\n                            }\n                 ", "       }\n                        if (!no_carry_in_18754) {\n                            if (!inactive_18755) {\n                                int64_t zp_res_18382 = add64(eta_p_18380, eta_p_18381);\n                                \n                                eta_p_18380 = zp_res_18382;\n                            }\n                        }\n                    }\n                    // write final result\n                    {\n                        if (!no_carry_in_18754) {\n                            ((__local int64_t *) red_arr_i64_mem_18736)[sext_i32_i64(local_tid_18732)] = eta_p_18380;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // restore correct values for first block\n                {\n                    if (squot32(local_tid_18732, 32) == 0 && ltid_in_bounds_18747) {\n                        ((__local int64_t *) red_arr_i64_mem_18736)[sext_i32_i64(local_tid_18732)] = eta_p_18381;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // save final values of segments\n        {\n            if (slt64(sext_i32_i64(virt_tblock_id_18741) * squot64(segred_tblock_sizze_18373, segment_sizze_nonzzero_18729) + sext_i32_i64(local_tid_18732), dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518) && slt64(sext_i32_i64(local_tid_18732), squot64(segred_tblock_sizze_18373, segment_sizze_nonzzero_18729))) {\n                int64_t tmp_18756 = ((__local int64_t *) red_arr_i64_mem_18736)[(sext_i32_i64(local_tid_18732) + (int64_t) 1) * segment_sizze_nonzzero_18729 - (int64_t) 1];\n                \n                ((__global int64_t *) mem_18421)[inf_13512 + (sext_i32_i64(virt_tblock_id_18741) * squot64(segred_tblock_sizze_18373, segment_sizze_nonzzero_18729) + sext_i32_i64(local_tid_18732))] = tmp_18756;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_", "LOCAL_MEM_FENCE);\n    }\n    \n  error_3:\n    return;\n    #undef segred_tblock_sizze_18373\n}\nFUTHARK_KERNEL_SIZED(isolate_core_points_6732zisegmap_16203_dim1, 1, 1)\nvoid isolate_core_points_6732zisegmap_16203(__global int *global_failure, int64_t n_11606, __global unsigned char *mem_18423, __global unsigned char *mem_18425, __global unsigned char *mem_18431)\n{\n    #define segmap_tblock_sizze_16199 (isolate_core_points_6732zisegmap_16203zisegmap_tblock_sizze_16199)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18797;\n    int32_t tblock_sizze_18800;\n    int32_t wave_sizze_18799;\n    int32_t block_id_18798;\n    int32_t global_tid_18796;\n    int64_t phys_tid_16203;\n    int64_t global_tid_18801;\n    int64_t slice_18802;\n    int64_t gtid_16202;\n    int64_t remnant_18803;\n    \n    local_tid_18797 = get_local_id(0);\n    tblock_sizze_18800 = get_local_size(0);\n    wave_sizze_18799 = LOCKSTEP_WIDTH;\n    block_id_18798 = get_tblock_id(0);\n    global_tid_18796 = block_id_18798 * tblock_sizze_18800 + local_tid_18797;\n    phys_tid_16203 = sext_i32_i64(global_tid_18796);\n    global_tid_18801 = sext_i32_i64(block_id_18798) * segmap_tblock_sizze_16199 + sext_i32_i64(local_tid_18797);\n    slice_18802 = n_11606;\n    gtid_16202 = global_tid_18801;\n    remnant_18803 = global_tid_18801 - gtid_16202;\n    if (slt64(gtid_16202, n_11606)) {\n        int64_t eta_p_16204;\n        bool cond_16206;\n        int64_t lifted_lambda_res_16207;\n        \n        eta_p_16204 = ((__global int64_t *) mem_18425)[gtid_16202];\n        cond_16206 = eta_p_16204 == (int64_t) 1;\n        if (cond_16206) {\n            int64_t eta_p_16205;\n            int64_t lifted_lambda_res_t_res_16208;\n            \n            eta_p_16205 = ((__global int64_t *) mem_18423)[gtid_16202];\n            lifted_lambda_res_t_res_16208 = sub64(eta_p_16205, (int64_t) 1);\n            lifted_lambda_res_16207 = lifted_lambda_res_t_res_16208;\n        } else {\n            lifted_lambda_res_16207 = (int64_t) -1;\n       ",
                                    " }\n        ((__global int64_t *) mem_18431)[gtid_16202] = lifted_lambda_res_16207;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_16199\n}\nFUTHARK_KERNEL_SIZED(isolate_core_points_6732zisegmap_16214_dim1, 1, 1)\nvoid isolate_core_points_6732zisegmap_16214(__global int *global_failure, int64_t n_11606, int64_t dim_11607, int64_t m_15698, int64_t num_tblocks_16220, int32_t virt_num_tblocks_18805, __global unsigned char *dat_mem_18419, __global unsigned char *mem_18428, __global unsigned char *mem_18431)\n{\n    #define segmap_tblock_sizze_16218 (isolate_core_points_6732zisegmap_16214zisegmap_tblock_sizze_16218)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18807;\n    int32_t tblock_sizze_18810;\n    int32_t wave_sizze_18809;\n    int32_t block_id_18808;\n    int32_t global_tid_18806;\n    int64_t phys_tid_16214;\n    int32_t phys_tblock_id_18811;\n    int32_t iterations_18812;\n    \n    local_tid_18807 = get_local_id(0);\n    tblock_sizze_18810 = get_local_size(0);\n    wave_sizze_18809 = LOCKSTEP_WIDTH;\n    block_id_18808 = get_tblock_id(0);\n    global_tid_18806 = block_id_18808 * tblock_sizze_18810 + local_tid_18807;\n    phys_tid_16214 = sext_i32_i64(global_tid_18806);\n    phys_tblock_id_18811 = get_tblock_id(0);\n    iterations_18812 = sdiv_up32(virt_num_tblocks_18805 - phys_tblock_id_18811, sext_i64_i32(num_tblocks_16220));\n    for (int32_t i_18813 = 0; i_18813 < iterations_18812; i_18813++) {\n        int32_t virt_tblock_id_18814;\n        int64_t global_tid_18815;\n        int64_t slice_18816;\n        int64_t slice_18817;\n        int64_t write_i_16210;\n        int64_t remnant_18818;\n        int64_t val_i_16211;\n        int64_t remnant_18819;\n        \n        virt_tblock_id_18814 = phys_tblock_id_18811 + i_18813 * sext_i64_i32(num_tblocks_16220);\n        global_tid_18815 = sext_i32_i64(virt_tblock_id_18814) * segmap_tblock_sizze_16218 + sext_i32_i64(local_tid_18807);\n        slice_18816 = dim_11607;\n        slice_18817 = n_11606 * slic", "e_18816;\n        write_i_16210 = squot64(global_tid_18815, slice_18816);\n        remnant_18818 = global_tid_18815 - write_i_16210 * slice_18816;\n        val_i_16211 = remnant_18818;\n        remnant_18819 = remnant_18818 - val_i_16211;\n        if (slt64(write_i_16210, n_11606) && slt64(val_i_16211, dim_11607)) {\n            float scatter_tmp_elem_16212;\n            int64_t scatter_tmp_i_16213;\n            \n            scatter_tmp_elem_16212 = ((__global float *) dat_mem_18419)[write_i_16210 * dim_11607 + val_i_16211];\n            scatter_tmp_i_16213 = ((__global int64_t *) mem_18431)[write_i_16210];\n            if ((sle64((int64_t) 0, scatter_tmp_i_16213) && slt64(scatter_tmp_i_16213, m_15698)) && (sle64((int64_t) 0, val_i_16211) && slt64(val_i_16211, dim_11607))) {\n                ((__global float *) mem_18428)[scatter_tmp_i_16213 * dim_11607 + val_i_16211] = scatter_tmp_elem_16212;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_16218\n}\nFUTHARK_KERNEL_SIZED(isolate_core_points_6732zisegscan_16182_dim1, 1, 1)\nvoid isolate_core_points_6732zisegscan_16182(__global int *global_failure, int64_t n_11606, int64_t num_tblocks_16179, int64_t num_virt_blocks_18658, int64_t num_virt_threads_18659, __global unsigned char *isCore_mem_18420, __global unsigned char *mem_18423, __global unsigned char *mem_18425, __global unsigned char *status_flags_mem_18660, __global unsigned char *aggregates_mem_18682, __global unsigned char *incprefixes_mem_18684, __global unsigned char *global_dynid_mem_18686)\n{\n    #define segscan_tblock_sizze_16177 (isolate_core_points_6732zisegscan_16182zisegscan_tblock_sizze_16177)\n    #define chunk_sizze_18657 (isolate_core_points_6732zisegscan_16182zichunk_sizze_18657)\n    \n    volatile __local unsigned char *local_mem_18716_backing_0 = &shared_mem[0];\n    const int64_t local_mem_18716_backing_0_offset = 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * se", "gscan_tblock_sizze_16177), chunk_sizze_18657 * segscan_tblock_sizze_16177 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_16177), chunk_sizze_18657 * segscan_tblock_sizze_16177 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18709;\n    int32_t tblock_sizze_18712;\n    int32_t wave_sizze_18711;\n    int32_t block_id_18710;\n    int32_t global_tid_18708;\n    int64_t phys_tid_16182;\n    int32_t chunk_sizze_32b_18713;\n    int64_t byte_offsets_18714;\n    int64_t warp_byte_offset_18715;\n    __local unsigned char *local_mem_18716;\n    int64_t trans_arr_len_18717;\n    int64_t phys_block_id_18723;\n    int64_t virtloop_bound_18724;\n    \n    local_tid_18709 = get_local_id(0);\n    tblock_sizze_18712 = get_local_size(0);\n    wave_sizze_18711 = LOCKSTEP_WIDTH;\n    block_id_18710 = get_tblock_id(0);\n    global_tid_18708 = block_id_18710 * tblock_sizze_18712 + local_tid_18709;\n    phys_tid_16182 = sext_i32_i64(global_tid_18708);\n    chunk_sizze_32b_18713 = sext_i64_i32(chunk_sizze_18657);\n    byte_offsets_18714 = segscan_tblock_sizze_16177 * (int64_t) 8;\n    warp_byte_offset_18715 = (int64_t) 288;\n    // Allocate reusable shared memory\n    { }\n    local_mem_18716 = (__local unsigned char *) local_mem_18716_backing_0;\n    trans_arr_len_18717 = chunk_sizze_18657 * segscan_tblock_sizze_16177;\n    phys_block_id_18723 = get_tblock_id(0);\n    virtloop_bound_18724 = sdiv_up64(num_virt_blocks_18658 - phys_block_id_18723, num_tblocks_16179);\n    for (int64_t virtloop_i_18725 = 0; virtloop_i_18725 < virtloop_bound_18724; virtloop_i_18725++) {\n        int64_t dynamic_id_18726;\n        int64_t block_offset_18727;\n        int64_t sgm_idx_18728;\n        int32_t boundary_18729;\n        int32_t segsizze_compact_18730;\n        int64_t private_mem_18731[chunk_sizze_18657];\n        int64_t thd_offset_18733;\n        int64_t acc_18749;\n        int64_t prefix_18759;\n      ",
                                    "  bool block_new_sgm_18760;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_18709 == 0) {\n                dynamic_id_18726 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_18686)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_18716)[(int64_t) 0] = dynamic_id_18726;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_18726 == num_virt_blocks_18658 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_18686)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_18726 = ((__local int32_t *) local_mem_18716)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_18727 = dynamic_id_18726 * chunk_sizze_18657 * segscan_tblock_sizze_16177;\n        sgm_idx_18728 = smod64(block_offset_18727, n_11606);\n        boundary_18729 = sext_i64_i32(smin64(chunk_sizze_18657 * segscan_tblock_sizze_16177, n_11606 - sgm_idx_18728));\n        segsizze_compact_18730 = sext_i64_i32(smin64(chunk_sizze_18657 * segscan_tblock_sizze_16177, n_11606));\n        thd_offset_18733 = block_offset_18727 + sext_i32_i64(local_tid_18709);\n        // Load and map\n        {\n            for (int64_t i_18734 = 0; i_18734 < chunk_sizze_18657; i_18734++) {\n                int64_t virt_tid_18735 = thd_offset_18733 + i_18734 * segscan_tblock_sizze_16177;\n                int64_t slice_18736 = n_11606;\n                int64_t gtid_16181 = virt_tid_18735;\n                int64_t remnant_18737 = virt_tid_18735 - gtid_16181;\n                \n                if (slt64(virt_tid_18735, n_11606)) {\n                    bool eta_p_16086 = ((__global bool *) isCore_mem_18420)[gtid_16181];\n                    int64_t defunc_0_f_re", "s_16087 = btoi_bool_i64(eta_p_16086);\n                    \n                    ((__global int64_t *) mem_18425)[gtid_16181] = defunc_0_f_res_16087;\n                    private_mem_18731[i_18734] = defunc_0_f_res_16087;\n                } else {\n                    private_mem_18731[i_18734] = (int64_t) 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_18738 = 0; i_18738 < chunk_sizze_18657; i_18738++) {\n                int64_t sharedIdx_18739 = sext_i32_i64(local_tid_18709) + i_18738 * segscan_tblock_sizze_16177;\n                int64_t tmp_18740 = private_mem_18731[i_18738];\n                \n                ((__local int64_t *) local_mem_18716)[sharedIdx_18739] = tmp_18740;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_18741 = 0; i_18741 < chunk_sizze_18657; i_18741++) {\n                int64_t sharedIdx_18742 = sext_i32_i64(local_tid_18709) * chunk_sizze_18657 + i_18741;\n                int64_t tmp_18743 = ((__local int64_t *) local_mem_18716)[sharedIdx_18742];\n                \n                private_mem_18731[i_18741] = tmp_18743;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_18744 = 0; i_18744 < chunk_sizze_18657 - (int64_t) 1; i_18744++) {\n                int64_t eta_p_15685;\n                int64_t eta_p_15686;\n                \n                eta_p_15685 = private_mem_18731[i_18744];\n                eta_p_15686 = private_mem_18731[i_18744 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_15687 = add64(eta_p_15685, eta_p_15686);\n                \n                private_mem_18731[i_18744 + (int64_t) 1] = defunc_0_op_res_15687;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_18745 = private_mem_18731[chunk_sizze_18657 - (int64_t) 1];\n            \n            ((__loca", "l int64_t *) local_mem_18716)[sext_i32_i64(local_tid_18709)] = tmp_18745;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_18746;\n            int64_t eta_p_18747;\n            int64_t eta_p_18750;\n            int64_t eta_p_18751;\n            bool ltid_in_bounds_18753 = slt64(sext_i32_i64(local_tid_18709), num_virt_threads_18659);\n            int32_t skip_threads_18754;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_18753) {\n                    eta_p_18747 = ((volatile __local int64_t *) local_mem_18716)[sext_i32_i64(local_tid_18709)];\n                    if ((local_tid_18709 - squot32(local_tid_18709, 32) * 32) == 0) {\n                        eta_p_18746 = eta_p_18747;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_18754 = 1;\n                while (slt32(skip_threads_18754, 32)) {\n                    bool thread_active_18755 = sle32(skip_threads_18754, local_tid_18709 - squot32(local_tid_18709, 32) * 32) && ltid_in_bounds_18753;\n                    \n                    if (thread_active_18755) {\n                        // read operands\n                        {\n                            eta_p_18746 = ((volatile __local int64_t *) local_mem_18716)[sext_i32_i64(local_tid_18709) - sext_i32_i64(skip_threads_18754)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_18755) {\n                            int64_t defunc_0_op_res_18748 = add64(eta_p_18746, eta_p_18747);\n                            \n                            eta_p_18746 = defunc_0_op_res_18748;\n                        }\n                    }\n                    if (sle32(wave_sizze_18711, skip_threads_18754)) {\n                        barrier(CLK_LOCAL_MEM_FENC",
                                    "E);\n                    }\n                    if (thread_active_18755) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_18716)[sext_i32_i64(local_tid_18709)] = eta_p_18746;\n                            eta_p_18747 = eta_p_18746;\n                        }\n                    }\n                    if (sle32(wave_sizze_18711, skip_threads_18754)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_18754 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_18709 - squot32(local_tid_18709, 32) * 32) == 31 && ltid_in_bounds_18753) {\n                    ((volatile __local int64_t *) local_mem_18716)[sext_i32_i64(squot32(local_tid_18709, 32))] = eta_p_18746;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_18756;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_18709, 32) == 0 && ltid_in_bounds_18753) {\n                        eta_p_18751 = ((volatile __local int64_t *) local_mem_18716)[sext_i32_i64(local_tid_18709)];\n                        if ((local_tid_18709 - squot32(local_tid_18709, 32) * 32) == 0) {\n                            eta_p_18750 = eta_p_18751;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_18756 = 1;\n                    while (slt32(skip_threads_18756, 32)) {\n                        bool thread_active_18757 = sle32(skip_threads_18756, local_tid_18709 - squot32(local_tid_18709, 32) * 32) && (squot32(lo", "cal_tid_18709, 32) == 0 && ltid_in_bounds_18753);\n                        \n                        if (thread_active_18757) {\n                            // read operands\n                            {\n                                eta_p_18750 = ((volatile __local int64_t *) local_mem_18716)[sext_i32_i64(local_tid_18709) - sext_i32_i64(skip_threads_18756)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_18757) {\n                                int64_t defunc_0_op_res_18752 = add64(eta_p_18750, eta_p_18751);\n                                \n                                eta_p_18750 = defunc_0_op_res_18752;\n                            }\n                        }\n                        if (sle32(wave_sizze_18711, skip_threads_18756)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_18757) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_18716)[sext_i32_i64(local_tid_18709)] = eta_p_18750;\n                                eta_p_18751 = eta_p_18750;\n                            }\n                        }\n                        if (sle32(wave_sizze_18711, skip_threads_18756)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_18756 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_18758 = squot32(local_tid_18709, 32) == 0 || !ltid_in_bounds_18753;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_18758) {\n                        eta_p_18747 = eta_p_18746;\n                        eta_p_18", "746 = ((__local int64_t *) local_mem_18716)[sext_i32_i64(squot32(local_tid_18709, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_18758) {\n                        int64_t defunc_0_op_res_18748 = add64(eta_p_18746, eta_p_18747);\n                        \n                        eta_p_18746 = defunc_0_op_res_18748;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_18758) {\n                        ((__local int64_t *) local_mem_18716)[sext_i32_i64(local_tid_18709)] = eta_p_18746;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_18709, 32) == 0 && ltid_in_bounds_18753) {\n                    ((__local int64_t *) local_mem_18716)[sext_i32_i64(local_tid_18709)] = eta_p_18747;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_18709 == 0) {\n                acc_18749 = ((__local int64_t *) local_mem_18716)[segscan_tblock_sizze_16177 - (int64_t) 1];\n            } else {\n                acc_18749 = ((__local int64_t *) local_mem_18716)[sext_i32_i64(local_tid_18709) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_18759 = (int64_t) 0;\n        block_new_sgm_18760 = sgm_idx_18728 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_18760 && local_tid_18709 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_18684)[dynamic_id_18726] = acc_18749;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_18660)[dynamic_id_18726] = (int8_t) 2;\n                acc_18749 = (int64_t) 0;\n            }\n            if (!block_new_",
                                    "sgm_18760 && slt32(local_tid_18709, wave_sizze_18711)) {\n                if (local_tid_18709 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_18682)[dynamic_id_18726] = acc_18749;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_18660)[dynamic_id_18726] = (int8_t) 1;\n                    \n                    int8_t tmp_18761 = ((volatile __global int8_t *) status_flags_mem_18660)[dynamic_id_18726 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_18716)[(int64_t) 0] = tmp_18761;\n                }\n                mem_fence_local();\n                \n                int8_t status_18762 = ((__local int8_t *) local_mem_18716)[(int64_t) 0];\n                \n                if (status_18762 == (int8_t) 2) {\n                    if (local_tid_18709 == 0) {\n                        prefix_18759 = ((volatile __global int64_t *) incprefixes_mem_18684)[dynamic_id_18726 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_18763 = sext_i64_i32(dynamic_id_18726 - sext_i32_i64(wave_sizze_18711));\n                    \n                    while (slt32(wave_sizze_18711 * -1, readOffset_18763)) {\n                        int32_t read_i_18764 = readOffset_18763 + local_tid_18709;\n                        int64_t aggr_18765 = (int64_t) 0;\n                        int8_t flag_18766 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_18764)) {\n                            flag_18766 = ((volatile __global int8_t *) status_flags_mem_18660)[sext_i32_i64(read_i_18764)];\n                            if (flag_18766 == (int8_t) 2) {\n                                aggr_18765 = ((volatile __global int64_t *) incprefixes_mem_18684)[sext_i32_i64(read_i_18764)];\n                            } else if (flag_18766 == (int8_t) 1) {\n                                aggr_18765 = ((volatile __global int64_t *) a", "ggregates_mem_18682)[sext_i32_i64(read_i_18764)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_18716)[(int64_t) 4 + sext_i32_i64(local_tid_18709)] = aggr_18765;\n                        ((__local int8_t *) local_mem_18716)[sext_i32_i64(local_tid_18709)] = flag_18766;\n                        flag_18766 = ((__local int8_t *) local_mem_18716)[sext_i32_i64(wave_sizze_18711) - (int64_t) 1];\n                        if (slt8(flag_18766, (int8_t) 2)) {\n                            int8_t flg_x_18770;\n                            int8_t flg_y_18771;\n                            int64_t eta_p_18767;\n                            int64_t eta_p_18768;\n                            int32_t skip_threads_18772;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_18771 = ((volatile __local int8_t *) local_mem_18716)[sext_i32_i64(local_tid_18709)];\n                                eta_p_18768 = ((volatile __local int64_t *) local_mem_18716)[(int64_t) 4 + sext_i32_i64(local_tid_18709)];\n                                if ((local_tid_18709 - squot32(local_tid_18709, 32) * 32) == 0) {\n                                    eta_p_18767 = eta_p_18768;\n                                    flg_x_18770 = flg_y_18771;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_18772 = 1;\n                                while (slt32(skip_threads_18772, 32)) {\n                                    if (sle32(skip_threads_18772, local_tid_18709 - squot32(local_tid_18709, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_18770 = ((volatile __local int8_t *) local_mem_18716)[sext_i3", "2_i64(local_tid_18709) - sext_i32_i64(skip_threads_18772)];\n                                            eta_p_18767 = ((volatile __local int64_t *) local_mem_18716)[(int64_t) 4 + (sext_i32_i64(local_tid_18709) - sext_i32_i64(skip_threads_18772))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_18771 == (int8_t) 2 || flg_y_18771 == (int8_t) 0) {\n                                                flg_x_18770 = flg_y_18771;\n                                                eta_p_18767 = eta_p_18768;\n                                            } else {\n                                                int64_t defunc_0_op_res_18769 = add64(eta_p_18767, eta_p_18768);\n                                                \n                                                eta_p_18767 = defunc_0_op_res_18769;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_18716)[sext_i32_i64(local_tid_18709)] = flg_x_18770;\n                                            flg_y_18771 = flg_x_18770;\n                                            ((volatile __local int64_t *) local_mem_18716)[(int64_t) 4 + sext_i32_i64(local_tid_18709)] = eta_p_18767;\n                                            eta_p_18768 = eta_p_18767;\n                                        }\n                                    }\n                                    skip_threads_18772 *= 2;\n                                }\n                            }\n                        }\n                        flag_18766 = ((__local int8_t *) local_mem_18716)[sext_i32_i64(wave_sizze_18711) - (int64_t) 1];\n                        aggr_18765 = ((__local int64_t *) local_mem_18716)[(int64_t)",
                                    " 4 + (sext_i32_i64(wave_sizze_18711) - (int64_t) 1)];\n                        if (flag_18766 == (int8_t) 2) {\n                            readOffset_18763 = wave_sizze_18711 * -1;\n                        } else if (flag_18766 == (int8_t) 1) {\n                            readOffset_18763 -= wave_sizze_18711;\n                        }\n                        if (slt8((int8_t) 0, flag_18766)) {\n                            int64_t eta_p_18773 = aggr_18765;\n                            int64_t eta_p_18774 = prefix_18759;\n                            int64_t defunc_0_op_res_18775 = add64(eta_p_18773, eta_p_18774);\n                            \n                            prefix_18759 = defunc_0_op_res_18775;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_18709 == 0) {\n                    if (boundary_18729 == sext_i64_i32(segscan_tblock_sizze_16177 * chunk_sizze_18657)) {\n                        int64_t eta_p_18776 = prefix_18759;\n                        int64_t eta_p_18777 = acc_18749;\n                        int64_t defunc_0_op_res_18778 = add64(eta_p_18776, eta_p_18777);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_18684)[dynamic_id_18726] = defunc_0_op_res_18778;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_18660)[dynamic_id_18726] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_18716)[(int64_t) 4] = prefix_18759;\n                    acc_18749 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_18726 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_18759 = ((__local int64_t *) local_mem_18716)[(int64_t) 4];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_18779;\n            in", "t64_t eta_p_18780;\n            int64_t eta_p_18782 = prefix_18759;\n            int64_t eta_p_18783 = acc_18749;\n            \n            if (slt32(local_tid_18709 * chunk_sizze_32b_18713, boundary_18729) && !block_new_sgm_18760) {\n                int64_t defunc_0_op_res_18784 = add64(eta_p_18782, eta_p_18783);\n                \n                eta_p_18779 = defunc_0_op_res_18784;\n            } else {\n                eta_p_18779 = acc_18749;\n            }\n            \n            int32_t stopping_point_18785 = segsizze_compact_18730 - srem32(local_tid_18709 * chunk_sizze_32b_18713 - 1 + segsizze_compact_18730 - boundary_18729, segsizze_compact_18730);\n            \n            for (int64_t i_18786 = 0; i_18786 < chunk_sizze_18657; i_18786++) {\n                if (slt32(sext_i64_i32(i_18786), stopping_point_18785 - 1)) {\n                    eta_p_18780 = private_mem_18731[i_18786];\n                    \n                    int64_t defunc_0_op_res_18781 = add64(eta_p_18779, eta_p_18780);\n                    \n                    private_mem_18731[i_18786] = defunc_0_op_res_18781;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_18787 = 0; i_18787 < chunk_sizze_18657; i_18787++) {\n                int64_t sharedIdx_18788 = sext_i32_i64(local_tid_18709) * chunk_sizze_18657 + i_18787;\n                int64_t tmp_18789 = private_mem_18731[i_18787];\n                \n                ((__local int64_t *) local_mem_18716)[sharedIdx_18788] = tmp_18789;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_18790 = 0; i_18790 < chunk_sizze_18657; i_18790++) {\n                int64_t flat_idx_18791 = thd_offset_18733 + i_18790 * segscan_tblock_sizze_16177;\n                int64_t slice_18792 = n_11606;\n                int64_t gtid_16181 = flat_idx_18791;\n                int64_t remnant_18793 = flat_idx_18791 - gtid_16181;\n                \n      ", "          if (slt64(flat_idx_18791, n_11606)) {\n                    int64_t tmp_18794 = ((__local int64_t *) local_mem_18716)[flat_idx_18791 - block_offset_18727];\n                    \n                    ((__global int64_t *) mem_18423)[gtid_16181] = tmp_18794;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_16177\n    #undef chunk_sizze_18657\n}\nFUTHARK_KERNEL_SIZED(isolate_core_points_6871zisegmap_16250_dim1, 1, 1)\nvoid isolate_core_points_6871zisegmap_16250(__global int *global_failure, int64_t n_13951, __global unsigned char *mem_18423, __global unsigned char *mem_18425, __global unsigned char *mem_18431)\n{\n    #define segmap_tblock_sizze_16246 (isolate_core_points_6871zisegmap_16250zisegmap_tblock_sizze_16246)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18797;\n    int32_t tblock_sizze_18800;\n    int32_t wave_sizze_18799;\n    int32_t block_id_18798;\n    int32_t global_tid_18796;\n    int64_t phys_tid_16250;\n    int64_t global_tid_18801;\n    int64_t slice_18802;\n    int64_t gtid_16249;\n    int64_t remnant_18803;\n    \n    local_tid_18797 = get_local_id(0);\n    tblock_sizze_18800 = get_local_size(0);\n    wave_sizze_18799 = LOCKSTEP_WIDTH;\n    block_id_18798 = get_tblock_id(0);\n    global_tid_18796 = block_id_18798 * tblock_sizze_18800 + local_tid_18797;\n    phys_tid_16250 = sext_i32_i64(global_tid_18796);\n    global_tid_18801 = sext_i32_i64(block_id_18798) * segmap_tblock_sizze_16246 + sext_i32_i64(local_tid_18797);\n    slice_18802 = n_13951;\n    gtid_16249 = global_tid_18801;\n    remnant_18803 = global_tid_18801 - gtid_16249;\n    if (slt64(gtid_16249, n_13951)) {\n        int64_t eta_p_16251;\n        bool cond_16253;\n        int64_t lifted_lambda_res_16254;\n        \n        eta_p_16251 = ((__global int64_t *) mem_18425)[gtid_16249];\n        cond_16253 = eta_p_16251 == (int64_t) 1;\n        if (cond_16253) {\n            int64_t eta_p_16252;",
                                    "\n            int64_t lifted_lambda_res_t_res_16255;\n            \n            eta_p_16252 = ((__global int64_t *) mem_18423)[gtid_16249];\n            lifted_lambda_res_t_res_16255 = sub64(eta_p_16252, (int64_t) 1);\n            lifted_lambda_res_16254 = lifted_lambda_res_t_res_16255;\n        } else {\n            lifted_lambda_res_16254 = (int64_t) -1;\n        }\n        ((__global int64_t *) mem_18431)[gtid_16249] = lifted_lambda_res_16254;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_16246\n}\nFUTHARK_KERNEL_SIZED(isolate_core_points_6871zisegmap_16261_dim1, 1, 1)\nvoid isolate_core_points_6871zisegmap_16261(__global int *global_failure, int64_t n_13951, int64_t dim_13952, int64_t m_15698, int64_t num_tblocks_16267, int32_t virt_num_tblocks_18805, __global unsigned char *dat_mem_18419, __global unsigned char *mem_18428, __global unsigned char *mem_18431)\n{\n    #define segmap_tblock_sizze_16265 (isolate_core_points_6871zisegmap_16261zisegmap_tblock_sizze_16265)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18807;\n    int32_t tblock_sizze_18810;\n    int32_t wave_sizze_18809;\n    int32_t block_id_18808;\n    int32_t global_tid_18806;\n    int64_t phys_tid_16261;\n    int32_t phys_tblock_id_18811;\n    int32_t iterations_18812;\n    \n    local_tid_18807 = get_local_id(0);\n    tblock_sizze_18810 = get_local_size(0);\n    wave_sizze_18809 = LOCKSTEP_WIDTH;\n    block_id_18808 = get_tblock_id(0);\n    global_tid_18806 = block_id_18808 * tblock_sizze_18810 + local_tid_18807;\n    phys_tid_16261 = sext_i32_i64(global_tid_18806);\n    phys_tblock_id_18811 = get_tblock_id(0);\n    iterations_18812 = sdiv_up32(virt_num_tblocks_18805 - phys_tblock_id_18811, sext_i64_i32(num_tblocks_16267));\n    for (int32_t i_18813 = 0; i_18813 < iterations_18812; i_18813++) {\n        int32_t virt_tblock_id_18814;\n        int64_t global_tid_18815;\n        int64_t slice_18816;\n        int64_t slice_18817;\n        int64_t write_i_16257;\n        int64_t remnant_18818;", "\n        int64_t val_i_16258;\n        int64_t remnant_18819;\n        \n        virt_tblock_id_18814 = phys_tblock_id_18811 + i_18813 * sext_i64_i32(num_tblocks_16267);\n        global_tid_18815 = sext_i32_i64(virt_tblock_id_18814) * segmap_tblock_sizze_16265 + sext_i32_i64(local_tid_18807);\n        slice_18816 = dim_13952;\n        slice_18817 = n_13951 * slice_18816;\n        write_i_16257 = squot64(global_tid_18815, slice_18816);\n        remnant_18818 = global_tid_18815 - write_i_16257 * slice_18816;\n        val_i_16258 = remnant_18818;\n        remnant_18819 = remnant_18818 - val_i_16258;\n        if (slt64(write_i_16257, n_13951) && slt64(val_i_16258, dim_13952)) {\n            double scatter_tmp_elem_16259;\n            int64_t scatter_tmp_i_16260;\n            \n            scatter_tmp_elem_16259 = ((__global double *) dat_mem_18419)[write_i_16257 * dim_13952 + val_i_16258];\n            scatter_tmp_i_16260 = ((__global int64_t *) mem_18431)[write_i_16257];\n            if ((sle64((int64_t) 0, scatter_tmp_i_16260) && slt64(scatter_tmp_i_16260, m_15698)) && (sle64((int64_t) 0, val_i_16258) && slt64(val_i_16258, dim_13952))) {\n                ((__global double *) mem_18428)[scatter_tmp_i_16260 * dim_13952 + val_i_16258] = scatter_tmp_elem_16259;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_16265\n}\nFUTHARK_KERNEL_SIZED(isolate_core_points_6871zisegscan_16229_dim1, 1, 1)\nvoid isolate_core_points_6871zisegscan_16229(__global int *global_failure, int64_t n_13951, int64_t num_tblocks_16226, int64_t num_virt_blocks_18658, int64_t num_virt_threads_18659, __global unsigned char *isCore_mem_18420, __global unsigned char *mem_18423, __global unsigned char *mem_18425, __global unsigned char *status_flags_mem_18660, __global unsigned char *aggregates_mem_18682, __global unsigned char *incprefixes_mem_18684, __global unsigned char *global_dynid_mem_18686)\n{\n    #define segscan_tblock", "_sizze_16224 (isolate_core_points_6871zisegscan_16229zisegscan_tblock_sizze_16224)\n    #define chunk_sizze_18657 (isolate_core_points_6871zisegscan_16229zichunk_sizze_18657)\n    \n    volatile __local unsigned char *local_mem_18716_backing_0 = &shared_mem[0];\n    const int64_t local_mem_18716_backing_0_offset = 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_16224), chunk_sizze_18657 * segscan_tblock_sizze_16224 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_16224), chunk_sizze_18657 * segscan_tblock_sizze_16224 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18709;\n    int32_t tblock_sizze_18712;\n    int32_t wave_sizze_18711;\n    int32_t block_id_18710;\n    int32_t global_tid_18708;\n    int64_t phys_tid_16229;\n    int32_t chunk_sizze_32b_18713;\n    int64_t byte_offsets_18714;\n    int64_t warp_byte_offset_18715;\n    __local unsigned char *local_mem_18716;\n    int64_t trans_arr_len_18717;\n    int64_t phys_block_id_18723;\n    int64_t virtloop_bound_18724;\n    \n    local_tid_18709 = get_local_id(0);\n    tblock_sizze_18712 = get_local_size(0);\n    wave_sizze_18711 = LOCKSTEP_WIDTH;\n    block_id_18710 = get_tblock_id(0);\n    global_tid_18708 = block_id_18710 * tblock_sizze_18712 + local_tid_18709;\n    phys_tid_16229 = sext_i32_i64(global_tid_18708);\n    chunk_sizze_32b_18713 = sext_i64_i32(chunk_sizze_18657);\n    byte_offsets_18714 = segscan_tblock_sizze_16224 * (int64_t) 8;\n    warp_byte_offset_18715 = (int64_t) 288;\n    // Allocate reusable shared memory\n    { }\n    local_mem_18716 = (__local unsigned char *) local_mem_18716_backing_0;\n    trans_arr_len_18717 = chunk_sizze_18657 * segscan_tblock_sizze_16224;\n    phys_block_id_18723 = get_tblock_id(0);\n    virtloop_bound_18724 = sdiv_up64(num_virt_blocks_18658 - phys_block_id_18723, num_tblocks_16226);\n    for (int64_t virtloop_i_18725 = 0; virtloop_i_18725 < virtlo",
                                    "op_bound_18724; virtloop_i_18725++) {\n        int64_t dynamic_id_18726;\n        int64_t block_offset_18727;\n        int64_t sgm_idx_18728;\n        int32_t boundary_18729;\n        int32_t segsizze_compact_18730;\n        int64_t private_mem_18731[chunk_sizze_18657];\n        int64_t thd_offset_18733;\n        int64_t acc_18749;\n        int64_t prefix_18759;\n        bool block_new_sgm_18760;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_18709 == 0) {\n                dynamic_id_18726 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_18686)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_18716)[(int64_t) 0] = dynamic_id_18726;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_18726 == num_virt_blocks_18658 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_18686)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_18726 = ((__local int32_t *) local_mem_18716)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_18727 = dynamic_id_18726 * chunk_sizze_18657 * segscan_tblock_sizze_16224;\n        sgm_idx_18728 = smod64(block_offset_18727, n_13951);\n        boundary_18729 = sext_i64_i32(smin64(chunk_sizze_18657 * segscan_tblock_sizze_16224, n_13951 - sgm_idx_18728));\n        segsizze_compact_18730 = sext_i64_i32(smin64(chunk_sizze_18657 * segscan_tblock_sizze_16224, n_13951));\n        thd_offset_18733 = block_offset_18727 + sext_i32_i64(local_tid_18709);\n        // Load and map\n        {\n            for (int64_t i_18734 = 0; i_18734 < chunk_sizze_18657; i_18734++) {\n                int64_t virt_tid_18735 = thd_offset_18733 + i_18734 * segscan_tblock_sizze_16224;\n        ", "        int64_t slice_18736 = n_13951;\n                int64_t gtid_16228 = virt_tid_18735;\n                int64_t remnant_18737 = virt_tid_18735 - gtid_16228;\n                \n                if (slt64(virt_tid_18735, n_13951)) {\n                    bool eta_p_16086 = ((__global bool *) isCore_mem_18420)[gtid_16228];\n                    int64_t defunc_0_f_res_16087 = btoi_bool_i64(eta_p_16086);\n                    \n                    ((__global int64_t *) mem_18425)[gtid_16228] = defunc_0_f_res_16087;\n                    private_mem_18731[i_18734] = defunc_0_f_res_16087;\n                } else {\n                    private_mem_18731[i_18734] = (int64_t) 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_18738 = 0; i_18738 < chunk_sizze_18657; i_18738++) {\n                int64_t sharedIdx_18739 = sext_i32_i64(local_tid_18709) + i_18738 * segscan_tblock_sizze_16224;\n                int64_t tmp_18740 = private_mem_18731[i_18738];\n                \n                ((__local int64_t *) local_mem_18716)[sharedIdx_18739] = tmp_18740;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_18741 = 0; i_18741 < chunk_sizze_18657; i_18741++) {\n                int64_t sharedIdx_18742 = sext_i32_i64(local_tid_18709) * chunk_sizze_18657 + i_18741;\n                int64_t tmp_18743 = ((__local int64_t *) local_mem_18716)[sharedIdx_18742];\n                \n                private_mem_18731[i_18741] = tmp_18743;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_18744 = 0; i_18744 < chunk_sizze_18657 - (int64_t) 1; i_18744++) {\n                int64_t eta_p_15685;\n                int64_t eta_p_15686;\n                \n                eta_p_15685 = private_mem_18731[i_18744];\n                eta_p_15686 = private_mem_18731[i_18744 + (int64_t) 1];\n                \n             ", "   int64_t defunc_0_op_res_15687 = add64(eta_p_15685, eta_p_15686);\n                \n                private_mem_18731[i_18744 + (int64_t) 1] = defunc_0_op_res_15687;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_18745 = private_mem_18731[chunk_sizze_18657 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_18716)[sext_i32_i64(local_tid_18709)] = tmp_18745;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_18746;\n            int64_t eta_p_18747;\n            int64_t eta_p_18750;\n            int64_t eta_p_18751;\n            bool ltid_in_bounds_18753 = slt64(sext_i32_i64(local_tid_18709), num_virt_threads_18659);\n            int32_t skip_threads_18754;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_18753) {\n                    eta_p_18747 = ((volatile __local int64_t *) local_mem_18716)[sext_i32_i64(local_tid_18709)];\n                    if ((local_tid_18709 - squot32(local_tid_18709, 32) * 32) == 0) {\n                        eta_p_18746 = eta_p_18747;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_18754 = 1;\n                while (slt32(skip_threads_18754, 32)) {\n                    bool thread_active_18755 = sle32(skip_threads_18754, local_tid_18709 - squot32(local_tid_18709, 32) * 32) && ltid_in_bounds_18753;\n                    \n                    if (thread_active_18755) {\n                        // read operands\n                        {\n                            eta_p_18746 = ((volatile __local int64_t *) local_mem_18716)[sext_i32_i64(local_tid_18709) - sext_i32_i64(skip_threads_18754)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_187",
                                    "55) {\n                            int64_t defunc_0_op_res_18748 = add64(eta_p_18746, eta_p_18747);\n                            \n                            eta_p_18746 = defunc_0_op_res_18748;\n                        }\n                    }\n                    if (sle32(wave_sizze_18711, skip_threads_18754)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_18755) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_18716)[sext_i32_i64(local_tid_18709)] = eta_p_18746;\n                            eta_p_18747 = eta_p_18746;\n                        }\n                    }\n                    if (sle32(wave_sizze_18711, skip_threads_18754)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_18754 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_18709 - squot32(local_tid_18709, 32) * 32) == 31 && ltid_in_bounds_18753) {\n                    ((volatile __local int64_t *) local_mem_18716)[sext_i32_i64(squot32(local_tid_18709, 32))] = eta_p_18746;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_18756;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_18709, 32) == 0 && ltid_in_bounds_18753) {\n                        eta_p_18751 = ((volatile __local int64_t *) local_mem_18716)[sext_i32_i64(local_tid_18709)];\n                        if ((local_tid_18709 - squot32(local_tid_18709, 32) * 32) == 0) {\n                            eta_p_18750 = eta_p_18751;\n                        }\n        ", "            }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_18756 = 1;\n                    while (slt32(skip_threads_18756, 32)) {\n                        bool thread_active_18757 = sle32(skip_threads_18756, local_tid_18709 - squot32(local_tid_18709, 32) * 32) && (squot32(local_tid_18709, 32) == 0 && ltid_in_bounds_18753);\n                        \n                        if (thread_active_18757) {\n                            // read operands\n                            {\n                                eta_p_18750 = ((volatile __local int64_t *) local_mem_18716)[sext_i32_i64(local_tid_18709) - sext_i32_i64(skip_threads_18756)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_18757) {\n                                int64_t defunc_0_op_res_18752 = add64(eta_p_18750, eta_p_18751);\n                                \n                                eta_p_18750 = defunc_0_op_res_18752;\n                            }\n                        }\n                        if (sle32(wave_sizze_18711, skip_threads_18756)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_18757) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_18716)[sext_i32_i64(local_tid_18709)] = eta_p_18750;\n                                eta_p_18751 = eta_p_18750;\n                            }\n                        }\n                        if (sle32(wave_sizze_18711, skip_threads_18756)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_18756 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            ", "\n            bool no_carry_in_18758 = squot32(local_tid_18709, 32) == 0 || !ltid_in_bounds_18753;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_18758) {\n                        eta_p_18747 = eta_p_18746;\n                        eta_p_18746 = ((__local int64_t *) local_mem_18716)[sext_i32_i64(squot32(local_tid_18709, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_18758) {\n                        int64_t defunc_0_op_res_18748 = add64(eta_p_18746, eta_p_18747);\n                        \n                        eta_p_18746 = defunc_0_op_res_18748;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_18758) {\n                        ((__local int64_t *) local_mem_18716)[sext_i32_i64(local_tid_18709)] = eta_p_18746;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_18709, 32) == 0 && ltid_in_bounds_18753) {\n                    ((__local int64_t *) local_mem_18716)[sext_i32_i64(local_tid_18709)] = eta_p_18747;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_18709 == 0) {\n                acc_18749 = ((__local int64_t *) local_mem_18716)[segscan_tblock_sizze_16224 - (int64_t) 1];\n            } else {\n                acc_18749 = ((__local int64_t *) local_mem_18716)[sext_i32_i64(local_tid_18709) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_18759 = (int64_t) 0;\n        block_new_sgm_18760 = sgm_idx_18728 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_",
                                    "new_sgm_18760 && local_tid_18709 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_18684)[dynamic_id_18726] = acc_18749;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_18660)[dynamic_id_18726] = (int8_t) 2;\n                acc_18749 = (int64_t) 0;\n            }\n            if (!block_new_sgm_18760 && slt32(local_tid_18709, wave_sizze_18711)) {\n                if (local_tid_18709 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_18682)[dynamic_id_18726] = acc_18749;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_18660)[dynamic_id_18726] = (int8_t) 1;\n                    \n                    int8_t tmp_18761 = ((volatile __global int8_t *) status_flags_mem_18660)[dynamic_id_18726 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_18716)[(int64_t) 0] = tmp_18761;\n                }\n                mem_fence_local();\n                \n                int8_t status_18762 = ((__local int8_t *) local_mem_18716)[(int64_t) 0];\n                \n                if (status_18762 == (int8_t) 2) {\n                    if (local_tid_18709 == 0) {\n                        prefix_18759 = ((volatile __global int64_t *) incprefixes_mem_18684)[dynamic_id_18726 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_18763 = sext_i64_i32(dynamic_id_18726 - sext_i32_i64(wave_sizze_18711));\n                    \n                    while (slt32(wave_sizze_18711 * -1, readOffset_18763)) {\n                        int32_t read_i_18764 = readOffset_18763 + local_tid_18709;\n                        int64_t aggr_18765 = (int64_t) 0;\n                        int8_t flag_18766 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_18764)) {\n                            flag_18766 = ((volatile __global int8_t *) status_flags_mem_18660)", "[sext_i32_i64(read_i_18764)];\n                            if (flag_18766 == (int8_t) 2) {\n                                aggr_18765 = ((volatile __global int64_t *) incprefixes_mem_18684)[sext_i32_i64(read_i_18764)];\n                            } else if (flag_18766 == (int8_t) 1) {\n                                aggr_18765 = ((volatile __global int64_t *) aggregates_mem_18682)[sext_i32_i64(read_i_18764)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_18716)[(int64_t) 4 + sext_i32_i64(local_tid_18709)] = aggr_18765;\n                        ((__local int8_t *) local_mem_18716)[sext_i32_i64(local_tid_18709)] = flag_18766;\n                        flag_18766 = ((__local int8_t *) local_mem_18716)[sext_i32_i64(wave_sizze_18711) - (int64_t) 1];\n                        if (slt8(flag_18766, (int8_t) 2)) {\n                            int8_t flg_x_18770;\n                            int8_t flg_y_18771;\n                            int64_t eta_p_18767;\n                            int64_t eta_p_18768;\n                            int32_t skip_threads_18772;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_18771 = ((volatile __local int8_t *) local_mem_18716)[sext_i32_i64(local_tid_18709)];\n                                eta_p_18768 = ((volatile __local int64_t *) local_mem_18716)[(int64_t) 4 + sext_i32_i64(local_tid_18709)];\n                                if ((local_tid_18709 - squot32(local_tid_18709, 32) * 32) == 0) {\n                                    eta_p_18767 = eta_p_18768;\n                                    flg_x_18770 = flg_y_18771;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_18772 = 1;\n                                while (slt", "32(skip_threads_18772, 32)) {\n                                    if (sle32(skip_threads_18772, local_tid_18709 - squot32(local_tid_18709, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_18770 = ((volatile __local int8_t *) local_mem_18716)[sext_i32_i64(local_tid_18709) - sext_i32_i64(skip_threads_18772)];\n                                            eta_p_18767 = ((volatile __local int64_t *) local_mem_18716)[(int64_t) 4 + (sext_i32_i64(local_tid_18709) - sext_i32_i64(skip_threads_18772))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_18771 == (int8_t) 2 || flg_y_18771 == (int8_t) 0) {\n                                                flg_x_18770 = flg_y_18771;\n                                                eta_p_18767 = eta_p_18768;\n                                            } else {\n                                                int64_t defunc_0_op_res_18769 = add64(eta_p_18767, eta_p_18768);\n                                                \n                                                eta_p_18767 = defunc_0_op_res_18769;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_18716)[sext_i32_i64(local_tid_18709)] = flg_x_18770;\n                                            flg_y_18771 = flg_x_18770;\n                                            ((volatile __local int64_t *) local_mem_18716)[(int64_t) 4 + sext_i32_i64(local_tid_18709)] = eta_p_18767;\n                                            eta_p_18768 = eta_p_18767;\n                                        }\n                                ",
                                    "    }\n                                    skip_threads_18772 *= 2;\n                                }\n                            }\n                        }\n                        flag_18766 = ((__local int8_t *) local_mem_18716)[sext_i32_i64(wave_sizze_18711) - (int64_t) 1];\n                        aggr_18765 = ((__local int64_t *) local_mem_18716)[(int64_t) 4 + (sext_i32_i64(wave_sizze_18711) - (int64_t) 1)];\n                        if (flag_18766 == (int8_t) 2) {\n                            readOffset_18763 = wave_sizze_18711 * -1;\n                        } else if (flag_18766 == (int8_t) 1) {\n                            readOffset_18763 -= wave_sizze_18711;\n                        }\n                        if (slt8((int8_t) 0, flag_18766)) {\n                            int64_t eta_p_18773 = aggr_18765;\n                            int64_t eta_p_18774 = prefix_18759;\n                            int64_t defunc_0_op_res_18775 = add64(eta_p_18773, eta_p_18774);\n                            \n                            prefix_18759 = defunc_0_op_res_18775;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_18709 == 0) {\n                    if (boundary_18729 == sext_i64_i32(segscan_tblock_sizze_16224 * chunk_sizze_18657)) {\n                        int64_t eta_p_18776 = prefix_18759;\n                        int64_t eta_p_18777 = acc_18749;\n                        int64_t defunc_0_op_res_18778 = add64(eta_p_18776, eta_p_18777);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_18684)[dynamic_id_18726] = defunc_0_op_res_18778;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_18660)[dynamic_id_18726] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_18716)[(int64_t) 4] = prefix_18759;\n                    acc_18749 = (int64_t) 0;\n          ", "      }\n            }\n            if (!(dynamic_id_18726 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_18759 = ((__local int64_t *) local_mem_18716)[(int64_t) 4];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_18779;\n            int64_t eta_p_18780;\n            int64_t eta_p_18782 = prefix_18759;\n            int64_t eta_p_18783 = acc_18749;\n            \n            if (slt32(local_tid_18709 * chunk_sizze_32b_18713, boundary_18729) && !block_new_sgm_18760) {\n                int64_t defunc_0_op_res_18784 = add64(eta_p_18782, eta_p_18783);\n                \n                eta_p_18779 = defunc_0_op_res_18784;\n            } else {\n                eta_p_18779 = acc_18749;\n            }\n            \n            int32_t stopping_point_18785 = segsizze_compact_18730 - srem32(local_tid_18709 * chunk_sizze_32b_18713 - 1 + segsizze_compact_18730 - boundary_18729, segsizze_compact_18730);\n            \n            for (int64_t i_18786 = 0; i_18786 < chunk_sizze_18657; i_18786++) {\n                if (slt32(sext_i64_i32(i_18786), stopping_point_18785 - 1)) {\n                    eta_p_18780 = private_mem_18731[i_18786];\n                    \n                    int64_t defunc_0_op_res_18781 = add64(eta_p_18779, eta_p_18780);\n                    \n                    private_mem_18731[i_18786] = defunc_0_op_res_18781;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_18787 = 0; i_18787 < chunk_sizze_18657; i_18787++) {\n                int64_t sharedIdx_18788 = sext_i32_i64(local_tid_18709) * chunk_sizze_18657 + i_18787;\n                int64_t tmp_18789 = private_mem_18731[i_18787];\n                \n                ((__local int64_t *) local_mem_18716)[sharedIdx_18788] = tmp_18789;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        ", "    for (int64_t i_18790 = 0; i_18790 < chunk_sizze_18657; i_18790++) {\n                int64_t flat_idx_18791 = thd_offset_18733 + i_18790 * segscan_tblock_sizze_16224;\n                int64_t slice_18792 = n_13951;\n                int64_t gtid_16228 = flat_idx_18791;\n                int64_t remnant_18793 = flat_idx_18791 - gtid_16228;\n                \n                if (slt64(flat_idx_18791, n_13951)) {\n                    int64_t tmp_18794 = ((__local int64_t *) local_mem_18716)[flat_idx_18791 - block_offset_18727];\n                    \n                    ((__global int64_t *) mem_18423)[gtid_16228] = tmp_18794;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_16224\n    #undef chunk_sizze_18657\n}\n", NULL};
// Start of gpu_prototypes.h

// Constants used for transpositions.  In principle these should be configurable.
#define TR_BLOCK_DIM 16
#define TR_TILE_DIM (TR_BLOCK_DIM*2)
#define TR_ELEMS_PER_THREAD 8

// Config stuff included in every GPU backend.
struct gpu_config {
  size_t default_block_size;
  size_t default_grid_size;
  size_t default_tile_size;
  size_t default_reg_tile_size;
  size_t default_cache;
  size_t default_shared_memory;
  size_t default_registers;
  size_t default_threshold;

  int default_block_size_changed;
  int default_grid_size_changed;
  int default_tile_size_changed;
};

// The following are dummy sizes that mean the concrete defaults
// will be set during initialisation via hardware-inspection-based
// heuristics.
struct gpu_config gpu_config_initial = {
  0
};

// Must be defined by the user.
static int gpu_macros(struct futhark_context *ctx, char*** names, int64_t** values);

static void gpu_init_log(struct futhark_context *ctx);
struct builtin_kernels* init_builtin_kernels(struct futhark_context* ctx);
void free_builtin_kernels(struct futhark_context* ctx, struct builtin_kernels* kernels);
static int gpu_free_all(struct futhark_context *ctx);

// End of gpu_prototypes.h

// Start of backends/cuda.h.

// Forward declarations.
// Invoked by setup_opencl() after the platform and device has been
// found, but before the program is loaded.  Its intended use is to
// tune constants based on the selected platform and device.
static void set_tuning_params(struct futhark_context* ctx);
static char* get_failure_msg(int failure_idx, int64_t args[]);

#define CUDA_SUCCEED_FATAL(x) cuda_api_succeed_fatal(x, #x, __FILE__, __LINE__)
#define CUDA_SUCCEED_NONFATAL(x) cuda_api_succeed_nonfatal(x, #x, __FILE__, __LINE__)
#define NVRTC_SUCCEED_FATAL(x) nvrtc_api_succeed_fatal(x, #x, __FILE__, __LINE__)
#define NVRTC_SUCCEED_NONFATAL(x) nvrtc_api_succeed_nonfatal(x, #x, __FILE__, __LINE__)
// Take care not to override an existing error.
#define CUDA_SUCCEED_OR_RETURN(e) {             \
    char *serror = CUDA_SUCCEED_NONFATAL(e);    \
    if (serror) {                               \
      if (!ctx->error) {                        \
        ctx->error = serror;                    \
      } else {                                  \
        free(serror);                           \
      }                                         \
      return bad;                               \
    }                                           \
  }

// CUDA_SUCCEED_OR_RETURN returns the value of the variable 'bad' in
// scope.  By default, it will be this one.  Create a local variable
// of some other type if needed.  This is a bit of a hack, but it
// saves effort in the code generator.
static const int bad = 1;

static inline void cuda_api_succeed_fatal(CUresult res, const char *call,
                                          const char *file, int line) {
  if (res != CUDA_SUCCESS) {
    const char *err_str;
    cuGetErrorString(res, &err_str);
    if (err_str == NULL) { err_str = "Unknown"; }
    futhark_panic(-1, "%s:%d: CUDA call\n  %s\nfailed with error code %d (%s)\n",
                  file, line, call, res, err_str);
  }
}

static char* cuda_api_succeed_nonfatal(CUresult res, const char *call,
                                       const char *file, int line) {
  if (res != CUDA_SUCCESS) {
    const char *err_str;
    cuGetErrorString(res, &err_str);
    if (err_str == NULL) { err_str = "Unknown"; }
    return msgprintf("%s:%d: CUDA call\n  %s\nfailed with error code %d (%s)\n",
                     file, line, call, res, err_str);
  } else {
    return NULL;
  }
}

static inline void nvrtc_api_succeed_fatal(nvrtcResult res, const char *call,
                                           const char *file, int line) {
  if (res != NVRTC_SUCCESS) {
    const char *err_str = nvrtcGetErrorString(res);
    futhark_panic(-1, "%s:%d: NVRTC call\n  %s\nfailed with error code %d (%s)\n",
                  file, line, call, res, err_str);
  }
}

static char* nvrtc_api_succeed_nonfatal(nvrtcResult res, const char *call,
                                        const char *file, int line) {
  if (res != NVRTC_SUCCESS) {
    const char *err_str = nvrtcGetErrorString(res);
    return msgprintf("%s:%d: NVRTC call\n  %s\nfailed with error code %d (%s)\n",
                     file, line, call, res, err_str);
  } else {
    return NULL;
  }
}

struct futhark_context_config {
  int in_use;
  int debugging;
  int profiling;
  int logging;
  char* cache_fname;
  int num_tuning_params;
  int64_t *tuning_params;
  const char** tuning_param_names;
  const char** tuning_param_vars;
  const char** tuning_param_classes;
  // Uniform fields above.

  char* program;
  int num_nvrtc_opts;
  char* *nvrtc_opts;

  char* preferred_device;
  int preferred_device_num;

  int unified_memory;

  char* dump_ptx_to;
  char* load_ptx_from;

  struct gpu_config gpu;
};

static void backend_context_config_setup(struct futhark_context_config *cfg) {
  cfg->num_nvrtc_opts = 0;
  cfg->nvrtc_opts = (char**) malloc(sizeof(char*));
  cfg->nvrtc_opts[0] = NULL;

  cfg->program = strconcat(gpu_program);

  cfg->preferred_device_num = 0;
  cfg->preferred_device = strdup("");

  cfg->dump_ptx_to = NULL;
  cfg->load_ptx_from = NULL;

  cfg->unified_memory = 2;

  cfg->gpu = gpu_config_initial;
  cfg->gpu.default_block_size = 256;
  cfg->gpu.default_tile_size = 32;
  cfg->gpu.default_reg_tile_size = 2;
  cfg->gpu.default_threshold = 32*1024;
}

static void backend_context_config_teardown(struct futhark_context_config* cfg) {
  for (int i = 0; i < cfg->num_nvrtc_opts; i++) {
    free(cfg->nvrtc_opts[i]);
  }
  free(cfg->nvrtc_opts);
  free(cfg->dump_ptx_to);
  free(cfg->load_ptx_from);
  free(cfg->preferred_device);
  free(cfg->program);
}

void futhark_context_config_add_nvrtc_option(struct futhark_context_config *cfg, const char *opt) {
  cfg->nvrtc_opts[cfg->num_nvrtc_opts] = strdup(opt);
  cfg->num_nvrtc_opts++;
  cfg->nvrtc_opts = (char **) realloc(cfg->nvrtc_opts, (cfg->num_nvrtc_opts + 1) * sizeof(char *));
  cfg->nvrtc_opts[cfg->num_nvrtc_opts] = NULL;
}

void futhark_context_config_set_device(struct futhark_context_config *cfg, const char *s) {
  int x = 0;
  if (*s == '#') {
    s++;
    while (isdigit(*s)) {
      x = x * 10 + (*s++)-'0';
    }
    // Skip trailing spaces.
    while (isspace(*s)) {
      s++;
    }
  }
  free(cfg->preferred_device);
  cfg->preferred_device = strdup(s);
  cfg->preferred_device_num = x;
}

const char* futhark_context_config_get_program(struct futhark_context_config *cfg) {
  return cfg->program;
}

void futhark_context_config_set_program(struct futhark_context_config *cfg, const char *s) {
  free(cfg->program);
  cfg->program = strdup(s);
}

void futhark_context_config_dump_ptx_to(struct futhark_context_config *cfg, const char *path) {
  free(cfg->dump_ptx_to);
  cfg->dump_ptx_to = strdup(path);
}

void futhark_context_config_load_ptx_from(struct futhark_context_config *cfg, const char *path) {
  free(cfg->load_ptx_from);
  cfg->load_ptx_from = strdup(path);
}

void futhark_context_config_set_unified_memory(struct futhark_context_config* cfg, int flag) {
  cfg->unified_memory = flag;
}

// A record of something that happened.
struct profiling_record {
  cudaEvent_t *events; // Points to two events.
  const char *name;
};

struct futhark_context {
  struct futhark_context_config* cfg;
  int detail_memory;
  int debugging;
  int profiling;
  int profiling_paused;
  int logging;
  lock_t lock;
  char *error;
  lock_t error_lock;
  FILE *log;
  struct constants *constants;
  struct free_list free_list;
  struct event_list event_list;
  int64_t peak_mem_usage_default;
  int64_t cur_mem_usage_default;
  struct program* program;
  bool program_initialised;
  // Uniform fields above.

  CUdeviceptr global_failure;
  CUdeviceptr global_failure_args;
  struct tuning_params tuning_params;
  // True if a potentially failing kernel has been enqueued.
  int32_t failure_is_an_option;
  int total_runs;
  long int total_runtime;
  int64_t peak_mem_usage_device;
  int64_t cur_mem_usage_device;

  CUdevice dev;
  CUcontext cu_ctx;
  CUmodule module;
  CUstream stream;

  struct free_list gpu_free_list;

  size_t max_thread_block_size;
  size_t max_grid_size;
  size_t max_tile_size;
  size_t max_threshold;
  size_t max_shared_memory;
  size_t max_bespoke;
  size_t max_registers;
  size_t max_cache;

  size_t lockstep_width;

  struct builtin_kernels* kernels;
};

#define CU_DEV_ATTR(x) (CU_DEVICE_ATTRIBUTE_##x)
#define device_query(dev,attrib) _device_query(dev, CU_DEV_ATTR(attrib))
static int _device_query(CUdevice dev, CUdevice_attribute attrib) {
  int val;
  CUDA_SUCCEED_FATAL(cuDeviceGetAttribute(&val, attrib, dev));
  return val;
}

#define CU_FUN_ATTR(x) (CU_FUNC_ATTRIBUTE_##x)
#define function_query(fn,attrib) _function_query(dev, CU_FUN_ATTR(attrib))
static int _function_query(CUfunction dev, CUfunction_attribute attrib) {
  int val;
  CUDA_SUCCEED_FATAL(cuFuncGetAttribute(&val, attrib, dev));
  return val;
}

static int cuda_device_setup(struct futhark_context *ctx) {
  struct futhark_context_config *cfg = ctx->cfg;
  char name[256];
  int count, chosen = -1, best_cc = -1;
  int cc_major_best = 0, cc_minor_best = 0;
  int cc_major = 0, cc_minor = 0;
  CUdevice dev;

  CUDA_SUCCEED_FATAL(cuDeviceGetCount(&count));
  if (count == 0) { return 1; }

  int num_device_matches = 0;

  // XXX: Current device selection policy is to choose the device with the
  // highest compute capability (if no preferred device is set).
  // This should maybe be changed, since greater compute capability is not
  // necessarily an indicator of better performance.
  for (int i = 0; i < count; i++) {
    CUDA_SUCCEED_FATAL(cuDeviceGet(&dev, i));

    cc_major = device_query(dev, COMPUTE_CAPABILITY_MAJOR);
    cc_minor = device_query(dev, COMPUTE_CAPABILITY_MINOR);

    CUDA_SUCCEED_FATAL(cuDeviceGetName(name, sizeof(name) - 1, dev));
    name[sizeof(name) - 1] = 0;

    if (cfg->logging) {
      fprintf(ctx->log, "Device #%d: name=\"%s\", compute capability=%d.%d\n",
              i, name, cc_major, cc_minor);
    }

    if (device_query(dev, COMPUTE_MODE) == CU_COMPUTEMODE_PROHIBITED) {
      if (cfg->logging) {
        fprintf(ctx->log, "Device #%d is compute-prohibited, ignoring\n", i);
      }
      continue;
    }

    if (best_cc == -1 || cc_major > cc_major_best ||
        (cc_major == cc_major_best && cc_minor > cc_minor_best)) {
      best_cc = i;
      cc_major_best = cc_major;
      cc_minor_best = cc_minor;
    }

    if (strstr(name, cfg->preferred_device) != NULL &&
        num_device_matches++ == cfg->preferred_device_num) {
      chosen = i;
      break;
    }
  }

  if (chosen == -1) { chosen = best_cc; }
  if (chosen == -1) { return 1; }

  if (cfg->logging) {
    fprintf(ctx->log, "Using device #%d\n", chosen);
  }

  CUDA_SUCCEED_FATAL(cuDeviceGet(&ctx->dev, chosen));
  return 0;
}

static const char *cuda_nvrtc_get_arch(CUdevice dev) {
  static struct {
    int major;
    int minor;
    const char *arch_str;
  } const x[] = {
    { 3, 0, "compute_30" },
    { 3, 2, "compute_32" },
    { 3, 5, "compute_35" },
    { 3, 7, "compute_37" },
    { 5, 0, "compute_50" },
    { 5, 2, "compute_52" },
    { 5, 3, "compute_53" },
    { 6, 0, "compute_60" },
    { 6, 1, "compute_61" },
    { 6, 2, "compute_62" },
    { 7, 0, "compute_70" },
    { 7, 2, "compute_72" },
    { 7, 5, "compute_75" },
    { 8, 0, "compute_80" },
    { 8, 6, "compute_80" },
    { 8, 7, "compute_80" }
  };

  int major = device_query(dev, COMPUTE_CAPABILITY_MAJOR);
  int minor = device_query(dev, COMPUTE_CAPABILITY_MINOR);

  int chosen = -1;
  int num_archs = sizeof(x)/sizeof(x[0]);
  for (int i = 0; i < num_archs; i++) {
    if (x[i].major < major || (x[i].major == major && x[i].minor <= minor)) {
      chosen = i;
    } else {
      break;
    }
  }

  if (chosen == -1) {
    futhark_panic(-1, "Unsupported compute capability %d.%d\n", major, minor);
  }

  if (x[chosen].major != major || x[chosen].minor != minor) {
    fprintf(stderr,
            "Warning: device compute capability is %d.%d, but newest supported by Futhark is %d.%d.\n",
            major, minor, x[chosen].major, x[chosen].minor);
  }

  return x[chosen].arch_str;
}

static void cuda_nvrtc_mk_build_options(struct futhark_context *ctx, const char *extra_opts[],
                                        char*** opts_out, size_t *n_opts) {
  int arch_set = 0, num_extra_opts;
  struct futhark_context_config *cfg = ctx->cfg;

  char** macro_names;
  int64_t* macro_vals;
  int num_macros = gpu_macros(ctx, &macro_names, &macro_vals);

  // nvrtc cannot handle multiple -arch options.  Hence, if one of the
  // extra_opts is -arch, we have to be careful not to do our usual
  // automatic generation.
  for (num_extra_opts = 0; extra_opts[num_extra_opts] != NULL; num_extra_opts++) {
    if (strstr(extra_opts[num_extra_opts], "-arch")
        == extra_opts[num_extra_opts] ||
        strstr(extra_opts[num_extra_opts], "--gpu-architecture")
        == extra_opts[num_extra_opts]) {
      arch_set = 1;
    }
  }

  size_t i = 0, n_opts_alloc = 20 + num_macros + num_extra_opts + cfg->num_tuning_params;
  char **opts = (char**) malloc(n_opts_alloc * sizeof(char *));
  if (!arch_set) {
    opts[i++] = strdup("-arch");
    opts[i++] = strdup(cuda_nvrtc_get_arch(ctx->dev));
  }
  opts[i++] = strdup("-default-device");
  if (cfg->debugging) {
    opts[i++] = strdup("-G");
    opts[i++] = strdup("-lineinfo");
  } else {
    opts[i++] = strdup("--disable-warnings");
  }
  opts[i++] = msgprintf("-D%s=%d",
                        "max_thread_block_size",
                        (int)ctx->max_thread_block_size);
  opts[i++] = msgprintf("-D%s=%d",
                        "max_shared_memory",
                        (int)ctx->max_shared_memory);
  opts[i++] = msgprintf("-D%s=%d",
                        "max_registers",
                        (int)ctx->max_registers);

  for (int j = 0; j < num_macros; j++) {
    opts[i++] = msgprintf("-D%s=%zu", macro_names[j], macro_vals[j]);
  }

  for (int j = 0; j < cfg->num_tuning_params; j++) {
    opts[i++] = msgprintf("-D%s=%zu", cfg->tuning_param_vars[j],
                          cfg->tuning_params[j]);
  }
  opts[i++] = msgprintf("-DLOCKSTEP_WIDTH=%zu", ctx->lockstep_width);
  opts[i++] = msgprintf("-DMAX_THREADS_PER_BLOCK=%zu", ctx->max_thread_block_size);

  // Time for the best lines of the code in the entire compiler.
  if (getenv("CUDA_HOME") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_HOME"));
  }
  if (getenv("CUDA_ROOT") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_ROOT"));
  }
  if (getenv("CUDA_PATH") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_PATH"));
  }
  opts[i++] = msgprintf("-I/usr/local/cuda/include");
  opts[i++] = msgprintf("-I/usr/include");

  for (int j = 0; extra_opts[j] != NULL; j++) {
    opts[i++] = strdup(extra_opts[j]);
  }

  opts[i++] = msgprintf("-DTR_BLOCK_DIM=%d", TR_BLOCK_DIM);
  opts[i++] = msgprintf("-DTR_TILE_DIM=%d", TR_TILE_DIM);
  opts[i++] = msgprintf("-DTR_ELEMS_PER_THREAD=%d", TR_ELEMS_PER_THREAD);

  free(macro_names);
  free(macro_vals);

  *n_opts = i;
  *opts_out = opts;
}

static char* cuda_nvrtc_build(const char *src, const char *opts[], size_t n_opts,
                              char **ptx) {
  nvrtcProgram prog;
  char *problem = NULL;

  problem = NVRTC_SUCCEED_NONFATAL(nvrtcCreateProgram(&prog, src, "futhark-cuda", 0, NULL, NULL));

  if (problem) {
    return problem;
  }

  nvrtcResult res = nvrtcCompileProgram(prog, n_opts, opts);
  if (res != NVRTC_SUCCESS) {
    size_t log_size;
    if (nvrtcGetProgramLogSize(prog, &log_size) == NVRTC_SUCCESS) {
      char *log = (char*) malloc(log_size);
      if (nvrtcGetProgramLog(prog, log) == NVRTC_SUCCESS) {
        problem = msgprintf("NVRTC compilation failed.\n\n%s\n", log);
      } else {
        problem = msgprintf("Could not retrieve compilation log\n");
      }
      free(log);
    }
    return problem;
  }

  size_t ptx_size;
  NVRTC_SUCCEED_FATAL(nvrtcGetPTXSize(prog, &ptx_size));
  *ptx = (char*) malloc(ptx_size);
  NVRTC_SUCCEED_FATAL(nvrtcGetPTX(prog, *ptx));

  NVRTC_SUCCEED_FATAL(nvrtcDestroyProgram(&prog));

  return NULL;
}

static void cuda_load_ptx_from_cache(struct futhark_context_config *cfg,
                                     const char *src,
                                     const char *opts[], size_t n_opts,
                                     struct cache_hash *h, const char *cache_fname,
                                     char **ptx) {
  if (cfg->logging) {
    fprintf(stderr, "Restoring cache from from %s...\n", cache_fname);
  }
  cache_hash_init(h);
  for (size_t i = 0; i < n_opts; i++) {
    cache_hash(h, opts[i], strlen(opts[i]));
  }
  cache_hash(h, src, strlen(src));
  size_t ptxsize;
  errno = 0;
  if (cache_restore(cache_fname, h, (unsigned char**)ptx, &ptxsize) != 0) {
    if (cfg->logging) {
      fprintf(stderr, "Failed to restore cache (errno: %s)\n", strerror(errno));
    }
  }
}

static void cuda_size_setup(struct futhark_context *ctx)
{
  struct futhark_context_config *cfg = ctx->cfg;
  if (cfg->gpu.default_block_size > ctx->max_thread_block_size) {
    if (cfg->gpu.default_block_size_changed) {
      fprintf(stderr,
              "Note: Device limits default block size to %zu (down from %zu).\n",
              ctx->max_thread_block_size, cfg->gpu.default_block_size);
    }
    cfg->gpu.default_block_size = ctx->max_thread_block_size;
  }
  if (cfg->gpu.default_grid_size > ctx->max_grid_size) {
    if (cfg->gpu.default_grid_size_changed) {
      fprintf(stderr,
              "Note: Device limits default grid size to %zu (down from %zu).\n",
              ctx->max_grid_size, cfg->gpu.default_grid_size);
    }
    cfg->gpu.default_grid_size = ctx->max_grid_size;
  }
  if (cfg->gpu.default_tile_size > ctx->max_tile_size) {
    if (cfg->gpu.default_tile_size_changed) {
      fprintf(stderr,
              "Note: Device limits default tile size to %zu (down from %zu).\n",
              ctx->max_tile_size, cfg->gpu.default_tile_size);
    }
    cfg->gpu.default_tile_size = ctx->max_tile_size;
  }

  if (!cfg->gpu.default_grid_size_changed) {
    cfg->gpu.default_grid_size =
      (device_query(ctx->dev, MULTIPROCESSOR_COUNT) *
       device_query(ctx->dev, MAX_THREADS_PER_MULTIPROCESSOR))
      / cfg->gpu.default_block_size;
  }

  for (int i = 0; i < cfg->num_tuning_params; i++) {
    const char *size_class = cfg->tuning_param_classes[i];
    int64_t *size_value = &cfg->tuning_params[i];
    const char* size_name = cfg->tuning_param_names[i];
    int64_t max_value = 0, default_value = 0;

    if (strstr(size_class, "thread_block_size") == size_class) {
      max_value = ctx->max_thread_block_size;
      default_value = cfg->gpu.default_block_size;
    } else if (strstr(size_class, "grid_size") == size_class) {
      max_value = ctx->max_grid_size;
      default_value = cfg->gpu.default_grid_size;
      // XXX: as a quick and dirty hack, use twice as many threads for
      // histograms by default.  We really should just be smarter
      // about sizes somehow.
      if (strstr(size_name, ".seghist_") != NULL) {
        default_value *= 2;
      }
    } else if (strstr(size_class, "tile_size") == size_class) {
      max_value = ctx->max_tile_size;
      default_value = cfg->gpu.default_tile_size;
    } else if (strstr(size_class, "reg_tile_size") == size_class) {
      max_value = 0; // No limit.
      default_value = cfg->gpu.default_reg_tile_size;
    } else if (strstr(size_class, "shared_memory") == size_class) {
      max_value = ctx->max_shared_memory;
      default_value = ctx->max_shared_memory;
    } else if (strstr(size_class, "cache") == size_class) {
      max_value = ctx->max_cache;
      default_value = ctx->max_cache;
    } else if (strstr(size_class, "threshold") == size_class) {
      // Threshold can be as large as it takes.
      default_value = cfg->gpu.default_threshold;
    } else {
      // Bespoke sizes have no limit or default.
    }

    if (*size_value == 0) {
      *size_value = default_value;
    } else if (max_value > 0 && *size_value > max_value) {
      fprintf(stderr, "Note: Device limits %s to %zu (down from %zu)\n",
              size_name, max_value, *size_value);
      *size_value = max_value;
    }
  }
}

static char* cuda_module_setup(struct futhark_context *ctx,
                               const char *src,
                               const char *extra_opts[],
                               const char* cache_fname) {
  char *ptx = NULL;
  struct futhark_context_config *cfg = ctx->cfg;

  if (cfg->load_ptx_from) {
    ptx = slurp_file(cfg->load_ptx_from, NULL);
  }

  char **opts;
  size_t n_opts;
  cuda_nvrtc_mk_build_options(ctx, extra_opts, &opts, &n_opts);

  if (cfg->logging) {
    fprintf(stderr, "NVRTC compile options:\n");
    for (size_t j = 0; j < n_opts; j++) {
      fprintf(stderr, "\t%s\n", opts[j]);
    }
    fprintf(stderr, "\n");
  }

  struct cache_hash h;
  int loaded_ptx_from_cache = 0;
  if (cache_fname != NULL) {
    cuda_load_ptx_from_cache(cfg, src, (const char**)opts, n_opts, &h, cache_fname, &ptx);

    if (ptx != NULL) {
      if (cfg->logging) {
        fprintf(stderr, "Restored PTX from cache; now loading module...\n");
      }
      if (cuModuleLoadData(&ctx->module, ptx) == CUDA_SUCCESS) {
        if (cfg->logging) {
          fprintf(stderr, "Success!\n");
        }
        loaded_ptx_from_cache = 1;
      } else {
        if (cfg->logging) {
          fprintf(stderr, "Failed!\n");
        }
        free(ptx);
        ptx = NULL;
      }
    }
  }

  if (ptx == NULL) {
    char* problem = cuda_nvrtc_build(src, (const char**)opts, n_opts, &ptx);
    if (problem != NULL) {
      return problem;
    }
  }

  if (cfg->dump_ptx_to != NULL) {
    dump_file(cfg->dump_ptx_to, ptx, strlen(ptx));
  }

  if (!loaded_ptx_from_cache) {
    CUDA_SUCCEED_FATAL(cuModuleLoadData(&ctx->module, ptx));
  }

  if (cache_fname != NULL && !loaded_ptx_from_cache) {
    if (cfg->logging) {
      fprintf(stderr, "Caching PTX in %s...\n", cache_fname);
    }
    errno = 0;
    if (cache_store(cache_fname, &h, (const unsigned char*)ptx, strlen(ptx)) != 0) {
      fprintf(stderr, "Failed to cache PTX: %s\n", strerror(errno));
    }
  }

  for (size_t i = 0; i < n_opts; i++) {
    free((char *)opts[i]);
  }
  free(opts);
  free(ptx);

  return NULL;
}

struct cuda_event {
  cudaEvent_t start;
  cudaEvent_t end;
};

static struct cuda_event* cuda_event_new(struct futhark_context* ctx) {
  if (ctx->profiling && !ctx->profiling_paused) {
    struct cuda_event* e = malloc(sizeof(struct cuda_event));
    cudaEventCreate(&e->start);
    cudaEventCreate(&e->end);
    return e;
  } else {
    return NULL;
  }
}

static int cuda_event_report(struct str_builder* sb, struct cuda_event* e) {
  float ms;
  CUresult err;
  if ((err = cuEventElapsedTime(&ms, e->start, e->end)) != CUDA_SUCCESS) {
    return err;
  }

  // CUDA provides milisecond resolution, but we want microseconds.
  str_builder(sb, ",\"duration\":%f", ms*1000);

  if ((err = cuEventDestroy(e->start)) != CUDA_SUCCESS) {
    return 1;
  }

  if ((err = cuEventDestroy(e->end)) != CUDA_SUCCESS) {
    return 1;
  }

  free(e);

  return 0;
}

int futhark_context_sync(struct futhark_context* ctx) {
  CUDA_SUCCEED_OR_RETURN(cuCtxPushCurrent(ctx->cu_ctx));
  CUDA_SUCCEED_OR_RETURN(cuCtxSynchronize());
  if (ctx->failure_is_an_option) {
    // Check for any delayed error.
    int32_t failure_idx;
    CUDA_SUCCEED_OR_RETURN(
                           cuMemcpyDtoH(&failure_idx,
                                        ctx->global_failure,
                                        sizeof(int32_t)));
    ctx->failure_is_an_option = 0;

    if (failure_idx >= 0) {
      // We have to clear global_failure so that the next entry point
      // is not considered a failure from the start.
      int32_t no_failure = -1;
      CUDA_SUCCEED_OR_RETURN(
                             cuMemcpyHtoD(ctx->global_failure,
                                          &no_failure,
                                          sizeof(int32_t)));

      int64_t args[max_failure_args+1];
      CUDA_SUCCEED_OR_RETURN(
                             cuMemcpyDtoH(&args,
                                          ctx->global_failure_args,
                                          sizeof(args)));

      ctx->error = get_failure_msg(failure_idx, args);

      return FUTHARK_PROGRAM_ERROR;
    }
  }

  CUDA_SUCCEED_OR_RETURN(cuCtxPopCurrent(&ctx->cu_ctx));
  return 0;
}

struct builtin_kernels* init_builtin_kernels(struct futhark_context* ctx);
void free_builtin_kernels(struct futhark_context* ctx, struct builtin_kernels* kernels);

int backend_context_setup(struct futhark_context* ctx) {
  ctx->failure_is_an_option = 0;
  ctx->total_runs = 0;
  ctx->total_runtime = 0;
  ctx->peak_mem_usage_device = 0;
  ctx->cur_mem_usage_device = 0;
  ctx->kernels = NULL;

  CUDA_SUCCEED_FATAL(cuInit(0));
  if (cuda_device_setup(ctx) != 0) {
    futhark_panic(-1, "No suitable CUDA device found.\n");
  }
  CUDA_SUCCEED_FATAL(cuCtxCreate(&ctx->cu_ctx, 0, ctx->dev));

  free_list_init(&ctx->gpu_free_list);

  if (ctx->cfg->unified_memory == 2) {
    ctx->cfg->unified_memory = device_query(ctx->dev, MANAGED_MEMORY);
  }

  if (ctx->cfg->logging) {
    if (ctx->cfg->unified_memory) {
      fprintf(ctx->log, "Using managed memory\n");
    } else {
      fprintf(ctx->log, "Using unmanaged memory\n");
    }
  }

  ctx->max_thread_block_size = device_query(ctx->dev, MAX_THREADS_PER_BLOCK);
  ctx->max_grid_size = device_query(ctx->dev, MAX_GRID_DIM_X);
  ctx->max_tile_size = sqrt(ctx->max_thread_block_size);
  ctx->max_threshold = 1U<<31; // No limit.
  ctx->max_bespoke = 1U<<31; // No limit.

  if (ctx->cfg->gpu.default_registers != 0) {
    ctx->max_registers = ctx->cfg->gpu.default_registers;
  } else {
    ctx->max_registers = device_query(ctx->dev, MAX_REGISTERS_PER_BLOCK);
  }

  if (ctx->cfg->gpu.default_shared_memory != 0) {
    ctx->max_shared_memory = ctx->cfg->gpu.default_shared_memory;
  } else {
    // MAX_SHARED_MEMORY_PER_BLOCK gives bogus numbers (48KiB); probably
    // for backwards compatibility.  Add _OPTIN and you seem to get the
    // right number.
    ctx->max_shared_memory = device_query(ctx->dev, MAX_SHARED_MEMORY_PER_BLOCK_OPTIN);
#if CUDART_VERSION >= 12000
    ctx->max_shared_memory -= device_query(ctx->dev, RESERVED_SHARED_MEMORY_PER_BLOCK);
#endif
  }

  if (ctx->cfg->gpu.default_cache != 0) {
    ctx->max_cache = ctx->cfg->gpu.default_cache;
  } else {
    ctx->max_cache = device_query(ctx->dev, L2_CACHE_SIZE);
  }

  ctx->lockstep_width = device_query(ctx->dev, WARP_SIZE);
  CUDA_SUCCEED_FATAL(cuStreamCreate(&ctx->stream, CU_STREAM_DEFAULT));
  cuda_size_setup(ctx);

  gpu_init_log(ctx);

  ctx->error = cuda_module_setup(ctx,
                                 ctx->cfg->program,
                                 (const char**)ctx->cfg->nvrtc_opts,
                                 ctx->cfg->cache_fname);

  if (ctx->error != NULL) {
    futhark_panic(1, "During CUDA initialisation:\n%s\n", ctx->error);
  }

  int32_t no_error = -1;
  CUDA_SUCCEED_FATAL(cuMemAlloc(&ctx->global_failure, sizeof(no_error)));
  CUDA_SUCCEED_FATAL(cuMemcpyHtoD(ctx->global_failure, &no_error, sizeof(no_error)));
  // The +1 is to avoid zero-byte allocations.
  CUDA_SUCCEED_FATAL(cuMemAlloc(&ctx->global_failure_args, sizeof(int64_t)*(max_failure_args+1)));

  if ((ctx->kernels = init_builtin_kernels(ctx)) == NULL) {
    return 1;
  }

  return 0;
}

void backend_context_teardown(struct futhark_context* ctx) {
  if (ctx->kernels != NULL) {
    free_builtin_kernels(ctx, ctx->kernels);
    cuMemFree(ctx->global_failure);
    cuMemFree(ctx->global_failure_args);
    CUDA_SUCCEED_FATAL(gpu_free_all(ctx));
    CUDA_SUCCEED_FATAL(cuStreamDestroy(ctx->stream));
    CUDA_SUCCEED_FATAL(cuModuleUnload(ctx->module));
    CUDA_SUCCEED_FATAL(cuCtxDestroy(ctx->cu_ctx));
  }
  free_list_destroy(&ctx->gpu_free_list);
}

// GPU ABSTRACTION LAYER

// Types.

typedef CUfunction gpu_kernel;
typedef CUdeviceptr gpu_mem;

static void gpu_create_kernel(struct futhark_context *ctx,
                              gpu_kernel* kernel,
                              const char* name) {
  if (ctx->debugging) {
    fprintf(ctx->log, "Creating kernel %s.\n", name);
  }
  CUDA_SUCCEED_FATAL(cuModuleGetFunction(kernel, ctx->module, name));
  // Unless the below is set, the kernel is limited to 48KiB of memory.
  CUDA_SUCCEED_FATAL(cuFuncSetAttribute(*kernel,
                                        cudaFuncAttributeMaxDynamicSharedMemorySize,
                                        ctx->max_shared_memory));
}

static void gpu_free_kernel(struct futhark_context *ctx,
                            gpu_kernel kernel) {
  (void)ctx;
  (void)kernel;
}

static int gpu_scalar_to_device(struct futhark_context* ctx,
                                gpu_mem dst, size_t offset, size_t size,
                                void *src) {
  struct cuda_event *event = cuda_event_new(ctx);
  if (event != NULL) {
    add_event(ctx,
              "copy_scalar_to_dev",
              strdup(""),
              event,
              (event_report_fn)cuda_event_report);
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
  }
  CUDA_SUCCEED_OR_RETURN(cuMemcpyHtoD(dst + offset, src, size));
  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }
  return FUTHARK_SUCCESS;
}

static int gpu_scalar_from_device(struct futhark_context* ctx,
                                  void *dst,
                                  gpu_mem src, size_t offset, size_t size) {
  struct cuda_event *event = cuda_event_new(ctx);
  if (event != NULL) {
    add_event(ctx,
              "copy_scalar_from_dev",
              strdup(""),
              event,
              (event_report_fn)cuda_event_report);
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
  }
  CUDA_SUCCEED_OR_RETURN(cuMemcpyDtoH(dst, src + offset, size));
  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }
  return FUTHARK_SUCCESS;
}

static int gpu_memcpy(struct futhark_context* ctx,
                      gpu_mem dst, int64_t dst_offset,
                      gpu_mem src, int64_t src_offset,
                      int64_t nbytes) {
  struct cuda_event *event = cuda_event_new(ctx);
  if (event != NULL) {
    add_event(ctx,
              "copy_dev_to_dev",
              strdup(""),
              event,
              (event_report_fn)cuda_event_report);
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
  }
  CUDA_SUCCEED_OR_RETURN(cuMemcpyAsync(dst+dst_offset, src+src_offset, nbytes, ctx->stream));
  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }
  return FUTHARK_SUCCESS;
}

static int memcpy_host2gpu(struct futhark_context* ctx, bool sync,
                           gpu_mem dst, int64_t dst_offset,
                           const unsigned char* src, int64_t src_offset,
                           int64_t nbytes) {
  if (nbytes > 0) {
    struct cuda_event *event = cuda_event_new(ctx);
    if (event != NULL) {
      add_event(ctx,
                "copy_host_to_dev",
                strdup(""),
                event,
                (event_report_fn)cuda_event_report);
      CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
    }
    if (sync) {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyHtoD(dst + dst_offset, src + src_offset, nbytes));
    } else {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyHtoDAsync(dst + dst_offset, src + src_offset, nbytes, ctx->stream));
    }
    if (event != NULL) {
      CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
    }
  }
  return FUTHARK_SUCCESS;
}

static int memcpy_gpu2host(struct futhark_context* ctx, bool sync,
                           unsigned char* dst, int64_t dst_offset,
                           gpu_mem src, int64_t src_offset,
                           int64_t nbytes) {
  if (nbytes > 0) {
    struct cuda_event *event = cuda_event_new(ctx);
    if (event != NULL) {
      add_event(ctx,
                "copy_dev_to_host",
                strdup(""),
                event,
                (event_report_fn)cuda_event_report);
      CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
    }
    if (sync) {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyDtoH(dst + dst_offset, src + src_offset, nbytes));
    } else {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyDtoHAsync(dst + dst_offset, src + src_offset, nbytes, ctx->stream));
    }
    if (event != NULL) {
      CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
    }
    if (sync &&
        ctx->failure_is_an_option &&
        futhark_context_sync(ctx) != 0) {
      return 1;
    }
  }
  return FUTHARK_SUCCESS;
}

static int gpu_launch_kernel(struct futhark_context* ctx,
                             gpu_kernel kernel, const char *name,
                             const int32_t grid[3],
                             const int32_t block[3],
                             unsigned int shared_mem_bytes,
                             int num_args,
                             void* args[num_args],
                             size_t args_sizes[num_args]) {
  (void) args_sizes;

  if (shared_mem_bytes > ctx->max_shared_memory) {
    set_error(ctx, msgprintf("Kernel %s with %d bytes of memory exceeds device limit of %d\n",
                             name, shared_mem_bytes, (int)ctx->max_shared_memory));
    return 1;
  }

  int64_t time_start = 0, time_end = 0;
  if (ctx->debugging) {
    time_start = get_wall_time();
  }

  struct cuda_event *event = cuda_event_new(ctx);

  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
    add_event(ctx,
              name,
              msgprintf("Kernel %s with\n"
                        "  grid=(%d,%d,%d)\n"
                        "  block=(%d,%d,%d)\n"
                        "  shared memory=%d",
                        name,
                        grid[0], grid[1], grid[2],
                        block[0], block[1], block[2],
                        shared_mem_bytes),
              event,
              (event_report_fn)cuda_event_report);
  }

  CUDA_SUCCEED_OR_RETURN
    (cuLaunchKernel(kernel,
                    grid[0], grid[1], grid[2],
                    block[0], block[1], block[2],
                    shared_mem_bytes, ctx->stream,
                    args, NULL));

  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }

  if (ctx->debugging) {
    CUDA_SUCCEED_FATAL(cuCtxSynchronize());
    time_end = get_wall_time();
    long int time_diff = time_end - time_start;
    fprintf(ctx->log, "  runtime: %ldus\n", time_diff);
  }
  if (ctx->logging) {
    fprintf(ctx->log, "\n");
  }

  return FUTHARK_SUCCESS;
}

static int gpu_alloc_actual(struct futhark_context *ctx, size_t size, gpu_mem *mem_out) {
  CUresult res;
  if (ctx->cfg->unified_memory) {
    res = cuMemAllocManaged(mem_out, size, CU_MEM_ATTACH_GLOBAL);
  } else {
    res = cuMemAlloc(mem_out, size);
  }

  if (res == CUDA_ERROR_OUT_OF_MEMORY) {
    return FUTHARK_OUT_OF_MEMORY;
  }

  CUDA_SUCCEED_OR_RETURN(res);
  return FUTHARK_SUCCESS;
}

static int gpu_free_actual(struct futhark_context *ctx, gpu_mem mem) {
  (void)ctx;
  CUDA_SUCCEED_OR_RETURN(cuMemFree(mem));
  return FUTHARK_SUCCESS;
}

// End of backends/cuda.h.

// Start of gpu.h

// Generic functions that use our tiny GPU abstraction layer.  The
// entire context must be defined before this header is included.  In
// particular we expect the following functions to be available:

static int gpu_free_actual(struct futhark_context *ctx, gpu_mem mem);
static int gpu_alloc_actual(struct futhark_context *ctx, size_t size, gpu_mem *mem_out);
int gpu_launch_kernel(struct futhark_context* ctx,
                      gpu_kernel kernel, const char *name,
                      const int32_t grid[3],
                      const int32_t block[3],
                      unsigned int shared_mem_bytes,
                      int num_args,
                      void* args[num_args],
                      size_t args_sizes[num_args]);
int gpu_memcpy(struct futhark_context* ctx,
               gpu_mem dst, int64_t dst_offset,
               gpu_mem src, int64_t src_offset,
               int64_t nbytes);
int gpu_scalar_from_device(struct futhark_context* ctx,
                           void *dst,
                           gpu_mem src, size_t offset, size_t size);
int gpu_scalar_to_device(struct futhark_context* ctx,
                         gpu_mem dst, size_t offset, size_t size,
                         void *src);
void gpu_create_kernel(struct futhark_context *ctx,
                       gpu_kernel* kernel,
                       const char* name);

static void gpu_init_log(struct futhark_context *ctx) {
  if (ctx->cfg->logging) {
    fprintf(ctx->log, "Default block size: %ld\n", (long)ctx->cfg->gpu.default_block_size);
    fprintf(ctx->log, "Default grid size: %ld\n", (long)ctx->cfg->gpu.default_grid_size);
    fprintf(ctx->log, "Default tile size: %ld\n", (long)ctx->cfg->gpu.default_tile_size);
    fprintf(ctx->log, "Default register tile size: %ld\n", (long)ctx->cfg->gpu.default_reg_tile_size);
    fprintf(ctx->log, "Default cache: %ld\n", (long)ctx->cfg->gpu.default_cache);
    fprintf(ctx->log, "Default registers: %ld\n", (long)ctx->cfg->gpu.default_registers);
    fprintf(ctx->log, "Default threshold: %ld\n", (long)ctx->cfg->gpu.default_threshold);
    fprintf(ctx->log, "Max thread block size: %ld\n", (long)ctx->max_thread_block_size);
    fprintf(ctx->log, "Max grid size: %ld\n", (long)ctx->max_grid_size);
    fprintf(ctx->log, "Max tile size: %ld\n", (long)ctx->max_tile_size);
    fprintf(ctx->log, "Max threshold: %ld\n", (long)ctx->max_threshold);
    fprintf(ctx->log, "Max shared memory: %ld\n", (long)ctx->max_shared_memory);
    fprintf(ctx->log, "Max registers: %ld\n", (long)ctx->max_registers);
    fprintf(ctx->log, "Max cache: %ld\n", (long)ctx->max_cache);
    fprintf(ctx->log, "Lockstep width: %ld\n", (long)ctx->lockstep_width);
  }
}

// Generic GPU command line options.

void futhark_context_config_set_default_thread_block_size(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_block_size = size;
  cfg->gpu.default_block_size_changed = 1;
}

void futhark_context_config_set_default_group_size(struct futhark_context_config *cfg, int size) {
  futhark_context_config_set_default_thread_block_size(cfg, size);
}

void futhark_context_config_set_default_grid_size(struct futhark_context_config *cfg, int num) {
  cfg->gpu.default_grid_size = num;
  cfg->gpu.default_grid_size_changed = 1;
}

void futhark_context_config_set_default_num_groups(struct futhark_context_config *cfg, int num) {
  futhark_context_config_set_default_grid_size(cfg, num);
}

void futhark_context_config_set_default_tile_size(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_tile_size = size;
  cfg->gpu.default_tile_size_changed = 1;
}

void futhark_context_config_set_default_reg_tile_size(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_reg_tile_size = size;
}

void futhark_context_config_set_default_cache(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_cache = size;
}

void futhark_context_config_set_default_registers(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_registers = size;
}

void futhark_context_config_set_default_threshold(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_threshold = size;
}

int futhark_context_config_set_tuning_param(struct futhark_context_config *cfg,
                                            const char *param_name,
                                            size_t new_value) {
  for (int i = 0; i < cfg->num_tuning_params; i++) {
    if (strcmp(param_name, cfg->tuning_param_names[i]) == 0) {
      cfg->tuning_params[i] = new_value;
      return 0;
    }
  }
  if (strcmp(param_name, "default_thread_block_size") == 0 ||
      strcmp(param_name, "default_group_size") == 0) {
    cfg->gpu.default_block_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_grid_size") == 0 ||
      strcmp(param_name, "default_num_groups") == 0) {
    cfg->gpu.default_grid_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_threshold") == 0) {
    cfg->gpu.default_threshold = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_tile_size") == 0) {
    cfg->gpu.default_tile_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_reg_tile_size") == 0) {
    cfg->gpu.default_reg_tile_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_cache") == 0) {
    cfg->gpu.default_cache = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_shared_memory") == 0) {
    cfg->gpu.default_shared_memory = new_value;
    return 0;
  }

  return 1;
}

// End of GPU command line optiopns.

// Max number of thead blocks we allow along the second or third
// dimension for transpositions.
#define MAX_TR_THREAD_BLOCKS 65535

struct builtin_kernels {
  // We have a lot of ways to transpose arrays.
  gpu_kernel map_transpose_1b;
  gpu_kernel map_transpose_1b_low_height;
  gpu_kernel map_transpose_1b_low_width;
  gpu_kernel map_transpose_1b_small;
  gpu_kernel map_transpose_1b_large;
  gpu_kernel map_transpose_2b;
  gpu_kernel map_transpose_2b_low_height;
  gpu_kernel map_transpose_2b_low_width;
  gpu_kernel map_transpose_2b_small;
  gpu_kernel map_transpose_2b_large;
  gpu_kernel map_transpose_4b;
  gpu_kernel map_transpose_4b_low_height;
  gpu_kernel map_transpose_4b_low_width;
  gpu_kernel map_transpose_4b_small;
  gpu_kernel map_transpose_4b_large;
  gpu_kernel map_transpose_8b;
  gpu_kernel map_transpose_8b_low_height;
  gpu_kernel map_transpose_8b_low_width;
  gpu_kernel map_transpose_8b_small;
  gpu_kernel map_transpose_8b_large;

  // And a few ways of copying.
  gpu_kernel lmad_copy_1b;
  gpu_kernel lmad_copy_2b;
  gpu_kernel lmad_copy_4b;
  gpu_kernel lmad_copy_8b;
};

struct builtin_kernels* init_builtin_kernels(struct futhark_context* ctx) {
  struct builtin_kernels *kernels = malloc(sizeof(struct builtin_kernels));
  gpu_create_kernel(ctx, &kernels->map_transpose_1b, "map_transpose_1b");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_large, "map_transpose_1b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_low_height, "map_transpose_1b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_low_width, "map_transpose_1b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_small, "map_transpose_1b_small");

  gpu_create_kernel(ctx, &kernels->map_transpose_2b, "map_transpose_2b");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_large, "map_transpose_2b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_low_height, "map_transpose_2b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_low_width, "map_transpose_2b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_small, "map_transpose_2b_small");

  gpu_create_kernel(ctx, &kernels->map_transpose_4b, "map_transpose_4b");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_large, "map_transpose_4b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_low_height, "map_transpose_4b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_low_width, "map_transpose_4b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_small, "map_transpose_4b_small");

  gpu_create_kernel(ctx, &kernels->map_transpose_8b, "map_transpose_8b");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_large, "map_transpose_8b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_low_height, "map_transpose_8b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_low_width, "map_transpose_8b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_small, "map_transpose_8b_small");

  gpu_create_kernel(ctx, &kernels->lmad_copy_1b, "lmad_copy_1b");
  gpu_create_kernel(ctx, &kernels->lmad_copy_2b, "lmad_copy_2b");
  gpu_create_kernel(ctx, &kernels->lmad_copy_4b, "lmad_copy_4b");
  gpu_create_kernel(ctx, &kernels->lmad_copy_8b, "lmad_copy_8b");

  return kernels;
}

void free_builtin_kernels(struct futhark_context* ctx, struct builtin_kernels* kernels) {
  gpu_free_kernel(ctx, kernels->map_transpose_1b);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_small);

  gpu_free_kernel(ctx, kernels->map_transpose_2b);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_small);

  gpu_free_kernel(ctx, kernels->map_transpose_4b);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_small);

  gpu_free_kernel(ctx, kernels->map_transpose_8b);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_small);

  gpu_free_kernel(ctx, kernels->lmad_copy_1b);
  gpu_free_kernel(ctx, kernels->lmad_copy_2b);
  gpu_free_kernel(ctx, kernels->lmad_copy_4b);
  gpu_free_kernel(ctx, kernels->lmad_copy_8b);

  free(kernels);
}

static int gpu_alloc(struct futhark_context *ctx, FILE *log,
                     size_t min_size, const char *tag,
                     gpu_mem *mem_out, size_t *size_out) {
  if (min_size < sizeof(int)) {
    min_size = sizeof(int);
  }

  gpu_mem* memptr;
  if (free_list_find(&ctx->gpu_free_list, min_size, tag, size_out, (fl_mem*)&memptr) == 0) {
    // Successfully found a free block.  Is it big enough?
    if (*size_out >= min_size) {
      if (ctx->cfg->debugging) {
        fprintf(log, "No need to allocate: Found a block in the free list.\n");
      }
      *mem_out = *memptr;
      free(memptr);
      return FUTHARK_SUCCESS;
    } else {
      if (ctx->cfg->debugging) {
        fprintf(log, "Found a free block, but it was too small.\n");
      }
      int error = gpu_free_actual(ctx, *memptr);
      free(memptr);
      if (error != FUTHARK_SUCCESS) {
        return error;
      }
    }
  }

  *size_out = min_size;

  // We have to allocate a new block from the driver.  If the
  // allocation does not succeed, then we might be in an out-of-memory
  // situation.  We now start freeing things from the free list until
  // we think we have freed enough that the allocation will succeed.
  // Since we don't know how far the allocation is from fitting, we
  // have to check after every deallocation.  This might be pretty
  // expensive.  Let's hope that this case is hit rarely.

  if (ctx->cfg->debugging) {
    fprintf(log, "Actually allocating the desired block.\n");
  }

  int error = gpu_alloc_actual(ctx, min_size, mem_out);

  while (error == FUTHARK_OUT_OF_MEMORY) {
    if (ctx->cfg->debugging) {
      fprintf(log, "Out of GPU memory: releasing entry from the free list...\n");
    }
    gpu_mem* memptr;
    if (free_list_first(&ctx->gpu_free_list, (fl_mem*)&memptr) == 0) {
      gpu_mem mem = *memptr;
      free(memptr);
      error = gpu_free_actual(ctx, mem);
      if (error != FUTHARK_SUCCESS) {
        return error;
      }
    } else {
      break;
    }
    error = gpu_alloc_actual(ctx, min_size, mem_out);
  }

  return error;
}

static int gpu_free(struct futhark_context *ctx,
                    gpu_mem mem, size_t size, const char *tag) {
  gpu_mem* memptr = malloc(sizeof(gpu_mem));
  *memptr = mem;
  free_list_insert(&ctx->gpu_free_list, size, (fl_mem)memptr, tag);
  return FUTHARK_SUCCESS;
}

static int gpu_free_all(struct futhark_context *ctx) {
  free_list_pack(&ctx->gpu_free_list);
  gpu_mem* memptr;
  while (free_list_first(&ctx->gpu_free_list, (fl_mem*)&memptr) == 0) {
    gpu_mem mem = *memptr;
    free(memptr);
    int error = gpu_free_actual(ctx, mem);
    if (error != FUTHARK_SUCCESS) {
      return error;
    }
  }

  return FUTHARK_SUCCESS;
}

static int gpu_map_transpose(struct futhark_context* ctx,
                             gpu_kernel kernel_default,
                             gpu_kernel kernel_low_height,
                             gpu_kernel kernel_low_width,
                             gpu_kernel kernel_small,
                             gpu_kernel kernel_large,
                             const char *name, size_t elem_size,
                             gpu_mem dst, int64_t dst_offset,
                             gpu_mem src, int64_t src_offset,
                             int64_t k, int64_t n, int64_t m) {
  int64_t mulx = TR_BLOCK_DIM / n;
  int64_t muly = TR_BLOCK_DIM / m;
  int32_t mulx32 = mulx;
  int32_t muly32 = muly;
  int32_t k32 = k;
  int32_t n32 = n;
  int32_t m32 = m;

  gpu_kernel kernel = kernel_default;
  int32_t grid[3];
  int32_t block[3];

  void* args[11];
  size_t args_sizes[11] = {
    sizeof(gpu_mem), sizeof(int64_t),
    sizeof(gpu_mem), sizeof(int64_t),
    sizeof(int32_t),
    sizeof(int32_t),
    sizeof(int32_t),
    sizeof(int32_t),
    sizeof(int32_t)
  };

  args[0] = &dst;
  args[1] = &dst_offset;
  args[2] = &src;
  args[3] = &src_offset;
  args[7] = &mulx;
  args[8] = &muly;

  if (dst_offset + k * n * m <= 2147483647L &&
      src_offset + k * n * m <= 2147483647L) {
    if (m <= TR_BLOCK_DIM/2 && n <= TR_BLOCK_DIM/2) {
      if (ctx->logging) { fprintf(ctx->log, "Using small kernel\n"); }
      kernel = kernel_small;
      grid[0] = ((k * n * m) + (TR_BLOCK_DIM*TR_BLOCK_DIM) - 1) / (TR_BLOCK_DIM*TR_BLOCK_DIM);
      grid[1] = 1;
      grid[2] = 1;
      block[0] = TR_BLOCK_DIM*TR_BLOCK_DIM;
      block[1] = 1;
      block[2] = 1;
    } else if (m <= TR_BLOCK_DIM/2 && TR_BLOCK_DIM < n) {
      if (ctx->logging) { fprintf(ctx->log, "Using low-width kernel\n"); }
      kernel = kernel_low_width;
      int64_t x_elems = m;
      int64_t y_elems = (n + muly - 1) / muly;
      grid[0] = (x_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[1] = (y_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[2] = k;
      block[0] = TR_BLOCK_DIM;
      block[1] = TR_BLOCK_DIM;
      block[2] = 1;
    } else if (n <= TR_BLOCK_DIM/2 && TR_BLOCK_DIM < m) {
      if (ctx->logging) { fprintf(ctx->log, "Using low-height kernel\n"); }
      kernel = kernel_low_height;
      int64_t x_elems = (m + mulx - 1) / mulx;
      int64_t y_elems = n;
      grid[0] = (x_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[1] = (y_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[2] = k;
      block[0] = TR_BLOCK_DIM;
      block[1] = TR_BLOCK_DIM;
      block[2] = 1;
    } else {
      if (ctx->logging) { fprintf(ctx->log, "Using default kernel\n"); }
      kernel = kernel_default;
      grid[0] = (m+TR_TILE_DIM-1)/TR_TILE_DIM;
      grid[1] = (n+TR_TILE_DIM-1)/TR_TILE_DIM;
      grid[2] = k;
      block[0] = TR_TILE_DIM;
      block[1] = TR_TILE_DIM/TR_ELEMS_PER_THREAD;
      block[2] = 1;
    }
    args[4] = &k32;
    args[5] = &m32;
    args[6] = &n32;
    args[7] = &mulx32;
    args[8] = &muly32;
  } else {
    if (ctx->logging) { fprintf(ctx->log, "Using large kernel\n"); }
    kernel = kernel_large;
    grid[0] = (m+TR_TILE_DIM-1)/TR_TILE_DIM;
    grid[1] = (n+TR_TILE_DIM-1)/TR_TILE_DIM;
    grid[2] = k;
    block[0] = TR_TILE_DIM;
    block[1] = TR_TILE_DIM/TR_ELEMS_PER_THREAD;
    block[2] = 1;
    args[4] = &k;
    args[5] = &m;
    args[6] = &n;
    args[7] = &mulx;
    args[8] = &muly;
    args_sizes[4] = sizeof(int64_t);
    args_sizes[5] = sizeof(int64_t);
    args_sizes[6] = sizeof(int64_t);
    args_sizes[7] = sizeof(int64_t);
    args_sizes[8] = sizeof(int64_t);
  }

  // Cap the number of thead blocks we launch and figure out how many
  // repeats we need alongside each dimension.
  int32_t repeat_1 = grid[1] / MAX_TR_THREAD_BLOCKS;
  int32_t repeat_2 = grid[2] / MAX_TR_THREAD_BLOCKS;
  grid[1] = repeat_1 > 0 ? MAX_TR_THREAD_BLOCKS : grid[1];
  grid[2] = repeat_2 > 0 ? MAX_TR_THREAD_BLOCKS : grid[2];
  args[9] = &repeat_1;
  args[10] = &repeat_2;
  args_sizes[9] = sizeof(repeat_1);
  args_sizes[10] = sizeof(repeat_2);

  if (ctx->logging) {
    fprintf(ctx->log, "\n");
  }

  return gpu_launch_kernel(ctx, kernel, name, grid, block,
                           TR_TILE_DIM*(TR_TILE_DIM+1)*elem_size,
                           sizeof(args)/sizeof(args[0]), args, args_sizes);
}

#define GEN_MAP_TRANSPOSE_GPU2GPU(NAME, ELEM_TYPE)                      \
  static int map_transpose_gpu2gpu_##NAME                               \
  (struct futhark_context* ctx,                                         \
   gpu_mem dst, int64_t dst_offset,                                     \
   gpu_mem src, int64_t src_offset,                                     \
   int64_t k, int64_t m, int64_t n)                                     \
  {                                                                     \
    return                                                              \
      gpu_map_transpose                                                 \
      (ctx,                                                             \
       ctx->kernels->map_transpose_##NAME,                              \
       ctx->kernels->map_transpose_##NAME##_low_height,                 \
       ctx->kernels->map_transpose_##NAME##_low_width,                  \
       ctx->kernels->map_transpose_##NAME##_small,                      \
       ctx->kernels->map_transpose_##NAME##_large,                      \
       "map_transpose_" #NAME, sizeof(ELEM_TYPE),                       \
       dst, dst_offset, src, src_offset,                                \
       k, n, m);                                                        \
  }

static int gpu_lmad_copy(struct futhark_context* ctx,
                         gpu_kernel kernel, int r,
                         gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],
                         gpu_mem src, int64_t src_offset, int64_t src_strides[r],
                         int64_t shape[r]) {
  if (r > 8) {
    set_error(ctx, strdup("Futhark runtime limitation:\nCannot copy array of greater than rank 8.\n"));
    return 1;
  }

  int64_t n = 1;
  for (int i = 0; i < r; i++) { n *= shape[i]; }

  void* args[6+(8*3)];
  size_t args_sizes[6+(8*3)];

  args[0] = &dst;
  args_sizes[0] = sizeof(gpu_mem);
  args[1] = &dst_offset;
  args_sizes[1] = sizeof(dst_offset);
  args[2] = &src;
  args_sizes[2] = sizeof(gpu_mem);
  args[3] = &src_offset;
  args_sizes[3] = sizeof(src_offset);
  args[4] = &n;
  args_sizes[4] = sizeof(n);
  args[5] = &r;
  args_sizes[5] = sizeof(r);

  int64_t zero = 0;

  for (int i = 0; i < 8; i++) {
    args_sizes[6+i*3] = sizeof(int64_t);
    args_sizes[6+i*3+1] = sizeof(int64_t);
    args_sizes[6+i*3+2] = sizeof(int64_t);
    if (i < r) {
      args[6+i*3] = &shape[i];
      args[6+i*3+1] = &dst_strides[i];
      args[6+i*3+2] = &src_strides[i];
    } else {
      args[6+i*3] = &zero;
      args[6+i*3+1] = &zero;
      args[6+i*3+2] = &zero;
    }
  }
  const size_t w = 256; // XXX: hardcoded thread block size.

  return gpu_launch_kernel(ctx, kernel, "copy_lmad_dev_to_dev",
                           (const int32_t[3]) {(n+w-1)/w,1,1},
                           (const int32_t[3]) {w,1,1},
                           0, 6+(8*3), args, args_sizes);
}

#define GEN_LMAD_COPY_ELEMENTS_GPU2GPU(NAME, ELEM_TYPE)                 \
  static int lmad_copy_elements_gpu2gpu_##NAME                          \
  (struct futhark_context* ctx,                                         \
   int r,                                                               \
   gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],             \
   gpu_mem src, int64_t src_offset, int64_t src_strides[r],             \
   int64_t shape[r]) {                                                  \
    return gpu_lmad_copy(ctx, ctx->kernels->lmad_copy_##NAME, r,        \
                         dst, dst_offset, dst_strides,                  \
                         src, src_offset, src_strides,                  \
                         shape);                                        \
  }                                                                     \

#define GEN_LMAD_COPY_GPU2GPU(NAME, ELEM_TYPE)                          \
  static int lmad_copy_gpu2gpu_##NAME                                   \
  (struct futhark_context* ctx,                                         \
   int r,                                                               \
   gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],             \
   gpu_mem src, int64_t src_offset, int64_t src_strides[r],             \
   int64_t shape[r]) {                                                  \
    log_copy(ctx, "GPU to GPU", r, dst_offset, dst_strides,             \
             src_offset, src_strides, shape);                           \
    int64_t size = 1;                                                   \
    for (int i = 0; i < r; i++) { size *= shape[i]; }                   \
    if (size == 0) { return FUTHARK_SUCCESS; }                          \
    int64_t k, n, m;                                                    \
    if (lmad_map_tr(&k, &n, &m,                                         \
                       r, dst_strides, src_strides, shape)) {           \
      log_transpose(ctx, k, n, m);                                      \
      return map_transpose_gpu2gpu_##NAME                               \
        (ctx, dst, dst_offset, src, src_offset, k, n, m);               \
    } else if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {   \
      if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}        \
      return gpu_memcpy(ctx,                                            \
                        dst, dst_offset*sizeof(ELEM_TYPE),              \
                        src, src_offset*sizeof(ELEM_TYPE),              \
                        size * sizeof(ELEM_TYPE));                      \
    } else {                                                            \
      if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}     \
      return lmad_copy_elements_gpu2gpu_##NAME                          \
        (ctx, r,                                                        \
         dst, dst_offset, dst_strides,                                  \
         src, src_offset, src_strides,                                  \
         shape);                                                        \
    }                                                                   \
  }

static int
lmad_copy_elements_host2gpu(struct futhark_context *ctx, size_t elem_size,
                            int r,
                            gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],
                            unsigned char* src, int64_t src_offset, int64_t src_strides[r],
                            int64_t shape[r]) {
  (void)ctx; (void)elem_size; (void)r;
  (void)dst; (void)dst_offset; (void)dst_strides;
  (void)src; (void)src_offset; (void)src_strides;
  (void)shape;
  set_error(ctx, strdup("Futhark runtime limitation:\nCannot copy unstructured array from host to GPU.\n"));
  return 1;
}

static int
lmad_copy_elements_gpu2host (struct futhark_context *ctx, size_t elem_size,
                             int r,
                             unsigned char* dst, int64_t dst_offset, int64_t dst_strides[r],
                             gpu_mem src, int64_t src_offset, int64_t src_strides[r],
                             int64_t shape[r]) {
  (void)ctx; (void)elem_size; (void)r;
  (void)dst; (void)dst_offset; (void)dst_strides;
  (void)src; (void)src_offset; (void)src_strides;
  (void)shape;
  set_error(ctx, strdup("Futhark runtime limitation:\nCannot copy unstructured array from GPU to host.\n"));
  return 1;
}

#define GEN_LMAD_COPY_ELEMENTS_HOSTGPU(NAME, ELEM_TYPE)                 \
  static int lmad_copy_elements_gpu2gpu_##NAME                          \
  (struct futhark_context* ctx,                                         \
   int r,                                                               \
   gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],             \
   gpu_mem src, int64_t src_offset, int64_t src_strides[r],             \
   int64_t shape[r]) {                                                  \
    return (ctx, ctx->kernels->lmad_copy_##NAME, r,                     \
                         dst, dst_offset, dst_strides,                  \
                         src, src_offset, src_strides,                  \
                         shape);                                        \
  }                                                                     \


static int lmad_copy_host2gpu(struct futhark_context* ctx, size_t elem_size, bool sync,
                              int r,
                              gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],
                              unsigned char* src, int64_t src_offset, int64_t src_strides[r],
                              int64_t shape[r]) {
  log_copy(ctx, "Host to GPU", r, dst_offset, dst_strides,
           src_offset, src_strides, shape);
  int64_t size = elem_size;
  for (int i = 0; i < r; i++) { size *= shape[i]; }
  if (size == 0) { return FUTHARK_SUCCESS; }
  int64_t k, n, m;
  if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {
    if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}
    return memcpy_host2gpu(ctx, sync,
                           dst, dst_offset*elem_size,
                           src, src_offset*elem_size,
                           size);
  } else {
    if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}
    int error;
    error = lmad_copy_elements_host2gpu
      (ctx, elem_size, r,
       dst, dst_offset, dst_strides,
       src, src_offset, src_strides,
       shape);
    if (error == 0 && sync) {
      error = futhark_context_sync(ctx);
    }
    return error;
  }
}

static int lmad_copy_gpu2host(struct futhark_context* ctx, size_t elem_size, bool sync,
                              int r,
                              unsigned char* dst, int64_t dst_offset, int64_t dst_strides[r],
                              gpu_mem src, int64_t src_offset, int64_t src_strides[r],
                              int64_t shape[r]) {
  log_copy(ctx, "Host to GPU", r, dst_offset, dst_strides,
           src_offset, src_strides, shape);
  int64_t size = elem_size;
  for (int i = 0; i < r; i++) { size *= shape[i]; }
  if (size == 0) { return FUTHARK_SUCCESS; }
  int64_t k, n, m;
  if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {
    if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}
    return memcpy_gpu2host(ctx, sync,
                           dst, dst_offset*elem_size,
                           src, src_offset*elem_size,
                           size);
  } else {
    if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}
    int error;
    error = lmad_copy_elements_gpu2host
      (ctx, elem_size, r,
       dst, dst_offset, dst_strides,
       src, src_offset, src_strides,
       shape);
    if (error == 0 && sync) {
      error = futhark_context_sync(ctx);
    }
    return error;
  }
}

GEN_MAP_TRANSPOSE_GPU2GPU(1b, uint8_t)
GEN_MAP_TRANSPOSE_GPU2GPU(2b, uint16_t)
GEN_MAP_TRANSPOSE_GPU2GPU(4b, uint32_t)
GEN_MAP_TRANSPOSE_GPU2GPU(8b, uint64_t)

GEN_LMAD_COPY_ELEMENTS_GPU2GPU(1b, uint8_t)
GEN_LMAD_COPY_ELEMENTS_GPU2GPU(2b, uint16_t)
GEN_LMAD_COPY_ELEMENTS_GPU2GPU(4b, uint32_t)
GEN_LMAD_COPY_ELEMENTS_GPU2GPU(8b, uint64_t)

GEN_LMAD_COPY_GPU2GPU(1b, uint8_t)
GEN_LMAD_COPY_GPU2GPU(2b, uint16_t)
GEN_LMAD_COPY_GPU2GPU(4b, uint32_t)
GEN_LMAD_COPY_GPU2GPU(8b, uint64_t)

// End of gpu.h

static int gpu_macros(struct futhark_context *ctx, char ***names_out, int64_t **values_out)
{
    int num_macros = 112;
    char **names = malloc(num_macros * sizeof(char *));
    int64_t *values = malloc(num_macros * sizeof(int64_t));
    
    {
        names[0] = "isolate_core_points_6871zisegmap_16261_dim1";
        values[0] = *ctx->tuning_params.isolate_core_points_6871zisegmap_tblock_sizze_16264;
    }
    {
        names[1] = "isolate_core_points_6871zisegmap_16261zisegmap_tblock_sizze_16265";
        values[1] = *ctx->tuning_params.isolate_core_points_6871zisegmap_tblock_sizze_16264;
    }
    {
        names[2] = "isolate_core_points_6871zisegmap_16250_dim1";
        values[2] = *ctx->tuning_params.isolate_core_points_6871zisegmap_tblock_sizze_16235;
    }
    {
        names[3] = "isolate_core_points_6871zisegmap_16250zisegmap_tblock_sizze_16246";
        values[3] = *ctx->tuning_params.isolate_core_points_6871zisegmap_tblock_sizze_16235;
    }
    {
        names[4] = "isolate_core_points_6871zisegscan_16229_dim1";
        values[4] = *ctx->tuning_params.isolate_core_points_6871zisegscan_tblock_sizze_16223;
    }
    {
        names[5] = "isolate_core_points_6871zisegscan_16229zisegscan_tblock_sizze_16224";
        values[5] = *ctx->tuning_params.isolate_core_points_6871zisegscan_tblock_sizze_16223;
    }
    {
        names[6] = "isolate_core_points_6871zisegscan_16229zichunk_sizze_18657";
        values[6] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[7] = "isolate_core_points_6732zisegmap_16214_dim1";
        values[7] = *ctx->tuning_params.isolate_core_points_6732zisegmap_tblock_sizze_16217;
    }
    {
        names[8] = "isolate_core_points_6732zisegmap_16214zisegmap_tblock_sizze_16218";
        values[8] = *ctx->tuning_params.isolate_core_points_6732zisegmap_tblock_sizze_16217;
    }
    {
        names[9] = "isolate_core_points_6732zisegmap_16203_dim1";
        values[9] = *ctx->tuning_params.isolate_core_points_6732zisegmap_tblock_sizze_16188;
    }
    {
        names[10] = "isolate_core_points_6732zisegmap_16203zisegmap_tblock_sizze_16199";
        values[10] = *ctx->tuning_params.isolate_core_points_6732zisegmap_tblock_sizze_16188;
    }
    {
        names[11] = "isolate_core_points_6732zisegscan_16182_dim1";
        values[11] = *ctx->tuning_params.isolate_core_points_6732zisegscan_tblock_sizze_16176;
    }
    {
        names[12] = "isolate_core_points_6732zisegscan_16182zisegscan_tblock_sizze_16177";
        values[12] = *ctx->tuning_params.isolate_core_points_6732zisegscan_tblock_sizze_16176;
    }
    {
        names[13] = "isolate_core_points_6732zisegscan_16182zichunk_sizze_18657";
        values[13] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[14] = "get_num_neighbours_6842zisegmap_18390_dim1";
        values[14] = *ctx->tuning_params.get_num_neighbours_6842zisegmap_tblock_sizze_18194;
    }
    {
        names[15] = "get_num_neighbours_6842zisegmap_18390zisegmap_tblock_sizze_18386";
        values[15] = *ctx->tuning_params.get_num_neighbours_6842zisegmap_tblock_sizze_18194;
    }
    {
        names[16] = "get_num_neighbours_6842zisegred_large_18379_dim1";
        values[16] = *ctx->tuning_params.get_num_neighbours_6842zisegred_tblock_sizze_18205;
    }
    {
        names[17] = "get_num_neighbours_6842zisegred_large_18379zisegred_tblock_sizze_18373";
        values[17] = *ctx->tuning_params.get_num_neighbours_6842zisegred_tblock_sizze_18205;
    }
    {
        names[18] = "get_num_neighbours_6842zisegred_large_18379zichunk_sizze_18728";
        values[18] = (int64_t) 1;
    }
    {
        names[19] = "get_num_neighbours_6842zisegred_small_18379_dim1";
        values[19] = *ctx->tuning_params.get_num_neighbours_6842zisegred_tblock_sizze_18205;
    }
    {
        names[20] = "get_num_neighbours_6842zisegred_small_18379zisegred_tblock_sizze_18373";
        values[20] = *ctx->tuning_params.get_num_neighbours_6842zisegred_tblock_sizze_18205;
    }
    {
        names[21] = "get_num_neighbours_6842zisegmap_18360_dim1";
        values[21] = *ctx->tuning_params.get_num_neighbours_6842zisegmap_tblock_sizze_18235;
    }
    {
        names[22] = "get_num_neighbours_6842zisegmap_18360zisegmap_tblock_sizze_18355";
        values[22] = *ctx->tuning_params.get_num_neighbours_6842zisegmap_tblock_sizze_18235;
    }
    {
        names[23] = "get_num_neighbours_6842zisegmap_18347_dim1";
        values[23] = *ctx->tuning_params.get_num_neighbours_6842zisegmap_tblock_sizze_18267;
    }
    {
        names[24] = "get_num_neighbours_6842zisegmap_18347zisegmap_tblock_sizze_18341";
        values[24] = *ctx->tuning_params.get_num_neighbours_6842zisegmap_tblock_sizze_18267;
    }
    {
        names[25] = "get_num_neighbours_6842zisegmap_18136_dim1";
        values[25] = *ctx->tuning_params.get_num_neighbours_6842zisegmap_tblock_sizze_18106;
    }
    {
        names[26] = "get_num_neighbours_6842zisegmap_18136zisegmap_tblock_sizze_18132";
        values[26] = *ctx->tuning_params.get_num_neighbours_6842zisegmap_tblock_sizze_18106;
    }
    {
        names[27] = "get_num_neighbours_6695zisegmap_18089_dim1";
        values[27] = *ctx->tuning_params.get_num_neighbours_6695zisegmap_tblock_sizze_17893;
    }
    {
        names[28] = "get_num_neighbours_6695zisegmap_18089zisegmap_tblock_sizze_18085";
        values[28] = *ctx->tuning_params.get_num_neighbours_6695zisegmap_tblock_sizze_17893;
    }
    {
        names[29] = "get_num_neighbours_6695zisegred_large_18078_dim1";
        values[29] = *ctx->tuning_params.get_num_neighbours_6695zisegred_tblock_sizze_17904;
    }
    {
        names[30] = "get_num_neighbours_6695zisegred_large_18078zisegred_tblock_sizze_18072";
        values[30] = *ctx->tuning_params.get_num_neighbours_6695zisegred_tblock_sizze_17904;
    }
    {
        names[31] = "get_num_neighbours_6695zisegred_large_18078zichunk_sizze_18728";
        values[31] = (int64_t) 1;
    }
    {
        names[32] = "get_num_neighbours_6695zisegred_small_18078_dim1";
        values[32] = *ctx->tuning_params.get_num_neighbours_6695zisegred_tblock_sizze_17904;
    }
    {
        names[33] = "get_num_neighbours_6695zisegred_small_18078zisegred_tblock_sizze_18072";
        values[33] = *ctx->tuning_params.get_num_neighbours_6695zisegred_tblock_sizze_17904;
    }
    {
        names[34] = "get_num_neighbours_6695zisegmap_18059_dim1";
        values[34] = *ctx->tuning_params.get_num_neighbours_6695zisegmap_tblock_sizze_17934;
    }
    {
        names[35] = "get_num_neighbours_6695zisegmap_18059zisegmap_tblock_sizze_18054";
        values[35] = *ctx->tuning_params.get_num_neighbours_6695zisegmap_tblock_sizze_17934;
    }
    {
        names[36] = "get_num_neighbours_6695zisegmap_18046_dim1";
        values[36] = *ctx->tuning_params.get_num_neighbours_6695zisegmap_tblock_sizze_17966;
    }
    {
        names[37] = "get_num_neighbours_6695zisegmap_18046zisegmap_tblock_sizze_18040";
        values[37] = *ctx->tuning_params.get_num_neighbours_6695zisegmap_tblock_sizze_17966;
    }
    {
        names[38] = "get_num_neighbours_6695zisegmap_17835_dim1";
        values[38] = *ctx->tuning_params.get_num_neighbours_6695zisegmap_tblock_sizze_17805;
    }
    {
        names[39] = "get_num_neighbours_6695zisegmap_17835zisegmap_tblock_sizze_17831";
        values[39] = *ctx->tuning_params.get_num_neighbours_6695zisegmap_tblock_sizze_17805;
    }
    {
        names[40] = "find_cluster_ids_6890zisegmap_17035_dim1";
        values[40] = *ctx->tuning_params.find_cluster_ids_6890zisegmap_tblock_sizze_17014;
    }
    {
        names[41] = "find_cluster_ids_6890zisegmap_17035zisegmap_tblock_sizze_17031";
        values[41] = *ctx->tuning_params.find_cluster_ids_6890zisegmap_tblock_sizze_17014;
    }
    {
        names[42] = "find_cluster_ids_6890zisegmap_17004_dim1";
        values[42] = *ctx->tuning_params.find_cluster_ids_6890zisegmap_tblock_sizze_16988;
    }
    {
        names[43] = "find_cluster_ids_6890zisegmap_17004zisegmap_tblock_sizze_17000";
        values[43] = *ctx->tuning_params.find_cluster_ids_6890zisegmap_tblock_sizze_16988;
    }
    {
        names[44] = "find_cluster_ids_6890zisegscan_16984_dim1";
        values[44] = *ctx->tuning_params.find_cluster_ids_6890zisegscan_tblock_sizze_16978;
    }
    {
        names[45] = "find_cluster_ids_6890zisegscan_16984zisegscan_tblock_sizze_16979";
        values[45] = *ctx->tuning_params.find_cluster_ids_6890zisegscan_tblock_sizze_16978;
    }
    {
        names[46] = "find_cluster_ids_6890zisegscan_16984zichunk_sizze_18863";
        values[46] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[47] = "find_cluster_ids_6890zisegred_nonseg_16976_dim1";
        values[47] = *ctx->tuning_params.find_cluster_ids_6890zisegred_tblock_sizze_16968;
    }
    {
        names[48] = "find_cluster_ids_6890zisegred_nonseg_16976zisegred_tblock_sizze_16969";
        values[48] = *ctx->tuning_params.find_cluster_ids_6890zisegred_tblock_sizze_16968;
    }
    {
        names[49] = "find_cluster_ids_6890zisegred_nonseg_16976zichunk_sizze_18824";
        values[49] = (int64_t) 1;
    }
    {
        names[50] = "find_cluster_ids_6890zisegred_large_16959_dim1";
        values[50] = *ctx->tuning_params.find_cluster_ids_6890zisegred_tblock_sizze_16779;
    }
    {
        names[51] = "find_cluster_ids_6890zisegred_large_16959zisegred_tblock_sizze_16953";
        values[51] = *ctx->tuning_params.find_cluster_ids_6890zisegred_tblock_sizze_16779;
    }
    {
        names[52] = "find_cluster_ids_6890zisegred_large_16959zichunk_sizze_18730";
        values[52] = (int64_t) 1;
    }
    {
        names[53] = "find_cluster_ids_6890zisegred_small_16959_dim1";
        values[53] = *ctx->tuning_params.find_cluster_ids_6890zisegred_tblock_sizze_16779;
    }
    {
        names[54] = "find_cluster_ids_6890zisegred_small_16959zisegred_tblock_sizze_16953";
        values[54] = *ctx->tuning_params.find_cluster_ids_6890zisegred_tblock_sizze_16779;
    }
    {
        names[55] = "find_cluster_ids_6890zisegmap_16938_dim1";
        values[55] = *ctx->tuning_params.find_cluster_ids_6890zisegmap_tblock_sizze_16809;
    }
    {
        names[56] = "find_cluster_ids_6890zisegmap_16938zisegmap_tblock_sizze_16933";
        values[56] = *ctx->tuning_params.find_cluster_ids_6890zisegmap_tblock_sizze_16809;
    }
    {
        names[57] = "find_cluster_ids_6890zisegmap_16925_dim1";
        values[57] = *ctx->tuning_params.find_cluster_ids_6890zisegmap_tblock_sizze_16843;
    }
    {
        names[58] = "find_cluster_ids_6890zisegmap_16925zisegmap_tblock_sizze_16919";
        values[58] = *ctx->tuning_params.find_cluster_ids_6890zisegmap_tblock_sizze_16843;
    }
    {
        names[59] = "find_cluster_ids_6890zisegmap_16719_dim1";
        values[59] = *ctx->tuning_params.find_cluster_ids_6890zisegmap_tblock_sizze_16688;
    }
    {
        names[60] = "find_cluster_ids_6890zisegmap_16719zisegmap_tblock_sizze_16715";
        values[60] = *ctx->tuning_params.find_cluster_ids_6890zisegmap_tblock_sizze_16688;
    }
    {
        names[61] = "find_cluster_ids_6783zisegmap_16664_dim1";
        values[61] = *ctx->tuning_params.find_cluster_ids_6783zisegmap_tblock_sizze_16643;
    }
    {
        names[62] = "find_cluster_ids_6783zisegmap_16664zisegmap_tblock_sizze_16660";
        values[62] = *ctx->tuning_params.find_cluster_ids_6783zisegmap_tblock_sizze_16643;
    }
    {
        names[63] = "find_cluster_ids_6783zisegmap_16633_dim1";
        values[63] = *ctx->tuning_params.find_cluster_ids_6783zisegmap_tblock_sizze_16617;
    }
    {
        names[64] = "find_cluster_ids_6783zisegmap_16633zisegmap_tblock_sizze_16629";
        values[64] = *ctx->tuning_params.find_cluster_ids_6783zisegmap_tblock_sizze_16617;
    }
    {
        names[65] = "find_cluster_ids_6783zisegscan_16613_dim1";
        values[65] = *ctx->tuning_params.find_cluster_ids_6783zisegscan_tblock_sizze_16607;
    }
    {
        names[66] = "find_cluster_ids_6783zisegscan_16613zisegscan_tblock_sizze_16608";
        values[66] = *ctx->tuning_params.find_cluster_ids_6783zisegscan_tblock_sizze_16607;
    }
    {
        names[67] = "find_cluster_ids_6783zisegscan_16613zichunk_sizze_18863";
        values[67] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[68] = "find_cluster_ids_6783zisegred_nonseg_16605_dim1";
        values[68] = *ctx->tuning_params.find_cluster_ids_6783zisegred_tblock_sizze_16597;
    }
    {
        names[69] = "find_cluster_ids_6783zisegred_nonseg_16605zisegred_tblock_sizze_16598";
        values[69] = *ctx->tuning_params.find_cluster_ids_6783zisegred_tblock_sizze_16597;
    }
    {
        names[70] = "find_cluster_ids_6783zisegred_nonseg_16605zichunk_sizze_18824";
        values[70] = (int64_t) 1;
    }
    {
        names[71] = "find_cluster_ids_6783zisegred_large_16588_dim1";
        values[71] = *ctx->tuning_params.find_cluster_ids_6783zisegred_tblock_sizze_16408;
    }
    {
        names[72] = "find_cluster_ids_6783zisegred_large_16588zisegred_tblock_sizze_16582";
        values[72] = *ctx->tuning_params.find_cluster_ids_6783zisegred_tblock_sizze_16408;
    }
    {
        names[73] = "find_cluster_ids_6783zisegred_large_16588zichunk_sizze_18730";
        values[73] = (int64_t) 1;
    }
    {
        names[74] = "find_cluster_ids_6783zisegred_small_16588_dim1";
        values[74] = *ctx->tuning_params.find_cluster_ids_6783zisegred_tblock_sizze_16408;
    }
    {
        names[75] = "find_cluster_ids_6783zisegred_small_16588zisegred_tblock_sizze_16582";
        values[75] = *ctx->tuning_params.find_cluster_ids_6783zisegred_tblock_sizze_16408;
    }
    {
        names[76] = "find_cluster_ids_6783zisegmap_16567_dim1";
        values[76] = *ctx->tuning_params.find_cluster_ids_6783zisegmap_tblock_sizze_16438;
    }
    {
        names[77] = "find_cluster_ids_6783zisegmap_16567zisegmap_tblock_sizze_16562";
        values[77] = *ctx->tuning_params.find_cluster_ids_6783zisegmap_tblock_sizze_16438;
    }
    {
        names[78] = "find_cluster_ids_6783zisegmap_16554_dim1";
        values[78] = *ctx->tuning_params.find_cluster_ids_6783zisegmap_tblock_sizze_16472;
    }
    {
        names[79] = "find_cluster_ids_6783zisegmap_16554zisegmap_tblock_sizze_16548";
        values[79] = *ctx->tuning_params.find_cluster_ids_6783zisegmap_tblock_sizze_16472;
    }
    {
        names[80] = "find_cluster_ids_6783zisegmap_16348_dim1";
        values[80] = *ctx->tuning_params.find_cluster_ids_6783zisegmap_tblock_sizze_16317;
    }
    {
        names[81] = "find_cluster_ids_6783zisegmap_16348zisegmap_tblock_sizze_16344";
        values[81] = *ctx->tuning_params.find_cluster_ids_6783zisegmap_tblock_sizze_16317;
    }
    {
        names[82] = "ftDBSCAN_star_floatzisegmap_16284_dim1";
        values[82] = *ctx->tuning_params.ftDBSCAN_star_floatzisegmap_tblock_sizze_16272;
    }
    {
        names[83] = "ftDBSCAN_star_floatzisegmap_16284zisegmap_tblock_sizze_16280";
        values[83] = *ctx->tuning_params.ftDBSCAN_star_floatzisegmap_tblock_sizze_16272;
    }
    {
        names[84] = "ftDBSCAN_star_doublezisegmap_16302_dim1";
        values[84] = *ctx->tuning_params.ftDBSCAN_star_doublezisegmap_tblock_sizze_16290;
    }
    {
        names[85] = "ftDBSCAN_star_doublezisegmap_16302zisegmap_tblock_sizze_16298";
        values[85] = *ctx->tuning_params.ftDBSCAN_star_doublezisegmap_tblock_sizze_16290;
    }
    {
        names[86] = "ftDBSCAN_floatzisegred_large_17401_dim1";
        values[86] = *ctx->tuning_params.ftDBSCAN_floatzisegred_tblock_sizze_17193;
    }
    {
        names[87] = "ftDBSCAN_floatzisegred_large_17401zisegred_tblock_sizze_17394";
        values[87] = *ctx->tuning_params.ftDBSCAN_floatzisegred_tblock_sizze_17193;
    }
    {
        names[88] = "ftDBSCAN_floatzisegred_large_17401zichunk_sizze_18740";
        values[88] = (int64_t) 1;
    }
    {
        names[89] = "ftDBSCAN_floatzisegred_small_17401_dim1";
        values[89] = *ctx->tuning_params.ftDBSCAN_floatzisegred_tblock_sizze_17193;
    }
    {
        names[90] = "ftDBSCAN_floatzisegred_small_17401zisegred_tblock_sizze_17394";
        values[90] = *ctx->tuning_params.ftDBSCAN_floatzisegred_tblock_sizze_17193;
    }
    {
        names[91] = "ftDBSCAN_floatzisegmap_17382_dim1";
        values[91] = *ctx->tuning_params.ftDBSCAN_floatzisegmap_tblock_sizze_17234;
    }
    {
        names[92] = "ftDBSCAN_floatzisegmap_17382zisegmap_tblock_sizze_17377";
        values[92] = *ctx->tuning_params.ftDBSCAN_floatzisegmap_tblock_sizze_17234;
    }
    {
        names[93] = "ftDBSCAN_floatzisegmap_17369_dim1";
        values[93] = *ctx->tuning_params.ftDBSCAN_floatzisegmap_tblock_sizze_17264;
    }
    {
        names[94] = "ftDBSCAN_floatzisegmap_17369zisegmap_tblock_sizze_17363";
        values[94] = *ctx->tuning_params.ftDBSCAN_floatzisegmap_tblock_sizze_17264;
    }
    {
        names[95] = "ftDBSCAN_floatzisegmap_17115_dim1";
        values[95] = *ctx->tuning_params.ftDBSCAN_floatzisegmap_tblock_sizze_17077;
    }
    {
        names[96] = "ftDBSCAN_floatzisegmap_17115zisegmap_tblock_sizze_17111";
        values[96] = *ctx->tuning_params.ftDBSCAN_floatzisegmap_tblock_sizze_17077;
    }
    {
        names[97] = "ftDBSCAN_floatzisegmap_17062_dim1";
        values[97] = *ctx->tuning_params.ftDBSCAN_floatzisegmap_tblock_sizze_17050;
    }
    {
        names[98] = "ftDBSCAN_floatzisegmap_17062zisegmap_tblock_sizze_17058";
        values[98] = *ctx->tuning_params.ftDBSCAN_floatzisegmap_tblock_sizze_17050;
    }
    {
        names[99] = "ftDBSCAN_doublezisegred_large_17774_dim1";
        values[99] = *ctx->tuning_params.ftDBSCAN_doublezisegred_tblock_sizze_17566;
    }
    {
        names[100] = "ftDBSCAN_doublezisegred_large_17774zisegred_tblock_sizze_17767";
        values[100] = *ctx->tuning_params.ftDBSCAN_doublezisegred_tblock_sizze_17566;
    }
    {
        names[101] = "ftDBSCAN_doublezisegred_large_17774zichunk_sizze_18740";
        values[101] = (int64_t) 1;
    }
    {
        names[102] = "ftDBSCAN_doublezisegred_small_17774_dim1";
        values[102] = *ctx->tuning_params.ftDBSCAN_doublezisegred_tblock_sizze_17566;
    }
    {
        names[103] = "ftDBSCAN_doublezisegred_small_17774zisegred_tblock_sizze_17767";
        values[103] = *ctx->tuning_params.ftDBSCAN_doublezisegred_tblock_sizze_17566;
    }
    {
        names[104] = "ftDBSCAN_doublezisegmap_17755_dim1";
        values[104] = *ctx->tuning_params.ftDBSCAN_doublezisegmap_tblock_sizze_17607;
    }
    {
        names[105] = "ftDBSCAN_doublezisegmap_17755zisegmap_tblock_sizze_17750";
        values[105] = *ctx->tuning_params.ftDBSCAN_doublezisegmap_tblock_sizze_17607;
    }
    {
        names[106] = "ftDBSCAN_doublezisegmap_17742_dim1";
        values[106] = *ctx->tuning_params.ftDBSCAN_doublezisegmap_tblock_sizze_17637;
    }
    {
        names[107] = "ftDBSCAN_doublezisegmap_17742zisegmap_tblock_sizze_17736";
        values[107] = *ctx->tuning_params.ftDBSCAN_doublezisegmap_tblock_sizze_17637;
    }
    {
        names[108] = "ftDBSCAN_doublezisegmap_17488_dim1";
        values[108] = *ctx->tuning_params.ftDBSCAN_doublezisegmap_tblock_sizze_17450;
    }
    {
        names[109] = "ftDBSCAN_doublezisegmap_17488zisegmap_tblock_sizze_17484";
        values[109] = *ctx->tuning_params.ftDBSCAN_doublezisegmap_tblock_sizze_17450;
    }
    {
        names[110] = "ftDBSCAN_doublezisegmap_17435_dim1";
        values[110] = *ctx->tuning_params.ftDBSCAN_doublezisegmap_tblock_sizze_17423;
    }
    {
        names[111] = "ftDBSCAN_doublezisegmap_17435zisegmap_tblock_sizze_17431";
        values[111] = *ctx->tuning_params.ftDBSCAN_doublezisegmap_tblock_sizze_17423;
    }
    *names_out = names;
    *values_out = values;
    return num_macros;
}
static char *get_failure_msg(int failure_idx, int64_t args[])
{
    (void) args;
    switch (failure_idx) {
        
      case 0:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ft_libs/ftbasics.fut:35:14-19\n   #1  /prelude/functional.fut:9:44-45\n   #2  ft_libs/ftbasics.fut:33:10-37:8\n", args[0], args[1]);
            break;
        }
        
      case 1:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ft_libs/ftbasics.fut:35:14-19\n   #1  /prelude/functional.fut:9:44-45\n   #2  ft_libs/ftbasics.fut:33:10-37:8\n", args[0], args[1]);
            break;
        }
    }
    return strdup("Unknown error.  This is a compiler bug.");
}
struct program {
    int dummy;
    gpu_kernel builtinzhiota_i64ziiota_i64_18656;
    gpu_kernel builtinzhreplicate_i32zireplicate_18770;
    gpu_kernel builtinzhreplicate_i64zireplicate_18656;
    gpu_kernel builtinzhreplicate_i8zireplicate_18873;
    gpu_kernel find_cluster_ids_6783zisegmap_16348;
    gpu_kernel find_cluster_ids_6783zisegmap_16554;
    gpu_kernel find_cluster_ids_6783zisegmap_16567;
    gpu_kernel find_cluster_ids_6783zisegmap_16633;
    gpu_kernel find_cluster_ids_6783zisegmap_16664;
    gpu_kernel find_cluster_ids_6783zisegmap_intrablock_16377;
    gpu_kernel find_cluster_ids_6783zisegred_large_16588;
    gpu_kernel find_cluster_ids_6783zisegred_nonseg_16605;
    gpu_kernel find_cluster_ids_6783zisegred_small_16588;
    gpu_kernel find_cluster_ids_6783zisegscan_16613;
    gpu_kernel find_cluster_ids_6890zisegmap_16719;
    gpu_kernel find_cluster_ids_6890zisegmap_16925;
    gpu_kernel find_cluster_ids_6890zisegmap_16938;
    gpu_kernel find_cluster_ids_6890zisegmap_17004;
    gpu_kernel find_cluster_ids_6890zisegmap_17035;
    gpu_kernel find_cluster_ids_6890zisegmap_intrablock_16748;
    gpu_kernel find_cluster_ids_6890zisegred_large_16959;
    gpu_kernel find_cluster_ids_6890zisegred_nonseg_16976;
    gpu_kernel find_cluster_ids_6890zisegred_small_16959;
    gpu_kernel find_cluster_ids_6890zisegscan_16984;
    gpu_kernel ftDBSCAN_doublezisegmap_17435;
    gpu_kernel ftDBSCAN_doublezisegmap_17488;
    gpu_kernel ftDBSCAN_doublezisegmap_17742;
    gpu_kernel ftDBSCAN_doublezisegmap_17755;
    gpu_kernel ftDBSCAN_doublezisegmap_intrablock_17524;
    gpu_kernel ftDBSCAN_doublezisegred_large_17774;
    gpu_kernel ftDBSCAN_doublezisegred_small_17774;
    gpu_kernel ftDBSCAN_floatzisegmap_17062;
    gpu_kernel ftDBSCAN_floatzisegmap_17115;
    gpu_kernel ftDBSCAN_floatzisegmap_17369;
    gpu_kernel ftDBSCAN_floatzisegmap_17382;
    gpu_kernel ftDBSCAN_floatzisegmap_intrablock_17151;
    gpu_kernel ftDBSCAN_floatzisegred_large_17401;
    gpu_kernel ftDBSCAN_floatzisegred_small_17401;
    gpu_kernel ftDBSCAN_star_doublezisegmap_16302;
    gpu_kernel ftDBSCAN_star_floatzisegmap_16284;
    gpu_kernel get_num_neighbours_6695zisegmap_17835;
    gpu_kernel get_num_neighbours_6695zisegmap_18046;
    gpu_kernel get_num_neighbours_6695zisegmap_18059;
    gpu_kernel get_num_neighbours_6695zisegmap_18089;
    gpu_kernel get_num_neighbours_6695zisegmap_intrablock_17863;
    gpu_kernel get_num_neighbours_6695zisegred_large_18078;
    gpu_kernel get_num_neighbours_6695zisegred_small_18078;
    gpu_kernel get_num_neighbours_6842zisegmap_18136;
    gpu_kernel get_num_neighbours_6842zisegmap_18347;
    gpu_kernel get_num_neighbours_6842zisegmap_18360;
    gpu_kernel get_num_neighbours_6842zisegmap_18390;
    gpu_kernel get_num_neighbours_6842zisegmap_intrablock_18164;
    gpu_kernel get_num_neighbours_6842zisegred_large_18379;
    gpu_kernel get_num_neighbours_6842zisegred_small_18379;
    gpu_kernel isolate_core_points_6732zisegmap_16203;
    gpu_kernel isolate_core_points_6732zisegmap_16214;
    gpu_kernel isolate_core_points_6732zisegscan_16182;
    gpu_kernel isolate_core_points_6871zisegmap_16250;
    gpu_kernel isolate_core_points_6871zisegmap_16261;
    gpu_kernel isolate_core_points_6871zisegscan_16229;
};
static void setup_program(struct futhark_context *ctx)
{
    (void) ctx;
    
    int error = 0;
    
    (void) error;
    ctx->program = malloc(sizeof(struct program));
    gpu_create_kernel(ctx, &ctx->program->builtinzhiota_i64ziiota_i64_18656, "builtinzhiota_i64ziiota_i64_18656");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_i32zireplicate_18770, "builtinzhreplicate_i32zireplicate_18770");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_i64zireplicate_18656, "builtinzhreplicate_i64zireplicate_18656");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_i8zireplicate_18873, "builtinzhreplicate_i8zireplicate_18873");
    gpu_create_kernel(ctx, &ctx->program->find_cluster_ids_6783zisegmap_16348, "find_cluster_ids_6783zisegmap_16348");
    gpu_create_kernel(ctx, &ctx->program->find_cluster_ids_6783zisegmap_16554, "find_cluster_ids_6783zisegmap_16554");
    gpu_create_kernel(ctx, &ctx->program->find_cluster_ids_6783zisegmap_16567, "find_cluster_ids_6783zisegmap_16567");
    gpu_create_kernel(ctx, &ctx->program->find_cluster_ids_6783zisegmap_16633, "find_cluster_ids_6783zisegmap_16633");
    gpu_create_kernel(ctx, &ctx->program->find_cluster_ids_6783zisegmap_16664, "find_cluster_ids_6783zisegmap_16664");
    gpu_create_kernel(ctx, &ctx->program->find_cluster_ids_6783zisegmap_intrablock_16377, "find_cluster_ids_6783zisegmap_intrablock_16377");
    gpu_create_kernel(ctx, &ctx->program->find_cluster_ids_6783zisegred_large_16588, "find_cluster_ids_6783zisegred_large_16588");
    gpu_create_kernel(ctx, &ctx->program->find_cluster_ids_6783zisegred_nonseg_16605, "find_cluster_ids_6783zisegred_nonseg_16605");
    gpu_create_kernel(ctx, &ctx->program->find_cluster_ids_6783zisegred_small_16588, "find_cluster_ids_6783zisegred_small_16588");
    gpu_create_kernel(ctx, &ctx->program->find_cluster_ids_6783zisegscan_16613, "find_cluster_ids_6783zisegscan_16613");
    gpu_create_kernel(ctx, &ctx->program->find_cluster_ids_6890zisegmap_16719, "find_cluster_ids_6890zisegmap_16719");
    gpu_create_kernel(ctx, &ctx->program->find_cluster_ids_6890zisegmap_16925, "find_cluster_ids_6890zisegmap_16925");
    gpu_create_kernel(ctx, &ctx->program->find_cluster_ids_6890zisegmap_16938, "find_cluster_ids_6890zisegmap_16938");
    gpu_create_kernel(ctx, &ctx->program->find_cluster_ids_6890zisegmap_17004, "find_cluster_ids_6890zisegmap_17004");
    gpu_create_kernel(ctx, &ctx->program->find_cluster_ids_6890zisegmap_17035, "find_cluster_ids_6890zisegmap_17035");
    gpu_create_kernel(ctx, &ctx->program->find_cluster_ids_6890zisegmap_intrablock_16748, "find_cluster_ids_6890zisegmap_intrablock_16748");
    gpu_create_kernel(ctx, &ctx->program->find_cluster_ids_6890zisegred_large_16959, "find_cluster_ids_6890zisegred_large_16959");
    gpu_create_kernel(ctx, &ctx->program->find_cluster_ids_6890zisegred_nonseg_16976, "find_cluster_ids_6890zisegred_nonseg_16976");
    gpu_create_kernel(ctx, &ctx->program->find_cluster_ids_6890zisegred_small_16959, "find_cluster_ids_6890zisegred_small_16959");
    gpu_create_kernel(ctx, &ctx->program->find_cluster_ids_6890zisegscan_16984, "find_cluster_ids_6890zisegscan_16984");
    gpu_create_kernel(ctx, &ctx->program->ftDBSCAN_doublezisegmap_17435, "ftDBSCAN_doublezisegmap_17435");
    gpu_create_kernel(ctx, &ctx->program->ftDBSCAN_doublezisegmap_17488, "ftDBSCAN_doublezisegmap_17488");
    gpu_create_kernel(ctx, &ctx->program->ftDBSCAN_doublezisegmap_17742, "ftDBSCAN_doublezisegmap_17742");
    gpu_create_kernel(ctx, &ctx->program->ftDBSCAN_doublezisegmap_17755, "ftDBSCAN_doublezisegmap_17755");
    gpu_create_kernel(ctx, &ctx->program->ftDBSCAN_doublezisegmap_intrablock_17524, "ftDBSCAN_doublezisegmap_intrablock_17524");
    gpu_create_kernel(ctx, &ctx->program->ftDBSCAN_doublezisegred_large_17774, "ftDBSCAN_doublezisegred_large_17774");
    gpu_create_kernel(ctx, &ctx->program->ftDBSCAN_doublezisegred_small_17774, "ftDBSCAN_doublezisegred_small_17774");
    gpu_create_kernel(ctx, &ctx->program->ftDBSCAN_floatzisegmap_17062, "ftDBSCAN_floatzisegmap_17062");
    gpu_create_kernel(ctx, &ctx->program->ftDBSCAN_floatzisegmap_17115, "ftDBSCAN_floatzisegmap_17115");
    gpu_create_kernel(ctx, &ctx->program->ftDBSCAN_floatzisegmap_17369, "ftDBSCAN_floatzisegmap_17369");
    gpu_create_kernel(ctx, &ctx->program->ftDBSCAN_floatzisegmap_17382, "ftDBSCAN_floatzisegmap_17382");
    gpu_create_kernel(ctx, &ctx->program->ftDBSCAN_floatzisegmap_intrablock_17151, "ftDBSCAN_floatzisegmap_intrablock_17151");
    gpu_create_kernel(ctx, &ctx->program->ftDBSCAN_floatzisegred_large_17401, "ftDBSCAN_floatzisegred_large_17401");
    gpu_create_kernel(ctx, &ctx->program->ftDBSCAN_floatzisegred_small_17401, "ftDBSCAN_floatzisegred_small_17401");
    gpu_create_kernel(ctx, &ctx->program->ftDBSCAN_star_doublezisegmap_16302, "ftDBSCAN_star_doublezisegmap_16302");
    gpu_create_kernel(ctx, &ctx->program->ftDBSCAN_star_floatzisegmap_16284, "ftDBSCAN_star_floatzisegmap_16284");
    gpu_create_kernel(ctx, &ctx->program->get_num_neighbours_6695zisegmap_17835, "get_num_neighbours_6695zisegmap_17835");
    gpu_create_kernel(ctx, &ctx->program->get_num_neighbours_6695zisegmap_18046, "get_num_neighbours_6695zisegmap_18046");
    gpu_create_kernel(ctx, &ctx->program->get_num_neighbours_6695zisegmap_18059, "get_num_neighbours_6695zisegmap_18059");
    gpu_create_kernel(ctx, &ctx->program->get_num_neighbours_6695zisegmap_18089, "get_num_neighbours_6695zisegmap_18089");
    gpu_create_kernel(ctx, &ctx->program->get_num_neighbours_6695zisegmap_intrablock_17863, "get_num_neighbours_6695zisegmap_intrablock_17863");
    gpu_create_kernel(ctx, &ctx->program->get_num_neighbours_6695zisegred_large_18078, "get_num_neighbours_6695zisegred_large_18078");
    gpu_create_kernel(ctx, &ctx->program->get_num_neighbours_6695zisegred_small_18078, "get_num_neighbours_6695zisegred_small_18078");
    gpu_create_kernel(ctx, &ctx->program->get_num_neighbours_6842zisegmap_18136, "get_num_neighbours_6842zisegmap_18136");
    gpu_create_kernel(ctx, &ctx->program->get_num_neighbours_6842zisegmap_18347, "get_num_neighbours_6842zisegmap_18347");
    gpu_create_kernel(ctx, &ctx->program->get_num_neighbours_6842zisegmap_18360, "get_num_neighbours_6842zisegmap_18360");
    gpu_create_kernel(ctx, &ctx->program->get_num_neighbours_6842zisegmap_18390, "get_num_neighbours_6842zisegmap_18390");
    gpu_create_kernel(ctx, &ctx->program->get_num_neighbours_6842zisegmap_intrablock_18164, "get_num_neighbours_6842zisegmap_intrablock_18164");
    gpu_create_kernel(ctx, &ctx->program->get_num_neighbours_6842zisegred_large_18379, "get_num_neighbours_6842zisegred_large_18379");
    gpu_create_kernel(ctx, &ctx->program->get_num_neighbours_6842zisegred_small_18379, "get_num_neighbours_6842zisegred_small_18379");
    gpu_create_kernel(ctx, &ctx->program->isolate_core_points_6732zisegmap_16203, "isolate_core_points_6732zisegmap_16203");
    gpu_create_kernel(ctx, &ctx->program->isolate_core_points_6732zisegmap_16214, "isolate_core_points_6732zisegmap_16214");
    gpu_create_kernel(ctx, &ctx->program->isolate_core_points_6732zisegscan_16182, "isolate_core_points_6732zisegscan_16182");
    gpu_create_kernel(ctx, &ctx->program->isolate_core_points_6871zisegmap_16250, "isolate_core_points_6871zisegmap_16250");
    gpu_create_kernel(ctx, &ctx->program->isolate_core_points_6871zisegmap_16261, "isolate_core_points_6871zisegmap_16261");
    gpu_create_kernel(ctx, &ctx->program->isolate_core_points_6871zisegscan_16229, "isolate_core_points_6871zisegscan_16229");
}
static void teardown_program(struct futhark_context *ctx)
{
    (void) ctx;
    
    int error = 0;
    
    (void) error;
    gpu_free_kernel(ctx, ctx->program->builtinzhiota_i64ziiota_i64_18656);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_i32zireplicate_18770);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_i64zireplicate_18656);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_i8zireplicate_18873);
    gpu_free_kernel(ctx, ctx->program->find_cluster_ids_6783zisegmap_16348);
    gpu_free_kernel(ctx, ctx->program->find_cluster_ids_6783zisegmap_16554);
    gpu_free_kernel(ctx, ctx->program->find_cluster_ids_6783zisegmap_16567);
    gpu_free_kernel(ctx, ctx->program->find_cluster_ids_6783zisegmap_16633);
    gpu_free_kernel(ctx, ctx->program->find_cluster_ids_6783zisegmap_16664);
    gpu_free_kernel(ctx, ctx->program->find_cluster_ids_6783zisegmap_intrablock_16377);
    gpu_free_kernel(ctx, ctx->program->find_cluster_ids_6783zisegred_large_16588);
    gpu_free_kernel(ctx, ctx->program->find_cluster_ids_6783zisegred_nonseg_16605);
    gpu_free_kernel(ctx, ctx->program->find_cluster_ids_6783zisegred_small_16588);
    gpu_free_kernel(ctx, ctx->program->find_cluster_ids_6783zisegscan_16613);
    gpu_free_kernel(ctx, ctx->program->find_cluster_ids_6890zisegmap_16719);
    gpu_free_kernel(ctx, ctx->program->find_cluster_ids_6890zisegmap_16925);
    gpu_free_kernel(ctx, ctx->program->find_cluster_ids_6890zisegmap_16938);
    gpu_free_kernel(ctx, ctx->program->find_cluster_ids_6890zisegmap_17004);
    gpu_free_kernel(ctx, ctx->program->find_cluster_ids_6890zisegmap_17035);
    gpu_free_kernel(ctx, ctx->program->find_cluster_ids_6890zisegmap_intrablock_16748);
    gpu_free_kernel(ctx, ctx->program->find_cluster_ids_6890zisegred_large_16959);
    gpu_free_kernel(ctx, ctx->program->find_cluster_ids_6890zisegred_nonseg_16976);
    gpu_free_kernel(ctx, ctx->program->find_cluster_ids_6890zisegred_small_16959);
    gpu_free_kernel(ctx, ctx->program->find_cluster_ids_6890zisegscan_16984);
    gpu_free_kernel(ctx, ctx->program->ftDBSCAN_doublezisegmap_17435);
    gpu_free_kernel(ctx, ctx->program->ftDBSCAN_doublezisegmap_17488);
    gpu_free_kernel(ctx, ctx->program->ftDBSCAN_doublezisegmap_17742);
    gpu_free_kernel(ctx, ctx->program->ftDBSCAN_doublezisegmap_17755);
    gpu_free_kernel(ctx, ctx->program->ftDBSCAN_doublezisegmap_intrablock_17524);
    gpu_free_kernel(ctx, ctx->program->ftDBSCAN_doublezisegred_large_17774);
    gpu_free_kernel(ctx, ctx->program->ftDBSCAN_doublezisegred_small_17774);
    gpu_free_kernel(ctx, ctx->program->ftDBSCAN_floatzisegmap_17062);
    gpu_free_kernel(ctx, ctx->program->ftDBSCAN_floatzisegmap_17115);
    gpu_free_kernel(ctx, ctx->program->ftDBSCAN_floatzisegmap_17369);
    gpu_free_kernel(ctx, ctx->program->ftDBSCAN_floatzisegmap_17382);
    gpu_free_kernel(ctx, ctx->program->ftDBSCAN_floatzisegmap_intrablock_17151);
    gpu_free_kernel(ctx, ctx->program->ftDBSCAN_floatzisegred_large_17401);
    gpu_free_kernel(ctx, ctx->program->ftDBSCAN_floatzisegred_small_17401);
    gpu_free_kernel(ctx, ctx->program->ftDBSCAN_star_doublezisegmap_16302);
    gpu_free_kernel(ctx, ctx->program->ftDBSCAN_star_floatzisegmap_16284);
    gpu_free_kernel(ctx, ctx->program->get_num_neighbours_6695zisegmap_17835);
    gpu_free_kernel(ctx, ctx->program->get_num_neighbours_6695zisegmap_18046);
    gpu_free_kernel(ctx, ctx->program->get_num_neighbours_6695zisegmap_18059);
    gpu_free_kernel(ctx, ctx->program->get_num_neighbours_6695zisegmap_18089);
    gpu_free_kernel(ctx, ctx->program->get_num_neighbours_6695zisegmap_intrablock_17863);
    gpu_free_kernel(ctx, ctx->program->get_num_neighbours_6695zisegred_large_18078);
    gpu_free_kernel(ctx, ctx->program->get_num_neighbours_6695zisegred_small_18078);
    gpu_free_kernel(ctx, ctx->program->get_num_neighbours_6842zisegmap_18136);
    gpu_free_kernel(ctx, ctx->program->get_num_neighbours_6842zisegmap_18347);
    gpu_free_kernel(ctx, ctx->program->get_num_neighbours_6842zisegmap_18360);
    gpu_free_kernel(ctx, ctx->program->get_num_neighbours_6842zisegmap_18390);
    gpu_free_kernel(ctx, ctx->program->get_num_neighbours_6842zisegmap_intrablock_18164);
    gpu_free_kernel(ctx, ctx->program->get_num_neighbours_6842zisegred_large_18379);
    gpu_free_kernel(ctx, ctx->program->get_num_neighbours_6842zisegred_small_18379);
    gpu_free_kernel(ctx, ctx->program->isolate_core_points_6732zisegmap_16203);
    gpu_free_kernel(ctx, ctx->program->isolate_core_points_6732zisegmap_16214);
    gpu_free_kernel(ctx, ctx->program->isolate_core_points_6732zisegscan_16182);
    gpu_free_kernel(ctx, ctx->program->isolate_core_points_6871zisegmap_16250);
    gpu_free_kernel(ctx, ctx->program->isolate_core_points_6871zisegmap_16261);
    gpu_free_kernel(ctx, ctx->program->isolate_core_points_6871zisegscan_16229);
    free(ctx->program);
}
static void set_tuning_params(struct futhark_context *ctx)
{
    (void) ctx;
    ctx->tuning_params.builtinzhiota_i64zitblock_sizze_18660 = &ctx->cfg->tuning_params[0];
    ctx->tuning_params.builtinzhreplicate_i32zitblock_sizze_18774 = &ctx->cfg->tuning_params[1];
    ctx->tuning_params.builtinzhreplicate_i64zitblock_sizze_18660 = &ctx->cfg->tuning_params[2];
    ctx->tuning_params.builtinzhreplicate_i8zitblock_sizze_18877 = &ctx->cfg->tuning_params[3];
    ctx->tuning_params.find_cluster_ids_6783zisegmap_tblock_sizze_16317 = &ctx->cfg->tuning_params[4];
    ctx->tuning_params.find_cluster_ids_6783zisegmap_tblock_sizze_16438 = &ctx->cfg->tuning_params[5];
    ctx->tuning_params.find_cluster_ids_6783zisegmap_tblock_sizze_16472 = &ctx->cfg->tuning_params[6];
    ctx->tuning_params.find_cluster_ids_6783zisegmap_tblock_sizze_16617 = &ctx->cfg->tuning_params[7];
    ctx->tuning_params.find_cluster_ids_6783zisegmap_tblock_sizze_16643 = &ctx->cfg->tuning_params[8];
    ctx->tuning_params.find_cluster_ids_6783zisegred_num_tblocks_16410 = &ctx->cfg->tuning_params[9];
    ctx->tuning_params.find_cluster_ids_6783zisegred_num_tblocks_16599 = &ctx->cfg->tuning_params[10];
    ctx->tuning_params.find_cluster_ids_6783zisegred_tblock_sizze_16408 = &ctx->cfg->tuning_params[11];
    ctx->tuning_params.find_cluster_ids_6783zisegred_tblock_sizze_16597 = &ctx->cfg->tuning_params[12];
    ctx->tuning_params.find_cluster_ids_6783zisegscan_num_tblocks_16609 = &ctx->cfg->tuning_params[13];
    ctx->tuning_params.find_cluster_ids_6783zisegscan_tblock_sizze_16607 = &ctx->cfg->tuning_params[14];
    ctx->tuning_params.find_cluster_ids_6783zisuff_intra_par_1 = &ctx->cfg->tuning_params[15];
    ctx->tuning_params.find_cluster_ids_6783zisuff_outer_par_0 = &ctx->cfg->tuning_params[16];
    ctx->tuning_params.find_cluster_ids_6890zisegmap_tblock_sizze_16688 = &ctx->cfg->tuning_params[17];
    ctx->tuning_params.find_cluster_ids_6890zisegmap_tblock_sizze_16809 = &ctx->cfg->tuning_params[18];
    ctx->tuning_params.find_cluster_ids_6890zisegmap_tblock_sizze_16843 = &ctx->cfg->tuning_params[19];
    ctx->tuning_params.find_cluster_ids_6890zisegmap_tblock_sizze_16988 = &ctx->cfg->tuning_params[20];
    ctx->tuning_params.find_cluster_ids_6890zisegmap_tblock_sizze_17014 = &ctx->cfg->tuning_params[21];
    ctx->tuning_params.find_cluster_ids_6890zisegred_num_tblocks_16781 = &ctx->cfg->tuning_params[22];
    ctx->tuning_params.find_cluster_ids_6890zisegred_num_tblocks_16970 = &ctx->cfg->tuning_params[23];
    ctx->tuning_params.find_cluster_ids_6890zisegred_tblock_sizze_16779 = &ctx->cfg->tuning_params[24];
    ctx->tuning_params.find_cluster_ids_6890zisegred_tblock_sizze_16968 = &ctx->cfg->tuning_params[25];
    ctx->tuning_params.find_cluster_ids_6890zisegscan_num_tblocks_16980 = &ctx->cfg->tuning_params[26];
    ctx->tuning_params.find_cluster_ids_6890zisegscan_tblock_sizze_16978 = &ctx->cfg->tuning_params[27];
    ctx->tuning_params.find_cluster_ids_6890zisuff_intra_par_1 = &ctx->cfg->tuning_params[28];
    ctx->tuning_params.find_cluster_ids_6890zisuff_outer_par_0 = &ctx->cfg->tuning_params[29];
    ctx->tuning_params.ftDBSCAN_doublezisegmap_tblock_sizze_17423 = &ctx->cfg->tuning_params[30];
    ctx->tuning_params.ftDBSCAN_doublezisegmap_tblock_sizze_17450 = &ctx->cfg->tuning_params[31];
    ctx->tuning_params.ftDBSCAN_doublezisegmap_tblock_sizze_17607 = &ctx->cfg->tuning_params[32];
    ctx->tuning_params.ftDBSCAN_doublezisegmap_tblock_sizze_17637 = &ctx->cfg->tuning_params[33];
    ctx->tuning_params.ftDBSCAN_doublezisegred_num_tblocks_17568 = &ctx->cfg->tuning_params[34];
    ctx->tuning_params.ftDBSCAN_doublezisegred_tblock_sizze_17566 = &ctx->cfg->tuning_params[35];
    ctx->tuning_params.ftDBSCAN_doublezisuff_intra_par_1 = &ctx->cfg->tuning_params[36];
    ctx->tuning_params.ftDBSCAN_doublezisuff_outer_par_0 = &ctx->cfg->tuning_params[37];
    ctx->tuning_params.ftDBSCAN_floatzisegmap_tblock_sizze_17050 = &ctx->cfg->tuning_params[38];
    ctx->tuning_params.ftDBSCAN_floatzisegmap_tblock_sizze_17077 = &ctx->cfg->tuning_params[39];
    ctx->tuning_params.ftDBSCAN_floatzisegmap_tblock_sizze_17234 = &ctx->cfg->tuning_params[40];
    ctx->tuning_params.ftDBSCAN_floatzisegmap_tblock_sizze_17264 = &ctx->cfg->tuning_params[41];
    ctx->tuning_params.ftDBSCAN_floatzisegred_num_tblocks_17195 = &ctx->cfg->tuning_params[42];
    ctx->tuning_params.ftDBSCAN_floatzisegred_tblock_sizze_17193 = &ctx->cfg->tuning_params[43];
    ctx->tuning_params.ftDBSCAN_floatzisuff_intra_par_1 = &ctx->cfg->tuning_params[44];
    ctx->tuning_params.ftDBSCAN_floatzisuff_outer_par_0 = &ctx->cfg->tuning_params[45];
    ctx->tuning_params.ftDBSCAN_star_doublezisegmap_tblock_sizze_16290 = &ctx->cfg->tuning_params[46];
    ctx->tuning_params.ftDBSCAN_star_floatzisegmap_tblock_sizze_16272 = &ctx->cfg->tuning_params[47];
    ctx->tuning_params.get_num_neighbours_6695zisegmap_tblock_sizze_17805 = &ctx->cfg->tuning_params[48];
    ctx->tuning_params.get_num_neighbours_6695zisegmap_tblock_sizze_17893 = &ctx->cfg->tuning_params[49];
    ctx->tuning_params.get_num_neighbours_6695zisegmap_tblock_sizze_17934 = &ctx->cfg->tuning_params[50];
    ctx->tuning_params.get_num_neighbours_6695zisegmap_tblock_sizze_17966 = &ctx->cfg->tuning_params[51];
    ctx->tuning_params.get_num_neighbours_6695zisegred_num_tblocks_17906 = &ctx->cfg->tuning_params[52];
    ctx->tuning_params.get_num_neighbours_6695zisegred_tblock_sizze_17904 = &ctx->cfg->tuning_params[53];
    ctx->tuning_params.get_num_neighbours_6695zisuff_intra_par_1 = &ctx->cfg->tuning_params[54];
    ctx->tuning_params.get_num_neighbours_6695zisuff_outer_par_0 = &ctx->cfg->tuning_params[55];
    ctx->tuning_params.get_num_neighbours_6842zisegmap_tblock_sizze_18106 = &ctx->cfg->tuning_params[56];
    ctx->tuning_params.get_num_neighbours_6842zisegmap_tblock_sizze_18194 = &ctx->cfg->tuning_params[57];
    ctx->tuning_params.get_num_neighbours_6842zisegmap_tblock_sizze_18235 = &ctx->cfg->tuning_params[58];
    ctx->tuning_params.get_num_neighbours_6842zisegmap_tblock_sizze_18267 = &ctx->cfg->tuning_params[59];
    ctx->tuning_params.get_num_neighbours_6842zisegred_num_tblocks_18207 = &ctx->cfg->tuning_params[60];
    ctx->tuning_params.get_num_neighbours_6842zisegred_tblock_sizze_18205 = &ctx->cfg->tuning_params[61];
    ctx->tuning_params.get_num_neighbours_6842zisuff_intra_par_1 = &ctx->cfg->tuning_params[62];
    ctx->tuning_params.get_num_neighbours_6842zisuff_outer_par_0 = &ctx->cfg->tuning_params[63];
    ctx->tuning_params.isolate_core_points_6732zisegmap_num_tblocks_16219 = &ctx->cfg->tuning_params[64];
    ctx->tuning_params.isolate_core_points_6732zisegmap_tblock_sizze_16188 = &ctx->cfg->tuning_params[65];
    ctx->tuning_params.isolate_core_points_6732zisegmap_tblock_sizze_16217 = &ctx->cfg->tuning_params[66];
    ctx->tuning_params.isolate_core_points_6732zisegscan_num_tblocks_16178 = &ctx->cfg->tuning_params[67];
    ctx->tuning_params.isolate_core_points_6732zisegscan_tblock_sizze_16176 = &ctx->cfg->tuning_params[68];
    ctx->tuning_params.isolate_core_points_6871zisegmap_num_tblocks_16266 = &ctx->cfg->tuning_params[69];
    ctx->tuning_params.isolate_core_points_6871zisegmap_tblock_sizze_16235 = &ctx->cfg->tuning_params[70];
    ctx->tuning_params.isolate_core_points_6871zisegmap_tblock_sizze_16264 = &ctx->cfg->tuning_params[71];
    ctx->tuning_params.isolate_core_points_6871zisegscan_num_tblocks_16225 = &ctx->cfg->tuning_params[72];
    ctx->tuning_params.isolate_core_points_6871zisegscan_tblock_sizze_16223 = &ctx->cfg->tuning_params[73];
}
int memblock_unref_device(struct futhark_context *ctx, struct memblock_device *block, const char *desc)
{
    if (block->references != NULL) {
        *block->references -= 1;
        if (ctx->detail_memory)
            fprintf(ctx->log, "Unreferencing block %s (allocated as %s) in %s: %d references remaining.\n", desc, block->desc, "space 'device'", *block->references);
        if (*block->references == 0) {
            ctx->cur_mem_usage_device -= block->size;
            (void) gpu_free(ctx, block->mem, block->size, desc);
            free(block->references);
            if (ctx->detail_memory)
                fprintf(ctx->log, "%lld bytes freed (now allocated: %lld bytes)\n", (long long) block->size, (long long) ctx->cur_mem_usage_device);
        }
        block->references = NULL;
    }
    return 0;
}
int memblock_alloc_device(struct futhark_context *ctx, struct memblock_device *block, int64_t size, const char *desc)
{
    if (size < 0)
        futhark_panic(1, "Negative allocation of %lld bytes attempted for %s in %s.\n", (long long) size, desc, "space 'device'", ctx->cur_mem_usage_device);
    
    int ret = memblock_unref_device(ctx, block, desc);
    
    if (ret != FUTHARK_SUCCESS)
        return ret;
    if (ctx->detail_memory)
        fprintf(ctx->log, "Allocating %lld bytes for %s in %s (currently allocated: %lld bytes).\n", (long long) size, desc, "space 'device'", (long long) ctx->cur_mem_usage_device);
    (void) gpu_alloc(ctx, ctx->log, (size_t) size, desc, &block->mem, (size_t *) &size);
    if (ctx->error == NULL) {
        block->references = (int *) malloc(sizeof(int));
        *block->references = 1;
        block->size = size;
        block->desc = desc;
        
        long long new_usage = ctx->cur_mem_usage_device + size;
        
        if (ctx->detail_memory)
            fprintf(ctx->log, "Received block of %lld bytes; now allocated: %lld bytes", (long long) block->size, new_usage);
        ctx->cur_mem_usage_device = new_usage;
        if (new_usage > ctx->peak_mem_usage_device) {
            ctx->peak_mem_usage_device = new_usage;
            if (ctx->detail_memory)
                fprintf(ctx->log, " (new peak).\n");
        } else if (ctx->detail_memory)
            fprintf(ctx->log, ".\n");
        return FUTHARK_SUCCESS;
    } else {
        // We are naively assuming that any memory allocation error is due to OOM.
        lock_lock(&ctx->error_lock);
        
        char *old_error = ctx->error;
        
        ctx->error = msgprintf("Failed to allocate memory in %s.\nAttempted allocation: %12lld bytes\nCurrently allocated:  %12lld bytes\n%s", "space 'device'", (long long) size, (long long) ctx->cur_mem_usage_device, old_error);
        free(old_error);
        lock_unlock(&ctx->error_lock);
        return FUTHARK_OUT_OF_MEMORY;
    }
}
int memblock_set_device(struct futhark_context *ctx, struct memblock_device *lhs, struct memblock_device *rhs, const char *lhs_desc)
{
    int ret = memblock_unref_device(ctx, lhs, lhs_desc);
    
    if (rhs->references != NULL)
        (*rhs->references)++;
    *lhs = *rhs;
    return ret;
}
int memblock_unref(struct futhark_context *ctx, struct memblock *block, const char *desc)
{
    if (block->references != NULL) {
        *block->references -= 1;
        if (ctx->detail_memory)
            fprintf(ctx->log, "Unreferencing block %s (allocated as %s) in %s: %d references remaining.\n", desc, block->desc, "default space", *block->references);
        if (*block->references == 0) {
            ctx->cur_mem_usage_default -= block->size;
            host_free(ctx, (size_t) block->size, desc, (void *) block->mem);
            free(block->references);
            if (ctx->detail_memory)
                fprintf(ctx->log, "%lld bytes freed (now allocated: %lld bytes)\n", (long long) block->size, (long long) ctx->cur_mem_usage_default);
        }
        block->references = NULL;
    }
    return 0;
}
int memblock_alloc(struct futhark_context *ctx, struct memblock *block, int64_t size, const char *desc)
{
    if (size < 0)
        futhark_panic(1, "Negative allocation of %lld bytes attempted for %s in %s.\n", (long long) size, desc, "default space", ctx->cur_mem_usage_default);
    
    int ret = memblock_unref(ctx, block, desc);
    
    if (ret != FUTHARK_SUCCESS)
        return ret;
    if (ctx->detail_memory)
        fprintf(ctx->log, "Allocating %lld bytes for %s in %s (currently allocated: %lld bytes).\n", (long long) size, desc, "default space", (long long) ctx->cur_mem_usage_default);
    host_alloc(ctx, (size_t) size, desc, (size_t *) &size, (void *) &block->mem);
    if (ctx->error == NULL) {
        block->references = (int *) malloc(sizeof(int));
        *block->references = 1;
        block->size = size;
        block->desc = desc;
        
        long long new_usage = ctx->cur_mem_usage_default + size;
        
        if (ctx->detail_memory)
            fprintf(ctx->log, "Received block of %lld bytes; now allocated: %lld bytes", (long long) block->size, new_usage);
        ctx->cur_mem_usage_default = new_usage;
        if (new_usage > ctx->peak_mem_usage_default) {
            ctx->peak_mem_usage_default = new_usage;
            if (ctx->detail_memory)
                fprintf(ctx->log, " (new peak).\n");
        } else if (ctx->detail_memory)
            fprintf(ctx->log, ".\n");
        return FUTHARK_SUCCESS;
    } else {
        // We are naively assuming that any memory allocation error is due to OOM.
        lock_lock(&ctx->error_lock);
        
        char *old_error = ctx->error;
        
        ctx->error = msgprintf("Failed to allocate memory in %s.\nAttempted allocation: %12lld bytes\nCurrently allocated:  %12lld bytes\n%s", "default space", (long long) size, (long long) ctx->cur_mem_usage_default, old_error);
        free(old_error);
        lock_unlock(&ctx->error_lock);
        return FUTHARK_OUT_OF_MEMORY;
    }
}
int memblock_set(struct futhark_context *ctx, struct memblock *lhs, struct memblock *rhs, const char *lhs_desc)
{
    int ret = memblock_unref(ctx, lhs, lhs_desc);
    
    if (rhs->references != NULL)
        (*rhs->references)++;
    *lhs = *rhs;
    return ret;
}
char *futhark_context_report(struct futhark_context *ctx)
{
    if (futhark_context_sync(ctx) != 0)
        return NULL;
    
    struct str_builder builder;
    
    str_builder_init(&builder);
    str_builder_char(&builder, '{');
    str_builder_str(&builder, "\"memory\":{");
    str_builder(&builder, "\"space 'device'\": %lld", (long long) ctx->peak_mem_usage_device);
    str_builder_char(&builder, ',');
    str_builder(&builder, "\"default space\": %lld", (long long) ctx->peak_mem_usage_default);
    str_builder_str(&builder, "},\"events\":[");
    if (report_events_in_list(&ctx->event_list, &builder) != 0) {
        free(builder.str);
        return NULL;
    } else {
        str_builder_str(&builder, "]}");
        return builder.str;
    }
}
int futhark_context_clear_caches(struct futhark_context *ctx)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    ctx->peak_mem_usage_device = 0;
    ctx->peak_mem_usage_default = 0;
    if (ctx->error == NULL)
        gpu_free_all(ctx);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ctx->error != NULL;
}

// Start of context.h

// Internal functions.

static void set_error(struct futhark_context* ctx, char *error) {
  lock_lock(&ctx->error_lock);
  if (ctx->error == NULL) {
    ctx->error = error;
  } else {
    free(error);
  }
  lock_unlock(&ctx->error_lock);
}

// XXX: should be static, but used in ispc_util.h
void lexical_realloc_error(struct futhark_context* ctx, size_t new_size) {
  set_error(ctx,
            msgprintf("Failed to allocate memory.\nAttempted allocation: %12lld bytes\n",
                      (long long) new_size));
}

static int lexical_realloc(struct futhark_context *ctx,
                           unsigned char **ptr,
                           int64_t *old_size,
                           int64_t new_size) {
  unsigned char *new = realloc(*ptr, (size_t)new_size);
  if (new == NULL) {
    lexical_realloc_error(ctx, new_size);
    return FUTHARK_OUT_OF_MEMORY;
  } else {
    *ptr = new;
    *old_size = new_size;
    return FUTHARK_SUCCESS;
  }
}

static void free_all_in_free_list(struct futhark_context* ctx) {
  fl_mem mem;
  free_list_pack(&ctx->free_list);
  while (free_list_first(&ctx->free_list, (fl_mem*)&mem) == 0) {
    free((void*)mem);
  }
}

static int is_small_alloc(size_t size) {
  return size < 1024*1024;
}

static void host_alloc(struct futhark_context* ctx,
                       size_t size, const char* tag, size_t* size_out, void** mem_out) {
  if (is_small_alloc(size) || free_list_find(&ctx->free_list, size, tag, size_out, (fl_mem*)mem_out) != 0) {
    *size_out = size;
    *mem_out = malloc(size);
  }
}

static void host_free(struct futhark_context* ctx,
                      size_t size, const char* tag, void* mem) {
  // Small allocations are handled by malloc()s own free list.  The
  // threshold here is kind of arbitrary, but seems to work OK.
  // Larger allocations are mmap()ed/munmapped() every time, which is
  // very slow, and Futhark programs tend to use a few very large
  // allocations.
  if (is_small_alloc(size)) {
    free(mem);
  } else {
    free_list_insert(&ctx->free_list, size, (fl_mem)mem, tag);
  }
}

static void add_event(struct futhark_context* ctx,
                      const char* name,
                      char* description,
                      void* data,
                      event_report_fn f) {
  if (ctx->logging) {
    fprintf(ctx->log, "Event: %s\n%s\n", name, description);
  }
  add_event_to_list(&ctx->event_list, name, description, data, f);
}

char *futhark_context_get_error(struct futhark_context *ctx) {
  char *error = ctx->error;
  ctx->error = NULL;
  return error;
}

void futhark_context_config_set_debugging(struct futhark_context_config *cfg, int flag) {
    cfg->profiling = cfg->logging = cfg->debugging = flag;
}

void futhark_context_config_set_profiling(struct futhark_context_config *cfg, int flag) {
    cfg->profiling = flag;
}

void futhark_context_config_set_logging(struct futhark_context_config *cfg, int flag) {
    cfg->logging = flag;
}

void futhark_context_config_set_cache_file(struct futhark_context_config *cfg, const char *f) {
  cfg->cache_fname = strdup(f);
}

int futhark_get_tuning_param_count(void) {
  return num_tuning_params;
}

const char *futhark_get_tuning_param_name(int i) {
  return tuning_param_names[i];
}

const char *futhark_get_tuning_param_class(int i) {
    return tuning_param_classes[i];
}

void futhark_context_set_logging_file(struct futhark_context *ctx, FILE *f){
  ctx->log = f;
}

void futhark_context_pause_profiling(struct futhark_context *ctx) {
  ctx->profiling_paused = 1;
}

void futhark_context_unpause_profiling(struct futhark_context *ctx) {
  ctx->profiling_paused = 0;
}

struct futhark_context_config* futhark_context_config_new(void) {
  struct futhark_context_config* cfg = malloc(sizeof(struct futhark_context_config));
  if (cfg == NULL) {
    return NULL;
  }
  cfg->in_use = 0;
  cfg->debugging = 0;
  cfg->profiling = 0;
  cfg->logging = 0;
  cfg->cache_fname = NULL;
  cfg->num_tuning_params = num_tuning_params;
  cfg->tuning_params = malloc(cfg->num_tuning_params * sizeof(int64_t));
  memcpy(cfg->tuning_params, tuning_param_defaults,
         cfg->num_tuning_params * sizeof(int64_t));
  cfg->tuning_param_names = tuning_param_names;
  cfg->tuning_param_vars = tuning_param_vars;
  cfg->tuning_param_classes = tuning_param_classes;
  backend_context_config_setup(cfg);
  return cfg;
}

void futhark_context_config_free(struct futhark_context_config* cfg) {
  assert(!cfg->in_use);
  backend_context_config_teardown(cfg);
  free(cfg->cache_fname);
  free(cfg->tuning_params);
  free(cfg);
}

struct futhark_context* futhark_context_new(struct futhark_context_config* cfg) {
  struct futhark_context* ctx = malloc(sizeof(struct futhark_context));
  if (ctx == NULL) {
    return NULL;
  }
  assert(!cfg->in_use);
  ctx->cfg = cfg;
  ctx->cfg->in_use = 1;
  ctx->program_initialised = false;
  create_lock(&ctx->error_lock);
  create_lock(&ctx->lock);
  free_list_init(&ctx->free_list);
  event_list_init(&ctx->event_list);
  ctx->peak_mem_usage_default = 0;
  ctx->cur_mem_usage_default = 0;
  ctx->constants = malloc(sizeof(struct constants));
  ctx->debugging = cfg->debugging;
  ctx->logging = cfg->logging;
  ctx->detail_memory = cfg->logging;
  ctx->profiling = cfg->profiling;
  ctx->profiling_paused = 0;
  ctx->error = NULL;
  ctx->log = stderr;
  set_tuning_params(ctx);
  if (backend_context_setup(ctx) == 0) {
    setup_program(ctx);
    init_constants(ctx);
    ctx->program_initialised = true;
    (void)futhark_context_clear_caches(ctx);
    (void)futhark_context_sync(ctx);
  }
  return ctx;
}

void futhark_context_free(struct futhark_context* ctx) {
  if (ctx->program_initialised) {
    free_constants(ctx);
    teardown_program(ctx);
  }
  backend_context_teardown(ctx);
  free_all_in_free_list(ctx);
  free_list_destroy(&ctx->free_list);
  event_list_free(&ctx->event_list);
  free(ctx->constants);
  free(ctx->error);
  free_lock(&ctx->lock);
  free_lock(&ctx->error_lock);
  ctx->cfg->in_use = 0;
  free(ctx);
}

// End of context.h

// Start of copy.h

// Cache-oblivious map-transpose function.
#define GEN_MAP_TRANSPOSE(NAME, ELEM_TYPE)                              \
  static void map_transpose_##NAME                                      \
  (ELEM_TYPE* dst, ELEM_TYPE* src,                                      \
   int64_t k, int64_t m, int64_t n,                                     \
   int64_t cb, int64_t ce, int64_t rb, int64_t re)                      \
  {                                                                     \
  int32_t r = re - rb;                                                  \
  int32_t c = ce - cb;                                                  \
  if (k == 1) {                                                         \
    if (r <= 64 && c <= 64) {                                           \
      for (int64_t j = 0; j < c; j++) {                                 \
        for (int64_t i = 0; i < r; i++) {                               \
          dst[(j + cb) * n + (i + rb)] = src[(i + rb) * m + (j + cb)];  \
        }                                                               \
      }                                                                 \
    } else if (c <= r) {                                                \
      map_transpose_##NAME(dst, src, k, m, n, cb, ce, rb, rb + r/2);    \
      map_transpose_##NAME(dst, src, k, m, n, cb, ce, rb + r/2, re);    \
    } else {                                                            \
      map_transpose_##NAME(dst, src, k, m, n, cb, cb + c/2, rb, re);    \
      map_transpose_##NAME(dst, src, k, m, n, cb + c/2, ce, rb, re);    \
    }                                                                   \
  } else {                                                              \
  for (int64_t i = 0; i < k; i++) {                                     \
    map_transpose_##NAME(dst + i * m * n, src + i * m * n, 1, m, n, cb, ce, rb, re); \
  }\
} \
}

// Straightforward LMAD copy function.
#define GEN_LMAD_COPY_ELEMENTS(NAME, ELEM_TYPE)                         \
  static void lmad_copy_elements_##NAME(int r,                          \
                                        ELEM_TYPE* dst, int64_t dst_strides[r], \
                                        ELEM_TYPE *src, int64_t src_strides[r], \
                                        int64_t shape[r]) {             \
    if (r == 1) {                                                       \
      for (int i = 0; i < shape[0]; i++) {                              \
        dst[i*dst_strides[0]] = src[i*src_strides[0]];                  \
      }                                                                 \
    } else if (r > 1) {                                                 \
      for (int i = 0; i < shape[0]; i++) {                              \
        lmad_copy_elements_##NAME(r-1,                                  \
                                  dst+i*dst_strides[0], dst_strides+1,  \
                                  src+i*src_strides[0], src_strides+1,  \
                                  shape+1);                             \
      }                                                                 \
    }                                                                   \
  }                                                                     \

// Check whether this LMAD can be seen as a transposed 2D array.  This
// is done by checking every possible splitting point.
static bool lmad_is_tr(int64_t *n_out, int64_t *m_out,
                       int r,
                       const int64_t strides[r],
                       const int64_t shape[r]) {
  for (int i = 1; i < r; i++) {
    int n = 1, m = 1;
    bool ok = true;
    int64_t expected = 1;
    // Check strides before 'i'.
    for (int j = i-1; j >= 0; j--) {
      ok = ok && strides[j] == expected;
      expected *= shape[j];
      n *= shape[j];
    }
    // Check strides after 'i'.
    for (int j = r-1; j >= i; j--) {
      ok = ok && strides[j] == expected;
      expected *= shape[j];
      m *= shape[j];
    }
    if (ok) {
      *n_out = n;
      *m_out = m;
      return true;
    }
  }
  return false;
}

// This function determines whether the a 'dst' LMAD is row-major and
// 'src' LMAD is column-major.  Both LMADs are for arrays of the same
// shape.  Both LMADs are allowed to have additional dimensions "on
// top".  Essentially, this function determines whether a copy from
// 'src' to 'dst' is a "map(transpose)" that we know how to implement
// efficiently.  The LMADs can have arbitrary rank, and the main
// challenge here is checking whether the src LMAD actually
// corresponds to a 2D column-major layout by morally collapsing
// dimensions.  There is a lot of looping here, but the actual trip
// count is going to be very low in practice.
//
// Returns true if this is indeed a map(transpose), and writes the
// number of arrays, and moral array size to appropriate output
// parameters.
static bool lmad_map_tr(int64_t *num_arrays_out, int64_t *n_out, int64_t *m_out,
                        int r,
                        const int64_t dst_strides[r],
                        const int64_t src_strides[r],
                        const int64_t shape[r]) {
  int64_t rowmajor_strides[r];
  rowmajor_strides[r-1] = 1;

  for (int i = r-2; i >= 0; i--) {
    rowmajor_strides[i] = rowmajor_strides[i+1] * shape[i+1];
  }

  // map_r will be the number of mapped dimensions on top.
  int map_r = 0;
  int64_t num_arrays = 1;
  for (int i = 0; i < r; i++) {
    if (dst_strides[i] != rowmajor_strides[i] ||
        src_strides[i] != rowmajor_strides[i]) {
      break;
    } else {
      num_arrays *= shape[i];
      map_r++;
    }
  }

  *num_arrays_out = num_arrays;

  if (r==map_r) {
    return false;
  }

  if (memcmp(&rowmajor_strides[map_r],
             &dst_strides[map_r],
             sizeof(int64_t)*(r-map_r)) == 0) {
    return lmad_is_tr(n_out, m_out, r-map_r, src_strides+map_r, shape+map_r);
  } else if (memcmp(&rowmajor_strides[map_r],
                    &src_strides[map_r],
                    sizeof(int64_t)*(r-map_r)) == 0) {
    return lmad_is_tr(m_out, n_out, r-map_r, dst_strides+map_r, shape+map_r);
  }
  return false;
}

// Check if the strides correspond to row-major strides of *any*
// permutation of the shape.  This is done by recursive search with
// backtracking.  This is worst-case exponential, but hopefully the
// arrays we encounter do not have that many dimensions.
static bool lmad_contiguous_search(int checked, int64_t expected,
                                   int r,
                                   int64_t strides[r], int64_t shape[r], bool used[r]) {
  for (int i = 0; i < r; i++) {
    for (int j = 0; j < r; j++) {
      if (!used[j] && strides[j] == expected && strides[j] >= 0) {
        used[j] = true;
        if (checked+1 == r ||
            lmad_contiguous_search(checked+1, expected * shape[j], r, strides, shape, used)) {
          return true;
        }
        used[j] = false;
      }
    }
  }
  return false;
}

// Does this LMAD correspond to an array with positive strides and no
// holes?
static bool lmad_contiguous(int r, int64_t strides[r], int64_t shape[r]) {
  bool used[r];
  for (int i = 0; i < r; i++) {
    used[i] = false;
  }
  return lmad_contiguous_search(0, 1, r, strides, shape, used);
}

// Does this copy correspond to something that could be done with a
// memcpy()-like operation?  I.e. do the LMADs actually represent the
// same in-memory layout and are they contiguous?
static bool lmad_memcpyable(int r,
                            int64_t dst_strides[r], int64_t src_strides[r], int64_t shape[r]) {
  if (!lmad_contiguous(r, dst_strides, shape)) {
    return false;
  }
  for (int i = 0; i < r; i++) {
    if (dst_strides[i] != src_strides[i] && shape[i] != 1) {
      return false;
    }
  }
  return true;
}


static void log_copy(struct futhark_context* ctx,
                     const char *kind, int r,
                     int64_t dst_offset, int64_t dst_strides[r],
                     int64_t src_offset, int64_t src_strides[r],
                     int64_t shape[r]) {
  if (ctx->logging) {
    fprintf(ctx->log, "\n# Copy %s\n", kind);
    fprintf(ctx->log, "Shape: ");
    for (int i = 0; i < r; i++) { fprintf(ctx->log, "[%ld]", (long int)shape[i]); }
    fprintf(ctx->log, "\n");
    fprintf(ctx->log, "Dst offset: %ld\n", (long int)dst_offset);
    fprintf(ctx->log, "Dst strides:");
    for (int i = 0; i < r; i++) { fprintf(ctx->log, " %ld", (long int)dst_strides[i]); }
    fprintf(ctx->log, "\n");
    fprintf(ctx->log, "Src offset: %ld\n", (long int)src_offset);
    fprintf(ctx->log, "Src strides:");
    for (int i = 0; i < r; i++) { fprintf(ctx->log, " %ld", (long int)src_strides[i]); }
    fprintf(ctx->log, "\n");
  }
}

static void log_transpose(struct futhark_context* ctx,
                          int64_t k, int64_t n, int64_t m) {
  if (ctx->logging) {
    fprintf(ctx->log, "## Transpose\n");
    fprintf(ctx->log, "Arrays     : %ld\n", (long int)k);
    fprintf(ctx->log, "X elements : %ld\n", (long int)m);
    fprintf(ctx->log, "Y elements : %ld\n", (long int)n);
    fprintf(ctx->log, "\n");
  }
}

#define GEN_LMAD_COPY(NAME, ELEM_TYPE)                                  \
  static void lmad_copy_##NAME                                          \
  (struct futhark_context *ctx, int r,                                  \
   ELEM_TYPE* dst, int64_t dst_offset, int64_t dst_strides[r],          \
   ELEM_TYPE *src, int64_t src_offset, int64_t src_strides[r],          \
   int64_t shape[r]) {                                                  \
    log_copy(ctx, "CPU to CPU", r, dst_offset, dst_strides,             \
             src_offset, src_strides, shape);                           \
    int64_t size = 1;                                                   \
    for (int i = 0; i < r; i++) { size *= shape[i]; }                   \
    if (size == 0) { return; }                                          \
    int64_t k, n, m;                                                    \
    if (lmad_map_tr(&k, &n, &m,                                         \
                    r, dst_strides, src_strides, shape)) {              \
      log_transpose(ctx, k, n, m);                                      \
      map_transpose_##NAME                                              \
        (dst+dst_offset, src+src_offset, k, n, m, 0, n, 0, m);          \
    } else if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {   \
      if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}          \
      memcpy(dst+dst_offset, src+src_offset, size*sizeof(*dst));        \
    } else {                                                            \
      if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}       \
      lmad_copy_elements_##NAME                                         \
        (r,                                                             \
         dst+dst_offset, dst_strides,                                   \
         src+src_offset, src_strides, shape);                           \
    }                                                                   \
  }

GEN_MAP_TRANSPOSE(1b, uint8_t)
GEN_MAP_TRANSPOSE(2b, uint16_t)
GEN_MAP_TRANSPOSE(4b, uint32_t)
GEN_MAP_TRANSPOSE(8b, uint64_t)

GEN_LMAD_COPY_ELEMENTS(1b, uint8_t)
GEN_LMAD_COPY_ELEMENTS(2b, uint16_t)
GEN_LMAD_COPY_ELEMENTS(4b, uint32_t)
GEN_LMAD_COPY_ELEMENTS(8b, uint64_t)

GEN_LMAD_COPY(1b, uint8_t)
GEN_LMAD_COPY(2b, uint16_t)
GEN_LMAD_COPY(4b, uint32_t)
GEN_LMAD_COPY(8b, uint64_t)

// End of copy.h

#define FUTHARK_FUN_ATTR static

FUTHARK_FUN_ATTR int futrts_builtinzhiota_i64(struct futhark_context *ctx, struct memblock_device mem_18651, int64_t n_18652, int64_t x_18653, int64_t s_18654);
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i32(struct futhark_context *ctx, struct memblock_device mem_18765, int64_t num_elems_18766, int32_t val_18767);
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i64(struct futhark_context *ctx, struct memblock_device mem_18651, int64_t num_elems_18652, int64_t val_18653);
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i8(struct futhark_context *ctx, struct memblock_device mem_18868, int64_t num_elems_18869, int8_t val_18870);
FUTHARK_FUN_ATTR int futrts_entry_ftDBSCAN_double(struct futhark_context *ctx, struct memblock_device *mem_out_p_19021, struct memblock_device dat_mem_18419, int64_t nz2080U_15177, int64_t dimz2081U_15178, double eps_15180, int64_t minPts_15181, int64_t pMem_15182, int64_t gather_psizze_15183);
FUTHARK_FUN_ATTR int futrts_entry_ftDBSCAN_float(struct futhark_context *ctx, struct memblock_device *mem_out_p_19022, struct memblock_device dat_mem_18419, int64_t nz2080U_13119, int64_t dimz2081U_13120, float eps_13122, int64_t minPts_13123, int64_t pMem_13124, int64_t gather_psizze_13125);
FUTHARK_FUN_ATTR int futrts_entry_ftDBSCAN_star_double(struct futhark_context *ctx, struct memblock_device *mem_out_p_19023, struct memblock_device *mem_out_p_19024, int64_t *out_prim_out_19025, int64_t *out_prim_out_19026, struct memblock_device dat_mem_18419, int64_t dim_15336, int64_t nz2085U_15337, double eps_15339, int64_t minPts_15340, int64_t pMem_15341, int64_t gather_psizze_15342);
FUTHARK_FUN_ATTR int futrts_entry_ftDBSCAN_star_float(struct futhark_context *ctx, struct memblock_device *mem_out_p_19027, struct memblock_device *mem_out_p_19028, int64_t *out_prim_out_19029, int64_t *out_prim_out_19030, struct memblock_device dat_mem_18419, int64_t dim_15255, int64_t nz2085U_15256, float eps_15258, int64_t minPts_15259, int64_t pMem_15260, int64_t gather_psizze_15261);
FUTHARK_FUN_ATTR int futrts_find_cluster_ids_6783(struct futhark_context *ctx, struct memblock_device *mem_out_p_19031, struct memblock_device core_dat_mem_18419, int64_t n_12449, int64_t dim_12450, float eps_12452, int64_t extPar_12453, int64_t gather_psizze_12454);
FUTHARK_FUN_ATTR int futrts_find_cluster_ids_6890(struct futhark_context *ctx, struct memblock_device *mem_out_p_19033, struct memblock_device core_dat_mem_18419, int64_t n_14507, int64_t dim_14508, double eps_14510, int64_t extPar_14511, int64_t gather_psizze_14512);
FUTHARK_FUN_ATTR int futrts_get_num_neighbours_6695(struct futhark_context *ctx, struct memblock_device *mem_out_p_19035, struct memblock_device dat_mem_18419, int64_t n_11127, int64_t dim_11128, float eps_11130, int64_t extPar_11131);
FUTHARK_FUN_ATTR int futrts_get_num_neighbours_6842(struct futhark_context *ctx, struct memblock_device *mem_out_p_19036, struct memblock_device dat_mem_18419, int64_t n_13491, int64_t dim_13492, double eps_13494, int64_t extPar_13495);
FUTHARK_FUN_ATTR int futrts_isolate_core_points_6732(struct futhark_context *ctx, struct memblock_device *mem_out_p_19037, int64_t *out_prim_out_19038, struct memblock_device dat_mem_18419, struct memblock_device isCore_mem_18420, int64_t n_11606, int64_t dim_11607);
FUTHARK_FUN_ATTR int futrts_isolate_core_points_6871(struct futhark_context *ctx, struct memblock_device *mem_out_p_19040, int64_t *out_prim_out_19041, struct memblock_device dat_mem_18419, struct memblock_device isCore_mem_18420, int64_t n_13951, int64_t dim_13952);

static int init_constants(struct futhark_context *ctx)
{
    (void) ctx;
    
    int err = 0;
    
    #define counters_mem_18763 (ctx->constants->counters_mem_18763)
    #define counters_mem_18765 (ctx->constants->counters_mem_18765)
    #define counters_mem_18789 (ctx->constants->counters_mem_18789)
    #define counters_mem_18825 (ctx->constants->counters_mem_18825)
    #define global_dynid_mem_18686 (ctx->constants->global_dynid_mem_18686)
    #define global_dynid_mem_18892 (ctx->constants->global_dynid_mem_18892)
    counters_mem_18763.references = NULL;
    counters_mem_18765.references = NULL;
    counters_mem_18789.references = NULL;
    counters_mem_18825.references = NULL;
    global_dynid_mem_18686.references = NULL;
    global_dynid_mem_18892.references = NULL;
    if (memblock_alloc_device(ctx, &global_dynid_mem_18686, (int64_t) 4, "global_dynid_mem_18686")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_18686, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_18686, (int64_t) 4, "global_dynid_mem_18686")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_18686, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_18765, (int64_t) 81920, "counters_mem_18765")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_18765, (int64_t) 20480, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_18825, (int64_t) 80, "counters_mem_18825")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_18825, (int64_t) 20, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_18892, (int64_t) 4, "global_dynid_mem_18892")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_18892, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_18765, (int64_t) 81920, "counters_mem_18765")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_18765, (int64_t) 20480, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_18825, (int64_t) 80, "counters_mem_18825")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_18825, (int64_t) 20, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_18892, (int64_t) 4, "global_dynid_mem_18892")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_18892, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_18789, (int64_t) 81920, "counters_mem_18789")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_18789, (int64_t) 20480, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_18789, (int64_t) 81920, "counters_mem_18789")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_18789, (int64_t) 20480, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_18763, (int64_t) 81920, "counters_mem_18763")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_18763, (int64_t) 20480, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_18763, (int64_t) 81920, "counters_mem_18763")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_18763, (int64_t) 20480, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    #undef counters_mem_18763
    #undef counters_mem_18765
    #undef counters_mem_18789
    #undef counters_mem_18825
    #undef global_dynid_mem_18686
    #undef global_dynid_mem_18892
    
  cleanup:
    return err;
}
static int free_constants(struct futhark_context *ctx)
{
    (void) ctx;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_18763, "ctx->constants->counters_mem_18763") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_18765, "ctx->constants->counters_mem_18765") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_18789, "ctx->constants->counters_mem_18789") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_18825, "ctx->constants->counters_mem_18825") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_18686, "ctx->constants->global_dynid_mem_18686") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_18892, "ctx->constants->global_dynid_mem_18892") != 0)
        return 1;
    return 0;
}
static int gpu_kernel_builtinzhiota_i64ziiota_i64_18656(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhiota_i64ziiota_i64_18656, "builtin#iota_i64.iota_i64_18656", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_builtinzhreplicate_i32zireplicate_18770(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int32_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_i32zireplicate_18770, "builtin#replicate_i32.replicate_18770", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_builtinzhreplicate_i64zireplicate_18656(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_i64zireplicate_18656, "builtin#replicate_i64.replicate_18656", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_builtinzhreplicate_i8zireplicate_18873(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int8_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_i8zireplicate_18873, "builtin#replicate_i8.replicate_18873", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_ftDBSCAN_doublezisegmap_17435(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->ftDBSCAN_doublezisegmap_17435, "ftDBSCAN_double.segmap_17435", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_ftDBSCAN_doublezisegmap_17488(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, double arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->ftDBSCAN_doublezisegmap_17488, "ftDBSCAN_double.segmap_17488", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_ftDBSCAN_doublezisegmap_intrablock_17524(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, double arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->ftDBSCAN_doublezisegmap_intrablock_17524, "ftDBSCAN_double.segmap_intrablock_17524", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_ftDBSCAN_doublezisegmap_17742(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->ftDBSCAN_doublezisegmap_17742, "ftDBSCAN_double.segmap_17742", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_ftDBSCAN_doublezisegmap_17755(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4};
        size_t args_sizes[6] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4)};
        
        return gpu_launch_kernel(ctx, ctx->program->ftDBSCAN_doublezisegmap_17755, "ftDBSCAN_double.segmap_17755", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_ftDBSCAN_doublezisegred_small_17774(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, double arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->ftDBSCAN_doublezisegred_small_17774, "ftDBSCAN_double.segred_small_17774", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_ftDBSCAN_doublezisegred_large_17774(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, double arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, int64_t arg7, int64_t arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14, gpu_mem arg15)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[17] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14, &arg15};
        size_t args_sizes[17] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14), sizeof(arg15)};
        
        return gpu_launch_kernel(ctx, ctx->program->ftDBSCAN_doublezisegred_large_17774, "ftDBSCAN_double.segred_large_17774", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 17, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_ftDBSCAN_floatzisegmap_17062(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->ftDBSCAN_floatzisegmap_17062, "ftDBSCAN_float.segmap_17062", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_ftDBSCAN_floatzisegmap_17115(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, float arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->ftDBSCAN_floatzisegmap_17115, "ftDBSCAN_float.segmap_17115", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_ftDBSCAN_floatzisegmap_intrablock_17151(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, float arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->ftDBSCAN_floatzisegmap_intrablock_17151, "ftDBSCAN_float.segmap_intrablock_17151", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_ftDBSCAN_floatzisegmap_17369(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->ftDBSCAN_floatzisegmap_17369, "ftDBSCAN_float.segmap_17369", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_ftDBSCAN_floatzisegmap_17382(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4};
        size_t args_sizes[6] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4)};
        
        return gpu_launch_kernel(ctx, ctx->program->ftDBSCAN_floatzisegmap_17382, "ftDBSCAN_float.segmap_17382", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_ftDBSCAN_floatzisegred_small_17401(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, float arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->ftDBSCAN_floatzisegred_small_17401, "ftDBSCAN_float.segred_small_17401", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_ftDBSCAN_floatzisegred_large_17401(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, float arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, int64_t arg7, int64_t arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14, gpu_mem arg15)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[17] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14, &arg15};
        size_t args_sizes[17] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14), sizeof(arg15)};
        
        return gpu_launch_kernel(ctx, ctx->program->ftDBSCAN_floatzisegred_large_17401, "ftDBSCAN_float.segred_large_17401", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 17, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_ftDBSCAN_star_doublezisegmap_16302(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->ftDBSCAN_star_doublezisegmap_16302, "ftDBSCAN_star_double.segmap_16302", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_ftDBSCAN_star_floatzisegmap_16284(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->ftDBSCAN_star_floatzisegmap_16284, "ftDBSCAN_star_float.segmap_16284", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_find_cluster_ids_6783zisegmap_16348(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, float arg2, int64_t arg3, int64_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->find_cluster_ids_6783zisegmap_16348, "find_cluster_ids_6783.segmap_16348", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_find_cluster_ids_6783zisegmap_intrablock_16377(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, float arg2, int64_t arg3, int64_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->find_cluster_ids_6783zisegmap_intrablock_16377, "find_cluster_ids_6783.segmap_intrablock_16377", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_find_cluster_ids_6783zisegmap_16554(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->find_cluster_ids_6783zisegmap_16554, "find_cluster_ids_6783.segmap_16554", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_find_cluster_ids_6783zisegmap_16567(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, float arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->find_cluster_ids_6783zisegmap_16567, "find_cluster_ids_6783.segmap_16567", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_find_cluster_ids_6783zisegred_small_16588(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->find_cluster_ids_6783zisegred_small_16588, "find_cluster_ids_6783.segred_small_16588", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_find_cluster_ids_6783zisegred_large_16588(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->find_cluster_ids_6783zisegred_large_16588, "find_cluster_ids_6783.segred_large_16588", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_find_cluster_ids_6783zisegred_nonseg_16605(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->find_cluster_ids_6783zisegred_nonseg_16605, "find_cluster_ids_6783.segred_nonseg_16605", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_find_cluster_ids_6783zisegscan_16613(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->find_cluster_ids_6783zisegscan_16613, "find_cluster_ids_6783.segscan_16613", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_find_cluster_ids_6783zisegmap_16633(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->find_cluster_ids_6783zisegmap_16633, "find_cluster_ids_6783.segmap_16633", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_find_cluster_ids_6783zisegmap_16664(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[10] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[10] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->find_cluster_ids_6783zisegmap_16664, "find_cluster_ids_6783.segmap_16664", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 10, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_find_cluster_ids_6890zisegmap_16719(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, double arg2, int64_t arg3, int64_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->find_cluster_ids_6890zisegmap_16719, "find_cluster_ids_6890.segmap_16719", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_find_cluster_ids_6890zisegmap_intrablock_16748(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, double arg2, int64_t arg3, int64_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->find_cluster_ids_6890zisegmap_intrablock_16748, "find_cluster_ids_6890.segmap_intrablock_16748", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_find_cluster_ids_6890zisegmap_16925(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->find_cluster_ids_6890zisegmap_16925, "find_cluster_ids_6890.segmap_16925", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_find_cluster_ids_6890zisegmap_16938(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, double arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->find_cluster_ids_6890zisegmap_16938, "find_cluster_ids_6890.segmap_16938", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_find_cluster_ids_6890zisegred_small_16959(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->find_cluster_ids_6890zisegred_small_16959, "find_cluster_ids_6890.segred_small_16959", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_find_cluster_ids_6890zisegred_large_16959(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->find_cluster_ids_6890zisegred_large_16959, "find_cluster_ids_6890.segred_large_16959", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_find_cluster_ids_6890zisegred_nonseg_16976(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->find_cluster_ids_6890zisegred_nonseg_16976, "find_cluster_ids_6890.segred_nonseg_16976", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_find_cluster_ids_6890zisegscan_16984(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->find_cluster_ids_6890zisegscan_16984, "find_cluster_ids_6890.segscan_16984", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_find_cluster_ids_6890zisegmap_17004(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->find_cluster_ids_6890zisegmap_17004, "find_cluster_ids_6890.segmap_17004", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_find_cluster_ids_6890zisegmap_17035(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[10] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[10] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->find_cluster_ids_6890zisegmap_17035, "find_cluster_ids_6890.segmap_17035", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 10, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_get_num_neighbours_6695zisegmap_17835(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, float arg2, int64_t arg3, int64_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->get_num_neighbours_6695zisegmap_17835, "get_num_neighbours_6695.segmap_17835", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_get_num_neighbours_6695zisegmap_intrablock_17863(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, float arg2, int64_t arg3, int64_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[10] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8};
        size_t args_sizes[10] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8)};
        
        return gpu_launch_kernel(ctx, ctx->program->get_num_neighbours_6695zisegmap_intrablock_17863, "get_num_neighbours_6695.segmap_intrablock_17863", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 10, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_get_num_neighbours_6695zisegmap_18046(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->get_num_neighbours_6695zisegmap_18046, "get_num_neighbours_6695.segmap_18046", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_get_num_neighbours_6695zisegmap_18059(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, float arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->get_num_neighbours_6695zisegmap_18059, "get_num_neighbours_6695.segmap_18059", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_get_num_neighbours_6695zisegred_small_18078(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->get_num_neighbours_6695zisegred_small_18078, "get_num_neighbours_6695.segred_small_18078", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_get_num_neighbours_6695zisegred_large_18078(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, int64_t arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[13] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11};
        size_t args_sizes[13] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11)};
        
        return gpu_launch_kernel(ctx, ctx->program->get_num_neighbours_6695zisegred_large_18078, "get_num_neighbours_6695.segred_large_18078", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 13, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_get_num_neighbours_6695zisegmap_18089(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->get_num_neighbours_6695zisegmap_18089, "get_num_neighbours_6695.segmap_18089", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_get_num_neighbours_6842zisegmap_18136(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, double arg2, int64_t arg3, int64_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->get_num_neighbours_6842zisegmap_18136, "get_num_neighbours_6842.segmap_18136", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_get_num_neighbours_6842zisegmap_intrablock_18164(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, double arg2, int64_t arg3, int64_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[10] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8};
        size_t args_sizes[10] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8)};
        
        return gpu_launch_kernel(ctx, ctx->program->get_num_neighbours_6842zisegmap_intrablock_18164, "get_num_neighbours_6842.segmap_intrablock_18164", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 10, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_get_num_neighbours_6842zisegmap_18347(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->get_num_neighbours_6842zisegmap_18347, "get_num_neighbours_6842.segmap_18347", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_get_num_neighbours_6842zisegmap_18360(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, double arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->get_num_neighbours_6842zisegmap_18360, "get_num_neighbours_6842.segmap_18360", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_get_num_neighbours_6842zisegred_small_18379(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->get_num_neighbours_6842zisegred_small_18379, "get_num_neighbours_6842.segred_small_18379", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_get_num_neighbours_6842zisegred_large_18379(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, int64_t arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[13] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11};
        size_t args_sizes[13] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11)};
        
        return gpu_launch_kernel(ctx, ctx->program->get_num_neighbours_6842zisegred_large_18379, "get_num_neighbours_6842.segred_large_18379", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 13, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_get_num_neighbours_6842zisegmap_18390(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->get_num_neighbours_6842zisegmap_18390, "get_num_neighbours_6842.segmap_18390", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_isolate_core_points_6732zisegscan_16182(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->isolate_core_points_6732zisegscan_16182, "isolate_core_points_6732.segscan_16182", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_isolate_core_points_6732zisegmap_16203(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->isolate_core_points_6732zisegmap_16203, "isolate_core_points_6732.segmap_16203", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_isolate_core_points_6732zisegmap_16214(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->isolate_core_points_6732zisegmap_16214, "isolate_core_points_6732.segmap_16214", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_isolate_core_points_6871zisegscan_16229(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->isolate_core_points_6871zisegscan_16229, "isolate_core_points_6871.segscan_16229", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_isolate_core_points_6871zisegmap_16250(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->isolate_core_points_6871zisegmap_16250, "isolate_core_points_6871.segmap_16250", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_isolate_core_points_6871zisegmap_16261(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->isolate_core_points_6871zisegmap_16261, "isolate_core_points_6871.segmap_16261", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
struct futhark_i64_1d {
    struct memblock_device mem;
    int64_t shape[1];
};
struct futhark_i64_1d *futhark_new_i64_1d(struct futhark_context *ctx, const int64_t *data, int64_t dim0)
{
    int err = 0;
    struct futhark_i64_1d *bad = NULL;
    struct futhark_i64_1d *arr = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * 8, "arr->mem"))
        err = 1;
    arr->shape[0] = dim0;
    err = memcpy_host2gpu(ctx, false, arr->mem.mem, 0, (const unsigned char *) data, 0, (size_t) dim0 * 8);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    if (err != 0) {
        free(arr);
        return bad;
    }
    return arr;
}
struct futhark_i64_1d *futhark_new_raw_i64_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0)
{
    int err = 0;
    struct futhark_i64_1d *bad = NULL;
    struct futhark_i64_1d *arr = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    arr->mem.mem = data;
    arr->shape[0] = dim0;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr, int64_t *data)
{
    int err = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    err = memcpy_gpu2host(ctx, false, (unsigned char *) data, 0, arr->mem.mem, 0, (size_t) arr->shape[0] * 8);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return err;
}
int futhark_index_i64_1d(struct futhark_context *ctx, int64_t *out, struct futhark_i64_1d *arr, int64_t i0)
{
    int err = 0;
    
    if (i0 >= 0 && i0 < arr->shape[0]) {
        lock_lock(&ctx->lock);
        CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
        err = memcpy_gpu2host(ctx, false, (unsigned char *) out, 0, arr->mem.mem, 8 * (i0 * 1), 8);
        CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
        lock_unlock(&ctx->lock);
    } else {
        err = 1;
        set_error(ctx, strdup("Index out of bounds."));
    }
    return err;
}
CUdeviceptr futhark_values_raw_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr)
{
    (void) ctx;
    return arr->shape;
}
struct futhark_f32_2d {
    struct memblock_device mem;
    int64_t shape[2];
};
struct futhark_f32_2d *futhark_new_f32_2d(struct futhark_context *ctx, const float *data, int64_t dim0, int64_t dim1)
{
    int err = 0;
    struct futhark_f32_2d *bad = NULL;
    struct futhark_f32_2d *arr = (struct futhark_f32_2d *) malloc(sizeof(struct futhark_f32_2d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * dim1 * 4, "arr->mem"))
        err = 1;
    arr->shape[0] = dim0;
    arr->shape[1] = dim1;
    err = memcpy_host2gpu(ctx, false, arr->mem.mem, 0, (const unsigned char *) data, 0, (size_t) (dim0 * dim1) * 4);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    if (err != 0) {
        free(arr);
        return bad;
    }
    return arr;
}
struct futhark_f32_2d *futhark_new_raw_f32_2d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0, int64_t dim1)
{
    int err = 0;
    struct futhark_f32_2d *bad = NULL;
    struct futhark_f32_2d *arr = (struct futhark_f32_2d *) malloc(sizeof(struct futhark_f32_2d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    arr->mem.mem = data;
    arr->shape[0] = dim0;
    arr->shape[1] = dim1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_f32_2d(struct futhark_context *ctx, struct futhark_f32_2d *arr)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_f32_2d(struct futhark_context *ctx, struct futhark_f32_2d *arr, float *data)
{
    int err = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    err = memcpy_gpu2host(ctx, false, (unsigned char *) data, 0, arr->mem.mem, 0, (size_t) (arr->shape[0] * arr->shape[1]) * 4);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return err;
}
int futhark_index_f32_2d(struct futhark_context *ctx, float *out, struct futhark_f32_2d *arr, int64_t i0, int64_t i1)
{
    int err = 0;
    
    if ((i0 >= 0 && i0 < arr->shape[0]) && (i1 >= 0 && i1 < arr->shape[1])) {
        lock_lock(&ctx->lock);
        CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
        err = memcpy_gpu2host(ctx, false, (unsigned char *) out, 0, arr->mem.mem, 4 * (i0 * arr->shape[1] + i1 * 1), 4);
        CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
        lock_unlock(&ctx->lock);
    } else {
        err = 1;
        set_error(ctx, strdup("Index out of bounds."));
    }
    return err;
}
CUdeviceptr futhark_values_raw_f32_2d(struct futhark_context *ctx, struct futhark_f32_2d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_f32_2d(struct futhark_context *ctx, struct futhark_f32_2d *arr)
{
    (void) ctx;
    return arr->shape;
}
struct futhark_f64_2d {
    struct memblock_device mem;
    int64_t shape[2];
};
struct futhark_f64_2d *futhark_new_f64_2d(struct futhark_context *ctx, const double *data, int64_t dim0, int64_t dim1)
{
    int err = 0;
    struct futhark_f64_2d *bad = NULL;
    struct futhark_f64_2d *arr = (struct futhark_f64_2d *) malloc(sizeof(struct futhark_f64_2d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * dim1 * 8, "arr->mem"))
        err = 1;
    arr->shape[0] = dim0;
    arr->shape[1] = dim1;
    err = memcpy_host2gpu(ctx, false, arr->mem.mem, 0, (const unsigned char *) data, 0, (size_t) (dim0 * dim1) * 8);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    if (err != 0) {
        free(arr);
        return bad;
    }
    return arr;
}
struct futhark_f64_2d *futhark_new_raw_f64_2d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0, int64_t dim1)
{
    int err = 0;
    struct futhark_f64_2d *bad = NULL;
    struct futhark_f64_2d *arr = (struct futhark_f64_2d *) malloc(sizeof(struct futhark_f64_2d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    arr->mem.mem = data;
    arr->shape[0] = dim0;
    arr->shape[1] = dim1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_f64_2d(struct futhark_context *ctx, struct futhark_f64_2d *arr)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_f64_2d(struct futhark_context *ctx, struct futhark_f64_2d *arr, double *data)
{
    int err = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    err = memcpy_gpu2host(ctx, false, (unsigned char *) data, 0, arr->mem.mem, 0, (size_t) (arr->shape[0] * arr->shape[1]) * 8);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return err;
}
int futhark_index_f64_2d(struct futhark_context *ctx, double *out, struct futhark_f64_2d *arr, int64_t i0, int64_t i1)
{
    int err = 0;
    
    if ((i0 >= 0 && i0 < arr->shape[0]) && (i1 >= 0 && i1 < arr->shape[1])) {
        lock_lock(&ctx->lock);
        CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
        err = memcpy_gpu2host(ctx, false, (unsigned char *) out, 0, arr->mem.mem, 8 * (i0 * arr->shape[1] + i1 * 1), 8);
        CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
        lock_unlock(&ctx->lock);
    } else {
        err = 1;
        set_error(ctx, strdup("Index out of bounds."));
    }
    return err;
}
CUdeviceptr futhark_values_raw_f64_2d(struct futhark_context *ctx, struct futhark_f64_2d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_f64_2d(struct futhark_context *ctx, struct futhark_f64_2d *arr)
{
    (void) ctx;
    return arr->shape;
}
struct futhark_opaque_core_cluster_float {
    struct futhark_i64_1d *v0;
    struct futhark_f32_2d *v1;
    int64_t v2;
};
int futhark_project_opaque_core_cluster_float_core_ids(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_core_cluster_float *obj)
{
    (void) ctx;
    
    struct futhark_i64_1d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_i64_1d));
    memcpy(v, obj->v0, sizeof(struct futhark_i64_1d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_project_opaque_core_cluster_float_core_pts(struct futhark_context *ctx, struct futhark_f32_2d **out, const struct futhark_opaque_core_cluster_float *obj)
{
    (void) ctx;
    
    struct futhark_f32_2d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_f32_2d));
    memcpy(v, obj->v1, sizeof(struct futhark_f32_2d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_project_opaque_core_cluster_float_len(struct futhark_context *ctx, int64_t *out, const struct futhark_opaque_core_cluster_float *obj)
{
    (void) ctx;
    
    int64_t v;
    
    v = obj->v2;
    *out = v;
    return 0;
}
int futhark_new_opaque_core_cluster_float(struct futhark_context *ctx, struct futhark_opaque_core_cluster_float **out, const struct futhark_i64_1d *f_core_ids, const struct futhark_f32_2d *f_core_pts, const int64_t f_len)
{
    struct futhark_opaque_core_cluster_float *v = malloc(sizeof(struct futhark_opaque_core_cluster_float));
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    {
        v->v0 = malloc(sizeof(struct futhark_i64_1d));
        *v->v0 = *f_core_ids;
        (void) (*v->v0->mem.references)++;
    }
    {
        v->v1 = malloc(sizeof(struct futhark_f32_2d));
        *v->v1 = *f_core_pts;
        (void) (*v->v1->mem.references)++;
    }
    v->v2 = f_len;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return FUTHARK_SUCCESS;
}
int futhark_free_opaque_core_cluster_float(struct futhark_context *ctx, struct futhark_opaque_core_cluster_float *obj)
{
    (void) ctx;
    
    int ret = 0, tmp;
    
    if (obj->v0 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v0)) != 0)
        ret = tmp;
    if (obj->v1 != NULL && (tmp = futhark_free_f32_2d(ctx, obj->v1)) != 0)
        ret = tmp;
    free(obj);
    return ret;
}
int futhark_store_opaque_core_cluster_float(struct futhark_context *ctx, const struct futhark_opaque_core_cluster_float *obj, void **p, size_t *n)
{
    (void) ctx;
    
    int ret = 0;
    int64_t size_0 = 7 + 1 * sizeof(int64_t) + futhark_shape_i64_1d(ctx, obj->v0)[0] * sizeof(int64_t);
    int64_t size_1 = 7 + 2 * sizeof(int64_t) + futhark_shape_f32_2d(ctx, obj->v1)[0] * futhark_shape_f32_2d(ctx, obj->v1)[1] * sizeof(float);
    int64_t size_2 = 7 + 0 * sizeof(int64_t) + 1 * sizeof(int64_t);
    
    *n = size_0 + size_1 + size_2;
    if (p != NULL && *p == NULL)
        *p = malloc(*n);
    if (p != NULL) {
        unsigned char *out = *p;
        
        *out++ = 'b';
        *out++ = 2;
        *out++ = 1;
        memcpy(out, " i64", 4);
        out += 4;
        memcpy(out, futhark_shape_i64_1d(ctx, obj->v0), 1 * sizeof(int64_t));
        out += 1 * sizeof(int64_t);
        ret |= futhark_values_i64_1d(ctx, obj->v0, (void *) out);
        out += futhark_shape_i64_1d(ctx, obj->v0)[0] * sizeof(int64_t);
        *out++ = 'b';
        *out++ = 2;
        *out++ = 2;
        memcpy(out, " f32", 4);
        out += 4;
        memcpy(out, futhark_shape_f32_2d(ctx, obj->v1), 2 * sizeof(int64_t));
        out += 2 * sizeof(int64_t);
        ret |= futhark_values_f32_2d(ctx, obj->v1, (void *) out);
        out += futhark_shape_f32_2d(ctx, obj->v1)[0] * futhark_shape_f32_2d(ctx, obj->v1)[1] * sizeof(float);
        *out++ = 'b';
        *out++ = 2;
        *out++ = 0;
        memcpy(out, " i64", 4);
        out += 4;
        memcpy(out, &obj->v2, sizeof(obj->v2));
        out += sizeof(obj->v2);
    }
    return ret;
}
struct futhark_opaque_core_cluster_float *futhark_restore_opaque_core_cluster_float(struct futhark_context *ctx, const void *p)
{
    (void) ctx;
    
    int err = 0;
    const unsigned char *src = p;
    struct futhark_opaque_core_cluster_float *obj = malloc(sizeof(struct futhark_opaque_core_cluster_float));
    int64_t shape_0[1] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 1;
    err |= memcmp(src, " i64", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_0, src, 1 * sizeof(int64_t));
        src += 1 * sizeof(int64_t);
    }
    
    const void *data_0 = src;
    
    obj->v0 = NULL;
    src += shape_0[0] * sizeof(int64_t);
    
    int64_t shape_1[2] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 2;
    err |= memcmp(src, " f32", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_1, src, 2 * sizeof(int64_t));
        src += 2 * sizeof(int64_t);
    }
    
    const void *data_1 = src;
    
    obj->v1 = NULL;
    src += shape_1[0] * shape_1[1] * sizeof(float);
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 0;
    err |= memcmp(src, " i64", 4) != 0;
    src += 4;
    if (err == 0) {
        src += 0 * sizeof(int64_t);
    }
    
    const void *data_2 = src;
    
    src += sizeof(obj->v2);
    if (err == 0) {
        obj->v0 = futhark_new_i64_1d(ctx, data_0, shape_0[0]);
        if (obj->v0 == NULL)
            err = 1;
        obj->v1 = futhark_new_f32_2d(ctx, data_1, shape_1[0], shape_1[1]);
        if (obj->v1 == NULL)
            err = 1;
        memcpy(&obj->v2, data_2, sizeof(obj->v2));
    }
    if (err != 0) {
        int ret = 0, tmp;
        
        if (obj->v0 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v0)) != 0)
            ret = tmp;
        if (obj->v1 != NULL && (tmp = futhark_free_f32_2d(ctx, obj->v1)) != 0)
            ret = tmp;
        free(obj);
        obj = NULL;
    }
    return obj;
}
struct futhark_opaque_core_cluster_double {
    struct futhark_i64_1d *v0;
    struct futhark_f64_2d *v1;
    int64_t v2;
};
int futhark_project_opaque_core_cluster_double_core_ids(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_core_cluster_double *obj)
{
    (void) ctx;
    
    struct futhark_i64_1d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_i64_1d));
    memcpy(v, obj->v0, sizeof(struct futhark_i64_1d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_project_opaque_core_cluster_double_core_pts(struct futhark_context *ctx, struct futhark_f64_2d **out, const struct futhark_opaque_core_cluster_double *obj)
{
    (void) ctx;
    
    struct futhark_f64_2d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_f64_2d));
    memcpy(v, obj->v1, sizeof(struct futhark_f64_2d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_project_opaque_core_cluster_double_len(struct futhark_context *ctx, int64_t *out, const struct futhark_opaque_core_cluster_double *obj)
{
    (void) ctx;
    
    int64_t v;
    
    v = obj->v2;
    *out = v;
    return 0;
}
int futhark_new_opaque_core_cluster_double(struct futhark_context *ctx, struct futhark_opaque_core_cluster_double **out, const struct futhark_i64_1d *f_core_ids, const struct futhark_f64_2d *f_core_pts, const int64_t f_len)
{
    struct futhark_opaque_core_cluster_double *v = malloc(sizeof(struct futhark_opaque_core_cluster_double));
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    {
        v->v0 = malloc(sizeof(struct futhark_i64_1d));
        *v->v0 = *f_core_ids;
        (void) (*v->v0->mem.references)++;
    }
    {
        v->v1 = malloc(sizeof(struct futhark_f64_2d));
        *v->v1 = *f_core_pts;
        (void) (*v->v1->mem.references)++;
    }
    v->v2 = f_len;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return FUTHARK_SUCCESS;
}
int futhark_free_opaque_core_cluster_double(struct futhark_context *ctx, struct futhark_opaque_core_cluster_double *obj)
{
    (void) ctx;
    
    int ret = 0, tmp;
    
    if (obj->v0 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v0)) != 0)
        ret = tmp;
    if (obj->v1 != NULL && (tmp = futhark_free_f64_2d(ctx, obj->v1)) != 0)
        ret = tmp;
    free(obj);
    return ret;
}
int futhark_store_opaque_core_cluster_double(struct futhark_context *ctx, const struct futhark_opaque_core_cluster_double *obj, void **p, size_t *n)
{
    (void) ctx;
    
    int ret = 0;
    int64_t size_0 = 7 + 1 * sizeof(int64_t) + futhark_shape_i64_1d(ctx, obj->v0)[0] * sizeof(int64_t);
    int64_t size_1 = 7 + 2 * sizeof(int64_t) + futhark_shape_f64_2d(ctx, obj->v1)[0] * futhark_shape_f64_2d(ctx, obj->v1)[1] * sizeof(double);
    int64_t size_2 = 7 + 0 * sizeof(int64_t) + 1 * sizeof(int64_t);
    
    *n = size_0 + size_1 + size_2;
    if (p != NULL && *p == NULL)
        *p = malloc(*n);
    if (p != NULL) {
        unsigned char *out = *p;
        
        *out++ = 'b';
        *out++ = 2;
        *out++ = 1;
        memcpy(out, " i64", 4);
        out += 4;
        memcpy(out, futhark_shape_i64_1d(ctx, obj->v0), 1 * sizeof(int64_t));
        out += 1 * sizeof(int64_t);
        ret |= futhark_values_i64_1d(ctx, obj->v0, (void *) out);
        out += futhark_shape_i64_1d(ctx, obj->v0)[0] * sizeof(int64_t);
        *out++ = 'b';
        *out++ = 2;
        *out++ = 2;
        memcpy(out, " f64", 4);
        out += 4;
        memcpy(out, futhark_shape_f64_2d(ctx, obj->v1), 2 * sizeof(int64_t));
        out += 2 * sizeof(int64_t);
        ret |= futhark_values_f64_2d(ctx, obj->v1, (void *) out);
        out += futhark_shape_f64_2d(ctx, obj->v1)[0] * futhark_shape_f64_2d(ctx, obj->v1)[1] * sizeof(double);
        *out++ = 'b';
        *out++ = 2;
        *out++ = 0;
        memcpy(out, " i64", 4);
        out += 4;
        memcpy(out, &obj->v2, sizeof(obj->v2));
        out += sizeof(obj->v2);
    }
    return ret;
}
struct futhark_opaque_core_cluster_double *futhark_restore_opaque_core_cluster_double(struct futhark_context *ctx, const void *p)
{
    (void) ctx;
    
    int err = 0;
    const unsigned char *src = p;
    struct futhark_opaque_core_cluster_double *obj = malloc(sizeof(struct futhark_opaque_core_cluster_double));
    int64_t shape_0[1] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 1;
    err |= memcmp(src, " i64", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_0, src, 1 * sizeof(int64_t));
        src += 1 * sizeof(int64_t);
    }
    
    const void *data_0 = src;
    
    obj->v0 = NULL;
    src += shape_0[0] * sizeof(int64_t);
    
    int64_t shape_1[2] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 2;
    err |= memcmp(src, " f64", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_1, src, 2 * sizeof(int64_t));
        src += 2 * sizeof(int64_t);
    }
    
    const void *data_1 = src;
    
    obj->v1 = NULL;
    src += shape_1[0] * shape_1[1] * sizeof(double);
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 0;
    err |= memcmp(src, " i64", 4) != 0;
    src += 4;
    if (err == 0) {
        src += 0 * sizeof(int64_t);
    }
    
    const void *data_2 = src;
    
    src += sizeof(obj->v2);
    if (err == 0) {
        obj->v0 = futhark_new_i64_1d(ctx, data_0, shape_0[0]);
        if (obj->v0 == NULL)
            err = 1;
        obj->v1 = futhark_new_f64_2d(ctx, data_1, shape_1[0], shape_1[1]);
        if (obj->v1 == NULL)
            err = 1;
        memcpy(&obj->v2, data_2, sizeof(obj->v2));
    }
    if (err != 0) {
        int ret = 0, tmp;
        
        if (obj->v0 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v0)) != 0)
            ret = tmp;
        if (obj->v1 != NULL && (tmp = futhark_free_f64_2d(ctx, obj->v1)) != 0)
            ret = tmp;
        free(obj);
        obj = NULL;
    }
    return obj;
}

FUTHARK_FUN_ATTR int futrts_builtinzhiota_i64(struct futhark_context *ctx, struct memblock_device mem_18651, int64_t n_18652, int64_t x_18653, int64_t s_18654)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_18763 = ctx->constants->counters_mem_18763;
    struct memblock_device counters_mem_18765 = ctx->constants->counters_mem_18765;
    struct memblock_device counters_mem_18789 = ctx->constants->counters_mem_18789;
    struct memblock_device counters_mem_18825 = ctx->constants->counters_mem_18825;
    struct memblock_device global_dynid_mem_18686 = ctx->constants->global_dynid_mem_18686;
    struct memblock_device global_dynid_mem_18892 = ctx->constants->global_dynid_mem_18892;
    int64_t tblock_sizze_18660;
    
    tblock_sizze_18660 = *ctx->tuning_params.builtinzhiota_i64zitblock_sizze_18660;
    
    int64_t virt_num_tblocks_18661 = sdiv_up64(n_18652, tblock_sizze_18660);
    int64_t num_tblocks_18662 = smin64(virt_num_tblocks_18661, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhiota_i64ziiota_i64_18656(ctx, num_tblocks_18662, 1, 1, tblock_sizze_18660, 1, 1, (int64_t) 0, n_18652, x_18653, s_18654, virt_num_tblocks_18661, num_tblocks_18662, mem_18651.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i32(struct futhark_context *ctx, struct memblock_device mem_18765, int64_t num_elems_18766, int32_t val_18767)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_18763 = ctx->constants->counters_mem_18763;
    struct memblock_device counters_mem_18765 = ctx->constants->counters_mem_18765;
    struct memblock_device counters_mem_18789 = ctx->constants->counters_mem_18789;
    struct memblock_device counters_mem_18825 = ctx->constants->counters_mem_18825;
    struct memblock_device global_dynid_mem_18686 = ctx->constants->global_dynid_mem_18686;
    struct memblock_device global_dynid_mem_18892 = ctx->constants->global_dynid_mem_18892;
    int64_t replicate_n_18769 = num_elems_18766;
    int64_t tblock_sizze_18774;
    
    tblock_sizze_18774 = *ctx->tuning_params.builtinzhreplicate_i32zitblock_sizze_18774;
    
    int64_t virt_num_tblocks_18775 = sdiv_up64(replicate_n_18769, tblock_sizze_18774);
    int64_t num_tblocks_18776 = smin64(virt_num_tblocks_18775, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_i32zireplicate_18770(ctx, num_tblocks_18776, 1, 1, tblock_sizze_18774, 1, 1, (int64_t) 0, num_elems_18766, val_18767, replicate_n_18769, virt_num_tblocks_18775, num_tblocks_18776, mem_18765.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i64(struct futhark_context *ctx, struct memblock_device mem_18651, int64_t num_elems_18652, int64_t val_18653)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_18763 = ctx->constants->counters_mem_18763;
    struct memblock_device counters_mem_18765 = ctx->constants->counters_mem_18765;
    struct memblock_device counters_mem_18789 = ctx->constants->counters_mem_18789;
    struct memblock_device counters_mem_18825 = ctx->constants->counters_mem_18825;
    struct memblock_device global_dynid_mem_18686 = ctx->constants->global_dynid_mem_18686;
    struct memblock_device global_dynid_mem_18892 = ctx->constants->global_dynid_mem_18892;
    int64_t replicate_n_18655 = num_elems_18652;
    int64_t tblock_sizze_18660;
    
    tblock_sizze_18660 = *ctx->tuning_params.builtinzhreplicate_i64zitblock_sizze_18660;
    
    int64_t virt_num_tblocks_18661 = sdiv_up64(replicate_n_18655, tblock_sizze_18660);
    int64_t num_tblocks_18662 = smin64(virt_num_tblocks_18661, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_i64zireplicate_18656(ctx, num_tblocks_18662, 1, 1, tblock_sizze_18660, 1, 1, (int64_t) 0, num_elems_18652, val_18653, replicate_n_18655, virt_num_tblocks_18661, num_tblocks_18662, mem_18651.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i8(struct futhark_context *ctx, struct memblock_device mem_18868, int64_t num_elems_18869, int8_t val_18870)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_18763 = ctx->constants->counters_mem_18763;
    struct memblock_device counters_mem_18765 = ctx->constants->counters_mem_18765;
    struct memblock_device counters_mem_18789 = ctx->constants->counters_mem_18789;
    struct memblock_device counters_mem_18825 = ctx->constants->counters_mem_18825;
    struct memblock_device global_dynid_mem_18686 = ctx->constants->global_dynid_mem_18686;
    struct memblock_device global_dynid_mem_18892 = ctx->constants->global_dynid_mem_18892;
    int64_t replicate_n_18872 = num_elems_18869;
    int64_t tblock_sizze_18877;
    
    tblock_sizze_18877 = *ctx->tuning_params.builtinzhreplicate_i8zitblock_sizze_18877;
    
    int64_t virt_num_tblocks_18878 = sdiv_up64(replicate_n_18872, tblock_sizze_18877);
    int64_t num_tblocks_18879 = smin64(virt_num_tblocks_18878, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_i8zireplicate_18873(ctx, num_tblocks_18879, 1, 1, tblock_sizze_18877, 1, 1, (int64_t) 0, num_elems_18869, val_18870, replicate_n_18872, virt_num_tblocks_18878, num_tblocks_18879, mem_18868.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_ftDBSCAN_double(struct futhark_context *ctx, struct memblock_device *mem_out_p_19021, struct memblock_device dat_mem_18419, int64_t nz2080U_15177, int64_t dimz2081U_15178, double eps_15180, int64_t minPts_15181, int64_t pMem_15182, int64_t gather_psizze_15183)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device segred_tmp_mem_18787;
    
    segred_tmp_mem_18787.references = NULL;
    
    struct memblock_device segred_tmp_mem_18785;
    
    segred_tmp_mem_18785.references = NULL;
    
    struct memblock_device mem_18460;
    
    mem_18460.references = NULL;
    
    struct memblock_device mem_18455;
    
    mem_18455.references = NULL;
    
    struct memblock_device mem_18451;
    
    mem_18451.references = NULL;
    
    struct memblock_device mem_18434;
    
    mem_18434.references = NULL;
    
    struct memblock_device color_18527;
    
    color_18527.references = NULL;
    
    struct memblock_device color_18526;
    
    color_18526.references = NULL;
    
    struct memblock_device mem_18426;
    
    mem_18426.references = NULL;
    
    struct memblock_device ext_mem_18424;
    
    ext_mem_18424.references = NULL;
    
    struct memblock_device mem_18489;
    
    mem_18489.references = NULL;
    
    struct memblock_device ext_mem_18492;
    
    ext_mem_18492.references = NULL;
    
    struct memblock_device ext_mem_18423;
    
    ext_mem_18423.references = NULL;
    
    struct memblock_device mem_18422;
    
    mem_18422.references = NULL;
    
    struct memblock_device ext_mem_18420;
    
    ext_mem_18420.references = NULL;
    
    struct memblock_device mem_out_18650;
    
    mem_out_18650.references = NULL;
    
    struct memblock_device counters_mem_18763 = ctx->constants->counters_mem_18763;
    struct memblock_device counters_mem_18765 = ctx->constants->counters_mem_18765;
    struct memblock_device counters_mem_18789 = ctx->constants->counters_mem_18789;
    struct memblock_device counters_mem_18825 = ctx->constants->counters_mem_18825;
    struct memblock_device global_dynid_mem_18686 = ctx->constants->global_dynid_mem_18686;
    struct memblock_device global_dynid_mem_18892 = ctx->constants->global_dynid_mem_18892;
    bool zzero_15986 = nz2080U_15177 == (int64_t) 0;
    bool nonzzero_15987 = !zzero_15986;
    bool nonzzero_cert_15988;
    
    if (!nonzzero_15987) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ft_libs/ftDBSCAN.fut:127:46-48\n   #1  ft_libs/ftDBSCAN.fut:215:33-56\n   #2  ft_libs/ftDBSCAN.fut:215:9-56\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t max_arg1_15989 = sdiv64(pMem_15182, nz2080U_15177);
    int64_t max_res_15990 = smax64((int64_t) 1, max_arg1_15989);
    
    if (futrts_get_num_neighbours_6842(ctx, &ext_mem_18420, dat_mem_18419, nz2080U_15177, dimz2081U_15178, eps_15180, max_res_15990) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t segmap_tblock_sizze_17431;
    
    segmap_tblock_sizze_17431 = *ctx->tuning_params.ftDBSCAN_doublezisegmap_tblock_sizze_17423;
    
    int64_t segmap_usable_groups_17432 = sdiv_up64(nz2080U_15177, segmap_tblock_sizze_17431);
    
    if (memblock_alloc_device(ctx, &mem_18422, nz2080U_15177, "mem_18422")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_18651 = sext_i64_i32(sdiv_up64(nz2080U_15177, segmap_tblock_sizze_17431));
    
    {
        err = gpu_kernel_ftDBSCAN_doublezisegmap_17435(ctx, segmap_usable_groups_17432, 1, 1, *ctx->tuning_params.ftDBSCAN_doublezisegmap_tblock_sizze_17423, 1, 1, (int64_t) 0, nz2080U_15177, minPts_15181, ext_mem_18420.mem, mem_18422.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &ext_mem_18420, "ext_mem_18420") != 0)
        return 1;
    
    int64_t corePts_15993;
    
    if (futrts_isolate_core_points_6871(ctx, &ext_mem_18423, &corePts_15993, dat_mem_18419, mem_18422, nz2080U_15177, dimz2081U_15178) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_unref_device(ctx, &mem_18422, "mem_18422") != 0)
        return 1;
    
    bool cond_15995 = corePts_15993 == (int64_t) 0;
    int64_t bytes_18425 = (int64_t) 8 * nz2080U_15177;
    
    if (cond_15995) {
        if (memblock_alloc_device(ctx, &mem_18489, bytes_18425, "mem_18489")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i64(ctx, mem_18489, nz2080U_15177, (int64_t) -1) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_18492, &mem_18489, "mem_18489") != 0)
            return 1;
    } else {
        bool nonzzero_15998 = !cond_15995;
        bool nonzzero_cert_15999;
        
        if (!nonzzero_15998) {
            set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ft_libs/ftDBSCAN.fut:135:46-62\n   #1  ft_libs/ftDBSCAN.fut:215:33-56\n   #2  ft_libs/ftDBSCAN.fut:215:9-56\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t max_arg1_16000 = sdiv64(pMem_15182, corePts_15993);
        int64_t max_res_16001 = smax64((int64_t) 1, max_arg1_16000);
        int64_t zm_lhs_16003 = add64(nz2080U_15177, max_res_16001);
        int64_t zs_lhs_16004 = sub64(zm_lhs_16003, (int64_t) 1);
        bool zzero_16005 = max_res_16001 == (int64_t) 0;
        bool nonzzero_16006 = !zzero_16005;
        bool nonzzero_cert_16007;
        
        if (!nonzzero_16006) {
            set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ft_libs/ftDBSCAN.fut:103:48-55\n   #1  ft_libs/ftDBSCAN.fut:215:33-56\n   #2  ft_libs/ftDBSCAN.fut:215:9-56\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t num_iter_16008 = sdiv64(zs_lhs_16004, max_res_16001);
        bool bounds_invalid_upwards_16010 = slt64(num_iter_16008, (int64_t) 0);
        bool valid_16011 = !bounds_invalid_upwards_16010;
        bool range_valid_c_16012;
        
        if (!valid_16011) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) (int64_t) 0, "..", (long long) (int64_t) 1, "..<", (long long) num_iter_16008, " is invalid.", "-> #0  /prelude/array.fut:94:3-11\n   #1  ft_libs/ftDBSCAN.fut:104:61-74\n   #2  ft_libs/ftDBSCAN.fut:215:33-56\n   #3  ft_libs/ftDBSCAN.fut:215:9-56\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        if (futrts_find_cluster_ids_6890(ctx, &ext_mem_18424, ext_mem_18423, corePts_15993, dimz2081U_15178, eps_15180, max_res_16001, gather_psizze_15183) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_18426, bytes_18425, "mem_18426")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i64(ctx, mem_18426, nz2080U_15177, (int64_t) -1) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t max_tblock_sizze_17519;
        
        max_tblock_sizze_17519 = ctx->max_thread_block_size;
        
        bool fits_17520 = sle64(corePts_15993, max_tblock_sizze_17519);
        bool suff_intra_par_17518;
        
        suff_intra_par_17518 = *ctx->tuning_params.ftDBSCAN_doublezisuff_intra_par_1 <= corePts_15993;
        if (ctx->logging)
            fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "ftDBSCAN_double.suff_intra_par_1", (long) corePts_15993, suff_intra_par_17518 ? "true" : "false");
        
        bool intra_suff_and_fits_17521 = suff_intra_par_17518 && fits_17520;
        int64_t y_17734 = dimz2081U_15178 * corePts_15993;
        int64_t segmap_tblock_sizze_17736;
        
        segmap_tblock_sizze_17736 = *ctx->tuning_params.ftDBSCAN_doublezisegmap_tblock_sizze_17637;
        
        int64_t segmap_tblock_sizze_17750;
        
        segmap_tblock_sizze_17750 = *ctx->tuning_params.ftDBSCAN_doublezisegmap_tblock_sizze_17607;
        
        int64_t segred_tblock_sizze_17767;
        
        segred_tblock_sizze_17767 = *ctx->tuning_params.ftDBSCAN_doublezisegred_tblock_sizze_17566;
        
        int64_t segmap_tblock_sizze_17484;
        
        segmap_tblock_sizze_17484 = *ctx->tuning_params.ftDBSCAN_doublezisegmap_tblock_sizze_17450;
        
        int64_t binop_y_18439 = corePts_15993 - (int64_t) 1;
        int64_t binop_y_18441 = smax64((int64_t) 0, binop_y_18439);
        int64_t binop_y_18443 = dimz2081U_15178 - (int64_t) 1;
        int64_t binop_x_18444 = smax64((int64_t) 0, binop_y_18443);
        int64_t bytes_18462 = (int64_t) 8 * dimz2081U_15178;
        
        for (int64_t i_16014 = 0; i_16014 < num_iter_16008; i_16014++) {
            int64_t inf_16016 = mul64(max_res_16001, i_16014);
            int64_t min_arg1_16017 = add64(max_res_16001, inf_16016);
            int64_t min_res_16018 = smin64(nz2080U_15177, min_arg1_16017);
            int64_t dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019 = sub64(min_res_16018, inf_16016);
            bool empty_slice_16020 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019 == (int64_t) 0;
            int64_t m_16021 = sub64(dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, (int64_t) 1);
            int64_t i_p_m_t_s_16022 = add64(inf_16016, m_16021);
            bool zzero_leq_i_p_m_t_s_16023 = sle64((int64_t) 0, i_p_m_t_s_16022);
            bool i_p_m_t_s_leq_w_16024 = slt64(i_p_m_t_s_16022, nz2080U_15177);
            bool zzero_lte_i_16025 = sle64((int64_t) 0, inf_16016);
            bool i_lte_j_16026 = sle64(inf_16016, min_res_16018);
            bool y_16027 = i_p_m_t_s_leq_w_16024 && zzero_lte_i_16025;
            bool y_16028 = zzero_leq_i_p_m_t_s_16023 && y_16027;
            bool forwards_ok_16029 = i_lte_j_16026 && y_16028;
            bool ok_or_empty_16030 = empty_slice_16020 || forwards_ok_16029;
            bool index_certs_16031;
            
            if (!ok_or_empty_16030) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) inf_16016, ":", (long long) min_res_16018, "] out of bounds for array of shape [", (long long) nz2080U_15177, "].", "-> #0  ft_libs/ftDBSCAN.fut:107:40-52\n   #1  ft_libs/ftDBSCAN.fut:215:33-56\n   #2  ft_libs/ftDBSCAN.fut:215:9-56\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            
            bool suff_outer_par_17446;
            
            suff_outer_par_17446 = *ctx->tuning_params.ftDBSCAN_doublezisuff_outer_par_0 <= dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019;
            if (ctx->logging)
                fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "ftDBSCAN_double.suff_outer_par_0", (long) dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, suff_outer_par_17446 ? "true" : "false");
            
            int64_t nest_sizze_17735 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019 * y_17734;
            int64_t nest_sizze_17749 = corePts_15993 * dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019;
            int64_t num_tblocks_17768;
            int64_t max_num_tblocks_18681;
            
            max_num_tblocks_18681 = *ctx->tuning_params.ftDBSCAN_doublezisegred_num_tblocks_17568;
            num_tblocks_17768 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nest_sizze_17749, segred_tblock_sizze_17767), max_num_tblocks_18681)));
            
            int64_t binop_x_18431 = (int64_t) 8 * dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019;
            int64_t binop_x_18432 = corePts_15993 * binop_x_18431;
            int64_t bytes_18433 = dimz2081U_15178 * binop_x_18432;
            int64_t binop_x_18436 = smax64((int64_t) 0, m_16021);
            int64_t binop_y_18437 = corePts_15993 * binop_x_18436;
            int64_t binop_x_18438 = smax64((int64_t) 0, binop_y_18437);
            int64_t binop_x_18442 = binop_x_18438 + binop_y_18441;
            int64_t binop_y_18446 = nest_sizze_17749 * binop_x_18444;
            int64_t binop_y_18447 = smax64((int64_t) 0, binop_y_18446);
            int64_t binop_y_18448 = binop_x_18442 + binop_y_18447;
            int64_t binop_y_18449 = (int64_t) 1 + binop_y_18448;
            int64_t bytes_18450 = (int64_t) 8 * binop_y_18449;
            int64_t binop_x_18597 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019 * bytes_18462;
            int64_t total_sizze_18598 = corePts_15993 * binop_x_18597;
            int64_t ctx_18604 = corePts_15993 * dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019;
            int64_t segmap_usable_groups_17485 = sdiv_up_safe64(dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, segmap_tblock_sizze_17484);
            int64_t num_threads_18588 = segmap_tblock_sizze_17484 * segmap_usable_groups_17485;
            int64_t total_sizze_18589 = bytes_18462 * num_threads_18588;
            int64_t shared_memory_capacity_18859;
            
            shared_memory_capacity_18859 = ctx->max_shared_memory;
            if (suff_outer_par_17446 && sle64((int64_t) 0, shared_memory_capacity_18859)) {
                if (memblock_alloc_device(ctx, &color_18526, total_sizze_18589, "color_18526")) {
                    err = 1;
                    goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_18682 = sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, segmap_tblock_sizze_17484));
                
                {
                    err = gpu_kernel_ftDBSCAN_doublezisegmap_17488(ctx, segmap_usable_groups_17485, 1, 1, *ctx->tuning_params.ftDBSCAN_doublezisegmap_tblock_sizze_17450, 1, 1, (int64_t) 0, dimz2081U_15178, eps_15180, corePts_15993, inf_16016, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, num_threads_18588, dat_mem_18419.mem, ext_mem_18423.mem, ext_mem_18424.mem, mem_18426.mem, color_18526.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                if (memblock_unref_device(ctx, &color_18526, "color_18526") != 0)
                    return 1;
            } else {
                int64_t shared_memory_capacity_18858;
                
                shared_memory_capacity_18858 = ctx->max_shared_memory;
                if (intra_suff_and_fits_17521 && sle64(sdiv_up64((int64_t) 8 * corePts_15993, (int64_t) 8) * (int64_t) 8 + sdiv_up64((int64_t) 8 * corePts_15993, (int64_t) 8) * (int64_t) 8, shared_memory_capacity_18858)) {
                    if (memblock_alloc_device(ctx, &color_18527, total_sizze_18598, "color_18527")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t num_chunks_18695 = sext_i64_i32(sdiv_up64(corePts_15993, corePts_15993));
                    int32_t virt_num_tblocks_18696 = sext_i64_i32(dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019);
                    
                    {
                        err = gpu_kernel_ftDBSCAN_doublezisegmap_intrablock_17524(ctx, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, 1, 1, corePts_15993, 1, 1, (int64_t) 8 * corePts_15993 + srem64((int64_t) 8 - srem64((int64_t) 8 * corePts_15993, (int64_t) 8), (int64_t) 8) + ((int64_t) 8 * corePts_15993 + srem64((int64_t) 8 - srem64((int64_t) 8 * corePts_15993, (int64_t) 8), (int64_t) 8)), dimz2081U_15178, eps_15180, corePts_15993, inf_16016, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, ctx_18604, dat_mem_18419.mem, ext_mem_18423.mem, ext_mem_18424.mem, mem_18426.mem, color_18527.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_unref_device(ctx, &color_18527, "color_18527") != 0)
                        return 1;
                } else {
                    int64_t segmap_usable_groups_17737 = sdiv_up64(nest_sizze_17735, segmap_tblock_sizze_17736);
                    
                    if (memblock_alloc_device(ctx, &mem_18434, bytes_18433, "mem_18434")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t virt_num_tblocks_18715 = sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019 * corePts_15993 * dimz2081U_15178, segmap_tblock_sizze_17736));
                    
                    {
                        err = gpu_kernel_ftDBSCAN_doublezisegmap_17742(ctx, segmap_usable_groups_17737, 1, 1, *ctx->tuning_params.ftDBSCAN_doublezisegmap_tblock_sizze_17637, 1, 1, (int64_t) 0, dimz2081U_15178, corePts_15993, inf_16016, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, dat_mem_18419.mem, ext_mem_18423.mem, mem_18434.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    
                    int64_t segmap_usable_groups_17751 = sdiv_up64(nest_sizze_17749, segmap_tblock_sizze_17750);
                    
                    if (memblock_alloc_device(ctx, &mem_18451, bytes_18450, "mem_18451")) {
                        err = 1;
                        goto cleanup;
                    }
                    if ((err = lmad_copy_gpu2gpu_8b(ctx, 3, mem_18451.mem, (int64_t) 0, (int64_t []) {corePts_15993, (int64_t) 1, corePts_15993 * dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019}, mem_18434.mem, (int64_t) 0, (int64_t []) {dimz2081U_15178 * corePts_15993, dimz2081U_15178, (int64_t) 1}, (int64_t []) {dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, corePts_15993, dimz2081U_15178})) != 0)
                        goto cleanup;
                    if (memblock_unref_device(ctx, &mem_18434, "mem_18434") != 0)
                        return 1;
                    if (memblock_alloc_device(ctx, &mem_18455, binop_x_18432, "mem_18455")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t virt_num_tblocks_18728 = sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019 * corePts_15993, segmap_tblock_sizze_17750));
                    
                    {
                        err = gpu_kernel_ftDBSCAN_doublezisegmap_17755(ctx, segmap_usable_groups_17751, 1, 1, *ctx->tuning_params.ftDBSCAN_doublezisegmap_tblock_sizze_17607, 1, 1, (int64_t) 0, dimz2081U_15178, corePts_15993, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, mem_18451.mem, mem_18455.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_unref_device(ctx, &mem_18451, "mem_18451") != 0)
                        return 1;
                    if (memblock_alloc_device(ctx, &mem_18460, binop_x_18431, "mem_18460")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegRed");
                    
                    int64_t chunk_sizze_18740 = (int64_t) 1;
                    
                    if (slt64(corePts_15993 * (int64_t) 2, segred_tblock_sizze_17767 * chunk_sizze_18740)) {
                        int64_t segment_sizze_nonzzero_18741 = smax64((int64_t) 1, corePts_15993);
                        int64_t num_threads_18742 = segred_tblock_sizze_17767 * segred_tblock_sizze_17767;
                        
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "# SegRed-small");
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) corePts_15993, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "segments_per_block", (long long) squot64(segred_tblock_sizze_17767, segment_sizze_nonzzero_18741), '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "required_blocks", (long long) sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, squot64(segred_tblock_sizze_17767, segment_sizze_nonzzero_18741))), '\n');
                        {
                            err = gpu_kernel_ftDBSCAN_doublezisegred_small_17774(ctx, num_tblocks_17768, 1, 1, *ctx->tuning_params.ftDBSCAN_doublezisegred_tblock_sizze_17566, 1, 1, (int64_t) 8 * segred_tblock_sizze_17767 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_17767, (int64_t) 8), (int64_t) 8) + ((int64_t) 8 * segred_tblock_sizze_17767 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_17767, (int64_t) 8), (int64_t) 8)), eps_15180, corePts_15993, inf_16016, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, num_tblocks_17768, segment_sizze_nonzzero_18741, ext_mem_18424.mem, mem_18426.mem, mem_18455.mem, mem_18460.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                    } else {
                        int64_t blocks_per_segment_18781 = sdiv_up64(num_tblocks_17768, smax64((int64_t) 1, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019));
                        int64_t q_18782 = sdiv_up64(corePts_15993, segred_tblock_sizze_17767 * blocks_per_segment_18781 * chunk_sizze_18740);
                        int64_t num_virtblocks_18783 = blocks_per_segment_18781 * dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019;
                        int64_t threads_per_segment_18784 = blocks_per_segment_18781 * segred_tblock_sizze_17767;
                        
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "# SegRed-large");
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) corePts_15993, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "num_virtblocks", (long long) num_virtblocks_18783, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "num_tblocks", (long long) num_tblocks_17768, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "tblock_size", (long long) segred_tblock_sizze_17767, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "q", (long long) q_18782, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "blocks_per_segment", (long long) blocks_per_segment_18781, '\n');
                        if (memblock_alloc_device(ctx, &segred_tmp_mem_18785, (int64_t) 8 * num_virtblocks_18783, "segred_tmp_mem_18785")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (memblock_alloc_device(ctx, &segred_tmp_mem_18787, (int64_t) 8 * num_virtblocks_18783, "segred_tmp_mem_18787")) {
                            err = 1;
                            goto cleanup;
                        }
                        {
                            err = gpu_kernel_ftDBSCAN_doublezisegred_large_17774(ctx, num_tblocks_17768, 1, 1, *ctx->tuning_params.ftDBSCAN_doublezisegred_tblock_sizze_17566, 1, 1, 8 + ((int64_t) 8 * segred_tblock_sizze_17767 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_17767, (int64_t) 8), (int64_t) 8)) + ((int64_t) 8 * segred_tblock_sizze_17767 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_17767, (int64_t) 8), (int64_t) 8)), eps_15180, corePts_15993, inf_16016, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, num_tblocks_17768, blocks_per_segment_18781, q_18782, num_virtblocks_18783, threads_per_segment_18784, ext_mem_18424.mem, mem_18426.mem, mem_18455.mem, mem_18460.mem, segred_tmp_mem_18785.mem, segred_tmp_mem_18787.mem, counters_mem_18789.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_unref_device(ctx, &mem_18455, "mem_18455") != 0)
                        return 1;
                    if (memblock_unref_device(ctx, &mem_18460, "mem_18460") != 0)
                        return 1;
                }
            }
        }
        if (memblock_unref_device(ctx, &ext_mem_18424, "ext_mem_18424") != 0)
            return 1;
        if (memblock_set_device(ctx, &ext_mem_18492, &mem_18426, "mem_18426") != 0)
            return 1;
    }
    if (memblock_unref_device(ctx, &ext_mem_18423, "ext_mem_18423") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_18650, &ext_mem_18492, "ext_mem_18492") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_19021, &mem_out_18650, "mem_out_18650") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &segred_tmp_mem_18787, "segred_tmp_mem_18787") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_18785, "segred_tmp_mem_18785") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18460, "mem_18460") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18455, "mem_18455") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18451, "mem_18451") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18434, "mem_18434") != 0)
            return 1;
        if (memblock_unref_device(ctx, &color_18527, "color_18527") != 0)
            return 1;
        if (memblock_unref_device(ctx, &color_18526, "color_18526") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18426, "mem_18426") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_18424, "ext_mem_18424") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18489, "mem_18489") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_18492, "ext_mem_18492") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_18423, "ext_mem_18423") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18422, "mem_18422") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_18420, "ext_mem_18420") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_18650, "mem_out_18650") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_ftDBSCAN_float(struct futhark_context *ctx, struct memblock_device *mem_out_p_19022, struct memblock_device dat_mem_18419, int64_t nz2080U_13119, int64_t dimz2081U_13120, float eps_13122, int64_t minPts_13123, int64_t pMem_13124, int64_t gather_psizze_13125)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device segred_tmp_mem_18787;
    
    segred_tmp_mem_18787.references = NULL;
    
    struct memblock_device segred_tmp_mem_18785;
    
    segred_tmp_mem_18785.references = NULL;
    
    struct memblock_device mem_18460;
    
    mem_18460.references = NULL;
    
    struct memblock_device mem_18455;
    
    mem_18455.references = NULL;
    
    struct memblock_device mem_18451;
    
    mem_18451.references = NULL;
    
    struct memblock_device mem_18434;
    
    mem_18434.references = NULL;
    
    struct memblock_device color_18527;
    
    color_18527.references = NULL;
    
    struct memblock_device color_18526;
    
    color_18526.references = NULL;
    
    struct memblock_device mem_18426;
    
    mem_18426.references = NULL;
    
    struct memblock_device ext_mem_18424;
    
    ext_mem_18424.references = NULL;
    
    struct memblock_device mem_18489;
    
    mem_18489.references = NULL;
    
    struct memblock_device ext_mem_18492;
    
    ext_mem_18492.references = NULL;
    
    struct memblock_device ext_mem_18423;
    
    ext_mem_18423.references = NULL;
    
    struct memblock_device mem_18422;
    
    mem_18422.references = NULL;
    
    struct memblock_device ext_mem_18420;
    
    ext_mem_18420.references = NULL;
    
    struct memblock_device mem_out_18650;
    
    mem_out_18650.references = NULL;
    
    struct memblock_device counters_mem_18763 = ctx->constants->counters_mem_18763;
    struct memblock_device counters_mem_18765 = ctx->constants->counters_mem_18765;
    struct memblock_device counters_mem_18789 = ctx->constants->counters_mem_18789;
    struct memblock_device counters_mem_18825 = ctx->constants->counters_mem_18825;
    struct memblock_device global_dynid_mem_18686 = ctx->constants->global_dynid_mem_18686;
    struct memblock_device global_dynid_mem_18892 = ctx->constants->global_dynid_mem_18892;
    bool zzero_15986 = nz2080U_13119 == (int64_t) 0;
    bool nonzzero_15987 = !zzero_15986;
    bool nonzzero_cert_15988;
    
    if (!nonzzero_15987) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ft_libs/ftDBSCAN.fut:127:46-48\n   #1  ft_libs/ftDBSCAN.fut:214:32-54\n   #2  ft_libs/ftDBSCAN.fut:214:9-54\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t max_arg1_15989 = sdiv64(pMem_13124, nz2080U_13119);
    int64_t max_res_15990 = smax64((int64_t) 1, max_arg1_15989);
    
    if (futrts_get_num_neighbours_6695(ctx, &ext_mem_18420, dat_mem_18419, nz2080U_13119, dimz2081U_13120, eps_13122, max_res_15990) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t segmap_tblock_sizze_17058;
    
    segmap_tblock_sizze_17058 = *ctx->tuning_params.ftDBSCAN_floatzisegmap_tblock_sizze_17050;
    
    int64_t segmap_usable_groups_17059 = sdiv_up64(nz2080U_13119, segmap_tblock_sizze_17058);
    
    if (memblock_alloc_device(ctx, &mem_18422, nz2080U_13119, "mem_18422")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_18651 = sext_i64_i32(sdiv_up64(nz2080U_13119, segmap_tblock_sizze_17058));
    
    {
        err = gpu_kernel_ftDBSCAN_floatzisegmap_17062(ctx, segmap_usable_groups_17059, 1, 1, *ctx->tuning_params.ftDBSCAN_floatzisegmap_tblock_sizze_17050, 1, 1, (int64_t) 0, nz2080U_13119, minPts_13123, ext_mem_18420.mem, mem_18422.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &ext_mem_18420, "ext_mem_18420") != 0)
        return 1;
    
    int64_t corePts_15993;
    
    if (futrts_isolate_core_points_6732(ctx, &ext_mem_18423, &corePts_15993, dat_mem_18419, mem_18422, nz2080U_13119, dimz2081U_13120) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_unref_device(ctx, &mem_18422, "mem_18422") != 0)
        return 1;
    
    bool cond_15995 = corePts_15993 == (int64_t) 0;
    int64_t bytes_18425 = (int64_t) 8 * nz2080U_13119;
    
    if (cond_15995) {
        if (memblock_alloc_device(ctx, &mem_18489, bytes_18425, "mem_18489")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i64(ctx, mem_18489, nz2080U_13119, (int64_t) -1) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_18492, &mem_18489, "mem_18489") != 0)
            return 1;
    } else {
        bool nonzzero_15998 = !cond_15995;
        bool nonzzero_cert_15999;
        
        if (!nonzzero_15998) {
            set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ft_libs/ftDBSCAN.fut:135:46-62\n   #1  ft_libs/ftDBSCAN.fut:214:32-54\n   #2  ft_libs/ftDBSCAN.fut:214:9-54\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t max_arg1_16000 = sdiv64(pMem_13124, corePts_15993);
        int64_t max_res_16001 = smax64((int64_t) 1, max_arg1_16000);
        int64_t zm_lhs_16003 = add64(nz2080U_13119, max_res_16001);
        int64_t zs_lhs_16004 = sub64(zm_lhs_16003, (int64_t) 1);
        bool zzero_16005 = max_res_16001 == (int64_t) 0;
        bool nonzzero_16006 = !zzero_16005;
        bool nonzzero_cert_16007;
        
        if (!nonzzero_16006) {
            set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ft_libs/ftDBSCAN.fut:103:48-55\n   #1  ft_libs/ftDBSCAN.fut:214:32-54\n   #2  ft_libs/ftDBSCAN.fut:214:9-54\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t num_iter_16008 = sdiv64(zs_lhs_16004, max_res_16001);
        bool bounds_invalid_upwards_16010 = slt64(num_iter_16008, (int64_t) 0);
        bool valid_16011 = !bounds_invalid_upwards_16010;
        bool range_valid_c_16012;
        
        if (!valid_16011) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) (int64_t) 0, "..", (long long) (int64_t) 1, "..<", (long long) num_iter_16008, " is invalid.", "-> #0  /prelude/array.fut:94:3-11\n   #1  ft_libs/ftDBSCAN.fut:104:61-74\n   #2  ft_libs/ftDBSCAN.fut:214:32-54\n   #3  ft_libs/ftDBSCAN.fut:214:9-54\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        if (futrts_find_cluster_ids_6783(ctx, &ext_mem_18424, ext_mem_18423, corePts_15993, dimz2081U_13120, eps_13122, max_res_16001, gather_psizze_13125) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_18426, bytes_18425, "mem_18426")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i64(ctx, mem_18426, nz2080U_13119, (int64_t) -1) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t max_tblock_sizze_17146;
        
        max_tblock_sizze_17146 = ctx->max_thread_block_size;
        
        bool fits_17147 = sle64(corePts_15993, max_tblock_sizze_17146);
        bool suff_intra_par_17145;
        
        suff_intra_par_17145 = *ctx->tuning_params.ftDBSCAN_floatzisuff_intra_par_1 <= corePts_15993;
        if (ctx->logging)
            fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "ftDBSCAN_float.suff_intra_par_1", (long) corePts_15993, suff_intra_par_17145 ? "true" : "false");
        
        bool intra_suff_and_fits_17148 = suff_intra_par_17145 && fits_17147;
        int64_t y_17361 = dimz2081U_13120 * corePts_15993;
        int64_t segmap_tblock_sizze_17363;
        
        segmap_tblock_sizze_17363 = *ctx->tuning_params.ftDBSCAN_floatzisegmap_tblock_sizze_17264;
        
        int64_t segmap_tblock_sizze_17377;
        
        segmap_tblock_sizze_17377 = *ctx->tuning_params.ftDBSCAN_floatzisegmap_tblock_sizze_17234;
        
        int64_t segred_tblock_sizze_17394;
        
        segred_tblock_sizze_17394 = *ctx->tuning_params.ftDBSCAN_floatzisegred_tblock_sizze_17193;
        
        int64_t segmap_tblock_sizze_17111;
        
        segmap_tblock_sizze_17111 = *ctx->tuning_params.ftDBSCAN_floatzisegmap_tblock_sizze_17077;
        
        int64_t binop_y_18439 = corePts_15993 - (int64_t) 1;
        int64_t binop_y_18441 = smax64((int64_t) 0, binop_y_18439);
        int64_t binop_y_18443 = dimz2081U_13120 - (int64_t) 1;
        int64_t binop_x_18444 = smax64((int64_t) 0, binop_y_18443);
        int64_t bytes_18462 = (int64_t) 4 * dimz2081U_13120;
        
        for (int64_t i_16014 = 0; i_16014 < num_iter_16008; i_16014++) {
            int64_t inf_16016 = mul64(max_res_16001, i_16014);
            int64_t min_arg1_16017 = add64(max_res_16001, inf_16016);
            int64_t min_res_16018 = smin64(nz2080U_13119, min_arg1_16017);
            int64_t dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019 = sub64(min_res_16018, inf_16016);
            bool empty_slice_16020 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019 == (int64_t) 0;
            int64_t m_16021 = sub64(dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, (int64_t) 1);
            int64_t i_p_m_t_s_16022 = add64(inf_16016, m_16021);
            bool zzero_leq_i_p_m_t_s_16023 = sle64((int64_t) 0, i_p_m_t_s_16022);
            bool i_p_m_t_s_leq_w_16024 = slt64(i_p_m_t_s_16022, nz2080U_13119);
            bool zzero_lte_i_16025 = sle64((int64_t) 0, inf_16016);
            bool i_lte_j_16026 = sle64(inf_16016, min_res_16018);
            bool y_16027 = i_p_m_t_s_leq_w_16024 && zzero_lte_i_16025;
            bool y_16028 = zzero_leq_i_p_m_t_s_16023 && y_16027;
            bool forwards_ok_16029 = i_lte_j_16026 && y_16028;
            bool ok_or_empty_16030 = empty_slice_16020 || forwards_ok_16029;
            bool index_certs_16031;
            
            if (!ok_or_empty_16030) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) inf_16016, ":", (long long) min_res_16018, "] out of bounds for array of shape [", (long long) nz2080U_13119, "].", "-> #0  ft_libs/ftDBSCAN.fut:107:40-52\n   #1  ft_libs/ftDBSCAN.fut:214:32-54\n   #2  ft_libs/ftDBSCAN.fut:214:9-54\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            
            bool suff_outer_par_17073;
            
            suff_outer_par_17073 = *ctx->tuning_params.ftDBSCAN_floatzisuff_outer_par_0 <= dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019;
            if (ctx->logging)
                fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "ftDBSCAN_float.suff_outer_par_0", (long) dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, suff_outer_par_17073 ? "true" : "false");
            
            int64_t nest_sizze_17362 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019 * y_17361;
            int64_t nest_sizze_17376 = corePts_15993 * dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019;
            int64_t num_tblocks_17395;
            int64_t max_num_tblocks_18681;
            
            max_num_tblocks_18681 = *ctx->tuning_params.ftDBSCAN_floatzisegred_num_tblocks_17195;
            num_tblocks_17395 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nest_sizze_17376, segred_tblock_sizze_17394), max_num_tblocks_18681)));
            
            int64_t binop_x_18431 = (int64_t) 4 * dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019;
            int64_t binop_x_18432 = corePts_15993 * binop_x_18431;
            int64_t bytes_18433 = dimz2081U_13120 * binop_x_18432;
            int64_t binop_x_18436 = smax64((int64_t) 0, m_16021);
            int64_t binop_y_18437 = corePts_15993 * binop_x_18436;
            int64_t binop_x_18438 = smax64((int64_t) 0, binop_y_18437);
            int64_t binop_x_18442 = binop_x_18438 + binop_y_18441;
            int64_t binop_y_18446 = nest_sizze_17376 * binop_x_18444;
            int64_t binop_y_18447 = smax64((int64_t) 0, binop_y_18446);
            int64_t binop_y_18448 = binop_x_18442 + binop_y_18447;
            int64_t binop_y_18449 = (int64_t) 1 + binop_y_18448;
            int64_t bytes_18450 = (int64_t) 4 * binop_y_18449;
            int64_t binop_x_18577 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019 * bytes_18462;
            int64_t total_sizze_18578 = corePts_15993 * binop_x_18577;
            int64_t ctx_18584 = corePts_15993 * dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019;
            int64_t segmap_usable_groups_17112 = sdiv_up_safe64(dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, segmap_tblock_sizze_17111);
            int64_t num_threads_18568 = segmap_tblock_sizze_17111 * segmap_usable_groups_17112;
            int64_t total_sizze_18569 = bytes_18462 * num_threads_18568;
            int64_t shared_memory_capacity_18859;
            
            shared_memory_capacity_18859 = ctx->max_shared_memory;
            if (suff_outer_par_17073 && sle64((int64_t) 0, shared_memory_capacity_18859)) {
                if (memblock_alloc_device(ctx, &color_18526, total_sizze_18569, "color_18526")) {
                    err = 1;
                    goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_18682 = sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, segmap_tblock_sizze_17111));
                
                {
                    err = gpu_kernel_ftDBSCAN_floatzisegmap_17115(ctx, segmap_usable_groups_17112, 1, 1, *ctx->tuning_params.ftDBSCAN_floatzisegmap_tblock_sizze_17077, 1, 1, (int64_t) 0, dimz2081U_13120, eps_13122, corePts_15993, inf_16016, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, num_threads_18568, dat_mem_18419.mem, ext_mem_18423.mem, ext_mem_18424.mem, mem_18426.mem, color_18526.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                if (memblock_unref_device(ctx, &color_18526, "color_18526") != 0)
                    return 1;
            } else {
                int64_t shared_memory_capacity_18858;
                
                shared_memory_capacity_18858 = ctx->max_shared_memory;
                if (intra_suff_and_fits_17148 && sle64(sdiv_up64((int64_t) 8 * corePts_15993, (int64_t) 8) * (int64_t) 8 + sdiv_up64((int64_t) 4 * corePts_15993, (int64_t) 8) * (int64_t) 8, shared_memory_capacity_18858)) {
                    if (memblock_alloc_device(ctx, &color_18527, total_sizze_18578, "color_18527")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t num_chunks_18695 = sext_i64_i32(sdiv_up64(corePts_15993, corePts_15993));
                    int32_t virt_num_tblocks_18696 = sext_i64_i32(dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019);
                    
                    {
                        err = gpu_kernel_ftDBSCAN_floatzisegmap_intrablock_17151(ctx, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, 1, 1, corePts_15993, 1, 1, (int64_t) 4 * corePts_15993 + srem64((int64_t) 8 - srem64((int64_t) 4 * corePts_15993, (int64_t) 8), (int64_t) 8) + ((int64_t) 8 * corePts_15993 + srem64((int64_t) 8 - srem64((int64_t) 8 * corePts_15993, (int64_t) 8), (int64_t) 8)), dimz2081U_13120, eps_13122, corePts_15993, inf_16016, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, ctx_18584, dat_mem_18419.mem, ext_mem_18423.mem, ext_mem_18424.mem, mem_18426.mem, color_18527.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_unref_device(ctx, &color_18527, "color_18527") != 0)
                        return 1;
                } else {
                    int64_t segmap_usable_groups_17364 = sdiv_up64(nest_sizze_17362, segmap_tblock_sizze_17363);
                    
                    if (memblock_alloc_device(ctx, &mem_18434, bytes_18433, "mem_18434")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t virt_num_tblocks_18715 = sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019 * corePts_15993 * dimz2081U_13120, segmap_tblock_sizze_17363));
                    
                    {
                        err = gpu_kernel_ftDBSCAN_floatzisegmap_17369(ctx, segmap_usable_groups_17364, 1, 1, *ctx->tuning_params.ftDBSCAN_floatzisegmap_tblock_sizze_17264, 1, 1, (int64_t) 0, dimz2081U_13120, corePts_15993, inf_16016, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, dat_mem_18419.mem, ext_mem_18423.mem, mem_18434.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    
                    int64_t segmap_usable_groups_17378 = sdiv_up64(nest_sizze_17376, segmap_tblock_sizze_17377);
                    
                    if (memblock_alloc_device(ctx, &mem_18451, bytes_18450, "mem_18451")) {
                        err = 1;
                        goto cleanup;
                    }
                    if ((err = lmad_copy_gpu2gpu_4b(ctx, 3, mem_18451.mem, (int64_t) 0, (int64_t []) {corePts_15993, (int64_t) 1, corePts_15993 * dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019}, mem_18434.mem, (int64_t) 0, (int64_t []) {dimz2081U_13120 * corePts_15993, dimz2081U_13120, (int64_t) 1}, (int64_t []) {dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, corePts_15993, dimz2081U_13120})) != 0)
                        goto cleanup;
                    if (memblock_unref_device(ctx, &mem_18434, "mem_18434") != 0)
                        return 1;
                    if (memblock_alloc_device(ctx, &mem_18455, binop_x_18432, "mem_18455")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t virt_num_tblocks_18728 = sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019 * corePts_15993, segmap_tblock_sizze_17377));
                    
                    {
                        err = gpu_kernel_ftDBSCAN_floatzisegmap_17382(ctx, segmap_usable_groups_17378, 1, 1, *ctx->tuning_params.ftDBSCAN_floatzisegmap_tblock_sizze_17234, 1, 1, (int64_t) 0, dimz2081U_13120, corePts_15993, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, mem_18451.mem, mem_18455.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_unref_device(ctx, &mem_18451, "mem_18451") != 0)
                        return 1;
                    if (memblock_alloc_device(ctx, &mem_18460, binop_x_18431, "mem_18460")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegRed");
                    
                    int64_t chunk_sizze_18740 = (int64_t) 1;
                    
                    if (slt64(corePts_15993 * (int64_t) 2, segred_tblock_sizze_17394 * chunk_sizze_18740)) {
                        int64_t segment_sizze_nonzzero_18741 = smax64((int64_t) 1, corePts_15993);
                        int64_t num_threads_18742 = segred_tblock_sizze_17394 * segred_tblock_sizze_17394;
                        
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "# SegRed-small");
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) corePts_15993, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "segments_per_block", (long long) squot64(segred_tblock_sizze_17394, segment_sizze_nonzzero_18741), '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "required_blocks", (long long) sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, squot64(segred_tblock_sizze_17394, segment_sizze_nonzzero_18741))), '\n');
                        {
                            err = gpu_kernel_ftDBSCAN_floatzisegred_small_17401(ctx, num_tblocks_17395, 1, 1, *ctx->tuning_params.ftDBSCAN_floatzisegred_tblock_sizze_17193, 1, 1, (int64_t) 4 * segred_tblock_sizze_17394 + srem64((int64_t) 8 - srem64((int64_t) 4 * segred_tblock_sizze_17394, (int64_t) 8), (int64_t) 8) + ((int64_t) 8 * segred_tblock_sizze_17394 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_17394, (int64_t) 8), (int64_t) 8)), eps_13122, corePts_15993, inf_16016, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, num_tblocks_17395, segment_sizze_nonzzero_18741, ext_mem_18424.mem, mem_18426.mem, mem_18455.mem, mem_18460.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                    } else {
                        int64_t blocks_per_segment_18781 = sdiv_up64(num_tblocks_17395, smax64((int64_t) 1, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019));
                        int64_t q_18782 = sdiv_up64(corePts_15993, segred_tblock_sizze_17394 * blocks_per_segment_18781 * chunk_sizze_18740);
                        int64_t num_virtblocks_18783 = blocks_per_segment_18781 * dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019;
                        int64_t threads_per_segment_18784 = blocks_per_segment_18781 * segred_tblock_sizze_17394;
                        
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "# SegRed-large");
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) corePts_15993, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "num_virtblocks", (long long) num_virtblocks_18783, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "num_tblocks", (long long) num_tblocks_17395, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "tblock_size", (long long) segred_tblock_sizze_17394, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "q", (long long) q_18782, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "blocks_per_segment", (long long) blocks_per_segment_18781, '\n');
                        if (memblock_alloc_device(ctx, &segred_tmp_mem_18785, (int64_t) 8 * num_virtblocks_18783, "segred_tmp_mem_18785")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (memblock_alloc_device(ctx, &segred_tmp_mem_18787, (int64_t) 4 * num_virtblocks_18783, "segred_tmp_mem_18787")) {
                            err = 1;
                            goto cleanup;
                        }
                        {
                            err = gpu_kernel_ftDBSCAN_floatzisegred_large_17401(ctx, num_tblocks_17395, 1, 1, *ctx->tuning_params.ftDBSCAN_floatzisegred_tblock_sizze_17193, 1, 1, 8 + ((int64_t) 4 * segred_tblock_sizze_17394 + srem64((int64_t) 8 - srem64((int64_t) 4 * segred_tblock_sizze_17394, (int64_t) 8), (int64_t) 8)) + ((int64_t) 8 * segred_tblock_sizze_17394 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_17394, (int64_t) 8), (int64_t) 8)), eps_13122, corePts_15993, inf_16016, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_16019, num_tblocks_17395, blocks_per_segment_18781, q_18782, num_virtblocks_18783, threads_per_segment_18784, ext_mem_18424.mem, mem_18426.mem, mem_18455.mem, mem_18460.mem, segred_tmp_mem_18785.mem, segred_tmp_mem_18787.mem, counters_mem_18789.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_unref_device(ctx, &mem_18455, "mem_18455") != 0)
                        return 1;
                    if (memblock_unref_device(ctx, &mem_18460, "mem_18460") != 0)
                        return 1;
                }
            }
        }
        if (memblock_unref_device(ctx, &ext_mem_18424, "ext_mem_18424") != 0)
            return 1;
        if (memblock_set_device(ctx, &ext_mem_18492, &mem_18426, "mem_18426") != 0)
            return 1;
    }
    if (memblock_unref_device(ctx, &ext_mem_18423, "ext_mem_18423") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_18650, &ext_mem_18492, "ext_mem_18492") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_19022, &mem_out_18650, "mem_out_18650") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &segred_tmp_mem_18787, "segred_tmp_mem_18787") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_18785, "segred_tmp_mem_18785") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18460, "mem_18460") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18455, "mem_18455") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18451, "mem_18451") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18434, "mem_18434") != 0)
            return 1;
        if (memblock_unref_device(ctx, &color_18527, "color_18527") != 0)
            return 1;
        if (memblock_unref_device(ctx, &color_18526, "color_18526") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18426, "mem_18426") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_18424, "ext_mem_18424") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18489, "mem_18489") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_18492, "ext_mem_18492") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_18423, "ext_mem_18423") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18422, "mem_18422") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_18420, "ext_mem_18420") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_18650, "mem_out_18650") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_ftDBSCAN_star_double(struct futhark_context *ctx, struct memblock_device *mem_out_p_19023, struct memblock_device *mem_out_p_19024, int64_t *out_prim_out_19025, int64_t *out_prim_out_19026, struct memblock_device dat_mem_18419, int64_t dim_15336, int64_t nz2085U_15337, double eps_15339, int64_t minPts_15340, int64_t pMem_15341, int64_t gather_psizze_15342)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device ext_mem_18424;
    
    ext_mem_18424.references = NULL;
    
    struct memblock_device mem_18429;
    
    mem_18429.references = NULL;
    
    struct memblock_device mem_18426;
    
    mem_18426.references = NULL;
    
    struct memblock_device ext_mem_18430;
    
    ext_mem_18430.references = NULL;
    
    struct memblock_device ext_mem_18431;
    
    ext_mem_18431.references = NULL;
    
    struct memblock_device ext_mem_18423;
    
    ext_mem_18423.references = NULL;
    
    struct memblock_device mem_18422;
    
    mem_18422.references = NULL;
    
    struct memblock_device ext_mem_18420;
    
    ext_mem_18420.references = NULL;
    
    struct memblock_device mem_out_18651;
    
    mem_out_18651.references = NULL;
    
    struct memblock_device mem_out_18650;
    
    mem_out_18650.references = NULL;
    
    struct memblock_device counters_mem_18763 = ctx->constants->counters_mem_18763;
    struct memblock_device counters_mem_18765 = ctx->constants->counters_mem_18765;
    struct memblock_device counters_mem_18789 = ctx->constants->counters_mem_18789;
    struct memblock_device counters_mem_18825 = ctx->constants->counters_mem_18825;
    struct memblock_device global_dynid_mem_18686 = ctx->constants->global_dynid_mem_18686;
    struct memblock_device global_dynid_mem_18892 = ctx->constants->global_dynid_mem_18892;
    int64_t prim_out_18652;
    int64_t prim_out_18653;
    bool zzero_15508 = nz2085U_15337 == (int64_t) 0;
    bool nonzzero_15509 = !zzero_15508;
    bool nonzzero_cert_15510;
    
    if (!nonzzero_15509) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ft_libs/ftDBSCAN.fut:146:46-48\n   #1  ft_libs/ftDBSCAN.fut:223:17-78\n   #2  ft_libs/ftDBSCAN.fut:221:9-223:78\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t max_arg1_15511 = sdiv64(pMem_15341, nz2085U_15337);
    int64_t max_res_15512 = smax64((int64_t) 1, max_arg1_15511);
    
    if (futrts_get_num_neighbours_6842(ctx, &ext_mem_18420, dat_mem_18419, nz2085U_15337, dim_15336, eps_15339, max_res_15512) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t segmap_tblock_sizze_16298;
    
    segmap_tblock_sizze_16298 = *ctx->tuning_params.ftDBSCAN_star_doublezisegmap_tblock_sizze_16290;
    
    int64_t segmap_usable_groups_16299 = sdiv_up64(nz2085U_15337, segmap_tblock_sizze_16298);
    
    if (memblock_alloc_device(ctx, &mem_18422, nz2085U_15337, "mem_18422")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_18654 = sext_i64_i32(sdiv_up64(nz2085U_15337, segmap_tblock_sizze_16298));
    
    {
        err = gpu_kernel_ftDBSCAN_star_doublezisegmap_16302(ctx, segmap_usable_groups_16299, 1, 1, *ctx->tuning_params.ftDBSCAN_star_doublezisegmap_tblock_sizze_16290, 1, 1, (int64_t) 0, nz2085U_15337, minPts_15340, ext_mem_18420.mem, mem_18422.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &ext_mem_18420, "ext_mem_18420") != 0)
        return 1;
    
    int64_t corePts_15515;
    
    if (futrts_isolate_core_points_6871(ctx, &ext_mem_18423, &corePts_15515, dat_mem_18419, mem_18422, nz2085U_15337, dim_15336) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_unref_device(ctx, &mem_18422, "mem_18422") != 0)
        return 1;
    
    bool cond_15517 = corePts_15515 == (int64_t) 0;
    bool eq_x_zz_15533 = (int64_t) 0 == corePts_15515;
    bool not_p_15534 = !cond_15517;
    bool p_and_eq_x_y_15535 = eq_x_zz_15533 && not_p_15534;
    bool eq_x_y_15536 = cond_15517 || p_and_eq_x_y_15535;
    bool p_and_eq_x_y_15538 = cond_15517 && cond_15517;
    bool eq_x_zz_15540 = not_p_15534 || p_and_eq_x_y_15538;
    bool p_and_eq_x_y_15541 = cond_15517 && eq_x_y_15536;
    bool p_and_eq_x_y_15543 = not_p_15534 && eq_x_zz_15540;
    bool dim_match_15544 = p_and_eq_x_y_15541 || p_and_eq_x_y_15543;
    bool empty_or_match_cert_15545;
    
    if (!dim_match_15544) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "Function return value does not match shape of declared return type.", "-> #0  ft_libs/ftDBSCAN.fut:139:9-156:84\n   #1  ft_libs/ftDBSCAN.fut:223:17-78\n   #2  ft_libs/ftDBSCAN.fut:221:9-223:78\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t do_DBSCAN_star_res_15518;
    
    if (cond_15517) {
        do_DBSCAN_star_res_15518 = (int64_t) 0;
    } else {
        do_DBSCAN_star_res_15518 = corePts_15515;
    }
    
    int64_t max_arg1_15529 = sdiv_safe64(pMem_15341, corePts_15515);
    int64_t max_res_15530 = smax64((int64_t) 1, max_arg1_15529);
    int64_t bytes_18425 = (int64_t) 8 * do_DBSCAN_star_res_15518;
    int64_t bytes_18428 = dim_15336 * bytes_18425;
    
    if (cond_15517) {
        if (memblock_alloc_device(ctx, &mem_18426, bytes_18425, "mem_18426")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_18429, bytes_18428, "mem_18429")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_18431, &mem_18426, "mem_18426") != 0)
            return 1;
        if (memblock_set_device(ctx, &ext_mem_18430, &mem_18429, "mem_18429") != 0)
            return 1;
    } else {
        if (futrts_find_cluster_ids_6890(ctx, &ext_mem_18424, ext_mem_18423, corePts_15515, dim_15336, eps_15339, max_res_15530, gather_psizze_15342) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_18431, &ext_mem_18424, "ext_mem_18424") != 0)
            return 1;
        if (memblock_set_device(ctx, &ext_mem_18430, &ext_mem_18423, "ext_mem_18423") != 0)
            return 1;
    }
    if (memblock_unref_device(ctx, &ext_mem_18423, "ext_mem_18423") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_18650, &ext_mem_18431, "ext_mem_18431") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_18651, &ext_mem_18430, "ext_mem_18430") != 0)
        return 1;
    prim_out_18652 = do_DBSCAN_star_res_15518;
    prim_out_18653 = do_DBSCAN_star_res_15518;
    if (memblock_set_device(ctx, &*mem_out_p_19023, &mem_out_18650, "mem_out_18650") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_19024, &mem_out_18651, "mem_out_18651") != 0)
        return 1;
    *out_prim_out_19025 = prim_out_18652;
    *out_prim_out_19026 = prim_out_18653;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &ext_mem_18424, "ext_mem_18424") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18429, "mem_18429") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18426, "mem_18426") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_18430, "ext_mem_18430") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_18431, "ext_mem_18431") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_18423, "ext_mem_18423") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18422, "mem_18422") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_18420, "ext_mem_18420") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_18651, "mem_out_18651") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_18650, "mem_out_18650") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_ftDBSCAN_star_float(struct futhark_context *ctx, struct memblock_device *mem_out_p_19027, struct memblock_device *mem_out_p_19028, int64_t *out_prim_out_19029, int64_t *out_prim_out_19030, struct memblock_device dat_mem_18419, int64_t dim_15255, int64_t nz2085U_15256, float eps_15258, int64_t minPts_15259, int64_t pMem_15260, int64_t gather_psizze_15261)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device ext_mem_18424;
    
    ext_mem_18424.references = NULL;
    
    struct memblock_device mem_18429;
    
    mem_18429.references = NULL;
    
    struct memblock_device mem_18426;
    
    mem_18426.references = NULL;
    
    struct memblock_device ext_mem_18430;
    
    ext_mem_18430.references = NULL;
    
    struct memblock_device ext_mem_18431;
    
    ext_mem_18431.references = NULL;
    
    struct memblock_device ext_mem_18423;
    
    ext_mem_18423.references = NULL;
    
    struct memblock_device mem_18422;
    
    mem_18422.references = NULL;
    
    struct memblock_device ext_mem_18420;
    
    ext_mem_18420.references = NULL;
    
    struct memblock_device mem_out_18651;
    
    mem_out_18651.references = NULL;
    
    struct memblock_device mem_out_18650;
    
    mem_out_18650.references = NULL;
    
    struct memblock_device counters_mem_18763 = ctx->constants->counters_mem_18763;
    struct memblock_device counters_mem_18765 = ctx->constants->counters_mem_18765;
    struct memblock_device counters_mem_18789 = ctx->constants->counters_mem_18789;
    struct memblock_device counters_mem_18825 = ctx->constants->counters_mem_18825;
    struct memblock_device global_dynid_mem_18686 = ctx->constants->global_dynid_mem_18686;
    struct memblock_device global_dynid_mem_18892 = ctx->constants->global_dynid_mem_18892;
    int64_t prim_out_18652;
    int64_t prim_out_18653;
    bool zzero_15508 = nz2085U_15256 == (int64_t) 0;
    bool nonzzero_15509 = !zzero_15508;
    bool nonzzero_cert_15510;
    
    if (!nonzzero_15509) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ft_libs/ftDBSCAN.fut:146:46-48\n   #1  ft_libs/ftDBSCAN.fut:219:17-77\n   #2  ft_libs/ftDBSCAN.fut:217:9-219:77\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t max_arg1_15511 = sdiv64(pMem_15260, nz2085U_15256);
    int64_t max_res_15512 = smax64((int64_t) 1, max_arg1_15511);
    
    if (futrts_get_num_neighbours_6695(ctx, &ext_mem_18420, dat_mem_18419, nz2085U_15256, dim_15255, eps_15258, max_res_15512) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t segmap_tblock_sizze_16280;
    
    segmap_tblock_sizze_16280 = *ctx->tuning_params.ftDBSCAN_star_floatzisegmap_tblock_sizze_16272;
    
    int64_t segmap_usable_groups_16281 = sdiv_up64(nz2085U_15256, segmap_tblock_sizze_16280);
    
    if (memblock_alloc_device(ctx, &mem_18422, nz2085U_15256, "mem_18422")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_18654 = sext_i64_i32(sdiv_up64(nz2085U_15256, segmap_tblock_sizze_16280));
    
    {
        err = gpu_kernel_ftDBSCAN_star_floatzisegmap_16284(ctx, segmap_usable_groups_16281, 1, 1, *ctx->tuning_params.ftDBSCAN_star_floatzisegmap_tblock_sizze_16272, 1, 1, (int64_t) 0, nz2085U_15256, minPts_15259, ext_mem_18420.mem, mem_18422.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &ext_mem_18420, "ext_mem_18420") != 0)
        return 1;
    
    int64_t corePts_15515;
    
    if (futrts_isolate_core_points_6732(ctx, &ext_mem_18423, &corePts_15515, dat_mem_18419, mem_18422, nz2085U_15256, dim_15255) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_unref_device(ctx, &mem_18422, "mem_18422") != 0)
        return 1;
    
    bool cond_15517 = corePts_15515 == (int64_t) 0;
    bool eq_x_zz_15533 = (int64_t) 0 == corePts_15515;
    bool not_p_15534 = !cond_15517;
    bool p_and_eq_x_y_15535 = eq_x_zz_15533 && not_p_15534;
    bool eq_x_y_15536 = cond_15517 || p_and_eq_x_y_15535;
    bool p_and_eq_x_y_15538 = cond_15517 && cond_15517;
    bool eq_x_zz_15540 = not_p_15534 || p_and_eq_x_y_15538;
    bool p_and_eq_x_y_15541 = cond_15517 && eq_x_y_15536;
    bool p_and_eq_x_y_15543 = not_p_15534 && eq_x_zz_15540;
    bool dim_match_15544 = p_and_eq_x_y_15541 || p_and_eq_x_y_15543;
    bool empty_or_match_cert_15545;
    
    if (!dim_match_15544) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "Function return value does not match shape of declared return type.", "-> #0  ft_libs/ftDBSCAN.fut:139:9-156:84\n   #1  ft_libs/ftDBSCAN.fut:219:17-77\n   #2  ft_libs/ftDBSCAN.fut:217:9-219:77\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t do_DBSCAN_star_res_15518;
    
    if (cond_15517) {
        do_DBSCAN_star_res_15518 = (int64_t) 0;
    } else {
        do_DBSCAN_star_res_15518 = corePts_15515;
    }
    
    int64_t max_arg1_15529 = sdiv_safe64(pMem_15260, corePts_15515);
    int64_t max_res_15530 = smax64((int64_t) 1, max_arg1_15529);
    int64_t bytes_18425 = (int64_t) 8 * do_DBSCAN_star_res_15518;
    int64_t binop_x_18427 = (int64_t) 4 * do_DBSCAN_star_res_15518;
    int64_t bytes_18428 = dim_15255 * binop_x_18427;
    
    if (cond_15517) {
        if (memblock_alloc_device(ctx, &mem_18426, bytes_18425, "mem_18426")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_18429, bytes_18428, "mem_18429")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_18431, &mem_18426, "mem_18426") != 0)
            return 1;
        if (memblock_set_device(ctx, &ext_mem_18430, &mem_18429, "mem_18429") != 0)
            return 1;
    } else {
        if (futrts_find_cluster_ids_6783(ctx, &ext_mem_18424, ext_mem_18423, corePts_15515, dim_15255, eps_15258, max_res_15530, gather_psizze_15261) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_18431, &ext_mem_18424, "ext_mem_18424") != 0)
            return 1;
        if (memblock_set_device(ctx, &ext_mem_18430, &ext_mem_18423, "ext_mem_18423") != 0)
            return 1;
    }
    if (memblock_unref_device(ctx, &ext_mem_18423, "ext_mem_18423") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_18650, &ext_mem_18431, "ext_mem_18431") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_18651, &ext_mem_18430, "ext_mem_18430") != 0)
        return 1;
    prim_out_18652 = do_DBSCAN_star_res_15518;
    prim_out_18653 = do_DBSCAN_star_res_15518;
    if (memblock_set_device(ctx, &*mem_out_p_19027, &mem_out_18650, "mem_out_18650") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_19028, &mem_out_18651, "mem_out_18651") != 0)
        return 1;
    *out_prim_out_19029 = prim_out_18652;
    *out_prim_out_19030 = prim_out_18653;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &ext_mem_18424, "ext_mem_18424") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18429, "mem_18429") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18426, "mem_18426") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_18430, "ext_mem_18430") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_18431, "ext_mem_18431") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_18423, "ext_mem_18423") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18422, "mem_18422") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_18420, "ext_mem_18420") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_18651, "mem_out_18651") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_18650, "mem_out_18650") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_find_cluster_ids_6783(struct futhark_context *ctx, struct memblock_device *mem_out_p_19031, struct memblock_device core_dat_mem_18419, int64_t n_12449, int64_t dim_12450, float eps_12452, int64_t extPar_12453, int64_t gather_psizze_12454)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_param_tmp_19010;
    
    mem_param_tmp_19010.references = NULL;
    
    struct memblock_device mem_18515;
    
    mem_18515.references = NULL;
    
    struct memblock_device mem_param_18512;
    
    mem_param_18512.references = NULL;
    
    struct memblock_device ext_mem_18518;
    
    ext_mem_18518.references = NULL;
    
    struct memblock_device mem_18509;
    
    mem_18509.references = NULL;
    
    struct memblock_device mem_18507;
    
    mem_18507.references = NULL;
    
    struct memblock_device incprefixes_mem_18890;
    
    incprefixes_mem_18890.references = NULL;
    
    struct memblock_device aggregates_mem_18888;
    
    aggregates_mem_18888.references = NULL;
    
    struct memblock_device status_flags_mem_18866;
    
    status_flags_mem_18866.references = NULL;
    
    struct memblock_device mem_18504;
    
    mem_18504.references = NULL;
    
    struct memblock_device mem_param_tmp_18669;
    
    mem_param_tmp_18669.references = NULL;
    
    struct memblock_device segred_tmp_mem_18827;
    
    segred_tmp_mem_18827.references = NULL;
    
    struct memblock_device mem_param_tmp_18672;
    
    mem_param_tmp_18672.references = NULL;
    
    struct memblock_device mem_18493;
    
    mem_18493.references = NULL;
    
    struct memblock_device segred_tmp_mem_18763;
    
    segred_tmp_mem_18763.references = NULL;
    
    struct memblock_device mem_18456;
    
    mem_18456.references = NULL;
    
    struct memblock_device mem_18453;
    
    mem_18453.references = NULL;
    
    struct memblock_device mem_18449;
    
    mem_18449.references = NULL;
    
    struct memblock_device mem_18432;
    
    mem_18432.references = NULL;
    
    struct memblock_device color_18527;
    
    color_18527.references = NULL;
    
    struct memblock_device mem_18467;
    
    mem_18467.references = NULL;
    
    struct memblock_device ext_mem_18468;
    
    ext_mem_18468.references = NULL;
    
    struct memblock_device color_18526;
    
    color_18526.references = NULL;
    
    struct memblock_device mem_18490;
    
    mem_18490.references = NULL;
    
    struct memblock_device mem_18479;
    
    mem_18479.references = NULL;
    
    struct memblock_device ext_mem_18491;
    
    ext_mem_18491.references = NULL;
    
    struct memblock_device mem_param_18427;
    
    mem_param_18427.references = NULL;
    
    struct memblock_device ext_mem_18496;
    
    ext_mem_18496.references = NULL;
    
    struct memblock_device mem_param_18424;
    
    mem_param_18424.references = NULL;
    
    struct memblock_device ext_mem_18501;
    
    ext_mem_18501.references = NULL;
    
    struct memblock_device mem_18498;
    
    mem_18498.references = NULL;
    
    struct memblock_device mem_18421;
    
    mem_18421.references = NULL;
    
    struct memblock_device mem_out_18650;
    
    mem_out_18650.references = NULL;
    
    struct memblock_device counters_mem_18763 = ctx->constants->counters_mem_18763;
    struct memblock_device counters_mem_18765 = ctx->constants->counters_mem_18765;
    struct memblock_device counters_mem_18789 = ctx->constants->counters_mem_18789;
    struct memblock_device counters_mem_18825 = ctx->constants->counters_mem_18825;
    struct memblock_device global_dynid_mem_18686 = ctx->constants->global_dynid_mem_18686;
    struct memblock_device global_dynid_mem_18892 = ctx->constants->global_dynid_mem_18892;
    int64_t zm_lhs_12455 = add64(n_12449, extPar_12453);
    int64_t zs_lhs_12457 = sub64(zm_lhs_12455, (int64_t) 1);
    bool zzero_12459 = extPar_12453 == (int64_t) 0;
    bool nonzzero_12460 = !zzero_12459;
    bool nonzzero_cert_12461;
    
    if (!nonzzero_12460) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ft_libs/ftDBSCAN.fut:65:50-57\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t inner_iter_12462 = sdiv64(zs_lhs_12457, extPar_12453);
    int64_t bytes_18420 = (int64_t) 8 * n_12449;
    bool bounds_invalid_upwards_15391 = slt64(inner_iter_12462, (int64_t) 0);
    bool valid_15392 = !bounds_invalid_upwards_15391;
    bool range_valid_c_15393;
    
    if (!valid_15392) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) (int64_t) 0, "..", (long long) (int64_t) 1, "..<", (long long) inner_iter_12462, " is invalid.", "-> #0  /prelude/array.fut:94:3-11\n   #1  ft_libs/ftDBSCAN.fut:72:57-72\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t max_arg1_15639 = sdiv64(gather_psizze_12454, (int64_t) 8);
    int64_t max_res_15640 = smax64((int64_t) 1, max_arg1_15639);
    int64_t zm_lhs_15641 = add64(n_12449, max_res_15640);
    int64_t zs_lhs_15642 = sub64(zm_lhs_15641, (int64_t) 1);
    bool zzero_15643 = max_res_15640 == (int64_t) 0;
    bool nonzzero_15644 = !zzero_15643;
    bool nonzzero_cert_15645;
    
    if (!nonzzero_15644) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ft_libs/ftbasics.fut:27:31-39\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t max_iter_15646 = sdiv64(zs_lhs_15642, max_res_15640);
    bool bounds_invalid_upwards_15647 = slt64(max_iter_15646, (int64_t) 0);
    bool valid_15648 = !bounds_invalid_upwards_15647;
    bool range_valid_c_15649;
    
    if (!valid_15648) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) (int64_t) 0, "..", (long long) (int64_t) 1, "..<", (long long) max_iter_15646, " is invalid.", "-> #0  /prelude/array.fut:94:3-11\n   #1  ft_libs/ftbasics.fut:28:33-46\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_18421, bytes_18420, "mem_18421")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhiota_i64(ctx, mem_18421, n_12449, (int64_t) 0, (int64_t) 1) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t max_tblock_sizze_16372;
    
    max_tblock_sizze_16372 = ctx->max_thread_block_size;
    
    bool fits_16373 = sle64(n_12449, max_tblock_sizze_16372);
    bool suff_intra_par_16371;
    
    suff_intra_par_16371 = *ctx->tuning_params.find_cluster_ids_6783zisuff_intra_par_1 <= n_12449;
    if (ctx->logging)
        fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "find_cluster_ids_6783.suff_intra_par_1", (long) n_12449, suff_intra_par_16371 ? "true" : "false");
    
    bool intra_suff_and_fits_16374 = suff_intra_par_16371 && fits_16373;
    int64_t y_16546 = n_12449 * dim_12450;
    int64_t segmap_tblock_sizze_16548;
    
    segmap_tblock_sizze_16548 = *ctx->tuning_params.find_cluster_ids_6783zisegmap_tblock_sizze_16472;
    
    int64_t segmap_tblock_sizze_16562;
    
    segmap_tblock_sizze_16562 = *ctx->tuning_params.find_cluster_ids_6783zisegmap_tblock_sizze_16438;
    
    int64_t segred_tblock_sizze_16582;
    
    segred_tblock_sizze_16582 = *ctx->tuning_params.find_cluster_ids_6783zisegred_tblock_sizze_16408;
    
    int64_t segmap_tblock_sizze_16344;
    
    segmap_tblock_sizze_16344 = *ctx->tuning_params.find_cluster_ids_6783zisegmap_tblock_sizze_16317;
    
    int64_t segred_tblock_sizze_16598;
    
    segred_tblock_sizze_16598 = *ctx->tuning_params.find_cluster_ids_6783zisegred_tblock_sizze_16597;
    
    int64_t num_tblocks_16600;
    int64_t max_num_tblocks_18668;
    
    max_num_tblocks_18668 = *ctx->tuning_params.find_cluster_ids_6783zisegred_num_tblocks_16599;
    num_tblocks_16600 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(n_12449, segred_tblock_sizze_16598), max_num_tblocks_18668)));
    
    int64_t binop_y_18437 = n_12449 - (int64_t) 1;
    int64_t binop_y_18439 = smax64((int64_t) 0, binop_y_18437);
    int64_t binop_y_18441 = dim_12450 - (int64_t) 1;
    int64_t binop_x_18442 = smax64((int64_t) 0, binop_y_18441);
    int64_t bytes_18458 = (int64_t) 4 * dim_12450;
    int64_t binop_y_18474 = n_12449 * binop_x_18442;
    int64_t binop_y_18475 = smax64((int64_t) 0, binop_y_18474);
    int64_t binop_y_18476 = binop_y_18439 + binop_y_18475;
    int64_t binop_y_18477 = (int64_t) 1 + binop_y_18476;
    int64_t bytes_18478 = (int64_t) 4 * binop_y_18477;
    
    if (memblock_alloc_device(ctx, &mem_18498, (int64_t) 1, "mem_18498")) {
        err = 1;
        goto cleanup;
    }
    
    bool cluster_heads_12469;
    bool loop_while_12472;
    
    if (memblock_set_device(ctx, &mem_param_18424, &mem_18421, "mem_18421") != 0)
        return 1;
    loop_while_12472 = 1;
    while (loop_while_12472) {
        if (memblock_set_device(ctx, &mem_param_18427, &mem_param_18424, "mem_param_18424") != 0)
            return 1;
        for (int64_t i_12477 = 0; i_12477 < inner_iter_12462; i_12477++) {
            int64_t inf_12480 = mul64(extPar_12453, i_12477);
            int64_t min_arg1_12482 = add64(extPar_12453, inf_12480);
            int64_t min_res_15397 = smin64(n_12449, min_arg1_12482);
            int64_t j_m_i_12491 = sub64(min_res_15397, inf_12480);
            bool empty_slice_12498 = j_m_i_12491 == (int64_t) 0;
            int64_t m_12499 = sub64(j_m_i_12491, (int64_t) 1);
            int64_t i_p_m_t_s_12501 = add64(inf_12480, m_12499);
            bool zzero_leq_i_p_m_t_s_12502 = sle64((int64_t) 0, i_p_m_t_s_12501);
            bool i_p_m_t_s_leq_w_12504 = slt64(i_p_m_t_s_12501, n_12449);
            bool zzero_lte_i_12505 = sle64((int64_t) 0, inf_12480);
            bool i_lte_j_12506 = sle64(inf_12480, min_res_15397);
            bool y_12507 = i_p_m_t_s_leq_w_12504 && zzero_lte_i_12505;
            bool y_12508 = zzero_leq_i_p_m_t_s_12502 && y_12507;
            bool forwards_ok_12509 = i_lte_j_12506 && y_12508;
            bool ok_or_empty_12516 = empty_slice_12498 || forwards_ok_12509;
            bool index_certs_12518;
            
            if (!ok_or_empty_12516) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) inf_12480, ":", (long long) min_res_15397, "] out of bounds for array of shape [", (long long) n_12449, "].", "-> #0  ft_libs/ftDBSCAN.fut:75:48-65\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            
            bool suff_outer_par_16313;
            
            suff_outer_par_16313 = *ctx->tuning_params.find_cluster_ids_6783zisuff_outer_par_0 <= j_m_i_12491;
            if (ctx->logging)
                fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "find_cluster_ids_6783.suff_outer_par_0", (long) j_m_i_12491, suff_outer_par_16313 ? "true" : "false");
            
            int64_t nest_sizze_16547 = j_m_i_12491 * y_16546;
            int64_t nest_sizze_16561 = n_12449 * j_m_i_12491;
            int64_t num_tblocks_16583;
            int64_t max_num_tblocks_18674;
            
            max_num_tblocks_18674 = *ctx->tuning_params.find_cluster_ids_6783zisegred_num_tblocks_16410;
            num_tblocks_16583 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nest_sizze_16561, segred_tblock_sizze_16582), max_num_tblocks_18674)));
            
            int64_t binop_x_18429 = (int64_t) 4 * j_m_i_12491;
            int64_t binop_x_18430 = n_12449 * binop_x_18429;
            int64_t bytes_18431 = dim_12450 * binop_x_18430;
            int64_t binop_x_18434 = smax64((int64_t) 0, m_12499);
            int64_t binop_y_18435 = n_12449 * binop_x_18434;
            int64_t binop_x_18436 = smax64((int64_t) 0, binop_y_18435);
            int64_t binop_x_18440 = binop_x_18436 + binop_y_18439;
            int64_t binop_y_18444 = nest_sizze_16561 * binop_x_18442;
            int64_t binop_y_18445 = smax64((int64_t) 0, binop_y_18444);
            int64_t binop_y_18446 = binop_x_18440 + binop_y_18445;
            int64_t binop_y_18447 = (int64_t) 1 + binop_y_18446;
            int64_t bytes_18448 = (int64_t) 4 * binop_y_18447;
            int64_t binop_x_18451 = (int64_t) 8 * j_m_i_12491;
            int64_t bytes_18452 = n_12449 * binop_x_18451;
            int64_t binop_x_18537 = j_m_i_12491 * bytes_18458;
            int64_t total_sizze_18538 = n_12449 * binop_x_18537;
            int64_t ctx_18544 = n_12449 * j_m_i_12491;
            int64_t segmap_usable_groups_16345 = sdiv_up_safe64(j_m_i_12491, segmap_tblock_sizze_16344);
            int64_t num_threads_18528 = segmap_tblock_sizze_16344 * segmap_usable_groups_16345;
            int64_t total_sizze_18529 = bytes_18458 * num_threads_18528;
            int64_t shared_memory_capacity_18823;
            
            shared_memory_capacity_18823 = ctx->max_shared_memory;
            if (suff_outer_par_16313 && sle64((int64_t) 0, shared_memory_capacity_18823)) {
                if (memblock_alloc_device(ctx, &mem_18479, bytes_18478, "mem_18479")) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_4b(ctx, 2, mem_18479.mem, (int64_t) 0, (int64_t []) {(int64_t) 1, n_12449}, core_dat_mem_18419.mem, (int64_t) 0, (int64_t []) {dim_12450, (int64_t) 1}, (int64_t []) {n_12449, dim_12450})) != 0)
                    goto cleanup;
                if (memblock_alloc_device(ctx, &mem_18490, binop_x_18451, "mem_18490")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &color_18526, total_sizze_18529, "color_18526")) {
                    err = 1;
                    goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_18675 = sext_i64_i32(sdiv_up64(j_m_i_12491, segmap_tblock_sizze_16344));
                
                {
                    err = gpu_kernel_find_cluster_ids_6783zisegmap_16348(ctx, segmap_usable_groups_16345, 1, 1, *ctx->tuning_params.find_cluster_ids_6783zisegmap_tblock_sizze_16317, 1, 1, (int64_t) 0, n_12449, dim_12450, eps_12452, inf_12480, j_m_i_12491, num_threads_18528, core_dat_mem_18419.mem, mem_param_18427.mem, mem_18479.mem, mem_18490.mem, color_18526.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                if (memblock_unref_device(ctx, &mem_18479, "mem_18479") != 0)
                    return 1;
                if (memblock_unref_device(ctx, &color_18526, "color_18526") != 0)
                    return 1;
                if (memblock_set_device(ctx, &ext_mem_18491, &mem_18490, "mem_18490") != 0)
                    return 1;
            } else {
                int64_t shared_memory_capacity_18822;
                
                shared_memory_capacity_18822 = ctx->max_shared_memory;
                if (intra_suff_and_fits_16374 && sle64(sdiv_up64((int64_t) 8 * n_12449, (int64_t) 8) * (int64_t) 8, shared_memory_capacity_18822)) {
                    if (memblock_alloc_device(ctx, &mem_18467, binop_x_18451, "mem_18467")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &color_18527, total_sizze_18538, "color_18527")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t num_chunks_18687 = sext_i64_i32(sdiv_up64(n_12449, n_12449));
                    int32_t virt_num_tblocks_18688 = sext_i64_i32(j_m_i_12491);
                    
                    {
                        err = gpu_kernel_find_cluster_ids_6783zisegmap_intrablock_16377(ctx, j_m_i_12491, 1, 1, n_12449, 1, 1, (int64_t) 8 * n_12449 + srem64((int64_t) 8 - srem64((int64_t) 8 * n_12449, (int64_t) 8), (int64_t) 8), n_12449, dim_12450, eps_12452, inf_12480, j_m_i_12491, ctx_18544, core_dat_mem_18419.mem, mem_param_18427.mem, mem_18467.mem, color_18527.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_unref_device(ctx, &color_18527, "color_18527") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &ext_mem_18468, &mem_18467, "mem_18467") != 0)
                        return 1;
                } else {
                    int64_t segmap_usable_groups_16549 = sdiv_up64(nest_sizze_16547, segmap_tblock_sizze_16548);
                    
                    if (memblock_alloc_device(ctx, &mem_18432, bytes_18431, "mem_18432")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t virt_num_tblocks_18705 = sext_i64_i32(sdiv_up64(j_m_i_12491 * n_12449 * dim_12450, segmap_tblock_sizze_16548));
                    
                    {
                        err = gpu_kernel_find_cluster_ids_6783zisegmap_16554(ctx, segmap_usable_groups_16549, 1, 1, *ctx->tuning_params.find_cluster_ids_6783zisegmap_tblock_sizze_16472, 1, 1, (int64_t) 0, n_12449, dim_12450, inf_12480, j_m_i_12491, core_dat_mem_18419.mem, mem_18432.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    
                    int64_t segmap_usable_groups_16563 = sdiv_up64(nest_sizze_16561, segmap_tblock_sizze_16562);
                    
                    if (memblock_alloc_device(ctx, &mem_18449, bytes_18448, "mem_18449")) {
                        err = 1;
                        goto cleanup;
                    }
                    if ((err = lmad_copy_gpu2gpu_4b(ctx, 3, mem_18449.mem, (int64_t) 0, (int64_t []) {n_12449, (int64_t) 1, n_12449 * j_m_i_12491}, mem_18432.mem, (int64_t) 0, (int64_t []) {dim_12450 * n_12449, dim_12450, (int64_t) 1}, (int64_t []) {j_m_i_12491, n_12449, dim_12450})) != 0)
                        goto cleanup;
                    if (memblock_unref_device(ctx, &mem_18432, "mem_18432") != 0)
                        return 1;
                    if (memblock_alloc_device(ctx, &mem_18453, bytes_18452, "mem_18453")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t virt_num_tblocks_18718 = sext_i64_i32(sdiv_up64(j_m_i_12491 * n_12449, segmap_tblock_sizze_16562));
                    
                    {
                        err = gpu_kernel_find_cluster_ids_6783zisegmap_16567(ctx, segmap_usable_groups_16563, 1, 1, *ctx->tuning_params.find_cluster_ids_6783zisegmap_tblock_sizze_16438, 1, 1, (int64_t) 0, n_12449, dim_12450, eps_12452, inf_12480, j_m_i_12491, mem_param_18427.mem, mem_18449.mem, mem_18453.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_unref_device(ctx, &mem_18449, "mem_18449") != 0)
                        return 1;
                    if (memblock_alloc_device(ctx, &mem_18456, binop_x_18451, "mem_18456")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegRed");
                    
                    int64_t chunk_sizze_18730 = (int64_t) 1;
                    
                    if (slt64(n_12449 * (int64_t) 2, segred_tblock_sizze_16582 * chunk_sizze_18730)) {
                        int64_t segment_sizze_nonzzero_18731 = smax64((int64_t) 1, n_12449);
                        int64_t num_threads_18732 = segred_tblock_sizze_16582 * segred_tblock_sizze_16582;
                        
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "# SegRed-small");
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) j_m_i_12491, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) n_12449, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "segments_per_block", (long long) squot64(segred_tblock_sizze_16582, segment_sizze_nonzzero_18731), '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "required_blocks", (long long) sext_i64_i32(sdiv_up64(j_m_i_12491, squot64(segred_tblock_sizze_16582, segment_sizze_nonzzero_18731))), '\n');
                        {
                            err = gpu_kernel_find_cluster_ids_6783zisegred_small_16588(ctx, num_tblocks_16583, 1, 1, *ctx->tuning_params.find_cluster_ids_6783zisegred_tblock_sizze_16408, 1, 1, (int64_t) 8 * segred_tblock_sizze_16582 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_16582, (int64_t) 8), (int64_t) 8), n_12449, j_m_i_12491, num_tblocks_16583, segment_sizze_nonzzero_18731, mem_18453.mem, mem_18456.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                    } else {
                        int64_t blocks_per_segment_18759 = sdiv_up64(num_tblocks_16583, smax64((int64_t) 1, j_m_i_12491));
                        int64_t q_18760 = sdiv_up64(n_12449, segred_tblock_sizze_16582 * blocks_per_segment_18759 * chunk_sizze_18730);
                        int64_t num_virtblocks_18761 = blocks_per_segment_18759 * j_m_i_12491;
                        int64_t threads_per_segment_18762 = blocks_per_segment_18759 * segred_tblock_sizze_16582;
                        
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "# SegRed-large");
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) j_m_i_12491, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) n_12449, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "num_virtblocks", (long long) num_virtblocks_18761, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "num_tblocks", (long long) num_tblocks_16583, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "tblock_size", (long long) segred_tblock_sizze_16582, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "q", (long long) q_18760, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "blocks_per_segment", (long long) blocks_per_segment_18759, '\n');
                        if (memblock_alloc_device(ctx, &segred_tmp_mem_18763, (int64_t) 8 * num_virtblocks_18761, "segred_tmp_mem_18763")) {
                            err = 1;
                            goto cleanup;
                        }
                        {
                            err = gpu_kernel_find_cluster_ids_6783zisegred_large_16588(ctx, num_tblocks_16583, 1, 1, *ctx->tuning_params.find_cluster_ids_6783zisegred_tblock_sizze_16408, 1, 1, 8 + ((int64_t) 8 * segred_tblock_sizze_16582 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_16582, (int64_t) 8), (int64_t) 8)), n_12449, j_m_i_12491, num_tblocks_16583, blocks_per_segment_18759, q_18760, num_virtblocks_18761, threads_per_segment_18762, mem_18453.mem, mem_18456.mem, segred_tmp_mem_18763.mem, counters_mem_18765.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_unref_device(ctx, &mem_18453, "mem_18453") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &ext_mem_18468, &mem_18456, "mem_18456") != 0)
                        return 1;
                }
                if (memblock_set_device(ctx, &ext_mem_18491, &ext_mem_18468, "ext_mem_18468") != 0)
                    return 1;
            }
            if (memblock_alloc_device(ctx, &mem_18493, bytes_18420, "mem_18493")) {
                err = 1;
                goto cleanup;
            }
            if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_18493.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_18427.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_12449})) != 0)
                goto cleanup;
            if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_18493.mem, inf_12480, (int64_t []) {(int64_t) 1}, ext_mem_18491.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_12491})) != 0)
                goto cleanup;
            if (memblock_unref_device(ctx, &ext_mem_18491, "ext_mem_18491") != 0)
                return 1;
            if (memblock_set_device(ctx, &mem_param_tmp_18672, &mem_18493, "mem_18493") != 0)
                return 1;
            if (memblock_set_device(ctx, &mem_param_18427, &mem_param_tmp_18672, "mem_param_tmp_18672") != 0)
                return 1;
        }
        if (memblock_set_device(ctx, &ext_mem_18496, &mem_param_18427, "mem_param_18427") != 0)
            return 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegRed");
        
        int64_t chunk_sizze_18824 = (int64_t) 1;
        
        if (memblock_alloc_device(ctx, &segred_tmp_mem_18827, num_tblocks_16600, "segred_tmp_mem_18827")) {
            err = 1;
            goto cleanup;
        }
        
        int64_t num_threads_18829 = num_tblocks_16600 * segred_tblock_sizze_16598;
        
        {
            err = gpu_kernel_find_cluster_ids_6783zisegred_nonseg_16605(ctx, num_tblocks_16600, 1, 1, *ctx->tuning_params.find_cluster_ids_6783zisegred_tblock_sizze_16597, 1, 1, 8 + (segred_tblock_sizze_16598 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_16598, (int64_t) 8), (int64_t) 8)), n_12449, num_tblocks_16600, num_threads_18829, mem_param_18424.mem, ext_mem_18496.mem, mem_18498.mem, counters_mem_18825.mem, segred_tmp_mem_18827.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        bool read_res_19032;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_19032, mem_18498.mem, (int64_t) 0 * sizeof(bool), sizeof(bool))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        bool defunc_0_reduce_res_16166 = read_res_19032;
        bool loop_cond_12631 = !defunc_0_reduce_res_16166;
        
        if (memblock_set_device(ctx, &mem_param_tmp_18669, &ext_mem_18496, "ext_mem_18496") != 0)
            return 1;
        
        bool loop_while_tmp_18670 = loop_cond_12631;
        
        if (memblock_set_device(ctx, &mem_param_18424, &mem_param_tmp_18669, "mem_param_tmp_18669") != 0)
            return 1;
        loop_while_12472 = loop_while_tmp_18670;
    }
    if (memblock_set_device(ctx, &ext_mem_18501, &mem_param_18424, "mem_param_18424") != 0)
        return 1;
    cluster_heads_12469 = loop_while_12472;
    if (memblock_unref_device(ctx, &mem_18421, "mem_18421") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18498, "mem_18498") != 0)
        return 1;
    
    int64_t segscan_tblock_sizze_16608;
    
    segscan_tblock_sizze_16608 = *ctx->tuning_params.find_cluster_ids_6783zisegscan_tblock_sizze_16607;
    
    int64_t num_tblocks_16610;
    int64_t max_num_tblocks_18858;
    
    max_num_tblocks_18858 = *ctx->tuning_params.find_cluster_ids_6783zisegscan_num_tblocks_16609;
    num_tblocks_16610 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(n_12449, segscan_tblock_sizze_16608), max_num_tblocks_18858)));
    if (memblock_alloc_device(ctx, &mem_18504, bytes_18420, "mem_18504")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, n_12449)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_18859;
        
        shared_memory_18859 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_18860;
        
        thread_block_sizze_18860 = ctx->max_thread_block_size;
        
        int64_t registers_18861;
        
        registers_18861 = ctx->max_registers;
        
        int64_t thread_block_sizze_18862;
        
        thread_block_sizze_18862 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_18863 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_18859, thread_block_sizze_18860), (int64_t) 8), squot64(squot64(registers_18861, thread_block_sizze_18862) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
        int64_t num_virt_blocks_18864 = sdiv_up64(n_12449, segscan_tblock_sizze_16608 * chunk_sizze_18863);
        int64_t num_virt_threads_18865 = num_virt_blocks_18864 * segscan_tblock_sizze_16608;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_18863, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_18866, num_virt_blocks_18864, "status_flags_mem_18866")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_18866, num_virt_blocks_18864, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_18888, (int64_t) 8 * num_virt_blocks_18864, "aggregates_mem_18888")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_18890, (int64_t) 8 * num_virt_blocks_18864, "incprefixes_mem_18890")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_find_cluster_ids_6783zisegscan_16613(ctx, num_tblocks_16610, 1, 1, *ctx->tuning_params.find_cluster_ids_6783zisegscan_tblock_sizze_16607, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_16608), chunk_sizze_18863 * segscan_tblock_sizze_16608 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_16608), chunk_sizze_18863 * segscan_tblock_sizze_16608 * (int64_t) 8), (int64_t) 8), (int64_t) 8), n_12449, num_tblocks_16610, num_virt_blocks_18864, num_virt_threads_18865, ext_mem_18501.mem, mem_18504.mem, status_flags_mem_18866.mem, aggregates_mem_18888.mem, incprefixes_mem_18890.mem, global_dynid_mem_18892.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    
    int64_t segmap_tblock_sizze_16629;
    
    segmap_tblock_sizze_16629 = *ctx->tuning_params.find_cluster_ids_6783zisegmap_tblock_sizze_16617;
    
    int64_t segmap_usable_groups_16630 = sdiv_up64(n_12449, segmap_tblock_sizze_16629);
    
    if (memblock_alloc_device(ctx, &mem_18507, bytes_18420, "mem_18507")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_18981 = sext_i64_i32(sdiv_up64(n_12449, segmap_tblock_sizze_16629));
    
    {
        err = gpu_kernel_find_cluster_ids_6783zisegmap_16633(ctx, segmap_usable_groups_16630, 1, 1, *ctx->tuning_params.find_cluster_ids_6783zisegmap_tblock_sizze_16617, 1, 1, (int64_t) 0, n_12449, mem_18504.mem, mem_18507.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_18504, "mem_18504") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_18509, bytes_18420, "mem_18509")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_18509, n_12449, (int64_t) -1) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t segmap_tblock_sizze_16660;
    
    segmap_tblock_sizze_16660 = *ctx->tuning_params.find_cluster_ids_6783zisegmap_tblock_sizze_16643;
    
    int64_t segmap_usable_groups_16661 = sdiv_up_safe64(n_12449, segmap_tblock_sizze_16660);
    
    if (memblock_set_device(ctx, &mem_param_18512, &mem_18509, "mem_18509") != 0)
        return 1;
    for (int64_t i_15651 = 0; i_15651 < max_iter_15646; i_15651++) {
        int64_t inf_15653 = mul64(max_res_15640, i_15651);
        int64_t min_arg1_15654 = add64(max_res_15640, inf_15653);
        int64_t min_res_15655 = smin64(n_12449, min_arg1_15654);
        
        if (memblock_alloc_device(ctx, &mem_18515, bytes_18420, "mem_18515")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_19012 = sext_i64_i32(sdiv_up64(n_12449, segmap_tblock_sizze_16660));
        
        {
            err = gpu_kernel_find_cluster_ids_6783zisegmap_16664(ctx, segmap_usable_groups_16661, 1, 1, *ctx->tuning_params.find_cluster_ids_6783zisegmap_tblock_sizze_16643, 1, 1, (int64_t) 0, n_12449, inf_15653, min_res_15655, ext_mem_18501.mem, mem_18507.mem, mem_param_18512.mem, mem_18515.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if (memblock_set_device(ctx, &mem_param_tmp_19010, &mem_18515, "mem_18515") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_18512, &mem_param_tmp_19010, "mem_param_tmp_19010") != 0)
            return 1;
    }
    if (memblock_set_device(ctx, &ext_mem_18518, &mem_param_18512, "mem_param_18512") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_18501, "ext_mem_18501") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18507, "mem_18507") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18509, "mem_18509") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_18650, &ext_mem_18518, "ext_mem_18518") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_19031, &mem_out_18650, "mem_out_18650") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_param_tmp_19010, "mem_param_tmp_19010") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18515, "mem_18515") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_18512, "mem_param_18512") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_18518, "ext_mem_18518") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18509, "mem_18509") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18507, "mem_18507") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_18890, "incprefixes_mem_18890") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_18888, "aggregates_mem_18888") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_18866, "status_flags_mem_18866") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18504, "mem_18504") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_18669, "mem_param_tmp_18669") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_18827, "segred_tmp_mem_18827") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_18672, "mem_param_tmp_18672") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18493, "mem_18493") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_18763, "segred_tmp_mem_18763") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18456, "mem_18456") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18453, "mem_18453") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18449, "mem_18449") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18432, "mem_18432") != 0)
            return 1;
        if (memblock_unref_device(ctx, &color_18527, "color_18527") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18467, "mem_18467") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_18468, "ext_mem_18468") != 0)
            return 1;
        if (memblock_unref_device(ctx, &color_18526, "color_18526") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18490, "mem_18490") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18479, "mem_18479") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_18491, "ext_mem_18491") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_18427, "mem_param_18427") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_18496, "ext_mem_18496") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_18424, "mem_param_18424") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_18501, "ext_mem_18501") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18498, "mem_18498") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18421, "mem_18421") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_18650, "mem_out_18650") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_find_cluster_ids_6890(struct futhark_context *ctx, struct memblock_device *mem_out_p_19033, struct memblock_device core_dat_mem_18419, int64_t n_14507, int64_t dim_14508, double eps_14510, int64_t extPar_14511, int64_t gather_psizze_14512)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_param_tmp_19010;
    
    mem_param_tmp_19010.references = NULL;
    
    struct memblock_device mem_18515;
    
    mem_18515.references = NULL;
    
    struct memblock_device mem_param_18512;
    
    mem_param_18512.references = NULL;
    
    struct memblock_device ext_mem_18518;
    
    ext_mem_18518.references = NULL;
    
    struct memblock_device mem_18509;
    
    mem_18509.references = NULL;
    
    struct memblock_device mem_18507;
    
    mem_18507.references = NULL;
    
    struct memblock_device incprefixes_mem_18890;
    
    incprefixes_mem_18890.references = NULL;
    
    struct memblock_device aggregates_mem_18888;
    
    aggregates_mem_18888.references = NULL;
    
    struct memblock_device status_flags_mem_18866;
    
    status_flags_mem_18866.references = NULL;
    
    struct memblock_device mem_18504;
    
    mem_18504.references = NULL;
    
    struct memblock_device mem_param_tmp_18669;
    
    mem_param_tmp_18669.references = NULL;
    
    struct memblock_device segred_tmp_mem_18827;
    
    segred_tmp_mem_18827.references = NULL;
    
    struct memblock_device mem_param_tmp_18672;
    
    mem_param_tmp_18672.references = NULL;
    
    struct memblock_device mem_18493;
    
    mem_18493.references = NULL;
    
    struct memblock_device segred_tmp_mem_18763;
    
    segred_tmp_mem_18763.references = NULL;
    
    struct memblock_device mem_18456;
    
    mem_18456.references = NULL;
    
    struct memblock_device mem_18453;
    
    mem_18453.references = NULL;
    
    struct memblock_device mem_18449;
    
    mem_18449.references = NULL;
    
    struct memblock_device mem_18432;
    
    mem_18432.references = NULL;
    
    struct memblock_device color_18527;
    
    color_18527.references = NULL;
    
    struct memblock_device mem_18467;
    
    mem_18467.references = NULL;
    
    struct memblock_device ext_mem_18468;
    
    ext_mem_18468.references = NULL;
    
    struct memblock_device color_18526;
    
    color_18526.references = NULL;
    
    struct memblock_device mem_18490;
    
    mem_18490.references = NULL;
    
    struct memblock_device mem_18479;
    
    mem_18479.references = NULL;
    
    struct memblock_device ext_mem_18491;
    
    ext_mem_18491.references = NULL;
    
    struct memblock_device mem_param_18427;
    
    mem_param_18427.references = NULL;
    
    struct memblock_device ext_mem_18496;
    
    ext_mem_18496.references = NULL;
    
    struct memblock_device mem_param_18424;
    
    mem_param_18424.references = NULL;
    
    struct memblock_device ext_mem_18501;
    
    ext_mem_18501.references = NULL;
    
    struct memblock_device mem_18498;
    
    mem_18498.references = NULL;
    
    struct memblock_device mem_18421;
    
    mem_18421.references = NULL;
    
    struct memblock_device mem_out_18650;
    
    mem_out_18650.references = NULL;
    
    struct memblock_device counters_mem_18763 = ctx->constants->counters_mem_18763;
    struct memblock_device counters_mem_18765 = ctx->constants->counters_mem_18765;
    struct memblock_device counters_mem_18789 = ctx->constants->counters_mem_18789;
    struct memblock_device counters_mem_18825 = ctx->constants->counters_mem_18825;
    struct memblock_device global_dynid_mem_18686 = ctx->constants->global_dynid_mem_18686;
    struct memblock_device global_dynid_mem_18892 = ctx->constants->global_dynid_mem_18892;
    int64_t zm_lhs_14513 = add64(n_14507, extPar_14511);
    int64_t zs_lhs_14515 = sub64(zm_lhs_14513, (int64_t) 1);
    bool zzero_14517 = extPar_14511 == (int64_t) 0;
    bool nonzzero_14518 = !zzero_14517;
    bool nonzzero_cert_14519;
    
    if (!nonzzero_14518) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ft_libs/ftDBSCAN.fut:65:50-57\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t inner_iter_14520 = sdiv64(zs_lhs_14515, extPar_14511);
    int64_t bytes_18420 = (int64_t) 8 * n_14507;
    bool bounds_invalid_upwards_15391 = slt64(inner_iter_14520, (int64_t) 0);
    bool valid_15392 = !bounds_invalid_upwards_15391;
    bool range_valid_c_15393;
    
    if (!valid_15392) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) (int64_t) 0, "..", (long long) (int64_t) 1, "..<", (long long) inner_iter_14520, " is invalid.", "-> #0  /prelude/array.fut:94:3-11\n   #1  ft_libs/ftDBSCAN.fut:72:57-72\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t max_arg1_15639 = sdiv64(gather_psizze_14512, (int64_t) 8);
    int64_t max_res_15640 = smax64((int64_t) 1, max_arg1_15639);
    int64_t zm_lhs_15641 = add64(n_14507, max_res_15640);
    int64_t zs_lhs_15642 = sub64(zm_lhs_15641, (int64_t) 1);
    bool zzero_15643 = max_res_15640 == (int64_t) 0;
    bool nonzzero_15644 = !zzero_15643;
    bool nonzzero_cert_15645;
    
    if (!nonzzero_15644) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ft_libs/ftbasics.fut:27:31-39\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t max_iter_15646 = sdiv64(zs_lhs_15642, max_res_15640);
    bool bounds_invalid_upwards_15647 = slt64(max_iter_15646, (int64_t) 0);
    bool valid_15648 = !bounds_invalid_upwards_15647;
    bool range_valid_c_15649;
    
    if (!valid_15648) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) (int64_t) 0, "..", (long long) (int64_t) 1, "..<", (long long) max_iter_15646, " is invalid.", "-> #0  /prelude/array.fut:94:3-11\n   #1  ft_libs/ftbasics.fut:28:33-46\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_18421, bytes_18420, "mem_18421")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhiota_i64(ctx, mem_18421, n_14507, (int64_t) 0, (int64_t) 1) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t max_tblock_sizze_16743;
    
    max_tblock_sizze_16743 = ctx->max_thread_block_size;
    
    bool fits_16744 = sle64(n_14507, max_tblock_sizze_16743);
    bool suff_intra_par_16742;
    
    suff_intra_par_16742 = *ctx->tuning_params.find_cluster_ids_6890zisuff_intra_par_1 <= n_14507;
    if (ctx->logging)
        fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "find_cluster_ids_6890.suff_intra_par_1", (long) n_14507, suff_intra_par_16742 ? "true" : "false");
    
    bool intra_suff_and_fits_16745 = suff_intra_par_16742 && fits_16744;
    int64_t y_16917 = n_14507 * dim_14508;
    int64_t segmap_tblock_sizze_16919;
    
    segmap_tblock_sizze_16919 = *ctx->tuning_params.find_cluster_ids_6890zisegmap_tblock_sizze_16843;
    
    int64_t segmap_tblock_sizze_16933;
    
    segmap_tblock_sizze_16933 = *ctx->tuning_params.find_cluster_ids_6890zisegmap_tblock_sizze_16809;
    
    int64_t segred_tblock_sizze_16953;
    
    segred_tblock_sizze_16953 = *ctx->tuning_params.find_cluster_ids_6890zisegred_tblock_sizze_16779;
    
    int64_t segmap_tblock_sizze_16715;
    
    segmap_tblock_sizze_16715 = *ctx->tuning_params.find_cluster_ids_6890zisegmap_tblock_sizze_16688;
    
    int64_t segred_tblock_sizze_16969;
    
    segred_tblock_sizze_16969 = *ctx->tuning_params.find_cluster_ids_6890zisegred_tblock_sizze_16968;
    
    int64_t num_tblocks_16971;
    int64_t max_num_tblocks_18668;
    
    max_num_tblocks_18668 = *ctx->tuning_params.find_cluster_ids_6890zisegred_num_tblocks_16970;
    num_tblocks_16971 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(n_14507, segred_tblock_sizze_16969), max_num_tblocks_18668)));
    
    int64_t binop_y_18437 = n_14507 - (int64_t) 1;
    int64_t binop_y_18439 = smax64((int64_t) 0, binop_y_18437);
    int64_t binop_y_18441 = dim_14508 - (int64_t) 1;
    int64_t binop_x_18442 = smax64((int64_t) 0, binop_y_18441);
    int64_t bytes_18458 = (int64_t) 8 * dim_14508;
    int64_t binop_y_18474 = n_14507 * binop_x_18442;
    int64_t binop_y_18475 = smax64((int64_t) 0, binop_y_18474);
    int64_t binop_y_18476 = binop_y_18439 + binop_y_18475;
    int64_t binop_y_18477 = (int64_t) 1 + binop_y_18476;
    int64_t bytes_18478 = (int64_t) 8 * binop_y_18477;
    
    if (memblock_alloc_device(ctx, &mem_18498, (int64_t) 1, "mem_18498")) {
        err = 1;
        goto cleanup;
    }
    
    bool cluster_heads_14527;
    bool loop_while_14530;
    
    if (memblock_set_device(ctx, &mem_param_18424, &mem_18421, "mem_18421") != 0)
        return 1;
    loop_while_14530 = 1;
    while (loop_while_14530) {
        if (memblock_set_device(ctx, &mem_param_18427, &mem_param_18424, "mem_param_18424") != 0)
            return 1;
        for (int64_t i_14535 = 0; i_14535 < inner_iter_14520; i_14535++) {
            int64_t inf_14538 = mul64(extPar_14511, i_14535);
            int64_t min_arg1_14540 = add64(extPar_14511, inf_14538);
            int64_t min_res_15397 = smin64(n_14507, min_arg1_14540);
            int64_t j_m_i_14549 = sub64(min_res_15397, inf_14538);
            bool empty_slice_14556 = j_m_i_14549 == (int64_t) 0;
            int64_t m_14557 = sub64(j_m_i_14549, (int64_t) 1);
            int64_t i_p_m_t_s_14559 = add64(inf_14538, m_14557);
            bool zzero_leq_i_p_m_t_s_14560 = sle64((int64_t) 0, i_p_m_t_s_14559);
            bool i_p_m_t_s_leq_w_14562 = slt64(i_p_m_t_s_14559, n_14507);
            bool zzero_lte_i_14563 = sle64((int64_t) 0, inf_14538);
            bool i_lte_j_14564 = sle64(inf_14538, min_res_15397);
            bool y_14565 = i_p_m_t_s_leq_w_14562 && zzero_lte_i_14563;
            bool y_14566 = zzero_leq_i_p_m_t_s_14560 && y_14565;
            bool forwards_ok_14567 = i_lte_j_14564 && y_14566;
            bool ok_or_empty_14574 = empty_slice_14556 || forwards_ok_14567;
            bool index_certs_14576;
            
            if (!ok_or_empty_14574) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) inf_14538, ":", (long long) min_res_15397, "] out of bounds for array of shape [", (long long) n_14507, "].", "-> #0  ft_libs/ftDBSCAN.fut:75:48-65\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            
            bool suff_outer_par_16684;
            
            suff_outer_par_16684 = *ctx->tuning_params.find_cluster_ids_6890zisuff_outer_par_0 <= j_m_i_14549;
            if (ctx->logging)
                fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "find_cluster_ids_6890.suff_outer_par_0", (long) j_m_i_14549, suff_outer_par_16684 ? "true" : "false");
            
            int64_t nest_sizze_16918 = j_m_i_14549 * y_16917;
            int64_t nest_sizze_16932 = n_14507 * j_m_i_14549;
            int64_t num_tblocks_16954;
            int64_t max_num_tblocks_18674;
            
            max_num_tblocks_18674 = *ctx->tuning_params.find_cluster_ids_6890zisegred_num_tblocks_16781;
            num_tblocks_16954 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nest_sizze_16932, segred_tblock_sizze_16953), max_num_tblocks_18674)));
            
            int64_t binop_x_18429 = (int64_t) 8 * j_m_i_14549;
            int64_t binop_x_18430 = n_14507 * binop_x_18429;
            int64_t bytes_18431 = dim_14508 * binop_x_18430;
            int64_t binop_x_18434 = smax64((int64_t) 0, m_14557);
            int64_t binop_y_18435 = n_14507 * binop_x_18434;
            int64_t binop_x_18436 = smax64((int64_t) 0, binop_y_18435);
            int64_t binop_x_18440 = binop_x_18436 + binop_y_18439;
            int64_t binop_y_18444 = nest_sizze_16932 * binop_x_18442;
            int64_t binop_y_18445 = smax64((int64_t) 0, binop_y_18444);
            int64_t binop_y_18446 = binop_x_18440 + binop_y_18445;
            int64_t binop_y_18447 = (int64_t) 1 + binop_y_18446;
            int64_t bytes_18448 = (int64_t) 8 * binop_y_18447;
            int64_t binop_x_18557 = j_m_i_14549 * bytes_18458;
            int64_t total_sizze_18558 = n_14507 * binop_x_18557;
            int64_t ctx_18564 = n_14507 * j_m_i_14549;
            int64_t segmap_usable_groups_16716 = sdiv_up_safe64(j_m_i_14549, segmap_tblock_sizze_16715);
            int64_t num_threads_18548 = segmap_tblock_sizze_16715 * segmap_usable_groups_16716;
            int64_t total_sizze_18549 = bytes_18458 * num_threads_18548;
            int64_t shared_memory_capacity_18823;
            
            shared_memory_capacity_18823 = ctx->max_shared_memory;
            if (suff_outer_par_16684 && sle64((int64_t) 0, shared_memory_capacity_18823)) {
                if (memblock_alloc_device(ctx, &mem_18479, bytes_18478, "mem_18479")) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_8b(ctx, 2, mem_18479.mem, (int64_t) 0, (int64_t []) {(int64_t) 1, n_14507}, core_dat_mem_18419.mem, (int64_t) 0, (int64_t []) {dim_14508, (int64_t) 1}, (int64_t []) {n_14507, dim_14508})) != 0)
                    goto cleanup;
                if (memblock_alloc_device(ctx, &mem_18490, binop_x_18429, "mem_18490")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &color_18526, total_sizze_18549, "color_18526")) {
                    err = 1;
                    goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_18675 = sext_i64_i32(sdiv_up64(j_m_i_14549, segmap_tblock_sizze_16715));
                
                {
                    err = gpu_kernel_find_cluster_ids_6890zisegmap_16719(ctx, segmap_usable_groups_16716, 1, 1, *ctx->tuning_params.find_cluster_ids_6890zisegmap_tblock_sizze_16688, 1, 1, (int64_t) 0, n_14507, dim_14508, eps_14510, inf_14538, j_m_i_14549, num_threads_18548, core_dat_mem_18419.mem, mem_param_18427.mem, mem_18479.mem, mem_18490.mem, color_18526.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                if (memblock_unref_device(ctx, &mem_18479, "mem_18479") != 0)
                    return 1;
                if (memblock_unref_device(ctx, &color_18526, "color_18526") != 0)
                    return 1;
                if (memblock_set_device(ctx, &ext_mem_18491, &mem_18490, "mem_18490") != 0)
                    return 1;
            } else {
                int64_t shared_memory_capacity_18822;
                
                shared_memory_capacity_18822 = ctx->max_shared_memory;
                if (intra_suff_and_fits_16745 && sle64(sdiv_up64((int64_t) 8 * n_14507, (int64_t) 8) * (int64_t) 8, shared_memory_capacity_18822)) {
                    if (memblock_alloc_device(ctx, &mem_18467, binop_x_18429, "mem_18467")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &color_18527, total_sizze_18558, "color_18527")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t num_chunks_18687 = sext_i64_i32(sdiv_up64(n_14507, n_14507));
                    int32_t virt_num_tblocks_18688 = sext_i64_i32(j_m_i_14549);
                    
                    {
                        err = gpu_kernel_find_cluster_ids_6890zisegmap_intrablock_16748(ctx, j_m_i_14549, 1, 1, n_14507, 1, 1, (int64_t) 8 * n_14507 + srem64((int64_t) 8 - srem64((int64_t) 8 * n_14507, (int64_t) 8), (int64_t) 8), n_14507, dim_14508, eps_14510, inf_14538, j_m_i_14549, ctx_18564, core_dat_mem_18419.mem, mem_param_18427.mem, mem_18467.mem, color_18527.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_unref_device(ctx, &color_18527, "color_18527") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &ext_mem_18468, &mem_18467, "mem_18467") != 0)
                        return 1;
                } else {
                    int64_t segmap_usable_groups_16920 = sdiv_up64(nest_sizze_16918, segmap_tblock_sizze_16919);
                    
                    if (memblock_alloc_device(ctx, &mem_18432, bytes_18431, "mem_18432")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t virt_num_tblocks_18705 = sext_i64_i32(sdiv_up64(j_m_i_14549 * n_14507 * dim_14508, segmap_tblock_sizze_16919));
                    
                    {
                        err = gpu_kernel_find_cluster_ids_6890zisegmap_16925(ctx, segmap_usable_groups_16920, 1, 1, *ctx->tuning_params.find_cluster_ids_6890zisegmap_tblock_sizze_16843, 1, 1, (int64_t) 0, n_14507, dim_14508, inf_14538, j_m_i_14549, core_dat_mem_18419.mem, mem_18432.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    
                    int64_t segmap_usable_groups_16934 = sdiv_up64(nest_sizze_16932, segmap_tblock_sizze_16933);
                    
                    if (memblock_alloc_device(ctx, &mem_18449, bytes_18448, "mem_18449")) {
                        err = 1;
                        goto cleanup;
                    }
                    if ((err = lmad_copy_gpu2gpu_8b(ctx, 3, mem_18449.mem, (int64_t) 0, (int64_t []) {n_14507, (int64_t) 1, n_14507 * j_m_i_14549}, mem_18432.mem, (int64_t) 0, (int64_t []) {dim_14508 * n_14507, dim_14508, (int64_t) 1}, (int64_t []) {j_m_i_14549, n_14507, dim_14508})) != 0)
                        goto cleanup;
                    if (memblock_unref_device(ctx, &mem_18432, "mem_18432") != 0)
                        return 1;
                    if (memblock_alloc_device(ctx, &mem_18453, binop_x_18430, "mem_18453")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t virt_num_tblocks_18718 = sext_i64_i32(sdiv_up64(j_m_i_14549 * n_14507, segmap_tblock_sizze_16933));
                    
                    {
                        err = gpu_kernel_find_cluster_ids_6890zisegmap_16938(ctx, segmap_usable_groups_16934, 1, 1, *ctx->tuning_params.find_cluster_ids_6890zisegmap_tblock_sizze_16809, 1, 1, (int64_t) 0, n_14507, dim_14508, eps_14510, inf_14538, j_m_i_14549, mem_param_18427.mem, mem_18449.mem, mem_18453.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_unref_device(ctx, &mem_18449, "mem_18449") != 0)
                        return 1;
                    if (memblock_alloc_device(ctx, &mem_18456, binop_x_18429, "mem_18456")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegRed");
                    
                    int64_t chunk_sizze_18730 = (int64_t) 1;
                    
                    if (slt64(n_14507 * (int64_t) 2, segred_tblock_sizze_16953 * chunk_sizze_18730)) {
                        int64_t segment_sizze_nonzzero_18731 = smax64((int64_t) 1, n_14507);
                        int64_t num_threads_18732 = segred_tblock_sizze_16953 * segred_tblock_sizze_16953;
                        
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "# SegRed-small");
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) j_m_i_14549, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) n_14507, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "segments_per_block", (long long) squot64(segred_tblock_sizze_16953, segment_sizze_nonzzero_18731), '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "required_blocks", (long long) sext_i64_i32(sdiv_up64(j_m_i_14549, squot64(segred_tblock_sizze_16953, segment_sizze_nonzzero_18731))), '\n');
                        {
                            err = gpu_kernel_find_cluster_ids_6890zisegred_small_16959(ctx, num_tblocks_16954, 1, 1, *ctx->tuning_params.find_cluster_ids_6890zisegred_tblock_sizze_16779, 1, 1, (int64_t) 8 * segred_tblock_sizze_16953 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_16953, (int64_t) 8), (int64_t) 8), n_14507, j_m_i_14549, num_tblocks_16954, segment_sizze_nonzzero_18731, mem_18453.mem, mem_18456.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                    } else {
                        int64_t blocks_per_segment_18759 = sdiv_up64(num_tblocks_16954, smax64((int64_t) 1, j_m_i_14549));
                        int64_t q_18760 = sdiv_up64(n_14507, segred_tblock_sizze_16953 * blocks_per_segment_18759 * chunk_sizze_18730);
                        int64_t num_virtblocks_18761 = blocks_per_segment_18759 * j_m_i_14549;
                        int64_t threads_per_segment_18762 = blocks_per_segment_18759 * segred_tblock_sizze_16953;
                        
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "# SegRed-large");
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) j_m_i_14549, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) n_14507, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "num_virtblocks", (long long) num_virtblocks_18761, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "num_tblocks", (long long) num_tblocks_16954, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "tblock_size", (long long) segred_tblock_sizze_16953, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "q", (long long) q_18760, '\n');
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "blocks_per_segment", (long long) blocks_per_segment_18759, '\n');
                        if (memblock_alloc_device(ctx, &segred_tmp_mem_18763, (int64_t) 8 * num_virtblocks_18761, "segred_tmp_mem_18763")) {
                            err = 1;
                            goto cleanup;
                        }
                        {
                            err = gpu_kernel_find_cluster_ids_6890zisegred_large_16959(ctx, num_tblocks_16954, 1, 1, *ctx->tuning_params.find_cluster_ids_6890zisegred_tblock_sizze_16779, 1, 1, 8 + ((int64_t) 8 * segred_tblock_sizze_16953 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_16953, (int64_t) 8), (int64_t) 8)), n_14507, j_m_i_14549, num_tblocks_16954, blocks_per_segment_18759, q_18760, num_virtblocks_18761, threads_per_segment_18762, mem_18453.mem, mem_18456.mem, segred_tmp_mem_18763.mem, counters_mem_18765.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_unref_device(ctx, &mem_18453, "mem_18453") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &ext_mem_18468, &mem_18456, "mem_18456") != 0)
                        return 1;
                }
                if (memblock_set_device(ctx, &ext_mem_18491, &ext_mem_18468, "ext_mem_18468") != 0)
                    return 1;
            }
            if (memblock_alloc_device(ctx, &mem_18493, bytes_18420, "mem_18493")) {
                err = 1;
                goto cleanup;
            }
            if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_18493.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_18427.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_14507})) != 0)
                goto cleanup;
            if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_18493.mem, inf_14538, (int64_t []) {(int64_t) 1}, ext_mem_18491.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_14549})) != 0)
                goto cleanup;
            if (memblock_unref_device(ctx, &ext_mem_18491, "ext_mem_18491") != 0)
                return 1;
            if (memblock_set_device(ctx, &mem_param_tmp_18672, &mem_18493, "mem_18493") != 0)
                return 1;
            if (memblock_set_device(ctx, &mem_param_18427, &mem_param_tmp_18672, "mem_param_tmp_18672") != 0)
                return 1;
        }
        if (memblock_set_device(ctx, &ext_mem_18496, &mem_param_18427, "mem_param_18427") != 0)
            return 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegRed");
        
        int64_t chunk_sizze_18824 = (int64_t) 1;
        
        if (memblock_alloc_device(ctx, &segred_tmp_mem_18827, num_tblocks_16971, "segred_tmp_mem_18827")) {
            err = 1;
            goto cleanup;
        }
        
        int64_t num_threads_18829 = num_tblocks_16971 * segred_tblock_sizze_16969;
        
        {
            err = gpu_kernel_find_cluster_ids_6890zisegred_nonseg_16976(ctx, num_tblocks_16971, 1, 1, *ctx->tuning_params.find_cluster_ids_6890zisegred_tblock_sizze_16968, 1, 1, 8 + (segred_tblock_sizze_16969 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_16969, (int64_t) 8), (int64_t) 8)), n_14507, num_tblocks_16971, num_threads_18829, mem_param_18424.mem, ext_mem_18496.mem, mem_18498.mem, counters_mem_18825.mem, segred_tmp_mem_18827.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        bool read_res_19034;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_19034, mem_18498.mem, (int64_t) 0 * sizeof(bool), sizeof(bool))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        bool defunc_0_reduce_res_16166 = read_res_19034;
        bool loop_cond_14689 = !defunc_0_reduce_res_16166;
        
        if (memblock_set_device(ctx, &mem_param_tmp_18669, &ext_mem_18496, "ext_mem_18496") != 0)
            return 1;
        
        bool loop_while_tmp_18670 = loop_cond_14689;
        
        if (memblock_set_device(ctx, &mem_param_18424, &mem_param_tmp_18669, "mem_param_tmp_18669") != 0)
            return 1;
        loop_while_14530 = loop_while_tmp_18670;
    }
    if (memblock_set_device(ctx, &ext_mem_18501, &mem_param_18424, "mem_param_18424") != 0)
        return 1;
    cluster_heads_14527 = loop_while_14530;
    if (memblock_unref_device(ctx, &mem_18421, "mem_18421") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18498, "mem_18498") != 0)
        return 1;
    
    int64_t segscan_tblock_sizze_16979;
    
    segscan_tblock_sizze_16979 = *ctx->tuning_params.find_cluster_ids_6890zisegscan_tblock_sizze_16978;
    
    int64_t num_tblocks_16981;
    int64_t max_num_tblocks_18858;
    
    max_num_tblocks_18858 = *ctx->tuning_params.find_cluster_ids_6890zisegscan_num_tblocks_16980;
    num_tblocks_16981 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(n_14507, segscan_tblock_sizze_16979), max_num_tblocks_18858)));
    if (memblock_alloc_device(ctx, &mem_18504, bytes_18420, "mem_18504")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, n_14507)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_18859;
        
        shared_memory_18859 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_18860;
        
        thread_block_sizze_18860 = ctx->max_thread_block_size;
        
        int64_t registers_18861;
        
        registers_18861 = ctx->max_registers;
        
        int64_t thread_block_sizze_18862;
        
        thread_block_sizze_18862 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_18863 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_18859, thread_block_sizze_18860), (int64_t) 8), squot64(squot64(registers_18861, thread_block_sizze_18862) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
        int64_t num_virt_blocks_18864 = sdiv_up64(n_14507, segscan_tblock_sizze_16979 * chunk_sizze_18863);
        int64_t num_virt_threads_18865 = num_virt_blocks_18864 * segscan_tblock_sizze_16979;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_18863, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_18866, num_virt_blocks_18864, "status_flags_mem_18866")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_18866, num_virt_blocks_18864, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_18888, (int64_t) 8 * num_virt_blocks_18864, "aggregates_mem_18888")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_18890, (int64_t) 8 * num_virt_blocks_18864, "incprefixes_mem_18890")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_find_cluster_ids_6890zisegscan_16984(ctx, num_tblocks_16981, 1, 1, *ctx->tuning_params.find_cluster_ids_6890zisegscan_tblock_sizze_16978, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_16979), chunk_sizze_18863 * segscan_tblock_sizze_16979 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_16979), chunk_sizze_18863 * segscan_tblock_sizze_16979 * (int64_t) 8), (int64_t) 8), (int64_t) 8), n_14507, num_tblocks_16981, num_virt_blocks_18864, num_virt_threads_18865, ext_mem_18501.mem, mem_18504.mem, status_flags_mem_18866.mem, aggregates_mem_18888.mem, incprefixes_mem_18890.mem, global_dynid_mem_18892.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    
    int64_t segmap_tblock_sizze_17000;
    
    segmap_tblock_sizze_17000 = *ctx->tuning_params.find_cluster_ids_6890zisegmap_tblock_sizze_16988;
    
    int64_t segmap_usable_groups_17001 = sdiv_up64(n_14507, segmap_tblock_sizze_17000);
    
    if (memblock_alloc_device(ctx, &mem_18507, bytes_18420, "mem_18507")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_18981 = sext_i64_i32(sdiv_up64(n_14507, segmap_tblock_sizze_17000));
    
    {
        err = gpu_kernel_find_cluster_ids_6890zisegmap_17004(ctx, segmap_usable_groups_17001, 1, 1, *ctx->tuning_params.find_cluster_ids_6890zisegmap_tblock_sizze_16988, 1, 1, (int64_t) 0, n_14507, mem_18504.mem, mem_18507.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_18504, "mem_18504") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_18509, bytes_18420, "mem_18509")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_18509, n_14507, (int64_t) -1) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t segmap_tblock_sizze_17031;
    
    segmap_tblock_sizze_17031 = *ctx->tuning_params.find_cluster_ids_6890zisegmap_tblock_sizze_17014;
    
    int64_t segmap_usable_groups_17032 = sdiv_up_safe64(n_14507, segmap_tblock_sizze_17031);
    
    if (memblock_set_device(ctx, &mem_param_18512, &mem_18509, "mem_18509") != 0)
        return 1;
    for (int64_t i_15651 = 0; i_15651 < max_iter_15646; i_15651++) {
        int64_t inf_15653 = mul64(max_res_15640, i_15651);
        int64_t min_arg1_15654 = add64(max_res_15640, inf_15653);
        int64_t min_res_15655 = smin64(n_14507, min_arg1_15654);
        
        if (memblock_alloc_device(ctx, &mem_18515, bytes_18420, "mem_18515")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_19012 = sext_i64_i32(sdiv_up64(n_14507, segmap_tblock_sizze_17031));
        
        {
            err = gpu_kernel_find_cluster_ids_6890zisegmap_17035(ctx, segmap_usable_groups_17032, 1, 1, *ctx->tuning_params.find_cluster_ids_6890zisegmap_tblock_sizze_17014, 1, 1, (int64_t) 0, n_14507, inf_15653, min_res_15655, ext_mem_18501.mem, mem_18507.mem, mem_param_18512.mem, mem_18515.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if (memblock_set_device(ctx, &mem_param_tmp_19010, &mem_18515, "mem_18515") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_18512, &mem_param_tmp_19010, "mem_param_tmp_19010") != 0)
            return 1;
    }
    if (memblock_set_device(ctx, &ext_mem_18518, &mem_param_18512, "mem_param_18512") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_18501, "ext_mem_18501") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18507, "mem_18507") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18509, "mem_18509") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_18650, &ext_mem_18518, "ext_mem_18518") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_19033, &mem_out_18650, "mem_out_18650") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_param_tmp_19010, "mem_param_tmp_19010") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18515, "mem_18515") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_18512, "mem_param_18512") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_18518, "ext_mem_18518") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18509, "mem_18509") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18507, "mem_18507") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_18890, "incprefixes_mem_18890") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_18888, "aggregates_mem_18888") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_18866, "status_flags_mem_18866") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18504, "mem_18504") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_18669, "mem_param_tmp_18669") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_18827, "segred_tmp_mem_18827") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_18672, "mem_param_tmp_18672") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18493, "mem_18493") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_18763, "segred_tmp_mem_18763") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18456, "mem_18456") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18453, "mem_18453") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18449, "mem_18449") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18432, "mem_18432") != 0)
            return 1;
        if (memblock_unref_device(ctx, &color_18527, "color_18527") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18467, "mem_18467") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_18468, "ext_mem_18468") != 0)
            return 1;
        if (memblock_unref_device(ctx, &color_18526, "color_18526") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18490, "mem_18490") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18479, "mem_18479") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_18491, "ext_mem_18491") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_18427, "mem_param_18427") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_18496, "ext_mem_18496") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_18424, "mem_param_18424") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_18501, "ext_mem_18501") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18498, "mem_18498") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18421, "mem_18421") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_18650, "mem_out_18650") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_get_num_neighbours_6695(struct futhark_context *ctx, struct memblock_device *mem_out_p_19035, struct memblock_device dat_mem_18419, int64_t n_11127, int64_t dim_11128, float eps_11130, int64_t extPar_11131)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device segred_tmp_mem_18761;
    
    segred_tmp_mem_18761.references = NULL;
    
    struct memblock_device mem_18450;
    
    mem_18450.references = NULL;
    
    struct memblock_device mem_18446;
    
    mem_18446.references = NULL;
    
    struct memblock_device mem_18429;
    
    mem_18429.references = NULL;
    
    struct memblock_device color_18527;
    
    color_18527.references = NULL;
    
    struct memblock_device color_18526;
    
    color_18526.references = NULL;
    
    struct memblock_device mem_18479;
    
    mem_18479.references = NULL;
    
    struct memblock_device mem_18421;
    
    mem_18421.references = NULL;
    
    struct memblock_device mem_out_18650;
    
    mem_out_18650.references = NULL;
    
    struct memblock_device counters_mem_18763 = ctx->constants->counters_mem_18763;
    struct memblock_device counters_mem_18765 = ctx->constants->counters_mem_18765;
    struct memblock_device counters_mem_18789 = ctx->constants->counters_mem_18789;
    struct memblock_device counters_mem_18825 = ctx->constants->counters_mem_18825;
    struct memblock_device global_dynid_mem_18686 = ctx->constants->global_dynid_mem_18686;
    struct memblock_device global_dynid_mem_18892 = ctx->constants->global_dynid_mem_18892;
    int64_t zm_lhs_11132 = add64(n_11127, extPar_11131);
    int64_t zs_lhs_11134 = sub64(zm_lhs_11132, (int64_t) 1);
    bool zzero_11136 = extPar_11131 == (int64_t) 0;
    bool nonzzero_11137 = !zzero_11136;
    bool nonzzero_cert_11138;
    
    if (!nonzzero_11137) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ft_libs/ftDBSCAN.fut:34:48-55\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t num_iter_11139 = sdiv64(zs_lhs_11134, extPar_11131);
    int64_t bytes_18420 = (int64_t) 8 * n_11127;
    bool bounds_invalid_upwards_15377 = slt64(num_iter_11139, (int64_t) 0);
    bool valid_15378 = !bounds_invalid_upwards_15377;
    bool range_valid_c_15379;
    
    if (!valid_15378) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) (int64_t) 0, "..", (long long) (int64_t) 1, "..<", (long long) num_iter_11139, " is invalid.", "-> #0  /prelude/array.fut:94:3-11\n   #1  ft_libs/ftDBSCAN.fut:35:60-73\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_18421, bytes_18420, "mem_18421")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_18421, n_11127, (int64_t) 0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t max_tblock_sizze_17858;
    
    max_tblock_sizze_17858 = ctx->max_thread_block_size;
    
    bool fits_17859 = sle64(n_11127, max_tblock_sizze_17858);
    bool suff_intra_par_17857;
    
    suff_intra_par_17857 = *ctx->tuning_params.get_num_neighbours_6695zisuff_intra_par_1 <= n_11127;
    if (ctx->logging)
        fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "get_num_neighbours_6695.suff_intra_par_1", (long) n_11127, suff_intra_par_17857 ? "true" : "false");
    
    bool intra_suff_and_fits_17860 = suff_intra_par_17857 && fits_17859;
    int64_t y_18038 = n_11127 * dim_11128;
    int64_t segmap_tblock_sizze_18040;
    
    segmap_tblock_sizze_18040 = *ctx->tuning_params.get_num_neighbours_6695zisegmap_tblock_sizze_17966;
    
    int64_t segmap_tblock_sizze_18054;
    
    segmap_tblock_sizze_18054 = *ctx->tuning_params.get_num_neighbours_6695zisegmap_tblock_sizze_17934;
    
    int64_t segred_tblock_sizze_18072;
    
    segred_tblock_sizze_18072 = *ctx->tuning_params.get_num_neighbours_6695zisegred_tblock_sizze_17904;
    
    int64_t segmap_tblock_sizze_18085;
    
    segmap_tblock_sizze_18085 = *ctx->tuning_params.get_num_neighbours_6695zisegmap_tblock_sizze_17893;
    
    int64_t segmap_tblock_sizze_17831;
    
    segmap_tblock_sizze_17831 = *ctx->tuning_params.get_num_neighbours_6695zisegmap_tblock_sizze_17805;
    
    int64_t binop_y_18434 = n_11127 - (int64_t) 1;
    int64_t binop_y_18436 = smax64((int64_t) 0, binop_y_18434);
    int64_t binop_y_18438 = dim_11128 - (int64_t) 1;
    int64_t binop_x_18439 = smax64((int64_t) 0, binop_y_18438);
    int64_t bytes_18458 = (int64_t) 4 * dim_11128;
    int64_t binop_y_18474 = n_11127 * binop_x_18439;
    int64_t binop_y_18475 = smax64((int64_t) 0, binop_y_18474);
    int64_t binop_y_18476 = binop_y_18436 + binop_y_18475;
    int64_t binop_y_18477 = (int64_t) 1 + binop_y_18476;
    int64_t bytes_18478 = (int64_t) 4 * binop_y_18477;
    
    for (int64_t i_11145 = 0; i_11145 < num_iter_11139; i_11145++) {
        int64_t inf_11148 = mul64(extPar_11131, i_11145);
        int64_t min_arg1_11150 = add64(extPar_11131, inf_11148);
        int64_t min_res_15390 = smin64(n_11127, min_arg1_11150);
        int64_t dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154 = sub64(min_res_15390, inf_11148);
        bool empty_slice_11166 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154 == (int64_t) 0;
        int64_t m_11167 = sub64(dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154, (int64_t) 1);
        int64_t i_p_m_t_s_11169 = add64(inf_11148, m_11167);
        bool zzero_leq_i_p_m_t_s_11170 = sle64((int64_t) 0, i_p_m_t_s_11169);
        bool i_p_m_t_s_leq_w_11172 = slt64(i_p_m_t_s_11169, n_11127);
        bool zzero_lte_i_11173 = sle64((int64_t) 0, inf_11148);
        bool i_lte_j_11174 = sle64(inf_11148, min_res_15390);
        bool y_11175 = i_p_m_t_s_leq_w_11172 && zzero_lte_i_11173;
        bool y_11176 = zzero_leq_i_p_m_t_s_11170 && y_11175;
        bool forwards_ok_11177 = i_lte_j_11174 && y_11176;
        bool ok_or_empty_11184 = empty_slice_11166 || forwards_ok_11177;
        bool index_certs_11186;
        
        if (!ok_or_empty_11184) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) inf_11148, ":", (long long) min_res_15390, "] out of bounds for array of shape [", (long long) n_11127, "].", "-> #0  ft_libs/ftDBSCAN.fut:38:39-51\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        bool suff_outer_par_17801;
        
        suff_outer_par_17801 = *ctx->tuning_params.get_num_neighbours_6695zisuff_outer_par_0 <= dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154;
        if (ctx->logging)
            fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "get_num_neighbours_6695.suff_outer_par_0", (long) dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154, suff_outer_par_17801 ? "true" : "false");
        
        int64_t nest_sizze_18039 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154 * y_18038;
        int64_t nest_sizze_18053 = n_11127 * dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154;
        int64_t num_tblocks_18073;
        int64_t max_num_tblocks_18672;
        
        max_num_tblocks_18672 = *ctx->tuning_params.get_num_neighbours_6695zisegred_num_tblocks_17906;
        num_tblocks_18073 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nest_sizze_18053, segred_tblock_sizze_18072), max_num_tblocks_18672)));
        
        int64_t binop_x_18426 = (int64_t) 4 * dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154;
        int64_t binop_x_18427 = n_11127 * binop_x_18426;
        int64_t bytes_18428 = dim_11128 * binop_x_18427;
        int64_t binop_x_18431 = smax64((int64_t) 0, m_11167);
        int64_t binop_y_18432 = n_11127 * binop_x_18431;
        int64_t binop_x_18433 = smax64((int64_t) 0, binop_y_18432);
        int64_t binop_x_18437 = binop_x_18433 + binop_y_18436;
        int64_t binop_y_18441 = nest_sizze_18053 * binop_x_18439;
        int64_t binop_y_18442 = smax64((int64_t) 0, binop_y_18441);
        int64_t binop_y_18443 = binop_x_18437 + binop_y_18442;
        int64_t binop_y_18444 = (int64_t) 1 + binop_y_18443;
        int64_t bytes_18445 = (int64_t) 4 * binop_y_18444;
        int64_t binop_x_18448 = (int64_t) 8 * dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154;
        int64_t bytes_18449 = n_11127 * binop_x_18448;
        int64_t binop_x_18617 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154 * bytes_18458;
        int64_t total_sizze_18618 = n_11127 * binop_x_18617;
        int64_t ctx_18624 = n_11127 * dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154;
        int64_t segmap_usable_groups_17832 = sdiv_up_safe64(dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154, segmap_tblock_sizze_17831);
        int64_t num_threads_18608 = segmap_tblock_sizze_17831 * segmap_usable_groups_17832;
        int64_t total_sizze_18609 = bytes_18458 * num_threads_18608;
        int64_t shared_memory_capacity_18830;
        
        shared_memory_capacity_18830 = ctx->max_shared_memory;
        if (suff_outer_par_17801 && sle64((int64_t) 0, shared_memory_capacity_18830)) {
            if (memblock_alloc_device(ctx, &mem_18479, bytes_18478, "mem_18479")) {
                err = 1;
                goto cleanup;
            }
            if ((err = lmad_copy_gpu2gpu_4b(ctx, 2, mem_18479.mem, (int64_t) 0, (int64_t []) {(int64_t) 1, n_11127}, dat_mem_18419.mem, (int64_t) 0, (int64_t []) {dim_11128, (int64_t) 1}, (int64_t []) {n_11127, dim_11128})) != 0)
                goto cleanup;
            if (memblock_alloc_device(ctx, &color_18526, total_sizze_18609, "color_18526")) {
                err = 1;
                goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegMap");
            
            int32_t virt_num_tblocks_18673 = sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154, segmap_tblock_sizze_17831));
            
            {
                err = gpu_kernel_get_num_neighbours_6695zisegmap_17835(ctx, segmap_usable_groups_17832, 1, 1, *ctx->tuning_params.get_num_neighbours_6695zisegmap_tblock_sizze_17805, 1, 1, (int64_t) 0, n_11127, dim_11128, eps_11130, inf_11148, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154, num_threads_18608, dat_mem_18419.mem, mem_18421.mem, mem_18479.mem, color_18526.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
            if (memblock_unref_device(ctx, &mem_18479, "mem_18479") != 0)
                return 1;
            if (memblock_unref_device(ctx, &color_18526, "color_18526") != 0)
                return 1;
        } else {
            int64_t shared_memory_capacity_18829;
            
            shared_memory_capacity_18829 = ctx->max_shared_memory;
            if (intra_suff_and_fits_17860 && sle64(sdiv_up64((int64_t) 8 * n_11127, (int64_t) 8) * (int64_t) 8, shared_memory_capacity_18829)) {
                if (memblock_alloc_device(ctx, &color_18527, total_sizze_18618, "color_18527")) {
                    err = 1;
                    goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t num_chunks_18685 = sext_i64_i32(sdiv_up64(n_11127, n_11127));
                int32_t virt_num_tblocks_18686 = sext_i64_i32(dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154);
                
                {
                    err = gpu_kernel_get_num_neighbours_6695zisegmap_intrablock_17863(ctx, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154, 1, 1, n_11127, 1, 1, (int64_t) 8 * n_11127 + srem64((int64_t) 8 - srem64((int64_t) 8 * n_11127, (int64_t) 8), (int64_t) 8), n_11127, dim_11128, eps_11130, inf_11148, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154, ctx_18624, dat_mem_18419.mem, mem_18421.mem, color_18527.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                if (memblock_unref_device(ctx, &color_18527, "color_18527") != 0)
                    return 1;
            } else {
                int64_t segmap_usable_groups_18041 = sdiv_up64(nest_sizze_18039, segmap_tblock_sizze_18040);
                
                if (memblock_alloc_device(ctx, &mem_18429, bytes_18428, "mem_18429")) {
                    err = 1;
                    goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_18703 = sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154 * n_11127 * dim_11128, segmap_tblock_sizze_18040));
                
                {
                    err = gpu_kernel_get_num_neighbours_6695zisegmap_18046(ctx, segmap_usable_groups_18041, 1, 1, *ctx->tuning_params.get_num_neighbours_6695zisegmap_tblock_sizze_17966, 1, 1, (int64_t) 0, n_11127, dim_11128, inf_11148, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154, dat_mem_18419.mem, mem_18429.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                
                int64_t segmap_usable_groups_18055 = sdiv_up64(nest_sizze_18053, segmap_tblock_sizze_18054);
                
                if (memblock_alloc_device(ctx, &mem_18446, bytes_18445, "mem_18446")) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_4b(ctx, 3, mem_18446.mem, (int64_t) 0, (int64_t []) {n_11127, (int64_t) 1, n_11127 * dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154}, mem_18429.mem, (int64_t) 0, (int64_t []) {dim_11128 * n_11127, dim_11128, (int64_t) 1}, (int64_t []) {dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154, n_11127, dim_11128})) != 0)
                    goto cleanup;
                if (memblock_unref_device(ctx, &mem_18429, "mem_18429") != 0)
                    return 1;
                if (memblock_alloc_device(ctx, &mem_18450, bytes_18449, "mem_18450")) {
                    err = 1;
                    goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_18716 = sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154 * n_11127, segmap_tblock_sizze_18054));
                
                {
                    err = gpu_kernel_get_num_neighbours_6695zisegmap_18059(ctx, segmap_usable_groups_18055, 1, 1, *ctx->tuning_params.get_num_neighbours_6695zisegmap_tblock_sizze_17934, 1, 1, (int64_t) 0, n_11127, dim_11128, eps_11130, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154, mem_18446.mem, mem_18450.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                if (memblock_unref_device(ctx, &mem_18446, "mem_18446") != 0)
                    return 1;
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegRed");
                
                int64_t chunk_sizze_18728 = (int64_t) 1;
                
                if (slt64(n_11127 * (int64_t) 2, segred_tblock_sizze_18072 * chunk_sizze_18728)) {
                    int64_t segment_sizze_nonzzero_18729 = smax64((int64_t) 1, n_11127);
                    int64_t num_threads_18730 = segred_tblock_sizze_18072 * segred_tblock_sizze_18072;
                    
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "# SegRed-small");
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) n_11127, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "segments_per_block", (long long) squot64(segred_tblock_sizze_18072, segment_sizze_nonzzero_18729), '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "required_blocks", (long long) sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154, squot64(segred_tblock_sizze_18072, segment_sizze_nonzzero_18729))), '\n');
                    {
                        err = gpu_kernel_get_num_neighbours_6695zisegred_small_18078(ctx, num_tblocks_18073, 1, 1, *ctx->tuning_params.get_num_neighbours_6695zisegred_tblock_sizze_17904, 1, 1, (int64_t) 8 * segred_tblock_sizze_18072 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_18072, (int64_t) 8), (int64_t) 8), n_11127, inf_11148, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154, num_tblocks_18073, segment_sizze_nonzzero_18729, mem_18421.mem, mem_18450.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                } else {
                    int64_t blocks_per_segment_18757 = sdiv_up64(num_tblocks_18073, smax64((int64_t) 1, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154));
                    int64_t q_18758 = sdiv_up64(n_11127, segred_tblock_sizze_18072 * blocks_per_segment_18757 * chunk_sizze_18728);
                    int64_t num_virtblocks_18759 = blocks_per_segment_18757 * dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154;
                    int64_t threads_per_segment_18760 = blocks_per_segment_18757 * segred_tblock_sizze_18072;
                    
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "# SegRed-large");
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) n_11127, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_virtblocks", (long long) num_virtblocks_18759, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_tblocks", (long long) num_tblocks_18073, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "tblock_size", (long long) segred_tblock_sizze_18072, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "q", (long long) q_18758, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "blocks_per_segment", (long long) blocks_per_segment_18757, '\n');
                    if (memblock_alloc_device(ctx, &segred_tmp_mem_18761, (int64_t) 8 * num_virtblocks_18759, "segred_tmp_mem_18761")) {
                        err = 1;
                        goto cleanup;
                    }
                    {
                        err = gpu_kernel_get_num_neighbours_6695zisegred_large_18078(ctx, num_tblocks_18073, 1, 1, *ctx->tuning_params.get_num_neighbours_6695zisegred_tblock_sizze_17904, 1, 1, 8 + ((int64_t) 8 * segred_tblock_sizze_18072 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_18072, (int64_t) 8), (int64_t) 8)), n_11127, inf_11148, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154, num_tblocks_18073, blocks_per_segment_18757, q_18758, num_virtblocks_18759, threads_per_segment_18760, mem_18421.mem, mem_18450.mem, segred_tmp_mem_18761.mem, counters_mem_18763.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                if (memblock_unref_device(ctx, &mem_18450, "mem_18450") != 0)
                    return 1;
                
                int64_t segmap_usable_groups_18086 = sdiv_up64(dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154, segmap_tblock_sizze_18085);
                
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_18820 = sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154, segmap_tblock_sizze_18085));
                
                {
                    err = gpu_kernel_get_num_neighbours_6695zisegmap_18089(ctx, segmap_usable_groups_18086, 1, 1, *ctx->tuning_params.get_num_neighbours_6695zisegmap_tblock_sizze_17893, 1, 1, (int64_t) 0, inf_11148, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_11154, mem_18421.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
            }
        }
    }
    if (memblock_set_device(ctx, &mem_out_18650, &mem_18421, "mem_18421") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_19035, &mem_out_18650, "mem_out_18650") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &segred_tmp_mem_18761, "segred_tmp_mem_18761") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18450, "mem_18450") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18446, "mem_18446") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18429, "mem_18429") != 0)
            return 1;
        if (memblock_unref_device(ctx, &color_18527, "color_18527") != 0)
            return 1;
        if (memblock_unref_device(ctx, &color_18526, "color_18526") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18479, "mem_18479") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18421, "mem_18421") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_18650, "mem_out_18650") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_get_num_neighbours_6842(struct futhark_context *ctx, struct memblock_device *mem_out_p_19036, struct memblock_device dat_mem_18419, int64_t n_13491, int64_t dim_13492, double eps_13494, int64_t extPar_13495)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device segred_tmp_mem_18761;
    
    segred_tmp_mem_18761.references = NULL;
    
    struct memblock_device mem_18450;
    
    mem_18450.references = NULL;
    
    struct memblock_device mem_18446;
    
    mem_18446.references = NULL;
    
    struct memblock_device mem_18429;
    
    mem_18429.references = NULL;
    
    struct memblock_device color_18527;
    
    color_18527.references = NULL;
    
    struct memblock_device color_18526;
    
    color_18526.references = NULL;
    
    struct memblock_device mem_18479;
    
    mem_18479.references = NULL;
    
    struct memblock_device mem_18421;
    
    mem_18421.references = NULL;
    
    struct memblock_device mem_out_18650;
    
    mem_out_18650.references = NULL;
    
    struct memblock_device counters_mem_18763 = ctx->constants->counters_mem_18763;
    struct memblock_device counters_mem_18765 = ctx->constants->counters_mem_18765;
    struct memblock_device counters_mem_18789 = ctx->constants->counters_mem_18789;
    struct memblock_device counters_mem_18825 = ctx->constants->counters_mem_18825;
    struct memblock_device global_dynid_mem_18686 = ctx->constants->global_dynid_mem_18686;
    struct memblock_device global_dynid_mem_18892 = ctx->constants->global_dynid_mem_18892;
    int64_t zm_lhs_13496 = add64(n_13491, extPar_13495);
    int64_t zs_lhs_13498 = sub64(zm_lhs_13496, (int64_t) 1);
    bool zzero_13500 = extPar_13495 == (int64_t) 0;
    bool nonzzero_13501 = !zzero_13500;
    bool nonzzero_cert_13502;
    
    if (!nonzzero_13501) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ft_libs/ftDBSCAN.fut:34:48-55\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t num_iter_13503 = sdiv64(zs_lhs_13498, extPar_13495);
    int64_t bytes_18420 = (int64_t) 8 * n_13491;
    bool bounds_invalid_upwards_15377 = slt64(num_iter_13503, (int64_t) 0);
    bool valid_15378 = !bounds_invalid_upwards_15377;
    bool range_valid_c_15379;
    
    if (!valid_15378) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) (int64_t) 0, "..", (long long) (int64_t) 1, "..<", (long long) num_iter_13503, " is invalid.", "-> #0  /prelude/array.fut:94:3-11\n   #1  ft_libs/ftDBSCAN.fut:35:60-73\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_18421, bytes_18420, "mem_18421")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_18421, n_13491, (int64_t) 0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t max_tblock_sizze_18159;
    
    max_tblock_sizze_18159 = ctx->max_thread_block_size;
    
    bool fits_18160 = sle64(n_13491, max_tblock_sizze_18159);
    bool suff_intra_par_18158;
    
    suff_intra_par_18158 = *ctx->tuning_params.get_num_neighbours_6842zisuff_intra_par_1 <= n_13491;
    if (ctx->logging)
        fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "get_num_neighbours_6842.suff_intra_par_1", (long) n_13491, suff_intra_par_18158 ? "true" : "false");
    
    bool intra_suff_and_fits_18161 = suff_intra_par_18158 && fits_18160;
    int64_t y_18339 = n_13491 * dim_13492;
    int64_t segmap_tblock_sizze_18341;
    
    segmap_tblock_sizze_18341 = *ctx->tuning_params.get_num_neighbours_6842zisegmap_tblock_sizze_18267;
    
    int64_t segmap_tblock_sizze_18355;
    
    segmap_tblock_sizze_18355 = *ctx->tuning_params.get_num_neighbours_6842zisegmap_tblock_sizze_18235;
    
    int64_t segred_tblock_sizze_18373;
    
    segred_tblock_sizze_18373 = *ctx->tuning_params.get_num_neighbours_6842zisegred_tblock_sizze_18205;
    
    int64_t segmap_tblock_sizze_18386;
    
    segmap_tblock_sizze_18386 = *ctx->tuning_params.get_num_neighbours_6842zisegmap_tblock_sizze_18194;
    
    int64_t segmap_tblock_sizze_18132;
    
    segmap_tblock_sizze_18132 = *ctx->tuning_params.get_num_neighbours_6842zisegmap_tblock_sizze_18106;
    
    int64_t binop_y_18434 = n_13491 - (int64_t) 1;
    int64_t binop_y_18436 = smax64((int64_t) 0, binop_y_18434);
    int64_t binop_y_18438 = dim_13492 - (int64_t) 1;
    int64_t binop_x_18439 = smax64((int64_t) 0, binop_y_18438);
    int64_t bytes_18458 = (int64_t) 8 * dim_13492;
    int64_t binop_y_18474 = n_13491 * binop_x_18439;
    int64_t binop_y_18475 = smax64((int64_t) 0, binop_y_18474);
    int64_t binop_y_18476 = binop_y_18436 + binop_y_18475;
    int64_t binop_y_18477 = (int64_t) 1 + binop_y_18476;
    int64_t bytes_18478 = (int64_t) 8 * binop_y_18477;
    
    for (int64_t i_13509 = 0; i_13509 < num_iter_13503; i_13509++) {
        int64_t inf_13512 = mul64(extPar_13495, i_13509);
        int64_t min_arg1_13514 = add64(extPar_13495, inf_13512);
        int64_t min_res_15390 = smin64(n_13491, min_arg1_13514);
        int64_t dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518 = sub64(min_res_15390, inf_13512);
        bool empty_slice_13530 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518 == (int64_t) 0;
        int64_t m_13531 = sub64(dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518, (int64_t) 1);
        int64_t i_p_m_t_s_13533 = add64(inf_13512, m_13531);
        bool zzero_leq_i_p_m_t_s_13534 = sle64((int64_t) 0, i_p_m_t_s_13533);
        bool i_p_m_t_s_leq_w_13536 = slt64(i_p_m_t_s_13533, n_13491);
        bool zzero_lte_i_13537 = sle64((int64_t) 0, inf_13512);
        bool i_lte_j_13538 = sle64(inf_13512, min_res_15390);
        bool y_13539 = i_p_m_t_s_leq_w_13536 && zzero_lte_i_13537;
        bool y_13540 = zzero_leq_i_p_m_t_s_13534 && y_13539;
        bool forwards_ok_13541 = i_lte_j_13538 && y_13540;
        bool ok_or_empty_13548 = empty_slice_13530 || forwards_ok_13541;
        bool index_certs_13550;
        
        if (!ok_or_empty_13548) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) inf_13512, ":", (long long) min_res_15390, "] out of bounds for array of shape [", (long long) n_13491, "].", "-> #0  ft_libs/ftDBSCAN.fut:38:39-51\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        bool suff_outer_par_18102;
        
        suff_outer_par_18102 = *ctx->tuning_params.get_num_neighbours_6842zisuff_outer_par_0 <= dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518;
        if (ctx->logging)
            fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "get_num_neighbours_6842.suff_outer_par_0", (long) dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518, suff_outer_par_18102 ? "true" : "false");
        
        int64_t nest_sizze_18340 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518 * y_18339;
        int64_t nest_sizze_18354 = n_13491 * dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518;
        int64_t num_tblocks_18374;
        int64_t max_num_tblocks_18672;
        
        max_num_tblocks_18672 = *ctx->tuning_params.get_num_neighbours_6842zisegred_num_tblocks_18207;
        num_tblocks_18374 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nest_sizze_18354, segred_tblock_sizze_18373), max_num_tblocks_18672)));
        
        int64_t binop_x_18426 = (int64_t) 8 * dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518;
        int64_t binop_x_18427 = n_13491 * binop_x_18426;
        int64_t bytes_18428 = dim_13492 * binop_x_18427;
        int64_t binop_x_18431 = smax64((int64_t) 0, m_13531);
        int64_t binop_y_18432 = n_13491 * binop_x_18431;
        int64_t binop_x_18433 = smax64((int64_t) 0, binop_y_18432);
        int64_t binop_x_18437 = binop_x_18433 + binop_y_18436;
        int64_t binop_y_18441 = nest_sizze_18354 * binop_x_18439;
        int64_t binop_y_18442 = smax64((int64_t) 0, binop_y_18441);
        int64_t binop_y_18443 = binop_x_18437 + binop_y_18442;
        int64_t binop_y_18444 = (int64_t) 1 + binop_y_18443;
        int64_t bytes_18445 = (int64_t) 8 * binop_y_18444;
        int64_t binop_x_18637 = dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518 * bytes_18458;
        int64_t total_sizze_18638 = n_13491 * binop_x_18637;
        int64_t ctx_18644 = n_13491 * dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518;
        int64_t segmap_usable_groups_18133 = sdiv_up_safe64(dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518, segmap_tblock_sizze_18132);
        int64_t num_threads_18628 = segmap_tblock_sizze_18132 * segmap_usable_groups_18133;
        int64_t total_sizze_18629 = bytes_18458 * num_threads_18628;
        int64_t shared_memory_capacity_18830;
        
        shared_memory_capacity_18830 = ctx->max_shared_memory;
        if (suff_outer_par_18102 && sle64((int64_t) 0, shared_memory_capacity_18830)) {
            if (memblock_alloc_device(ctx, &mem_18479, bytes_18478, "mem_18479")) {
                err = 1;
                goto cleanup;
            }
            if ((err = lmad_copy_gpu2gpu_8b(ctx, 2, mem_18479.mem, (int64_t) 0, (int64_t []) {(int64_t) 1, n_13491}, dat_mem_18419.mem, (int64_t) 0, (int64_t []) {dim_13492, (int64_t) 1}, (int64_t []) {n_13491, dim_13492})) != 0)
                goto cleanup;
            if (memblock_alloc_device(ctx, &color_18526, total_sizze_18629, "color_18526")) {
                err = 1;
                goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegMap");
            
            int32_t virt_num_tblocks_18673 = sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518, segmap_tblock_sizze_18132));
            
            {
                err = gpu_kernel_get_num_neighbours_6842zisegmap_18136(ctx, segmap_usable_groups_18133, 1, 1, *ctx->tuning_params.get_num_neighbours_6842zisegmap_tblock_sizze_18106, 1, 1, (int64_t) 0, n_13491, dim_13492, eps_13494, inf_13512, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518, num_threads_18628, dat_mem_18419.mem, mem_18421.mem, mem_18479.mem, color_18526.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
            if (memblock_unref_device(ctx, &mem_18479, "mem_18479") != 0)
                return 1;
            if (memblock_unref_device(ctx, &color_18526, "color_18526") != 0)
                return 1;
        } else {
            int64_t shared_memory_capacity_18829;
            
            shared_memory_capacity_18829 = ctx->max_shared_memory;
            if (intra_suff_and_fits_18161 && sle64(sdiv_up64((int64_t) 8 * n_13491, (int64_t) 8) * (int64_t) 8, shared_memory_capacity_18829)) {
                if (memblock_alloc_device(ctx, &color_18527, total_sizze_18638, "color_18527")) {
                    err = 1;
                    goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t num_chunks_18685 = sext_i64_i32(sdiv_up64(n_13491, n_13491));
                int32_t virt_num_tblocks_18686 = sext_i64_i32(dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518);
                
                {
                    err = gpu_kernel_get_num_neighbours_6842zisegmap_intrablock_18164(ctx, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518, 1, 1, n_13491, 1, 1, (int64_t) 8 * n_13491 + srem64((int64_t) 8 - srem64((int64_t) 8 * n_13491, (int64_t) 8), (int64_t) 8), n_13491, dim_13492, eps_13494, inf_13512, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518, ctx_18644, dat_mem_18419.mem, mem_18421.mem, color_18527.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                if (memblock_unref_device(ctx, &color_18527, "color_18527") != 0)
                    return 1;
            } else {
                int64_t segmap_usable_groups_18342 = sdiv_up64(nest_sizze_18340, segmap_tblock_sizze_18341);
                
                if (memblock_alloc_device(ctx, &mem_18429, bytes_18428, "mem_18429")) {
                    err = 1;
                    goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_18703 = sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518 * n_13491 * dim_13492, segmap_tblock_sizze_18341));
                
                {
                    err = gpu_kernel_get_num_neighbours_6842zisegmap_18347(ctx, segmap_usable_groups_18342, 1, 1, *ctx->tuning_params.get_num_neighbours_6842zisegmap_tblock_sizze_18267, 1, 1, (int64_t) 0, n_13491, dim_13492, inf_13512, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518, dat_mem_18419.mem, mem_18429.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                
                int64_t segmap_usable_groups_18356 = sdiv_up64(nest_sizze_18354, segmap_tblock_sizze_18355);
                
                if (memblock_alloc_device(ctx, &mem_18446, bytes_18445, "mem_18446")) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_8b(ctx, 3, mem_18446.mem, (int64_t) 0, (int64_t []) {n_13491, (int64_t) 1, n_13491 * dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518}, mem_18429.mem, (int64_t) 0, (int64_t []) {dim_13492 * n_13491, dim_13492, (int64_t) 1}, (int64_t []) {dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518, n_13491, dim_13492})) != 0)
                    goto cleanup;
                if (memblock_unref_device(ctx, &mem_18429, "mem_18429") != 0)
                    return 1;
                if (memblock_alloc_device(ctx, &mem_18450, binop_x_18427, "mem_18450")) {
                    err = 1;
                    goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_18716 = sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518 * n_13491, segmap_tblock_sizze_18355));
                
                {
                    err = gpu_kernel_get_num_neighbours_6842zisegmap_18360(ctx, segmap_usable_groups_18356, 1, 1, *ctx->tuning_params.get_num_neighbours_6842zisegmap_tblock_sizze_18235, 1, 1, (int64_t) 0, n_13491, dim_13492, eps_13494, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518, mem_18446.mem, mem_18450.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                if (memblock_unref_device(ctx, &mem_18446, "mem_18446") != 0)
                    return 1;
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegRed");
                
                int64_t chunk_sizze_18728 = (int64_t) 1;
                
                if (slt64(n_13491 * (int64_t) 2, segred_tblock_sizze_18373 * chunk_sizze_18728)) {
                    int64_t segment_sizze_nonzzero_18729 = smax64((int64_t) 1, n_13491);
                    int64_t num_threads_18730 = segred_tblock_sizze_18373 * segred_tblock_sizze_18373;
                    
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "# SegRed-small");
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) n_13491, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "segments_per_block", (long long) squot64(segred_tblock_sizze_18373, segment_sizze_nonzzero_18729), '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "required_blocks", (long long) sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518, squot64(segred_tblock_sizze_18373, segment_sizze_nonzzero_18729))), '\n');
                    {
                        err = gpu_kernel_get_num_neighbours_6842zisegred_small_18379(ctx, num_tblocks_18374, 1, 1, *ctx->tuning_params.get_num_neighbours_6842zisegred_tblock_sizze_18205, 1, 1, (int64_t) 8 * segred_tblock_sizze_18373 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_18373, (int64_t) 8), (int64_t) 8), n_13491, inf_13512, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518, num_tblocks_18374, segment_sizze_nonzzero_18729, mem_18421.mem, mem_18450.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                } else {
                    int64_t blocks_per_segment_18757 = sdiv_up64(num_tblocks_18374, smax64((int64_t) 1, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518));
                    int64_t q_18758 = sdiv_up64(n_13491, segred_tblock_sizze_18373 * blocks_per_segment_18757 * chunk_sizze_18728);
                    int64_t num_virtblocks_18759 = blocks_per_segment_18757 * dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518;
                    int64_t threads_per_segment_18760 = blocks_per_segment_18757 * segred_tblock_sizze_18373;
                    
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "# SegRed-large");
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) n_13491, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_virtblocks", (long long) num_virtblocks_18759, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_tblocks", (long long) num_tblocks_18374, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "tblock_size", (long long) segred_tblock_sizze_18373, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "q", (long long) q_18758, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "blocks_per_segment", (long long) blocks_per_segment_18757, '\n');
                    if (memblock_alloc_device(ctx, &segred_tmp_mem_18761, (int64_t) 8 * num_virtblocks_18759, "segred_tmp_mem_18761")) {
                        err = 1;
                        goto cleanup;
                    }
                    {
                        err = gpu_kernel_get_num_neighbours_6842zisegred_large_18379(ctx, num_tblocks_18374, 1, 1, *ctx->tuning_params.get_num_neighbours_6842zisegred_tblock_sizze_18205, 1, 1, 8 + ((int64_t) 8 * segred_tblock_sizze_18373 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_18373, (int64_t) 8), (int64_t) 8)), n_13491, inf_13512, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518, num_tblocks_18374, blocks_per_segment_18757, q_18758, num_virtblocks_18759, threads_per_segment_18760, mem_18421.mem, mem_18450.mem, segred_tmp_mem_18761.mem, counters_mem_18763.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                if (memblock_unref_device(ctx, &mem_18450, "mem_18450") != 0)
                    return 1;
                
                int64_t segmap_usable_groups_18387 = sdiv_up64(dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518, segmap_tblock_sizze_18386);
                
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_18820 = sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518, segmap_tblock_sizze_18386));
                
                {
                    err = gpu_kernel_get_num_neighbours_6842zisegmap_18390(ctx, segmap_usable_groups_18387, 1, 1, *ctx->tuning_params.get_num_neighbours_6842zisegmap_tblock_sizze_18194, 1, 1, (int64_t) 0, inf_13512, dzlz7bUZLzmZRz20Usupz20Uinfz7dUzg_13518, mem_18421.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
            }
        }
    }
    if (memblock_set_device(ctx, &mem_out_18650, &mem_18421, "mem_18421") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_19036, &mem_out_18650, "mem_out_18650") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &segred_tmp_mem_18761, "segred_tmp_mem_18761") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18450, "mem_18450") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18446, "mem_18446") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18429, "mem_18429") != 0)
            return 1;
        if (memblock_unref_device(ctx, &color_18527, "color_18527") != 0)
            return 1;
        if (memblock_unref_device(ctx, &color_18526, "color_18526") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18479, "mem_18479") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18421, "mem_18421") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_18650, "mem_out_18650") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_isolate_core_points_6732(struct futhark_context *ctx, struct memblock_device *mem_out_p_19037, int64_t *out_prim_out_19038, struct memblock_device dat_mem_18419, struct memblock_device isCore_mem_18420, int64_t n_11606, int64_t dim_11607)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_18431;
    
    mem_18431.references = NULL;
    
    struct memblock_device mem_18428;
    
    mem_18428.references = NULL;
    
    struct memblock_device incprefixes_mem_18684;
    
    incprefixes_mem_18684.references = NULL;
    
    struct memblock_device aggregates_mem_18682;
    
    aggregates_mem_18682.references = NULL;
    
    struct memblock_device status_flags_mem_18660;
    
    status_flags_mem_18660.references = NULL;
    
    struct memblock_device mem_18425;
    
    mem_18425.references = NULL;
    
    struct memblock_device mem_18423;
    
    mem_18423.references = NULL;
    
    struct memblock_device mem_out_18650;
    
    mem_out_18650.references = NULL;
    
    struct memblock_device counters_mem_18763 = ctx->constants->counters_mem_18763;
    struct memblock_device counters_mem_18765 = ctx->constants->counters_mem_18765;
    struct memblock_device counters_mem_18789 = ctx->constants->counters_mem_18789;
    struct memblock_device counters_mem_18825 = ctx->constants->counters_mem_18825;
    struct memblock_device global_dynid_mem_18686 = ctx->constants->global_dynid_mem_18686;
    struct memblock_device global_dynid_mem_18892 = ctx->constants->global_dynid_mem_18892;
    int64_t prim_out_18651;
    int64_t segscan_tblock_sizze_16177;
    
    segscan_tblock_sizze_16177 = *ctx->tuning_params.isolate_core_points_6732zisegscan_tblock_sizze_16176;
    
    int64_t num_tblocks_16179;
    int64_t max_num_tblocks_18652;
    
    max_num_tblocks_18652 = *ctx->tuning_params.isolate_core_points_6732zisegscan_num_tblocks_16178;
    num_tblocks_16179 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(n_11606, segscan_tblock_sizze_16177), max_num_tblocks_18652)));
    
    int64_t bytes_18422 = (int64_t) 8 * n_11606;
    
    if (memblock_alloc_device(ctx, &mem_18423, bytes_18422, "mem_18423")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_18425, bytes_18422, "mem_18425")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, n_11606)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_18653;
        
        shared_memory_18653 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_18654;
        
        thread_block_sizze_18654 = ctx->max_thread_block_size;
        
        int64_t registers_18655;
        
        registers_18655 = ctx->max_registers;
        
        int64_t thread_block_sizze_18656;
        
        thread_block_sizze_18656 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_18657 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_18653, thread_block_sizze_18654), (int64_t) 8), squot64(squot64(registers_18655, thread_block_sizze_18656) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
        int64_t num_virt_blocks_18658 = sdiv_up64(n_11606, segscan_tblock_sizze_16177 * chunk_sizze_18657);
        int64_t num_virt_threads_18659 = num_virt_blocks_18658 * segscan_tblock_sizze_16177;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_18657, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_18660, num_virt_blocks_18658, "status_flags_mem_18660")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_18660, num_virt_blocks_18658, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_18682, (int64_t) 8 * num_virt_blocks_18658, "aggregates_mem_18682")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_18684, (int64_t) 8 * num_virt_blocks_18658, "incprefixes_mem_18684")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_isolate_core_points_6732zisegscan_16182(ctx, num_tblocks_16179, 1, 1, *ctx->tuning_params.isolate_core_points_6732zisegscan_tblock_sizze_16176, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_16177), chunk_sizze_18657 * segscan_tblock_sizze_16177 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_16177), chunk_sizze_18657 * segscan_tblock_sizze_16177 * (int64_t) 8), (int64_t) 8), (int64_t) 8), n_11606, num_tblocks_16179, num_virt_blocks_18658, num_virt_threads_18659, isCore_mem_18420.mem, mem_18423.mem, mem_18425.mem, status_flags_mem_18660.mem, aggregates_mem_18682.mem, incprefixes_mem_18684.mem, global_dynid_mem_18686.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    
    bool cond_15688 = n_11606 == (int64_t) 0;
    bool x_15689 = !cond_15688;
    int64_t tmp_15690 = sub64(n_11606, (int64_t) 1);
    bool x_15691 = sle64((int64_t) 0, tmp_15690);
    bool y_15692 = slt64(tmp_15690, n_11606);
    bool bounds_check_15693 = x_15691 && y_15692;
    bool protect_assert_disj_15694 = cond_15688 || bounds_check_15693;
    bool index_certs_15695;
    
    if (!protect_assert_disj_15694) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) tmp_15690, "] out of bounds for array of shape [", (long long) n_11606, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t m_f_res_15696;
    
    if (x_15689) {
        int64_t read_res_19039;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_19039, mem_18423.mem, tmp_15690 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_16091 = read_res_19039;
        
        m_f_res_15696 = x_16091;
    } else {
        m_f_res_15696 = (int64_t) 0;
    }
    
    int64_t m_15698;
    
    if (cond_15688) {
        m_15698 = (int64_t) 0;
    } else {
        m_15698 = m_f_res_15696;
    }
    
    int64_t m_15708 = sub64(m_15698, (int64_t) 1);
    bool i_p_m_t_s_leq_w_15710 = slt64(m_15708, n_11606);
    bool zzero_leq_i_p_m_t_s_15709 = sle64((int64_t) 0, m_15708);
    bool y_15712 = zzero_leq_i_p_m_t_s_15709 && i_p_m_t_s_leq_w_15710;
    bool i_lte_j_15711 = sle64((int64_t) 0, m_15698);
    bool forwards_ok_15713 = i_lte_j_15711 && y_15712;
    bool eq_x_zz_15705 = (int64_t) 0 == m_f_res_15696;
    bool p_and_eq_x_y_15706 = x_15689 && eq_x_zz_15705;
    bool empty_slice_15707 = cond_15688 || p_and_eq_x_y_15706;
    bool ok_or_empty_15714 = empty_slice_15707 || forwards_ok_15713;
    bool index_certs_15715;
    
    if (!ok_or_empty_15714) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_15698, "] out of bounds for array of shape [", (long long) n_11606, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t binop_x_18426 = (int64_t) 4 * m_15698;
    int64_t bytes_18427 = dim_11607 * binop_x_18426;
    
    if (memblock_alloc_device(ctx, &mem_18428, bytes_18427, "mem_18428")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_4b(ctx, 2, mem_18428.mem, (int64_t) 0, (int64_t []) {dim_11607, (int64_t) 1}, dat_mem_18419.mem, (int64_t) 0, (int64_t []) {dim_11607, (int64_t) 1}, (int64_t []) {m_15698, dim_11607})) != 0)
        goto cleanup;
    
    int64_t segmap_tblock_sizze_16199;
    
    segmap_tblock_sizze_16199 = *ctx->tuning_params.isolate_core_points_6732zisegmap_tblock_sizze_16188;
    
    int64_t segmap_usable_groups_16200 = sdiv_up64(n_11606, segmap_tblock_sizze_16199);
    
    if (memblock_alloc_device(ctx, &mem_18431, bytes_18422, "mem_18431")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_18795 = sext_i64_i32(sdiv_up64(n_11606, segmap_tblock_sizze_16199));
    
    {
        err = gpu_kernel_isolate_core_points_6732zisegmap_16203(ctx, segmap_usable_groups_16200, 1, 1, *ctx->tuning_params.isolate_core_points_6732zisegmap_tblock_sizze_16188, 1, 1, (int64_t) 0, n_11606, mem_18423.mem, mem_18425.mem, mem_18431.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_18423, "mem_18423") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18425, "mem_18425") != 0)
        return 1;
    
    int64_t nest_sizze_16216 = n_11606 * dim_11607;
    int64_t segmap_tblock_sizze_16218;
    
    segmap_tblock_sizze_16218 = *ctx->tuning_params.isolate_core_points_6732zisegmap_tblock_sizze_16217;
    
    int64_t num_tblocks_16220;
    int64_t max_num_tblocks_18804;
    
    max_num_tblocks_18804 = *ctx->tuning_params.isolate_core_points_6732zisegmap_num_tblocks_16219;
    num_tblocks_16220 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nest_sizze_16216, segmap_tblock_sizze_16218), max_num_tblocks_18804)));
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_18805 = sext_i64_i32(sdiv_up64(n_11606 * dim_11607, segmap_tblock_sizze_16218));
    
    {
        err = gpu_kernel_isolate_core_points_6732zisegmap_16214(ctx, num_tblocks_16220, 1, 1, *ctx->tuning_params.isolate_core_points_6732zisegmap_tblock_sizze_16217, 1, 1, (int64_t) 0, n_11606, dim_11607, m_15698, num_tblocks_16220, virt_num_tblocks_18805, dat_mem_18419.mem, mem_18428.mem, mem_18431.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_18431, "mem_18431") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_18650, &mem_18428, "mem_18428") != 0)
        return 1;
    prim_out_18651 = m_15698;
    if (memblock_set_device(ctx, &*mem_out_p_19037, &mem_out_18650, "mem_out_18650") != 0)
        return 1;
    *out_prim_out_19038 = prim_out_18651;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_18431, "mem_18431") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18428, "mem_18428") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_18684, "incprefixes_mem_18684") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_18682, "aggregates_mem_18682") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_18660, "status_flags_mem_18660") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18425, "mem_18425") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18423, "mem_18423") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_18650, "mem_out_18650") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_isolate_core_points_6871(struct futhark_context *ctx, struct memblock_device *mem_out_p_19040, int64_t *out_prim_out_19041, struct memblock_device dat_mem_18419, struct memblock_device isCore_mem_18420, int64_t n_13951, int64_t dim_13952)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_18431;
    
    mem_18431.references = NULL;
    
    struct memblock_device mem_18428;
    
    mem_18428.references = NULL;
    
    struct memblock_device incprefixes_mem_18684;
    
    incprefixes_mem_18684.references = NULL;
    
    struct memblock_device aggregates_mem_18682;
    
    aggregates_mem_18682.references = NULL;
    
    struct memblock_device status_flags_mem_18660;
    
    status_flags_mem_18660.references = NULL;
    
    struct memblock_device mem_18425;
    
    mem_18425.references = NULL;
    
    struct memblock_device mem_18423;
    
    mem_18423.references = NULL;
    
    struct memblock_device mem_out_18650;
    
    mem_out_18650.references = NULL;
    
    struct memblock_device counters_mem_18763 = ctx->constants->counters_mem_18763;
    struct memblock_device counters_mem_18765 = ctx->constants->counters_mem_18765;
    struct memblock_device counters_mem_18789 = ctx->constants->counters_mem_18789;
    struct memblock_device counters_mem_18825 = ctx->constants->counters_mem_18825;
    struct memblock_device global_dynid_mem_18686 = ctx->constants->global_dynid_mem_18686;
    struct memblock_device global_dynid_mem_18892 = ctx->constants->global_dynid_mem_18892;
    int64_t prim_out_18651;
    int64_t segscan_tblock_sizze_16224;
    
    segscan_tblock_sizze_16224 = *ctx->tuning_params.isolate_core_points_6871zisegscan_tblock_sizze_16223;
    
    int64_t num_tblocks_16226;
    int64_t max_num_tblocks_18652;
    
    max_num_tblocks_18652 = *ctx->tuning_params.isolate_core_points_6871zisegscan_num_tblocks_16225;
    num_tblocks_16226 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(n_13951, segscan_tblock_sizze_16224), max_num_tblocks_18652)));
    
    int64_t bytes_18422 = (int64_t) 8 * n_13951;
    
    if (memblock_alloc_device(ctx, &mem_18423, bytes_18422, "mem_18423")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_18425, bytes_18422, "mem_18425")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, n_13951)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_18653;
        
        shared_memory_18653 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_18654;
        
        thread_block_sizze_18654 = ctx->max_thread_block_size;
        
        int64_t registers_18655;
        
        registers_18655 = ctx->max_registers;
        
        int64_t thread_block_sizze_18656;
        
        thread_block_sizze_18656 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_18657 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_18653, thread_block_sizze_18654), (int64_t) 8), squot64(squot64(registers_18655, thread_block_sizze_18656) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
        int64_t num_virt_blocks_18658 = sdiv_up64(n_13951, segscan_tblock_sizze_16224 * chunk_sizze_18657);
        int64_t num_virt_threads_18659 = num_virt_blocks_18658 * segscan_tblock_sizze_16224;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_18657, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_18660, num_virt_blocks_18658, "status_flags_mem_18660")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_18660, num_virt_blocks_18658, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_18682, (int64_t) 8 * num_virt_blocks_18658, "aggregates_mem_18682")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_18684, (int64_t) 8 * num_virt_blocks_18658, "incprefixes_mem_18684")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_isolate_core_points_6871zisegscan_16229(ctx, num_tblocks_16226, 1, 1, *ctx->tuning_params.isolate_core_points_6871zisegscan_tblock_sizze_16223, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_16224), chunk_sizze_18657 * segscan_tblock_sizze_16224 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_16224), chunk_sizze_18657 * segscan_tblock_sizze_16224 * (int64_t) 8), (int64_t) 8), (int64_t) 8), n_13951, num_tblocks_16226, num_virt_blocks_18658, num_virt_threads_18659, isCore_mem_18420.mem, mem_18423.mem, mem_18425.mem, status_flags_mem_18660.mem, aggregates_mem_18682.mem, incprefixes_mem_18684.mem, global_dynid_mem_18686.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    
    bool cond_15688 = n_13951 == (int64_t) 0;
    bool x_15689 = !cond_15688;
    int64_t tmp_15690 = sub64(n_13951, (int64_t) 1);
    bool x_15691 = sle64((int64_t) 0, tmp_15690);
    bool y_15692 = slt64(tmp_15690, n_13951);
    bool bounds_check_15693 = x_15691 && y_15692;
    bool protect_assert_disj_15694 = cond_15688 || bounds_check_15693;
    bool index_certs_15695;
    
    if (!protect_assert_disj_15694) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) tmp_15690, "] out of bounds for array of shape [", (long long) n_13951, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t m_f_res_15696;
    
    if (x_15689) {
        int64_t read_res_19042;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_19042, mem_18423.mem, tmp_15690 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_16091 = read_res_19042;
        
        m_f_res_15696 = x_16091;
    } else {
        m_f_res_15696 = (int64_t) 0;
    }
    
    int64_t m_15698;
    
    if (cond_15688) {
        m_15698 = (int64_t) 0;
    } else {
        m_15698 = m_f_res_15696;
    }
    
    int64_t m_15708 = sub64(m_15698, (int64_t) 1);
    bool i_p_m_t_s_leq_w_15710 = slt64(m_15708, n_13951);
    bool zzero_leq_i_p_m_t_s_15709 = sle64((int64_t) 0, m_15708);
    bool y_15712 = zzero_leq_i_p_m_t_s_15709 && i_p_m_t_s_leq_w_15710;
    bool i_lte_j_15711 = sle64((int64_t) 0, m_15698);
    bool forwards_ok_15713 = i_lte_j_15711 && y_15712;
    bool eq_x_zz_15705 = (int64_t) 0 == m_f_res_15696;
    bool p_and_eq_x_y_15706 = x_15689 && eq_x_zz_15705;
    bool empty_slice_15707 = cond_15688 || p_and_eq_x_y_15706;
    bool ok_or_empty_15714 = empty_slice_15707 || forwards_ok_15713;
    bool index_certs_15715;
    
    if (!ok_or_empty_15714) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_15698, "] out of bounds for array of shape [", (long long) n_13951, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t binop_x_18426 = (int64_t) 8 * m_15698;
    int64_t bytes_18427 = dim_13952 * binop_x_18426;
    
    if (memblock_alloc_device(ctx, &mem_18428, bytes_18427, "mem_18428")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 2, mem_18428.mem, (int64_t) 0, (int64_t []) {dim_13952, (int64_t) 1}, dat_mem_18419.mem, (int64_t) 0, (int64_t []) {dim_13952, (int64_t) 1}, (int64_t []) {m_15698, dim_13952})) != 0)
        goto cleanup;
    
    int64_t segmap_tblock_sizze_16246;
    
    segmap_tblock_sizze_16246 = *ctx->tuning_params.isolate_core_points_6871zisegmap_tblock_sizze_16235;
    
    int64_t segmap_usable_groups_16247 = sdiv_up64(n_13951, segmap_tblock_sizze_16246);
    
    if (memblock_alloc_device(ctx, &mem_18431, bytes_18422, "mem_18431")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_18795 = sext_i64_i32(sdiv_up64(n_13951, segmap_tblock_sizze_16246));
    
    {
        err = gpu_kernel_isolate_core_points_6871zisegmap_16250(ctx, segmap_usable_groups_16247, 1, 1, *ctx->tuning_params.isolate_core_points_6871zisegmap_tblock_sizze_16235, 1, 1, (int64_t) 0, n_13951, mem_18423.mem, mem_18425.mem, mem_18431.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_18423, "mem_18423") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18425, "mem_18425") != 0)
        return 1;
    
    int64_t nest_sizze_16263 = n_13951 * dim_13952;
    int64_t segmap_tblock_sizze_16265;
    
    segmap_tblock_sizze_16265 = *ctx->tuning_params.isolate_core_points_6871zisegmap_tblock_sizze_16264;
    
    int64_t num_tblocks_16267;
    int64_t max_num_tblocks_18804;
    
    max_num_tblocks_18804 = *ctx->tuning_params.isolate_core_points_6871zisegmap_num_tblocks_16266;
    num_tblocks_16267 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nest_sizze_16263, segmap_tblock_sizze_16265), max_num_tblocks_18804)));
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_18805 = sext_i64_i32(sdiv_up64(n_13951 * dim_13952, segmap_tblock_sizze_16265));
    
    {
        err = gpu_kernel_isolate_core_points_6871zisegmap_16261(ctx, num_tblocks_16267, 1, 1, *ctx->tuning_params.isolate_core_points_6871zisegmap_tblock_sizze_16264, 1, 1, (int64_t) 0, n_13951, dim_13952, m_15698, num_tblocks_16267, virt_num_tblocks_18805, dat_mem_18419.mem, mem_18428.mem, mem_18431.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_18431, "mem_18431") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_18650, &mem_18428, "mem_18428") != 0)
        return 1;
    prim_out_18651 = m_15698;
    if (memblock_set_device(ctx, &*mem_out_p_19040, &mem_out_18650, "mem_out_18650") != 0)
        return 1;
    *out_prim_out_19041 = prim_out_18651;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_18431, "mem_18431") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18428, "mem_18428") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_18684, "incprefixes_mem_18684") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_18682, "aggregates_mem_18682") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_18660, "status_flags_mem_18660") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18425, "mem_18425") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18423, "mem_18423") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_18650, "mem_out_18650") != 0)
            return 1;
    }
    return err;
}

int futhark_entry_ftDBSCAN_double(struct futhark_context *ctx, struct futhark_i64_1d **out0, const struct futhark_f64_2d *in0, const double in1, const int64_t in2, const int64_t in3, const int64_t in4)
{
    int64_t nz2080U_15177 = (int64_t) 0;
    int64_t dimz2081U_15178 = (int64_t) 0;
    double eps_15180 = 0.0;
    int64_t minPts_15181 = (int64_t) 0;
    int64_t pMem_15182 = (int64_t) 0;
    int64_t gather_psizze_15183 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_18650;
    
    mem_out_18650.references = NULL;
    
    struct memblock_device dat_mem_18419;
    
    dat_mem_18419.references = NULL;
    dat_mem_18419 = in0->mem;
    nz2080U_15177 = in0->shape[0];
    dimz2081U_15178 = in0->shape[1];
    eps_15180 = in1;
    minPts_15181 = in2;
    pMem_15182 = in3;
    gather_psizze_15183 = in4;
    if (!(nz2080U_15177 == in0->shape[0] && dimz2081U_15178 == in0->shape[1])) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_ftDBSCAN_double(ctx, &mem_out_18650, dat_mem_18419, nz2080U_15177, dimz2081U_15178, eps_15180, minPts_15181, pMem_15182, gather_psizze_15183);
        if (ret == 0) {
            struct memblock_device counters_mem_18763 = ctx->constants->counters_mem_18763;
            struct memblock_device counters_mem_18765 = ctx->constants->counters_mem_18765;
            struct memblock_device counters_mem_18789 = ctx->constants->counters_mem_18789;
            struct memblock_device counters_mem_18825 = ctx->constants->counters_mem_18825;
            struct memblock_device global_dynid_mem_18686 = ctx->constants->global_dynid_mem_18686;
            struct memblock_device global_dynid_mem_18892 = ctx->constants->global_dynid_mem_18892;
            
            assert((*out0 = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d))) != NULL);
            (*out0)->mem = mem_out_18650;
            (*out0)->shape[0] = nz2080U_15177;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_ftDBSCAN_float(struct futhark_context *ctx, struct futhark_i64_1d **out0, const struct futhark_f32_2d *in0, const float in1, const int64_t in2, const int64_t in3, const int64_t in4)
{
    int64_t nz2080U_13119 = (int64_t) 0;
    int64_t dimz2081U_13120 = (int64_t) 0;
    float eps_13122 = 0.0F;
    int64_t minPts_13123 = (int64_t) 0;
    int64_t pMem_13124 = (int64_t) 0;
    int64_t gather_psizze_13125 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_18650;
    
    mem_out_18650.references = NULL;
    
    struct memblock_device dat_mem_18419;
    
    dat_mem_18419.references = NULL;
    dat_mem_18419 = in0->mem;
    nz2080U_13119 = in0->shape[0];
    dimz2081U_13120 = in0->shape[1];
    eps_13122 = in1;
    minPts_13123 = in2;
    pMem_13124 = in3;
    gather_psizze_13125 = in4;
    if (!(nz2080U_13119 == in0->shape[0] && dimz2081U_13120 == in0->shape[1])) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_ftDBSCAN_float(ctx, &mem_out_18650, dat_mem_18419, nz2080U_13119, dimz2081U_13120, eps_13122, minPts_13123, pMem_13124, gather_psizze_13125);
        if (ret == 0) {
            struct memblock_device counters_mem_18763 = ctx->constants->counters_mem_18763;
            struct memblock_device counters_mem_18765 = ctx->constants->counters_mem_18765;
            struct memblock_device counters_mem_18789 = ctx->constants->counters_mem_18789;
            struct memblock_device counters_mem_18825 = ctx->constants->counters_mem_18825;
            struct memblock_device global_dynid_mem_18686 = ctx->constants->global_dynid_mem_18686;
            struct memblock_device global_dynid_mem_18892 = ctx->constants->global_dynid_mem_18892;
            
            assert((*out0 = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d))) != NULL);
            (*out0)->mem = mem_out_18650;
            (*out0)->shape[0] = nz2080U_13119;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_ftDBSCAN_star_double(struct futhark_context *ctx, struct futhark_opaque_core_cluster_double **out0, const struct futhark_f64_2d *in0, const double in1, const int64_t in2, const int64_t in3, const int64_t in4)
{
    int64_t dim_15336 = (int64_t) 0;
    int64_t nz2085U_15337 = (int64_t) 0;
    double eps_15339 = 0.0;
    int64_t minPts_15340 = (int64_t) 0;
    int64_t pMem_15341 = (int64_t) 0;
    int64_t gather_psizze_15342 = (int64_t) 0;
    int64_t prim_out_18652 = (int64_t) 0;
    int64_t prim_out_18653 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_18651;
    
    mem_out_18651.references = NULL;
    
    struct memblock_device mem_out_18650;
    
    mem_out_18650.references = NULL;
    
    struct memblock_device dat_mem_18419;
    
    dat_mem_18419.references = NULL;
    dat_mem_18419 = in0->mem;
    nz2085U_15337 = in0->shape[0];
    dim_15336 = in0->shape[1];
    eps_15339 = in1;
    minPts_15340 = in2;
    pMem_15341 = in3;
    gather_psizze_15342 = in4;
    if (!(nz2085U_15337 == in0->shape[0] && dim_15336 == in0->shape[1])) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_ftDBSCAN_star_double(ctx, &mem_out_18650, &mem_out_18651, &prim_out_18652, &prim_out_18653, dat_mem_18419, dim_15336, nz2085U_15337, eps_15339, minPts_15340, pMem_15341, gather_psizze_15342);
        if (ret == 0) {
            struct memblock_device counters_mem_18763 = ctx->constants->counters_mem_18763;
            struct memblock_device counters_mem_18765 = ctx->constants->counters_mem_18765;
            struct memblock_device counters_mem_18789 = ctx->constants->counters_mem_18789;
            struct memblock_device counters_mem_18825 = ctx->constants->counters_mem_18825;
            struct memblock_device global_dynid_mem_18686 = ctx->constants->global_dynid_mem_18686;
            struct memblock_device global_dynid_mem_18892 = ctx->constants->global_dynid_mem_18892;
            
            assert((*out0 = (struct futhark_opaque_core_cluster_double *) malloc(sizeof(struct futhark_opaque_core_cluster_double))) != NULL);
            assert(((*out0)->v0 = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d))) != NULL);
            (*out0)->v0->mem = mem_out_18650;
            (*out0)->v0->shape[0] = prim_out_18652;
            assert(((*out0)->v1 = (struct futhark_f64_2d *) malloc(sizeof(struct futhark_f64_2d))) != NULL);
            (*out0)->v1->mem = mem_out_18651;
            (*out0)->v1->shape[0] = prim_out_18652;
            (*out0)->v1->shape[1] = dim_15336;
            (*out0)->v2 = prim_out_18653;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_ftDBSCAN_star_float(struct futhark_context *ctx, struct futhark_opaque_core_cluster_float **out0, const struct futhark_f32_2d *in0, const float in1, const int64_t in2, const int64_t in3, const int64_t in4)
{
    int64_t dim_15255 = (int64_t) 0;
    int64_t nz2085U_15256 = (int64_t) 0;
    float eps_15258 = 0.0F;
    int64_t minPts_15259 = (int64_t) 0;
    int64_t pMem_15260 = (int64_t) 0;
    int64_t gather_psizze_15261 = (int64_t) 0;
    int64_t prim_out_18652 = (int64_t) 0;
    int64_t prim_out_18653 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_18651;
    
    mem_out_18651.references = NULL;
    
    struct memblock_device mem_out_18650;
    
    mem_out_18650.references = NULL;
    
    struct memblock_device dat_mem_18419;
    
    dat_mem_18419.references = NULL;
    dat_mem_18419 = in0->mem;
    nz2085U_15256 = in0->shape[0];
    dim_15255 = in0->shape[1];
    eps_15258 = in1;
    minPts_15259 = in2;
    pMem_15260 = in3;
    gather_psizze_15261 = in4;
    if (!(nz2085U_15256 == in0->shape[0] && dim_15255 == in0->shape[1])) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_ftDBSCAN_star_float(ctx, &mem_out_18650, &mem_out_18651, &prim_out_18652, &prim_out_18653, dat_mem_18419, dim_15255, nz2085U_15256, eps_15258, minPts_15259, pMem_15260, gather_psizze_15261);
        if (ret == 0) {
            struct memblock_device counters_mem_18763 = ctx->constants->counters_mem_18763;
            struct memblock_device counters_mem_18765 = ctx->constants->counters_mem_18765;
            struct memblock_device counters_mem_18789 = ctx->constants->counters_mem_18789;
            struct memblock_device counters_mem_18825 = ctx->constants->counters_mem_18825;
            struct memblock_device global_dynid_mem_18686 = ctx->constants->global_dynid_mem_18686;
            struct memblock_device global_dynid_mem_18892 = ctx->constants->global_dynid_mem_18892;
            
            assert((*out0 = (struct futhark_opaque_core_cluster_float *) malloc(sizeof(struct futhark_opaque_core_cluster_float))) != NULL);
            assert(((*out0)->v0 = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d))) != NULL);
            (*out0)->v0->mem = mem_out_18650;
            (*out0)->v0->shape[0] = prim_out_18652;
            assert(((*out0)->v1 = (struct futhark_f32_2d *) malloc(sizeof(struct futhark_f32_2d))) != NULL);
            (*out0)->v1->mem = mem_out_18651;
            (*out0)->v1->shape[0] = prim_out_18652;
            (*out0)->v1->shape[1] = dim_15255;
            (*out0)->v2 = prim_out_18653;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
  
