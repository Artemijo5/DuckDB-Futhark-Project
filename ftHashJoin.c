// Generated by Futhark 0.26.0 (prerelease - include info below when reporting bugs).
// git: 1de4f0c (Fri Jan 24 11:10:52 2025 +0100)
// Compiled with GHC 9.4.8.

// We need to define _GNU_SOURCE before
// _any_ headers files are imported to get
// the usage statistics of a thread (i.e. have RUSAGE_THREAD) on GNU/Linux
// https://manpages.courier-mta.org/htmlman2/getrusage.2.html
#ifndef _GNU_SOURCE // Avoid possible double-definition warning.
#define _GNU_SOURCE
#endif

#ifdef __clang__
#pragma clang diagnostic ignored "-Wunused-function"
#pragma clang diagnostic ignored "-Wunused-variable"
#pragma clang diagnostic ignored "-Wunused-const-variable"
#pragma clang diagnostic ignored "-Wparentheses"
#pragma clang diagnostic ignored "-Wunused-label"
#pragma clang diagnostic ignored "-Wunused-but-set-variable"
#elif __GNUC__
#pragma GCC diagnostic ignored "-Wunused-function"
#pragma GCC diagnostic ignored "-Wunused-variable"
#pragma GCC diagnostic ignored "-Wunused-const-variable"
#pragma GCC diagnostic ignored "-Wparentheses"
#pragma GCC diagnostic ignored "-Wunused-label"
#pragma GCC diagnostic ignored "-Wunused-but-set-variable"
#endif

// Headers
#include <stdint.h>
#include <stddef.h>
#include <stdbool.h>
#include <stdio.h>
#include <float.h>

#include <cuda.h>
#include <cuda_runtime.h>
#include <nvrtc.h>

#ifdef __cplusplus
extern "C" {
#endif

// Initialisation
struct futhark_context_config;
struct futhark_context_config *futhark_context_config_new(void);
void futhark_context_config_free(struct futhark_context_config *cfg);
int futhark_context_config_set_tuning_param(struct futhark_context_config *cfg, const char *param_name, size_t new_value);
struct futhark_context;
struct futhark_context *futhark_context_new(struct futhark_context_config *cfg);
void futhark_context_free(struct futhark_context *cfg);
void futhark_context_config_set_default_thread_block_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_grid_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_group_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_num_groups(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_tile_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_reg_tile_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_registers(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_cache(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_threshold(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_unified_memory(struct futhark_context_config *cfg, int flag);
void futhark_context_config_add_nvrtc_option(struct futhark_context_config *cfg, const char *opt);
void futhark_context_config_set_device(struct futhark_context_config *cfg, const char *s);
const char *futhark_context_config_get_program(struct futhark_context_config *cfg);
void futhark_context_config_set_program(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_dump_ptx_to(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_load_ptx_from(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_set_debugging(struct futhark_context_config *cfg, int flag);
void futhark_context_config_set_profiling(struct futhark_context_config *cfg, int flag);
void futhark_context_config_set_logging(struct futhark_context_config *cfg, int flag);
int futhark_get_tuning_param_count(void);
const char *futhark_get_tuning_param_name(int);
const char *futhark_get_tuning_param_class(int);

// Arrays
struct futhark_bool_1d;
struct futhark_bool_1d *futhark_new_bool_1d(struct futhark_context *ctx, const bool *data, int64_t dim0);
struct futhark_bool_1d *futhark_new_raw_bool_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0);
int futhark_free_bool_1d(struct futhark_context *ctx, struct futhark_bool_1d *arr);
int futhark_values_bool_1d(struct futhark_context *ctx, struct futhark_bool_1d *arr, bool *data);
int futhark_index_bool_1d(struct futhark_context *ctx, bool *out, struct futhark_bool_1d *arr, int64_t i0);
CUdeviceptr futhark_values_raw_bool_1d(struct futhark_context *ctx, struct futhark_bool_1d *arr);
const int64_t *futhark_shape_bool_1d(struct futhark_context *ctx, struct futhark_bool_1d *arr);
struct futhark_i64_1d;
struct futhark_i64_1d *futhark_new_i64_1d(struct futhark_context *ctx, const int64_t *data, int64_t dim0);
struct futhark_i64_1d *futhark_new_raw_i64_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0);
int futhark_free_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr);
int futhark_values_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr, int64_t *data);
int futhark_index_i64_1d(struct futhark_context *ctx, int64_t *out, struct futhark_i64_1d *arr, int64_t i0);
CUdeviceptr futhark_values_raw_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr);
const int64_t *futhark_shape_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr);
struct futhark_u8_2d;
struct futhark_u8_2d *futhark_new_u8_2d(struct futhark_context *ctx, const uint8_t *data, int64_t dim0, int64_t dim1);
struct futhark_u8_2d *futhark_new_raw_u8_2d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0, int64_t dim1);
int futhark_free_u8_2d(struct futhark_context *ctx, struct futhark_u8_2d *arr);
int futhark_values_u8_2d(struct futhark_context *ctx, struct futhark_u8_2d *arr, uint8_t *data);
int futhark_index_u8_2d(struct futhark_context *ctx, uint8_t *out, struct futhark_u8_2d *arr, int64_t i0, int64_t i1);
CUdeviceptr futhark_values_raw_u8_2d(struct futhark_context *ctx, struct futhark_u8_2d *arr);
const int64_t *futhark_shape_u8_2d(struct futhark_context *ctx, struct futhark_u8_2d *arr);

// Opaque values



// Entry points
int futhark_entry_main(struct futhark_context *ctx, struct futhark_u8_2d **out0, struct futhark_i64_1d **out1, struct futhark_bool_1d **out2, const int32_t in0);

// Miscellaneous
int futhark_context_sync(struct futhark_context *ctx);
void futhark_context_config_set_cache_file(struct futhark_context_config *cfg, const char *f);
char *futhark_context_get_error(struct futhark_context *ctx);
void futhark_context_set_logging_file(struct futhark_context *ctx, FILE *f);
void futhark_context_pause_profiling(struct futhark_context *ctx);
void futhark_context_unpause_profiling(struct futhark_context *ctx);
char *futhark_context_report(struct futhark_context *ctx);
int futhark_context_clear_caches(struct futhark_context *ctx);
#define FUTHARK_BACKEND_cuda
#define FUTHARK_SUCCESS 0
#define FUTHARK_PROGRAM_ERROR 2
#define FUTHARK_OUT_OF_MEMORY 3

#ifdef __cplusplus
}
#endif

#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <math.h>
#include <stdint.h>
// If NDEBUG is set, the assert() macro will do nothing. Since Futhark
// (unfortunately) makes use of assert() for error detection (and even some
// side effects), we want to avoid that.
#undef NDEBUG
#include <assert.h>
#include <stdarg.h>
#define SCALAR_FUN_ATTR static inline
// Start of util.h.
//
// Various helper functions that are useful in all generated C code.

#include <errno.h>
#include <string.h>

static const char *fut_progname = "(embedded Futhark)";

static void futhark_panic(int eval, const char *fmt, ...) __attribute__((noreturn));
static char* msgprintf(const char *s, ...);
static void* slurp_file(const char *filename, size_t *size);
static int dump_file(const char *file, const void *buf, size_t n);
struct str_builder;
static void str_builder_init(struct str_builder *b);
static void str_builder(struct str_builder *b, const char *s, ...);
static char *strclone(const char *str);

static void futhark_panic(int eval, const char *fmt, ...) {
  va_list ap;
  va_start(ap, fmt);
  fprintf(stderr, "%s: ", fut_progname);
  vfprintf(stderr, fmt, ap);
  va_end(ap);
  exit(eval);
}

// For generating arbitrary-sized error messages.  It is the callers
// responsibility to free the buffer at some point.
static char* msgprintf(const char *s, ...) {
  va_list vl;
  va_start(vl, s);
  size_t needed = 1 + (size_t)vsnprintf(NULL, 0, s, vl);
  char *buffer = (char*) malloc(needed);
  va_start(vl, s); // Must re-init.
  vsnprintf(buffer, needed, s, vl);
  return buffer;
}

static inline void check_err(int errval, int sets_errno, const char *fun, int line,
                             const char *msg, ...) {
  if (errval) {
    char errnum[10];

    va_list vl;
    va_start(vl, msg);

    fprintf(stderr, "ERROR: ");
    vfprintf(stderr, msg, vl);
    fprintf(stderr, " in %s() at line %d with error code %s\n",
            fun, line,
            sets_errno ? strerror(errno) : errnum);
    exit(errval);
  }
}

#define CHECK_ERR(err, ...) check_err(err, 0, __func__, __LINE__, __VA_ARGS__)
#define CHECK_ERRNO(err, ...) check_err(err, 1, __func__, __LINE__, __VA_ARGS__)

// Read the rest of an open file into a NUL-terminated string; returns
// NULL on error.
static void* fslurp_file(FILE *f, size_t *size) {
  long start = ftell(f);
  fseek(f, 0, SEEK_END);
  long src_size = ftell(f)-start;
  fseek(f, start, SEEK_SET);
  unsigned char *s = (unsigned char*) malloc((size_t)src_size + 1);
  if (fread(s, 1, (size_t)src_size, f) != (size_t)src_size) {
    free(s);
    s = NULL;
  } else {
    s[src_size] = '\0';
  }

  if (size) {
    *size = (size_t)src_size;
  }

  return s;
}

// Read a file into a NUL-terminated string; returns NULL on error.
static void* slurp_file(const char *filename, size_t *size) {
  FILE *f = fopen(filename, "rb"); // To avoid Windows messing with linebreaks.
  if (f == NULL) return NULL;
  unsigned char *s = fslurp_file(f, size);
  fclose(f);
  return s;
}

// Dump 'n' bytes from 'buf' into the file at the designated location.
// Returns 0 on success.
static int dump_file(const char *file, const void *buf, size_t n) {
  FILE *f = fopen(file, "w");

  if (f == NULL) {
    return 1;
  }

  if (fwrite(buf, sizeof(char), n, f) != n) {
    return 1;
  }

  if (fclose(f) != 0) {
    return 1;
  }

  return 0;
}

struct str_builder {
  char *str;
  size_t capacity; // Size of buffer.
  size_t used; // Bytes used, *not* including final zero.
};

static void str_builder_init(struct str_builder *b) {
  b->capacity = 10;
  b->used = 0;
  b->str = malloc(b->capacity);
  b->str[0] = 0;
}

static void str_builder(struct str_builder *b, const char *s, ...) {
  va_list vl;
  va_start(vl, s);
  size_t needed = (size_t)vsnprintf(NULL, 0, s, vl);

  while (b->capacity < b->used + needed + 1) {
    b->capacity *= 2;
    b->str = realloc(b->str, b->capacity);
  }

  va_start(vl, s); // Must re-init.
  vsnprintf(b->str+b->used, b->capacity-b->used, s, vl);
  b->used += needed;
}

static void str_builder_str(struct str_builder *b, const char *s) {
  size_t needed = strlen(s);
  if (b->capacity < b->used + needed + 1) {
    b->capacity *= 2;
    b->str = realloc(b->str, b->capacity);
  }
  strcpy(b->str+b->used, s);
  b->used += needed;
}

static void str_builder_char(struct str_builder *b, char c) {
  size_t needed = 1;
  if (b->capacity < b->used + needed + 1) {
    b->capacity *= 2;
    b->str = realloc(b->str, b->capacity);
  }
  b->str[b->used] = c;
  b->str[b->used+1] = 0;
  b->used += needed;
}

static void str_builder_json_str(struct str_builder* sb, const char* s) {
  str_builder_char(sb, '"');
  for (int j = 0; s[j]; j++) {
    char c = s[j];
    switch (c) {
    case '\n':
      str_builder_str(sb, "\\n");
      break;
    case '"':
      str_builder_str(sb, "\\\"");
      break;
    default:
      str_builder_char(sb, c);
    }
  }
  str_builder_char(sb, '"');
}

static char *strclone(const char *str) {
  size_t size = strlen(str) + 1;
  char *copy = (char*) malloc(size);
  if (copy == NULL) {
    return NULL;
  }

  memcpy(copy, str, size);
  return copy;
}

// Assumes NULL-terminated.
static char *strconcat(const char *src_fragments[]) {
  size_t src_len = 0;
  const char **p;

  for (p = src_fragments; *p; p++) {
    src_len += strlen(*p);
  }

  char *src = (char*) malloc(src_len + 1);
  size_t n = 0;
  for (p = src_fragments; *p; p++) {
    strcpy(src + n, *p);
    n += strlen(*p);
  }

  return src;
}

// End of util.h.
// Start of cache.h

#define CACHE_HASH_SIZE 8 // In 32-bit words.

struct cache_hash {
  uint32_t hash[CACHE_HASH_SIZE];
};

// Initialise a blank cache.
static void cache_hash_init(struct cache_hash *c);

// Hash some bytes and add them to the accumulated hash.
static void cache_hash(struct cache_hash *out, const char *in, size_t n);

// Try to restore cache contents from a file with the given name.
// Assumes the cache is invalid if it contains the given hash.
// Allocates memory and reads the cache conents, which is returned in
// *buf with size *buflen.  If the cache is successfully loaded, this
// function returns 0.  Otherwise it returns nonzero.  Errno is set if
// the failure to load the cache is due to anything except invalid
// cache conents.  Note that failing to restore the cache is not
// necessarily a problem: it might just be invalid or not created yet.
static int cache_restore(const char *fname, const struct cache_hash *hash,
                         unsigned char **buf, size_t *buflen);

// Store cache contents in the given file, with the given hash.
static int cache_store(const char *fname, const struct cache_hash *hash,
                       const unsigned char *buf, size_t buflen);

// Now for the implementation.

static void cache_hash_init(struct cache_hash *c) {
  memset(c->hash, 0, CACHE_HASH_SIZE * sizeof(uint32_t));
}

static void cache_hash(struct cache_hash *out, const char *in, size_t n) {
  // Adaptation of djb2 for larger output size by storing intermediate
  // states.
  uint32_t hash = 5381;
  for (size_t i = 0; i < n; i++) {
    hash = ((hash << 5) + hash) + in[i];
    out->hash[i % CACHE_HASH_SIZE] ^= hash;
  }
}

#define CACHE_HEADER_SIZE 8
static const char cache_header[CACHE_HEADER_SIZE] = "FUTHARK\0";

static int cache_restore(const char *fname, const struct cache_hash *hash,
                         unsigned char **buf, size_t *buflen) {
  FILE *f = fopen(fname, "rb");

  if (f == NULL) {
    return 1;
  }

  char f_header[CACHE_HEADER_SIZE];

  if (fread(f_header, sizeof(char), CACHE_HEADER_SIZE, f) != CACHE_HEADER_SIZE) {
    goto error;
  }

  if (memcmp(f_header, cache_header, CACHE_HEADER_SIZE) != 0) {
    goto error;
  }

  if (fseek(f, 0, SEEK_END) != 0) {
    goto error;
  }
  int64_t f_size = (int64_t)ftell(f);
  if (fseek(f, CACHE_HEADER_SIZE, SEEK_SET) != 0) {
    goto error;
  }

  int64_t expected_size;

  if (fread(&expected_size, sizeof(int64_t), 1, f) != 1) {
    goto error;
  }

  if (f_size != expected_size) {
    errno = 0;
    goto error;
  }

  int32_t f_hash[CACHE_HASH_SIZE];

  if (fread(f_hash, sizeof(int32_t), CACHE_HASH_SIZE, f) != CACHE_HASH_SIZE) {
    goto error;
  }

  if (memcmp(f_hash, hash->hash, CACHE_HASH_SIZE) != 0) {
    errno = 0;
    goto error;
  }

  *buflen = f_size - CACHE_HEADER_SIZE - sizeof(int64_t) - CACHE_HASH_SIZE*sizeof(int32_t);
  *buf = malloc(*buflen);
  if (fread(*buf, sizeof(char), *buflen, f) != *buflen) {
    free(*buf);
    goto error;
  }

  fclose(f);

  return 0;

 error:
  fclose(f);
  return 1;
}

static int cache_store(const char *fname, const struct cache_hash *hash,
                       const unsigned char *buf, size_t buflen) {
  FILE *f = fopen(fname, "wb");

  if (f == NULL) {
    return 1;
  }

  if (fwrite(cache_header, CACHE_HEADER_SIZE, 1, f) != 1) {
    goto error;
  }

  int64_t size = CACHE_HEADER_SIZE + sizeof(int64_t) + CACHE_HASH_SIZE*sizeof(int32_t) + buflen;

  if (fwrite(&size, sizeof(size), 1, f) != 1) {
    goto error;
  }

  if (fwrite(hash->hash, sizeof(int32_t), CACHE_HASH_SIZE, f) != CACHE_HASH_SIZE) {
    goto error;
  }

  if (fwrite(buf, sizeof(unsigned char), buflen, f) != buflen) {
    goto error;
  }

  fclose(f);

  return 0;

 error:
  fclose(f);
  return 1;
}

// End of cache.h
// Start of half.h.

// Conversion functions are from http://half.sourceforge.net/, but
// translated to C.
//
// Copyright (c) 2012-2021 Christian Rau
//
// Permission is hereby granted, free of charge, to any person obtaining a copy
// of this software and associated documentation files (the "Software"), to deal
// in the Software without restriction, including without limitation the rights
// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
// copies of the Software, and to permit persons to whom the Software is
// furnished to do so, subject to the following conditions:
//
// The above copyright notice and this permission notice shall be included in
// all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
// THE SOFTWARE.

#ifndef __OPENCL_VERSION__
#define __constant
#endif

__constant static const uint16_t base_table[512] = {
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0001, 0x0002, 0x0004, 0x0008, 0x0010, 0x0020, 0x0040, 0x0080, 0x0100,
  0x0200, 0x0400, 0x0800, 0x0C00, 0x1000, 0x1400, 0x1800, 0x1C00, 0x2000, 0x2400, 0x2800, 0x2C00, 0x3000, 0x3400, 0x3800, 0x3C00,
  0x4000, 0x4400, 0x4800, 0x4C00, 0x5000, 0x5400, 0x5800, 0x5C00, 0x6000, 0x6400, 0x6800, 0x6C00, 0x7000, 0x7400, 0x7800, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8001, 0x8002, 0x8004, 0x8008, 0x8010, 0x8020, 0x8040, 0x8080, 0x8100,
  0x8200, 0x8400, 0x8800, 0x8C00, 0x9000, 0x9400, 0x9800, 0x9C00, 0xA000, 0xA400, 0xA800, 0xAC00, 0xB000, 0xB400, 0xB800, 0xBC00,
  0xC000, 0xC400, 0xC800, 0xCC00, 0xD000, 0xD400, 0xD800, 0xDC00, 0xE000, 0xE400, 0xE800, 0xEC00, 0xF000, 0xF400, 0xF800, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00 };

__constant static const unsigned char shift_table[512] = {
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13 };

__constant static const uint32_t mantissa_table[2048] = {
  0x00000000, 0x33800000, 0x34000000, 0x34400000, 0x34800000, 0x34A00000, 0x34C00000, 0x34E00000, 0x35000000, 0x35100000, 0x35200000, 0x35300000, 0x35400000, 0x35500000, 0x35600000, 0x35700000,
  0x35800000, 0x35880000, 0x35900000, 0x35980000, 0x35A00000, 0x35A80000, 0x35B00000, 0x35B80000, 0x35C00000, 0x35C80000, 0x35D00000, 0x35D80000, 0x35E00000, 0x35E80000, 0x35F00000, 0x35F80000,
  0x36000000, 0x36040000, 0x36080000, 0x360C0000, 0x36100000, 0x36140000, 0x36180000, 0x361C0000, 0x36200000, 0x36240000, 0x36280000, 0x362C0000, 0x36300000, 0x36340000, 0x36380000, 0x363C0000,
  0x36400000, 0x36440000, 0x36480000, 0x364C0000, 0x36500000, 0x36540000, 0x36580000, 0x365C0000, 0x36600000, 0x36640000, 0x36680000, 0x366C0000, 0x36700000, 0x36740000, 0x36780000, 0x367C0000,
  0x36800000, 0x36820000, 0x36840000, 0x36860000, 0x36880000, 0x368A0000, 0x368C0000, 0x368E0000, 0x36900000, 0x36920000, 0x36940000, 0x36960000, 0x36980000, 0x369A0000, 0x369C0000, 0x369E0000,
  0x36A00000, 0x36A20000, 0x36A40000, 0x36A60000, 0x36A80000, 0x36AA0000, 0x36AC0000, 0x36AE0000, 0x36B00000, 0x36B20000, 0x36B40000, 0x36B60000, 0x36B80000, 0x36BA0000, 0x36BC0000, 0x36BE0000,
  0x36C00000, 0x36C20000, 0x36C40000, 0x36C60000, 0x36C80000, 0x36CA0000, 0x36CC0000, 0x36CE0000, 0x36D00000, 0x36D20000, 0x36D40000, 0x36D60000, 0x36D80000, 0x36DA0000, 0x36DC0000, 0x36DE0000,
  0x36E00000, 0x36E20000, 0x36E40000, 0x36E60000, 0x36E80000, 0x36EA0000, 0x36EC0000, 0x36EE0000, 0x36F00000, 0x36F20000, 0x36F40000, 0x36F60000, 0x36F80000, 0x36FA0000, 0x36FC0000, 0x36FE0000,
  0x37000000, 0x37010000, 0x37020000, 0x37030000, 0x37040000, 0x37050000, 0x37060000, 0x37070000, 0x37080000, 0x37090000, 0x370A0000, 0x370B0000, 0x370C0000, 0x370D0000, 0x370E0000, 0x370F0000,
  0x37100000, 0x37110000, 0x37120000, 0x37130000, 0x37140000, 0x37150000, 0x37160000, 0x37170000, 0x37180000, 0x37190000, 0x371A0000, 0x371B0000, 0x371C0000, 0x371D0000, 0x371E0000, 0x371F0000,
  0x37200000, 0x37210000, 0x37220000, 0x37230000, 0x37240000, 0x37250000, 0x37260000, 0x37270000, 0x37280000, 0x37290000, 0x372A0000, 0x372B0000, 0x372C0000, 0x372D0000, 0x372E0000, 0x372F0000,
  0x37300000, 0x37310000, 0x37320000, 0x37330000, 0x37340000, 0x37350000, 0x37360000, 0x37370000, 0x37380000, 0x37390000, 0x373A0000, 0x373B0000, 0x373C0000, 0x373D0000, 0x373E0000, 0x373F0000,
  0x37400000, 0x37410000, 0x37420000, 0x37430000, 0x37440000, 0x37450000, 0x37460000, 0x37470000, 0x37480000, 0x37490000, 0x374A0000, 0x374B0000, 0x374C0000, 0x374D0000, 0x374E0000, 0x374F0000,
  0x37500000, 0x37510000, 0x37520000, 0x37530000, 0x37540000, 0x37550000, 0x37560000, 0x37570000, 0x37580000, 0x37590000, 0x375A0000, 0x375B0000, 0x375C0000, 0x375D0000, 0x375E0000, 0x375F0000,
  0x37600000, 0x37610000, 0x37620000, 0x37630000, 0x37640000, 0x37650000, 0x37660000, 0x37670000, 0x37680000, 0x37690000, 0x376A0000, 0x376B0000, 0x376C0000, 0x376D0000, 0x376E0000, 0x376F0000,
  0x37700000, 0x37710000, 0x37720000, 0x37730000, 0x37740000, 0x37750000, 0x37760000, 0x37770000, 0x37780000, 0x37790000, 0x377A0000, 0x377B0000, 0x377C0000, 0x377D0000, 0x377E0000, 0x377F0000,
  0x37800000, 0x37808000, 0x37810000, 0x37818000, 0x37820000, 0x37828000, 0x37830000, 0x37838000, 0x37840000, 0x37848000, 0x37850000, 0x37858000, 0x37860000, 0x37868000, 0x37870000, 0x37878000,
  0x37880000, 0x37888000, 0x37890000, 0x37898000, 0x378A0000, 0x378A8000, 0x378B0000, 0x378B8000, 0x378C0000, 0x378C8000, 0x378D0000, 0x378D8000, 0x378E0000, 0x378E8000, 0x378F0000, 0x378F8000,
  0x37900000, 0x37908000, 0x37910000, 0x37918000, 0x37920000, 0x37928000, 0x37930000, 0x37938000, 0x37940000, 0x37948000, 0x37950000, 0x37958000, 0x37960000, 0x37968000, 0x37970000, 0x37978000,
  0x37980000, 0x37988000, 0x37990000, 0x37998000, 0x379A0000, 0x379A8000, 0x379B0000, 0x379B8000, 0x379C0000, 0x379C8000, 0x379D0000, 0x379D8000, 0x379E0000, 0x379E8000, 0x379F0000, 0x379F8000,
  0x37A00000, 0x37A08000, 0x37A10000, 0x37A18000, 0x37A20000, 0x37A28000, 0x37A30000, 0x37A38000, 0x37A40000, 0x37A48000, 0x37A50000, 0x37A58000, 0x37A60000, 0x37A68000, 0x37A70000, 0x37A78000,
  0x37A80000, 0x37A88000, 0x37A90000, 0x37A98000, 0x37AA0000, 0x37AA8000, 0x37AB0000, 0x37AB8000, 0x37AC0000, 0x37AC8000, 0x37AD0000, 0x37AD8000, 0x37AE0000, 0x37AE8000, 0x37AF0000, 0x37AF8000,
  0x37B00000, 0x37B08000, 0x37B10000, 0x37B18000, 0x37B20000, 0x37B28000, 0x37B30000, 0x37B38000, 0x37B40000, 0x37B48000, 0x37B50000, 0x37B58000, 0x37B60000, 0x37B68000, 0x37B70000, 0x37B78000,
  0x37B80000, 0x37B88000, 0x37B90000, 0x37B98000, 0x37BA0000, 0x37BA8000, 0x37BB0000, 0x37BB8000, 0x37BC0000, 0x37BC8000, 0x37BD0000, 0x37BD8000, 0x37BE0000, 0x37BE8000, 0x37BF0000, 0x37BF8000,
  0x37C00000, 0x37C08000, 0x37C10000, 0x37C18000, 0x37C20000, 0x37C28000, 0x37C30000, 0x37C38000, 0x37C40000, 0x37C48000, 0x37C50000, 0x37C58000, 0x37C60000, 0x37C68000, 0x37C70000, 0x37C78000,
  0x37C80000, 0x37C88000, 0x37C90000, 0x37C98000, 0x37CA0000, 0x37CA8000, 0x37CB0000, 0x37CB8000, 0x37CC0000, 0x37CC8000, 0x37CD0000, 0x37CD8000, 0x37CE0000, 0x37CE8000, 0x37CF0000, 0x37CF8000,
  0x37D00000, 0x37D08000, 0x37D10000, 0x37D18000, 0x37D20000, 0x37D28000, 0x37D30000, 0x37D38000, 0x37D40000, 0x37D48000, 0x37D50000, 0x37D58000, 0x37D60000, 0x37D68000, 0x37D70000, 0x37D78000,
  0x37D80000, 0x37D88000, 0x37D90000, 0x37D98000, 0x37DA0000, 0x37DA8000, 0x37DB0000, 0x37DB8000, 0x37DC0000, 0x37DC8000, 0x37DD0000, 0x37DD8000, 0x37DE0000, 0x37DE8000, 0x37DF0000, 0x37DF8000,
  0x37E00000, 0x37E08000, 0x37E10000, 0x37E18000, 0x37E20000, 0x37E28000, 0x37E30000, 0x37E38000, 0x37E40000, 0x37E48000, 0x37E50000, 0x37E58000, 0x37E60000, 0x37E68000, 0x37E70000, 0x37E78000,
  0x37E80000, 0x37E88000, 0x37E90000, 0x37E98000, 0x37EA0000, 0x37EA8000, 0x37EB0000, 0x37EB8000, 0x37EC0000, 0x37EC8000, 0x37ED0000, 0x37ED8000, 0x37EE0000, 0x37EE8000, 0x37EF0000, 0x37EF8000,
  0x37F00000, 0x37F08000, 0x37F10000, 0x37F18000, 0x37F20000, 0x37F28000, 0x37F30000, 0x37F38000, 0x37F40000, 0x37F48000, 0x37F50000, 0x37F58000, 0x37F60000, 0x37F68000, 0x37F70000, 0x37F78000,
  0x37F80000, 0x37F88000, 0x37F90000, 0x37F98000, 0x37FA0000, 0x37FA8000, 0x37FB0000, 0x37FB8000, 0x37FC0000, 0x37FC8000, 0x37FD0000, 0x37FD8000, 0x37FE0000, 0x37FE8000, 0x37FF0000, 0x37FF8000,
  0x38000000, 0x38004000, 0x38008000, 0x3800C000, 0x38010000, 0x38014000, 0x38018000, 0x3801C000, 0x38020000, 0x38024000, 0x38028000, 0x3802C000, 0x38030000, 0x38034000, 0x38038000, 0x3803C000,
  0x38040000, 0x38044000, 0x38048000, 0x3804C000, 0x38050000, 0x38054000, 0x38058000, 0x3805C000, 0x38060000, 0x38064000, 0x38068000, 0x3806C000, 0x38070000, 0x38074000, 0x38078000, 0x3807C000,
  0x38080000, 0x38084000, 0x38088000, 0x3808C000, 0x38090000, 0x38094000, 0x38098000, 0x3809C000, 0x380A0000, 0x380A4000, 0x380A8000, 0x380AC000, 0x380B0000, 0x380B4000, 0x380B8000, 0x380BC000,
  0x380C0000, 0x380C4000, 0x380C8000, 0x380CC000, 0x380D0000, 0x380D4000, 0x380D8000, 0x380DC000, 0x380E0000, 0x380E4000, 0x380E8000, 0x380EC000, 0x380F0000, 0x380F4000, 0x380F8000, 0x380FC000,
  0x38100000, 0x38104000, 0x38108000, 0x3810C000, 0x38110000, 0x38114000, 0x38118000, 0x3811C000, 0x38120000, 0x38124000, 0x38128000, 0x3812C000, 0x38130000, 0x38134000, 0x38138000, 0x3813C000,
  0x38140000, 0x38144000, 0x38148000, 0x3814C000, 0x38150000, 0x38154000, 0x38158000, 0x3815C000, 0x38160000, 0x38164000, 0x38168000, 0x3816C000, 0x38170000, 0x38174000, 0x38178000, 0x3817C000,
  0x38180000, 0x38184000, 0x38188000, 0x3818C000, 0x38190000, 0x38194000, 0x38198000, 0x3819C000, 0x381A0000, 0x381A4000, 0x381A8000, 0x381AC000, 0x381B0000, 0x381B4000, 0x381B8000, 0x381BC000,
  0x381C0000, 0x381C4000, 0x381C8000, 0x381CC000, 0x381D0000, 0x381D4000, 0x381D8000, 0x381DC000, 0x381E0000, 0x381E4000, 0x381E8000, 0x381EC000, 0x381F0000, 0x381F4000, 0x381F8000, 0x381FC000,
  0x38200000, 0x38204000, 0x38208000, 0x3820C000, 0x38210000, 0x38214000, 0x38218000, 0x3821C000, 0x38220000, 0x38224000, 0x38228000, 0x3822C000, 0x38230000, 0x38234000, 0x38238000, 0x3823C000,
  0x38240000, 0x38244000, 0x38248000, 0x3824C000, 0x38250000, 0x38254000, 0x38258000, 0x3825C000, 0x38260000, 0x38264000, 0x38268000, 0x3826C000, 0x38270000, 0x38274000, 0x38278000, 0x3827C000,
  0x38280000, 0x38284000, 0x38288000, 0x3828C000, 0x38290000, 0x38294000, 0x38298000, 0x3829C000, 0x382A0000, 0x382A4000, 0x382A8000, 0x382AC000, 0x382B0000, 0x382B4000, 0x382B8000, 0x382BC000,
  0x382C0000, 0x382C4000, 0x382C8000, 0x382CC000, 0x382D0000, 0x382D4000, 0x382D8000, 0x382DC000, 0x382E0000, 0x382E4000, 0x382E8000, 0x382EC000, 0x382F0000, 0x382F4000, 0x382F8000, 0x382FC000,
  0x38300000, 0x38304000, 0x38308000, 0x3830C000, 0x38310000, 0x38314000, 0x38318000, 0x3831C000, 0x38320000, 0x38324000, 0x38328000, 0x3832C000, 0x38330000, 0x38334000, 0x38338000, 0x3833C000,
  0x38340000, 0x38344000, 0x38348000, 0x3834C000, 0x38350000, 0x38354000, 0x38358000, 0x3835C000, 0x38360000, 0x38364000, 0x38368000, 0x3836C000, 0x38370000, 0x38374000, 0x38378000, 0x3837C000,
  0x38380000, 0x38384000, 0x38388000, 0x3838C000, 0x38390000, 0x38394000, 0x38398000, 0x3839C000, 0x383A0000, 0x383A4000, 0x383A8000, 0x383AC000, 0x383B0000, 0x383B4000, 0x383B8000, 0x383BC000,
  0x383C0000, 0x383C4000, 0x383C8000, 0x383CC000, 0x383D0000, 0x383D4000, 0x383D8000, 0x383DC000, 0x383E0000, 0x383E4000, 0x383E8000, 0x383EC000, 0x383F0000, 0x383F4000, 0x383F8000, 0x383FC000,
  0x38400000, 0x38404000, 0x38408000, 0x3840C000, 0x38410000, 0x38414000, 0x38418000, 0x3841C000, 0x38420000, 0x38424000, 0x38428000, 0x3842C000, 0x38430000, 0x38434000, 0x38438000, 0x3843C000,
  0x38440000, 0x38444000, 0x38448000, 0x3844C000, 0x38450000, 0x38454000, 0x38458000, 0x3845C000, 0x38460000, 0x38464000, 0x38468000, 0x3846C000, 0x38470000, 0x38474000, 0x38478000, 0x3847C000,
  0x38480000, 0x38484000, 0x38488000, 0x3848C000, 0x38490000, 0x38494000, 0x38498000, 0x3849C000, 0x384A0000, 0x384A4000, 0x384A8000, 0x384AC000, 0x384B0000, 0x384B4000, 0x384B8000, 0x384BC000,
  0x384C0000, 0x384C4000, 0x384C8000, 0x384CC000, 0x384D0000, 0x384D4000, 0x384D8000, 0x384DC000, 0x384E0000, 0x384E4000, 0x384E8000, 0x384EC000, 0x384F0000, 0x384F4000, 0x384F8000, 0x384FC000,
  0x38500000, 0x38504000, 0x38508000, 0x3850C000, 0x38510000, 0x38514000, 0x38518000, 0x3851C000, 0x38520000, 0x38524000, 0x38528000, 0x3852C000, 0x38530000, 0x38534000, 0x38538000, 0x3853C000,
  0x38540000, 0x38544000, 0x38548000, 0x3854C000, 0x38550000, 0x38554000, 0x38558000, 0x3855C000, 0x38560000, 0x38564000, 0x38568000, 0x3856C000, 0x38570000, 0x38574000, 0x38578000, 0x3857C000,
  0x38580000, 0x38584000, 0x38588000, 0x3858C000, 0x38590000, 0x38594000, 0x38598000, 0x3859C000, 0x385A0000, 0x385A4000, 0x385A8000, 0x385AC000, 0x385B0000, 0x385B4000, 0x385B8000, 0x385BC000,
  0x385C0000, 0x385C4000, 0x385C8000, 0x385CC000, 0x385D0000, 0x385D4000, 0x385D8000, 0x385DC000, 0x385E0000, 0x385E4000, 0x385E8000, 0x385EC000, 0x385F0000, 0x385F4000, 0x385F8000, 0x385FC000,
  0x38600000, 0x38604000, 0x38608000, 0x3860C000, 0x38610000, 0x38614000, 0x38618000, 0x3861C000, 0x38620000, 0x38624000, 0x38628000, 0x3862C000, 0x38630000, 0x38634000, 0x38638000, 0x3863C000,
  0x38640000, 0x38644000, 0x38648000, 0x3864C000, 0x38650000, 0x38654000, 0x38658000, 0x3865C000, 0x38660000, 0x38664000, 0x38668000, 0x3866C000, 0x38670000, 0x38674000, 0x38678000, 0x3867C000,
  0x38680000, 0x38684000, 0x38688000, 0x3868C000, 0x38690000, 0x38694000, 0x38698000, 0x3869C000, 0x386A0000, 0x386A4000, 0x386A8000, 0x386AC000, 0x386B0000, 0x386B4000, 0x386B8000, 0x386BC000,
  0x386C0000, 0x386C4000, 0x386C8000, 0x386CC000, 0x386D0000, 0x386D4000, 0x386D8000, 0x386DC000, 0x386E0000, 0x386E4000, 0x386E8000, 0x386EC000, 0x386F0000, 0x386F4000, 0x386F8000, 0x386FC000,
  0x38700000, 0x38704000, 0x38708000, 0x3870C000, 0x38710000, 0x38714000, 0x38718000, 0x3871C000, 0x38720000, 0x38724000, 0x38728000, 0x3872C000, 0x38730000, 0x38734000, 0x38738000, 0x3873C000,
  0x38740000, 0x38744000, 0x38748000, 0x3874C000, 0x38750000, 0x38754000, 0x38758000, 0x3875C000, 0x38760000, 0x38764000, 0x38768000, 0x3876C000, 0x38770000, 0x38774000, 0x38778000, 0x3877C000,
  0x38780000, 0x38784000, 0x38788000, 0x3878C000, 0x38790000, 0x38794000, 0x38798000, 0x3879C000, 0x387A0000, 0x387A4000, 0x387A8000, 0x387AC000, 0x387B0000, 0x387B4000, 0x387B8000, 0x387BC000,
  0x387C0000, 0x387C4000, 0x387C8000, 0x387CC000, 0x387D0000, 0x387D4000, 0x387D8000, 0x387DC000, 0x387E0000, 0x387E4000, 0x387E8000, 0x387EC000, 0x387F0000, 0x387F4000, 0x387F8000, 0x387FC000,
  0x38000000, 0x38002000, 0x38004000, 0x38006000, 0x38008000, 0x3800A000, 0x3800C000, 0x3800E000, 0x38010000, 0x38012000, 0x38014000, 0x38016000, 0x38018000, 0x3801A000, 0x3801C000, 0x3801E000,
  0x38020000, 0x38022000, 0x38024000, 0x38026000, 0x38028000, 0x3802A000, 0x3802C000, 0x3802E000, 0x38030000, 0x38032000, 0x38034000, 0x38036000, 0x38038000, 0x3803A000, 0x3803C000, 0x3803E000,
  0x38040000, 0x38042000, 0x38044000, 0x38046000, 0x38048000, 0x3804A000, 0x3804C000, 0x3804E000, 0x38050000, 0x38052000, 0x38054000, 0x38056000, 0x38058000, 0x3805A000, 0x3805C000, 0x3805E000,
  0x38060000, 0x38062000, 0x38064000, 0x38066000, 0x38068000, 0x3806A000, 0x3806C000, 0x3806E000, 0x38070000, 0x38072000, 0x38074000, 0x38076000, 0x38078000, 0x3807A000, 0x3807C000, 0x3807E000,
  0x38080000, 0x38082000, 0x38084000, 0x38086000, 0x38088000, 0x3808A000, 0x3808C000, 0x3808E000, 0x38090000, 0x38092000, 0x38094000, 0x38096000, 0x38098000, 0x3809A000, 0x3809C000, 0x3809E000,
  0x380A0000, 0x380A2000, 0x380A4000, 0x380A6000, 0x380A8000, 0x380AA000, 0x380AC000, 0x380AE000, 0x380B0000, 0x380B2000, 0x380B4000, 0x380B6000, 0x380B8000, 0x380BA000, 0x380BC000, 0x380BE000,
  0x380C0000, 0x380C2000, 0x380C4000, 0x380C6000, 0x380C8000, 0x380CA000, 0x380CC000, 0x380CE000, 0x380D0000, 0x380D2000, 0x380D4000, 0x380D6000, 0x380D8000, 0x380DA000, 0x380DC000, 0x380DE000,
  0x380E0000, 0x380E2000, 0x380E4000, 0x380E6000, 0x380E8000, 0x380EA000, 0x380EC000, 0x380EE000, 0x380F0000, 0x380F2000, 0x380F4000, 0x380F6000, 0x380F8000, 0x380FA000, 0x380FC000, 0x380FE000,
  0x38100000, 0x38102000, 0x38104000, 0x38106000, 0x38108000, 0x3810A000, 0x3810C000, 0x3810E000, 0x38110000, 0x38112000, 0x38114000, 0x38116000, 0x38118000, 0x3811A000, 0x3811C000, 0x3811E000,
  0x38120000, 0x38122000, 0x38124000, 0x38126000, 0x38128000, 0x3812A000, 0x3812C000, 0x3812E000, 0x38130000, 0x38132000, 0x38134000, 0x38136000, 0x38138000, 0x3813A000, 0x3813C000, 0x3813E000,
  0x38140000, 0x38142000, 0x38144000, 0x38146000, 0x38148000, 0x3814A000, 0x3814C000, 0x3814E000, 0x38150000, 0x38152000, 0x38154000, 0x38156000, 0x38158000, 0x3815A000, 0x3815C000, 0x3815E000,
  0x38160000, 0x38162000, 0x38164000, 0x38166000, 0x38168000, 0x3816A000, 0x3816C000, 0x3816E000, 0x38170000, 0x38172000, 0x38174000, 0x38176000, 0x38178000, 0x3817A000, 0x3817C000, 0x3817E000,
  0x38180000, 0x38182000, 0x38184000, 0x38186000, 0x38188000, 0x3818A000, 0x3818C000, 0x3818E000, 0x38190000, 0x38192000, 0x38194000, 0x38196000, 0x38198000, 0x3819A000, 0x3819C000, 0x3819E000,
  0x381A0000, 0x381A2000, 0x381A4000, 0x381A6000, 0x381A8000, 0x381AA000, 0x381AC000, 0x381AE000, 0x381B0000, 0x381B2000, 0x381B4000, 0x381B6000, 0x381B8000, 0x381BA000, 0x381BC000, 0x381BE000,
  0x381C0000, 0x381C2000, 0x381C4000, 0x381C6000, 0x381C8000, 0x381CA000, 0x381CC000, 0x381CE000, 0x381D0000, 0x381D2000, 0x381D4000, 0x381D6000, 0x381D8000, 0x381DA000, 0x381DC000, 0x381DE000,
  0x381E0000, 0x381E2000, 0x381E4000, 0x381E6000, 0x381E8000, 0x381EA000, 0x381EC000, 0x381EE000, 0x381F0000, 0x381F2000, 0x381F4000, 0x381F6000, 0x381F8000, 0x381FA000, 0x381FC000, 0x381FE000,
  0x38200000, 0x38202000, 0x38204000, 0x38206000, 0x38208000, 0x3820A000, 0x3820C000, 0x3820E000, 0x38210000, 0x38212000, 0x38214000, 0x38216000, 0x38218000, 0x3821A000, 0x3821C000, 0x3821E000,
  0x38220000, 0x38222000, 0x38224000, 0x38226000, 0x38228000, 0x3822A000, 0x3822C000, 0x3822E000, 0x38230000, 0x38232000, 0x38234000, 0x38236000, 0x38238000, 0x3823A000, 0x3823C000, 0x3823E000,
  0x38240000, 0x38242000, 0x38244000, 0x38246000, 0x38248000, 0x3824A000, 0x3824C000, 0x3824E000, 0x38250000, 0x38252000, 0x38254000, 0x38256000, 0x38258000, 0x3825A000, 0x3825C000, 0x3825E000,
  0x38260000, 0x38262000, 0x38264000, 0x38266000, 0x38268000, 0x3826A000, 0x3826C000, 0x3826E000, 0x38270000, 0x38272000, 0x38274000, 0x38276000, 0x38278000, 0x3827A000, 0x3827C000, 0x3827E000,
  0x38280000, 0x38282000, 0x38284000, 0x38286000, 0x38288000, 0x3828A000, 0x3828C000, 0x3828E000, 0x38290000, 0x38292000, 0x38294000, 0x38296000, 0x38298000, 0x3829A000, 0x3829C000, 0x3829E000,
  0x382A0000, 0x382A2000, 0x382A4000, 0x382A6000, 0x382A8000, 0x382AA000, 0x382AC000, 0x382AE000, 0x382B0000, 0x382B2000, 0x382B4000, 0x382B6000, 0x382B8000, 0x382BA000, 0x382BC000, 0x382BE000,
  0x382C0000, 0x382C2000, 0x382C4000, 0x382C6000, 0x382C8000, 0x382CA000, 0x382CC000, 0x382CE000, 0x382D0000, 0x382D2000, 0x382D4000, 0x382D6000, 0x382D8000, 0x382DA000, 0x382DC000, 0x382DE000,
  0x382E0000, 0x382E2000, 0x382E4000, 0x382E6000, 0x382E8000, 0x382EA000, 0x382EC000, 0x382EE000, 0x382F0000, 0x382F2000, 0x382F4000, 0x382F6000, 0x382F8000, 0x382FA000, 0x382FC000, 0x382FE000,
  0x38300000, 0x38302000, 0x38304000, 0x38306000, 0x38308000, 0x3830A000, 0x3830C000, 0x3830E000, 0x38310000, 0x38312000, 0x38314000, 0x38316000, 0x38318000, 0x3831A000, 0x3831C000, 0x3831E000,
  0x38320000, 0x38322000, 0x38324000, 0x38326000, 0x38328000, 0x3832A000, 0x3832C000, 0x3832E000, 0x38330000, 0x38332000, 0x38334000, 0x38336000, 0x38338000, 0x3833A000, 0x3833C000, 0x3833E000,
  0x38340000, 0x38342000, 0x38344000, 0x38346000, 0x38348000, 0x3834A000, 0x3834C000, 0x3834E000, 0x38350000, 0x38352000, 0x38354000, 0x38356000, 0x38358000, 0x3835A000, 0x3835C000, 0x3835E000,
  0x38360000, 0x38362000, 0x38364000, 0x38366000, 0x38368000, 0x3836A000, 0x3836C000, 0x3836E000, 0x38370000, 0x38372000, 0x38374000, 0x38376000, 0x38378000, 0x3837A000, 0x3837C000, 0x3837E000,
  0x38380000, 0x38382000, 0x38384000, 0x38386000, 0x38388000, 0x3838A000, 0x3838C000, 0x3838E000, 0x38390000, 0x38392000, 0x38394000, 0x38396000, 0x38398000, 0x3839A000, 0x3839C000, 0x3839E000,
  0x383A0000, 0x383A2000, 0x383A4000, 0x383A6000, 0x383A8000, 0x383AA000, 0x383AC000, 0x383AE000, 0x383B0000, 0x383B2000, 0x383B4000, 0x383B6000, 0x383B8000, 0x383BA000, 0x383BC000, 0x383BE000,
  0x383C0000, 0x383C2000, 0x383C4000, 0x383C6000, 0x383C8000, 0x383CA000, 0x383CC000, 0x383CE000, 0x383D0000, 0x383D2000, 0x383D4000, 0x383D6000, 0x383D8000, 0x383DA000, 0x383DC000, 0x383DE000,
  0x383E0000, 0x383E2000, 0x383E4000, 0x383E6000, 0x383E8000, 0x383EA000, 0x383EC000, 0x383EE000, 0x383F0000, 0x383F2000, 0x383F4000, 0x383F6000, 0x383F8000, 0x383FA000, 0x383FC000, 0x383FE000,
  0x38400000, 0x38402000, 0x38404000, 0x38406000, 0x38408000, 0x3840A000, 0x3840C000, 0x3840E000, 0x38410000, 0x38412000, 0x38414000, 0x38416000, 0x38418000, 0x3841A000, 0x3841C000, 0x3841E000,
  0x38420000, 0x38422000, 0x38424000, 0x38426000, 0x38428000, 0x3842A000, 0x3842C000, 0x3842E000, 0x38430000, 0x38432000, 0x38434000, 0x38436000, 0x38438000, 0x3843A000, 0x3843C000, 0x3843E000,
  0x38440000, 0x38442000, 0x38444000, 0x38446000, 0x38448000, 0x3844A000, 0x3844C000, 0x3844E000, 0x38450000, 0x38452000, 0x38454000, 0x38456000, 0x38458000, 0x3845A000, 0x3845C000, 0x3845E000,
  0x38460000, 0x38462000, 0x38464000, 0x38466000, 0x38468000, 0x3846A000, 0x3846C000, 0x3846E000, 0x38470000, 0x38472000, 0x38474000, 0x38476000, 0x38478000, 0x3847A000, 0x3847C000, 0x3847E000,
  0x38480000, 0x38482000, 0x38484000, 0x38486000, 0x38488000, 0x3848A000, 0x3848C000, 0x3848E000, 0x38490000, 0x38492000, 0x38494000, 0x38496000, 0x38498000, 0x3849A000, 0x3849C000, 0x3849E000,
  0x384A0000, 0x384A2000, 0x384A4000, 0x384A6000, 0x384A8000, 0x384AA000, 0x384AC000, 0x384AE000, 0x384B0000, 0x384B2000, 0x384B4000, 0x384B6000, 0x384B8000, 0x384BA000, 0x384BC000, 0x384BE000,
  0x384C0000, 0x384C2000, 0x384C4000, 0x384C6000, 0x384C8000, 0x384CA000, 0x384CC000, 0x384CE000, 0x384D0000, 0x384D2000, 0x384D4000, 0x384D6000, 0x384D8000, 0x384DA000, 0x384DC000, 0x384DE000,
  0x384E0000, 0x384E2000, 0x384E4000, 0x384E6000, 0x384E8000, 0x384EA000, 0x384EC000, 0x384EE000, 0x384F0000, 0x384F2000, 0x384F4000, 0x384F6000, 0x384F8000, 0x384FA000, 0x384FC000, 0x384FE000,
  0x38500000, 0x38502000, 0x38504000, 0x38506000, 0x38508000, 0x3850A000, 0x3850C000, 0x3850E000, 0x38510000, 0x38512000, 0x38514000, 0x38516000, 0x38518000, 0x3851A000, 0x3851C000, 0x3851E000,
  0x38520000, 0x38522000, 0x38524000, 0x38526000, 0x38528000, 0x3852A000, 0x3852C000, 0x3852E000, 0x38530000, 0x38532000, 0x38534000, 0x38536000, 0x38538000, 0x3853A000, 0x3853C000, 0x3853E000,
  0x38540000, 0x38542000, 0x38544000, 0x38546000, 0x38548000, 0x3854A000, 0x3854C000, 0x3854E000, 0x38550000, 0x38552000, 0x38554000, 0x38556000, 0x38558000, 0x3855A000, 0x3855C000, 0x3855E000,
  0x38560000, 0x38562000, 0x38564000, 0x38566000, 0x38568000, 0x3856A000, 0x3856C000, 0x3856E000, 0x38570000, 0x38572000, 0x38574000, 0x38576000, 0x38578000, 0x3857A000, 0x3857C000, 0x3857E000,
  0x38580000, 0x38582000, 0x38584000, 0x38586000, 0x38588000, 0x3858A000, 0x3858C000, 0x3858E000, 0x38590000, 0x38592000, 0x38594000, 0x38596000, 0x38598000, 0x3859A000, 0x3859C000, 0x3859E000,
  0x385A0000, 0x385A2000, 0x385A4000, 0x385A6000, 0x385A8000, 0x385AA000, 0x385AC000, 0x385AE000, 0x385B0000, 0x385B2000, 0x385B4000, 0x385B6000, 0x385B8000, 0x385BA000, 0x385BC000, 0x385BE000,
  0x385C0000, 0x385C2000, 0x385C4000, 0x385C6000, 0x385C8000, 0x385CA000, 0x385CC000, 0x385CE000, 0x385D0000, 0x385D2000, 0x385D4000, 0x385D6000, 0x385D8000, 0x385DA000, 0x385DC000, 0x385DE000,
  0x385E0000, 0x385E2000, 0x385E4000, 0x385E6000, 0x385E8000, 0x385EA000, 0x385EC000, 0x385EE000, 0x385F0000, 0x385F2000, 0x385F4000, 0x385F6000, 0x385F8000, 0x385FA000, 0x385FC000, 0x385FE000,
  0x38600000, 0x38602000, 0x38604000, 0x38606000, 0x38608000, 0x3860A000, 0x3860C000, 0x3860E000, 0x38610000, 0x38612000, 0x38614000, 0x38616000, 0x38618000, 0x3861A000, 0x3861C000, 0x3861E000,
  0x38620000, 0x38622000, 0x38624000, 0x38626000, 0x38628000, 0x3862A000, 0x3862C000, 0x3862E000, 0x38630000, 0x38632000, 0x38634000, 0x38636000, 0x38638000, 0x3863A000, 0x3863C000, 0x3863E000,
  0x38640000, 0x38642000, 0x38644000, 0x38646000, 0x38648000, 0x3864A000, 0x3864C000, 0x3864E000, 0x38650000, 0x38652000, 0x38654000, 0x38656000, 0x38658000, 0x3865A000, 0x3865C000, 0x3865E000,
  0x38660000, 0x38662000, 0x38664000, 0x38666000, 0x38668000, 0x3866A000, 0x3866C000, 0x3866E000, 0x38670000, 0x38672000, 0x38674000, 0x38676000, 0x38678000, 0x3867A000, 0x3867C000, 0x3867E000,
  0x38680000, 0x38682000, 0x38684000, 0x38686000, 0x38688000, 0x3868A000, 0x3868C000, 0x3868E000, 0x38690000, 0x38692000, 0x38694000, 0x38696000, 0x38698000, 0x3869A000, 0x3869C000, 0x3869E000,
  0x386A0000, 0x386A2000, 0x386A4000, 0x386A6000, 0x386A8000, 0x386AA000, 0x386AC000, 0x386AE000, 0x386B0000, 0x386B2000, 0x386B4000, 0x386B6000, 0x386B8000, 0x386BA000, 0x386BC000, 0x386BE000,
  0x386C0000, 0x386C2000, 0x386C4000, 0x386C6000, 0x386C8000, 0x386CA000, 0x386CC000, 0x386CE000, 0x386D0000, 0x386D2000, 0x386D4000, 0x386D6000, 0x386D8000, 0x386DA000, 0x386DC000, 0x386DE000,
  0x386E0000, 0x386E2000, 0x386E4000, 0x386E6000, 0x386E8000, 0x386EA000, 0x386EC000, 0x386EE000, 0x386F0000, 0x386F2000, 0x386F4000, 0x386F6000, 0x386F8000, 0x386FA000, 0x386FC000, 0x386FE000,
  0x38700000, 0x38702000, 0x38704000, 0x38706000, 0x38708000, 0x3870A000, 0x3870C000, 0x3870E000, 0x38710000, 0x38712000, 0x38714000, 0x38716000, 0x38718000, 0x3871A000, 0x3871C000, 0x3871E000,
  0x38720000, 0x38722000, 0x38724000, 0x38726000, 0x38728000, 0x3872A000, 0x3872C000, 0x3872E000, 0x38730000, 0x38732000, 0x38734000, 0x38736000, 0x38738000, 0x3873A000, 0x3873C000, 0x3873E000,
  0x38740000, 0x38742000, 0x38744000, 0x38746000, 0x38748000, 0x3874A000, 0x3874C000, 0x3874E000, 0x38750000, 0x38752000, 0x38754000, 0x38756000, 0x38758000, 0x3875A000, 0x3875C000, 0x3875E000,
  0x38760000, 0x38762000, 0x38764000, 0x38766000, 0x38768000, 0x3876A000, 0x3876C000, 0x3876E000, 0x38770000, 0x38772000, 0x38774000, 0x38776000, 0x38778000, 0x3877A000, 0x3877C000, 0x3877E000,
  0x38780000, 0x38782000, 0x38784000, 0x38786000, 0x38788000, 0x3878A000, 0x3878C000, 0x3878E000, 0x38790000, 0x38792000, 0x38794000, 0x38796000, 0x38798000, 0x3879A000, 0x3879C000, 0x3879E000,
  0x387A0000, 0x387A2000, 0x387A4000, 0x387A6000, 0x387A8000, 0x387AA000, 0x387AC000, 0x387AE000, 0x387B0000, 0x387B2000, 0x387B4000, 0x387B6000, 0x387B8000, 0x387BA000, 0x387BC000, 0x387BE000,
  0x387C0000, 0x387C2000, 0x387C4000, 0x387C6000, 0x387C8000, 0x387CA000, 0x387CC000, 0x387CE000, 0x387D0000, 0x387D2000, 0x387D4000, 0x387D6000, 0x387D8000, 0x387DA000, 0x387DC000, 0x387DE000,
  0x387E0000, 0x387E2000, 0x387E4000, 0x387E6000, 0x387E8000, 0x387EA000, 0x387EC000, 0x387EE000, 0x387F0000, 0x387F2000, 0x387F4000, 0x387F6000, 0x387F8000, 0x387FA000, 0x387FC000, 0x387FE000 };
__constant static const uint32_t exponent_table[64] = {
  0x00000000, 0x00800000, 0x01000000, 0x01800000, 0x02000000, 0x02800000, 0x03000000, 0x03800000, 0x04000000, 0x04800000, 0x05000000, 0x05800000, 0x06000000, 0x06800000, 0x07000000, 0x07800000,
  0x08000000, 0x08800000, 0x09000000, 0x09800000, 0x0A000000, 0x0A800000, 0x0B000000, 0x0B800000, 0x0C000000, 0x0C800000, 0x0D000000, 0x0D800000, 0x0E000000, 0x0E800000, 0x0F000000, 0x47800000,
  0x80000000, 0x80800000, 0x81000000, 0x81800000, 0x82000000, 0x82800000, 0x83000000, 0x83800000, 0x84000000, 0x84800000, 0x85000000, 0x85800000, 0x86000000, 0x86800000, 0x87000000, 0x87800000,
  0x88000000, 0x88800000, 0x89000000, 0x89800000, 0x8A000000, 0x8A800000, 0x8B000000, 0x8B800000, 0x8C000000, 0x8C800000, 0x8D000000, 0x8D800000, 0x8E000000, 0x8E800000, 0x8F000000, 0xC7800000 };
__constant static const unsigned short offset_table[64] = {
  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024,
  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024 };

SCALAR_FUN_ATTR uint16_t float2halfbits(float value) {
  union { float x; uint32_t y; } u;
  u.x = value;
  uint32_t bits = u.y;

  uint16_t hbits = base_table[bits>>23] + (uint16_t)((bits&0x7FFFFF)>>shift_table[bits>>23]);;

  return hbits;
}

SCALAR_FUN_ATTR float halfbits2float(uint16_t value) {
  uint32_t bits = mantissa_table[offset_table[value>>10]+(value&0x3FF)] + exponent_table[value>>10];

  union { uint32_t x; float y; } u;
  u.x = bits;
  return u.y;
}

SCALAR_FUN_ATTR uint16_t halfbitsnextafter(uint16_t from, uint16_t to) {
  int fabs = from & 0x7FFF, tabs = to & 0x7FFF;
  if(fabs > 0x7C00 || tabs > 0x7C00) {
    return ((from&0x7FFF)>0x7C00) ? (from|0x200) : (to|0x200);
  }
  if(from == to || !(fabs|tabs)) {
    return to;
  }
  if(!fabs) {
    return (to&0x8000)+1;
  }
  unsigned int out =
    from +
    (((from>>15)^(unsigned int)((from^(0x8000|(0x8000-(from>>15))))<(to^(0x8000|(0x8000-(to>>15))))))<<1)
    - 1;
  return out;
}

// End of half.h.
// Start of timing.h.

// The function get_wall_time() returns the wall time in microseconds
// (with an unspecified offset).

#ifdef _WIN32

#include <windows.h>

static int64_t get_wall_time(void) {
  LARGE_INTEGER time,freq;
  assert(QueryPerformanceFrequency(&freq));
  assert(QueryPerformanceCounter(&time));
  return ((double)time.QuadPart / freq.QuadPart) * 1000000;
}

static int64_t get_wall_time_ns(void) {
  return get_wall_time() * 1000;
}

#else
// Assuming POSIX

#include <time.h>
#include <sys/time.h>

static int64_t get_wall_time(void) {
  struct timeval time;
  assert(gettimeofday(&time,NULL) == 0);
  return time.tv_sec * 1000000 + time.tv_usec;
}

static int64_t get_wall_time_ns(void) {
  struct timespec time;
  assert(clock_gettime(CLOCK_REALTIME, &time) == 0);
  return time.tv_sec * 1000000000 + time.tv_nsec;
}

#endif

// End of timing.h.
// Start of lock.h.

// A very simple cross-platform implementation of locks.  Uses
// pthreads on Unix and some Windows thing there.  Futhark's
// host-level code is not multithreaded, but user code may be, so we
// need some mechanism for ensuring atomic access to API functions.
// This is that mechanism.  It is not exposed to user code at all, so
// we do not have to worry about name collisions.

#ifdef _WIN32

typedef HANDLE lock_t;

static void create_lock(lock_t *lock) {
  *lock = CreateMutex(NULL,  // Default security attributes.
                      FALSE, // Initially unlocked.
                      NULL); // Unnamed.
}

static void lock_lock(lock_t *lock) {
  assert(WaitForSingleObject(*lock, INFINITE) == WAIT_OBJECT_0);
}

static void lock_unlock(lock_t *lock) {
  assert(ReleaseMutex(*lock));
}

static void free_lock(lock_t *lock) {
  CloseHandle(*lock);
}

#else
// Assuming POSIX

#include <pthread.h>

typedef pthread_mutex_t lock_t;

static void create_lock(lock_t *lock) {
  int r = pthread_mutex_init(lock, NULL);
  assert(r == 0);
}

static void lock_lock(lock_t *lock) {
  int r = pthread_mutex_lock(lock);
  assert(r == 0);
}

static void lock_unlock(lock_t *lock) {
  int r = pthread_mutex_unlock(lock);
  assert(r == 0);
}

static void free_lock(lock_t *lock) {
  // Nothing to do for pthreads.
  (void)lock;
}

#endif

// End of lock.h.
// Start of free_list.h.

typedef uintptr_t fl_mem;

// An entry in the free list.  May be invalid, to avoid having to
// deallocate entries as soon as they are removed.  There is also a
// tag, to help with memory reuse.
struct free_list_entry {
  size_t size;
  fl_mem mem;
  const char *tag;
  unsigned char valid;
};

struct free_list {
  struct free_list_entry *entries; // Pointer to entries.
  int capacity;                    // Number of entries.
  int used;                        // Number of valid entries.
  lock_t lock;                     // Thread safety.
};

static void free_list_init(struct free_list *l) {
  l->capacity = 30; // Picked arbitrarily.
  l->used = 0;
  l->entries = (struct free_list_entry*) malloc(sizeof(struct free_list_entry) * l->capacity);
  for (int i = 0; i < l->capacity; i++) {
    l->entries[i].valid = 0;
  }
  create_lock(&l->lock);
}

// Remove invalid entries from the free list.
static void free_list_pack(struct free_list *l) {
  lock_lock(&l->lock);
  int p = 0;
  for (int i = 0; i < l->capacity; i++) {
    if (l->entries[i].valid) {
      l->entries[p] = l->entries[i];
      if (i > p) {
        l->entries[i].valid = 0;
      }
      p++;
    }
  }

  // Now p is the number of used elements.  We don't want it to go
  // less than the default capacity (although in practice it's OK as
  // long as it doesn't become 1).
  if (p < 30) {
    p = 30;
  }
  l->entries = realloc(l->entries, p * sizeof(struct free_list_entry));
  l->capacity = p;
  lock_unlock(&l->lock);
}

static void free_list_destroy(struct free_list *l) {
  assert(l->used == 0);
  free(l->entries);
  free_lock(&l->lock);
}

// Not part of the interface, so no locking.
static int free_list_find_invalid(struct free_list *l) {
  int i;
  for (i = 0; i < l->capacity; i++) {
    if (!l->entries[i].valid) {
      break;
    }
  }
  return i;
}

static void free_list_insert(struct free_list *l, size_t size, fl_mem mem, const char *tag) {
  lock_lock(&l->lock);
  int i = free_list_find_invalid(l);

  if (i == l->capacity) {
    // List is full; so we have to grow it.
    int new_capacity = l->capacity * 2 * sizeof(struct free_list_entry);
    l->entries = realloc(l->entries, new_capacity);
    for (int j = 0; j < l->capacity; j++) {
      l->entries[j+l->capacity].valid = 0;
    }
    l->capacity *= 2;
  }

  // Now 'i' points to the first invalid entry.
  l->entries[i].valid = 1;
  l->entries[i].size = size;
  l->entries[i].mem = mem;
  l->entries[i].tag = tag;

  l->used++;
  lock_unlock(&l->lock);
}

// Determine whether this entry in the free list is acceptable for
// satisfying the request.  Not public, so no locking.
static bool free_list_acceptable(size_t size, const char* tag, struct free_list_entry *entry) {
  // We check not just the hard requirement (is the entry acceptable
  // and big enough?) but also put a cap on how much wasted space
  // (internal fragmentation) we allow.  This is necessarily a
  // heuristic, and a crude one.

  if (!entry->valid) {
    return false;
  }

  if (size > entry->size) {
    return false;
  }

  // We know the block fits.  Now the question is whether it is too
  // big.  Our policy is as follows:
  //
  // 1) We don't care about wasted space below 4096 bytes (to avoid
  // churn in tiny allocations).
  //
  // 2) If the tag matches, we allow _any_ amount of wasted space.
  //
  // 3) Otherwise we allow up to 50% wasted space.

  if (entry->size < 4096) {
    return true;
  }

  if (entry->tag == tag) {
    return true;
  }

  if (entry->size < size * 2) {
    return true;
  }

  return false;
}

// Find and remove a memory block of the indicated tag, or if that
// does not exist, another memory block with exactly the desired size.
// Returns 0 on success.
static int free_list_find(struct free_list *l, size_t size, const char *tag,
                          size_t *size_out, fl_mem *mem_out) {
  lock_lock(&l->lock);
  int size_match = -1;
  int i;
  int ret = 1;
  for (i = 0; i < l->capacity; i++) {
    if (free_list_acceptable(size, tag, &l->entries[i]) &&
        (size_match < 0 || l->entries[i].size < l->entries[size_match].size)) {
      // If this entry is valid, has sufficient size, and is smaller than the
      // best entry found so far, use this entry.
      size_match = i;
    }
  }

  if (size_match >= 0) {
    l->entries[size_match].valid = 0;
    *size_out = l->entries[size_match].size;
    *mem_out = l->entries[size_match].mem;
    l->used--;
    ret = 0;
  }
  lock_unlock(&l->lock);
  return ret;
}

// Remove the first block in the free list.  Returns 0 if a block was
// removed, and nonzero if the free list was already empty.
static int free_list_first(struct free_list *l, fl_mem *mem_out) {
  lock_lock(&l->lock);
  int ret = 1;
  for (int i = 0; i < l->capacity; i++) {
    if (l->entries[i].valid) {
      l->entries[i].valid = 0;
      *mem_out = l->entries[i].mem;
      l->used--;
      ret = 0;
      break;
    }
  }
  lock_unlock(&l->lock);
  return ret;
}

// End of free_list.h.
// Start of event_list.h

typedef int (*event_report_fn)(struct str_builder*, void*);

struct event {
  void* data;
  event_report_fn f;
  const char* name;
  char *description;
};

struct event_list {
  struct event *events;
  int num_events;
  int capacity;
};

static void event_list_init(struct event_list *l) {
  l->capacity = 100;
  l->num_events = 0;
  l->events = calloc(l->capacity, sizeof(struct event));
}

static void event_list_free(struct event_list *l) {
  free(l->events);
}

static void add_event_to_list(struct event_list *l,
                              const char* name,
                              char* description,
                              void* data,
                              event_report_fn f) {
  if (l->num_events == l->capacity) {
    l->capacity *= 2;
    l->events = realloc(l->events, l->capacity * sizeof(struct event));
  }
  l->events[l->num_events].name = name;
  l->events[l->num_events].description = description;
  l->events[l->num_events].data = data;
  l->events[l->num_events].f = f;
  l->num_events++;
}

static int report_events_in_list(struct event_list *l,
                                 struct str_builder* sb) {
  int ret = 0;
  for (int i = 0; i < l->num_events; i++) {
    if (i != 0) {
      str_builder_str(sb, ",");
    }
    str_builder_str(sb, "{\"name\":");
    str_builder_json_str(sb, l->events[i].name);
    str_builder_str(sb, ",\"description\":");
    str_builder_json_str(sb, l->events[i].description);
    free(l->events[i].description);
    if (l->events[i].f(sb, l->events[i].data) != 0) {
      ret = 1;
      break;
    }
    str_builder(sb, "}");
  }
  event_list_free(l);
  event_list_init(l);
  return ret;
}

// End of event_list.h

#ifdef _MSC_VER
#define inline __inline
#endif
#include <string.h>
#include <string.h>
#include <errno.h>
#include <assert.h>
#include <ctype.h>


#include <cuda.h>
#include <cuda_runtime.h>
#include <nvrtc.h>


#define FUTHARK_F64_ENABLED

// Start of scalar.h.

// Implementation of the primitive scalar operations.  Very
// repetitive.  This code is inserted directly into both CUDA and
// OpenCL programs, as well as the CPU code, so it has some #ifdefs to
// work everywhere.  Some operations are defined as macros because
// this allows us to use them as constant expressions in things like
// array sizes and static initialisers.

// Some of the #ifdefs are because OpenCL uses type-generic functions
// for some operations (e.g. sqrt), while C and CUDA sensibly use
// distinct functions for different precisions (e.g. sqrtf() and
// sqrt()).  This is quite annoying.  Due to C's unfortunate casting
// rules, it is also really easy to accidentally implement
// floating-point functions in the wrong precision, so be careful.

// Double-precision definitions are only included if the preprocessor
// macro FUTHARK_F64_ENABLED is set.

SCALAR_FUN_ATTR int32_t futrts_to_bits32(float x);
SCALAR_FUN_ATTR float futrts_from_bits32(int32_t x);

SCALAR_FUN_ATTR uint8_t add8(uint8_t x, uint8_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint16_t add16(uint16_t x, uint16_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint32_t add32(uint32_t x, uint32_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint64_t add64(uint64_t x, uint64_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint8_t sub8(uint8_t x, uint8_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint16_t sub16(uint16_t x, uint16_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint32_t sub32(uint32_t x, uint32_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint64_t sub64(uint64_t x, uint64_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint8_t mul8(uint8_t x, uint8_t y) {
  return x * y;
}

SCALAR_FUN_ATTR uint16_t mul16(uint16_t x, uint16_t y) {
  return x * y;
}

SCALAR_FUN_ATTR uint32_t mul32(uint32_t x, uint32_t y) {
  return x * y;
}

SCALAR_FUN_ATTR uint64_t mul64(uint64_t x, uint64_t y) {
  return x * y;
}

#if ISPC

SCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {
  // This strange pattern is used to prevent the ISPC compiler from
  // causing SIGFPEs and bogus results on divisions where inactive lanes
  // have 0-valued divisors. It ensures that any inactive lane instead
  // has a divisor of 1. https://github.com/ispc/ispc/issues/2292
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return x / ys;
}

SCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return x / ys;
}

SCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return x % ys;
}

SCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int8_t q = x / ys;
  int8_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int16_t q = x / ys;
  int16_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  int32_t q = x / ys;
  int32_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int64_t q = x / ys;
  int64_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {
  return sdiv8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {
  return sdiv16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {
  return sdiv32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {
  return sdiv64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int8_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int16_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int32_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int64_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : sdiv8(x, y);
}

SCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : sdiv16(x, y);
}

SCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : sdiv32(x, y);
}

SCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : sdiv64(x, y);
}

SCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {
  return sdiv_safe8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {
  return sdiv_safe16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {
  return sdiv_safe32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {
  return sdiv_safe64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : smod8(x, y);
}

SCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : smod16(x, y);
}

SCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : smod32(x, y);
}

SCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : smod64(x, y);
}

SCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

#else

SCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {
  int8_t q = x / y;
  int8_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {
  int16_t q = x / y;
  int16_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {
  int32_t q = x / y;
  int32_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {
  int64_t q = x / y;
  int64_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {
  return sdiv8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {
  return sdiv16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {
  return sdiv32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {
  return sdiv64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {
  int8_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {
  int16_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {
  int32_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {
  int64_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : sdiv8(x, y);
}

SCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : sdiv16(x, y);
}

SCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : sdiv32(x, y);
}

SCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : sdiv64(x, y);
}

SCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {
  return sdiv_safe8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {
  return sdiv_safe16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {
  return sdiv_safe32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {
  return sdiv_safe64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : smod8(x, y);
}

SCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : smod16(x, y);
}

SCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : smod32(x, y);
}

SCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : smod64(x, y);
}

SCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : x % y;
}

#endif

SCALAR_FUN_ATTR int8_t smin8(int8_t x, int8_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int16_t smin16(int16_t x, int16_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int32_t smin32(int32_t x, int32_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int64_t smin64(int64_t x, int64_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint8_t umin8(uint8_t x, uint8_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint16_t umin16(uint16_t x, uint16_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint32_t umin32(uint32_t x, uint32_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint64_t umin64(uint64_t x, uint64_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int8_t smax8(int8_t x, int8_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR int16_t smax16(int16_t x, int16_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR int32_t smax32(int32_t x, int32_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR int64_t smax64(int64_t x, int64_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint8_t umax8(uint8_t x, uint8_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint16_t umax16(uint16_t x, uint16_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint32_t umax32(uint32_t x, uint32_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint64_t umax64(uint64_t x, uint64_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint8_t shl8(uint8_t x, uint8_t y) {
  return (uint8_t)(x << y);
}

SCALAR_FUN_ATTR uint16_t shl16(uint16_t x, uint16_t y) {
  return (uint16_t)(x << y);
}

SCALAR_FUN_ATTR uint32_t shl32(uint32_t x, uint32_t y) {
  return x << y;
}

SCALAR_FUN_ATTR uint64_t shl64(uint64_t x, uint64_t y) {
  return x << y;
}

SCALAR_FUN_ATTR uint8_t lshr8(uint8_t x, uint8_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint16_t lshr16(uint16_t x, uint16_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint32_t lshr32(uint32_t x, uint32_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint64_t lshr64(uint64_t x, uint64_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int8_t ashr8(int8_t x, int8_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int16_t ashr16(int16_t x, int16_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int32_t ashr32(int32_t x, int32_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int64_t ashr64(int64_t x, int64_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint8_t and8(uint8_t x, uint8_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint16_t and16(uint16_t x, uint16_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint32_t and32(uint32_t x, uint32_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint64_t and64(uint64_t x, uint64_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint8_t or8(uint8_t x, uint8_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint16_t or16(uint16_t x, uint16_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint32_t or32(uint32_t x, uint32_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint64_t or64(uint64_t x, uint64_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint8_t xor8(uint8_t x, uint8_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR uint16_t xor16(uint16_t x, uint16_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR uint32_t xor32(uint32_t x, uint32_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR uint64_t xor64(uint64_t x, uint64_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR bool ult8(uint8_t x, uint8_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ult16(uint16_t x, uint16_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ult32(uint32_t x, uint32_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ult64(uint64_t x, uint64_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ule8(uint8_t x, uint8_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool ule16(uint16_t x, uint16_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool ule32(uint32_t x, uint32_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool ule64(uint64_t x, uint64_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool slt8(int8_t x, int8_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool slt16(int16_t x, int16_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool slt32(int32_t x, int32_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool slt64(int64_t x, int64_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool sle8(int8_t x, int8_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool sle16(int16_t x, int16_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool sle32(int32_t x, int32_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool sle64(int64_t x, int64_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR uint8_t pow8(uint8_t x, uint8_t y) {
  uint8_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint16_t pow16(uint16_t x, uint16_t y) {
  uint16_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint32_t pow32(uint32_t x, uint32_t y) {
  uint32_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint64_t pow64(uint64_t x, uint64_t y) {
  uint64_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR bool itob_i8_bool(int8_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR bool itob_i16_bool(int16_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR bool itob_i32_bool(int32_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR bool itob_i64_bool(int64_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR int8_t btoi_bool_i8(bool x) {
  return x;
}

SCALAR_FUN_ATTR int16_t btoi_bool_i16(bool x) {
  return x;
}

SCALAR_FUN_ATTR int32_t btoi_bool_i32(bool x) {
  return x;
}

SCALAR_FUN_ATTR int64_t btoi_bool_i64(bool x) {
  return x;
}

#define sext_i8_i8(x) ((int8_t) (int8_t) (x))
#define sext_i8_i16(x) ((int16_t) (int8_t) (x))
#define sext_i8_i32(x) ((int32_t) (int8_t) (x))
#define sext_i8_i64(x) ((int64_t) (int8_t) (x))
#define sext_i16_i8(x) ((int8_t) (int16_t) (x))
#define sext_i16_i16(x) ((int16_t) (int16_t) (x))
#define sext_i16_i32(x) ((int32_t) (int16_t) (x))
#define sext_i16_i64(x) ((int64_t) (int16_t) (x))
#define sext_i32_i8(x) ((int8_t) (int32_t) (x))
#define sext_i32_i16(x) ((int16_t) (int32_t) (x))
#define sext_i32_i32(x) ((int32_t) (int32_t) (x))
#define sext_i32_i64(x) ((int64_t) (int32_t) (x))
#define sext_i64_i8(x) ((int8_t) (int64_t) (x))
#define sext_i64_i16(x) ((int16_t) (int64_t) (x))
#define sext_i64_i32(x) ((int32_t) (int64_t) (x))
#define sext_i64_i64(x) ((int64_t) (int64_t) (x))
#define zext_i8_i8(x) ((int8_t) (uint8_t) (x))
#define zext_i8_i16(x) ((int16_t) (uint8_t) (x))
#define zext_i8_i32(x) ((int32_t) (uint8_t) (x))
#define zext_i8_i64(x) ((int64_t) (uint8_t) (x))
#define zext_i16_i8(x) ((int8_t) (uint16_t) (x))
#define zext_i16_i16(x) ((int16_t) (uint16_t) (x))
#define zext_i16_i32(x) ((int32_t) (uint16_t) (x))
#define zext_i16_i64(x) ((int64_t) (uint16_t) (x))
#define zext_i32_i8(x) ((int8_t) (uint32_t) (x))
#define zext_i32_i16(x) ((int16_t) (uint32_t) (x))
#define zext_i32_i32(x) ((int32_t) (uint32_t) (x))
#define zext_i32_i64(x) ((int64_t) (uint32_t) (x))
#define zext_i64_i8(x) ((int8_t) (uint64_t) (x))
#define zext_i64_i16(x) ((int16_t) (uint64_t) (x))
#define zext_i64_i32(x) ((int32_t) (uint64_t) (x))
#define zext_i64_i64(x) ((int64_t) (uint64_t) (x))

SCALAR_FUN_ATTR int8_t abs8(int8_t x) {
  return (int8_t)abs(x);
}

SCALAR_FUN_ATTR int16_t abs16(int16_t x) {
  return (int16_t)abs(x);
}

SCALAR_FUN_ATTR int32_t abs32(int32_t x) {
  return abs(x);
}

SCALAR_FUN_ATTR int64_t abs64(int64_t x) {
#if defined(__OPENCL_VERSION__) || defined(ISPC)
  return abs(x);
#else
  return llabs(x);
#endif
}

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {
  return popcount(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {
  return popcount(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {
  return popcount(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {
  return popcount(x);
}
#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {
  return __popc(zext_i8_i32(x));
}

SCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {
  return __popc(zext_i16_i32(x));
}

SCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {
  return __popc(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {
  return __popcll(x);
}

#else // Not OpenCL or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_popc8(uint8_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc16(uint16_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc32(uint32_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc64(uint64_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR uint8_t  futrts_umul_hi8 ( uint8_t a,  uint8_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint8_t  futrts_smul_hi8 ( int8_t a,  int8_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return mul_hi(a, b); }
#elif defined(__CUDA_ARCH__)
SCALAR_FUN_ATTR  uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return __umulhi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return __umul64hi(a, b); }
SCALAR_FUN_ATTR  uint8_t futrts_smul_hi8 ( int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return __mulhi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return __mul64hi(a, b); }
#elif ISPC
SCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) {
  uint64_t ah = a >> 32;
  uint64_t al = a & 0xffffffff;
  uint64_t bh = b >> 32;
  uint64_t bl = b & 0xffffffff;

  uint64_t p1 = al * bl;
  uint64_t p2 = al * bh;
  uint64_t p3 = ah * bl;
  uint64_t p4 = ah * bh;

  uint64_t p1h = p1 >> 32;
  uint64_t p2h = p2 >> 32;
  uint64_t p3h = p3 >> 32;
  uint64_t p2l = p2 & 0xffffffff;
  uint64_t p3l = p3 & 0xffffffff;

  uint64_t l = p1h + p2l + p3l;
  uint64_t m = (p2 >> 32) + (p3 >> 32);
  uint64_t h = (l >> 32) + m + p4;

  return h;
}
SCALAR_FUN_ATTR  int8_t futrts_smul_hi8 ( int8_t a,  int8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) {
  uint64_t ah = a >> 32;
  uint64_t al = a & 0xffffffff;
  uint64_t bh = b >> 32;
  uint64_t bl = b & 0xffffffff;

  uint64_t p1 =  al * bl;
  int64_t  p2 = al * bh;
  int64_t  p3 = ah * bl;
  uint64_t p4 =  ah * bh;

  uint64_t p1h = p1 >> 32;
  uint64_t p2h = p2 >> 32;
  uint64_t p3h = p3 >> 32;
  uint64_t p2l = p2 & 0xffffffff;
  uint64_t p3l = p3 & 0xffffffff;

  uint64_t l = p1h + p2l + p3l;
  uint64_t m = (p2 >> 32) + (p3 >> 32);
  uint64_t h = (l >> 32) + m + p4;

  return h;
}

#else // Not OpenCL, ISPC, or CUDA, but plain C.
SCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return ((__uint128_t)a) * ((__uint128_t)b) >> 64; }
SCALAR_FUN_ATTR int8_t futrts_smul_hi8(int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }
SCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }
SCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((int64_t)a) * ((int64_t)b) >> 32; }
SCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) { return ((__int128_t)a) * ((__int128_t)b) >> 64; }
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR  uint8_t futrts_umad_hi8 ( uint8_t a,  uint8_t b,  uint8_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR  uint8_t futrts_smad_hi8( int8_t a,  int8_t b,   int8_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return mad_hi(a, b, c); }
#else // Not OpenCL

SCALAR_FUN_ATTR  uint8_t futrts_umad_hi8( uint8_t a,  uint8_t b,  uint8_t c) { return futrts_umul_hi8(a, b) + c; }
SCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return futrts_umul_hi16(a, b) + c; }
SCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return futrts_umul_hi32(a, b) + c; }
SCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return futrts_umul_hi64(a, b) + c; }
SCALAR_FUN_ATTR  uint8_t futrts_smad_hi8 ( int8_t a,  int8_t b,  int8_t c) { return futrts_smul_hi8(a, b) + c; }
SCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return futrts_smul_hi16(a, b) + c; }
SCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return futrts_smul_hi32(a, b) + c; }
SCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return futrts_smul_hi64(a, b) + c; }
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return clz(x);
}

#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return __clz(zext_i8_i32(x)) - 24;
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return __clz(zext_i16_i32(x)) - 16;
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return __clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return __clzll(x);
}

#elif ISPC

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return count_leading_zeros((int32_t)(uint8_t)x)-24;
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return count_leading_zeros((int32_t)(uint16_t)x)-16;
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return count_leading_zeros(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return count_leading_zeros(x);
}

#else // Not OpenCL, ISPC or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return x == 0 ? 8 : __builtin_clz((uint32_t)zext_i8_i32(x)) - 24;
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return x == 0 ? 16 : __builtin_clz((uint32_t)zext_i16_i32(x)) - 16;
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return x == 0 ? 32 : __builtin_clz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return x == 0 ? 64 : __builtin_clzll((uint64_t)x);
}
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  int i = 0;
  for (; i < 8 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  int i = 0;
  for (; i < 16 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  int i = 0;
  for (; i < 32 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  int i = 0;
  for (; i < 64 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  int y = __ffs(x);
  return y == 0 ? 8 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  int y = __ffs(x);
  return y == 0 ? 16 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  int y = __ffs(x);
  return y == 0 ? 32 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  int y = __ffsll(x);
  return y == 0 ? 64 : y - 1;
}

#elif ISPC

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  return x == 0 ? 8 : count_trailing_zeros((int32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  return x == 0 ? 16 : count_trailing_zeros((int32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  return count_trailing_zeros(x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  return count_trailing_zeros(x);
}

#else // Not OpenCL or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  return x == 0 ? 8 : __builtin_ctz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  return x == 0 ? 16 : __builtin_ctz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  return x == 0 ? 32 : __builtin_ctz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  return x == 0 ? 64 : __builtin_ctzll((uint64_t)x);
}
#endif

SCALAR_FUN_ATTR float fdiv32(float x, float y) {
  return x / y;
}

SCALAR_FUN_ATTR float fadd32(float x, float y) {
  return x + y;
}

SCALAR_FUN_ATTR float fsub32(float x, float y) {
  return x - y;
}

SCALAR_FUN_ATTR float fmul32(float x, float y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt32(float x, float y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple32(float x, float y) {
  return x <= y;
}

SCALAR_FUN_ATTR float sitofp_i8_f32(int8_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float sitofp_i16_f32(int16_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float sitofp_i32_f32(int32_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float sitofp_i64_f32(int64_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i8_f32(uint8_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i16_f32(uint16_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i32_f32(uint32_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i64_f32(uint64_t x) {
  return (float) x;
}

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR float fabs32(float x) {
  return fabs(x);
}

SCALAR_FUN_ATTR float fmax32(float x, float y) {
  return fmax(x, y);
}

SCALAR_FUN_ATTR float fmin32(float x, float y) {
  return fmin(x, y);
}

SCALAR_FUN_ATTR float fpow32(float x, float y) {
  return pow(x, y);
}

#elif ISPC

SCALAR_FUN_ATTR float fabs32(float x) {
  return abs(x);
}

SCALAR_FUN_ATTR float fmax32(float x, float y) {
  return isnan(x) ? y : isnan(y) ? x : max(x, y);
}

SCALAR_FUN_ATTR float fmin32(float x, float y) {
  return isnan(x) ? y : isnan(y) ? x : min(x, y);
}

SCALAR_FUN_ATTR float fpow32(float a, float b) {
  float ret;
  foreach_active (i) {
      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));
      ret = insert(ret, i, r);
  }
  return ret;
}

#else // Not OpenCL, but CUDA or plain C.

SCALAR_FUN_ATTR float fabs32(float x) {
  return fabsf(x);
}

SCALAR_FUN_ATTR float fmax32(float x, float y) {
  return fmaxf(x, y);
}

SCALAR_FUN_ATTR float fmin32(float x, float y) {
  return fminf(x, y);
}

SCALAR_FUN_ATTR float fpow32(float x, float y) {
  return powf(x, y);
}
#endif

SCALAR_FUN_ATTR bool futrts_isnan32(float x) {
  return isnan(x);
}

#if ISPC

SCALAR_FUN_ATTR bool futrts_isinf32(float x) {
  return !isnan(x) && isnan(x - x);
}

SCALAR_FUN_ATTR bool futrts_isfinite32(float x) {
  return !isnan(x) && !futrts_isinf32(x);
}

#else

SCALAR_FUN_ATTR bool futrts_isinf32(float x) {
  return isinf(x);
}

#endif

SCALAR_FUN_ATTR int8_t fptosi_f32_i8(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f32_i16(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f32_i32(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f32_i64(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int64_t) x;
  };
}

SCALAR_FUN_ATTR uint8_t fptoui_f32_i8(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f32_i16(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f32_i32(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f32_i64(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f32_bool(float x) {
  return x != 0;
}

SCALAR_FUN_ATTR float btof_bool_f32(bool x) {
  return x ? 1 : 0;
}

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR float futrts_log32(float x) {
  return log(x);
}

SCALAR_FUN_ATTR float futrts_log2_32(float x) {
  return log2(x);
}

SCALAR_FUN_ATTR float futrts_log10_32(float x) {
  return log10(x);
}

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  return log1p(x);
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) {
  return sqrt(x);
}

SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  return cbrt(x);
}

SCALAR_FUN_ATTR float futrts_exp32(float x) {
  return exp(x);
}

SCALAR_FUN_ATTR float futrts_cos32(float x) {
  return cos(x);
}

SCALAR_FUN_ATTR float futrts_sin32(float x) {
  return sin(x);
}

SCALAR_FUN_ATTR float futrts_tan32(float x) {
  return tan(x);
}

SCALAR_FUN_ATTR float futrts_acos32(float x) {
  return acos(x);
}

SCALAR_FUN_ATTR float futrts_asin32(float x) {
  return asin(x);
}

SCALAR_FUN_ATTR float futrts_atan32(float x) {
  return atan(x);
}

SCALAR_FUN_ATTR float futrts_cosh32(float x) {
  return cosh(x);
}

SCALAR_FUN_ATTR float futrts_sinh32(float x) {
  return sinh(x);
}

SCALAR_FUN_ATTR float futrts_tanh32(float x) {
  return tanh(x);
}

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  return acosh(x);
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  return asinh(x);
}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  return atanh(x);
}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {
  return atan2(x, y);
}

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  return hypot(x, y);
}

SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  return tgamma(x);
}

SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  return lgamma(x);
}

SCALAR_FUN_ATTR float futrts_erf32(float x) {
  return erf(x);
}

SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  return erfc(x);
}

SCALAR_FUN_ATTR float fmod32(float x, float y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR float futrts_round32(float x) {
  return rint(x);
}

SCALAR_FUN_ATTR float futrts_floor32(float x) {
  return floor(x);
}

SCALAR_FUN_ATTR float futrts_ceil32(float x) {
  return ceil(x);
}

SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  return nextafter(x, y);
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return mix(v0, v1, t);
}

SCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {
  return ldexp(x, y);
}

SCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {
  return copysign(x, y);
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return mad(a, b, c);
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return fma(a, b, c);
}

#elif ISPC

SCALAR_FUN_ATTR float futrts_log32(float x) {
  return futrts_isfinite32(x) || (futrts_isinf32(x) && x < 0)? log(x) : x;
}

SCALAR_FUN_ATTR float futrts_log2_32(float x) {
  return futrts_log32(x) / log(2.0f);
}

SCALAR_FUN_ATTR float futrts_log10_32(float x) {
  return futrts_log32(x) / log(10.0f);
}

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  if(x == -1.0f || (futrts_isinf32(x) && x > 0.0f)) return x / 0.0f;
  float y = 1.0f + x;
  float z = y - 1.0f;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) {
  return sqrt(x);
}

extern "C" unmasked uniform float cbrtf(uniform float);
SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = cbrtf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float futrts_exp32(float x) {
  return exp(x);
}

SCALAR_FUN_ATTR float futrts_cos32(float x) {
  return cos(x);
}

SCALAR_FUN_ATTR float futrts_sin32(float x) {
  return sin(x);
}

SCALAR_FUN_ATTR float futrts_tan32(float x) {
  return tan(x);
}

SCALAR_FUN_ATTR float futrts_acos32(float x) {
  return acos(x);
}

SCALAR_FUN_ATTR float futrts_asin32(float x) {
  return asin(x);
}

SCALAR_FUN_ATTR float futrts_atan32(float x) {
  return atan(x);
}

SCALAR_FUN_ATTR float futrts_cosh32(float x) {
  return (exp(x)+exp(-x)) / 2.0f;
}

SCALAR_FUN_ATTR float futrts_sinh32(float x) {
  return (exp(x)-exp(-x)) / 2.0f;
}

SCALAR_FUN_ATTR float futrts_tanh32(float x) {
  return futrts_sinh32(x)/futrts_cosh32(x);
}

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  float f = x+sqrt(x*x-1);
  if(futrts_isfinite32(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  float f = x+sqrt(x*x+1);
  if(futrts_isfinite32(f)) return log(f);
  return f;

}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  float f = (1+x)/(1-x);
  if(futrts_isfinite32(f)) return log(f)/2.0f;
  return f;

}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {
  return (x == 0.0f && y == 0.0f) ? 0.0f : atan2(x, y);
}

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  if (futrts_isfinite32(x) && futrts_isfinite32(y)) {
    x = abs(x);
    y = abs(y);
    float a;
    float b;
    if (x >= y){
        a = x;
        b = y;
    } else {
        a = y;
        b = x;
    }
    if(b == 0){
      return a;
    }

    int e;
    float an;
    float bn;
    an = frexp (a, &e);
    bn = ldexp (b, - e);
    float cn;
    cn = sqrt (an * an + bn * bn);
    return ldexp (cn, e);
  } else {
    if (futrts_isinf32(x) || futrts_isinf32(y)) return INFINITY;
    else return x + y;
  }

}

extern "C" unmasked uniform float tgammaf(uniform float x);
SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = tgammaf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float lgammaf(uniform float x);
SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = lgammaf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float erff(uniform float x);
SCALAR_FUN_ATTR float futrts_erf32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = erff(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float erfcf(uniform float x);
SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = erfcf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float fmod32(float x, float y) {
  return x - y * trunc(x/y);
}

SCALAR_FUN_ATTR float futrts_round32(float x) {
  return round(x);
}

SCALAR_FUN_ATTR float futrts_floor32(float x) {
  return floor(x);
}

SCALAR_FUN_ATTR float futrts_ceil32(float x) {
  return ceil(x);
}

extern "C" unmasked uniform float nextafterf(uniform float x, uniform float y);
SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  float res;
  foreach_active (i) {
    uniform float r = nextafterf(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {
  return x * pow((double)2.0, (double)y);
}

SCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {
  int32_t xb = futrts_to_bits32(x);
  int32_t yb = futrts_to_bits32(y);
  return futrts_from_bits32((xb & ~(1<<31)) | (yb & (1<<31)));
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return a * b + c;
}

#else // Not OpenCL or ISPC, but CUDA or plain C.

SCALAR_FUN_ATTR float futrts_log32(float x) {
  return logf(x);
}

SCALAR_FUN_ATTR float futrts_log2_32(float x) {
  return log2f(x);
}

SCALAR_FUN_ATTR float futrts_log10_32(float x) {
  return log10f(x);
}

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  return log1pf(x);
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) {
  return sqrtf(x);
}

SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  return cbrtf(x);
}

SCALAR_FUN_ATTR float futrts_exp32(float x) {
  return expf(x);
}

SCALAR_FUN_ATTR float futrts_cos32(float x) {
  return cosf(x);
}

SCALAR_FUN_ATTR float futrts_sin32(float x) {
  return sinf(x);
}

SCALAR_FUN_ATTR float futrts_tan32(float x) {
  return tanf(x);
}

SCALAR_FUN_ATTR float futrts_acos32(float x) {
  return acosf(x);
}

SCALAR_FUN_ATTR float futrts_asin32(float x) {
  return asinf(x);
}

SCALAR_FUN_ATTR float futrts_atan32(float x) {
  return atanf(x);
}

SCALAR_FUN_ATTR float futrts_cosh32(float x) {
  return coshf(x);
}

SCALAR_FUN_ATTR float futrts_sinh32(float x) {
  return sinhf(x);
}

SCALAR_FUN_ATTR float futrts_tanh32(float x) {
  return tanhf(x);
}

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  return acoshf(x);
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  return asinhf(x);
}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  return atanhf(x);
}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {
  return atan2f(x, y);
}

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  return hypotf(x, y);
}

SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  return tgammaf(x);
}

SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  return lgammaf(x);
}

SCALAR_FUN_ATTR float futrts_erf32(float x) {
  return erff(x);
}

SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  return erfcf(x);
}

SCALAR_FUN_ATTR float fmod32(float x, float y) {
  return fmodf(x, y);
}

SCALAR_FUN_ATTR float futrts_round32(float x) {
  return rintf(x);
}

SCALAR_FUN_ATTR float futrts_floor32(float x) {
  return floorf(x);
}

SCALAR_FUN_ATTR float futrts_ceil32(float x) {
  return ceilf(x);
}

SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  return nextafterf(x, y);
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {
  return ldexpf(x, y);
}

SCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {
  return copysignf(x, y);
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return fmaf(a, b, c);
}
#endif

#if ISPC
SCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {
  return intbits(x);
}

SCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {
  return floatbits(x);
}
#else
SCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {
  union {
    float f;
    int32_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {
  union {
    int32_t f;
    float t;
  } p;

  p.f = x;
  return p.t;
}
#endif

SCALAR_FUN_ATTR float fsignum32(float x) {
  return futrts_isnan32(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);
}

#ifdef FUTHARK_F64_ENABLED

SCALAR_FUN_ATTR double futrts_from_bits64(int64_t x);
SCALAR_FUN_ATTR int64_t futrts_to_bits64(double x);

#if ISPC
SCALAR_FUN_ATTR bool futrts_isinf64(float x) {
  return !isnan(x) && isnan(x - x);
}

SCALAR_FUN_ATTR bool futrts_isfinite64(float x) {
  return !isnan(x) && !futrts_isinf64(x);
}

SCALAR_FUN_ATTR double fdiv64(double x, double y) {
  return x / y;
}

SCALAR_FUN_ATTR double fadd64(double x, double y) {
  return x + y;
}

SCALAR_FUN_ATTR double fsub64(double x, double y) {
  return x - y;
}

SCALAR_FUN_ATTR double fmul64(double x, double y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt64(double x, double y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple64(double x, double y) {
  return x <= y;
}

SCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double fabs64(double x) {
  return abs(x);
}

SCALAR_FUN_ATTR double fmax64(double x, double y) {
  return isnan(x) ? y : isnan(y) ? x : max(x, y);
}

SCALAR_FUN_ATTR double fmin64(double x, double y) {
  return isnan(x) ? y : isnan(y) ? x : min(x, y);
}

SCALAR_FUN_ATTR double fpow64(double a, double b) {
  float ret;
  foreach_active (i) {
      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));
      ret = insert(ret, i, r);
  }
  return ret;
}

SCALAR_FUN_ATTR double futrts_log64(double x) {
  return futrts_isfinite64(x) || (futrts_isinf64(x) && x < 0)? log(x) : x;
}

SCALAR_FUN_ATTR double futrts_log2_64(double x) {
  return futrts_log64(x)/log(2.0d);
}

SCALAR_FUN_ATTR double futrts_log10_64(double x) {
  return futrts_log64(x)/log(10.0d);
}

SCALAR_FUN_ATTR double futrts_log1p_64(double x) {
  if(x == -1.0d || (futrts_isinf64(x) && x > 0.0d)) return x / 0.0d;
  double y = 1.0d + x;
  double z = y - 1.0d;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR double futrts_sqrt64(double x) {
  return sqrt(x);
}

extern "C" unmasked uniform double cbrt(uniform double);
SCALAR_FUN_ATTR double futrts_cbrt64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = cbrtf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_exp64(double x) {
  return exp(x);
}

SCALAR_FUN_ATTR double futrts_cos64(double x) {
  return cos(x);
}

SCALAR_FUN_ATTR double futrts_sin64(double x) {
  return sin(x);
}

SCALAR_FUN_ATTR double futrts_tan64(double x) {
  return tan(x);
}

SCALAR_FUN_ATTR double futrts_acos64(double x) {
  return acos(x);
}

SCALAR_FUN_ATTR double futrts_asin64(double x) {
  return asin(x);
}

SCALAR_FUN_ATTR double futrts_atan64(double x) {
  return atan(x);
}

SCALAR_FUN_ATTR double futrts_cosh64(double x) {
  return (exp(x)+exp(-x)) / 2.0d;
}

SCALAR_FUN_ATTR double futrts_sinh64(double x) {
  return (exp(x)-exp(-x)) / 2.0d;
}

SCALAR_FUN_ATTR double futrts_tanh64(double x) {
  return futrts_sinh64(x)/futrts_cosh64(x);
}

SCALAR_FUN_ATTR double futrts_acosh64(double x) {
  double f = x+sqrt(x*x-1.0d);
  if(futrts_isfinite64(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR double futrts_asinh64(double x) {
  double f = x+sqrt(x*x+1.0d);
  if(futrts_isfinite64(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR double futrts_atanh64(double x) {
  double f = (1.0d+x)/(1.0d-x);
  if(futrts_isfinite64(f)) return log(f)/2.0d;
  return f;

}

SCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {
  return atan2(x, y);
}

extern "C" unmasked uniform double hypot(uniform double x, uniform double y);
SCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {
  double res;
  foreach_active (i) {
    uniform double r = hypot(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double tgamma(uniform double x);
SCALAR_FUN_ATTR double futrts_gamma64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = tgamma(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double lgamma(uniform double x);
SCALAR_FUN_ATTR double futrts_lgamma64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = lgamma(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double erf(uniform double x);
SCALAR_FUN_ATTR double futrts_erf64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = erf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double erfc(uniform double x);
SCALAR_FUN_ATTR double futrts_erfc64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = erfc(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {
  return a * b + c;
}

SCALAR_FUN_ATTR double futrts_round64(double x) {
  return round(x);
}

SCALAR_FUN_ATTR double futrts_ceil64(double x) {
  return ceil(x);
}

extern "C" unmasked uniform double nextafter(uniform float x, uniform double y);
SCALAR_FUN_ATTR float futrts_nextafter64(double x, double y) {
  double res;
  foreach_active (i) {
    uniform double r = nextafter(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_floor64(double x) {
  return floor(x);
}

SCALAR_FUN_ATTR bool futrts_isnan64(double x) {
  return isnan(x);
}

SCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int64_t) x;
  }
}

SCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f64_bool(double x) {
  return x != 0.0;
}

SCALAR_FUN_ATTR double btof_bool_f64(bool x) {
  return x ? 1.0 : 0.0;
}

SCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {
  int64_t res;
  foreach_active (i) {
    uniform double tmp = extract(x, i);
    uniform int64_t r = *((uniform int64_t* uniform)&tmp);
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {
  double res;
  foreach_active (i) {
    uniform int64_t tmp = extract(x, i);
    uniform double r = *((uniform double* uniform)&tmp);
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double fmod64(double x, double y) {
  return x - y * trunc(x/y);
}

SCALAR_FUN_ATTR double fsignum64(double x) {
  return futrts_isnan64(x) ? x : (x > 0 ? 1.0d : 0.0d) - (x < 0 ? 1.0d : 0.0d);
}

SCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {
  return x * pow((double)2.0, (double)y);
}

SCALAR_FUN_ATTR double futrts_copysign64(double x, double y) {
  int64_t xb = futrts_to_bits64(x);
  int64_t yb = futrts_to_bits64(y);
  return futrts_from_bits64((xb & ~(((int64_t)1)<<63)) | (yb & (((int64_t)1)<<63)));
}

SCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float fpconv_f32_f32(float x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f32_f64(float x) {
  return (double) x;
}

SCALAR_FUN_ATTR float fpconv_f64_f32(double x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f64_f64(double x) {
  return (double) x;
}

#else

SCALAR_FUN_ATTR double fdiv64(double x, double y) {
  return x / y;
}

SCALAR_FUN_ATTR double fadd64(double x, double y) {
  return x + y;
}

SCALAR_FUN_ATTR double fsub64(double x, double y) {
  return x - y;
}

SCALAR_FUN_ATTR double fmul64(double x, double y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt64(double x, double y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple64(double x, double y) {
  return x <= y;
}

SCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double fabs64(double x) {
  return fabs(x);
}

SCALAR_FUN_ATTR double fmax64(double x, double y) {
  return fmax(x, y);
}

SCALAR_FUN_ATTR double fmin64(double x, double y) {
  return fmin(x, y);
}

SCALAR_FUN_ATTR double fpow64(double x, double y) {
  return pow(x, y);
}

SCALAR_FUN_ATTR double futrts_log64(double x) {
  return log(x);
}

SCALAR_FUN_ATTR double futrts_log2_64(double x) {
  return log2(x);
}

SCALAR_FUN_ATTR double futrts_log10_64(double x) {
  return log10(x);
}

SCALAR_FUN_ATTR double futrts_log1p_64(double x) {
  return log1p(x);
}

SCALAR_FUN_ATTR double futrts_sqrt64(double x) {
  return sqrt(x);
}

SCALAR_FUN_ATTR double futrts_cbrt64(double x) {
  return cbrt(x);
}

SCALAR_FUN_ATTR double futrts_exp64(double x) {
  return exp(x);
}

SCALAR_FUN_ATTR double futrts_cos64(double x) {
  return cos(x);
}

SCALAR_FUN_ATTR double futrts_sin64(double x) {
  return sin(x);
}

SCALAR_FUN_ATTR double futrts_tan64(double x) {
  return tan(x);
}

SCALAR_FUN_ATTR double futrts_acos64(double x) {
  return acos(x);
}

SCALAR_FUN_ATTR double futrts_asin64(double x) {
  return asin(x);
}

SCALAR_FUN_ATTR double futrts_atan64(double x) {
  return atan(x);
}

SCALAR_FUN_ATTR double futrts_cosh64(double x) {
  return cosh(x);
}

SCALAR_FUN_ATTR double futrts_sinh64(double x) {
  return sinh(x);
}

SCALAR_FUN_ATTR double futrts_tanh64(double x) {
  return tanh(x);
}

SCALAR_FUN_ATTR double futrts_acosh64(double x) {
  return acosh(x);
}

SCALAR_FUN_ATTR double futrts_asinh64(double x) {
  return asinh(x);
}

SCALAR_FUN_ATTR double futrts_atanh64(double x) {
  return atanh(x);
}

SCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {
  return atan2(x, y);
}

SCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {
  return hypot(x, y);
}

SCALAR_FUN_ATTR double futrts_gamma64(double x) {
  return tgamma(x);
}

SCALAR_FUN_ATTR double futrts_lgamma64(double x) {
  return lgamma(x);
}

SCALAR_FUN_ATTR double futrts_erf64(double x) {
  return erf(x);
}

SCALAR_FUN_ATTR double futrts_erfc64(double x) {
  return erfc(x);
}

SCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {
  return fma(a, b, c);
}

SCALAR_FUN_ATTR double futrts_round64(double x) {
  return rint(x);
}

SCALAR_FUN_ATTR double futrts_ceil64(double x) {
  return ceil(x);
}

SCALAR_FUN_ATTR float futrts_nextafter64(float x, float y) {
  return nextafter(x, y);
}

SCALAR_FUN_ATTR double futrts_floor64(double x) {
  return floor(x);
}

SCALAR_FUN_ATTR bool futrts_isnan64(double x) {
  return isnan(x);
}

SCALAR_FUN_ATTR bool futrts_isinf64(double x) {
  return isinf(x);
}

SCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int64_t) x;
  }
}

SCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f64_bool(double x) {
  return x != 0;
}

SCALAR_FUN_ATTR double btof_bool_f64(bool x) {
  return x ? 1 : 0;
}

SCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {
  union {
    double f;
    int64_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {
  union {
    int64_t f;
    double t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR double fmod64(double x, double y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR double fsignum64(double x) {
  return futrts_isnan64(x) ? x : (x > 0) - (x < 0);
}

SCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {
#ifdef __OPENCL_VERSION__
  return mix(v0, v1, t);
#else
  return v0 + (v1 - v0) * t;
#endif
}

SCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {
  return ldexp(x, y);
}

SCALAR_FUN_ATTR float futrts_copysign64(double x, double y) {
  return copysign(x, y);
}

SCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {
#ifdef __OPENCL_VERSION__
  return mad(a, b, c);
#else
  return a * b + c;
#endif
}

SCALAR_FUN_ATTR float fpconv_f32_f32(float x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f32_f64(float x) {
  return (double) x;
}

SCALAR_FUN_ATTR float fpconv_f64_f32(double x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f64_f64(double x) {
  return (double) x;
}

#endif

#endif

// End of scalar.h.
// Start of scalar_f16.h.

// Half-precision is emulated if needed (e.g. in straight C) with the
// native type used if possible.  The emulation works by typedef'ing
// 'float' to 'f16', and then implementing all operations on single
// precision.  To cut down on duplication, we use the same code for
// those Futhark functions that require just operators or casts.  The
// in-memory representation for arrays will still be 16 bits even
// under emulation, so the compiler will have to be careful when
// generating reads or writes.

#if !defined(cl_khr_fp16) && !(defined(__CUDA_ARCH__) && __CUDA_ARCH__ >= 600) && !(defined(ISPC))
#define EMULATE_F16
#endif

#if !defined(EMULATE_F16) && defined(__OPENCL_VERSION__)
#pragma OPENCL EXTENSION cl_khr_fp16 : enable
#endif

#ifdef EMULATE_F16

// Note that the half-precision storage format is still 16 bits - the
// compiler will have to be real careful!
typedef float f16;

#elif ISPC
typedef float16 f16;

#else

#ifdef __CUDA_ARCH__
#include <cuda_fp16.h>
#endif

typedef half f16;

#endif

// Some of these functions convert to single precision because half
// precision versions are not available.

SCALAR_FUN_ATTR f16 fadd16(f16 x, f16 y) {
  return x + y;
}

SCALAR_FUN_ATTR f16 fsub16(f16 x, f16 y) {
  return x - y;
}

SCALAR_FUN_ATTR f16 fmul16(f16 x, f16 y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt16(f16 x, f16 y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple16(f16 x, f16 y) {
  return x <= y;
}

SCALAR_FUN_ATTR f16 sitofp_i8_f16(int8_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 sitofp_i16_f16(int16_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 sitofp_i32_f16(int32_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 sitofp_i64_f16(int64_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i8_f16(uint8_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i16_f16(uint16_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i32_f16(uint32_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i64_f16(uint64_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR int8_t fptosi_f16_i8(f16 x) {
  return (int8_t) (float) x;
}

SCALAR_FUN_ATTR int16_t fptosi_f16_i16(f16 x) {
  return (int16_t) x;
}

SCALAR_FUN_ATTR int32_t fptosi_f16_i32(f16 x) {
  return (int32_t) x;
}

SCALAR_FUN_ATTR int64_t fptosi_f16_i64(f16 x) {
  return (int64_t) x;
}

SCALAR_FUN_ATTR uint8_t fptoui_f16_i8(f16 x) {
  return (uint8_t) (float) x;
}

SCALAR_FUN_ATTR uint16_t fptoui_f16_i16(f16 x) {
  return (uint16_t) x;
}

SCALAR_FUN_ATTR uint32_t fptoui_f16_i32(f16 x) {
  return (uint32_t) x;
}

SCALAR_FUN_ATTR uint64_t fptoui_f16_i64(f16 x) {
  return (uint64_t) x;
}

SCALAR_FUN_ATTR bool ftob_f16_bool(f16 x) {
  return x != (f16)0;
}

SCALAR_FUN_ATTR f16 btof_bool_f16(bool x) {
  return x ? 1 : 0;
}

#ifndef EMULATE_F16
SCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {
  return isnan((float)x);
}

#ifdef __OPENCL_VERSION__

SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return fabs(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return fmax(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return fmin(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return pow(x, y);
}

#elif ISPC
SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return abs(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : max(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : min(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return pow(x, y);
}

#else // Assuming CUDA.

SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return fabsf(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return fmaxf(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return fminf(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return powf(x, y);
}
#endif

#if ISPC
SCALAR_FUN_ATTR bool futrts_isinf16(float x) {
  return !futrts_isnan16(x) && futrts_isnan16(x - x);
}
SCALAR_FUN_ATTR bool futrts_isfinite16(float x) {
  return !futrts_isnan16(x) && !futrts_isinf16(x);
}

#else

SCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {
  return isinf((float)x);
}
#endif

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return log(x);
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return log2(x);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return log10(x);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  return log1p(x);
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return sqrt(x);
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  return cbrt(x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return exp(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return cos(x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return sin(x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return tan(x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return acos(x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return asin(x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return atan(x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return cosh(x);
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return sinh(x);
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return tanh(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  return acosh(x);
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  return asinh(x);
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  return atanh(x);
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return atan2(x, y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return hypot(x, y);
}

SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  return tgamma(x);
}

SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  return lgamma(x);
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  return erf(x);
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  return erfc(x);
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return rint(x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return floor(x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return ceil(x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return nextafter(x, y);
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return mix(v0, v1, t);
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return ldexp(x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return copysign(x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return mad(a, b, c);
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return fma(a, b, c);
}
#elif ISPC

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return futrts_isfinite16(x) || (futrts_isinf16(x) && x < 0) ? log(x) : x;
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return futrts_log16(x) / log(2.0f16);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return futrts_log16(x) / log(10.0f16);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  if(x == -1.0f16 || (futrts_isinf16(x) && x > 0.0f16)) return x / 0.0f16;
  f16 y = 1.0f16 + x;
  f16 z = y - 1.0f16;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return (float16)sqrt((float)x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return exp(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return (float16)cos((float)x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return (float16)sin((float)x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return (float16)tan((float)x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return (float16)acos((float)x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return (float16)asin((float)x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return (float16)atan((float)x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return (exp(x)+exp(-x)) / 2.0f16;
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return (exp(x)-exp(-x)) / 2.0f16;
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return futrts_sinh16(x)/futrts_cosh16(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  float16 f = x+(float16)sqrt((float)(x*x-1));
  if(futrts_isfinite16(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  float16 f = x+(float16)sqrt((float)(x*x+1));
  if(futrts_isfinite16(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  float16 f = (1+x)/(1-x);
  if(futrts_isfinite16(f)) return log(f)/2.0f16;
  return f;
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return (float16)atan2((float)x, (float)y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return (float16)futrts_hypot32((float)x, (float)y);
}

extern "C" unmasked uniform float tgammaf(uniform float x);
SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  f16 res;
  foreach_active (i) {
    uniform f16 r = (f16)tgammaf(extract((float)x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float lgammaf(uniform float x);
SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  f16 res;
  foreach_active (i) {
    uniform f16 r = (f16)lgammaf(extract((float)x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  f16 res = (f16)futrts_cbrt32((float)x);
  return res;
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  f16 res = (f16)futrts_erf32((float)x);
  return res;
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  f16 res = (f16)futrts_erfc32((float)x);
  return res;
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return x - y * (float16)trunc((float) (x/y));
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return (float16)round((float)x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return (float16)floor((float)x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return (float16)ceil((float)x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return (float16)futrts_nextafter32((float)x, (float) y);
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return futrts_ldexp32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return futrts_copysign32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

#else // Assume CUDA.

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return hlog(x);
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return hlog2(x);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return hlog10(x);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  return (f16)log1pf((float)x);
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return hsqrt(x);
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  return cbrtf(x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return hexp(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return hcos(x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return hsin(x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return tanf(x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return acosf(x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return asinf(x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return atanf(x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return coshf(x);
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return sinhf(x);
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return tanhf(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  return acoshf(x);
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  return asinhf(x);
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  return atanhf(x);
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return atan2f(x, y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return hypotf(x, y);
}

SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  return tgammaf(x);
}

SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  return lgammaf(x);
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  return erff(x);
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  return erfcf(x);
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return fmodf(x, y);
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return rintf(x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return hfloor(x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return hceil(x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return __ushort_as_half(halfbitsnextafter(__half_as_ushort(x), __half_as_ushort(y)));
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return futrts_ldexp32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return futrts_copysign32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return fmaf(a, b, c);
}

#endif

// The CUDA __half type cannot be put in unions for some reason, so we
// use bespoke conversion functions instead.
#ifdef __CUDA_ARCH__
SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  return __half_as_ushort(x);
}
SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  return __ushort_as_half(x);
}
#elif ISPC

SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  varying int16_t y = *((varying int16_t * uniform)&x);
  return y;
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  varying f16 y = *((varying f16 * uniform)&x);
  return y;
}
#else
SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  union {
    f16 f;
    int16_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  union {
    int16_t f;
    f16 t;
  } p;

  p.f = x;
  return p.t;
}
#endif

#else // No native f16 - emulate.

SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return fabs32(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return fmax32(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return fmin32(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return fpow32(x, y);
}

SCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {
  return futrts_isnan32(x);
}

SCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {
  return futrts_isinf32(x);
}

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return futrts_log32(x);
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return futrts_log2_32(x);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return futrts_log10_32(x);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  return futrts_log1p_32(x);
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return futrts_sqrt32(x);
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  return futrts_cbrt32(x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return futrts_exp32(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return futrts_cos32(x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return futrts_sin32(x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return futrts_tan32(x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return futrts_acos32(x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return futrts_asin32(x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return futrts_atan32(x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return futrts_cosh32(x);
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return futrts_sinh32(x);
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return futrts_tanh32(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  return futrts_acosh32(x);
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  return futrts_asinh32(x);
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  return futrts_atanh32(x);
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return futrts_atan2_32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return futrts_hypot32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  return futrts_gamma32(x);
}

SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  return futrts_lgamma32(x);
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  return futrts_erf32(x);
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  return futrts_erfc32(x);
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return fmod32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return futrts_round32(x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return futrts_floor32(x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return futrts_ceil32(x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return halfbits2float(halfbitsnextafter(float2halfbits(x), float2halfbits(y)));
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return futrts_lerp32(v0, v1, t);
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return futrts_ldexp32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return futrts_copysign32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return futrts_mad32(a, b, c);
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return futrts_fma32(a, b, c);
}

// Even when we are using an OpenCL that does not support cl_khr_fp16,
// it must still support vload_half for actually creating a
// half-precision number, which can then be efficiently converted to a
// float.  Similarly for vstore_half.
#ifdef __OPENCL_VERSION__

SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  int16_t y;
  // Violating strict aliasing here.
  vstore_half((float)x, 0, (half*)&y);
  return y;
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  return (f16)vload_half(0, (half*)&x);
}

#else

SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  return (int16_t)float2halfbits(x);
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  return halfbits2float((uint16_t)x);
}

SCALAR_FUN_ATTR f16 fsignum16(f16 x) {
  return futrts_isnan16(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);
}

#endif

#endif

SCALAR_FUN_ATTR float fpconv_f16_f16(f16 x) {
  return x;
}

SCALAR_FUN_ATTR float fpconv_f16_f32(f16 x) {
  return x;
}

SCALAR_FUN_ATTR f16 fpconv_f32_f16(float x) {
  return (f16) x;
}

#ifdef FUTHARK_F64_ENABLED

SCALAR_FUN_ATTR double fpconv_f16_f64(f16 x) {
  return (double) x;
}

#if ISPC
SCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {
  return (f16) ((float)x);
}
#else
SCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {
  return (f16) x;
}
#endif
#endif


// End of scalar_f16.h.

// Start of context_prototypes.h
//
// Prototypes for the functions in context.h, or that will be called
// from those functions, that need to be available very early.

struct futhark_context_config;
struct futhark_context;

static void set_error(struct futhark_context* ctx, char *error);

// These are called in context/config new/free functions and contain
// shared setup.  They are generated by the compiler itself.
static int init_constants(struct futhark_context*);
static int free_constants(struct futhark_context*);
static void setup_program(struct futhark_context* ctx);
static void teardown_program(struct futhark_context *ctx);

// Allocate host memory.  Must be freed with host_free().
static void host_alloc(struct futhark_context* ctx, size_t size, const char* tag, size_t* size_out, void** mem_out);
// Allocate memory allocated with host_alloc().
static void host_free(struct futhark_context* ctx, size_t size, const char* tag, void* mem);

// Log that a copy has occurred.
static void log_copy(struct futhark_context* ctx,
                     const char *kind, int r,
                     int64_t dst_offset, int64_t dst_strides[r],
                     int64_t src_offset, int64_t src_strides[r],
                     int64_t shape[r]);

static void log_transpose(struct futhark_context* ctx,
                          int64_t k, int64_t m, int64_t n);

static bool lmad_map_tr(int64_t *num_arrays_out, int64_t *n_out, int64_t *m_out,
                        int r,
                        const int64_t dst_strides[r],
                        const int64_t src_strides[r],
                        const int64_t shape[r]);

static bool lmad_contiguous(int r, int64_t strides[r], int64_t shape[r]);

static bool lmad_memcpyable(int r,
                            int64_t dst_strides[r], int64_t src_strides[r], int64_t shape[r]);

static void add_event(struct futhark_context* ctx,
                      const char* name,
                      char* description,
                      void* data,
                      event_report_fn f);

// Functions that must be defined by the backend.
static void backend_context_config_setup(struct futhark_context_config* cfg);
static void backend_context_config_teardown(struct futhark_context_config* cfg);
static int backend_context_setup(struct futhark_context *ctx);
static void backend_context_teardown(struct futhark_context *ctx);

// End of of context_prototypes.h

struct memblock_device {
    int *references;
    CUdeviceptr mem;
    int64_t size;
    const char *desc;
};
struct memblock {
    int *references;
    unsigned char *mem;
    int64_t size;
    const char *desc;
};
struct constants {
    int dummy;
    struct memblock_device counters_mem_21821;
    struct memblock_device counters_mem_21866;
    struct memblock_device global_dynid_mem_21636;
    struct memblock_device global_dynid_mem_21711;
    struct memblock_device global_dynid_mem_21924;
    struct memblock_device global_dynid_mem_21927;
    struct memblock_device global_dynid_mem_22062;
};
static int8_t mainzistatic_array_realtype_22281[16] = { (int8_t) 4,(int8_t) 2,(int8_t) 2,(int8_t) 1,(int8_t) 2,(int8_t) 2,(int8_t) 3,(int8_t) 5,(int8_t) 2,(int8_t) 5,(int8_t) 3,(int8_t) 1,(int8_t) 4,(int8_t) 5,(int8_t) 3,(int8_t) 7};
struct tuning_params {
    int dummy;
    int64_t *builtinzhiota_i64zitblock_sizze_21606;
    int64_t *builtinzhreplicate_boolzitblock_sizze_22204;
    int64_t *builtinzhreplicate_i32zitblock_sizze_21722;
    int64_t *builtinzhreplicate_i64zitblock_sizze_21623;
    int64_t *builtinzhreplicate_i8zitblock_sizze_21696;
    int64_t *getPartitionBounds_8487zisegmap_num_tblocks_20294;
    int64_t *getPartitionBounds_8487zisegmap_num_tblocks_20772;
    int64_t *getPartitionBounds_8487zisegmap_tblock_sizze_20100;
    int64_t *getPartitionBounds_8487zisegmap_tblock_sizze_20256;
    int64_t *getPartitionBounds_8487zisegmap_tblock_sizze_20292;
    int64_t *getPartitionBounds_8487zisegmap_tblock_sizze_20328;
    int64_t *getPartitionBounds_8487zisegmap_tblock_sizze_20367;
    int64_t *getPartitionBounds_8487zisegmap_tblock_sizze_20383;
    int64_t *getPartitionBounds_8487zisegmap_tblock_sizze_20395;
    int64_t *getPartitionBounds_8487zisegmap_tblock_sizze_20770;
    int64_t *getPartitionBounds_8487zisegred_num_tblocks_20270;
    int64_t *getPartitionBounds_8487zisegred_tblock_sizze_20268;
    int64_t *getPartitionBounds_8487zisegscan_num_tblocks_20016;
    int64_t *getPartitionBounds_8487zisegscan_num_tblocks_20526;
    int64_t *getPartitionBounds_8487zisegscan_tblock_sizze_20014;
    int64_t *getPartitionBounds_8487zisegscan_tblock_sizze_20524;
    int64_t *getPartitionBounds_8487zisuff_intra_par_2;
    int64_t *getPartitionBounds_8487zisuff_outer_par_1;
    int64_t *getPartitionBounds_8487zisuff_outer_screma_0;
    int64_t *mainzisegmap_num_tblocks_20923;
    int64_t *mainzisegmap_num_tblocks_20933;
    int64_t *mainzisegmap_num_tblocks_20949;
    int64_t *mainzisegmap_num_tblocks_20988;
    int64_t *mainzisegmap_num_tblocks_21175;
    int64_t *mainzisegmap_num_tblocks_21183;
    int64_t *mainzisegmap_tblock_sizze_20778;
    int64_t *mainzisegmap_tblock_sizze_20854;
    int64_t *mainzisegmap_tblock_sizze_20888;
    int64_t *mainzisegmap_tblock_sizze_20921;
    int64_t *mainzisegmap_tblock_sizze_20931;
    int64_t *mainzisegmap_tblock_sizze_20947;
    int64_t *mainzisegmap_tblock_sizze_20955;
    int64_t *mainzisegmap_tblock_sizze_20986;
    int64_t *mainzisegmap_tblock_sizze_20994;
    int64_t *mainzisegmap_tblock_sizze_21012;
    int64_t *mainzisegmap_tblock_sizze_21076;
    int64_t *mainzisegmap_tblock_sizze_21143;
    int64_t *mainzisegmap_tblock_sizze_21173;
    int64_t *mainzisegmap_tblock_sizze_21181;
    int64_t *mainzisegmap_tblock_sizze_21189;
    int64_t *mainzisegred_num_tblocks_20844;
    int64_t *mainzisegred_tblock_sizze_20842;
    int64_t *mainzisegscan_num_tblocks_20836;
    int64_t *mainzisegscan_num_tblocks_20939;
    int64_t *mainzisegscan_num_tblocks_20978;
    int64_t *mainzisegscan_tblock_sizze_20834;
    int64_t *mainzisegscan_tblock_sizze_20937;
    int64_t *mainzisegscan_tblock_sizze_20976;
};
static const int num_tuning_params = 53;
static const char *tuning_param_names[] = {"builtin#iota_i64.tblock_size_21606", "builtin#replicate_bool.tblock_size_22204", "builtin#replicate_i32.tblock_size_21722", "builtin#replicate_i64.tblock_size_21623", "builtin#replicate_i8.tblock_size_21696", "getPartitionBounds_8487.segmap_num_tblocks_20294", "getPartitionBounds_8487.segmap_num_tblocks_20772", "getPartitionBounds_8487.segmap_tblock_size_20100", "getPartitionBounds_8487.segmap_tblock_size_20256", "getPartitionBounds_8487.segmap_tblock_size_20292", "getPartitionBounds_8487.segmap_tblock_size_20328", "getPartitionBounds_8487.segmap_tblock_size_20367", "getPartitionBounds_8487.segmap_tblock_size_20383", "getPartitionBounds_8487.segmap_tblock_size_20395", "getPartitionBounds_8487.segmap_tblock_size_20770", "getPartitionBounds_8487.segred_num_tblocks_20270", "getPartitionBounds_8487.segred_tblock_size_20268", "getPartitionBounds_8487.segscan_num_tblocks_20016", "getPartitionBounds_8487.segscan_num_tblocks_20526", "getPartitionBounds_8487.segscan_tblock_size_20014", "getPartitionBounds_8487.segscan_tblock_size_20524", "getPartitionBounds_8487.suff_intra_par_2", "getPartitionBounds_8487.suff_outer_par_1", "getPartitionBounds_8487.suff_outer_screma_0", "main.segmap_num_tblocks_20923", "main.segmap_num_tblocks_20933", "main.segmap_num_tblocks_20949", "main.segmap_num_tblocks_20988", "main.segmap_num_tblocks_21175", "main.segmap_num_tblocks_21183", "main.segmap_tblock_size_20778", "main.segmap_tblock_size_20854", "main.segmap_tblock_size_20888", "main.segmap_tblock_size_20921", "main.segmap_tblock_size_20931", "main.segmap_tblock_size_20947", "main.segmap_tblock_size_20955", "main.segmap_tblock_size_20986", "main.segmap_tblock_size_20994", "main.segmap_tblock_size_21012", "main.segmap_tblock_size_21076", "main.segmap_tblock_size_21143", "main.segmap_tblock_size_21173", "main.segmap_tblock_size_21181", "main.segmap_tblock_size_21189", "main.segred_num_tblocks_20844", "main.segred_tblock_size_20842", "main.segscan_num_tblocks_20836", "main.segscan_num_tblocks_20939", "main.segscan_num_tblocks_20978", "main.segscan_tblock_size_20834", "main.segscan_tblock_size_20937", "main.segscan_tblock_size_20976", NULL};
static const char *tuning_param_vars[] = {"builtinzhiota_i64zitblock_sizze_21606", "builtinzhreplicate_boolzitblock_sizze_22204", "builtinzhreplicate_i32zitblock_sizze_21722", "builtinzhreplicate_i64zitblock_sizze_21623", "builtinzhreplicate_i8zitblock_sizze_21696", "getPartitionBounds_8487zisegmap_num_tblocks_20294", "getPartitionBounds_8487zisegmap_num_tblocks_20772", "getPartitionBounds_8487zisegmap_tblock_sizze_20100", "getPartitionBounds_8487zisegmap_tblock_sizze_20256", "getPartitionBounds_8487zisegmap_tblock_sizze_20292", "getPartitionBounds_8487zisegmap_tblock_sizze_20328", "getPartitionBounds_8487zisegmap_tblock_sizze_20367", "getPartitionBounds_8487zisegmap_tblock_sizze_20383", "getPartitionBounds_8487zisegmap_tblock_sizze_20395", "getPartitionBounds_8487zisegmap_tblock_sizze_20770", "getPartitionBounds_8487zisegred_num_tblocks_20270", "getPartitionBounds_8487zisegred_tblock_sizze_20268", "getPartitionBounds_8487zisegscan_num_tblocks_20016", "getPartitionBounds_8487zisegscan_num_tblocks_20526", "getPartitionBounds_8487zisegscan_tblock_sizze_20014", "getPartitionBounds_8487zisegscan_tblock_sizze_20524", "getPartitionBounds_8487zisuff_intra_par_2", "getPartitionBounds_8487zisuff_outer_par_1", "getPartitionBounds_8487zisuff_outer_screma_0", "mainzisegmap_num_tblocks_20923", "mainzisegmap_num_tblocks_20933", "mainzisegmap_num_tblocks_20949", "mainzisegmap_num_tblocks_20988", "mainzisegmap_num_tblocks_21175", "mainzisegmap_num_tblocks_21183", "mainzisegmap_tblock_sizze_20778", "mainzisegmap_tblock_sizze_20854", "mainzisegmap_tblock_sizze_20888", "mainzisegmap_tblock_sizze_20921", "mainzisegmap_tblock_sizze_20931", "mainzisegmap_tblock_sizze_20947", "mainzisegmap_tblock_sizze_20955", "mainzisegmap_tblock_sizze_20986", "mainzisegmap_tblock_sizze_20994", "mainzisegmap_tblock_sizze_21012", "mainzisegmap_tblock_sizze_21076", "mainzisegmap_tblock_sizze_21143", "mainzisegmap_tblock_sizze_21173", "mainzisegmap_tblock_sizze_21181", "mainzisegmap_tblock_sizze_21189", "mainzisegred_num_tblocks_20844", "mainzisegred_tblock_sizze_20842", "mainzisegscan_num_tblocks_20836", "mainzisegscan_num_tblocks_20939", "mainzisegscan_num_tblocks_20978", "mainzisegscan_tblock_sizze_20834", "mainzisegscan_tblock_sizze_20937", "mainzisegscan_tblock_sizze_20976", NULL};
static const char *tuning_param_classes[] = {"thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "thread_block_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "threshold(32, !getPartitionBounds_8487.suff_outer_par_1 !getPartitionBounds_8487.suff_outer_screma_0)", "threshold(def, !getPartitionBounds_8487.suff_outer_screma_0)", "threshold(def, )", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "thread_block_size", "grid_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", NULL};
static int64_t tuning_param_defaults[] = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
static const int max_failure_args = 2;
static const int f64_required = 0;
static const char *gpu_program[] = {"#define FUTHARK_CUDA\n// start of prelude.cu\n\n#define SCALAR_FUN_ATTR __device__ static inline\n#define FUTHARK_FUN_ATTR __device__ static\n#define FUTHARK_F64_ENABLED\n\ntypedef char int8_t;\ntypedef short int16_t;\ntypedef int int32_t;\ntypedef long long int64_t;\ntypedef unsigned char uint8_t;\ntypedef unsigned short uint16_t;\ntypedef unsigned int uint32_t;\ntypedef unsigned long long uint64_t;\n\n#define __global\n#define __local\n#define __private\n#define __constant\n#define __write_only\n#define __read_only\n\nstatic inline __device__ int get_tblock_id(int d) {\n  switch (d) {\n  case 0: return blockIdx.x;\n  case 1: return blockIdx.y;\n  case 2: return blockIdx.z;\n  default: return 0;\n  }\n}\n\nstatic inline __device__ int get_num_tblocks(int d) {\n  switch(d) {\n  case 0: return gridDim.x;\n  case 1: return gridDim.y;\n  case 2: return gridDim.z;\n  default: return 0;\n  }\n}\n\nstatic inline __device__ int get_global_id(int d) {\n  switch (d) {\n    case 0: return threadIdx.x + blockIdx.x * blockDim.x;\n    case 1: return threadIdx.y + blockIdx.y * blockDim.y;\n    case 2: return threadIdx.z + blockIdx.z * blockDim.z;\n    default: return 0;\n  }\n}\n\nstatic inline __device__ int get_local_id(int d) {\n  switch (d) {\n    case 0: return threadIdx.x;\n    case 1: return threadIdx.y;\n    case 2: return threadIdx.z;\n    default: return 0;\n  }\n}\n\nstatic inline __device__ int get_local_size(int d) {\n  switch (d) {\n    case 0: return blockDim.x;\n    case 1: return blockDim.y;\n    case 2: return blockDim.z;\n    default: return 0;\n  }\n}\n\nstatic inline __device__ int get_global_size(int d) {\n  switch (d) {\n    case 0: return gridDim.x * blockDim.x;\n    case 1: return gridDim.y * blockDim.y;\n    case 2: return gridDim.z * blockDim.z;\n    default: return 0;\n  }\n}\n\n\n#define CLK_LOCAL_MEM_FENCE 1\n#define CLK_GLOBAL_MEM_FENCE 2\nstatic inline __device__ void barrier(int x) {\n  __syncthreads();\n}\nstatic inline __device__ void mem_fence_local() {\n  __threadfence_block();\n}\nstatic inline __device__ void mem_fence_global", "() {\n  __threadfence();\n}\n\nstatic inline __device__ void barrier_local() {\n  __syncthreads();\n}\n\n#define NAN (0.0/0.0)\n#define INFINITY (1.0/0.0)\nextern volatile __shared__ unsigned char shared_mem[];\n\n#define SHARED_MEM_PARAM\n#define FUTHARK_KERNEL extern \"C\" __global__ __launch_bounds__(MAX_THREADS_PER_BLOCK)\n#define FUTHARK_KERNEL_SIZED(a,b,c) extern \"C\" __global__ __launch_bounds__(a*b*c)\n\n// End of prelude.cu\n// Start of half.h.\n\n// Conversion functions are from http://half.sourceforge.net/, but\n// translated to C.\n//\n// Copyright (c) 2012-2021 Christian Rau\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in\n// all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n// THE SOFTWARE.\n\n#ifndef __OPENCL_VERSION__\n#define __constant\n#endif\n\n__constant static const uint16_t base_table[512] = {\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0", "000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0001, 0x0002, 0x0004, 0x0008, 0x0010, 0x0020, 0x0040, 0x0080, 0x0100,\n  0x0200, 0x0400, 0x0800, 0x0C00, 0x1000, 0x1400, 0x1800, 0x1C00, 0x2000, 0x2400, 0x2800, 0x2C00, 0x3000, 0x3400, 0x3800, 0x3C00,\n  0x4000, 0x4400, 0x4800, 0x4C00, 0x5000, 0x5400, 0x5800, 0x5C00, 0x6000, 0x6400, 0x6800, 0x6C00, 0x7000, 0x7400, 0x7800, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8",
                                    "000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8001, 0x8002, 0x8004, 0x8008, 0x8010, 0x8020, 0x8040, 0x8080, 0x8100,\n  0x8200, 0x8400, 0x8800, 0x8C00, 0x9000, 0x9400, 0x9800, 0x9C00, 0xA000, 0xA400, 0xA800, 0xAC00, 0xB000, 0xB400, 0xB800, 0xBC00,\n  0xC000, 0xC400, 0xC800, 0xCC00, 0xD000, 0xD400, 0xD800, 0xDC00, 0xE000, 0xE400, 0xE800, 0xEC00, 0xF000, 0xF400, 0xF800, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00 };\n\n__constant static const unsigned char shift_table[512] = {\n  24, 24, 24, 24, 24, 24,", " 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 2", "4, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13 };\n\n__constant static const uint32_t mantissa_table[2048] = {\n  0x00000000, 0x33800000, 0x34000000, 0x34400000, 0x34800000, 0x34A00000, 0x34C00000, 0x34E00000, 0x35000000, 0x35100000, 0x35200000, 0x35300000, 0x35400000, 0x35500000, 0x35600000, 0x35700000,\n  0x35800000, 0x35880000, 0x35900000, 0x35980000, 0x35A00000, 0x35A80000, 0x35B00000, 0x35B80000, 0x35C00000, 0x35C80000, 0x35D00000, 0x35D80000, 0x35E00000, 0x35E80000, 0x35F00000, 0x35F80000,\n  0x36000000, 0x36040000, 0x36080000, 0x360C0000, 0x36100000, 0x36140000, 0x36180000, 0x361C0000, 0x36200000, 0x36240000, 0x36280000, 0x362C0000, 0x36300000, 0x36340000, 0x36380000, 0x363C0000,\n  0x36400000, 0x36440000, 0x36480000, 0x364C0000, 0x36500000, 0x36540000, 0x36580000, 0x365C0000, 0x36600000, 0x36640000, 0x36680000, 0x366C0000, 0x36700000, 0x36740000, 0x36780000, 0x367C0000,\n  0x36800000, 0x36820000, 0x36840000, 0x36860000, 0x36880000, 0x368A0000, 0x368C0000, 0x368E0000, 0x36900000, 0x36920000, 0x36940000, 0x36960000, 0x36980000, 0x369A0000, 0x369C0000, 0x369E0000,\n  0x36A00000, 0x36A20000, 0x36A40000, 0x36A60000, 0x36A80000, 0x36AA0000, 0x36AC0000, 0x36AE0000, 0x36B00000, 0x36B20000, 0x36B40000, 0x36B60000, 0x36B80000, 0x36BA0000, 0x36BC0000, 0x36BE0000,\n  0x36C00000, 0x36C20000, 0x36C40000, 0x36C60000, 0x36C80000, 0x36CA0000, 0x36CC0000, 0x36CE0000, 0x36D00000, 0x36D20000, 0x36D40000, 0x36D60000, 0x36D80000, 0x36DA0000, 0x36DC0000, 0x36DE0000,\n  0x36E00000, 0x36E20000, 0x36E40000, 0x36E60000, 0x36E80000, 0x36EA0000, 0x36EC0000, 0x36EE0000, 0x36F00000, 0x36F20000, 0x36F40000, 0x36F60000, 0x36F80000, 0x36FA0000, 0x36FC0000, 0x36FE0000,\n  0x37000000, 0x37010000, 0x37020000, 0x37030000, 0x37040000, 0x37050000, 0x37060000, 0x37070000, 0x37080000, 0x37090000, 0x370A0000, 0x370B0000, 0x370C0000, 0x370D0000, 0x370E0000, 0x370F0000,\n  0x37100000, 0x37110000, 0x37120000, 0x37130000, 0x37140000, 0x37150000, 0x37160000, 0x37170000, 0x37180000, 0x37190000, 0x371A0000, 0x37",
                                    "1B0000, 0x371C0000, 0x371D0000, 0x371E0000, 0x371F0000,\n  0x37200000, 0x37210000, 0x37220000, 0x37230000, 0x37240000, 0x37250000, 0x37260000, 0x37270000, 0x37280000, 0x37290000, 0x372A0000, 0x372B0000, 0x372C0000, 0x372D0000, 0x372E0000, 0x372F0000,\n  0x37300000, 0x37310000, 0x37320000, 0x37330000, 0x37340000, 0x37350000, 0x37360000, 0x37370000, 0x37380000, 0x37390000, 0x373A0000, 0x373B0000, 0x373C0000, 0x373D0000, 0x373E0000, 0x373F0000,\n  0x37400000, 0x37410000, 0x37420000, 0x37430000, 0x37440000, 0x37450000, 0x37460000, 0x37470000, 0x37480000, 0x37490000, 0x374A0000, 0x374B0000, 0x374C0000, 0x374D0000, 0x374E0000, 0x374F0000,\n  0x37500000, 0x37510000, 0x37520000, 0x37530000, 0x37540000, 0x37550000, 0x37560000, 0x37570000, 0x37580000, 0x37590000, 0x375A0000, 0x375B0000, 0x375C0000, 0x375D0000, 0x375E0000, 0x375F0000,\n  0x37600000, 0x37610000, 0x37620000, 0x37630000, 0x37640000, 0x37650000, 0x37660000, 0x37670000, 0x37680000, 0x37690000, 0x376A0000, 0x376B0000, 0x376C0000, 0x376D0000, 0x376E0000, 0x376F0000,\n  0x37700000, 0x37710000, 0x37720000, 0x37730000, 0x37740000, 0x37750000, 0x37760000, 0x37770000, 0x37780000, 0x37790000, 0x377A0000, 0x377B0000, 0x377C0000, 0x377D0000, 0x377E0000, 0x377F0000,\n  0x37800000, 0x37808000, 0x37810000, 0x37818000, 0x37820000, 0x37828000, 0x37830000, 0x37838000, 0x37840000, 0x37848000, 0x37850000, 0x37858000, 0x37860000, 0x37868000, 0x37870000, 0x37878000,\n  0x37880000, 0x37888000, 0x37890000, 0x37898000, 0x378A0000, 0x378A8000, 0x378B0000, 0x378B8000, 0x378C0000, 0x378C8000, 0x378D0000, 0x378D8000, 0x378E0000, 0x378E8000, 0x378F0000, 0x378F8000,\n  0x37900000, 0x37908000, 0x37910000, 0x37918000, 0x37920000, 0x37928000, 0x37930000, 0x37938000, 0x37940000, 0x37948000, 0x37950000, 0x37958000, 0x37960000, 0x37968000, 0x37970000, 0x37978000,\n  0x37980000, 0x37988000, 0x37990000, 0x37998000, 0x379A0000, 0x379A8000, 0x379B0000, 0x379B8000, 0x379C0000, 0x379C8000, 0x379D0000, 0x379D8000, 0x379E0000, 0x379E8000, 0x379F0000, 0x379F8000,\n  0x", "37A00000, 0x37A08000, 0x37A10000, 0x37A18000, 0x37A20000, 0x37A28000, 0x37A30000, 0x37A38000, 0x37A40000, 0x37A48000, 0x37A50000, 0x37A58000, 0x37A60000, 0x37A68000, 0x37A70000, 0x37A78000,\n  0x37A80000, 0x37A88000, 0x37A90000, 0x37A98000, 0x37AA0000, 0x37AA8000, 0x37AB0000, 0x37AB8000, 0x37AC0000, 0x37AC8000, 0x37AD0000, 0x37AD8000, 0x37AE0000, 0x37AE8000, 0x37AF0000, 0x37AF8000,\n  0x37B00000, 0x37B08000, 0x37B10000, 0x37B18000, 0x37B20000, 0x37B28000, 0x37B30000, 0x37B38000, 0x37B40000, 0x37B48000, 0x37B50000, 0x37B58000, 0x37B60000, 0x37B68000, 0x37B70000, 0x37B78000,\n  0x37B80000, 0x37B88000, 0x37B90000, 0x37B98000, 0x37BA0000, 0x37BA8000, 0x37BB0000, 0x37BB8000, 0x37BC0000, 0x37BC8000, 0x37BD0000, 0x37BD8000, 0x37BE0000, 0x37BE8000, 0x37BF0000, 0x37BF8000,\n  0x37C00000, 0x37C08000, 0x37C10000, 0x37C18000, 0x37C20000, 0x37C28000, 0x37C30000, 0x37C38000, 0x37C40000, 0x37C48000, 0x37C50000, 0x37C58000, 0x37C60000, 0x37C68000, 0x37C70000, 0x37C78000,\n  0x37C80000, 0x37C88000, 0x37C90000, 0x37C98000, 0x37CA0000, 0x37CA8000, 0x37CB0000, 0x37CB8000, 0x37CC0000, 0x37CC8000, 0x37CD0000, 0x37CD8000, 0x37CE0000, 0x37CE8000, 0x37CF0000, 0x37CF8000,\n  0x37D00000, 0x37D08000, 0x37D10000, 0x37D18000, 0x37D20000, 0x37D28000, 0x37D30000, 0x37D38000, 0x37D40000, 0x37D48000, 0x37D50000, 0x37D58000, 0x37D60000, 0x37D68000, 0x37D70000, 0x37D78000,\n  0x37D80000, 0x37D88000, 0x37D90000, 0x37D98000, 0x37DA0000, 0x37DA8000, 0x37DB0000, 0x37DB8000, 0x37DC0000, 0x37DC8000, 0x37DD0000, 0x37DD8000, 0x37DE0000, 0x37DE8000, 0x37DF0000, 0x37DF8000,\n  0x37E00000, 0x37E08000, 0x37E10000, 0x37E18000, 0x37E20000, 0x37E28000, 0x37E30000, 0x37E38000, 0x37E40000, 0x37E48000, 0x37E50000, 0x37E58000, 0x37E60000, 0x37E68000, 0x37E70000, 0x37E78000,\n  0x37E80000, 0x37E88000, 0x37E90000, 0x37E98000, 0x37EA0000, 0x37EA8000, 0x37EB0000, 0x37EB8000, 0x37EC0000, 0x37EC8000, 0x37ED0000, 0x37ED8000, 0x37EE0000, 0x37EE8000, 0x37EF0000, 0x37EF8000,\n  0x37F00000, 0x37F08000, 0x37F10000, 0x37F18000, 0x37F20000, 0x", "37F28000, 0x37F30000, 0x37F38000, 0x37F40000, 0x37F48000, 0x37F50000, 0x37F58000, 0x37F60000, 0x37F68000, 0x37F70000, 0x37F78000,\n  0x37F80000, 0x37F88000, 0x37F90000, 0x37F98000, 0x37FA0000, 0x37FA8000, 0x37FB0000, 0x37FB8000, 0x37FC0000, 0x37FC8000, 0x37FD0000, 0x37FD8000, 0x37FE0000, 0x37FE8000, 0x37FF0000, 0x37FF8000,\n  0x38000000, 0x38004000, 0x38008000, 0x3800C000, 0x38010000, 0x38014000, 0x38018000, 0x3801C000, 0x38020000, 0x38024000, 0x38028000, 0x3802C000, 0x38030000, 0x38034000, 0x38038000, 0x3803C000,\n  0x38040000, 0x38044000, 0x38048000, 0x3804C000, 0x38050000, 0x38054000, 0x38058000, 0x3805C000, 0x38060000, 0x38064000, 0x38068000, 0x3806C000, 0x38070000, 0x38074000, 0x38078000, 0x3807C000,\n  0x38080000, 0x38084000, 0x38088000, 0x3808C000, 0x38090000, 0x38094000, 0x38098000, 0x3809C000, 0x380A0000, 0x380A4000, 0x380A8000, 0x380AC000, 0x380B0000, 0x380B4000, 0x380B8000, 0x380BC000,\n  0x380C0000, 0x380C4000, 0x380C8000, 0x380CC000, 0x380D0000, 0x380D4000, 0x380D8000, 0x380DC000, 0x380E0000, 0x380E4000, 0x380E8000, 0x380EC000, 0x380F0000, 0x380F4000, 0x380F8000, 0x380FC000,\n  0x38100000, 0x38104000, 0x38108000, 0x3810C000, 0x38110000, 0x38114000, 0x38118000, 0x3811C000, 0x38120000, 0x38124000, 0x38128000, 0x3812C000, 0x38130000, 0x38134000, 0x38138000, 0x3813C000,\n  0x38140000, 0x38144000, 0x38148000, 0x3814C000, 0x38150000, 0x38154000, 0x38158000, 0x3815C000, 0x38160000, 0x38164000, 0x38168000, 0x3816C000, 0x38170000, 0x38174000, 0x38178000, 0x3817C000,\n  0x38180000, 0x38184000, 0x38188000, 0x3818C000, 0x38190000, 0x38194000, 0x38198000, 0x3819C000, 0x381A0000, 0x381A4000, 0x381A8000, 0x381AC000, 0x381B0000, 0x381B4000, 0x381B8000, 0x381BC000,\n  0x381C0000, 0x381C4000, 0x381C8000, 0x381CC000, 0x381D0000, 0x381D4000, 0x381D8000, 0x381DC000, 0x381E0000, 0x381E4000, 0x381E8000, 0x381EC000, 0x381F0000, 0x381F4000, 0x381F8000, 0x381FC000,\n  0x38200000, 0x38204000, 0x38208000, 0x3820C000, 0x38210000, 0x38214000, 0x38218000, 0x3821C000, 0x38220000, 0x38224000, 0x",
                                    "38228000, 0x3822C000, 0x38230000, 0x38234000, 0x38238000, 0x3823C000,\n  0x38240000, 0x38244000, 0x38248000, 0x3824C000, 0x38250000, 0x38254000, 0x38258000, 0x3825C000, 0x38260000, 0x38264000, 0x38268000, 0x3826C000, 0x38270000, 0x38274000, 0x38278000, 0x3827C000,\n  0x38280000, 0x38284000, 0x38288000, 0x3828C000, 0x38290000, 0x38294000, 0x38298000, 0x3829C000, 0x382A0000, 0x382A4000, 0x382A8000, 0x382AC000, 0x382B0000, 0x382B4000, 0x382B8000, 0x382BC000,\n  0x382C0000, 0x382C4000, 0x382C8000, 0x382CC000, 0x382D0000, 0x382D4000, 0x382D8000, 0x382DC000, 0x382E0000, 0x382E4000, 0x382E8000, 0x382EC000, 0x382F0000, 0x382F4000, 0x382F8000, 0x382FC000,\n  0x38300000, 0x38304000, 0x38308000, 0x3830C000, 0x38310000, 0x38314000, 0x38318000, 0x3831C000, 0x38320000, 0x38324000, 0x38328000, 0x3832C000, 0x38330000, 0x38334000, 0x38338000, 0x3833C000,\n  0x38340000, 0x38344000, 0x38348000, 0x3834C000, 0x38350000, 0x38354000, 0x38358000, 0x3835C000, 0x38360000, 0x38364000, 0x38368000, 0x3836C000, 0x38370000, 0x38374000, 0x38378000, 0x3837C000,\n  0x38380000, 0x38384000, 0x38388000, 0x3838C000, 0x38390000, 0x38394000, 0x38398000, 0x3839C000, 0x383A0000, 0x383A4000, 0x383A8000, 0x383AC000, 0x383B0000, 0x383B4000, 0x383B8000, 0x383BC000,\n  0x383C0000, 0x383C4000, 0x383C8000, 0x383CC000, 0x383D0000, 0x383D4000, 0x383D8000, 0x383DC000, 0x383E0000, 0x383E4000, 0x383E8000, 0x383EC000, 0x383F0000, 0x383F4000, 0x383F8000, 0x383FC000,\n  0x38400000, 0x38404000, 0x38408000, 0x3840C000, 0x38410000, 0x38414000, 0x38418000, 0x3841C000, 0x38420000, 0x38424000, 0x38428000, 0x3842C000, 0x38430000, 0x38434000, 0x38438000, 0x3843C000,\n  0x38440000, 0x38444000, 0x38448000, 0x3844C000, 0x38450000, 0x38454000, 0x38458000, 0x3845C000, 0x38460000, 0x38464000, 0x38468000, 0x3846C000, 0x38470000, 0x38474000, 0x38478000, 0x3847C000,\n  0x38480000, 0x38484000, 0x38488000, 0x3848C000, 0x38490000, 0x38494000, 0x38498000, 0x3849C000, 0x384A0000, 0x384A4000, 0x384A8000, 0x384AC000, 0x384B0000, 0x384B4000, 0x384B8000, 0x", "384BC000,\n  0x384C0000, 0x384C4000, 0x384C8000, 0x384CC000, 0x384D0000, 0x384D4000, 0x384D8000, 0x384DC000, 0x384E0000, 0x384E4000, 0x384E8000, 0x384EC000, 0x384F0000, 0x384F4000, 0x384F8000, 0x384FC000,\n  0x38500000, 0x38504000, 0x38508000, 0x3850C000, 0x38510000, 0x38514000, 0x38518000, 0x3851C000, 0x38520000, 0x38524000, 0x38528000, 0x3852C000, 0x38530000, 0x38534000, 0x38538000, 0x3853C000,\n  0x38540000, 0x38544000, 0x38548000, 0x3854C000, 0x38550000, 0x38554000, 0x38558000, 0x3855C000, 0x38560000, 0x38564000, 0x38568000, 0x3856C000, 0x38570000, 0x38574000, 0x38578000, 0x3857C000,\n  0x38580000, 0x38584000, 0x38588000, 0x3858C000, 0x38590000, 0x38594000, 0x38598000, 0x3859C000, 0x385A0000, 0x385A4000, 0x385A8000, 0x385AC000, 0x385B0000, 0x385B4000, 0x385B8000, 0x385BC000,\n  0x385C0000, 0x385C4000, 0x385C8000, 0x385CC000, 0x385D0000, 0x385D4000, 0x385D8000, 0x385DC000, 0x385E0000, 0x385E4000, 0x385E8000, 0x385EC000, 0x385F0000, 0x385F4000, 0x385F8000, 0x385FC000,\n  0x38600000, 0x38604000, 0x38608000, 0x3860C000, 0x38610000, 0x38614000, 0x38618000, 0x3861C000, 0x38620000, 0x38624000, 0x38628000, 0x3862C000, 0x38630000, 0x38634000, 0x38638000, 0x3863C000,\n  0x38640000, 0x38644000, 0x38648000, 0x3864C000, 0x38650000, 0x38654000, 0x38658000, 0x3865C000, 0x38660000, 0x38664000, 0x38668000, 0x3866C000, 0x38670000, 0x38674000, 0x38678000, 0x3867C000,\n  0x38680000, 0x38684000, 0x38688000, 0x3868C000, 0x38690000, 0x38694000, 0x38698000, 0x3869C000, 0x386A0000, 0x386A4000, 0x386A8000, 0x386AC000, 0x386B0000, 0x386B4000, 0x386B8000, 0x386BC000,\n  0x386C0000, 0x386C4000, 0x386C8000, 0x386CC000, 0x386D0000, 0x386D4000, 0x386D8000, 0x386DC000, 0x386E0000, 0x386E4000, 0x386E8000, 0x386EC000, 0x386F0000, 0x386F4000, 0x386F8000, 0x386FC000,\n  0x38700000, 0x38704000, 0x38708000, 0x3870C000, 0x38710000, 0x38714000, 0x38718000, 0x3871C000, 0x38720000, 0x38724000, 0x38728000, 0x3872C000, 0x38730000, 0x38734000, 0x38738000, 0x3873C000,\n  0x38740000, 0x38744000, 0x38748000, 0x3874C000, ", "0x38750000, 0x38754000, 0x38758000, 0x3875C000, 0x38760000, 0x38764000, 0x38768000, 0x3876C000, 0x38770000, 0x38774000, 0x38778000, 0x3877C000,\n  0x38780000, 0x38784000, 0x38788000, 0x3878C000, 0x38790000, 0x38794000, 0x38798000, 0x3879C000, 0x387A0000, 0x387A4000, 0x387A8000, 0x387AC000, 0x387B0000, 0x387B4000, 0x387B8000, 0x387BC000,\n  0x387C0000, 0x387C4000, 0x387C8000, 0x387CC000, 0x387D0000, 0x387D4000, 0x387D8000, 0x387DC000, 0x387E0000, 0x387E4000, 0x387E8000, 0x387EC000, 0x387F0000, 0x387F4000, 0x387F8000, 0x387FC000,\n  0x38000000, 0x38002000, 0x38004000, 0x38006000, 0x38008000, 0x3800A000, 0x3800C000, 0x3800E000, 0x38010000, 0x38012000, 0x38014000, 0x38016000, 0x38018000, 0x3801A000, 0x3801C000, 0x3801E000,\n  0x38020000, 0x38022000, 0x38024000, 0x38026000, 0x38028000, 0x3802A000, 0x3802C000, 0x3802E000, 0x38030000, 0x38032000, 0x38034000, 0x38036000, 0x38038000, 0x3803A000, 0x3803C000, 0x3803E000,\n  0x38040000, 0x38042000, 0x38044000, 0x38046000, 0x38048000, 0x3804A000, 0x3804C000, 0x3804E000, 0x38050000, 0x38052000, 0x38054000, 0x38056000, 0x38058000, 0x3805A000, 0x3805C000, 0x3805E000,\n  0x38060000, 0x38062000, 0x38064000, 0x38066000, 0x38068000, 0x3806A000, 0x3806C000, 0x3806E000, 0x38070000, 0x38072000, 0x38074000, 0x38076000, 0x38078000, 0x3807A000, 0x3807C000, 0x3807E000,\n  0x38080000, 0x38082000, 0x38084000, 0x38086000, 0x38088000, 0x3808A000, 0x3808C000, 0x3808E000, 0x38090000, 0x38092000, 0x38094000, 0x38096000, 0x38098000, 0x3809A000, 0x3809C000, 0x3809E000,\n  0x380A0000, 0x380A2000, 0x380A4000, 0x380A6000, 0x380A8000, 0x380AA000, 0x380AC000, 0x380AE000, 0x380B0000, 0x380B2000, 0x380B4000, 0x380B6000, 0x380B8000, 0x380BA000, 0x380BC000, 0x380BE000,\n  0x380C0000, 0x380C2000, 0x380C4000, 0x380C6000, 0x380C8000, 0x380CA000, 0x380CC000, 0x380CE000, 0x380D0000, 0x380D2000, 0x380D4000, 0x380D6000, 0x380D8000, 0x380DA000, 0x380DC000, 0x380DE000,\n  0x380E0000, 0x380E2000, 0x380E4000, 0x380E6000, 0x380E8000, 0x380EA000, 0x380EC000, 0x380EE000, 0x380F0000, ",
                                    "0x380F2000, 0x380F4000, 0x380F6000, 0x380F8000, 0x380FA000, 0x380FC000, 0x380FE000,\n  0x38100000, 0x38102000, 0x38104000, 0x38106000, 0x38108000, 0x3810A000, 0x3810C000, 0x3810E000, 0x38110000, 0x38112000, 0x38114000, 0x38116000, 0x38118000, 0x3811A000, 0x3811C000, 0x3811E000,\n  0x38120000, 0x38122000, 0x38124000, 0x38126000, 0x38128000, 0x3812A000, 0x3812C000, 0x3812E000, 0x38130000, 0x38132000, 0x38134000, 0x38136000, 0x38138000, 0x3813A000, 0x3813C000, 0x3813E000,\n  0x38140000, 0x38142000, 0x38144000, 0x38146000, 0x38148000, 0x3814A000, 0x3814C000, 0x3814E000, 0x38150000, 0x38152000, 0x38154000, 0x38156000, 0x38158000, 0x3815A000, 0x3815C000, 0x3815E000,\n  0x38160000, 0x38162000, 0x38164000, 0x38166000, 0x38168000, 0x3816A000, 0x3816C000, 0x3816E000, 0x38170000, 0x38172000, 0x38174000, 0x38176000, 0x38178000, 0x3817A000, 0x3817C000, 0x3817E000,\n  0x38180000, 0x38182000, 0x38184000, 0x38186000, 0x38188000, 0x3818A000, 0x3818C000, 0x3818E000, 0x38190000, 0x38192000, 0x38194000, 0x38196000, 0x38198000, 0x3819A000, 0x3819C000, 0x3819E000,\n  0x381A0000, 0x381A2000, 0x381A4000, 0x381A6000, 0x381A8000, 0x381AA000, 0x381AC000, 0x381AE000, 0x381B0000, 0x381B2000, 0x381B4000, 0x381B6000, 0x381B8000, 0x381BA000, 0x381BC000, 0x381BE000,\n  0x381C0000, 0x381C2000, 0x381C4000, 0x381C6000, 0x381C8000, 0x381CA000, 0x381CC000, 0x381CE000, 0x381D0000, 0x381D2000, 0x381D4000, 0x381D6000, 0x381D8000, 0x381DA000, 0x381DC000, 0x381DE000,\n  0x381E0000, 0x381E2000, 0x381E4000, 0x381E6000, 0x381E8000, 0x381EA000, 0x381EC000, 0x381EE000, 0x381F0000, 0x381F2000, 0x381F4000, 0x381F6000, 0x381F8000, 0x381FA000, 0x381FC000, 0x381FE000,\n  0x38200000, 0x38202000, 0x38204000, 0x38206000, 0x38208000, 0x3820A000, 0x3820C000, 0x3820E000, 0x38210000, 0x38212000, 0x38214000, 0x38216000, 0x38218000, 0x3821A000, 0x3821C000, 0x3821E000,\n  0x38220000, 0x38222000, 0x38224000, 0x38226000, 0x38228000, 0x3822A000, 0x3822C000, 0x3822E000, 0x38230000, 0x38232000, 0x38234000, 0x38236000, 0x38238000, 0x3823A000, ", "0x3823C000, 0x3823E000,\n  0x38240000, 0x38242000, 0x38244000, 0x38246000, 0x38248000, 0x3824A000, 0x3824C000, 0x3824E000, 0x38250000, 0x38252000, 0x38254000, 0x38256000, 0x38258000, 0x3825A000, 0x3825C000, 0x3825E000,\n  0x38260000, 0x38262000, 0x38264000, 0x38266000, 0x38268000, 0x3826A000, 0x3826C000, 0x3826E000, 0x38270000, 0x38272000, 0x38274000, 0x38276000, 0x38278000, 0x3827A000, 0x3827C000, 0x3827E000,\n  0x38280000, 0x38282000, 0x38284000, 0x38286000, 0x38288000, 0x3828A000, 0x3828C000, 0x3828E000, 0x38290000, 0x38292000, 0x38294000, 0x38296000, 0x38298000, 0x3829A000, 0x3829C000, 0x3829E000,\n  0x382A0000, 0x382A2000, 0x382A4000, 0x382A6000, 0x382A8000, 0x382AA000, 0x382AC000, 0x382AE000, 0x382B0000, 0x382B2000, 0x382B4000, 0x382B6000, 0x382B8000, 0x382BA000, 0x382BC000, 0x382BE000,\n  0x382C0000, 0x382C2000, 0x382C4000, 0x382C6000, 0x382C8000, 0x382CA000, 0x382CC000, 0x382CE000, 0x382D0000, 0x382D2000, 0x382D4000, 0x382D6000, 0x382D8000, 0x382DA000, 0x382DC000, 0x382DE000,\n  0x382E0000, 0x382E2000, 0x382E4000, 0x382E6000, 0x382E8000, 0x382EA000, 0x382EC000, 0x382EE000, 0x382F0000, 0x382F2000, 0x382F4000, 0x382F6000, 0x382F8000, 0x382FA000, 0x382FC000, 0x382FE000,\n  0x38300000, 0x38302000, 0x38304000, 0x38306000, 0x38308000, 0x3830A000, 0x3830C000, 0x3830E000, 0x38310000, 0x38312000, 0x38314000, 0x38316000, 0x38318000, 0x3831A000, 0x3831C000, 0x3831E000,\n  0x38320000, 0x38322000, 0x38324000, 0x38326000, 0x38328000, 0x3832A000, 0x3832C000, 0x3832E000, 0x38330000, 0x38332000, 0x38334000, 0x38336000, 0x38338000, 0x3833A000, 0x3833C000, 0x3833E000,\n  0x38340000, 0x38342000, 0x38344000, 0x38346000, 0x38348000, 0x3834A000, 0x3834C000, 0x3834E000, 0x38350000, 0x38352000, 0x38354000, 0x38356000, 0x38358000, 0x3835A000, 0x3835C000, 0x3835E000,\n  0x38360000, 0x38362000, 0x38364000, 0x38366000, 0x38368000, 0x3836A000, 0x3836C000, 0x3836E000, 0x38370000, 0x38372000, 0x38374000, 0x38376000, 0x38378000, 0x3837A000, 0x3837C000, 0x3837E000,\n  0x38380000, 0x38382000, 0x38384000", ", 0x38386000, 0x38388000, 0x3838A000, 0x3838C000, 0x3838E000, 0x38390000, 0x38392000, 0x38394000, 0x38396000, 0x38398000, 0x3839A000, 0x3839C000, 0x3839E000,\n  0x383A0000, 0x383A2000, 0x383A4000, 0x383A6000, 0x383A8000, 0x383AA000, 0x383AC000, 0x383AE000, 0x383B0000, 0x383B2000, 0x383B4000, 0x383B6000, 0x383B8000, 0x383BA000, 0x383BC000, 0x383BE000,\n  0x383C0000, 0x383C2000, 0x383C4000, 0x383C6000, 0x383C8000, 0x383CA000, 0x383CC000, 0x383CE000, 0x383D0000, 0x383D2000, 0x383D4000, 0x383D6000, 0x383D8000, 0x383DA000, 0x383DC000, 0x383DE000,\n  0x383E0000, 0x383E2000, 0x383E4000, 0x383E6000, 0x383E8000, 0x383EA000, 0x383EC000, 0x383EE000, 0x383F0000, 0x383F2000, 0x383F4000, 0x383F6000, 0x383F8000, 0x383FA000, 0x383FC000, 0x383FE000,\n  0x38400000, 0x38402000, 0x38404000, 0x38406000, 0x38408000, 0x3840A000, 0x3840C000, 0x3840E000, 0x38410000, 0x38412000, 0x38414000, 0x38416000, 0x38418000, 0x3841A000, 0x3841C000, 0x3841E000,\n  0x38420000, 0x38422000, 0x38424000, 0x38426000, 0x38428000, 0x3842A000, 0x3842C000, 0x3842E000, 0x38430000, 0x38432000, 0x38434000, 0x38436000, 0x38438000, 0x3843A000, 0x3843C000, 0x3843E000,\n  0x38440000, 0x38442000, 0x38444000, 0x38446000, 0x38448000, 0x3844A000, 0x3844C000, 0x3844E000, 0x38450000, 0x38452000, 0x38454000, 0x38456000, 0x38458000, 0x3845A000, 0x3845C000, 0x3845E000,\n  0x38460000, 0x38462000, 0x38464000, 0x38466000, 0x38468000, 0x3846A000, 0x3846C000, 0x3846E000, 0x38470000, 0x38472000, 0x38474000, 0x38476000, 0x38478000, 0x3847A000, 0x3847C000, 0x3847E000,\n  0x38480000, 0x38482000, 0x38484000, 0x38486000, 0x38488000, 0x3848A000, 0x3848C000, 0x3848E000, 0x38490000, 0x38492000, 0x38494000, 0x38496000, 0x38498000, 0x3849A000, 0x3849C000, 0x3849E000,\n  0x384A0000, 0x384A2000, 0x384A4000, 0x384A6000, 0x384A8000, 0x384AA000, 0x384AC000, 0x384AE000, 0x384B0000, 0x384B2000, 0x384B4000, 0x384B6000, 0x384B8000, 0x384BA000, 0x384BC000, 0x384BE000,\n  0x384C0000, 0x384C2000, 0x384C4000, 0x384C6000, 0x384C8000, 0x384CA000, 0x384CC000, 0x384CE000",
                                    ", 0x384D0000, 0x384D2000, 0x384D4000, 0x384D6000, 0x384D8000, 0x384DA000, 0x384DC000, 0x384DE000,\n  0x384E0000, 0x384E2000, 0x384E4000, 0x384E6000, 0x384E8000, 0x384EA000, 0x384EC000, 0x384EE000, 0x384F0000, 0x384F2000, 0x384F4000, 0x384F6000, 0x384F8000, 0x384FA000, 0x384FC000, 0x384FE000,\n  0x38500000, 0x38502000, 0x38504000, 0x38506000, 0x38508000, 0x3850A000, 0x3850C000, 0x3850E000, 0x38510000, 0x38512000, 0x38514000, 0x38516000, 0x38518000, 0x3851A000, 0x3851C000, 0x3851E000,\n  0x38520000, 0x38522000, 0x38524000, 0x38526000, 0x38528000, 0x3852A000, 0x3852C000, 0x3852E000, 0x38530000, 0x38532000, 0x38534000, 0x38536000, 0x38538000, 0x3853A000, 0x3853C000, 0x3853E000,\n  0x38540000, 0x38542000, 0x38544000, 0x38546000, 0x38548000, 0x3854A000, 0x3854C000, 0x3854E000, 0x38550000, 0x38552000, 0x38554000, 0x38556000, 0x38558000, 0x3855A000, 0x3855C000, 0x3855E000,\n  0x38560000, 0x38562000, 0x38564000, 0x38566000, 0x38568000, 0x3856A000, 0x3856C000, 0x3856E000, 0x38570000, 0x38572000, 0x38574000, 0x38576000, 0x38578000, 0x3857A000, 0x3857C000, 0x3857E000,\n  0x38580000, 0x38582000, 0x38584000, 0x38586000, 0x38588000, 0x3858A000, 0x3858C000, 0x3858E000, 0x38590000, 0x38592000, 0x38594000, 0x38596000, 0x38598000, 0x3859A000, 0x3859C000, 0x3859E000,\n  0x385A0000, 0x385A2000, 0x385A4000, 0x385A6000, 0x385A8000, 0x385AA000, 0x385AC000, 0x385AE000, 0x385B0000, 0x385B2000, 0x385B4000, 0x385B6000, 0x385B8000, 0x385BA000, 0x385BC000, 0x385BE000,\n  0x385C0000, 0x385C2000, 0x385C4000, 0x385C6000, 0x385C8000, 0x385CA000, 0x385CC000, 0x385CE000, 0x385D0000, 0x385D2000, 0x385D4000, 0x385D6000, 0x385D8000, 0x385DA000, 0x385DC000, 0x385DE000,\n  0x385E0000, 0x385E2000, 0x385E4000, 0x385E6000, 0x385E8000, 0x385EA000, 0x385EC000, 0x385EE000, 0x385F0000, 0x385F2000, 0x385F4000, 0x385F6000, 0x385F8000, 0x385FA000, 0x385FC000, 0x385FE000,\n  0x38600000, 0x38602000, 0x38604000, 0x38606000, 0x38608000, 0x3860A000, 0x3860C000, 0x3860E000, 0x38610000, 0x38612000, 0x38614000, 0x38616000, 0x38618000", ", 0x3861A000, 0x3861C000, 0x3861E000,\n  0x38620000, 0x38622000, 0x38624000, 0x38626000, 0x38628000, 0x3862A000, 0x3862C000, 0x3862E000, 0x38630000, 0x38632000, 0x38634000, 0x38636000, 0x38638000, 0x3863A000, 0x3863C000, 0x3863E000,\n  0x38640000, 0x38642000, 0x38644000, 0x38646000, 0x38648000, 0x3864A000, 0x3864C000, 0x3864E000, 0x38650000, 0x38652000, 0x38654000, 0x38656000, 0x38658000, 0x3865A000, 0x3865C000, 0x3865E000,\n  0x38660000, 0x38662000, 0x38664000, 0x38666000, 0x38668000, 0x3866A000, 0x3866C000, 0x3866E000, 0x38670000, 0x38672000, 0x38674000, 0x38676000, 0x38678000, 0x3867A000, 0x3867C000, 0x3867E000,\n  0x38680000, 0x38682000, 0x38684000, 0x38686000, 0x38688000, 0x3868A000, 0x3868C000, 0x3868E000, 0x38690000, 0x38692000, 0x38694000, 0x38696000, 0x38698000, 0x3869A000, 0x3869C000, 0x3869E000,\n  0x386A0000, 0x386A2000, 0x386A4000, 0x386A6000, 0x386A8000, 0x386AA000, 0x386AC000, 0x386AE000, 0x386B0000, 0x386B2000, 0x386B4000, 0x386B6000, 0x386B8000, 0x386BA000, 0x386BC000, 0x386BE000,\n  0x386C0000, 0x386C2000, 0x386C4000, 0x386C6000, 0x386C8000, 0x386CA000, 0x386CC000, 0x386CE000, 0x386D0000, 0x386D2000, 0x386D4000, 0x386D6000, 0x386D8000, 0x386DA000, 0x386DC000, 0x386DE000,\n  0x386E0000, 0x386E2000, 0x386E4000, 0x386E6000, 0x386E8000, 0x386EA000, 0x386EC000, 0x386EE000, 0x386F0000, 0x386F2000, 0x386F4000, 0x386F6000, 0x386F8000, 0x386FA000, 0x386FC000, 0x386FE000,\n  0x38700000, 0x38702000, 0x38704000, 0x38706000, 0x38708000, 0x3870A000, 0x3870C000, 0x3870E000, 0x38710000, 0x38712000, 0x38714000, 0x38716000, 0x38718000, 0x3871A000, 0x3871C000, 0x3871E000,\n  0x38720000, 0x38722000, 0x38724000, 0x38726000, 0x38728000, 0x3872A000, 0x3872C000, 0x3872E000, 0x38730000, 0x38732000, 0x38734000, 0x38736000, 0x38738000, 0x3873A000, 0x3873C000, 0x3873E000,\n  0x38740000, 0x38742000, 0x38744000, 0x38746000, 0x38748000, 0x3874A000, 0x3874C000, 0x3874E000, 0x38750000, 0x38752000, 0x38754000, 0x38756000, 0x38758000, 0x3875A000, 0x3875C000, 0x3875E000,\n  0x38760000, 0x387620", "00, 0x38764000, 0x38766000, 0x38768000, 0x3876A000, 0x3876C000, 0x3876E000, 0x38770000, 0x38772000, 0x38774000, 0x38776000, 0x38778000, 0x3877A000, 0x3877C000, 0x3877E000,\n  0x38780000, 0x38782000, 0x38784000, 0x38786000, 0x38788000, 0x3878A000, 0x3878C000, 0x3878E000, 0x38790000, 0x38792000, 0x38794000, 0x38796000, 0x38798000, 0x3879A000, 0x3879C000, 0x3879E000,\n  0x387A0000, 0x387A2000, 0x387A4000, 0x387A6000, 0x387A8000, 0x387AA000, 0x387AC000, 0x387AE000, 0x387B0000, 0x387B2000, 0x387B4000, 0x387B6000, 0x387B8000, 0x387BA000, 0x387BC000, 0x387BE000,\n  0x387C0000, 0x387C2000, 0x387C4000, 0x387C6000, 0x387C8000, 0x387CA000, 0x387CC000, 0x387CE000, 0x387D0000, 0x387D2000, 0x387D4000, 0x387D6000, 0x387D8000, 0x387DA000, 0x387DC000, 0x387DE000,\n  0x387E0000, 0x387E2000, 0x387E4000, 0x387E6000, 0x387E8000, 0x387EA000, 0x387EC000, 0x387EE000, 0x387F0000, 0x387F2000, 0x387F4000, 0x387F6000, 0x387F8000, 0x387FA000, 0x387FC000, 0x387FE000 };\n__constant static const uint32_t exponent_table[64] = {\n  0x00000000, 0x00800000, 0x01000000, 0x01800000, 0x02000000, 0x02800000, 0x03000000, 0x03800000, 0x04000000, 0x04800000, 0x05000000, 0x05800000, 0x06000000, 0x06800000, 0x07000000, 0x07800000,\n  0x08000000, 0x08800000, 0x09000000, 0x09800000, 0x0A000000, 0x0A800000, 0x0B000000, 0x0B800000, 0x0C000000, 0x0C800000, 0x0D000000, 0x0D800000, 0x0E000000, 0x0E800000, 0x0F000000, 0x47800000,\n  0x80000000, 0x80800000, 0x81000000, 0x81800000, 0x82000000, 0x82800000, 0x83000000, 0x83800000, 0x84000000, 0x84800000, 0x85000000, 0x85800000, 0x86000000, 0x86800000, 0x87000000, 0x87800000,\n  0x88000000, 0x88800000, 0x89000000, 0x89800000, 0x8A000000, 0x8A800000, 0x8B000000, 0x8B800000, 0x8C000000, 0x8C800000, 0x8D000000, 0x8D800000, 0x8E000000, 0x8E800000, 0x8F000000, 0xC7800000 };\n__constant static const unsigned short offset_table[64] = {\n  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1",
                                    "024, 1024, 1024, 1024, 1024, 1024,\n  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024 };\n\nSCALAR_FUN_ATTR uint16_t float2halfbits(float value) {\n  union { float x; uint32_t y; } u;\n  u.x = value;\n  uint32_t bits = u.y;\n\n  uint16_t hbits = base_table[bits>>23] + (uint16_t)((bits&0x7FFFFF)>>shift_table[bits>>23]);;\n\n  return hbits;\n}\n\nSCALAR_FUN_ATTR float halfbits2float(uint16_t value) {\n  uint32_t bits = mantissa_table[offset_table[value>>10]+(value&0x3FF)] + exponent_table[value>>10];\n\n  union { uint32_t x; float y; } u;\n  u.x = bits;\n  return u.y;\n}\n\nSCALAR_FUN_ATTR uint16_t halfbitsnextafter(uint16_t from, uint16_t to) {\n  int fabs = from & 0x7FFF, tabs = to & 0x7FFF;\n  if(fabs > 0x7C00 || tabs > 0x7C00) {\n    return ((from&0x7FFF)>0x7C00) ? (from|0x200) : (to|0x200);\n  }\n  if(from == to || !(fabs|tabs)) {\n    return to;\n  }\n  if(!fabs) {\n    return (to&0x8000)+1;\n  }\n  unsigned int out =\n    from +\n    (((from>>15)^(unsigned int)((from^(0x8000|(0x8000-(from>>15))))<(to^(0x8000|(0x8000-(to>>15))))))<<1)\n    - 1;\n  return out;\n}\n\n// End of half.h.\n// Start of scalar.h.\n\n// Implementation of the primitive scalar operations.  Very\n// repetitive.  This code is inserted directly into both CUDA and\n// OpenCL programs, as well as the CPU code, so it has some #ifdefs to\n// work everywhere.  Some operations are defined as macros because\n// this allows us to use them as constant expressions in things like\n// array sizes and static initialisers.\n\n// Some of the #ifdefs are because OpenCL uses type-generic functions\n// for some operations (e.g. sqrt), while C and CUDA sensibly use\n// distinct functions for different precisions (e.g. sqrtf() and\n// sqrt()).  This is quite annoying.  Due to C's unfortunate casting\n// rules, it is also really easy to accidentally implement\n// floating-point functions in the wrong precision, so be careful.\n\n/", "/ Double-precision definitions are only included if the preprocessor\n// macro FUTHARK_F64_ENABLED is set.\n\nSCALAR_FUN_ATTR int32_t futrts_to_bits32(float x);\nSCALAR_FUN_ATTR float futrts_from_bits32(int32_t x);\n\nSCALAR_FUN_ATTR uint8_t add8(uint8_t x, uint8_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint16_t add16(uint16_t x, uint16_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint32_t add32(uint32_t x, uint32_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint64_t add64(uint64_t x, uint64_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint8_t sub8(uint8_t x, uint8_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint16_t sub16(uint16_t x, uint16_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint32_t sub32(uint32_t x, uint32_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint64_t sub64(uint64_t x, uint64_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint8_t mul8(uint8_t x, uint8_t y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR uint16_t mul16(uint16_t x, uint16_t y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR uint32_t mul32(uint32_t x, uint32_t y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR uint64_t mul64(uint64_t x, uint64_t y) {\n  return x * y;\n}\n\n#if ISPC\n\nSCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {\n  // This strange pattern is used to prevent the ISPC compiler from\n  // causing SIGFPEs and bogus results on divisions where inactive lanes\n  // have 0-valued divisors. It ensures that any inactive lane instead\n  // has a divisor of 1. https://github.com/ispc/ispc/issues/2292\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {\n  uint", "8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALA",
                                    "R_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int8_t q = x / ys;\n  int8_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int16_t q = x / ys;\n  int16_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  int32_t q = x / ys;\n  int32_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int64_t q = x / ys;\n  int64_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {\n  return sdiv8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {\n  return sdiv16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y)", " {\n  return sdiv32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {\n  return sdiv64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int8_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int16_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int32_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int64_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : sdiv8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : sdiv16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : sdiv32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : sdiv64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {\n  return sdiv_safe8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {\n  return sdiv_safe16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {\n  return sdiv_safe32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {\n  return sdiv_safe64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : smod8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : smod16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) ", "{\n  return y == 0 ? 0 : smod32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : smod64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  ",
                                    "foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\n#else\n\nSCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {\n  return", " y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {\n  int8_t q = x / y;\n  int8_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {\n  int16_t q = x / y;\n  int16_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {\n  int32_t q = x / y;\n  int32_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {\n  int64_t q = x / y;\n  int64_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {\n  return sdiv8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {\n  return sdiv16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {\n  return sdiv32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {\n  return sdiv64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {\n  int8_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {\n  int16_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {\n  int32_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {\n  int64_t r = ", "x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : sdiv8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : sdiv16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : sdiv32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : sdiv64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {\n  return sdiv_safe8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {\n  return sdiv_safe16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {\n  return sdiv_safe32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {\n  return sdiv_safe64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : smod8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : smod16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : smod32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : smod64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t ",
                                    "y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\n#endif\n\nSCALAR_FUN_ATTR int8_t smin8(int8_t x, int8_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int16_t smin16(int16_t x, int16_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int32_t smin32(int32_t x, int32_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int64_t smin64(int64_t x, int64_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint8_t umin8(uint8_t x, uint8_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint16_t umin16(uint16_t x, uint16_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint32_t umin32(uint32_t x, uint32_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint64_t umin64(uint64_t x, uint64_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int8_t smax8(int8_t x, int8_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR int16_t smax16(int16_t x, int16_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR int32_t smax32(int32_t x, int32_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR int64_t smax64(int64_t x, int64_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint8_t umax8(uint8_t x, uint8_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint16_t umax16(uint16_t x, uint16_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint32_t umax32(uint32_t x, uint32_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint64_t umax64(uint64_t x, uint64_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint8_t shl8(uint8_t x, uint8_t y) {\n  return (uint8_t)(x << y);\n}\n\nS", "CALAR_FUN_ATTR uint16_t shl16(uint16_t x, uint16_t y) {\n  return (uint16_t)(x << y);\n}\n\nSCALAR_FUN_ATTR uint32_t shl32(uint32_t x, uint32_t y) {\n  return x << y;\n}\n\nSCALAR_FUN_ATTR uint64_t shl64(uint64_t x, uint64_t y) {\n  return x << y;\n}\n\nSCALAR_FUN_ATTR uint8_t lshr8(uint8_t x, uint8_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint16_t lshr16(uint16_t x, uint16_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint32_t lshr32(uint32_t x, uint32_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint64_t lshr64(uint64_t x, uint64_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int8_t ashr8(int8_t x, int8_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int16_t ashr16(int16_t x, int16_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int32_t ashr32(int32_t x, int32_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int64_t ashr64(int64_t x, int64_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint8_t and8(uint8_t x, uint8_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint16_t and16(uint16_t x, uint16_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint32_t and32(uint32_t x, uint32_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint64_t and64(uint64_t x, uint64_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint8_t or8(uint8_t x, uint8_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint16_t or16(uint16_t x, uint16_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint32_t or32(uint32_t x, uint32_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint64_t or64(uint64_t x, uint64_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint8_t xor8(uint8_t x, uint8_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR uint16_t xor16(uint16_t x, uint16_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR uint32_t xor32(uint32_t x, uint32_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR uint64_t xor64(uint64_t x, uint64_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR bool ult8(uint8_t x, uint8_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ult16(uint16_t x, uint16_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ult32(uint32_t x, uint32_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ult64(uint64_t x, uint64", "_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ule8(uint8_t x, uint8_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool ule16(uint16_t x, uint16_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool ule32(uint32_t x, uint32_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool ule64(uint64_t x, uint64_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool slt8(int8_t x, int8_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool slt16(int16_t x, int16_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool slt32(int32_t x, int32_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool slt64(int64_t x, int64_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool sle8(int8_t x, int8_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool sle16(int16_t x, int16_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool sle32(int32_t x, int32_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool sle64(int64_t x, int64_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR uint8_t pow8(uint8_t x, uint8_t y) {\n  uint8_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uint16_t pow16(uint16_t x, uint16_t y) {\n  uint16_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uint32_t pow32(uint32_t x, uint32_t y) {\n  uint32_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uint64_t pow64(uint64_t x, uint64_t y) {\n  uint64_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR bool itob_i8_bool(int8_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR bool itob_i16_bool(int16_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR bool itob_i32_bool(int32_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR bool itob_i64_bool(int64_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR int8_t btoi_bool_i8(bool x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR int16_t btoi_bool_i16(bool x",
                                    ") {\n  return x;\n}\n\nSCALAR_FUN_ATTR int32_t btoi_bool_i32(bool x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR int64_t btoi_bool_i64(bool x) {\n  return x;\n}\n\n#define sext_i8_i8(x) ((int8_t) (int8_t) (x))\n#define sext_i8_i16(x) ((int16_t) (int8_t) (x))\n#define sext_i8_i32(x) ((int32_t) (int8_t) (x))\n#define sext_i8_i64(x) ((int64_t) (int8_t) (x))\n#define sext_i16_i8(x) ((int8_t) (int16_t) (x))\n#define sext_i16_i16(x) ((int16_t) (int16_t) (x))\n#define sext_i16_i32(x) ((int32_t) (int16_t) (x))\n#define sext_i16_i64(x) ((int64_t) (int16_t) (x))\n#define sext_i32_i8(x) ((int8_t) (int32_t) (x))\n#define sext_i32_i16(x) ((int16_t) (int32_t) (x))\n#define sext_i32_i32(x) ((int32_t) (int32_t) (x))\n#define sext_i32_i64(x) ((int64_t) (int32_t) (x))\n#define sext_i64_i8(x) ((int8_t) (int64_t) (x))\n#define sext_i64_i16(x) ((int16_t) (int64_t) (x))\n#define sext_i64_i32(x) ((int32_t) (int64_t) (x))\n#define sext_i64_i64(x) ((int64_t) (int64_t) (x))\n#define zext_i8_i8(x) ((int8_t) (uint8_t) (x))\n#define zext_i8_i16(x) ((int16_t) (uint8_t) (x))\n#define zext_i8_i32(x) ((int32_t) (uint8_t) (x))\n#define zext_i8_i64(x) ((int64_t) (uint8_t) (x))\n#define zext_i16_i8(x) ((int8_t) (uint16_t) (x))\n#define zext_i16_i16(x) ((int16_t) (uint16_t) (x))\n#define zext_i16_i32(x) ((int32_t) (uint16_t) (x))\n#define zext_i16_i64(x) ((int64_t) (uint16_t) (x))\n#define zext_i32_i8(x) ((int8_t) (uint32_t) (x))\n#define zext_i32_i16(x) ((int16_t) (uint32_t) (x))\n#define zext_i32_i32(x) ((int32_t) (uint32_t) (x))\n#define zext_i32_i64(x) ((int64_t) (uint32_t) (x))\n#define zext_i64_i8(x) ((int8_t) (uint64_t) (x))\n#define zext_i64_i16(x) ((int16_t) (uint64_t) (x))\n#define zext_i64_i32(x) ((int32_t) (uint64_t) (x))\n#define zext_i64_i64(x) ((int64_t) (uint64_t) (x))\n\nSCALAR_FUN_ATTR int8_t abs8(int8_t x) {\n  return (int8_t)abs(x);\n}\n\nSCALAR_FUN_ATTR int16_t abs16(int16_t x) {\n  return (int16_t)abs(x);\n}\n\nSCALAR_FUN_ATTR int32_t abs32(int32_t x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR int64_t abs64(int64_t x) {\n#if defined(__OPENCL_VER", "SION__) || defined(ISPC)\n  return abs(x);\n#else\n  return llabs(x);\n#endif\n}\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {\n  return popcount(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {\n  return popcount(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {\n  return popcount(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {\n  return popcount(x);\n}\n#elif defined(__CUDA_ARCH__)\n\nSCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {\n  return __popc(zext_i8_i32(x));\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {\n  return __popc(zext_i16_i32(x));\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {\n  return __popc(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {\n  return __popcll(x);\n}\n\n#else // Not OpenCL or CUDA, but plain C.\n\nSCALAR_FUN_ATTR int32_t futrts_popc8(uint8_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc16(uint16_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc32(uint32_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc64(uint64_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR uint8_t  futrts_umul_hi8 ( uint8_t a,  uint8_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint8_t  futrts_smul_hi8 ( int8_t a,  int8_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return m", "ul_hi(a, b); }\n#elif defined(__CUDA_ARCH__)\nSCALAR_FUN_ATTR  uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return __umulhi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return __umul64hi(a, b); }\nSCALAR_FUN_ATTR  uint8_t futrts_smul_hi8 ( int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return __mulhi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return __mul64hi(a, b); }\n#elif ISPC\nSCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) {\n  uint64_t ah = a >> 32;\n  uint64_t al = a & 0xffffffff;\n  uint64_t bh = b >> 32;\n  uint64_t bl = b & 0xffffffff;\n\n  uint64_t p1 = al * bl;\n  uint64_t p2 = al * bh;\n  uint64_t p3 = ah * bl;\n  uint64_t p4 = ah * bh;\n\n  uint64_t p1h = p1 >> 32;\n  uint64_t p2h = p2 >> 32;\n  uint64_t p3h = p3 >> 32;\n  uint64_t p2l = p2 & 0xffffffff;\n  uint64_t p3l = p3 & 0xffffffff;\n\n  uint64_t l = p1h + p2l + p3l;\n  uint64_t m = (p2 >> 32) + (p3 >> 32);\n  uint64_t h = (l >> 32) + m + p4;\n\n  return h;\n}\nSCALAR_FUN_ATTR  int8_t futrts_smul_hi8 ( int8_t a,  int8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR int",
                                    "32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nSCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) {\n  uint64_t ah = a >> 32;\n  uint64_t al = a & 0xffffffff;\n  uint64_t bh = b >> 32;\n  uint64_t bl = b & 0xffffffff;\n\n  uint64_t p1 =  al * bl;\n  int64_t  p2 = al * bh;\n  int64_t  p3 = ah * bl;\n  uint64_t p4 =  ah * bh;\n\n  uint64_t p1h = p1 >> 32;\n  uint64_t p2h = p2 >> 32;\n  uint64_t p3h = p3 >> 32;\n  uint64_t p2l = p2 & 0xffffffff;\n  uint64_t p3l = p3 & 0xffffffff;\n\n  uint64_t l = p1h + p2l + p3l;\n  uint64_t m = (p2 >> 32) + (p3 >> 32);\n  uint64_t h = (l >> 32) + m + p4;\n\n  return h;\n}\n\n#else // Not OpenCL, ISPC, or CUDA, but plain C.\nSCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return ((__uint128_t)a) * ((__uint128_t)b) >> 64; }\nSCALAR_FUN_ATTR int8_t futrts_smul_hi8(int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }\nSCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }\nSCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((int64_t)a) * ((int64_t)b) >> 32; }\nSCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) { return ((__int128_t)a) * ((__int128_t)b) >> 64; }\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR  uint8_t futrts_umad_hi8 ( uint8_t a,  uint8_t b,  uint8_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t ", "a, uint64_t b, uint64_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR  uint8_t futrts_smad_hi8( int8_t a,  int8_t b,   int8_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return mad_hi(a, b, c); }\n#else // Not OpenCL\n\nSCALAR_FUN_ATTR  uint8_t futrts_umad_hi8( uint8_t a,  uint8_t b,  uint8_t c) { return futrts_umul_hi8(a, b) + c; }\nSCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return futrts_umul_hi16(a, b) + c; }\nSCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return futrts_umul_hi32(a, b) + c; }\nSCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return futrts_umul_hi64(a, b) + c; }\nSCALAR_FUN_ATTR  uint8_t futrts_smad_hi8 ( int8_t a,  int8_t b,  int8_t c) { return futrts_smul_hi8(a, b) + c; }\nSCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return futrts_smul_hi16(a, b) + c; }\nSCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return futrts_smul_hi32(a, b) + c; }\nSCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return futrts_smul_hi64(a, b) + c; }\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  return clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return clz(x);\n}\n\n#elif defined(__CUDA_ARCH__)\n\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return __clz(zext_i8_i32(x)) - 24;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return __clz(zext_i16_i32(x)) - 16;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  retur", "n __clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return __clzll(x);\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return count_leading_zeros((int32_t)(uint8_t)x)-24;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return count_leading_zeros((int32_t)(uint16_t)x)-16;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  return count_leading_zeros(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return count_leading_zeros(x);\n}\n\n#else // Not OpenCL, ISPC or CUDA, but plain C.\n\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return x == 0 ? 8 : __builtin_clz((uint32_t)zext_i8_i32(x)) - 24;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return x == 0 ? 16 : __builtin_clz((uint32_t)zext_i16_i32(x)) - 16;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  return x == 0 ? 32 : __builtin_clz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return x == 0 ? 64 : __builtin_clzll((uint64_t)x);\n}\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  int i = 0;\n  for (; i < 8 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  int i = 0;\n  for (; i < 16 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  int i = 0;\n  for (; i < 32 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  int i = 0;\n  for (; i < 64 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\n#elif defined(__CUDA_ARCH__)\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 8 : y - 1;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 16 : y - 1;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 32 : y - 1;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  int y = __ffsll(x);\n  return y == 0 ? 64 : y - 1",
                                    ";\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  return x == 0 ? 8 : count_trailing_zeros((int32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  return x == 0 ? 16 : count_trailing_zeros((int32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  return count_trailing_zeros(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  return count_trailing_zeros(x);\n}\n\n#else // Not OpenCL or CUDA, but plain C.\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  return x == 0 ? 8 : __builtin_ctz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  return x == 0 ? 16 : __builtin_ctz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  return x == 0 ? 32 : __builtin_ctz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  return x == 0 ? 64 : __builtin_ctzll((uint64_t)x);\n}\n#endif\n\nSCALAR_FUN_ATTR float fdiv32(float x, float y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR float fadd32(float x, float y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR float fsub32(float x, float y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR float fmul32(float x, float y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt32(float x, float y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple32(float x, float y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR float sitofp_i8_f32(int8_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float sitofp_i16_f32(int16_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float sitofp_i32_f32(int32_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float sitofp_i64_f32(int64_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i8_f32(uint8_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i16_f32(uint16_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i32_f32(uint32_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i64_f32(uint64_t x) {\n  return (float) x;\n}\n\n#ifdef __OPENCL_VERSION__\nSCALAR_FUN_ATTR float fabs32(float x) {\n  return fabs(x);\n}\n\nSCALAR_FUN_ATTR float fmax32(float x, f", "loat y) {\n  return fmax(x, y);\n}\n\nSCALAR_FUN_ATTR float fmin32(float x, float y) {\n  return fmin(x, y);\n}\n\nSCALAR_FUN_ATTR float fpow32(float x, float y) {\n  return pow(x, y);\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR float fabs32(float x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR float fmax32(float x, float y) {\n  return isnan(x) ? y : isnan(y) ? x : max(x, y);\n}\n\nSCALAR_FUN_ATTR float fmin32(float x, float y) {\n  return isnan(x) ? y : isnan(y) ? x : min(x, y);\n}\n\nSCALAR_FUN_ATTR float fpow32(float a, float b) {\n  float ret;\n  foreach_active (i) {\n      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));\n      ret = insert(ret, i, r);\n  }\n  return ret;\n}\n\n#else // Not OpenCL, but CUDA or plain C.\n\nSCALAR_FUN_ATTR float fabs32(float x) {\n  return fabsf(x);\n}\n\nSCALAR_FUN_ATTR float fmax32(float x, float y) {\n  return fmaxf(x, y);\n}\n\nSCALAR_FUN_ATTR float fmin32(float x, float y) {\n  return fminf(x, y);\n}\n\nSCALAR_FUN_ATTR float fpow32(float x, float y) {\n  return powf(x, y);\n}\n#endif\n\nSCALAR_FUN_ATTR bool futrts_isnan32(float x) {\n  return isnan(x);\n}\n\n#if ISPC\n\nSCALAR_FUN_ATTR bool futrts_isinf32(float x) {\n  return !isnan(x) && isnan(x - x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isfinite32(float x) {\n  return !isnan(x) && !futrts_isinf32(x);\n}\n\n#else\n\nSCALAR_FUN_ATTR bool futrts_isinf32(float x) {\n  return isinf(x);\n}\n\n#endif\n\nSCALAR_FUN_ATTR int8_t fptosi_f32_i8(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f32_i16(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f32_i32(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f32_i64(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  };\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f32_i8(float x) {", "\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f32_i16(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f32_i32(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f32_i64(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR bool ftob_f32_bool(float x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR float btof_bool_f32(bool x) {\n  return x ? 1 : 0;\n}\n\n#ifdef __OPENCL_VERSION__\nSCALAR_FUN_ATTR float futrts_log32(float x) {\n  return log(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log2_32(float x) {\n  return log2(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log10_32(float x) {\n  return log10(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log1p_32(float x) {\n  return log1p(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sqrt32(float x) {\n  return sqrt(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cbrt32(float x) {\n  return cbrt(x);\n}\n\nSCALAR_FUN_ATTR float futrts_exp32(float x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cos32(float x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sin32(float x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tan32(float x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acos32(float x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asin32(float x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan32(float x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cosh32(float x) {\n  return cosh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sinh32(float x) {\n  return sinh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tanh32(float x) {\n  return tanh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acosh32(float x) {\n  return acosh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asinh32(float x) {\n  return asinh(x);\n}\n\nSC",
                                    "ALAR_FUN_ATTR float futrts_atanh32(float x) {\n  return atanh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {\n  return atan2(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {\n  return hypot(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_gamma32(float x) {\n  return tgamma(x);\n}\n\nSCALAR_FUN_ATTR float futrts_lgamma32(float x) {\n  return lgamma(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erf32(float x) {\n  return erf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erfc32(float x) {\n  return erfc(x);\n}\n\nSCALAR_FUN_ATTR float fmod32(float x, float y) {\n  return fmod(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_round32(float x) {\n  return rint(x);\n}\n\nSCALAR_FUN_ATTR float futrts_floor32(float x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR float futrts_ceil32(float x) {\n  return ceil(x);\n}\n\nSCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {\n  return nextafter(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {\n  return mix(v0, v1, t);\n}\n\nSCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {\n  return ldexp(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {\n  return copysign(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {\n  return mad(a, b, c);\n}\n\nSCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {\n  return fma(a, b, c);\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR float futrts_log32(float x) {\n  return futrts_isfinite32(x) || (futrts_isinf32(x) && x < 0)? log(x) : x;\n}\n\nSCALAR_FUN_ATTR float futrts_log2_32(float x) {\n  return futrts_log32(x) / log(2.0f);\n}\n\nSCALAR_FUN_ATTR float futrts_log10_32(float x) {\n  return futrts_log32(x) / log(10.0f);\n}\n\nSCALAR_FUN_ATTR float futrts_log1p_32(float x) {\n  if(x == -1.0f || (futrts_isinf32(x) && x > 0.0f)) return x / 0.0f;\n  float y = 1.0f + x;\n  float z = y - 1.0f;\n  return log(y) - (z-x)/y;\n}\n\nSCALAR_FUN_ATTR float futrts_sqrt32(float x) {\n  return sqrt(x);\n}\n\nextern \"C\" unmasked uniform float cbrtf(uniform float);\nSCALAR_FUN_ATTR float futrts_cbrt32(float", " x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = cbrtf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR float futrts_exp32(float x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cos32(float x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sin32(float x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tan32(float x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acos32(float x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asin32(float x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan32(float x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cosh32(float x) {\n  return (exp(x)+exp(-x)) / 2.0f;\n}\n\nSCALAR_FUN_ATTR float futrts_sinh32(float x) {\n  return (exp(x)-exp(-x)) / 2.0f;\n}\n\nSCALAR_FUN_ATTR float futrts_tanh32(float x) {\n  return futrts_sinh32(x)/futrts_cosh32(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acosh32(float x) {\n  float f = x+sqrt(x*x-1);\n  if(futrts_isfinite32(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR float futrts_asinh32(float x) {\n  float f = x+sqrt(x*x+1);\n  if(futrts_isfinite32(f)) return log(f);\n  return f;\n\n}\n\nSCALAR_FUN_ATTR float futrts_atanh32(float x) {\n  float f = (1+x)/(1-x);\n  if(futrts_isfinite32(f)) return log(f)/2.0f;\n  return f;\n\n}\n\nSCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {\n  return (x == 0.0f && y == 0.0f) ? 0.0f : atan2(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {\n  if (futrts_isfinite32(x) && futrts_isfinite32(y)) {\n    x = abs(x);\n    y = abs(y);\n    float a;\n    float b;\n    if (x >= y){\n        a = x;\n        b = y;\n    } else {\n        a = y;\n        b = x;\n    }\n    if(b == 0){\n      return a;\n    }\n\n    int e;\n    float an;\n    float bn;\n    an = frexp (a, &e);\n    bn = ldexp (b, - e);\n    float cn;\n    cn = sqrt (an * an + bn * bn);\n    return ldexp (cn, e);\n  } else {\n    if (futrts_isinf32(x) || futrts_isinf32(y)) return INFINITY;\n    else return x + y;\n  }\n\n}\n\nextern \"C\" unmasked uniform float tgammaf(", "uniform float x);\nSCALAR_FUN_ATTR float futrts_gamma32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = tgammaf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float lgammaf(uniform float x);\nSCALAR_FUN_ATTR float futrts_lgamma32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = lgammaf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float erff(uniform float x);\nSCALAR_FUN_ATTR float futrts_erf32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = erff(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float erfcf(uniform float x);\nSCALAR_FUN_ATTR float futrts_erfc32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = erfcf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR float fmod32(float x, float y) {\n  return x - y * trunc(x/y);\n}\n\nSCALAR_FUN_ATTR float futrts_round32(float x) {\n  return round(x);\n}\n\nSCALAR_FUN_ATTR float futrts_floor32(float x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR float futrts_ceil32(float x) {\n  return ceil(x);\n}\n\nextern \"C\" unmasked uniform float nextafterf(uniform float x, uniform float y);\nSCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {\n  float res;\n  foreach_active (i) {\n    uniform float r = nextafterf(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {\n  return x * pow((double)2.0, (double)y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {\n  int32_t xb = futrts_to_bits32(x);\n  int32_t yb = futrts_to_bits32(y);\n  return futrts_from_bits32((xb & ~(1<<31)) | (yb & (1<<31)));\n}\n\nSCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR float futr",
                                    "ts_fma32(float a, float b, float c) {\n  return a * b + c;\n}\n\n#else // Not OpenCL or ISPC, but CUDA or plain C.\n\nSCALAR_FUN_ATTR float futrts_log32(float x) {\n  return logf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log2_32(float x) {\n  return log2f(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log10_32(float x) {\n  return log10f(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log1p_32(float x) {\n  return log1pf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sqrt32(float x) {\n  return sqrtf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cbrt32(float x) {\n  return cbrtf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_exp32(float x) {\n  return expf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cos32(float x) {\n  return cosf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sin32(float x) {\n  return sinf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tan32(float x) {\n  return tanf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acos32(float x) {\n  return acosf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asin32(float x) {\n  return asinf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan32(float x) {\n  return atanf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cosh32(float x) {\n  return coshf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sinh32(float x) {\n  return sinhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tanh32(float x) {\n  return tanhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acosh32(float x) {\n  return acoshf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asinh32(float x) {\n  return asinhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atanh32(float x) {\n  return atanhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {\n  return atan2f(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {\n  return hypotf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_gamma32(float x) {\n  return tgammaf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_lgamma32(float x) {\n  return lgammaf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erf32(float x) {\n  return erff(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erfc32(float x) {\n  return erfcf(x);\n}\n\nSCALAR_FUN_ATTR float fmod32(float x, float y) {\n  return fmodf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_round32(float x) {\n  re", "turn rintf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_floor32(float x) {\n  return floorf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_ceil32(float x) {\n  return ceilf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {\n  return nextafterf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {\n  return ldexpf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {\n  return copysignf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {\n  return fmaf(a, b, c);\n}\n#endif\n\n#if ISPC\nSCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {\n  return intbits(x);\n}\n\nSCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {\n  return floatbits(x);\n}\n#else\nSCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {\n  union {\n    float f;\n    int32_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {\n  union {\n    int32_t f;\n    float t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n#endif\n\nSCALAR_FUN_ATTR float fsignum32(float x) {\n  return futrts_isnan32(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nSCALAR_FUN_ATTR double futrts_from_bits64(int64_t x);\nSCALAR_FUN_ATTR int64_t futrts_to_bits64(double x);\n\n#if ISPC\nSCALAR_FUN_ATTR bool futrts_isinf64(float x) {\n  return !isnan(x) && isnan(x - x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isfinite64(float x) {\n  return !isnan(x) && !futrts_isinf64(x);\n}\n\nSCALAR_FUN_ATTR double fdiv64(double x, double y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR double fadd64(double x, double y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR double fsub64(double x, double y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR double fmul64(double x, double y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt64(double x, double y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple64(double x, double y) {\n  return x <= y;\n}", "\n\nSCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double fabs64(double x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR double fmax64(double x, double y) {\n  return isnan(x) ? y : isnan(y) ? x : max(x, y);\n}\n\nSCALAR_FUN_ATTR double fmin64(double x, double y) {\n  return isnan(x) ? y : isnan(y) ? x : min(x, y);\n}\n\nSCALAR_FUN_ATTR double fpow64(double a, double b) {\n  float ret;\n  foreach_active (i) {\n      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));\n      ret = insert(ret, i, r);\n  }\n  return ret;\n}\n\nSCALAR_FUN_ATTR double futrts_log64(double x) {\n  return futrts_isfinite64(x) || (futrts_isinf64(x) && x < 0)? log(x) : x;\n}\n\nSCALAR_FUN_ATTR double futrts_log2_64(double x) {\n  return futrts_log64(x)/log(2.0d);\n}\n\nSCALAR_FUN_ATTR double futrts_log10_64(double x) {\n  return futrts_log64(x)/log(10.0d);\n}\n\nSCALAR_FUN_ATTR double futrts_log1p_64(double x) {\n  if(x == -1.0d || (futrts_isinf64(x) && x > 0.0d)) return x / 0.0d;\n  double y = 1.0d + x;\n  double z = y - 1.0d;\n  return log(y) - (z-x)/y;\n}\n\nSCALAR_FUN_ATTR double futrts_sqrt64(double x) {\n  return sqrt(x);\n}\n\nextern \"C\" unmasked uniform double cbrt(uniform double);\nSCALAR_FUN_ATTR double futrts_cbrt64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = cbrtf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_exp64(double x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cos64(dou",
                                    "ble x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sin64(double x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_tan64(double x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acos64(double x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_asin64(double x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atan64(double x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cosh64(double x) {\n  return (exp(x)+exp(-x)) / 2.0d;\n}\n\nSCALAR_FUN_ATTR double futrts_sinh64(double x) {\n  return (exp(x)-exp(-x)) / 2.0d;\n}\n\nSCALAR_FUN_ATTR double futrts_tanh64(double x) {\n  return futrts_sinh64(x)/futrts_cosh64(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acosh64(double x) {\n  double f = x+sqrt(x*x-1.0d);\n  if(futrts_isfinite64(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR double futrts_asinh64(double x) {\n  double f = x+sqrt(x*x+1.0d);\n  if(futrts_isfinite64(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR double futrts_atanh64(double x) {\n  double f = (1.0d+x)/(1.0d-x);\n  if(futrts_isfinite64(f)) return log(f)/2.0d;\n  return f;\n\n}\n\nSCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {\n  return atan2(x, y);\n}\n\nextern \"C\" unmasked uniform double hypot(uniform double x, uniform double y);\nSCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {\n  double res;\n  foreach_active (i) {\n    uniform double r = hypot(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double tgamma(uniform double x);\nSCALAR_FUN_ATTR double futrts_gamma64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = tgamma(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double lgamma(uniform double x);\nSCALAR_FUN_ATTR double futrts_lgamma64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = lgamma(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double erf(uniform double x);\nSCALAR_FUN_ATTR do", "uble futrts_erf64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = erf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double erfc(uniform double x);\nSCALAR_FUN_ATTR double futrts_erfc64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = erfc(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR double futrts_round64(double x) {\n  return round(x);\n}\n\nSCALAR_FUN_ATTR double futrts_ceil64(double x) {\n  return ceil(x);\n}\n\nextern \"C\" unmasked uniform double nextafter(uniform float x, uniform double y);\nSCALAR_FUN_ATTR float futrts_nextafter64(double x, double y) {\n  double res;\n  foreach_active (i) {\n    uniform double r = nextafter(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_floor64(double x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isnan64(double x) {\n  return isnan(x);\n}\n\nSCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int", "16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR bool ftob_f64_bool(double x) {\n  return x != 0.0;\n}\n\nSCALAR_FUN_ATTR double btof_bool_f64(bool x) {\n  return x ? 1.0 : 0.0;\n}\n\nSCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {\n  int64_t res;\n  foreach_active (i) {\n    uniform double tmp = extract(x, i);\n    uniform int64_t r = *((uniform int64_t* uniform)&tmp);\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {\n  double res;\n  foreach_active (i) {\n    uniform int64_t tmp = extract(x, i);\n    uniform double r = *((uniform double* uniform)&tmp);\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double fmod64(double x, double y) {\n  return x - y * trunc(x/y);\n}\n\nSCALAR_FUN_ATTR double fsignum64(double x) {\n  return futrts_isnan64(x) ? x : (x > 0 ? 1.0d : 0.0d) - (x < 0 ? 1.0d : 0.0d);\n}\n\nSCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {\n  return x * pow((double)2.0, (double)y);\n}\n\nSCALAR_FUN_ATTR double futrts_copysign64(double x, double y) {\n  int64_t xb = futrts_to_bits64(x);\n  int64_t yb = futrts_to_bits64(y);\n  return futrts_from_bits64((xb & ~(((int64_t)1)<<63)) | (yb & (((int64_t)1)<<63)));\n}\n\nSCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR float fpconv_f32_f32(float x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f32_f64(float x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR float fpconv_f64_f32(double x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f64_f64(double x) {\n  return (double) x;\n}\n\n#e",
                                    "lse\n\nSCALAR_FUN_ATTR double fdiv64(double x, double y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR double fadd64(double x, double y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR double fsub64(double x, double y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR double fmul64(double x, double y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt64(double x, double y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple64(double x, double y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double fabs64(double x) {\n  return fabs(x);\n}\n\nSCALAR_FUN_ATTR double fmax64(double x, double y) {\n  return fmax(x, y);\n}\n\nSCALAR_FUN_ATTR double fmin64(double x, double y) {\n  return fmin(x, y);\n}\n\nSCALAR_FUN_ATTR double fpow64(double x, double y) {\n  return pow(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_log64(double x) {\n  return log(x);\n}\n\nSCALAR_FUN_ATTR double futrts_log2_64(double x) {\n  return log2(x);\n}\n\nSCALAR_FUN_ATTR double futrts_log10_64(double x) {\n  return log10(x);\n}\n\nSCALAR_FUN_ATTR double futrts_log1p_64(double x) {\n  return log1p(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sqrt64(double x) {\n  return sqrt(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cbrt64(double x) {\n  return cbrt(x);\n}\n\nSCALAR_FUN_ATTR double futrts_exp64(double x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cos64(double x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sin64(double x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_tan64(double x) {\n  r", "eturn tan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acos64(double x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_asin64(double x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atan64(double x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cosh64(double x) {\n  return cosh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sinh64(double x) {\n  return sinh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_tanh64(double x) {\n  return tanh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acosh64(double x) {\n  return acosh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_asinh64(double x) {\n  return asinh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atanh64(double x) {\n  return atanh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {\n  return atan2(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {\n  return hypot(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_gamma64(double x) {\n  return tgamma(x);\n}\n\nSCALAR_FUN_ATTR double futrts_lgamma64(double x) {\n  return lgamma(x);\n}\n\nSCALAR_FUN_ATTR double futrts_erf64(double x) {\n  return erf(x);\n}\n\nSCALAR_FUN_ATTR double futrts_erfc64(double x) {\n  return erfc(x);\n}\n\nSCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {\n  return fma(a, b, c);\n}\n\nSCALAR_FUN_ATTR double futrts_round64(double x) {\n  return rint(x);\n}\n\nSCALAR_FUN_ATTR double futrts_ceil64(double x) {\n  return ceil(x);\n}\n\nSCALAR_FUN_ATTR float futrts_nextafter64(float x, float y) {\n  return nextafter(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_floor64(double x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isnan64(double x) {\n  return isnan(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isinf64(double x) {\n  return isinf(x);\n}\n\nSCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x", ") {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR bool ftob_f64_bool(double x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR double btof_bool_f64(bool x) {\n  return x ? 1 : 0;\n}\n\nSCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {\n  union {\n    double f;\n    int64_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {\n  union {\n    int64_t f;\n    double t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR double fmod64(double x, double y) {\n  return fmod(x, y);\n}\n\nSCALAR_FUN_ATTR double fsignum64(double x) {\n  return futrts_isnan64(x) ? x : (x > 0) - (x < 0);\n}\n\nSCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {\n#ifdef __OPENCL_VERSION__\n  return mix(v0, v1, t);\n#else\n  return v0 + (v1 - v0) * t;\n#endif\n}\n\nSCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {\n  return ldexp(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign64(double x, double y) {\n  return copysign(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {\n#ifdef __OPENCL_VERSION__\n  return mad(a, b, c);\n#else\n  return a * b + c;\n#endif\n}\n\nSCALAR",
                                    "_FUN_ATTR float fpconv_f32_f32(float x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f32_f64(float x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR float fpconv_f64_f32(double x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f64_f64(double x) {\n  return (double) x;\n}\n\n#endif\n\n#endif\n\n// End of scalar.h.\n// Start of scalar_f16.h.\n\n// Half-precision is emulated if needed (e.g. in straight C) with the\n// native type used if possible.  The emulation works by typedef'ing\n// 'float' to 'f16', and then implementing all operations on single\n// precision.  To cut down on duplication, we use the same code for\n// those Futhark functions that require just operators or casts.  The\n// in-memory representation for arrays will still be 16 bits even\n// under emulation, so the compiler will have to be careful when\n// generating reads or writes.\n\n#if !defined(cl_khr_fp16) && !(defined(__CUDA_ARCH__) && __CUDA_ARCH__ >= 600) && !(defined(ISPC))\n#define EMULATE_F16\n#endif\n\n#if !defined(EMULATE_F16) && defined(__OPENCL_VERSION__)\n#pragma OPENCL EXTENSION cl_khr_fp16 : enable\n#endif\n\n#ifdef EMULATE_F16\n\n// Note that the half-precision storage format is still 16 bits - the\n// compiler will have to be real careful!\ntypedef float f16;\n\n#elif ISPC\ntypedef float16 f16;\n\n#else\n\n#ifdef __CUDA_ARCH__\n#include <cuda_fp16.h>\n#endif\n\ntypedef half f16;\n\n#endif\n\n// Some of these functions convert to single precision because half\n// precision versions are not available.\n\nSCALAR_FUN_ATTR f16 fadd16(f16 x, f16 y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR f16 fsub16(f16 x, f16 y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR f16 fmul16(f16 x, f16 y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt16(f16 x, f16 y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple16(f16 x, f16 y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR f16 sitofp_i8_f16(int8_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 sitofp_i16_f16(int16_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 sitofp_i32_f16(int32_t x) {\n  return (f16) x;\n}\n\nSCALAR", "_FUN_ATTR f16 sitofp_i64_f16(int64_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i8_f16(uint8_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i16_f16(uint16_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i32_f16(uint32_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i64_f16(uint64_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR int8_t fptosi_f16_i8(f16 x) {\n  return (int8_t) (float) x;\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f16_i16(f16 x) {\n  return (int16_t) x;\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f16_i32(f16 x) {\n  return (int32_t) x;\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f16_i64(f16 x) {\n  return (int64_t) x;\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f16_i8(f16 x) {\n  return (uint8_t) (float) x;\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f16_i16(f16 x) {\n  return (uint16_t) x;\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f16_i32(f16 x) {\n  return (uint32_t) x;\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f16_i64(f16 x) {\n  return (uint64_t) x;\n}\n\nSCALAR_FUN_ATTR bool ftob_f16_bool(f16 x) {\n  return x != (f16)0;\n}\n\nSCALAR_FUN_ATTR f16 btof_bool_f16(bool x) {\n  return x ? 1 : 0;\n}\n\n#ifndef EMULATE_F16\nSCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {\n  return isnan((float)x);\n}\n\n#ifdef __OPENCL_VERSION__\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return fabs(x);\n}\n\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return fmax(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {\n  return fmin(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return pow(x, y);\n}\n\n#elif ISPC\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : max(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {\n  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : min(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return pow(x, y);\n}\n\n#else // Assuming CUDA.\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return fabsf(x);\n}\n\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return fmaxf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 ", "x, f16 y) {\n  return fminf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return powf(x, y);\n}\n#endif\n\n#if ISPC\nSCALAR_FUN_ATTR bool futrts_isinf16(float x) {\n  return !futrts_isnan16(x) && futrts_isnan16(x - x);\n}\nSCALAR_FUN_ATTR bool futrts_isfinite16(float x) {\n  return !futrts_isnan16(x) && !futrts_isinf16(x);\n}\n\n#else\n\nSCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {\n  return isinf((float)x);\n}\n#endif\n\n#ifdef __OPENCL_VERSION__\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return log(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return log2(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return log10(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  return log1p(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return sqrt(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  return cbrt(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  return cosh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return sinh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return tanh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  return acosh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  return asinh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  return atanh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return atan2(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return hypot(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {\n  return tgamma(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  return lgamma(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  return e",
                                    "rf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  return erfc(x);\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return fmod(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return rint(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return ceil(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {\n  return nextafter(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return mix(v0, v1, t);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return ldexp(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return copysign(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return mad(a, b, c);\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return fma(a, b, c);\n}\n#elif ISPC\n\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return futrts_isfinite16(x) || (futrts_isinf16(x) && x < 0) ? log(x) : x;\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return futrts_log16(x) / log(2.0f16);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return futrts_log16(x) / log(10.0f16);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  if(x == -1.0f16 || (futrts_isinf16(x) && x > 0.0f16)) return x / 0.0f16;\n  f16 y = 1.0f16 + x;\n  f16 z = y - 1.0f16;\n  return log(y) - (z-x)/y;\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return (float16)sqrt((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return (float16)cos((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return (float16)sin((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return (float16)tan((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return (float16)acos((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return (float16)asin((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return (float16)atan((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  retu", "rn (exp(x)+exp(-x)) / 2.0f16;\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return (exp(x)-exp(-x)) / 2.0f16;\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return futrts_sinh16(x)/futrts_cosh16(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  float16 f = x+(float16)sqrt((float)(x*x-1));\n  if(futrts_isfinite16(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  float16 f = x+(float16)sqrt((float)(x*x+1));\n  if(futrts_isfinite16(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  float16 f = (1+x)/(1-x);\n  if(futrts_isfinite16(f)) return log(f)/2.0f16;\n  return f;\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return (float16)atan2((float)x, (float)y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return (float16)futrts_hypot32((float)x, (float)y);\n}\n\nextern \"C\" unmasked uniform float tgammaf(uniform float x);\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {\n  f16 res;\n  foreach_active (i) {\n    uniform f16 r = (f16)tgammaf(extract((float)x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float lgammaf(uniform float x);\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  f16 res;\n  foreach_active (i) {\n    uniform f16 r = (f16)lgammaf(extract((float)x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  f16 res = (f16)futrts_cbrt32((float)x);\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  f16 res = (f16)futrts_erf32((float)x);\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  f16 res = (f16)futrts_erfc32((float)x);\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return x - y * (float16)trunc((float) (x/y));\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return (float16)round((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return (float16)floor((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return (float16)ceil((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrt", "s_nextafter16(f16 x, f16 y) {\n  return (float16)futrts_nextafter32((float)x, (float) y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return futrts_ldexp32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return futrts_copysign32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\n#else // Assume CUDA.\n\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return hlog(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return hlog2(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return hlog10(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  return (f16)log1pf((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return hsqrt(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  return cbrtf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return hexp(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return hcos(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return hsin(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return tanf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return acosf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return asinf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return atanf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  return coshf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return sinhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return tanhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  return acoshf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  return asinhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  return atanhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return atan2f(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return hypotf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_gamma16(f1",
                                    "6 x) {\n  return tgammaf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  return lgammaf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  return erff(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  return erfcf(x);\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return fmodf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return rintf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return hfloor(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return hceil(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {\n  return __ushort_as_half(halfbitsnextafter(__half_as_ushort(x), __half_as_ushort(y)));\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return futrts_ldexp32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return futrts_copysign32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return fmaf(a, b, c);\n}\n\n#endif\n\n// The CUDA __half type cannot be put in unions for some reason, so we\n// use bespoke conversion functions instead.\n#ifdef __CUDA_ARCH__\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  return __half_as_ushort(x);\n}\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  return __ushort_as_half(x);\n}\n#elif ISPC\n\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  varying int16_t y = *((varying int16_t * uniform)&x);\n  return y;\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  varying f16 y = *((varying f16 * uniform)&x);\n  return y;\n}\n#else\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  union {\n    f16 f;\n    int16_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  union {\n    int16_t f;\n    f16 t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n#endif\n\n#else // No native f16 - emulate.\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return fabs32(x);\n}\n\nSC", "ALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return fmax32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {\n  return fmin32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return fpow32(x, y);\n}\n\nSCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {\n  return futrts_isnan32(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {\n  return futrts_isinf32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return futrts_log32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return futrts_log2_32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return futrts_log10_32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  return futrts_log1p_32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return futrts_sqrt32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  return futrts_cbrt32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return futrts_exp32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return futrts_cos32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return futrts_sin32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return futrts_tan32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return futrts_acos32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return futrts_asin32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return futrts_atan32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  return futrts_cosh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return futrts_sinh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return futrts_tanh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  return futrts_acosh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  return futrts_asinh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  return futrts_atanh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return futrts_atan2_32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return futrts_hypot32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {\n  return futrts_gamma32(x);\n}\n\nSCA", "LAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  return futrts_lgamma32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  return futrts_erf32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  return futrts_erfc32(x);\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return fmod32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return futrts_round32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return futrts_floor32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return futrts_ceil32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {\n  return halfbits2float(halfbitsnextafter(float2halfbits(x), float2halfbits(y)));\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return futrts_lerp32(v0, v1, t);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return futrts_ldexp32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return futrts_copysign32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return futrts_mad32(a, b, c);\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return futrts_fma32(a, b, c);\n}\n\n// Even when we are using an OpenCL that does not support cl_khr_fp16,\n// it must still support vload_half for actually creating a\n// half-precision number, which can then be efficiently converted to a\n// float.  Similarly for vstore_half.\n#ifdef __OPENCL_VERSION__\n\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  int16_t y;\n  // Violating strict aliasing here.\n  vstore_half((float)x, 0, (half*)&y);\n  return y;\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  return (f16)vload_half(0, (half*)&x);\n}\n\n#else\n\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  return (int16_t)float2halfbits(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  return halfbits2float((uint16_t)x);\n}\n\nSCALAR_FUN_ATTR f16 fsignum16(f16 x) {\n  return futrts_isnan16(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);\n}\n\n#endif\n\n#endif\n\nSCALAR_FUN_ATTR float fpconv_f16_f16(f16 x) {\n  retu",
                                    "rn x;\n}\n\nSCALAR_FUN_ATTR float fpconv_f16_f32(f16 x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR f16 fpconv_f32_f16(float x) {\n  return (f16) x;\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nSCALAR_FUN_ATTR double fpconv_f16_f64(f16 x) {\n  return (double) x;\n}\n\n#if ISPC\nSCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {\n  return (f16) ((float)x);\n}\n#else\nSCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {\n  return (f16) x;\n}\n#endif\n#endif\n\n\n// End of scalar_f16.h.\n// Start of atomics.h\n\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_global(volatile __global int32_t *p,\n                                                         int32_t cmp, int32_t val);\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_shared(volatile __local int32_t *p,\n                                                        int32_t cmp, int32_t val);\nSCALAR_FUN_ATTR int32_t atomic_add_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_add_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR float atomic_fadd_f32_global(volatile __global float *p, float x);\nSCALAR_FUN_ATTR float atomic_fadd_f32_shared(volatile __local float *p, float x);\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_global(volatile __global uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_shared(volatile __local uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_global(volatile __global uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_shared(volatile __local uint32", "_t *p, uint32_t x);\nSCALAR_FUN_ATTR int32_t atomic_and_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_and_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_or_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_or_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_shared(volatile __local int32_t *p, int32_t x);\n\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_global(volatile __global int32_t *p,\n                                                         int32_t cmp, int32_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((int32_t*)p, cmp, val);\n#else\n  return atomic_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_shared(volatile __local int32_t *p,\n                                                        int32_t cmp, int32_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((int32_t*)p, cmp, val);\n#else\n  return atomic_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_add_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((int32_t*)p, x);\n#else\n  return atomic_add(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_add_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((int32_t*)p, x);\n#el", "se\n  return atomic_add(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR float atomic_fadd_f32_global(volatile __global float *p, float x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((float*)p, x);\n  // On OpenCL, use technique from\n  // https://pipinspace.github.io/blog/atomic-float-addition-in-opencl.html\n#elif defined(cl_nv_pragma_unroll)\n  // use hardware-supported atomic addition on Nvidia GPUs with inline\n  // PTX assembly\n  float ret;\n  asm volatile(\"atom.global.add.f32 %0,[%1],%2;\":\"=f\"(ret):\"l\"(p),\"f\"(x):\"memory\");\n  return ret;\n#elif defined(__opencl_c_ext_fp32_global_atomic_add)\n  // use hardware-supported atomic addition on some Intel GPUs\n  return atomic_fetch_add_explicit((volatile __global atomic_float*)p,\n                                   x,\n                                   memory_order_relaxed);\n#elif __has_builtin(__builtin_amdgcn_global_atomic_fadd_f32)\n  // use hardware-supported atomic addition on some AMD GPUs\n  return __builtin_amdgcn_global_atomic_fadd_f32(p, x);\n#else\n  // fallback emulation:\n  // https://forums.developer.nvidia.com/t/atomicadd-float-float-atomicmul-float-float/14639/5\n  float old = x;\n  float ret;\n  while ((old=atomic_xchg(p, ret=atomic_xchg(p, 0.0f)+old))!=0.0f);\n  return ret;\n#endif\n}\n\nSCALAR_FUN_ATTR float atomic_fadd_f32_shared(volatile __local float *p, float x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((float*)p, x);\n#else\n  union { int32_t i; float f; } old;\n  union { int32_t i; float f; } assumed;\n  old.f = *p;\n  do {\n    assumed.f = old.f;\n    old.f = old.f + x;\n    old.i = atomic_cmpxchg_i32_shared((volatile __local int32_t*)p, assumed.i, old.i);\n  } while (assumed.i != old.i);\n  return old.f;\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((int32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_shared(volatile",
                                    " __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((int32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((int32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((int32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_global(volatile __global uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_shared(volatile __local uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_global(volatile __global uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_shared(volatile __local uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_and_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((int32_t*)p, x);\n#else\n  return atomic_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_and_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((int32_t*)p, x);\n#else\n  return atomic_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_or_i32_global(volatile __global int32_t *p, ", "int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((int32_t*)p, x);\n#else\n  return atomic_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_or_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((int32_t*)p, x);\n#else\n  return atomic_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\n// Start of 64 bit atomics\n\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP) || defined(cl_khr_int64_base_atomics) && defined(cl_khr_int64_extended_atomics)\n\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_global(volatile __global int64_t *p,\n                                                         int64_t cmp, int64_t val);\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_shared(volatile __local int64_t *p,\n                                                        int64_t cmp, int64_t val);\nSCALAR_FUN_ATTR int64_t atomic_add_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_add_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR uint", "64_t atomic_umax_i64_global(volatile __global uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_shared(volatile __local uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_global(volatile __global uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_shared(volatile __local uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR int64_t atomic_and_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_and_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_or_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_or_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_shared(volatile __local int64_t *p, int64_t x);\n\n#ifdef FUTHARK_F64_ENABLED\nSCALAR_FUN_ATTR double atomic_fadd_f64_global(volatile __global double *p, double x);\nSCALAR_FUN_ATTR double atomic_fadd_f64_shared(volatile __local double *p, double x);\n#endif\n\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_global(volatile __global int64_t *p,\n                                                         int64_t cmp, int64_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((uint64_t*)p, cmp, val);\n#else\n  return atom_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_shared(volatile __local int64_t *p,\n                                                        int64_t cmp, int64_t val) {\n#if defined(F",
                                    "UTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((uint64_t*)p, cmp, val);\n#else\n  return atom_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_add_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((uint64_t*)p, x);\n#else\n  return atom_add(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_add_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((uint64_t*)p, x);\n#else\n  return atom_add(p, x);\n#endif\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nSCALAR_FUN_ATTR double atomic_fadd_f64_global(volatile __global double *p, double x) {\n#if defined(FUTHARK_CUDA) && __CUDA_ARCH__ >= 600 || defined(FUTHARK_HIP)\n  return atomicAdd((double*)p, x);\n  // On OpenCL, use technique from\n  // https://pipinspace.github.io/blog/atomic-float-addition-in-opencl.html\n#elif defined(cl_nv_pragma_unroll)\n  // use hardware-supported atomic addition on Nvidia GPUs with inline\n  // PTX assembly\n  double ret;\n  asm volatile(\"atom.global.add.f64 %0,[%1],%2;\":\"=d\"(ret):\"l\"(p),\"d\"(x):\"memory\");\n  return ret;\n#elif __has_builtin(__builtin_amdgcn_global_atomic_fadd_f64)\n  // use hardware-supported atomic addition on some AMD GPUs\n  return __builtin_amdgcn_global_atomic_fadd_f64(p, x);\n#else\n  // fallback emulation:\n  // https://forums.developer.nvidia.com/t/atomicadd-float-float-atomicmul-float-float/14639/5\n  union {int64_t i; double f;} old;\n  union {int64_t i; double f;} ret;\n  old.f = x;\n  while (1) {\n    ret.i = atom_xchg((volatile __global int64_t*)p, (int64_t)0);\n    ret.f += old.f;\n    old.i = atom_xchg((volatile __global int64_t*)p, ret.i);\n    if (old.i == 0) {\n      break;\n    }\n  }\n  return ret.f;\n#endif\n}\n\nSCALAR_FUN_ATTR double atomic_fadd_f64_shared(volatile __local double *p, double x) {\n#if defined(FUTHARK_CUDA) && __CUDA_ARCH__ >= 600 || defined(FUTHARK_HIP)\n  return atomicAdd((double*)p, x);\n#else\n  union { int64_t i; double f; } old;\n  u", "nion { int64_t i; double f; } assumed;\n  old.f = *p;\n  do {\n    assumed.f = old.f;\n    old.f = old.f + x;\n    old.i = atomic_cmpxchg_i64_shared((volatile __local int64_t*)p, assumed.i, old.i);\n  } while (assumed.i != old.i);\n  return old.f;\n#endif\n}\n\n#endif\n\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMax((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smax64(old, x);\n    old = atomic_cmpxchg_i64_global((volatile __global int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMax((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smax64(old, x);\n    old = atomic_cmpxchg_i64_shared((volatile __local int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMin((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smin64(old, x);\n    old = atomic_cmpxchg_i64_global((volatile __global int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMin((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do ", "{\n    assumed = old;\n    old = smin64(old, x);\n    old = atomic_cmpxchg_i64_shared((volatile __local int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_global(volatile __global uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint64_t*)p, x);\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_shared(volatile __local uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint64_t*)p, x);\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_global(volatile __global uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint64_t*)p, x);\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_shared(volatile __local uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint64_t*)p, x);\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_and_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((uint64_t*)p, x);\n#else\n  return atom_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_and_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((uint64_t*)p, x);\n#else\n  return atom_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_or_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((uint64_t*)p, x);\n#else\n  return atom_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_or_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((uint64_t*)p, x);\n#else\n  return atom_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_global(v",
                                    "olatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\n#endif // defined(FUTHARK_CUDA) || defined(FUTHARK_HIP) || defined(cl_khr_int64_base_atomics) && defined(cl_khr_int64_extended_atomics)\n\n// End of atomics.h\n// Start of transpose.cl\n\n#define GEN_TRANSPOSE_KERNELS(NAME, ELEM_TYPE)                          \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*2, TR_TILE_DIM/TR_ELEMS_PER_THREAD, 1)\\\nvoid map_transpose_##NAME(SHARED_MEM_PARAM                              \\\n                          __global ELEM_TYPE *dst_mem,                  \\\n                          int64_t dst_offset,                           \\\n                          __global ELEM_TYPE *src_mem,                  \\\n                          int64_t src_offset,                           \\\n                          int32_t num_arrays,                           \\\n                          int32_t x_elems,                              \\\n                          int32_t y_elems,                              \\\n                          int32_t mulx,                                 \\\n                          int32_t muly,                                 \\\n                          int32_t repeat_1,                             \\\n                          int32_t repeat_2) {                           \\\n  (void)mulx; (void)muly;                                               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_g", "lobal_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t x_index = global_id_0;                                    \\\n      int32_t y_index = tblock_id_1 * TR_TILE_DIM + get_local_id(1);    \\\n      if (x_index < x_elems) {                                          \\\n        for (int32_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int32_t index_i = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * x_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < y_elems) { \\\n            block[(get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * (TR_TILE_DIM+1) + \\\n                  get_local_id(0)] =                                    \\\n              src_mem[idata_offset + index_i];                          \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_TILE_DIM + get_local_id(0);            \\\n      y_index = tblock_id_0 * TR_TILE_DIM + get_local_id(1);            \\\n      if (x_index < y_elems) {                                          \\\n        for (int32_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int32_t index_out = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * y_elems + x_index; \\\n          if (y_in", "dex + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < x_elems) { \\\n            dst_mem[(odata_offset + index_out)] =                       \\\n              block[get_local_id(0) * (TR_TILE_DIM+1) +                 \\\n                    get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)]; \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM, TR_BLOCK_DIM, 1)                     \\\nvoid map_transpose_##NAME##_low_height(SHARED_MEM_PARAM                 \\\n                                                __global ELEM_TYPE *dst_mem, \\\n                                                int64_t dst_offset,     \\\n                                                __global ELEM_TYPE *src_mem, \\\n                                                int64_t src_offset,     \\\n                                                int32_t num_arrays,     \\\n                                                int32_t x_elems,        \\\n                                                int32_t y_elems,        \\\n                                                int32_t mulx,           \\\n                                                int32_t muly,           \\\n                                                int32_t repeat_1,       \\\n ",
                                    "                                               int32_t repeat_2) {     \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t x_index =                                                 \\\n        tblock_id_0 * TR_BLOCK_DIM * mulx +                             \\\n        get_local_id(0) +                                               \\\n        get_local_id(1)%mulx * TR_BLOCK_DIM;                            \\\n      int32_t y_index = tblock_id_1 * TR_BLOCK_DIM + get_local_id(1)/mulx; \\\n      int32_t index_in = y_index * x_elems + x_index;                   \\\n      if (x_index < x_elems && y_index < y_elems) {                     \\\n        block[get_local_id(1) * (TR_BLOCK_DIM+1) + get_local_id(0)] =   \\\n          src_mem[idata_offset + index_in];                             \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_BLOCK_DIM + get_local_id(0)/mulx;      \\\n      y_index =                                                         \\\n        tblock_id_0 * TR_BLOCK_DIM * mulx +                             \\\n", "        get_local_id(1) +                                               \\\n        (get_local_id(0)%mulx) * TR_BLOCK_DIM;                          \\\n      int32_t index_out = y_index * y_elems + x_index;                  \\\n      if (x_index < y_elems && y_index < x_elems) {                     \\\n        dst_mem[odata_offset + index_out] =                             \\\n          block[get_local_id(0) * (TR_BLOCK_DIM+1) + get_local_id(1)];  \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM, TR_BLOCK_DIM, 1)                     \\\nvoid map_transpose_##NAME##_low_width(SHARED_MEM_PARAM                  \\\n                                      __global ELEM_TYPE *dst_mem,      \\\n                                      int64_t dst_offset,               \\\n                                      __global ELEM_TYPE *src_mem,      \\\n                                      int64_t src_offset,               \\\n                                      int32_t num_arrays,               \\\n                                      int32_t x_elems,                  \\\n                                      int32_t y_elems,                  \\\n                                      int32_t mulx,                     \\\n                                      int32_t muly,                     \\\n                                      int32_t repeat_1,                 \\\n  ", "                                    int32_t repeat_2) {               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t x_index = tblock_id_0 * TR_BLOCK_DIM + get_local_id(0)/muly; \\\n      int32_t y_index =                                                 \\\n        tblock_id_1 * TR_BLOCK_DIM * muly +                             \\\n        get_local_id(1) + (get_local_id(0)%muly) * TR_BLOCK_DIM;        \\\n      int32_t index_in = y_index * x_elems + x_index;                   \\\n      if (x_index < x_elems && y_index < y_elems) {                     \\\n        block[get_local_id(1) * (TR_BLOCK_DIM+1) + get_local_id(0)] =   \\\n          src_mem[idata_offset + index_in];                             \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_BLOCK_DIM * muly +                     \\\n        get_local_id(0) + (get_local_id(1)%muly) * TR_BLOCK_DIM;        \\\n      y_index = tblock_id_0 * TR_BLOCK_DIM + get_local_id(1)/muly;      \\\n      int32_t index_out = y_index * y_elems + x_index;                  \\\n ",
                                    "     if (x_index < y_elems && y_index < x_elems) {                     \\\n        dst_mem[odata_offset + index_out] =                             \\\n          block[get_local_id(0) * (TR_BLOCK_DIM+1) + get_local_id(1)];  \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_num_tblocks(2) * get_local_size(2);            \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_num_tblocks(1) * get_local_size(1);              \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*TR_BLOCK_DIM, 1, 1)                   \\\nvoid map_transpose_##NAME##_small(SHARED_MEM_PARAM                       \\\n                                  __global ELEM_TYPE *dst_mem,          \\\n                                  int64_t dst_offset,                   \\\n                                  __global ELEM_TYPE *src_mem,          \\\n                                  int64_t src_offset,                   \\\n                                  int32_t num_arrays,                   \\\n                                  int32_t x_elems,                      \\\n                                  int32_t y_elems,                      \\\n                                  int32_t mulx,                         \\\n                                  int32_t muly,                         \\\n                                  int32_t repeat_1,                     \\\n                                  int32_t repeat_2) {                   \\\n  (void)mulx; (void)muly;                                               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  ", "int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = global_id_0/(y_elems * x_elems) * y_elems * x_elems; \\\n      int32_t x_index = (global_id_0 % (y_elems * x_elems))/y_elems;    \\\n      int32_t y_index = global_id_0%y_elems;                            \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t index_in = y_index * x_elems + x_index;                   \\\n      int32_t index_out = x_index * y_elems + y_index;                  \\\n      if (global_id_0 < x_elems * y_elems * num_arrays) {               \\\n        dst_mem[odata_offset + index_out] = src_mem[idata_offset + index_in]; \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*2, TR_TILE_DIM/TR_ELEMS_", "PER_THREAD, 1)\\\nvoid map_transpose_##NAME##_large(SHARED_MEM_PARAM                      \\\n                                  __global ELEM_TYPE *dst_mem,          \\\n                                  int64_t dst_offset,                   \\\n                                  __global ELEM_TYPE *src_mem,          \\\n                                  int64_t src_offset,                   \\\n                                  int64_t num_arrays,                   \\\n                                  int64_t x_elems,                      \\\n                                  int64_t y_elems,                      \\\n                                  int64_t mulx,                         \\\n                                  int64_t muly,                         \\\n                                  int32_t repeat_1,                     \\\n                                  int32_t repeat_2) {                   \\\n  (void)mulx; (void)muly;                                               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;             \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int64_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int64_t odata_offset = dst_offset + our_array_offset;             \\\n      int64_t idata_offset = src_offset + our_array_offset;             \\\n      int64_t x_index = global_id_0;                                    \\\n      int64_t y_index = tblock_id_1 * TR_TILE_DIM + get_loc",
                                    "al_id(1);    \\\n      if (x_index < x_elems) {                                          \\\n        for (int64_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int64_t index_i = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * x_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < y_elems) { \\\n            block[(get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * (TR_TILE_DIM+1) + \\\n                  get_local_id(0)] =                                    \\\n              src_mem[idata_offset + index_i];                          \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_TILE_DIM + get_local_id(0);            \\\n      y_index = tblock_id_0 * TR_TILE_DIM + get_local_id(1);            \\\n      if (x_index < y_elems) {                                          \\\n        for (int64_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int64_t index_out = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * y_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < x_elems) { \\\n            dst_mem[(odata_offset + index_out)] =                       \\\n              block[get_local_id(0) * (TR_TILE_DIM+1) +                 \\\n                    get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)]; \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                      ", "                             \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n\nGEN_TRANSPOSE_KERNELS(1b, uint8_t)\nGEN_TRANSPOSE_KERNELS(2b, uint16_t)\nGEN_TRANSPOSE_KERNELS(4b, uint32_t)\nGEN_TRANSPOSE_KERNELS(8b, uint64_t)\n\n// End of transpose.cl\n// Start of copy.cl\n\n#define GEN_COPY_KERNEL(NAME, ELEM_TYPE) \\\nFUTHARK_KERNEL void lmad_copy_##NAME(SHARED_MEM_PARAM                   \\\n                               __global ELEM_TYPE *dst_mem,             \\\n                               int64_t dst_offset,                      \\\n                               __global ELEM_TYPE *src_mem,             \\\n                               int64_t src_offset,                      \\\n                               int64_t n,                               \\\n                               int r,                                   \\\n                               int64_t shape0, int64_t dst_stride0, int64_t src_stride0, \\\n                               int64_t shape1, int64_t dst_stride1, int64_t src_stride1, \\\n                               int64_t shape2, int64_t dst_stride2, int64_t src_stride2, \\\n                               int64_t shape3, int64_t dst_stride3, int64_t src_stride3, \\\n                               int64_t shape4, int64_t dst_stride4, int64_t src_stride4, \\\n                               int64_t shape5, int64_t dst_stride5, int64_t src_stride5, \\\n                               int64_t shape6, int64_t dst_stride6, int64_t src_stride6, \\\n                               int64_t shape7, int64_t dst_stride7, int64_t src_stride7) { \\\n  int64_t gtid = get_global_id(0);                                      \\\n  int64_t remainder = gtid;                                             \\\n                                             ", "                           \\\n  if (gtid >= n) {                                                      \\\n    return;                                                             \\\n  }                                                                     \\\n                                                                        \\\n  if (r > 0) {                                                          \\\n    int64_t i = remainder % shape0;                                     \\\n    dst_offset += i * dst_stride0;                                      \\\n    src_offset += i * src_stride0;                                      \\\n    remainder /= shape0;                                                \\\n  }                                                                     \\\n  if (r > 1) {                                                          \\\n    int64_t i = remainder % shape1;                                     \\\n    dst_offset += i * dst_stride1;                                      \\\n    src_offset += i * src_stride1;                                      \\\n    remainder /= shape1;                                                \\\n  }                                                                     \\\n  if (r > 2) {                                                          \\\n    int64_t i = remainder % shape2;                                     \\\n    dst_offset += i * dst_stride2;                                      \\\n    src_offset += i * src_stride2;                                      \\\n    remainder /= shape2;                                                \\\n  }                                                                     \\\n  if (r > 3) {                                                          \\\n    int64_t i = remainder % shape3;                                     \\\n    dst_offset += i * dst_stride3;                                      \\\n    src_offset += i * src_stride3;                                      \\\n    remainder /= shape3;                       ",
                                    "                         \\\n  }                                                                     \\\n  if (r > 4) {                                                          \\\n    int64_t i = remainder % shape4;                                     \\\n    dst_offset += i * dst_stride4;                                      \\\n    src_offset += i * src_stride4;                                      \\\n    remainder /= shape4;                                                \\\n  }                                                                     \\\n  if (r > 5) {                                                          \\\n    int64_t i = remainder % shape5;                                     \\\n    dst_offset += i * dst_stride5;                                      \\\n    src_offset += i * src_stride5;                                      \\\n    remainder /= shape5;                                                \\\n  }                                                                     \\\n  if (r > 6) {                                                          \\\n    int64_t i = remainder % shape6;                                     \\\n    dst_offset += i * dst_stride6;                                      \\\n    src_offset += i * src_stride6;                                      \\\n    remainder /= shape6;                                                \\\n  }                                                                     \\\n  if (r > 7) {                                                          \\\n    int64_t i = remainder % shape7;                                     \\\n    dst_offset += i * dst_stride7;                                      \\\n    src_offset += i * src_stride7;                                      \\\n    remainder /= shape7;                                                \\\n  }                                                                     \\\n                                                                        \\\n  dst_mem[dst_offset] = src_mem[src_offset];     ", "                       \\\n}\n\nGEN_COPY_KERNEL(1b, uint8_t)\nGEN_COPY_KERNEL(2b, uint16_t)\nGEN_COPY_KERNEL(4b, uint32_t)\nGEN_COPY_KERNEL(8b, uint64_t)\n\n// End of copy.cl\n\nFUTHARK_FUN_ATTR void futrts_set_bit_2464(int8_t *out_prim_out_0, int32_t bit_12481, int8_t x_12482, int32_t b_12483);\n\nFUTHARK_FUN_ATTR void futrts_set_bit_2464(int8_t *out_prim_out_0, int32_t bit_12481, int8_t x_12482, int32_t b_12483)\n{\n    int8_t prim_out_21592;\n    int32_t i32_arg0_12484 = shl32(1, bit_12481);\n    int32_t i32_arg_12486 = ~i32_arg0_12484;\n    int8_t unsign_arg0_17007 = zext_i32_i8(i32_arg_12486);\n    int8_t unsign_arg0_19298 = x_12482 & unsign_arg0_17007;\n    int32_t i32_arg0_12491 = shl32(b_12483, bit_12481);\n    int8_t unsign_arg0_17009 = zext_i32_i8(i32_arg0_12491);\n    int8_t unsign_arg0_17012 = unsign_arg0_17009 | unsign_arg0_19298;\n    \n    prim_out_21592 = unsign_arg0_17012;\n    *out_prim_out_0 = prim_out_21592;\n}\n\nFUTHARK_KERNEL\nvoid builtinzhiota_i64ziiota_i64_21602(int64_t n_21598, int64_t x_21599, int64_t s_21600, int64_t virt_num_tblocks_21607, int64_t num_tblocks_21608, __global unsigned char *mem_21597)\n{\n    int32_t iota_ltid_21603;\n    int32_t tblock_sizze_21605;\n    int32_t iota_gid_21604;\n    int32_t iota_gtid_21602;\n    int32_t phys_tblock_id_21609;\n    int32_t iterations_21610;\n    \n    iota_ltid_21603 = get_local_id(0);\n    tblock_sizze_21605 = get_local_size(0);\n    iota_gid_21604 = get_tblock_id(0);\n    iota_gtid_21602 = iota_gid_21604 * tblock_sizze_21605 + iota_ltid_21603;\n    phys_tblock_id_21609 = get_tblock_id(0);\n    iterations_21610 = sdiv_up32(sext_i64_i32(virt_num_tblocks_21607) - phys_tblock_id_21609, sext_i64_i32(num_tblocks_21608));\n    for (int32_t i_21611 = 0; i_21611 < iterations_21610; i_21611++) {\n        int32_t virt_tblock_id_21612;\n        int64_t global_tid_21613;\n        \n        virt_tblock_id_21612 = phys_tblock_id_21609 + i_21611 * sext_i64_i32(num_tblocks_21608);\n        global_tid_21613 = sext_i32_i64(virt_tblock_id_21612) * sext_i3", "2_i64(tblock_sizze_21605) + sext_i32_i64(iota_ltid_21603);\n        if (slt64(global_tid_21613, n_21598)) {\n            ((__global int64_t *) mem_21597)[global_tid_21613] = add64(mul64(global_tid_21613, s_21600), x_21599);\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_boolzireplicate_22200(int64_t num_elems_22196, unsigned char val_22197_bits, int64_t replicate_n_22199, int64_t virt_num_tblocks_22205, int64_t num_tblocks_22206, __global unsigned char *mem_22195)\n{\n    bool val_22197 = val_22197_bits;\n    int32_t replicate_ltid_22201;\n    int32_t tblock_sizze_22203;\n    int32_t replicate_gid_22202;\n    int32_t replicate_gtid_22200;\n    int32_t phys_tblock_id_22207;\n    int32_t iterations_22208;\n    \n    replicate_ltid_22201 = get_local_id(0);\n    tblock_sizze_22203 = get_local_size(0);\n    replicate_gid_22202 = get_tblock_id(0);\n    replicate_gtid_22200 = replicate_gid_22202 * tblock_sizze_22203 + replicate_ltid_22201;\n    phys_tblock_id_22207 = get_tblock_id(0);\n    iterations_22208 = sdiv_up32(sext_i64_i32(virt_num_tblocks_22205) - phys_tblock_id_22207, sext_i64_i32(num_tblocks_22206));\n    for (int32_t i_22209 = 0; i_22209 < iterations_22208; i_22209++) {\n        int32_t virt_tblock_id_22210;\n        int64_t global_tid_22211;\n        int64_t slice_22213;\n        int64_t rep_i_22212;\n        int64_t remnant_22214;\n        \n        virt_tblock_id_22210 = phys_tblock_id_22207 + i_22209 * sext_i64_i32(num_tblocks_22206);\n        global_tid_22211 = sext_i32_i64(virt_tblock_id_22210) * sext_i32_i64(tblock_sizze_22203) + sext_i32_i64(replicate_ltid_22201);\n        slice_22213 = num_elems_22196;\n        rep_i_22212 = global_tid_22211;\n        remnant_22214 = global_tid_22211 - rep_i_22212;\n        if (slt64(global_tid_22211, replicate_n_22199)) {\n            ((__global bool *) mem_22195)[rep_i_22212] = val_22197;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM",
                                    "_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_i32zireplicate_21718(int64_t num_elems_21714, int32_t val_21715, int64_t replicate_n_21717, int64_t virt_num_tblocks_21723, int64_t num_tblocks_21724, __global unsigned char *mem_21713)\n{\n    int32_t replicate_ltid_21719;\n    int32_t tblock_sizze_21721;\n    int32_t replicate_gid_21720;\n    int32_t replicate_gtid_21718;\n    int32_t phys_tblock_id_21725;\n    int32_t iterations_21726;\n    \n    replicate_ltid_21719 = get_local_id(0);\n    tblock_sizze_21721 = get_local_size(0);\n    replicate_gid_21720 = get_tblock_id(0);\n    replicate_gtid_21718 = replicate_gid_21720 * tblock_sizze_21721 + replicate_ltid_21719;\n    phys_tblock_id_21725 = get_tblock_id(0);\n    iterations_21726 = sdiv_up32(sext_i64_i32(virt_num_tblocks_21723) - phys_tblock_id_21725, sext_i64_i32(num_tblocks_21724));\n    for (int32_t i_21727 = 0; i_21727 < iterations_21726; i_21727++) {\n        int32_t virt_tblock_id_21728;\n        int64_t global_tid_21729;\n        int64_t slice_21731;\n        int64_t rep_i_21730;\n        int64_t remnant_21732;\n        \n        virt_tblock_id_21728 = phys_tblock_id_21725 + i_21727 * sext_i64_i32(num_tblocks_21724);\n        global_tid_21729 = sext_i32_i64(virt_tblock_id_21728) * sext_i32_i64(tblock_sizze_21721) + sext_i32_i64(replicate_ltid_21719);\n        slice_21731 = num_elems_21714;\n        rep_i_21730 = global_tid_21729;\n        remnant_21732 = global_tid_21729 - rep_i_21730;\n        if (slt64(global_tid_21729, replicate_n_21717)) {\n            ((__global int32_t *) mem_21713)[rep_i_21730] = val_21715;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_i64zireplicate_21619(int64_t num_elems_21615, int64_t val_21616, int64_t replicate_n_21618, int64_t virt_num_tblocks_21624, int64_t num_tblocks_21625, __global unsigned char *mem_21614)\n{\n    int32_t replicate_ltid_21620;\n    int32_t tblock_sizze", "_21622;\n    int32_t replicate_gid_21621;\n    int32_t replicate_gtid_21619;\n    int32_t phys_tblock_id_21626;\n    int32_t iterations_21627;\n    \n    replicate_ltid_21620 = get_local_id(0);\n    tblock_sizze_21622 = get_local_size(0);\n    replicate_gid_21621 = get_tblock_id(0);\n    replicate_gtid_21619 = replicate_gid_21621 * tblock_sizze_21622 + replicate_ltid_21620;\n    phys_tblock_id_21626 = get_tblock_id(0);\n    iterations_21627 = sdiv_up32(sext_i64_i32(virt_num_tblocks_21624) - phys_tblock_id_21626, sext_i64_i32(num_tblocks_21625));\n    for (int32_t i_21628 = 0; i_21628 < iterations_21627; i_21628++) {\n        int32_t virt_tblock_id_21629;\n        int64_t global_tid_21630;\n        int64_t slice_21632;\n        int64_t rep_i_21631;\n        int64_t remnant_21633;\n        \n        virt_tblock_id_21629 = phys_tblock_id_21626 + i_21628 * sext_i64_i32(num_tblocks_21625);\n        global_tid_21630 = sext_i32_i64(virt_tblock_id_21629) * sext_i32_i64(tblock_sizze_21622) + sext_i32_i64(replicate_ltid_21620);\n        slice_21632 = num_elems_21615;\n        rep_i_21631 = global_tid_21630;\n        remnant_21633 = global_tid_21630 - rep_i_21631;\n        if (slt64(global_tid_21630, replicate_n_21618)) {\n            ((__global int64_t *) mem_21614)[rep_i_21631] = val_21616;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_i8zireplicate_21692(int64_t num_elems_21688, int8_t val_21689, int64_t replicate_n_21691, int64_t virt_num_tblocks_21697, int64_t num_tblocks_21698, __global unsigned char *mem_21687)\n{\n    int32_t replicate_ltid_21693;\n    int32_t tblock_sizze_21695;\n    int32_t replicate_gid_21694;\n    int32_t replicate_gtid_21692;\n    int32_t phys_tblock_id_21699;\n    int32_t iterations_21700;\n    \n    replicate_ltid_21693 = get_local_id(0);\n    tblock_sizze_21695 = get_local_size(0);\n    replicate_gid_21694 = get_tblock_id(0);\n    replicate_gtid_21692 = replicate_gid_21694 * tblock_", "sizze_21695 + replicate_ltid_21693;\n    phys_tblock_id_21699 = get_tblock_id(0);\n    iterations_21700 = sdiv_up32(sext_i64_i32(virt_num_tblocks_21697) - phys_tblock_id_21699, sext_i64_i32(num_tblocks_21698));\n    for (int32_t i_21701 = 0; i_21701 < iterations_21700; i_21701++) {\n        int32_t virt_tblock_id_21702;\n        int64_t global_tid_21703;\n        int64_t slice_21705;\n        int64_t rep_i_21704;\n        int64_t remnant_21706;\n        \n        virt_tblock_id_21702 = phys_tblock_id_21699 + i_21701 * sext_i64_i32(num_tblocks_21698);\n        global_tid_21703 = sext_i32_i64(virt_tblock_id_21702) * sext_i32_i64(tblock_sizze_21695) + sext_i32_i64(replicate_ltid_21693);\n        slice_21705 = num_elems_21688;\n        rep_i_21704 = global_tid_21703;\n        remnant_21706 = global_tid_21703 - rep_i_21704;\n        if (slt64(global_tid_21703, replicate_n_21691)) {\n            ((__global int8_t *) mem_21687)[rep_i_21704] = val_21689;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL_SIZED(getPartitionBounds_8487zisegmap_20546_dim1, 1, 1)\nvoid getPartitionBounds_8487zisegmap_20546(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t n_14235, int64_t b_14236, int64_t dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, int64_t i32_res_19304, int64_t i32_res_19308, int8_t first_bitMask_19312, int8_t unsign_arg0_19316, int64_t num_threads_21577, __global unsigned char *mem_21321, __global unsigned char *mem_21338, __global unsigned char *color_21558, __global unsigned char *color_21559)\n{\n    #define segmap_tblock_sizze_20542 (getPartitionBounds_8487zisegmap_20546zisegmap_tblock_sizze_20542)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_21750;\n    int32_t tblock_sizze_21753;\n    int32_t wave_sizze_21752;\n    int32_t block_id_21751;\n    int32_t global_tid_21749;\n    int64_t phys_tid_20546;\n    int64_t global_tid_21754;\n    int64_t slice_21755;",
                                    "\n    int64_t gtid_20545;\n    int64_t remnant_21756;\n    \n    local_tid_21750 = get_local_id(0);\n    tblock_sizze_21753 = get_local_size(0);\n    wave_sizze_21752 = LOCKSTEP_WIDTH;\n    block_id_21751 = get_tblock_id(0);\n    global_tid_21749 = block_id_21751 * tblock_sizze_21753 + local_tid_21750;\n    phys_tid_20546 = sext_i32_i64(global_tid_21749);\n    global_tid_21754 = sext_i32_i64(block_id_21751) * segmap_tblock_sizze_20542 + sext_i32_i64(local_tid_21750);\n    slice_21755 = dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241;\n    gtid_20545 = global_tid_21754;\n    remnant_21756 = global_tid_21754 - gtid_20545;\n    if (slt64(gtid_20545, dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241)) {\n        int64_t index_primexp_21213;\n        bool x_20548;\n        bool y_20549;\n        bool bounds_check_20550;\n        bool index_certs_20551;\n        bool y_20553;\n        bool index_certs_20556;\n        int8_t za_lhs_20569;\n        int8_t mod1_x_20570;\n        int8_t za_lhs_20572;\n        int8_t tmp_20573;\n        int8_t za_lhs_20575;\n        int8_t mod1_x_20576;\n        int8_t za_lhs_20578;\n        int8_t tmp_20579;\n        bool defunc_0_reduce_res_20581;\n        bool redout_21247;\n        int64_t defunc_0_f_res_20589;\n        \n        index_primexp_21213 = add64((int64_t) 1, gtid_20545);\n        x_20548 = sle64((int64_t) 0, index_primexp_21213);\n        y_20549 = slt64(index_primexp_21213, n_14235);\n        bounds_check_20550 = x_20548 && y_20549;\n        if (!bounds_check_20550) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 7) == -1) {\n                    global_failure_args[0] = (int64_t) index_primexp_21213;\n                    global_failure_args[1] = (int64_t) n_14235;\n                    ;\n                }\n                return;\n            }\n        }\n        y_20553 = slt64(gtid_20545, n_14235);\n        if (!y_20553) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 8) == -1) {\n                    global_failure_args[0] = (int", "64_t) gtid_20545;\n                    global_failure_args[1] = (int64_t) n_14235;\n                    ;\n                }\n                return;\n            }\n        }\n        for (int64_t i_21244 = 0; i_21244 < b_14236; i_21244++) {\n            bool cond_20564;\n            bool cond_t_res_20565;\n            bool x_20566;\n            int8_t lifted_lambda_res_20567;\n            int8_t lifted_lambda_res_20568;\n            \n            cond_20564 = sle64(i_21244, i32_res_19304);\n            cond_t_res_20565 = sle64(i32_res_19308, i_21244);\n            x_20566 = cond_20564 && cond_t_res_20565;\n            if (x_20566) {\n                int8_t eta_p_20562 = ((__global int8_t *) mem_21321)[index_primexp_21213 + i_21244 * n_14235];\n                \n                lifted_lambda_res_20567 = eta_p_20562;\n            } else {\n                lifted_lambda_res_20567 = (int8_t) 0;\n            }\n            if (x_20566) {\n                int8_t eta_p_20563 = ((__global int8_t *) mem_21321)[gtid_20545 + i_21244 * n_14235];\n                \n                lifted_lambda_res_20568 = eta_p_20563;\n            } else {\n                lifted_lambda_res_20568 = (int8_t) 0;\n            }\n            ((__global int8_t *) color_21559)[phys_tid_20546 + i_21244 * num_threads_21577] = lifted_lambda_res_20568;\n            ((__global int8_t *) color_21558)[phys_tid_20546 + i_21244 * num_threads_21577] = lifted_lambda_res_20567;\n        }\n        za_lhs_20569 = ((__global int8_t *) color_21558)[phys_tid_20546 + i32_res_19304 * num_threads_21577];\n        mod1_x_20570 = first_bitMask_19312 & za_lhs_20569;\n        ((__global int8_t *) color_21558)[phys_tid_20546 + i32_res_19304 * num_threads_21577] = mod1_x_20570;\n        za_lhs_20572 = ((__global int8_t *) color_21558)[phys_tid_20546 + i32_res_19308 * num_threads_21577];\n        tmp_20573 = unsign_arg0_19316 & za_lhs_20572;\n        ((__global int8_t *) color_21558)[phys_tid_20546 + i32_res_19308 * num_threads_21577] = tmp_20573;\n        za_lhs", "_20575 = ((__global int8_t *) color_21559)[phys_tid_20546 + i32_res_19304 * num_threads_21577];\n        mod1_x_20576 = first_bitMask_19312 & za_lhs_20575;\n        ((__global int8_t *) color_21559)[phys_tid_20546 + i32_res_19304 * num_threads_21577] = mod1_x_20576;\n        za_lhs_20578 = ((__global int8_t *) color_21559)[phys_tid_20546 + i32_res_19308 * num_threads_21577];\n        tmp_20579 = unsign_arg0_19316 & za_lhs_20578;\n        ((__global int8_t *) color_21559)[phys_tid_20546 + i32_res_19308 * num_threads_21577] = tmp_20579;\n        redout_21247 = 0;\n        for (int64_t i_21248 = 0; i_21248 < b_14236; i_21248++) {\n            int8_t eta_p_20582;\n            int8_t eta_p_20583;\n            bool lifted_lambda_res_20584;\n            bool lifted_lambda_res_20585;\n            bool defunc_0_op_res_20588;\n            bool redout_tmp_21759;\n            \n            eta_p_20582 = ((__global int8_t *) color_21558)[phys_tid_20546 + i_21248 * num_threads_21577];\n            eta_p_20583 = ((__global int8_t *) color_21559)[phys_tid_20546 + i_21248 * num_threads_21577];\n            lifted_lambda_res_20584 = eta_p_20582 == eta_p_20583;\n            lifted_lambda_res_20585 = !lifted_lambda_res_20584;\n            defunc_0_op_res_20588 = lifted_lambda_res_20585 || redout_21247;\n            redout_tmp_21759 = defunc_0_op_res_20588;\n            redout_21247 = redout_tmp_21759;\n        }\n        defunc_0_reduce_res_20581 = redout_21247;\n        defunc_0_f_res_20589 = btoi_bool_i64(defunc_0_reduce_res_20581);\n        ((__global int64_t *) mem_21338)[gtid_20545] = defunc_0_f_res_20589;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_20542\n}\nFUTHARK_KERNEL_SIZED(getPartitionBounds_8487zisegmap_20648_dim1, 1, 1)\nvoid getPartitionBounds_8487zisegmap_20648(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t n_14235, int64_t dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, __global unsigned char *mem_21267, __global unsigned char *mem",
                                    "_21268)\n{\n    #define segmap_tblock_sizze_20642 (getPartitionBounds_8487zisegmap_20648zisegmap_tblock_sizze_20642)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_21778;\n    int32_t tblock_sizze_21781;\n    int32_t wave_sizze_21780;\n    int32_t block_id_21779;\n    int32_t global_tid_21777;\n    int64_t phys_tid_20648;\n    int64_t global_tid_21782;\n    int64_t slice_21783;\n    int64_t gtid_20647;\n    int64_t remnant_21784;\n    \n    local_tid_21778 = get_local_id(0);\n    tblock_sizze_21781 = get_local_size(0);\n    wave_sizze_21780 = LOCKSTEP_WIDTH;\n    block_id_21779 = get_tblock_id(0);\n    global_tid_21777 = block_id_21779 * tblock_sizze_21781 + local_tid_21778;\n    phys_tid_20648 = sext_i32_i64(global_tid_21777);\n    global_tid_21782 = sext_i32_i64(block_id_21779) * segmap_tblock_sizze_20642 + sext_i32_i64(local_tid_21778);\n    slice_21783 = dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241;\n    gtid_20647 = global_tid_21782;\n    remnant_21784 = global_tid_21782 - gtid_20647;\n    if (slt64(gtid_20647, dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241)) {\n        int64_t index_primexp_21225;\n        bool x_20650;\n        bool y_20651;\n        bool bounds_check_20652;\n        bool index_certs_20653;\n        bool y_20655;\n        bool index_certs_20658;\n        \n        index_primexp_21225 = add64((int64_t) 1, gtid_20647);\n        x_20650 = sle64((int64_t) 0, index_primexp_21225);\n        y_20651 = slt64(index_primexp_21225, n_14235);\n        bounds_check_20652 = x_20650 && y_20651;\n        if (!bounds_check_20652) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 11) == -1) {\n                    global_failure_args[0] = (int64_t) index_primexp_21225;\n                    global_failure_args[1] = (int64_t) n_14235;\n                    ;\n                }\n                return;\n            }\n        }\n        y_20655 = slt64(gtid_20647, n_14235);\n        if (!y_20655) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure", ", -1, 12) == -1) {\n                    global_failure_args[0] = (int64_t) gtid_20647;\n                    global_failure_args[1] = (int64_t) n_14235;\n                    ;\n                }\n                return;\n            }\n        }\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_20642\n}\nFUTHARK_KERNEL_SIZED(getPartitionBounds_8487zisegmap_20666_dim1, 1, 1)\nvoid getPartitionBounds_8487zisegmap_20666(__global int *global_failure, int64_t b_14236, int64_t dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, __global unsigned char *pXs_mem_21265, __global unsigned char *mem_21267, __global unsigned char *mem_21271)\n{\n    #define segmap_tblock_sizze_20661 (getPartitionBounds_8487zisegmap_20666zisegmap_tblock_sizze_20661)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_21787;\n    int32_t tblock_sizze_21790;\n    int32_t wave_sizze_21789;\n    int32_t block_id_21788;\n    int32_t global_tid_21786;\n    int64_t phys_tid_20666;\n    int64_t global_tid_21791;\n    int64_t slice_21792;\n    int64_t slice_21793;\n    int64_t gtid_20665;\n    int64_t remnant_21794;\n    int64_t gtid_slice_20664;\n    int64_t remnant_21795;\n    \n    local_tid_21787 = get_local_id(0);\n    tblock_sizze_21790 = get_local_size(0);\n    wave_sizze_21789 = LOCKSTEP_WIDTH;\n    block_id_21788 = get_tblock_id(0);\n    global_tid_21786 = block_id_21788 * tblock_sizze_21790 + local_tid_21787;\n    phys_tid_20666 = sext_i32_i64(global_tid_21786);\n    global_tid_21791 = sext_i32_i64(block_id_21788) * segmap_tblock_sizze_20661 + sext_i32_i64(local_tid_21787);\n    slice_21792 = b_14236;\n    slice_21793 = dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241 * slice_21792;\n    gtid_20665 = squot64(global_tid_21791, slice_21792);\n    remnant_21794 = global_tid_21791 - gtid_20665 * slice_21792;\n    gtid_slice_20664 = remnant_21794;\n    remnant_21795 = remnant_21794 - gtid_slice_20664;\n    if (slt64(gtid_20665, dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241) && slt64(gtid_slice_20664, b_14236)) {\n        int64_t index_primexp", "_21223;\n        bool index_certs_20668;\n        int8_t v_20669;\n        \n        index_primexp_21223 = add64((int64_t) 1, gtid_20665);\n        index_certs_20668 = 0;\n        v_20669 = ((__global int8_t *) pXs_mem_21265)[index_primexp_21223 * b_14236 + gtid_slice_20664];\n        ((__global int8_t *) mem_21271)[gtid_20665 * b_14236 + gtid_slice_20664] = v_20669;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_20661\n}\nFUTHARK_KERNEL_SIZED(getPartitionBounds_8487zisegmap_20677_dim1, 1, 1)\nvoid getPartitionBounds_8487zisegmap_20677(__global int *global_failure, int64_t b_14236, int64_t dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, __global unsigned char *pXs_mem_21265, __global unsigned char *mem_21268, __global unsigned char *mem_21274)\n{\n    #define segmap_tblock_sizze_20672 (getPartitionBounds_8487zisegmap_20677zisegmap_tblock_sizze_20672)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_21798;\n    int32_t tblock_sizze_21801;\n    int32_t wave_sizze_21800;\n    int32_t block_id_21799;\n    int32_t global_tid_21797;\n    int64_t phys_tid_20677;\n    int64_t global_tid_21802;\n    int64_t slice_21803;\n    int64_t slice_21804;\n    int64_t gtid_20676;\n    int64_t remnant_21805;\n    int64_t gtid_slice_20675;\n    int64_t remnant_21806;\n    \n    local_tid_21798 = get_local_id(0);\n    tblock_sizze_21801 = get_local_size(0);\n    wave_sizze_21800 = LOCKSTEP_WIDTH;\n    block_id_21799 = get_tblock_id(0);\n    global_tid_21797 = block_id_21799 * tblock_sizze_21801 + local_tid_21798;\n    phys_tid_20677 = sext_i32_i64(global_tid_21797);\n    global_tid_21802 = sext_i32_i64(block_id_21799) * segmap_tblock_sizze_20672 + sext_i32_i64(local_tid_21798);\n    slice_21803 = b_14236;\n    slice_21804 = dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241 * slice_21803;\n    gtid_20676 = squot64(global_tid_21802, slice_21803);\n    remnant_21805 = global_tid_21802 - gtid_20676 * slice_21803;\n    gtid_slice_20675 = remnant_21805;\n    remnant_21806 = remnant_21805 - gtid_slice_20675;\n    if",
                                    " (slt64(gtid_20676, dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241) && slt64(gtid_slice_20675, b_14236)) {\n        bool index_certs_20679;\n        int8_t v_20680;\n        \n        index_certs_20679 = 0;\n        v_20680 = ((__global int8_t *) pXs_mem_21265)[gtid_20676 * b_14236 + gtid_slice_20675];\n        ((__global int8_t *) mem_21274)[gtid_20676 * b_14236 + gtid_slice_20675] = v_20680;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_20672\n}\nFUTHARK_KERNEL_SIZED(getPartitionBounds_8487zisegmap_20693_dim1, 1, 1)\nvoid getPartitionBounds_8487zisegmap_20693(__global int *global_failure, int64_t b_14236, int64_t dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, int64_t i32_res_19304, int64_t i32_res_19308, __global unsigned char *mem_21271, __global unsigned char *mem_21274, __global unsigned char *mem_21277, __global unsigned char *mem_21279)\n{\n    #define segmap_tblock_sizze_20687 (getPartitionBounds_8487zisegmap_20693zisegmap_tblock_sizze_20687)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_21809;\n    int32_t tblock_sizze_21812;\n    int32_t wave_sizze_21811;\n    int32_t block_id_21810;\n    int32_t global_tid_21808;\n    int64_t phys_tid_20693;\n    int64_t global_tid_21813;\n    int64_t slice_21814;\n    int64_t slice_21815;\n    int64_t gtid_20691;\n    int64_t remnant_21816;\n    int64_t gtid_20692;\n    int64_t remnant_21817;\n    \n    local_tid_21809 = get_local_id(0);\n    tblock_sizze_21812 = get_local_size(0);\n    wave_sizze_21811 = LOCKSTEP_WIDTH;\n    block_id_21810 = get_tblock_id(0);\n    global_tid_21808 = block_id_21810 * tblock_sizze_21812 + local_tid_21809;\n    phys_tid_20693 = sext_i32_i64(global_tid_21808);\n    global_tid_21813 = sext_i32_i64(block_id_21810) * segmap_tblock_sizze_20687 + sext_i32_i64(local_tid_21809);\n    slice_21814 = b_14236;\n    slice_21815 = dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241 * slice_21814;\n    gtid_20691 = squot64(global_tid_21813, slice_21814);\n    remnant_21816 = global_tid_21813 - gtid_20691 * slice_21814;\n    gtid_2", "0692 = remnant_21816;\n    remnant_21817 = remnant_21816 - gtid_20692;\n    if (slt64(gtid_20691, dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241) && slt64(gtid_20692, b_14236)) {\n        bool cond_20697;\n        bool cond_t_res_20698;\n        bool x_20699;\n        int8_t lifted_lambda_res_20700;\n        int8_t lifted_lambda_res_20701;\n        \n        cond_20697 = sle64(gtid_20692, i32_res_19304);\n        cond_t_res_20698 = sle64(i32_res_19308, gtid_20692);\n        x_20699 = cond_20697 && cond_t_res_20698;\n        if (x_20699) {\n            int8_t eta_p_20695 = ((__global int8_t *) mem_21271)[gtid_20691 * b_14236 + gtid_20692];\n            \n            lifted_lambda_res_20700 = eta_p_20695;\n        } else {\n            lifted_lambda_res_20700 = (int8_t) 0;\n        }\n        if (x_20699) {\n            int8_t eta_p_20696 = ((__global int8_t *) mem_21274)[gtid_20691 * b_14236 + gtid_20692];\n            \n            lifted_lambda_res_20701 = eta_p_20696;\n        } else {\n            lifted_lambda_res_20701 = (int8_t) 0;\n        }\n        ((__global int8_t *) mem_21277)[gtid_20691 * b_14236 + gtid_20692] = lifted_lambda_res_20701;\n        ((__global int8_t *) mem_21279)[gtid_20691 * b_14236 + gtid_20692] = lifted_lambda_res_20700;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_20687\n}\nFUTHARK_KERNEL_SIZED(getPartitionBounds_8487zisegmap_20711_dim1, 1, 1)\nvoid getPartitionBounds_8487zisegmap_20711(__global int *global_failure, int64_t b_14236, int64_t dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, int64_t i32_res_19304, int64_t i32_res_19308, int8_t first_bitMask_19312, int8_t unsign_arg0_19316, int64_t num_tblocks_20706, int32_t virt_num_tblocks_21818, __global unsigned char *mem_21277, __global unsigned char *mem_21279, __global unsigned char *mem_21290, __global unsigned char *mem_21300)\n{\n    #define segmap_tblock_sizze_20705 (getPartitionBounds_8487zisegmap_20711zisegmap_tblock_sizze_20705)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_21820;\n  ", "  int32_t tblock_sizze_21823;\n    int32_t wave_sizze_21822;\n    int32_t block_id_21821;\n    int32_t global_tid_21819;\n    int64_t phys_tid_20711;\n    int32_t phys_tblock_id_21824;\n    int32_t iterations_21825;\n    \n    local_tid_21820 = get_local_id(0);\n    tblock_sizze_21823 = get_local_size(0);\n    wave_sizze_21822 = LOCKSTEP_WIDTH;\n    block_id_21821 = get_tblock_id(0);\n    global_tid_21819 = block_id_21821 * tblock_sizze_21823 + local_tid_21820;\n    phys_tid_20711 = sext_i32_i64(global_tid_21819);\n    phys_tblock_id_21824 = get_tblock_id(0);\n    iterations_21825 = sdiv_up32(virt_num_tblocks_21818 - phys_tblock_id_21824, sext_i64_i32(num_tblocks_20706));\n    for (int32_t i_21826 = 0; i_21826 < iterations_21825; i_21826++) {\n        int32_t virt_tblock_id_21827;\n        int64_t global_tid_21828;\n        int64_t slice_21829;\n        int64_t gtid_20710;\n        int64_t remnant_21830;\n        \n        virt_tblock_id_21827 = phys_tblock_id_21824 + i_21826 * sext_i64_i32(num_tblocks_20706);\n        global_tid_21828 = sext_i32_i64(virt_tblock_id_21827) * segmap_tblock_sizze_20705 + sext_i32_i64(local_tid_21820);\n        slice_21829 = dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241;\n        gtid_20710 = global_tid_21828;\n        remnant_21830 = global_tid_21828 - gtid_20710;\n        if (slt64(gtid_20710, dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241)) {\n            int8_t za_lhs_20714;\n            int8_t mod1_x_20715;\n            int8_t za_lhs_20717;\n            int8_t tmp_20718;\n            int8_t za_lhs_20720;\n            int8_t mod1_x_20721;\n            int8_t za_lhs_20723;\n            int8_t tmp_20724;\n            \n            za_lhs_20714 = ((__global int8_t *) mem_21279)[gtid_20710 * b_14236 + i32_res_19304];\n            mod1_x_20715 = first_bitMask_19312 & za_lhs_20714;\n            ((__global int8_t *) mem_21279)[gtid_20710 * b_14236 + i32_res_19304] = mod1_x_20715;\n            za_lhs_20717 = ((__global int8_t *) mem_21279)[gtid_20710 * b_14236 + i32_res_19308];\n            tmp_20718 =",
                                    " unsign_arg0_19316 & za_lhs_20717;\n            ((__global int8_t *) mem_21279)[gtid_20710 * b_14236 + i32_res_19308] = tmp_20718;\n            za_lhs_20720 = ((__global int8_t *) mem_21277)[gtid_20710 * b_14236 + i32_res_19304];\n            mod1_x_20721 = first_bitMask_19312 & za_lhs_20720;\n            ((__global int8_t *) mem_21277)[gtid_20710 * b_14236 + i32_res_19304] = mod1_x_20721;\n            za_lhs_20723 = ((__global int8_t *) mem_21277)[gtid_20710 * b_14236 + i32_res_19308];\n            tmp_20724 = unsign_arg0_19316 & za_lhs_20723;\n            ((__global int8_t *) mem_21277)[gtid_20710 * b_14236 + i32_res_19308] = tmp_20724;\n            for (int64_t i_0 = 0; i_0 < b_14236; i_0++) {\n                ((__global int8_t *) mem_21290)[gtid_20710 + i_0 * dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241] = ((__global int8_t *) mem_21279)[gtid_20710 * b_14236 + i_0];\n            }\n            for (int64_t i_0 = 0; i_0 < b_14236; i_0++) {\n                ((__global int8_t *) mem_21300)[gtid_20710 + i_0 * dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241] = ((__global int8_t *) mem_21277)[gtid_20710 * b_14236 + i_0];\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_20705\n}\nFUTHARK_KERNEL_SIZED(getPartitionBounds_8487zisegmap_20749_dim1, 1, 1)\nvoid getPartitionBounds_8487zisegmap_20749(__global int *global_failure, int64_t dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, __global unsigned char *mem_21302, __global unsigned char *mem_21305)\n{\n    #define segmap_tblock_sizze_20745 (getPartitionBounds_8487zisegmap_20749zisegmap_tblock_sizze_20745)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_21905;\n    int32_t tblock_sizze_21908;\n    int32_t wave_sizze_21907;\n    int32_t block_id_21906;\n    int32_t global_tid_21904;\n    int64_t phys_tid_20749;\n    int64_t global_tid_21909;\n    int64_t slice_21910;\n    int64_t gtid_20748;\n    int64_t remnant_21911;\n    \n    local_tid_21905 = get_local_i", "d(0);\n    tblock_sizze_21908 = get_local_size(0);\n    wave_sizze_21907 = LOCKSTEP_WIDTH;\n    block_id_21906 = get_tblock_id(0);\n    global_tid_21904 = block_id_21906 * tblock_sizze_21908 + local_tid_21905;\n    phys_tid_20749 = sext_i32_i64(global_tid_21904);\n    global_tid_21909 = sext_i32_i64(block_id_21906) * segmap_tblock_sizze_20745 + sext_i32_i64(local_tid_21905);\n    slice_21910 = dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241;\n    gtid_20748 = global_tid_21909;\n    remnant_21911 = global_tid_21909 - gtid_20748;\n    if (slt64(gtid_20748, dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241)) {\n        bool defunc_0_reduce_res_20750;\n        int64_t defunc_0_f_res_20751;\n        \n        defunc_0_reduce_res_20750 = ((__global bool *) mem_21302)[gtid_20748];\n        defunc_0_f_res_20751 = btoi_bool_i64(defunc_0_reduce_res_20750);\n        ((__global int64_t *) mem_21305)[gtid_20748] = defunc_0_f_res_20751;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_20745\n}\nFUTHARK_KERNEL_SIZED(getPartitionBounds_8487zisegmap_20768_dim1, 1, 1)\nvoid getPartitionBounds_8487zisegmap_20768(__global int *global_failure, int64_t dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, int64_t m_18095, int64_t num_tblocks_20773, int32_t virt_num_tblocks_22034, __global unsigned char *ext_mem_21374, __global unsigned char *ext_mem_21375, __global unsigned char *mem_21377)\n{\n    #define segmap_tblock_sizze_20771 (getPartitionBounds_8487zisegmap_20768zisegmap_tblock_sizze_20771)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_22036;\n    int32_t tblock_sizze_22039;\n    int32_t wave_sizze_22038;\n    int32_t block_id_22037;\n    int32_t global_tid_22035;\n    int64_t phys_tid_20768;\n    int32_t phys_tblock_id_22040;\n    int32_t iterations_22041;\n    \n    local_tid_22036 = get_local_id(0);\n    tblock_sizze_22039 = get_local_size(0);\n    wave_sizze_22038 = LOCKSTEP_WIDTH;\n    block_id_22037 = get_tblock_id(0);\n    global_tid_22035 = block_id_22037 * tblock_sizze_22039 + local_tid_22036;\n    phys_ti", "d_20768 = sext_i32_i64(global_tid_22035);\n    phys_tblock_id_22040 = get_tblock_id(0);\n    iterations_22041 = sdiv_up32(virt_num_tblocks_22034 - phys_tblock_id_22040, sext_i64_i32(num_tblocks_20773));\n    for (int32_t i_22042 = 0; i_22042 < iterations_22041; i_22042++) {\n        int32_t virt_tblock_id_22043;\n        int64_t global_tid_22044;\n        int64_t slice_22045;\n        int64_t write_i_20767;\n        int64_t remnant_22046;\n        \n        virt_tblock_id_22043 = phys_tblock_id_22040 + i_22042 * sext_i64_i32(num_tblocks_20773);\n        global_tid_22044 = sext_i32_i64(virt_tblock_id_22043) * segmap_tblock_sizze_20771 + sext_i32_i64(local_tid_22036);\n        slice_22045 = dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241;\n        write_i_20767 = global_tid_22044;\n        remnant_22046 = global_tid_22044 - write_i_20767;\n        if (slt64(write_i_20767, dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241)) {\n            int64_t eta_p_19419;\n            int64_t index_primexp_21209;\n            bool cond_19422;\n            int64_t lifted_lambda_res_19423;\n            \n            eta_p_19419 = ((__global int64_t *) ext_mem_21374)[write_i_20767];\n            index_primexp_21209 = add64((int64_t) 1, write_i_20767);\n            cond_19422 = eta_p_19419 == (int64_t) 1;\n            if (cond_19422) {\n                int64_t eta_p_19420;\n                int64_t lifted_lambda_res_t_res_19574;\n                \n                eta_p_19420 = ((__global int64_t *) ext_mem_21375)[write_i_20767];\n                lifted_lambda_res_t_res_19574 = sub64(eta_p_19420, (int64_t) 1);\n                lifted_lambda_res_19423 = lifted_lambda_res_t_res_19574;\n            } else {\n                lifted_lambda_res_19423 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_19423) && slt64(lifted_lambda_res_19423, m_18095)) {\n                ((__global int64_t *) mem_21377)[lifted_lambda_res_19423] = index_primexp_21209;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL",
                                    "_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_20771\n}\nFUTHARK_KERNEL\nvoid getPartitionBounds_8487zisegmap_intrablock_20593(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t n_14235, int64_t b_14236, int64_t dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, int64_t i32_res_19304, int64_t i32_res_19308, int8_t first_bitMask_19312, int8_t unsign_arg0_19316, __global unsigned char *pXs_mem_21265, __global unsigned char *mem_21310)\n{\n    volatile __local unsigned char *red_arr_mem_21772_backing_2 = &shared_mem[0];\n    const int64_t red_arr_mem_21772_backing_2_offset = 0 + (b_14236 + srem64((int64_t) 8 - srem64(b_14236, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_21561_backing_1 = &shared_mem[red_arr_mem_21772_backing_2_offset];\n    const int64_t color_21561_backing_1_offset = red_arr_mem_21772_backing_2_offset + (b_14236 + srem64((int64_t) 8 - srem64(b_14236, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_21560_backing_0 = &shared_mem[color_21561_backing_1_offset];\n    const int64_t color_21560_backing_0_offset = color_21561_backing_1_offset + (b_14236 + srem64((int64_t) 8 - srem64(b_14236, (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_21763;\n    int32_t tblock_sizze_21766;\n    int32_t wave_sizze_21765;\n    int32_t block_id_21764;\n    int32_t global_tid_21762;\n    int64_t phys_tblock_id_20593;\n    int64_t slice_21768;\n    int64_t ltid_pre_21767;\n    int64_t remnant_21769;\n    int64_t slice_21770;\n    int64_t gtid_20592;\n    int64_t remnant_21771;\n    __local unsigned char *color_21560;\n    __local unsigned char *color_21561;\n    int64_t index_primexp_21219;\n    bool x_20595;\n    bool y_20596;\n    bool bounds_chec", "k_20597;\n    bool index_certs_20598;\n    bool y_20600;\n    bool index_certs_20603;\n    int64_t phys_tid_20609;\n    int64_t gtid_20608;\n    bool cond_20613;\n    bool cond_t_res_20614;\n    bool x_20615;\n    int8_t lifted_lambda_res_20616;\n    int8_t lifted_lambda_res_20617;\n    int8_t za_lhs_20618;\n    int8_t mod1_x_20619;\n    int8_t za_lhs_20621;\n    int8_t tmp_20622;\n    int8_t za_lhs_20624;\n    int8_t mod1_x_20625;\n    int8_t za_lhs_20627;\n    int8_t tmp_20628;\n    bool defunc_0_reduce_res_20630;\n    int64_t phys_tid_20632;\n    __local unsigned char *red_arr_mem_21772;\n    int64_t gtid_20631;\n    int8_t eta_p_20636;\n    int8_t eta_p_20637;\n    bool lifted_lambda_res_20638;\n    bool lifted_lambda_res_20639;\n    int32_t offset_21774;\n    int32_t skip_waves_21775;\n    bool eta_p_20633;\n    bool eta_p_20634;\n    int64_t defunc_0_f_res_20640;\n    \n    local_tid_21763 = get_local_id(0);\n    tblock_sizze_21766 = get_local_size(0);\n    wave_sizze_21765 = LOCKSTEP_WIDTH;\n    block_id_21764 = get_tblock_id(0);\n    global_tid_21762 = block_id_21764 * tblock_sizze_21766 + local_tid_21763;\n    phys_tblock_id_20593 = sext_i32_i64(block_id_21764);\n    slice_21768 = b_14236;\n    ltid_pre_21767 = sext_i32_i64(local_tid_21763);\n    remnant_21769 = sext_i32_i64(local_tid_21763) - ltid_pre_21767;\n    slice_21770 = dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241;\n    gtid_20592 = sext_i32_i64(block_id_21764);\n    remnant_21771 = sext_i32_i64(block_id_21764) - gtid_20592;\n    color_21560 = (__local unsigned char *) color_21560_backing_0;\n    color_21561 = (__local unsigned char *) color_21561_backing_1;\n    index_primexp_21219 = add64((int64_t) 1, gtid_20592);\n    x_20595 = sle64((int64_t) 0, index_primexp_21219);\n    y_20596 = slt64(index_primexp_21219, n_14235);\n    bounds_check_20597 = x_20595 && y_20596;\n    if (!bounds_check_20597) {\n        {\n            if (atomic_cmpxchg_i32_global(global_failure, -1, 9) == -1) {\n                global_failure_args[0] = (int64_t) index_primexp_21219;\n      ", "          global_failure_args[1] = (int64_t) n_14235;\n                ;\n            }\n            local_failure = 1;\n            goto error_0;\n        }\n    }\n    y_20600 = slt64(gtid_20592, n_14235);\n    if (!y_20600) {\n        {\n            if (atomic_cmpxchg_i32_global(global_failure, -1, 10) == -1) {\n                global_failure_args[0] = (int64_t) gtid_20592;\n                global_failure_args[1] = (int64_t) n_14235;\n                ;\n            }\n            local_failure = 1;\n            goto error_0;\n        }\n    }\n    phys_tid_20609 = sext_i32_i64(local_tid_21763);\n    gtid_20608 = sext_i32_i64(sext_i64_i32(ltid_pre_21767));\n    cond_20613 = sle64(gtid_20608, i32_res_19304);\n    cond_t_res_20614 = sle64(i32_res_19308, gtid_20608);\n    x_20615 = cond_20613 && cond_t_res_20614;\n    if (x_20615) {\n        int8_t eta_p_20611 = ((__global int8_t *) pXs_mem_21265)[index_primexp_21219 * b_14236 + gtid_20608];\n        \n        lifted_lambda_res_20616 = eta_p_20611;\n    } else {\n        lifted_lambda_res_20616 = (int8_t) 0;\n    }\n    if (x_20615) {\n        int8_t eta_p_20612 = ((__global int8_t *) pXs_mem_21265)[gtid_20592 * b_14236 + gtid_20608];\n        \n        lifted_lambda_res_20617 = eta_p_20612;\n    } else {\n        lifted_lambda_res_20617 = (int8_t) 0;\n    }\n    ((__local int8_t *) color_21561)[gtid_20608] = lifted_lambda_res_20617;\n    ((__local int8_t *) color_21560)[gtid_20608] = lifted_lambda_res_20616;\n    \n  error_0:\n    barrier(CLK_LOCAL_MEM_FENCE);\n    if (local_failure)\n        return;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    za_lhs_20618 = ((__local int8_t *) color_21560)[i32_res_19304];\n    mod1_x_20619 = first_bitMask_19312 & za_lhs_20618;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    if (local_tid_21763 == 0) {\n        ((__local int8_t *) color_21560)[i32_res_19304] = mod1_x_20619;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    za_lhs_20621 = ((__local int8_t *) color_21560)[i32_res_19308];\n    tmp_20622 = unsign_arg0_19316 & za_lhs_20621;\n    barrier(CL",
                                    "K_LOCAL_MEM_FENCE);\n    if (local_tid_21763 == 0) {\n        ((__local int8_t *) color_21560)[i32_res_19308] = tmp_20622;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    za_lhs_20624 = ((__local int8_t *) color_21561)[i32_res_19304];\n    mod1_x_20625 = first_bitMask_19312 & za_lhs_20624;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    if (local_tid_21763 == 0) {\n        ((__local int8_t *) color_21561)[i32_res_19304] = mod1_x_20625;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    za_lhs_20627 = ((__local int8_t *) color_21561)[i32_res_19308];\n    tmp_20628 = unsign_arg0_19316 & za_lhs_20627;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    if (local_tid_21763 == 0) {\n        ((__local int8_t *) color_21561)[i32_res_19308] = tmp_20628;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    phys_tid_20632 = sext_i32_i64(local_tid_21763);\n    red_arr_mem_21772 = (__local unsigned char *) red_arr_mem_21772_backing_2;\n    gtid_20631 = sext_i32_i64(sext_i64_i32(ltid_pre_21767));\n    eta_p_20636 = ((__local int8_t *) color_21560)[gtid_20631];\n    eta_p_20637 = ((__local int8_t *) color_21561)[gtid_20631];\n    lifted_lambda_res_20638 = eta_p_20636 == eta_p_20637;\n    lifted_lambda_res_20639 = !lifted_lambda_res_20638;\n    ((__local bool *) red_arr_mem_21772)[gtid_20631] = lifted_lambda_res_20639;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    skip_waves_21775 = 1;\n    offset_21774 = 0;\n    // participating threads read initial accumulator\n    {\n        if (slt32(local_tid_21763, sext_i64_i32(b_14236))) {\n            eta_p_20633 = ((__local bool *) red_arr_mem_21772)[sext_i32_i64(local_tid_21763 + offset_21774)];\n        }\n    }\n    offset_21774 = 1;\n    while (slt32(offset_21774, wave_sizze_21765)) {\n        if (slt32(local_tid_21763 + offset_21774, sext_i64_i32(b_14236)) && ((local_tid_21763 - squot32(local_tid_21763, wave_sizze_21765) * wave_sizze_21765) & (2 * offset_21774 - 1)) == 0) {\n            // read array element\n            {\n                eta_p_20634 = ((volatile __local bool *) red_arr_mem_21772)[sext_i32_i6", "4(local_tid_21763 + offset_21774)];\n            }\n            // apply reduction operation\n            {\n                bool defunc_0_op_res_20635 = eta_p_20633 || eta_p_20634;\n                \n                eta_p_20633 = defunc_0_op_res_20635;\n            }\n            // write result of operation\n            {\n                ((volatile __local bool *) red_arr_mem_21772)[sext_i32_i64(local_tid_21763)] = eta_p_20633;\n            }\n        }\n        offset_21774 *= 2;\n    }\n    while (slt32(skip_waves_21775, squot32(sext_i64_i32(b_14236) + wave_sizze_21765 - 1, wave_sizze_21765))) {\n        barrier(CLK_LOCAL_MEM_FENCE);\n        offset_21774 = skip_waves_21775 * wave_sizze_21765;\n        if (slt32(local_tid_21763 + offset_21774, sext_i64_i32(b_14236)) && ((local_tid_21763 - squot32(local_tid_21763, wave_sizze_21765) * wave_sizze_21765) == 0 && (squot32(local_tid_21763, wave_sizze_21765) & (2 * skip_waves_21775 - 1)) == 0)) {\n            // read array element\n            {\n                eta_p_20634 = ((__local bool *) red_arr_mem_21772)[sext_i32_i64(local_tid_21763 + offset_21774)];\n            }\n            // apply reduction operation\n            {\n                bool defunc_0_op_res_20635 = eta_p_20633 || eta_p_20634;\n                \n                eta_p_20633 = defunc_0_op_res_20635;\n            }\n            // write result of operation\n            {\n                ((__local bool *) red_arr_mem_21772)[sext_i32_i64(local_tid_21763)] = eta_p_20633;\n            }\n        }\n        skip_waves_21775 *= 2;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // Save result of reduction.\n    {\n        defunc_0_reduce_res_20630 = ((__local bool *) red_arr_mem_21772)[(int64_t) 0];\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    defunc_0_f_res_20640 = btoi_bool_i64(defunc_0_reduce_res_20630);\n    if (local_tid_21763 == 0) {\n        ((__global int64_t *) mem_21310)[gtid_20592] = defunc_0_f_res_20640;\n    }\n    \n  error_5:\n    return;\n}\nFUTHARK_", "KERNEL_SIZED(getPartitionBounds_8487zisegred_large_20734_dim1, 1, 1)\nvoid getPartitionBounds_8487zisegred_large_20734(__global int *global_failure, int64_t b_14236, int64_t dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, int64_t num_tblocks_20729, int64_t blocks_per_segment_21860, int64_t q_21861, int64_t num_virtblocks_21862, int64_t threads_per_segment_21863, __global unsigned char *mem_21290, __global unsigned char *mem_21300, __global unsigned char *mem_21302, __global unsigned char *segred_tmp_mem_21864, __global unsigned char *counters_mem_21866)\n{\n    #define segred_tblock_sizze_20728 (getPartitionBounds_8487zisegred_large_20734zisegred_tblock_sizze_20728)\n    #define chunk_sizze_21831 (getPartitionBounds_8487zisegred_large_20734zichunk_sizze_21831)\n    \n    volatile __local unsigned char *sync_arr_mem_21875_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_21875_backing_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_bool_mem_21873_backing_0 = &shared_mem[sync_arr_mem_21875_backing_1_offset];\n    const int64_t red_arr_bool_mem_21873_backing_0_offset = sync_arr_mem_21875_backing_1_offset + (segred_tblock_sizze_20728 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_20728, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_21869;\n    int32_t tblock_sizze_21872;\n    int32_t wave_sizze_21871;\n    int32_t block_id_21870;\n    int32_t global_tid_21868;\n    int64_t phys_tid_20734;\n    __local unsigned char *red_arr_bool_mem_21873;\n    __local unsigned char *sync_arr_mem_21875;\n    int32_t phys_tblock_id_21877;\n    int32_t iterations_21878;\n    \n    local_tid_21869 = get_local_id(0);\n    tblock_sizze_21872 = get_local_size(0);\n    wave_sizze_21871 = LOCKSTEP_WIDTH;\n    block_id_21870 = get_tblock_id(0);\n    global_tid_21868 = block_id_21870 * tblock_sizze_21872 + local_tid_21869;\n    phys_tid_20734 = sext_i32_i64(global_tid_21868);\n    red_arr_bool_mem_21873 = (__local unsigned char *) red_arr_bool_m",
                                    "em_21873_backing_0;\n    sync_arr_mem_21875 = (__local unsigned char *) sync_arr_mem_21875_backing_1;\n    phys_tblock_id_21877 = get_tblock_id(0);\n    iterations_21878 = sdiv_up32(sext_i64_i32(num_virtblocks_21862) - phys_tblock_id_21877, sext_i64_i32(num_tblocks_20729));\n    for (int32_t i_21879 = 0; i_21879 < iterations_21878; i_21879++) {\n        int32_t virt_tblock_id_21880;\n        int64_t flat_segment_id_21881;\n        int64_t global_tid_21882;\n        int64_t slice_21883;\n        int64_t gtid_20732;\n        int64_t remnant_21884;\n        int64_t gtid_20733;\n        bool eta_p_block_res_acc_21885;\n        bool eta_p_20735;\n        bool eta_p_20736;\n        int64_t tblock_id_in_segment_21889;\n        int64_t block_base_offset_21890;\n        int32_t offset_21893;\n        int32_t skip_waves_21894;\n        bool eta_p_21886;\n        bool eta_p_21887;\n        \n        virt_tblock_id_21880 = phys_tblock_id_21877 + i_21879 * sext_i64_i32(num_tblocks_20729);\n        flat_segment_id_21881 = squot64(sext_i32_i64(virt_tblock_id_21880), blocks_per_segment_21860);\n        global_tid_21882 = srem64(sext_i32_i64(virt_tblock_id_21880) * segred_tblock_sizze_20728 + sext_i32_i64(local_tid_21869), threads_per_segment_21863);\n        slice_21883 = dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241;\n        gtid_20732 = flat_segment_id_21881;\n        remnant_21884 = flat_segment_id_21881 - gtid_20732;\n        // ne-initialise the outer (per-block) accumulator(s)\n        {\n            eta_p_block_res_acc_21885 = 0;\n        }\n        tblock_id_in_segment_21889 = squot64(global_tid_21882, segred_tblock_sizze_20728);\n        block_base_offset_21890 = tblock_id_in_segment_21889 * q_21861 * segred_tblock_sizze_20728;\n        for (int64_t i_21891 = 0; i_21891 < q_21861; i_21891++) {\n            int64_t block_offset_21892 = block_base_offset_21890 + i_21891 * segred_tblock_sizze_20728;\n            \n            gtid_20733 = global_tid_21882 + threads_per_segment_21863 * i_21891;\n            if (slt64(gtid_", "20733, b_14236)) {\n                // apply map function(s)\n                {\n                    // apply map function\n                    {\n                        int8_t eta_p_20740 = ((__global int8_t *) mem_21290)[gtid_20732 + gtid_20733 * dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241];\n                        int8_t eta_p_20741 = ((__global int8_t *) mem_21300)[gtid_20732 + gtid_20733 * dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241];\n                        bool lifted_lambda_res_20742 = eta_p_20740 == eta_p_20741;\n                        bool lifted_lambda_res_20743 = !lifted_lambda_res_20742;\n                        \n                        // load accumulator(s)\n                        {\n                            eta_p_20735 = eta_p_block_res_acc_21885;\n                        }\n                        // load next value(s)\n                        {\n                            eta_p_20736 = lifted_lambda_res_20743;\n                        }\n                        // apply reduction operator(s)\n                        {\n                            bool defunc_0_op_res_20737 = eta_p_20735 || eta_p_20736;\n                            \n                            // store in accumulator(s)\n                            {\n                                eta_p_block_res_acc_21885 = defunc_0_op_res_20737;\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // store accs. prims go in lmem; non-prims in params (in global mem)\n        {\n            ((__local bool *) red_arr_bool_mem_21873)[sext_i32_i64(local_tid_21869)] = eta_p_block_res_acc_21885;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        skip_waves_21894 = 1;\n        offset_21893 = 0;\n        // participating threads read initial accumulator\n        {\n            if (slt32(local_tid_21869, sext_i64_i32(segred_tblock_sizze_20728))) {\n                eta_p_21886 = ((__local bool *) red_arr_bool_mem_21873)[sext_", "i32_i64(local_tid_21869 + offset_21893)];\n            }\n        }\n        offset_21893 = 1;\n        while (slt32(offset_21893, wave_sizze_21871)) {\n            if (slt32(local_tid_21869 + offset_21893, sext_i64_i32(segred_tblock_sizze_20728)) && ((local_tid_21869 - squot32(local_tid_21869, wave_sizze_21871) * wave_sizze_21871) & (2 * offset_21893 - 1)) == 0) {\n                // read array element\n                {\n                    eta_p_21887 = ((volatile __local bool *) red_arr_bool_mem_21873)[sext_i32_i64(local_tid_21869 + offset_21893)];\n                }\n                // apply reduction operation\n                {\n                    bool defunc_0_op_res_21888 = eta_p_21886 || eta_p_21887;\n                    \n                    eta_p_21886 = defunc_0_op_res_21888;\n                }\n                // write result of operation\n                {\n                    ((volatile __local bool *) red_arr_bool_mem_21873)[sext_i32_i64(local_tid_21869)] = eta_p_21886;\n                }\n            }\n            offset_21893 *= 2;\n        }\n        while (slt32(skip_waves_21894, squot32(sext_i64_i32(segred_tblock_sizze_20728) + wave_sizze_21871 - 1, wave_sizze_21871))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_21893 = skip_waves_21894 * wave_sizze_21871;\n            if (slt32(local_tid_21869 + offset_21893, sext_i64_i32(segred_tblock_sizze_20728)) && ((local_tid_21869 - squot32(local_tid_21869, wave_sizze_21871) * wave_sizze_21871) == 0 && (squot32(local_tid_21869, wave_sizze_21871) & (2 * skip_waves_21894 - 1)) == 0)) {\n                // read array element\n                {\n                    eta_p_21887 = ((__local bool *) red_arr_bool_mem_21873)[sext_i32_i64(local_tid_21869 + offset_21893)];\n                }\n                // apply reduction operation\n                {\n                    bool defunc_0_op_res_21888 = eta_p_21886 || eta_p_21887;\n                    \n                    eta_p_21886 = defunc_0_op_res_21888;\n                ",
                                    "}\n                // write result of operation\n                {\n                    ((__local bool *) red_arr_bool_mem_21873)[sext_i32_i64(local_tid_21869)] = eta_p_21886;\n                }\n            }\n            skip_waves_21894 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // thread 0 updates per-block acc(s); rest reset to ne\n        {\n            if (sext_i32_i64(local_tid_21869) == (int64_t) 0) {\n                eta_p_block_res_acc_21885 = eta_p_21886;\n            } else {\n                eta_p_block_res_acc_21885 = 0;\n            }\n        }\n        if (blocks_per_segment_21860 == (int64_t) 1) {\n            // first thread in block saves final result to memory\n            {\n                if (local_tid_21869 == 0) {\n                    ((__global bool *) mem_21302)[gtid_20732] = eta_p_block_res_acc_21885;\n                }\n            }\n        } else {\n            int32_t old_counter_21895;\n            bool is_last_block_21896;\n            \n            // first thread in block saves block result to global memory\n            {\n                if (local_tid_21869 == 0) {\n                    ((__global bool *) segred_tmp_mem_21864)[sext_i32_i64(virt_tblock_id_21880)] = eta_p_block_res_acc_21885;\n                    mem_fence_global();\n                    old_counter_21895 = atomic_add_i32_global(&((volatile __global int *) counters_mem_21866)[srem64(flat_segment_id_21881, (int64_t) 20480)], (int) 1);\n                    ((__local bool *) sync_arr_mem_21875)[(int64_t) 0] = old_counter_21895 == sext_i64_i32(blocks_per_segment_21860 - (int64_t) 1);\n                }\n            }\n            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n            is_last_block_21896 = ((__local bool *) sync_arr_mem_21875)[(int64_t) 0];\n            if (is_last_block_21896) {\n                if (local_tid_21869 == 0) {\n                    old_counter_21895 = atomic_add_i32_global(&((volatile __global int *) counters_", "mem_21866)[srem64(flat_segment_id_21881, (int64_t) 20480)], (int) sext_i64_i32((int64_t) 0 - blocks_per_segment_21860));\n                }\n                // read in the per-block-results\n                {\n                    int64_t read_per_thread_21897 = sdiv_up64(blocks_per_segment_21860, segred_tblock_sizze_20728);\n                    \n                    eta_p_20735 = 0;\n                    for (int64_t i_21898 = 0; i_21898 < read_per_thread_21897; i_21898++) {\n                        int64_t block_res_id_21899 = sext_i32_i64(local_tid_21869) * read_per_thread_21897 + i_21898;\n                        int64_t index_of_block_res_21900 = flat_segment_id_21881 * blocks_per_segment_21860 + block_res_id_21899;\n                        \n                        if (slt64(block_res_id_21899, blocks_per_segment_21860)) {\n                            eta_p_20736 = ((__global bool *) segred_tmp_mem_21864)[index_of_block_res_21900];\n                            \n                            bool defunc_0_op_res_20737 = eta_p_20735 || eta_p_20736;\n                            \n                            eta_p_20735 = defunc_0_op_res_20737;\n                        }\n                    }\n                }\n                ((__local bool *) red_arr_bool_mem_21873)[sext_i32_i64(local_tid_21869)] = eta_p_20735;\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // reduce the per-block results\n                {\n                    int32_t offset_21901;\n                    int32_t skip_waves_21902 = 1;\n                    bool eta_p_21886;\n                    bool eta_p_21887;\n                    \n                    offset_21901 = 0;\n                    // participating threads read initial accumulator\n                    {\n                        if (slt32(local_tid_21869, sext_i64_i32(segred_tblock_sizze_20728))) {\n                            eta_p_21886 = ((__local bool *) red_arr_bool_mem_21873)[sext_i32_i64(local_tid_21869 + offset_21901)];\n                        }\n ", "                   }\n                    offset_21901 = 1;\n                    while (slt32(offset_21901, wave_sizze_21871)) {\n                        if (slt32(local_tid_21869 + offset_21901, sext_i64_i32(segred_tblock_sizze_20728)) && ((local_tid_21869 - squot32(local_tid_21869, wave_sizze_21871) * wave_sizze_21871) & (2 * offset_21901 - 1)) == 0) {\n                            // read array element\n                            {\n                                eta_p_21887 = ((volatile __local bool *) red_arr_bool_mem_21873)[sext_i32_i64(local_tid_21869 + offset_21901)];\n                            }\n                            // apply reduction operation\n                            {\n                                bool defunc_0_op_res_21888 = eta_p_21886 || eta_p_21887;\n                                \n                                eta_p_21886 = defunc_0_op_res_21888;\n                            }\n                            // write result of operation\n                            {\n                                ((volatile __local bool *) red_arr_bool_mem_21873)[sext_i32_i64(local_tid_21869)] = eta_p_21886;\n                            }\n                        }\n                        offset_21901 *= 2;\n                    }\n                    while (slt32(skip_waves_21902, squot32(sext_i64_i32(segred_tblock_sizze_20728) + wave_sizze_21871 - 1, wave_sizze_21871))) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                        offset_21901 = skip_waves_21902 * wave_sizze_21871;\n                        if (slt32(local_tid_21869 + offset_21901, sext_i64_i32(segred_tblock_sizze_20728)) && ((local_tid_21869 - squot32(local_tid_21869, wave_sizze_21871) * wave_sizze_21871) == 0 && (squot32(local_tid_21869, wave_sizze_21871) & (2 * skip_waves_21902 - 1)) == 0)) {\n                            // read array element\n                            {\n                                eta_p_21887 = ((__local bool *) red_arr_bool_mem_21873)[sext_i32_i64(local_t",
                                    "id_21869 + offset_21901)];\n                            }\n                            // apply reduction operation\n                            {\n                                bool defunc_0_op_res_21888 = eta_p_21886 || eta_p_21887;\n                                \n                                eta_p_21886 = defunc_0_op_res_21888;\n                            }\n                            // write result of operation\n                            {\n                                ((__local bool *) red_arr_bool_mem_21873)[sext_i32_i64(local_tid_21869)] = eta_p_21886;\n                            }\n                        }\n                        skip_waves_21902 *= 2;\n                    }\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                    // and back to memory with the final result\n                    {\n                        if (local_tid_21869 == 0) {\n                            ((__global bool *) mem_21302)[gtid_20732] = eta_p_21886;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_6:\n    return;\n    #undef segred_tblock_sizze_20728\n    #undef chunk_sizze_21831\n}\nFUTHARK_KERNEL_SIZED(getPartitionBounds_8487zisegred_small_20734_dim1, 1, 1)\nvoid getPartitionBounds_8487zisegred_small_20734(__global int *global_failure, int64_t b_14236, int64_t dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, int64_t num_tblocks_20729, int64_t segment_sizze_nonzzero_21832, __global unsigned char *mem_21290, __global unsigned char *mem_21300, __global unsigned char *mem_21302)\n{\n    #define segred_tblock_sizze_20728 (getPartitionBounds_8487zisegred_small_20734zisegred_tblock_sizze_20728)\n    \n    volatile __local unsigned char *red_arr_bool_mem_21839_backing_0 = &shared_mem[0];\n    const int64_t red_arr_bool_mem_21839_backing_0_offset = 0 + (segred_tblock_sizze_20728 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_20728, (int64_t) 8), (int64_t) 8));\n    \n  ", "  if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_21835;\n    int32_t tblock_sizze_21838;\n    int32_t wave_sizze_21837;\n    int32_t block_id_21836;\n    int32_t global_tid_21834;\n    int64_t phys_tid_20734;\n    __local unsigned char *red_arr_bool_mem_21839;\n    int32_t phys_tblock_id_21841;\n    int32_t iterations_21842;\n    \n    local_tid_21835 = get_local_id(0);\n    tblock_sizze_21838 = get_local_size(0);\n    wave_sizze_21837 = LOCKSTEP_WIDTH;\n    block_id_21836 = get_tblock_id(0);\n    global_tid_21834 = block_id_21836 * tblock_sizze_21838 + local_tid_21835;\n    phys_tid_20734 = sext_i32_i64(global_tid_21834);\n    red_arr_bool_mem_21839 = (__local unsigned char *) red_arr_bool_mem_21839_backing_0;\n    phys_tblock_id_21841 = get_tblock_id(0);\n    iterations_21842 = sdiv_up32(sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, squot64(segred_tblock_sizze_20728, segment_sizze_nonzzero_21832))) - phys_tblock_id_21841, sext_i64_i32(num_tblocks_20729));\n    for (int32_t i_21843 = 0; i_21843 < iterations_21842; i_21843++) {\n        int32_t virt_tblock_id_21844;\n        int64_t slice_21845;\n        int64_t gtid_20732;\n        int64_t remnant_21846;\n        int64_t gtid_20733;\n        \n        virt_tblock_id_21844 = phys_tblock_id_21841 + i_21843 * sext_i64_i32(num_tblocks_20729);\n        slice_21845 = dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241;\n        gtid_20732 = squot64(sext_i32_i64(local_tid_21835), segment_sizze_nonzzero_21832) + sext_i32_i64(virt_tblock_id_21844) * squot64(segred_tblock_sizze_20728, segment_sizze_nonzzero_21832);\n        remnant_21846 = squot64(sext_i32_i64(local_tid_21835), segment_sizze_nonzzero_21832) + sext_i32_i64(virt_tblock_id_21844) * squot64(segred_tblock_sizze_20728, segment_sizze_nonzzero_21832) - gtid_20732;\n        gtid_20733 = srem64(sext_i32_i64(local_tid_21835), b_14236);\n        // apply map function if in bounds\n        {\n            if (slt64((int64_t) 0, b_14236) && (slt64(gtid_20732, dzlz7bUZLzmZRz20Unz20U1z7d", "Uzg_14241) && slt64(sext_i32_i64(local_tid_21835), b_14236 * squot64(segred_tblock_sizze_20728, segment_sizze_nonzzero_21832)))) {\n                // apply map function\n                {\n                    int8_t eta_p_20740 = ((__global int8_t *) mem_21290)[gtid_20732 + gtid_20733 * dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241];\n                    int8_t eta_p_20741 = ((__global int8_t *) mem_21300)[gtid_20732 + gtid_20733 * dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241];\n                    bool lifted_lambda_res_20742 = eta_p_20740 == eta_p_20741;\n                    bool lifted_lambda_res_20743 = !lifted_lambda_res_20742;\n                    \n                    // save results to be reduced\n                    {\n                        ((__local bool *) red_arr_bool_mem_21839)[sext_i32_i64(local_tid_21835)] = lifted_lambda_res_20743;\n                    }\n                }\n            } else {\n                ((__local bool *) red_arr_bool_mem_21839)[sext_i32_i64(local_tid_21835)] = 0;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (slt64((int64_t) 0, b_14236)) {\n            // perform segmented scan to imitate reduction\n            {\n                bool eta_p_20735;\n                bool eta_p_20736;\n                bool eta_p_21847;\n                bool eta_p_21848;\n                bool ltid_in_bounds_21850 = slt64(sext_i32_i64(local_tid_21835), b_14236 * squot64(segred_tblock_sizze_20728, segment_sizze_nonzzero_21832));\n                int32_t skip_threads_21851;\n                \n                // read input for in-block scan\n                {\n                    if (ltid_in_bounds_21850) {\n                        eta_p_20736 = ((volatile __local bool *) red_arr_bool_mem_21839)[sext_i32_i64(local_tid_21835)];\n                        if ((local_tid_21835 - squot32(local_tid_21835, 32) * 32) == 0) {\n                            eta_p_20735 = eta_p_20736;\n                        }\n                    }\n                }\n                // in-block scan",
                                    " (hopefully no barriers needed)\n                {\n                    skip_threads_21851 = 1;\n                    while (slt32(skip_threads_21851, 32)) {\n                        bool thread_active_21852 = sle32(skip_threads_21851, local_tid_21835 - squot32(local_tid_21835, 32) * 32) && ltid_in_bounds_21850;\n                        \n                        if (thread_active_21852) {\n                            // read operands\n                            {\n                                eta_p_20735 = ((volatile __local bool *) red_arr_bool_mem_21839)[sext_i32_i64(local_tid_21835) - sext_i32_i64(skip_threads_21851)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            bool inactive_21853 = slt64(srem64(sext_i32_i64(local_tid_21835), b_14236), sext_i32_i64(local_tid_21835) - sext_i32_i64(local_tid_21835 - skip_threads_21851));\n                            \n                            if (thread_active_21852 && inactive_21853) {\n                                eta_p_20735 = eta_p_20736;\n                            }\n                            if (thread_active_21852) {\n                                if (!inactive_21853) {\n                                    bool defunc_0_op_res_20737 = eta_p_20735 || eta_p_20736;\n                                    \n                                    eta_p_20735 = defunc_0_op_res_20737;\n                                }\n                            }\n                        }\n                        if (sle32(wave_sizze_21837, skip_threads_21851)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_21852) {\n                            // write result\n                            {\n                                ((volatile __local bool *) red_arr_bool_mem_21839)[sext_i32_i64(local_tid_21835)] = eta_p_20735;\n                                eta_p_20736 = eta_p_2", "0735;\n                            }\n                        }\n                        if (sle32(wave_sizze_21837, skip_threads_21851)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_21851 *= 2;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // last thread of block 'i' writes its result to offset 'i'\n                {\n                    if ((local_tid_21835 - squot32(local_tid_21835, 32) * 32) == 31 && ltid_in_bounds_21850) {\n                        ((volatile __local bool *) red_arr_bool_mem_21839)[sext_i32_i64(squot32(local_tid_21835, 32))] = eta_p_20735;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n                {\n                    int32_t skip_threads_21854;\n                    \n                    // read input for in-block scan\n                    {\n                        if (squot32(local_tid_21835, 32) == 0 && ltid_in_bounds_21850) {\n                            eta_p_21848 = ((volatile __local bool *) red_arr_bool_mem_21839)[sext_i32_i64(local_tid_21835)];\n                            if ((local_tid_21835 - squot32(local_tid_21835, 32) * 32) == 0) {\n                                eta_p_21847 = eta_p_21848;\n                            }\n                        }\n                    }\n                    // in-block scan (hopefully no barriers needed)\n                    {\n                        skip_threads_21854 = 1;\n                        while (slt32(skip_threads_21854, 32)) {\n                            bool thread_active_21855 = sle32(skip_threads_21854, local_tid_21835 - squot32(local_tid_21835, 32) * 32) && (squot32(local_tid_21835, 32) == 0 && ltid_in_bounds_21850);\n                            \n                            if (thread_active_21855) {\n                               ", " // read operands\n                                {\n                                    eta_p_21847 = ((volatile __local bool *) red_arr_bool_mem_21839)[sext_i32_i64(local_tid_21835) - sext_i32_i64(skip_threads_21854)];\n                                }\n                            }\n                            // perform operation\n                            {\n                                bool inactive_21856 = slt64(srem64(sext_i32_i64(local_tid_21835 * 32 + 32 - 1), b_14236), sext_i32_i64(local_tid_21835 * 32 + 32 - 1) - sext_i32_i64((local_tid_21835 - skip_threads_21854) * 32 + 32 - 1));\n                                \n                                if (thread_active_21855 && inactive_21856) {\n                                    eta_p_21847 = eta_p_21848;\n                                }\n                                if (thread_active_21855) {\n                                    if (!inactive_21856) {\n                                        bool defunc_0_op_res_21849 = eta_p_21847 || eta_p_21848;\n                                        \n                                        eta_p_21847 = defunc_0_op_res_21849;\n                                    }\n                                }\n                            }\n                            if (sle32(wave_sizze_21837, skip_threads_21854)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            if (thread_active_21855) {\n                                // write result\n                                {\n                                    ((volatile __local bool *) red_arr_bool_mem_21839)[sext_i32_i64(local_tid_21835)] = eta_p_21847;\n                                    eta_p_21848 = eta_p_21847;\n                                }\n                            }\n                            if (sle32(wave_sizze_21837, skip_threads_21854)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                   ",
                                    "         skip_threads_21854 *= 2;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                \n                bool no_carry_in_21857 = squot32(local_tid_21835, 32) == 0 || !ltid_in_bounds_21850;\n                \n                // carry-in for every block except the first\n                {\n                    // read operands\n                    {\n                        if (!no_carry_in_21857) {\n                            eta_p_20736 = eta_p_20735;\n                            eta_p_20735 = ((__local bool *) red_arr_bool_mem_21839)[sext_i32_i64(squot32(local_tid_21835, 32)) - (int64_t) 1];\n                        }\n                    }\n                    // perform operation\n                    {\n                        bool inactive_21858 = slt64(srem64(sext_i32_i64(local_tid_21835), b_14236), sext_i32_i64(local_tid_21835) - sext_i32_i64(squot32(local_tid_21835, 32) * 32 - 1));\n                        \n                        if (!no_carry_in_21857) {\n                            if (inactive_21858) {\n                                eta_p_20735 = eta_p_20736;\n                            }\n                        }\n                        if (!no_carry_in_21857) {\n                            if (!inactive_21858) {\n                                bool defunc_0_op_res_20737 = eta_p_20735 || eta_p_20736;\n                                \n                                eta_p_20735 = defunc_0_op_res_20737;\n                            }\n                        }\n                    }\n                    // write final result\n                    {\n                        if (!no_carry_in_21857) {\n                            ((__local bool *) red_arr_bool_mem_21839)[sext_i32_i64(local_tid_21835)] = eta_p_20735;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // restore correct values for first block\n                {\n        ", "            if (squot32(local_tid_21835, 32) == 0 && ltid_in_bounds_21850) {\n                        ((__local bool *) red_arr_bool_mem_21839)[sext_i32_i64(local_tid_21835)] = eta_p_20736;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // save final values of segments\n        {\n            if (slt64(sext_i32_i64(virt_tblock_id_21844) * squot64(segred_tblock_sizze_20728, segment_sizze_nonzzero_21832) + sext_i32_i64(local_tid_21835), dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241) && slt64(sext_i32_i64(local_tid_21835), squot64(segred_tblock_sizze_20728, segment_sizze_nonzzero_21832))) {\n                bool tmp_21859 = ((__local bool *) red_arr_bool_mem_21839)[(sext_i32_i64(local_tid_21835) + (int64_t) 1) * segment_sizze_nonzzero_21832 - (int64_t) 1];\n                \n                ((__global bool *) mem_21302)[sext_i32_i64(virt_tblock_id_21844) * squot64(segred_tblock_sizze_20728, segment_sizze_nonzzero_21832) + sext_i32_i64(local_tid_21835)] = tmp_21859;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_3:\n    return;\n    #undef segred_tblock_sizze_20728\n}\nFUTHARK_KERNEL_SIZED(getPartitionBounds_8487zisegscan_20760_dim1, 1, 1)\nvoid getPartitionBounds_8487zisegscan_20760(__global int *global_failure, int64_t dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, int64_t num_tblocks_20756, int64_t num_virt_blocks_21919, int64_t num_virt_threads_21920, __global unsigned char *ext_mem_21339, __global unsigned char *mem_21344, __global unsigned char *status_flags_mem_21921, __global unsigned char *aggregates_mem_21923, __global unsigned char *incprefixes_mem_21925, __global unsigned char *global_dynid_mem_21927)\n{\n    #define segscan_tblock_sizze_20755 (getPartitionBounds_8487zisegscan_20760zisegscan_tblock_sizze_20755)\n    #define chunk_sizze_21918 (getPartitionBounds_8487zisegscan_20760zichunk_siz", "ze_21918)\n    \n    volatile __local unsigned char *local_mem_21937_backing_0 = &shared_mem[0];\n    const int64_t local_mem_21937_backing_0_offset = 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_20755), chunk_sizze_21918 * segscan_tblock_sizze_20755 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_20755), chunk_sizze_21918 * segscan_tblock_sizze_20755 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_21930;\n    int32_t tblock_sizze_21933;\n    int32_t wave_sizze_21932;\n    int32_t block_id_21931;\n    int32_t global_tid_21929;\n    int64_t phys_tid_20760;\n    int32_t chunk_sizze_32b_21934;\n    int64_t byte_offsets_21935;\n    int64_t warp_byte_offset_21936;\n    __local unsigned char *local_mem_21937;\n    int64_t trans_arr_len_21938;\n    int64_t phys_block_id_21944;\n    int64_t virtloop_bound_21945;\n    \n    local_tid_21930 = get_local_id(0);\n    tblock_sizze_21933 = get_local_size(0);\n    wave_sizze_21932 = LOCKSTEP_WIDTH;\n    block_id_21931 = get_tblock_id(0);\n    global_tid_21929 = block_id_21931 * tblock_sizze_21933 + local_tid_21930;\n    phys_tid_20760 = sext_i32_i64(global_tid_21929);\n    chunk_sizze_32b_21934 = sext_i64_i32(chunk_sizze_21918);\n    byte_offsets_21935 = segscan_tblock_sizze_20755 * (int64_t) 8;\n    warp_byte_offset_21936 = (int64_t) 288;\n    // Allocate reusable shared memory\n    { }\n    local_mem_21937 = (__local unsigned char *) local_mem_21937_backing_0;\n    trans_arr_len_21938 = chunk_sizze_21918 * segscan_tblock_sizze_20755;\n    phys_block_id_21944 = get_tblock_id(0);\n    virtloop_bound_21945 = sdiv_up64(num_virt_blocks_21919 - phys_block_id_21944, num_tblocks_20756);\n    for (int64_t virtloop_i_21946 = 0; virtloop_i_21946 < virtloop_bound_21945; virtloop_i_21946++) {\n        int64_t dynamic_id_21947;\n        int64_t block_offset_21948;\n        int64_t sgm_idx_21949;\n        int32_t boundary_",
                                    "21950;\n        int32_t segsizze_compact_21951;\n        int64_t private_mem_21952[chunk_sizze_21918];\n        int64_t thd_offset_21954;\n        int64_t acc_21970;\n        int64_t prefix_21980;\n        bool block_new_sgm_21981;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_21930 == 0) {\n                dynamic_id_21947 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_21927)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_21937)[(int64_t) 0] = dynamic_id_21947;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_21947 == num_virt_blocks_21919 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_21927)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_21947 = ((__local int32_t *) local_mem_21937)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_21948 = dynamic_id_21947 * chunk_sizze_21918 * segscan_tblock_sizze_20755;\n        sgm_idx_21949 = smod64(block_offset_21948, dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241);\n        boundary_21950 = sext_i64_i32(smin64(chunk_sizze_21918 * segscan_tblock_sizze_20755, dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241 - sgm_idx_21949));\n        segsizze_compact_21951 = sext_i64_i32(smin64(chunk_sizze_21918 * segscan_tblock_sizze_20755, dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241));\n        thd_offset_21954 = block_offset_21948 + sext_i32_i64(local_tid_21930);\n        // Load and map\n        {\n            for (int64_t i_21955 = 0; i_21955 < chunk_sizze_21918; i_21955++) {\n                int64_t virt_tid_21956 = thd_offset_21954 + i_21955 * segscan_tblock_sizze_20755;\n                int64_t slice_21957 = dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241;\n             ", "   int64_t gtid_20759 = virt_tid_21956;\n                int64_t remnant_21958 = virt_tid_21956 - gtid_20759;\n                \n                if (slt64(virt_tid_21956, dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241)) {\n                    int64_t x_20764 = ((__global int64_t *) ext_mem_21339)[gtid_20759];\n                    \n                    private_mem_21952[i_21955] = x_20764;\n                } else {\n                    private_mem_21952[i_21955] = (int64_t) 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_21959 = 0; i_21959 < chunk_sizze_21918; i_21959++) {\n                int64_t sharedIdx_21960 = sext_i32_i64(local_tid_21930) + i_21959 * segscan_tblock_sizze_20755;\n                int64_t tmp_21961 = private_mem_21952[i_21959];\n                \n                ((__local int64_t *) local_mem_21937)[sharedIdx_21960] = tmp_21961;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_21962 = 0; i_21962 < chunk_sizze_21918; i_21962++) {\n                int64_t sharedIdx_21963 = sext_i32_i64(local_tid_21930) * chunk_sizze_21918 + i_21962;\n                int64_t tmp_21964 = ((__local int64_t *) local_mem_21937)[sharedIdx_21963];\n                \n                private_mem_21952[i_21962] = tmp_21964;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_21965 = 0; i_21965 < chunk_sizze_21918 - (int64_t) 1; i_21965++) {\n                int64_t eta_p_20761;\n                int64_t eta_p_20762;\n                \n                eta_p_20761 = private_mem_21952[i_21965];\n                eta_p_20762 = private_mem_21952[i_21965 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_20763 = add64(eta_p_20761, eta_p_20762);\n                \n                private_mem_21952[i_21965 + (int64_t) 1] = defunc_0_op_res_20763;\n            }\n        }\n        // Publ", "ish results in shared memory\n        {\n            int64_t tmp_21966 = private_mem_21952[chunk_sizze_21918 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_21937)[sext_i32_i64(local_tid_21930)] = tmp_21966;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_21967;\n            int64_t eta_p_21968;\n            int64_t eta_p_21971;\n            int64_t eta_p_21972;\n            bool ltid_in_bounds_21974 = slt64(sext_i32_i64(local_tid_21930), num_virt_threads_21920);\n            int32_t skip_threads_21975;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_21974) {\n                    eta_p_21968 = ((volatile __local int64_t *) local_mem_21937)[sext_i32_i64(local_tid_21930)];\n                    if ((local_tid_21930 - squot32(local_tid_21930, 32) * 32) == 0) {\n                        eta_p_21967 = eta_p_21968;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_21975 = 1;\n                while (slt32(skip_threads_21975, 32)) {\n                    bool thread_active_21976 = sle32(skip_threads_21975, local_tid_21930 - squot32(local_tid_21930, 32) * 32) && ltid_in_bounds_21974;\n                    \n                    if (thread_active_21976) {\n                        // read operands\n                        {\n                            eta_p_21967 = ((volatile __local int64_t *) local_mem_21937)[sext_i32_i64(local_tid_21930) - sext_i32_i64(skip_threads_21975)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_21976) {\n                            int64_t defunc_0_op_res_21969 = add64(eta_p_21967, eta_p_21968);\n                            \n                            eta_p_21967 = defunc_0_op_res_21969;\n             ",
                                    "           }\n                    }\n                    if (sle32(wave_sizze_21932, skip_threads_21975)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_21976) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_21937)[sext_i32_i64(local_tid_21930)] = eta_p_21967;\n                            eta_p_21968 = eta_p_21967;\n                        }\n                    }\n                    if (sle32(wave_sizze_21932, skip_threads_21975)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_21975 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_21930 - squot32(local_tid_21930, 32) * 32) == 31 && ltid_in_bounds_21974) {\n                    ((volatile __local int64_t *) local_mem_21937)[sext_i32_i64(squot32(local_tid_21930, 32))] = eta_p_21967;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_21977;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_21930, 32) == 0 && ltid_in_bounds_21974) {\n                        eta_p_21972 = ((volatile __local int64_t *) local_mem_21937)[sext_i32_i64(local_tid_21930)];\n                        if ((local_tid_21930 - squot32(local_tid_21930, 32) * 32) == 0) {\n                            eta_p_21971 = eta_p_21972;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_21977 = 1;\n                    while (slt32(skip_threads_21", "977, 32)) {\n                        bool thread_active_21978 = sle32(skip_threads_21977, local_tid_21930 - squot32(local_tid_21930, 32) * 32) && (squot32(local_tid_21930, 32) == 0 && ltid_in_bounds_21974);\n                        \n                        if (thread_active_21978) {\n                            // read operands\n                            {\n                                eta_p_21971 = ((volatile __local int64_t *) local_mem_21937)[sext_i32_i64(local_tid_21930) - sext_i32_i64(skip_threads_21977)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_21978) {\n                                int64_t defunc_0_op_res_21973 = add64(eta_p_21971, eta_p_21972);\n                                \n                                eta_p_21971 = defunc_0_op_res_21973;\n                            }\n                        }\n                        if (sle32(wave_sizze_21932, skip_threads_21977)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_21978) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_21937)[sext_i32_i64(local_tid_21930)] = eta_p_21971;\n                                eta_p_21972 = eta_p_21971;\n                            }\n                        }\n                        if (sle32(wave_sizze_21932, skip_threads_21977)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_21977 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_21979 = squot32(local_tid_21930, 32) == 0 || !ltid_in_bounds_21974;\n            \n            // carry-in for every block except the first\n            {\n                // read ", "operands\n                {\n                    if (!no_carry_in_21979) {\n                        eta_p_21968 = eta_p_21967;\n                        eta_p_21967 = ((__local int64_t *) local_mem_21937)[sext_i32_i64(squot32(local_tid_21930, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_21979) {\n                        int64_t defunc_0_op_res_21969 = add64(eta_p_21967, eta_p_21968);\n                        \n                        eta_p_21967 = defunc_0_op_res_21969;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_21979) {\n                        ((__local int64_t *) local_mem_21937)[sext_i32_i64(local_tid_21930)] = eta_p_21967;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_21930, 32) == 0 && ltid_in_bounds_21974) {\n                    ((__local int64_t *) local_mem_21937)[sext_i32_i64(local_tid_21930)] = eta_p_21968;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_21930 == 0) {\n                acc_21970 = ((__local int64_t *) local_mem_21937)[segscan_tblock_sizze_20755 - (int64_t) 1];\n            } else {\n                acc_21970 = ((__local int64_t *) local_mem_21937)[sext_i32_i64(local_tid_21930) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_21980 = (int64_t) 0;\n        block_new_sgm_21981 = sgm_idx_21949 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_21981 && local_tid_21930 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_21925)[dynamic_id_21947] = acc_21970;\n                mem_fence_global();\n                ((volatile _",
                                    "_global int8_t *) status_flags_mem_21921)[dynamic_id_21947] = (int8_t) 2;\n                acc_21970 = (int64_t) 0;\n            }\n            if (!block_new_sgm_21981 && slt32(local_tid_21930, wave_sizze_21932)) {\n                if (local_tid_21930 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_21923)[dynamic_id_21947] = acc_21970;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_21921)[dynamic_id_21947] = (int8_t) 1;\n                    \n                    int8_t tmp_21982 = ((volatile __global int8_t *) status_flags_mem_21921)[dynamic_id_21947 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_21937)[(int64_t) 0] = tmp_21982;\n                }\n                mem_fence_local();\n                \n                int8_t status_21983 = ((__local int8_t *) local_mem_21937)[(int64_t) 0];\n                \n                if (status_21983 == (int8_t) 2) {\n                    if (local_tid_21930 == 0) {\n                        prefix_21980 = ((volatile __global int64_t *) incprefixes_mem_21925)[dynamic_id_21947 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_21984 = sext_i64_i32(dynamic_id_21947 - sext_i32_i64(wave_sizze_21932));\n                    \n                    while (slt32(wave_sizze_21932 * -1, readOffset_21984)) {\n                        int32_t read_i_21985 = readOffset_21984 + local_tid_21930;\n                        int64_t aggr_21986 = (int64_t) 0;\n                        int8_t flag_21987 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_21985)) {\n                            flag_21987 = ((volatile __global int8_t *) status_flags_mem_21921)[sext_i32_i64(read_i_21985)];\n                            if (flag_21987 == (int8_t) 2) {\n                                aggr_21986 = ((volatile __global int64_t *) incprefixes_mem_21925)[sext_i32_i64(read", "_i_21985)];\n                            } else if (flag_21987 == (int8_t) 1) {\n                                aggr_21986 = ((volatile __global int64_t *) aggregates_mem_21923)[sext_i32_i64(read_i_21985)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_21937)[(int64_t) 4 + sext_i32_i64(local_tid_21930)] = aggr_21986;\n                        ((__local int8_t *) local_mem_21937)[sext_i32_i64(local_tid_21930)] = flag_21987;\n                        flag_21987 = ((__local int8_t *) local_mem_21937)[sext_i32_i64(wave_sizze_21932) - (int64_t) 1];\n                        if (slt8(flag_21987, (int8_t) 2)) {\n                            int8_t flg_x_21991;\n                            int8_t flg_y_21992;\n                            int64_t eta_p_21988;\n                            int64_t eta_p_21989;\n                            int32_t skip_threads_21993;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_21992 = ((volatile __local int8_t *) local_mem_21937)[sext_i32_i64(local_tid_21930)];\n                                eta_p_21989 = ((volatile __local int64_t *) local_mem_21937)[(int64_t) 4 + sext_i32_i64(local_tid_21930)];\n                                if ((local_tid_21930 - squot32(local_tid_21930, 32) * 32) == 0) {\n                                    eta_p_21988 = eta_p_21989;\n                                    flg_x_21991 = flg_y_21992;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_21993 = 1;\n                                while (slt32(skip_threads_21993, 32)) {\n                                    if (sle32(skip_threads_21993, local_tid_21930 - squot32(local_tid_21930, 32) * 32)) {\n                                        // read operan", "ds\n                                        {\n                                            flg_x_21991 = ((volatile __local int8_t *) local_mem_21937)[sext_i32_i64(local_tid_21930) - sext_i32_i64(skip_threads_21993)];\n                                            eta_p_21988 = ((volatile __local int64_t *) local_mem_21937)[(int64_t) 4 + (sext_i32_i64(local_tid_21930) - sext_i32_i64(skip_threads_21993))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_21992 == (int8_t) 2 || flg_y_21992 == (int8_t) 0) {\n                                                flg_x_21991 = flg_y_21992;\n                                                eta_p_21988 = eta_p_21989;\n                                            } else {\n                                                int64_t defunc_0_op_res_21990 = add64(eta_p_21988, eta_p_21989);\n                                                \n                                                eta_p_21988 = defunc_0_op_res_21990;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_21937)[sext_i32_i64(local_tid_21930)] = flg_x_21991;\n                                            flg_y_21992 = flg_x_21991;\n                                            ((volatile __local int64_t *) local_mem_21937)[(int64_t) 4 + sext_i32_i64(local_tid_21930)] = eta_p_21988;\n                                            eta_p_21989 = eta_p_21988;\n                                        }\n                                    }\n                                    skip_threads_21993 *= 2;\n                                }\n                            }\n                        }\n                        flag_21987 = ((__local in",
                                    "t8_t *) local_mem_21937)[sext_i32_i64(wave_sizze_21932) - (int64_t) 1];\n                        aggr_21986 = ((__local int64_t *) local_mem_21937)[(int64_t) 4 + (sext_i32_i64(wave_sizze_21932) - (int64_t) 1)];\n                        if (flag_21987 == (int8_t) 2) {\n                            readOffset_21984 = wave_sizze_21932 * -1;\n                        } else if (flag_21987 == (int8_t) 1) {\n                            readOffset_21984 -= wave_sizze_21932;\n                        }\n                        if (slt8((int8_t) 0, flag_21987)) {\n                            int64_t eta_p_21994 = aggr_21986;\n                            int64_t eta_p_21995 = prefix_21980;\n                            int64_t defunc_0_op_res_21996 = add64(eta_p_21994, eta_p_21995);\n                            \n                            prefix_21980 = defunc_0_op_res_21996;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_21930 == 0) {\n                    if (boundary_21950 == sext_i64_i32(segscan_tblock_sizze_20755 * chunk_sizze_21918)) {\n                        int64_t eta_p_21997 = prefix_21980;\n                        int64_t eta_p_21998 = acc_21970;\n                        int64_t defunc_0_op_res_21999 = add64(eta_p_21997, eta_p_21998);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_21925)[dynamic_id_21947] = defunc_0_op_res_21999;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_21921)[dynamic_id_21947] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_21937)[(int64_t) 4] = prefix_21980;\n                    acc_21970 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_21947 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_21980 = ((__local int64_t *) local_mem_21937)[(int64_t) 4];\n ", "               barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_22000;\n            int64_t eta_p_22001;\n            int64_t eta_p_22003 = prefix_21980;\n            int64_t eta_p_22004 = acc_21970;\n            \n            if (slt32(local_tid_21930 * chunk_sizze_32b_21934, boundary_21950) && !block_new_sgm_21981) {\n                int64_t defunc_0_op_res_22005 = add64(eta_p_22003, eta_p_22004);\n                \n                eta_p_22000 = defunc_0_op_res_22005;\n            } else {\n                eta_p_22000 = acc_21970;\n            }\n            \n            int32_t stopping_point_22006 = segsizze_compact_21951 - srem32(local_tid_21930 * chunk_sizze_32b_21934 - 1 + segsizze_compact_21951 - boundary_21950, segsizze_compact_21951);\n            \n            for (int64_t i_22007 = 0; i_22007 < chunk_sizze_21918; i_22007++) {\n                if (slt32(sext_i64_i32(i_22007), stopping_point_22006 - 1)) {\n                    eta_p_22001 = private_mem_21952[i_22007];\n                    \n                    int64_t defunc_0_op_res_22002 = add64(eta_p_22000, eta_p_22001);\n                    \n                    private_mem_21952[i_22007] = defunc_0_op_res_22002;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_22008 = 0; i_22008 < chunk_sizze_21918; i_22008++) {\n                int64_t sharedIdx_22009 = sext_i32_i64(local_tid_21930) * chunk_sizze_21918 + i_22008;\n                int64_t tmp_22010 = private_mem_21952[i_22008];\n                \n                ((__local int64_t *) local_mem_21937)[sharedIdx_22009] = tmp_22010;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_22011 = 0; i_22011 < chunk_sizze_21918; i_22011++) {\n                int64_t flat_idx_22012 = thd_offset_21954 + i_22011 * segscan_tblock_sizze_20755;\n                int64_t slice_22013 ", "= dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241;\n                int64_t gtid_20759 = flat_idx_22012;\n                int64_t remnant_22014 = flat_idx_22012 - gtid_20759;\n                \n                if (slt64(flat_idx_22012, dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241)) {\n                    int64_t tmp_22015 = ((__local int64_t *) local_mem_21937)[flat_idx_22012 - block_offset_21948];\n                    \n                    ((__global int64_t *) mem_21344)[gtid_20759] = tmp_22015;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_20755\n    #undef chunk_sizze_21918\n}\nFUTHARK_KERNEL_SIZED(mainzigpuseq_21863_dim1, 1, 1)\nvoid mainzigpuseq_21863(__global int *global_failure, __global unsigned char *mem_param_21313, __global unsigned char *mem_21325, __global unsigned char *mem_21329)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_21865;\n    int32_t tblock_sizze_21868;\n    int32_t wave_sizze_21867;\n    int32_t block_id_21866;\n    int32_t global_tid_21864;\n    int64_t tid_21863;\n    int64_t acc0_21256;\n    int64_t offs_21259;\n    int64_t tmp_21261;\n    \n    local_tid_21865 = get_local_id(0);\n    tblock_sizze_21868 = get_local_size(0);\n    wave_sizze_21867 = LOCKSTEP_WIDTH;\n    block_id_21866 = get_tblock_id(0);\n    global_tid_21864 = block_id_21866 * tblock_sizze_21868 + local_tid_21865;\n    tid_21863 = sext_i32_i64(global_tid_21864);\n    acc0_21256 = ((__global int64_t *) mem_21325)[(int64_t) 0];\n    offs_21259 = ((__global int64_t *) mem_param_21313)[(int64_t) 0];\n    tmp_21261 = add64(acc0_21256, offs_21259);\n    ((__global int64_t *) mem_21329)[(int64_t) 0] = tmp_21261;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_20809_dim1, 1, 1)\nvoid mainzisegmap_20809(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, int32_t index_primexp_18738",
                                    ", int64_t distance_18747, int64_t ctx_param_ext_21298, __global unsigned char *mem_param_21301, __global unsigned char *mem_21310)\n{\n    #define segmap_tblock_sizze_20805 (mainzisegmap_20809zisegmap_tblock_sizze_20805)\n    \n    volatile __local int local_failure;\n    \n    // Harmless for all threads to write this.\n    local_failure = 0;\n    \n    int32_t local_tid_21666;\n    int32_t tblock_sizze_21669;\n    int32_t wave_sizze_21668;\n    int32_t block_id_21667;\n    int32_t global_tid_21665;\n    int64_t phys_tid_20809;\n    int64_t global_tid_21670;\n    int64_t slice_21671;\n    int64_t gtid_20808;\n    int64_t remnant_21672;\n    \n    local_tid_21666 = get_local_id(0);\n    tblock_sizze_21669 = get_local_size(0);\n    wave_sizze_21668 = LOCKSTEP_WIDTH;\n    block_id_21667 = get_tblock_id(0);\n    global_tid_21665 = block_id_21667 * tblock_sizze_21669 + local_tid_21666;\n    phys_tid_20809 = sext_i32_i64(global_tid_21665);\n    global_tid_21670 = sext_i32_i64(block_id_21667) * segmap_tblock_sizze_20805 + sext_i32_i64(local_tid_21666);\n    slice_21671 = dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685;\n    gtid_20808 = global_tid_21670;\n    remnant_21672 = global_tid_21670 - gtid_20808;\n    if (slt64(gtid_20808, dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685)) {\n        int8_t defunc_0_f_res_20811;\n        int8_t y_20813 = (int8_t) 0;\n        \n        for (int64_t i_20812 = 0; i_20812 < distance_18747; i_20812++) {\n            int32_t binop_x_20814;\n            int32_t get_bit_arg0_20815;\n            int32_t zm_rhs_20816;\n            int32_t zm_lhs_20817;\n            int32_t whichByte_20818;\n            int64_t whichByte_20820;\n            bool x_20821;\n            bool y_20822;\n            bool bounds_check_20823;\n            bool index_certs_20824;\n            int32_t whichBit_20819;\n            int8_t zbzg_lhs_20825;\n            int8_t unsign_arg0_20826;\n            int8_t unsign_arg0_20827;\n            int8_t unsign_arg0_20828;\n            int32_t to_i32_res_20829;\n   ", "         int8_t loopres_20830;\n            int8_t y_tmp_21673;\n            \n            binop_x_20814 = sext_i64_i32(i_20812);\n            get_bit_arg0_20815 = add32(index_primexp_18738, binop_x_20814);\n            zm_rhs_20816 = sdiv32(get_bit_arg0_20815, 8);\n            zm_lhs_20817 = sub32(2, zm_rhs_20816);\n            whichByte_20818 = sub32(zm_lhs_20817, 1);\n            whichByte_20820 = sext_i32_i64(whichByte_20818);\n            x_20821 = sle64((int64_t) 0, whichByte_20820);\n            y_20822 = slt64(whichByte_20820, (int64_t) 2);\n            bounds_check_20823 = x_20821 && y_20822;\n            if (!bounds_check_20823) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 0) == -1) {\n                        global_failure_args[0] = (int64_t) whichByte_20820;\n                        global_failure_args[1] = (int64_t) (int64_t) 2;\n                        ;\n                    }\n                    return;\n                }\n            }\n            whichBit_20819 = smod32(get_bit_arg0_20815, 8);\n            zbzg_lhs_20825 = ((__global int8_t *) mem_param_21301)[ctx_param_ext_21298 + (gtid_20808 * (int64_t) 2 + whichByte_20820)];\n            unsign_arg0_20826 = zext_i32_i8(whichBit_20819);\n            unsign_arg0_20827 = ashr8(zbzg_lhs_20825, unsign_arg0_20826);\n            unsign_arg0_20828 = (int8_t) 1 & unsign_arg0_20827;\n            to_i32_res_20829 = zext_i8_i32(unsign_arg0_20828);\n            futrts_set_bit_2464(&loopres_20830, binop_x_20814, y_20813, to_i32_res_20829);\n            y_tmp_21673 = loopres_20830;\n            y_20813 = y_tmp_21673;\n        }\n        defunc_0_f_res_20811 = y_20813;\n        ((__global int8_t *) mem_21310)[gtid_20808] = defunc_0_f_res_20811;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_20805\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_20872_dim1, 1, 1)\nvoid mainzisegmap_20872(__global int *global_failure, int64_t dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, __global unsigne", "d char *mem_param_21313, __global unsigned char *mem_param_21316, __global unsigned char *mem_21319, __global unsigned char *mem_21323, __global unsigned char *mem_21328)\n{\n    #define segmap_tblock_sizze_20868 (mainzisegmap_20872zisegmap_tblock_sizze_20868)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_21856;\n    int32_t tblock_sizze_21859;\n    int32_t wave_sizze_21858;\n    int32_t block_id_21857;\n    int32_t global_tid_21855;\n    int64_t phys_tid_20872;\n    int64_t global_tid_21860;\n    int64_t slice_21861;\n    int64_t gtid_20871;\n    int64_t remnant_21862;\n    \n    local_tid_21856 = get_local_id(0);\n    tblock_sizze_21859 = get_local_size(0);\n    wave_sizze_21858 = LOCKSTEP_WIDTH;\n    block_id_21857 = get_tblock_id(0);\n    global_tid_21855 = block_id_21857 * tblock_sizze_21859 + local_tid_21856;\n    phys_tid_20872 = sext_i32_i64(global_tid_21855);\n    global_tid_21860 = sext_i32_i64(block_id_21857) * segmap_tblock_sizze_20868 + sext_i32_i64(local_tid_21856);\n    slice_21861 = dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685;\n    gtid_20871 = global_tid_21860;\n    remnant_21862 = global_tid_21860 - gtid_20871;\n    if (slt64(gtid_20871, dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685)) {\n        int64_t offs_21258;\n        int64_t eta_p_20873;\n        int64_t eta_p_20874;\n        int64_t eta_p_20875;\n        int64_t zm_lhs_20877;\n        int64_t lifted_lambda_res_20878;\n        int64_t defunc_0_f_res_20879;\n        int64_t defunc_0_f_res_20880;\n        \n        offs_21258 = ((__global int64_t *) mem_param_21313)[(int64_t) 0];\n        eta_p_20873 = ((__global int64_t *) mem_21319)[gtid_20871];\n        eta_p_20874 = ((__global int64_t *) mem_21323)[gtid_20871];\n        eta_p_20875 = ((__global int64_t *) mem_param_21316)[gtid_20871];\n        zm_lhs_20877 = add64(eta_p_20873, offs_21258);\n        lifted_lambda_res_20878 = sub64(zm_lhs_20877, (int64_t) 1);\n        defunc_0_f_res_20879 = mul64(eta_p_20874, lifted_lambda_res_20878);\n    ",
                                    "    defunc_0_f_res_20880 = add64(eta_p_20875, defunc_0_f_res_20879);\n        ((__global int64_t *) mem_21328)[gtid_20871] = defunc_0_f_res_20880;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_20868\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_20905_dim1, 1, 1)\nvoid mainzisegmap_20905(__global int *global_failure, int64_t dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, int64_t lower_bound_18809, int64_t min_res_18811, __global unsigned char *ext_mem_21334, __global unsigned char *mem_21353, __global unsigned char *mem_21355)\n{\n    #define segmap_tblock_sizze_20900 (mainzisegmap_20905zisegmap_tblock_sizze_20900)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_21875;\n    int32_t tblock_sizze_21878;\n    int32_t wave_sizze_21877;\n    int32_t block_id_21876;\n    int32_t global_tid_21874;\n    int64_t phys_tid_20905;\n    int64_t global_tid_21879;\n    int64_t slice_21880;\n    int64_t gtid_20904;\n    int64_t remnant_21881;\n    \n    local_tid_21875 = get_local_id(0);\n    tblock_sizze_21878 = get_local_size(0);\n    wave_sizze_21877 = LOCKSTEP_WIDTH;\n    block_id_21876 = get_tblock_id(0);\n    global_tid_21874 = block_id_21876 * tblock_sizze_21878 + local_tid_21875;\n    phys_tid_20905 = sext_i32_i64(global_tid_21874);\n    global_tid_21879 = sext_i32_i64(block_id_21876) * segmap_tblock_sizze_20900 + sext_i32_i64(local_tid_21875);\n    slice_21880 = dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685;\n    gtid_20904 = global_tid_21879;\n    remnant_21881 = global_tid_21879 - gtid_20904;\n    if (slt64(gtid_20904, dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685)) {\n        int64_t eta_p_20906;\n        bool cond_20907;\n        bool cond_t_res_20908;\n        bool x_20909;\n        int64_t lifted_lambda_res_20910;\n        \n        eta_p_20906 = ((__global int64_t *) ext_mem_21334)[gtid_20904];\n        cond_20907 = sle64(lower_bound_18809, eta_p_20906);\n        cond_t_res_20908 = slt64(eta_p_20906, min_res_18811);\n        x_20909 = cond_20907 && c", "ond_t_res_20908;\n        if (x_20909) {\n            int64_t lifted_lambda_res_t_res_20911 = sub64(eta_p_20906, lower_bound_18809);\n            \n            lifted_lambda_res_20910 = lifted_lambda_res_t_res_20911;\n        } else {\n            lifted_lambda_res_20910 = (int64_t) -1;\n        }\n        ((__global int64_t *) mem_21353)[gtid_20904] = lifted_lambda_res_20910;\n        ((__global int64_t *) mem_21355)[gtid_20904] = lifted_lambda_res_20910;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_20900\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_20918_dim1, 1, 1)\nvoid mainzisegmap_20918(__global int *global_failure, int64_t dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, int64_t j_m_i_18812, int64_t num_tblocks_20924, int64_t ctx_param_ext_21298, int32_t virt_num_tblocks_21882, __global unsigned char *mem_param_21301, __global unsigned char *mem_21348, __global unsigned char *mem_21353)\n{\n    #define segmap_tblock_sizze_20922 (mainzisegmap_20918zisegmap_tblock_sizze_20922)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_21884;\n    int32_t tblock_sizze_21887;\n    int32_t wave_sizze_21886;\n    int32_t block_id_21885;\n    int32_t global_tid_21883;\n    int64_t phys_tid_20918;\n    int32_t phys_tblock_id_21888;\n    int32_t iterations_21889;\n    \n    local_tid_21884 = get_local_id(0);\n    tblock_sizze_21887 = get_local_size(0);\n    wave_sizze_21886 = LOCKSTEP_WIDTH;\n    block_id_21885 = get_tblock_id(0);\n    global_tid_21883 = block_id_21885 * tblock_sizze_21887 + local_tid_21884;\n    phys_tid_20918 = sext_i32_i64(global_tid_21883);\n    phys_tblock_id_21888 = get_tblock_id(0);\n    iterations_21889 = sdiv_up32(virt_num_tblocks_21882 - phys_tblock_id_21888, sext_i64_i32(num_tblocks_20924));\n    for (int32_t i_21890 = 0; i_21890 < iterations_21889; i_21890++) {\n        int32_t virt_tblock_id_21891;\n        int64_t global_tid_21892;\n        int64_t slice_21893;\n        int64_t slice_21894;\n        int64_t write_i_20914;\n        int64_t remn", "ant_21895;\n        int64_t val_i_20915;\n        int64_t remnant_21896;\n        \n        virt_tblock_id_21891 = phys_tblock_id_21888 + i_21890 * sext_i64_i32(num_tblocks_20924);\n        global_tid_21892 = sext_i32_i64(virt_tblock_id_21891) * segmap_tblock_sizze_20922 + sext_i32_i64(local_tid_21884);\n        slice_21893 = (int64_t) 2;\n        slice_21894 = dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685 * slice_21893;\n        write_i_20914 = squot64(global_tid_21892, slice_21893);\n        remnant_21895 = global_tid_21892 - write_i_20914 * slice_21893;\n        val_i_20915 = remnant_21895;\n        remnant_21896 = remnant_21895 - val_i_20915;\n        if (slt64(write_i_20914, dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685) && slt64(val_i_20915, (int64_t) 2)) {\n            int8_t scatter_tmp_elem_20916;\n            int64_t scatter_tmp_i_20917;\n            \n            scatter_tmp_elem_20916 = ((__global int8_t *) mem_param_21301)[ctx_param_ext_21298 + (write_i_20914 * (int64_t) 2 + val_i_20915)];\n            scatter_tmp_i_20917 = ((__global int64_t *) mem_21353)[write_i_20914];\n            if ((sle64((int64_t) 0, scatter_tmp_i_20917) && slt64(scatter_tmp_i_20917, j_m_i_18812)) && (sle64((int64_t) 0, val_i_20915) && slt64(val_i_20915, (int64_t) 2))) {\n                ((__global int8_t *) mem_21348)[scatter_tmp_i_20917 * (int64_t) 2 + val_i_20915] = scatter_tmp_elem_20916;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_20922\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_20929_dim1, 1, 1)\nvoid mainzisegmap_20929(__global int *global_failure, int64_t dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, int64_t j_m_i_18812, int64_t num_tblocks_20934, int64_t ctx_param_ext_21302, int32_t virt_num_tblocks_21897, __global unsigned char *mem_param_21304, __global unsigned char *mem_21350, __global unsigned char *mem_21355)\n{\n    #define segmap_tblock_sizze_20932 (mainzisegmap_20929",
                                    "zisegmap_tblock_sizze_20932)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_21899;\n    int32_t tblock_sizze_21902;\n    int32_t wave_sizze_21901;\n    int32_t block_id_21900;\n    int32_t global_tid_21898;\n    int64_t phys_tid_20929;\n    int32_t phys_tblock_id_21903;\n    int32_t iterations_21904;\n    \n    local_tid_21899 = get_local_id(0);\n    tblock_sizze_21902 = get_local_size(0);\n    wave_sizze_21901 = LOCKSTEP_WIDTH;\n    block_id_21900 = get_tblock_id(0);\n    global_tid_21898 = block_id_21900 * tblock_sizze_21902 + local_tid_21899;\n    phys_tid_20929 = sext_i32_i64(global_tid_21898);\n    phys_tblock_id_21903 = get_tblock_id(0);\n    iterations_21904 = sdiv_up32(virt_num_tblocks_21897 - phys_tblock_id_21903, sext_i64_i32(num_tblocks_20934));\n    for (int32_t i_21905 = 0; i_21905 < iterations_21904; i_21905++) {\n        int32_t virt_tblock_id_21906;\n        int64_t global_tid_21907;\n        int64_t slice_21908;\n        int64_t write_i_20926;\n        int64_t remnant_21909;\n        \n        virt_tblock_id_21906 = phys_tblock_id_21903 + i_21905 * sext_i64_i32(num_tblocks_20934);\n        global_tid_21907 = sext_i32_i64(virt_tblock_id_21906) * segmap_tblock_sizze_20932 + sext_i32_i64(local_tid_21899);\n        slice_21908 = dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685;\n        write_i_20926 = global_tid_21907;\n        remnant_21909 = global_tid_21907 - write_i_20926;\n        if (slt64(write_i_20926, dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685)) {\n            int64_t scatter_tmp_elem_20927;\n            int64_t scatter_tmp_i_20928;\n            \n            scatter_tmp_elem_20927 = ((__global int64_t *) mem_param_21304)[ctx_param_ext_21302 + write_i_20926];\n            scatter_tmp_i_20928 = ((__global int64_t *) mem_21355)[write_i_20926];\n            if (sle64((int64_t) 0, scatter_tmp_i_20928) && slt64(scatter_tmp_i_20928, j_m_i_18812)) {\n                ((__global int64_t *) mem_21350)[scatter_tmp_i_20928] = scatter_tmp_elem_20927;\n   ", "         }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_20932\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_20945_dim1, 1, 1)\nvoid mainzisegmap_20945(__global int *global_failure, int64_t deepen_step_res_18845, int64_t m_18890, int64_t num_tblocks_20950, int32_t virt_num_tblocks_22014, __global unsigned char *ext_mem_21376, __global unsigned char *mem_21379, __global unsigned char *mem_21381, __global unsigned char *mem_21383, __global unsigned char *mem_21385, __global unsigned char *mem_21387)\n{\n    #define segmap_tblock_sizze_20948 (mainzisegmap_20945zisegmap_tblock_sizze_20948)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_22016;\n    int32_t tblock_sizze_22019;\n    int32_t wave_sizze_22018;\n    int32_t block_id_22017;\n    int32_t global_tid_22015;\n    int64_t phys_tid_20945;\n    int32_t phys_tblock_id_22020;\n    int32_t iterations_22021;\n    \n    local_tid_22016 = get_local_id(0);\n    tblock_sizze_22019 = get_local_size(0);\n    wave_sizze_22018 = LOCKSTEP_WIDTH;\n    block_id_22017 = get_tblock_id(0);\n    global_tid_22015 = block_id_22017 * tblock_sizze_22019 + local_tid_22016;\n    phys_tid_20945 = sext_i32_i64(global_tid_22015);\n    phys_tblock_id_22020 = get_tblock_id(0);\n    iterations_22021 = sdiv_up32(virt_num_tblocks_22014 - phys_tblock_id_22020, sext_i64_i32(num_tblocks_20950));\n    for (int32_t i_22022 = 0; i_22022 < iterations_22021; i_22022++) {\n        int32_t virt_tblock_id_22023;\n        int64_t global_tid_22024;\n        int64_t slice_22025;\n        int64_t write_i_20944;\n        int64_t remnant_22026;\n        \n        virt_tblock_id_22023 = phys_tblock_id_22020 + i_22022 * sext_i64_i32(num_tblocks_20950);\n        global_tid_22024 = sext_i32_i64(virt_tblock_id_22023) * segmap_tblock_sizze_20948 + sext_i32_i64(local_tid_22016);\n        slice_22025 = deepen_step_res_18845;\n        write_i_20944 = global_tid_22024;\n        remnant_22026 = global_t", "id_22024 - write_i_20944;\n        if (slt64(write_i_20944, deepen_step_res_18845)) {\n            int64_t eta_p_19446;\n            int64_t write_value_19448;\n            int64_t write_value_19449;\n            bool cond_19450;\n            int64_t lifted_lambda_res_19451;\n            \n            eta_p_19446 = ((__global int64_t *) mem_21381)[write_i_20944];\n            write_value_19448 = ((__global int64_t *) ext_mem_21376)[write_i_20944];\n            write_value_19449 = ((__global int64_t *) mem_21383)[write_i_20944];\n            cond_19450 = eta_p_19446 == (int64_t) 1;\n            if (cond_19450) {\n                int64_t eta_p_19447;\n                int64_t lifted_lambda_res_t_res_19970;\n                \n                eta_p_19447 = ((__global int64_t *) mem_21379)[write_i_20944];\n                lifted_lambda_res_t_res_19970 = sub64(eta_p_19447, (int64_t) 1);\n                lifted_lambda_res_19451 = lifted_lambda_res_t_res_19970;\n            } else {\n                lifted_lambda_res_19451 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_19451) && slt64(lifted_lambda_res_19451, m_18890)) {\n                ((__global int64_t *) mem_21387)[lifted_lambda_res_19451] = write_value_19448;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_19451) && slt64(lifted_lambda_res_19451, m_18890)) {\n                ((__global int64_t *) mem_21385)[lifted_lambda_res_19451] = write_value_19449;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_20948\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_20970_dim1, 1, 1)\nvoid mainzisegmap_20970(__global int *global_failure, int64_t loop_dz2081Uz2089U_18678, int64_t bounds_18683, int64_t m_18890, __global unsigned char *mem_21385, __global unsigned char *mem_21387, __global unsigned char *mem_21397, __global unsigned char *mem_21399)\n{\n    #define segmap_tblock_sizze_20965 (mainzisegmap_20970zisegmap",
                                    "_tblock_sizze_20965)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_22029;\n    int32_t tblock_sizze_22032;\n    int32_t wave_sizze_22031;\n    int32_t block_id_22030;\n    int32_t global_tid_22028;\n    int64_t phys_tid_20970;\n    int64_t global_tid_22033;\n    int64_t slice_22034;\n    int64_t gtid_20969;\n    int64_t remnant_22035;\n    \n    local_tid_22029 = get_local_id(0);\n    tblock_sizze_22032 = get_local_size(0);\n    wave_sizze_22031 = LOCKSTEP_WIDTH;\n    block_id_22030 = get_tblock_id(0);\n    global_tid_22028 = block_id_22030 * tblock_sizze_22032 + local_tid_22029;\n    phys_tid_20970 = sext_i32_i64(global_tid_22028);\n    global_tid_22033 = sext_i32_i64(block_id_22030) * segmap_tblock_sizze_20965 + sext_i32_i64(local_tid_22029);\n    slice_22034 = m_18890;\n    gtid_20969 = global_tid_22033;\n    remnant_22035 = global_tid_22033 - gtid_20969;\n    if (slt64(gtid_20969, m_18890)) {\n        int64_t eta_p_20971;\n        int64_t eta_p_20972;\n        int64_t tmp_20973;\n        int64_t tmp_20974;\n        \n        eta_p_20971 = ((__global int64_t *) mem_21387)[gtid_20969];\n        eta_p_20972 = ((__global int64_t *) mem_21385)[gtid_20969];\n        tmp_20973 = add64(bounds_18683, eta_p_20971);\n        tmp_20974 = add64(bounds_18683, eta_p_20972);\n        ((__global int64_t *) mem_21397)[loop_dz2081Uz2089U_18678 + gtid_20969] = tmp_20973;\n        ((__global int64_t *) mem_21399)[loop_dz2081Uz2089U_18678 + gtid_20969] = tmp_20974;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_20965\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_20984_dim1, 1, 1)\nvoid mainzisegmap_20984(__global int *global_failure, int64_t loop_dz2088U_18952, int64_t m_18998, int64_t num_tblocks_20989, int32_t virt_num_tblocks_22152, __global unsigned char *mem_param_21432, __global unsigned char *mem_21438, __global unsigned char *mem_21440, __global unsigned char *mem_21442, __global unsigned char *mem_21444, __global unsigned char *mem_21446, __global unsigned char *mem_21448)", "\n{\n    #define segmap_tblock_sizze_20987 (mainzisegmap_20984zisegmap_tblock_sizze_20987)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_22154;\n    int32_t tblock_sizze_22157;\n    int32_t wave_sizze_22156;\n    int32_t block_id_22155;\n    int32_t global_tid_22153;\n    int64_t phys_tid_20984;\n    int32_t phys_tblock_id_22158;\n    int32_t iterations_22159;\n    \n    local_tid_22154 = get_local_id(0);\n    tblock_sizze_22157 = get_local_size(0);\n    wave_sizze_22156 = LOCKSTEP_WIDTH;\n    block_id_22155 = get_tblock_id(0);\n    global_tid_22153 = block_id_22155 * tblock_sizze_22157 + local_tid_22154;\n    phys_tid_20984 = sext_i32_i64(global_tid_22153);\n    phys_tblock_id_22158 = get_tblock_id(0);\n    iterations_22159 = sdiv_up32(virt_num_tblocks_22152 - phys_tblock_id_22158, sext_i64_i32(num_tblocks_20989));\n    for (int32_t i_22160 = 0; i_22160 < iterations_22159; i_22160++) {\n        int32_t virt_tblock_id_22161;\n        int64_t global_tid_22162;\n        int64_t slice_22163;\n        int64_t write_i_20983;\n        int64_t remnant_22164;\n        \n        virt_tblock_id_22161 = phys_tblock_id_22158 + i_22160 * sext_i64_i32(num_tblocks_20989);\n        global_tid_22162 = sext_i32_i64(virt_tblock_id_22161) * segmap_tblock_sizze_20987 + sext_i32_i64(local_tid_22154);\n        slice_22163 = loop_dz2088U_18952;\n        write_i_20983 = global_tid_22162;\n        remnant_22164 = global_tid_22162 - write_i_20983;\n        if (slt64(write_i_20983, loop_dz2088U_18952)) {\n            int64_t eta_p_19855;\n            int64_t write_value_19857;\n            int64_t write_value_19858;\n            bool cond_19860;\n            int64_t lifted_lambda_res_19861;\n            \n            eta_p_19855 = ((__global int64_t *) mem_21440)[write_i_20983];\n            write_value_19857 = ((__global int64_t *) mem_param_21432)[write_i_20983];\n            write_value_19858 = ((__global int64_t *) mem_21442)[write_i_20983];\n            cond_19860 = eta_p_19855 == (int64_t) 1;\n        ", "    if (cond_19860) {\n                int64_t eta_p_19856;\n                int64_t lifted_lambda_res_t_res_19986;\n                \n                eta_p_19856 = ((__global int64_t *) mem_21438)[write_i_20983];\n                lifted_lambda_res_t_res_19986 = sub64(eta_p_19856, (int64_t) 1);\n                lifted_lambda_res_19861 = lifted_lambda_res_t_res_19986;\n            } else {\n                lifted_lambda_res_19861 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_19861) && slt64(lifted_lambda_res_19861, m_18998)) {\n                ((__global int64_t *) mem_21448)[lifted_lambda_res_19861] = write_value_19857;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_19861) && slt64(lifted_lambda_res_19861, m_18998)) {\n                ((__global int64_t *) mem_21446)[lifted_lambda_res_19861] = write_value_19858;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_19861) && slt64(lifted_lambda_res_19861, m_18998)) {\n                ((__global int64_t *) mem_21444)[lifted_lambda_res_19861] = write_i_20983;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_20987\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_21006_dim1, 1, 1)\nvoid mainzisegmap_21006(__global int *global_failure, int64_t bounds_19047, int64_t bounds_19049, int64_t loopres_19064, __global unsigned char *ext_mem_21460, __global unsigned char *mem_21465)\n{\n    #define segmap_tblock_sizze_21002 (mainzisegmap_21006zisegmap_tblock_sizze_21002)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_22176;\n    int32_t tblock_sizze_22179;\n    int32_t wave_sizze_22178;\n    int32_t block_id_22177;\n    int32_t global_tid_22175;\n    int64_t phys_tid_21006;\n    int64_t global_tid_22180;\n    int64_t slice_22181;\n    int64_t gtid_21005;\n    int64_t remnant_22182;\n    \n    local_tid_22176 = get_local_id(0);\n    tblock_sizze_22179 = get_local_size(0);\n   ",
                                    " wave_sizze_22178 = LOCKSTEP_WIDTH;\n    block_id_22177 = get_tblock_id(0);\n    global_tid_22175 = block_id_22177 * tblock_sizze_22179 + local_tid_22176;\n    phys_tid_21006 = sext_i32_i64(global_tid_22175);\n    global_tid_22180 = sext_i32_i64(block_id_22177) * segmap_tblock_sizze_21002 + sext_i32_i64(local_tid_22176);\n    slice_22181 = loopres_19064;\n    gtid_21005 = global_tid_22180;\n    remnant_22182 = global_tid_22180 - gtid_21005;\n    if (slt64(gtid_21005, loopres_19064)) {\n        int64_t eta_p_21007;\n        int64_t lifted_lambda_res_21008;\n        \n        eta_p_21007 = ((__global int64_t *) ext_mem_21460)[gtid_21005];\n        lifted_lambda_res_21008 = add64(bounds_19047, eta_p_21007);\n        ((__global int64_t *) mem_21465)[bounds_19049 + gtid_21005] = lifted_lambda_res_21008;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_21002\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_21047_dim1, 1, 1)\nvoid mainzisegmap_21047(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t calc_partitions_from_partitioned_set_res_18944, int64_t distance_19133, __global unsigned char *ext_mem_21424, __global unsigned char *ext_mem_21479, __global unsigned char *mem_21482)\n{\n    #define segmap_tblock_sizze_21043 (mainzisegmap_21047zisegmap_tblock_sizze_21043)\n    \n    volatile __local int local_failure;\n    \n    // Harmless for all threads to write this.\n    local_failure = 0;\n    \n    int32_t local_tid_22187;\n    int32_t tblock_sizze_22190;\n    int32_t wave_sizze_22189;\n    int32_t block_id_22188;\n    int32_t global_tid_22186;\n    int64_t phys_tid_21047;\n    int64_t global_tid_22191;\n    int64_t slice_22192;\n    int64_t gtid_21046;\n    int64_t remnant_22193;\n    \n    local_tid_22187 = get_local_id(0);\n    tblock_sizze_22190 = get_local_size(0);\n    wave_sizze_22189 = LOCKSTEP_WIDTH;\n    block_id_22188 = get_tblock_id(0);\n    global_tid_22186 = block_id_22188 * tblock_sizze_22190 + local_tid_22187;\n    phys_tid_21047 = sext_i", "32_i64(global_tid_22186);\n    global_tid_22191 = sext_i32_i64(block_id_22188) * segmap_tblock_sizze_21043 + sext_i32_i64(local_tid_22187);\n    slice_22192 = calc_partitions_from_partitioned_set_res_18944;\n    gtid_21046 = global_tid_22191;\n    remnant_22193 = global_tid_22191 - gtid_21046;\n    if (slt64(gtid_21046, calc_partitions_from_partitioned_set_res_18944)) {\n        int64_t eta_p_21048;\n        bool x_21049;\n        bool y_21050;\n        bool bounds_check_21051;\n        bool index_certs_21052;\n        int8_t defunc_0_get_radix_res_21053;\n        int8_t y_21055;\n        int64_t u8_res_21072;\n        \n        eta_p_21048 = ((__global int64_t *) ext_mem_21479)[gtid_21046];\n        x_21049 = sle64((int64_t) 0, eta_p_21048);\n        y_21050 = slt64(eta_p_21048, (int64_t) 8);\n        bounds_check_21051 = x_21049 && y_21050;\n        if (!bounds_check_21051) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 3) == -1) {\n                    global_failure_args[0] = (int64_t) eta_p_21048;\n                    global_failure_args[1] = (int64_t) (int64_t) 8;\n                    ;\n                }\n                return;\n            }\n        }\n        y_21055 = (int8_t) 0;\n        for (int64_t i_21054 = 0; i_21054 < distance_19133; i_21054++) {\n            int32_t binop_x_21056;\n            int32_t zm_rhs_21057;\n            int32_t zm_lhs_21058;\n            int32_t whichByte_21059;\n            int64_t whichByte_21061;\n            bool x_21062;\n            bool y_21063;\n            bool bounds_check_21064;\n            bool index_certs_21065;\n            int32_t whichBit_21060;\n            int8_t zbzg_lhs_21066;\n            int8_t unsign_arg0_21067;\n            int8_t unsign_arg0_21068;\n            int8_t unsign_arg0_21069;\n            int32_t to_i32_res_21070;\n            int8_t loopres_21071;\n            int8_t y_tmp_22194;\n            \n            binop_x_21056 = sext_i64_i32(i_21054);\n            zm_rhs_21057 = sdiv32(binop_x_21056, 8);\n ", "           zm_lhs_21058 = sub32(2, zm_rhs_21057);\n            whichByte_21059 = sub32(zm_lhs_21058, 1);\n            whichByte_21061 = sext_i32_i64(whichByte_21059);\n            x_21062 = sle64((int64_t) 0, whichByte_21061);\n            y_21063 = slt64(whichByte_21061, (int64_t) 2);\n            bounds_check_21064 = x_21062 && y_21063;\n            if (!bounds_check_21064) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 4) == -1) {\n                        global_failure_args[0] = (int64_t) whichByte_21061;\n                        global_failure_args[1] = (int64_t) (int64_t) 2;\n                        ;\n                    }\n                    return;\n                }\n            }\n            whichBit_21060 = smod32(binop_x_21056, 8);\n            zbzg_lhs_21066 = ((__global int8_t *) ext_mem_21424)[eta_p_21048 * (int64_t) 2 + whichByte_21061];\n            unsign_arg0_21067 = zext_i32_i8(whichBit_21060);\n            unsign_arg0_21068 = ashr8(zbzg_lhs_21066, unsign_arg0_21067);\n            unsign_arg0_21069 = (int8_t) 1 & unsign_arg0_21068;\n            to_i32_res_21070 = zext_i8_i32(unsign_arg0_21069);\n            futrts_set_bit_2464(&loopres_21071, binop_x_21056, y_21055, to_i32_res_21070);\n            y_tmp_22194 = loopres_21071;\n            y_21055 = y_tmp_22194;\n        }\n        defunc_0_get_radix_res_21053 = y_21055;\n        u8_res_21072 = zext_i8_i64(defunc_0_get_radix_res_21053);\n        ((__global int64_t *) mem_21482)[gtid_21046] = u8_res_21072;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_21043\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_21113_dim1, 1, 1)\nvoid mainzisegmap_21113(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t calc_partitions_from_partitioned_set_res_18944, int64_t zeze_rhs_19157, __global unsigned char *mem_21482, __global unsigned char *mem_21484, __global unsigned char *mem_21485)\n{\n    #define segmap_tblock_sizze_21108 (mainzisegma",
                                    "p_21113zisegmap_tblock_sizze_21108)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_22217;\n    int32_t tblock_sizze_22220;\n    int32_t wave_sizze_22219;\n    int32_t block_id_22218;\n    int32_t global_tid_22216;\n    int64_t phys_tid_21113;\n    int64_t global_tid_22221;\n    int64_t slice_22222;\n    int64_t gtid_21112;\n    int64_t remnant_22223;\n    \n    local_tid_22217 = get_local_id(0);\n    tblock_sizze_22220 = get_local_size(0);\n    wave_sizze_22219 = LOCKSTEP_WIDTH;\n    block_id_22218 = get_tblock_id(0);\n    global_tid_22216 = block_id_22218 * tblock_sizze_22220 + local_tid_22217;\n    phys_tid_21113 = sext_i32_i64(global_tid_22216);\n    global_tid_22221 = sext_i32_i64(block_id_22218) * segmap_tblock_sizze_21108 + sext_i32_i64(local_tid_22217);\n    slice_22222 = calc_partitions_from_partitioned_set_res_18944;\n    gtid_21112 = global_tid_22221;\n    remnant_22223 = global_tid_22221 - gtid_21112;\n    if (slt64(gtid_21112, calc_partitions_from_partitioned_set_res_18944)) {\n        int64_t cur_i_21119;\n        bool cond_21120;\n        int64_t pre_i_21121;\n        bool cond_21128;\n        bool x_21129;\n        bool cond_21130;\n        int64_t pos_i_21131;\n        bool cond_21138;\n        bool x_21139;\n        \n        cur_i_21119 = ((__global int64_t *) mem_21482)[gtid_21112];\n        cond_21120 = gtid_21112 == (int64_t) 0;\n        if (cond_21120) {\n            pre_i_21121 = (int64_t) -1;\n        } else {\n            int64_t tmp_21122;\n            bool x_21123;\n            bool y_21124;\n            bool bounds_check_21125;\n            bool index_certs_21126;\n            int64_t pre_i_f_res_21127;\n            \n            tmp_21122 = sub64(gtid_21112, (int64_t) 1);\n            x_21123 = sle64((int64_t) 0, tmp_21122);\n            y_21124 = slt64(tmp_21122, calc_partitions_from_partitioned_set_res_18944);\n            bounds_check_21125 = x_21123 && y_21124;\n            if (!bounds_check_21125) {\n                {\n                    if (atomic_cmpxch", "g_i32_global(global_failure, -1, 5) == -1) {\n                        global_failure_args[0] = (int64_t) tmp_21122;\n                        global_failure_args[1] = (int64_t) calc_partitions_from_partitioned_set_res_18944;\n                        ;\n                    }\n                    return;\n                }\n            }\n            pre_i_f_res_21127 = ((__global int64_t *) mem_21482)[tmp_21122];\n            pre_i_21121 = pre_i_f_res_21127;\n        }\n        cond_21128 = cur_i_21119 == pre_i_21121;\n        x_21129 = !cond_21128;\n        cond_21130 = gtid_21112 == zeze_rhs_19157;\n        if (cond_21130) {\n            pos_i_21131 = (int64_t) -1;\n        } else {\n            int64_t tmp_21132;\n            bool x_21133;\n            bool y_21134;\n            bool bounds_check_21135;\n            bool index_certs_21136;\n            int64_t pos_i_f_res_21137;\n            \n            tmp_21132 = add64((int64_t) 1, gtid_21112);\n            x_21133 = sle64((int64_t) 0, tmp_21132);\n            y_21134 = slt64(tmp_21132, calc_partitions_from_partitioned_set_res_18944);\n            bounds_check_21135 = x_21133 && y_21134;\n            if (!bounds_check_21135) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 6) == -1) {\n                        global_failure_args[0] = (int64_t) tmp_21132;\n                        global_failure_args[1] = (int64_t) calc_partitions_from_partitioned_set_res_18944;\n                        ;\n                    }\n                    return;\n                }\n            }\n            pos_i_f_res_21137 = ((__global int64_t *) mem_21482)[tmp_21132];\n            pos_i_21131 = pos_i_f_res_21137;\n        }\n        cond_21138 = cur_i_21119 == pos_i_21131;\n        x_21139 = !cond_21138;\n        ((__global bool *) mem_21484)[gtid_21112] = x_21129;\n        ((__global bool *) mem_21485)[gtid_21112] = x_21139;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_21108\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_2", "1161_dim1, 1, 1)\nvoid mainzisegmap_21161(__global int *global_failure, int64_t calc_partitions_from_partitioned_set_res_18944, __global unsigned char *mem_21482, __global unsigned char *ext_mem_21488, __global unsigned char *mem_21491)\n{\n    #define segmap_tblock_sizze_21157 (mainzisegmap_21161zisegmap_tblock_sizze_21157)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_22226;\n    int32_t tblock_sizze_22229;\n    int32_t wave_sizze_22228;\n    int32_t block_id_22227;\n    int32_t global_tid_22225;\n    int64_t phys_tid_21161;\n    int64_t global_tid_22230;\n    int64_t slice_22231;\n    int64_t gtid_21160;\n    int64_t remnant_22232;\n    \n    local_tid_22226 = get_local_id(0);\n    tblock_sizze_22229 = get_local_size(0);\n    wave_sizze_22228 = LOCKSTEP_WIDTH;\n    block_id_22227 = get_tblock_id(0);\n    global_tid_22225 = block_id_22227 * tblock_sizze_22229 + local_tid_22226;\n    phys_tid_21161 = sext_i32_i64(global_tid_22225);\n    global_tid_22230 = sext_i32_i64(block_id_22227) * segmap_tblock_sizze_21157 + sext_i32_i64(local_tid_22226);\n    slice_22231 = calc_partitions_from_partitioned_set_res_18944;\n    gtid_21160 = global_tid_22230;\n    remnant_22232 = global_tid_22230 - gtid_21160;\n    if (slt64(gtid_21160, calc_partitions_from_partitioned_set_res_18944)) {\n        bool eta_p_21162;\n        int64_t lifted_lambda_res_21164;\n        \n        eta_p_21162 = ((__global bool *) ext_mem_21488)[gtid_21160];\n        if (eta_p_21162) {\n            int64_t lifted_lambda_res_t_res_21169 = ((__global int64_t *) mem_21482)[gtid_21160];\n            \n            lifted_lambda_res_21164 = lifted_lambda_res_t_res_21169;\n        } else {\n            lifted_lambda_res_21164 = (int64_t) -1;\n        }\n        ((__global int64_t *) mem_21491)[gtid_21160] = lifted_lambda_res_21164;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_21157\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_21171_dim1, 1, 1)\nvoid mainzisegmap_21171(__global int *global_failure, int64_t calc_",
                                    "partitions_from_partitioned_set_res_18944, int64_t lower_bound_19207, int64_t min_res_19209, int64_t j_m_i_19210, int64_t num_tblocks_21176, int32_t virt_num_tblocks_22237, __global unsigned char *ext_mem_21479, __global unsigned char *mem_21491, __global unsigned char *mem_21498)\n{\n    #define segmap_tblock_sizze_21174 (mainzisegmap_21171zisegmap_tblock_sizze_21174)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_22239;\n    int32_t tblock_sizze_22242;\n    int32_t wave_sizze_22241;\n    int32_t block_id_22240;\n    int32_t global_tid_22238;\n    int64_t phys_tid_21171;\n    int32_t phys_tblock_id_22243;\n    int32_t iterations_22244;\n    \n    local_tid_22239 = get_local_id(0);\n    tblock_sizze_22242 = get_local_size(0);\n    wave_sizze_22241 = LOCKSTEP_WIDTH;\n    block_id_22240 = get_tblock_id(0);\n    global_tid_22238 = block_id_22240 * tblock_sizze_22242 + local_tid_22239;\n    phys_tid_21171 = sext_i32_i64(global_tid_22238);\n    phys_tblock_id_22243 = get_tblock_id(0);\n    iterations_22244 = sdiv_up32(virt_num_tblocks_22237 - phys_tblock_id_22243, sext_i64_i32(num_tblocks_21176));\n    for (int32_t i_22245 = 0; i_22245 < iterations_22244; i_22245++) {\n        int32_t virt_tblock_id_22246;\n        int64_t global_tid_22247;\n        int64_t slice_22248;\n        int64_t write_i_21170;\n        int64_t remnant_22249;\n        \n        virt_tblock_id_22246 = phys_tblock_id_22243 + i_22245 * sext_i64_i32(num_tblocks_21176);\n        global_tid_22247 = sext_i32_i64(virt_tblock_id_22246) * segmap_tblock_sizze_21174 + sext_i32_i64(local_tid_22239);\n        slice_22248 = calc_partitions_from_partitioned_set_res_18944;\n        write_i_21170 = global_tid_22247;\n        remnant_22249 = global_tid_22247 - write_i_21170;\n        if (slt64(write_i_21170, calc_partitions_from_partitioned_set_res_18944)) {\n            int64_t eta_p_19927;\n            int64_t write_value_19928;\n            bool cond_19929;\n            bool cond_t_res_19930;\n            bool x_19931;\n   ", "         int64_t lifted_lambda_res_19932;\n            \n            eta_p_19927 = ((__global int64_t *) mem_21491)[write_i_21170];\n            write_value_19928 = ((__global int64_t *) ext_mem_21479)[write_i_21170];\n            cond_19929 = sle64(lower_bound_19207, eta_p_19927);\n            cond_t_res_19930 = slt64(eta_p_19927, min_res_19209);\n            x_19931 = cond_19929 && cond_t_res_19930;\n            if (x_19931) {\n                int64_t lifted_lambda_res_t_res_20003 = sub64(eta_p_19927, lower_bound_19207);\n                \n                lifted_lambda_res_19932 = lifted_lambda_res_t_res_20003;\n            } else {\n                lifted_lambda_res_19932 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_19932) && slt64(lifted_lambda_res_19932, j_m_i_19210)) {\n                ((__global int64_t *) mem_21498)[lifted_lambda_res_19932] = write_value_19928;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_21174\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_21179_dim1, 1, 1)\nvoid mainzisegmap_21179(__global int *global_failure, int64_t calc_partitions_from_partitioned_set_res_18944, int64_t lower_bound_19248, int64_t min_res_19250, int64_t j_m_i_19251, int64_t num_tblocks_21184, int32_t virt_num_tblocks_22255, __global unsigned char *ext_mem_21487, __global unsigned char *ext_mem_21488, __global unsigned char *mem_21491, __global unsigned char *mem_21503, __global unsigned char *mem_21512)\n{\n    #define segmap_tblock_sizze_21182 (mainzisegmap_21179zisegmap_tblock_sizze_21182)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_22257;\n    int32_t tblock_sizze_22260;\n    int32_t wave_sizze_22259;\n    int32_t block_id_22258;\n    int32_t global_tid_22256;\n    int64_t phys_tid_21179;\n    int32_t phys_tblock_id_22261;\n    int32_t iterations_22262;\n    \n    local_tid_22257 = get_local_id(0);\n    tblock_sizze_22260 = get_local_s", "ize(0);\n    wave_sizze_22259 = LOCKSTEP_WIDTH;\n    block_id_22258 = get_tblock_id(0);\n    global_tid_22256 = block_id_22258 * tblock_sizze_22260 + local_tid_22257;\n    phys_tid_21179 = sext_i32_i64(global_tid_22256);\n    phys_tblock_id_22261 = get_tblock_id(0);\n    iterations_22262 = sdiv_up32(virt_num_tblocks_22255 - phys_tblock_id_22261, sext_i64_i32(num_tblocks_21184));\n    for (int32_t i_22263 = 0; i_22263 < iterations_22262; i_22263++) {\n        int32_t virt_tblock_id_22264;\n        int64_t global_tid_22265;\n        int64_t slice_22266;\n        int64_t write_i_21178;\n        int64_t remnant_22267;\n        \n        virt_tblock_id_22264 = phys_tblock_id_22261 + i_22263 * sext_i64_i32(num_tblocks_21184);\n        global_tid_22265 = sext_i32_i64(virt_tblock_id_22264) * segmap_tblock_sizze_21182 + sext_i32_i64(local_tid_22257);\n        slice_22266 = calc_partitions_from_partitioned_set_res_18944;\n        write_i_21178 = global_tid_22265;\n        remnant_22267 = global_tid_22265 - write_i_21178;\n        if (slt64(write_i_21178, calc_partitions_from_partitioned_set_res_18944)) {\n            int64_t eta_p_19939;\n            bool write_value_19940;\n            bool write_value_19941;\n            bool cond_19942;\n            bool cond_t_res_19943;\n            bool x_19944;\n            int64_t lifted_lambda_res_19945;\n            \n            eta_p_19939 = ((__global int64_t *) mem_21491)[write_i_21178];\n            write_value_19940 = ((__global bool *) ext_mem_21488)[write_i_21178];\n            write_value_19941 = ((__global bool *) ext_mem_21487)[write_i_21178];\n            cond_19942 = sle64(lower_bound_19248, eta_p_19939);\n            cond_t_res_19943 = slt64(eta_p_19939, min_res_19250);\n            x_19944 = cond_19942 && cond_t_res_19943;\n            if (x_19944) {\n                int64_t lifted_lambda_res_t_res_20005 = sub64(eta_p_19939, lower_bound_19248);\n                \n                lifted_lambda_res_19945 = lifted_lambda_res_t_res_20005;\n            } else ",
                                    "{\n                lifted_lambda_res_19945 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_19945) && slt64(lifted_lambda_res_19945, j_m_i_19251)) {\n                ((__global bool *) mem_21503)[lower_bound_19248 + lifted_lambda_res_19945] = write_value_19940;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_19945) && slt64(lifted_lambda_res_19945, j_m_i_19251)) {\n                ((__global bool *) mem_21512)[lifted_lambda_res_19945] = write_value_19941;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_21182\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_21203_dim1, 1, 1)\nvoid mainzisegmap_21203(__global int *global_failure, int64_t dzlz7bUZLztztZRz20U2z20Ursz7dUzg_19129, __global unsigned char *mem_21503, __global unsigned char *mem_21504, __global unsigned char *mem_21521)\n{\n    #define segmap_tblock_sizze_21199 (mainzisegmap_21203zisegmap_tblock_sizze_21199)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_22270;\n    int32_t tblock_sizze_22273;\n    int32_t wave_sizze_22272;\n    int32_t block_id_22271;\n    int32_t global_tid_22269;\n    int64_t phys_tid_21203;\n    int64_t global_tid_22274;\n    int64_t slice_22275;\n    int64_t gtid_21202;\n    int64_t remnant_22276;\n    \n    local_tid_22270 = get_local_id(0);\n    tblock_sizze_22273 = get_local_size(0);\n    wave_sizze_22272 = LOCKSTEP_WIDTH;\n    block_id_22271 = get_tblock_id(0);\n    global_tid_22269 = block_id_22271 * tblock_sizze_22273 + local_tid_22270;\n    phys_tid_21203 = sext_i32_i64(global_tid_22269);\n    global_tid_22274 = sext_i32_i64(block_id_22271) * segmap_tblock_sizze_21199 + sext_i32_i64(local_tid_22270);\n    slice_22275 = dzlz7bUZLztztZRz20U2z20Ursz7dUzg_19129;\n    gtid_21202 = global_tid_22274;\n    remnant_22276 = global_tid_22274 - gtid_21202;\n    if (slt64(gtid_21202, dzlz7bUZLztztZRz20U2z20Ursz7dUzg_19129)) {\n        bool eta_p_21204;\n  ", "      bool eta_p_21205;\n        bool x_21206;\n        bool lifted_lambda_res_21207;\n        \n        eta_p_21204 = ((__global bool *) mem_21503)[gtid_21202];\n        eta_p_21205 = ((__global bool *) mem_21504)[gtid_21202];\n        x_21206 = eta_p_21204 && eta_p_21205;\n        lifted_lambda_res_21207 = !x_21206;\n        ((__global bool *) mem_21521)[gtid_21202] = lifted_lambda_res_21207;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_21199\n}\nFUTHARK_KERNEL_SIZED(mainzisegred_nonseg_20850_dim1, 1, 1)\nvoid mainzisegred_nonseg_20850(__global int *global_failure, int64_t dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, int64_t num_tblocks_20845, int64_t num_threads_21825, __global unsigned char *mem_21321, __global unsigned char *mem_21325, __global unsigned char *counters_mem_21821, __global unsigned char *segred_tmp_mem_21823)\n{\n    #define segred_tblock_sizze_20843 (mainzisegred_nonseg_20850zisegred_tblock_sizze_20843)\n    #define chunk_sizze_21820 (mainzisegred_nonseg_20850zichunk_sizze_21820)\n    \n    volatile __local unsigned char *sync_arr_mem_21833_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_21833_backing_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i64_mem_21831_backing_0 = &shared_mem[sync_arr_mem_21833_backing_1_offset];\n    const int64_t red_arr_i64_mem_21831_backing_0_offset = sync_arr_mem_21833_backing_1_offset + ((int64_t) 8 * segred_tblock_sizze_20843 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_20843, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_21827;\n    int32_t tblock_sizze_21830;\n    int32_t wave_sizze_21829;\n    int32_t block_id_21828;\n    int32_t global_tid_21826;\n    int64_t phys_tid_20850;\n    __local unsigned char *red_arr_i64_mem_21831;\n    __local unsigned char *sync_arr_mem_21833;\n    int64_t dummy_20848;\n    int64_t gtid_20849;\n    int64_t q_21835;\n    int64_t eta_p_block_res_acc_21836;\n    int64_t eta_p_1972", "3;\n    int64_t eta_p_19724;\n    int64_t tblock_id_in_segment_21840;\n    int64_t block_base_offset_21841;\n    int32_t offset_21844;\n    int32_t skip_waves_21845;\n    int64_t eta_p_21837;\n    int64_t eta_p_21838;\n    int32_t old_counter_21846;\n    bool is_last_block_21847;\n    \n    local_tid_21827 = get_local_id(0);\n    tblock_sizze_21830 = get_local_size(0);\n    wave_sizze_21829 = LOCKSTEP_WIDTH;\n    block_id_21828 = get_tblock_id(0);\n    global_tid_21826 = block_id_21828 * tblock_sizze_21830 + local_tid_21827;\n    phys_tid_20850 = sext_i32_i64(global_tid_21826);\n    red_arr_i64_mem_21831 = (__local unsigned char *) red_arr_i64_mem_21831_backing_0;\n    sync_arr_mem_21833 = (__local unsigned char *) sync_arr_mem_21833_backing_1;\n    dummy_20848 = (int64_t) 0;\n    gtid_20849 = (int64_t) 0;\n    q_21835 = sdiv_up64(dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, sext_i32_i64(sext_i64_i32(segred_tblock_sizze_20843 * num_tblocks_20845)) * chunk_sizze_21820);\n    // ne-initialise the outer (per-block) accumulator(s)\n    {\n        eta_p_block_res_acc_21836 = (int64_t) 0;\n    }\n    tblock_id_in_segment_21840 = squot64(phys_tid_20850, segred_tblock_sizze_20843);\n    block_base_offset_21841 = tblock_id_in_segment_21840 * q_21835 * segred_tblock_sizze_20843;\n    for (int64_t i_21842 = 0; i_21842 < q_21835; i_21842++) {\n        int64_t block_offset_21843 = block_base_offset_21841 + i_21842 * segred_tblock_sizze_20843;\n        \n        gtid_20849 = phys_tid_20850 + num_threads_21825 * i_21842;\n        if (slt64(gtid_20849, dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685)) {\n            // apply map function(s)\n            {\n                // apply map function\n                {\n                    int64_t x_20832 = ((__global int64_t *) mem_21321)[gtid_20849];\n                    \n                    // load accumulator(s)\n                    {\n                        eta_p_19723 = eta_p_block_res_acc_21836;\n                    }\n                    // load next value(s)",
                                    "\n                    {\n                        eta_p_19724 = x_20832;\n                    }\n                    // apply reduction operator(s)\n                    {\n                        int64_t defunc_0_op_res_19725 = add64(eta_p_19723, eta_p_19724);\n                        \n                        // store in accumulator(s)\n                        {\n                            eta_p_block_res_acc_21836 = defunc_0_op_res_19725;\n                        }\n                    }\n                }\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // store accs. prims go in lmem; non-prims in params (in global mem)\n    {\n        ((__local int64_t *) red_arr_i64_mem_21831)[sext_i32_i64(local_tid_21827)] = eta_p_block_res_acc_21836;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    skip_waves_21845 = 1;\n    offset_21844 = 0;\n    // participating threads read initial accumulator\n    {\n        if (slt32(local_tid_21827, sext_i64_i32(segred_tblock_sizze_20843))) {\n            eta_p_21837 = ((__local int64_t *) red_arr_i64_mem_21831)[sext_i32_i64(local_tid_21827 + offset_21844)];\n        }\n    }\n    offset_21844 = 1;\n    while (slt32(offset_21844, wave_sizze_21829)) {\n        if (slt32(local_tid_21827 + offset_21844, sext_i64_i32(segred_tblock_sizze_20843)) && ((local_tid_21827 - squot32(local_tid_21827, wave_sizze_21829) * wave_sizze_21829) & (2 * offset_21844 - 1)) == 0) {\n            // read array element\n            {\n                eta_p_21838 = ((volatile __local int64_t *) red_arr_i64_mem_21831)[sext_i32_i64(local_tid_21827 + offset_21844)];\n            }\n            // apply reduction operation\n            {\n                int64_t defunc_0_op_res_21839 = add64(eta_p_21837, eta_p_21838);\n                \n                eta_p_21837 = defunc_0_op_res_21839;\n            }\n            // write result of operation\n            {\n                ((volatile __local int64_t *) red_arr_i64_mem_21831)[sext_i32_i64(local_tid_21827)] = eta_p_21837;\n            }\n   ", "     }\n        offset_21844 *= 2;\n    }\n    while (slt32(skip_waves_21845, squot32(sext_i64_i32(segred_tblock_sizze_20843) + wave_sizze_21829 - 1, wave_sizze_21829))) {\n        barrier(CLK_LOCAL_MEM_FENCE);\n        offset_21844 = skip_waves_21845 * wave_sizze_21829;\n        if (slt32(local_tid_21827 + offset_21844, sext_i64_i32(segred_tblock_sizze_20843)) && ((local_tid_21827 - squot32(local_tid_21827, wave_sizze_21829) * wave_sizze_21829) == 0 && (squot32(local_tid_21827, wave_sizze_21829) & (2 * skip_waves_21845 - 1)) == 0)) {\n            // read array element\n            {\n                eta_p_21838 = ((__local int64_t *) red_arr_i64_mem_21831)[sext_i32_i64(local_tid_21827 + offset_21844)];\n            }\n            // apply reduction operation\n            {\n                int64_t defunc_0_op_res_21839 = add64(eta_p_21837, eta_p_21838);\n                \n                eta_p_21837 = defunc_0_op_res_21839;\n            }\n            // write result of operation\n            {\n                ((__local int64_t *) red_arr_i64_mem_21831)[sext_i32_i64(local_tid_21827)] = eta_p_21837;\n            }\n        }\n        skip_waves_21845 *= 2;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // thread 0 updates per-block acc(s); rest reset to ne\n    {\n        if (sext_i32_i64(local_tid_21827) == (int64_t) 0) {\n            eta_p_block_res_acc_21836 = eta_p_21837;\n        } else {\n            eta_p_block_res_acc_21836 = (int64_t) 0;\n        }\n    }\n    // first thread in block saves block result to global memory\n    {\n        if (local_tid_21827 == 0) {\n            ((__global int64_t *) segred_tmp_mem_21823)[sext_i32_i64(block_id_21828)] = eta_p_block_res_acc_21836;\n            mem_fence_global();\n            old_counter_21846 = atomic_add_i32_global(&((volatile __global int *) counters_mem_21821)[(int64_t) 0], (int) 1);\n            ((__local bool *) sync_arr_mem_21833)[(int64_t) 0] = old_counter_21846 == sext_i64_i32(num_tblocks_20845 - (int64_t)", " 1);\n        }\n    }\n    barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    is_last_block_21847 = ((__local bool *) sync_arr_mem_21833)[(int64_t) 0];\n    if (is_last_block_21847) {\n        if (local_tid_21827 == 0) {\n            old_counter_21846 = atomic_add_i32_global(&((volatile __global int *) counters_mem_21821)[(int64_t) 0], (int) sext_i64_i32((int64_t) 0 - num_tblocks_20845));\n        }\n        // read in the per-block-results\n        {\n            int64_t read_per_thread_21848 = sdiv_up64(num_tblocks_20845, segred_tblock_sizze_20843);\n            \n            eta_p_19723 = (int64_t) 0;\n            for (int64_t i_21849 = 0; i_21849 < read_per_thread_21848; i_21849++) {\n                int64_t block_res_id_21850 = sext_i32_i64(local_tid_21827) * read_per_thread_21848 + i_21849;\n                int64_t index_of_block_res_21851 = block_res_id_21850;\n                \n                if (slt64(block_res_id_21850, num_tblocks_20845)) {\n                    eta_p_19724 = ((__global int64_t *) segred_tmp_mem_21823)[index_of_block_res_21851];\n                    \n                    int64_t defunc_0_op_res_19725 = add64(eta_p_19723, eta_p_19724);\n                    \n                    eta_p_19723 = defunc_0_op_res_19725;\n                }\n            }\n        }\n        ((__local int64_t *) red_arr_i64_mem_21831)[sext_i32_i64(local_tid_21827)] = eta_p_19723;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // reduce the per-block results\n        {\n            int32_t offset_21852;\n            int32_t skip_waves_21853 = 1;\n            int64_t eta_p_21837;\n            int64_t eta_p_21838;\n            \n            offset_21852 = 0;\n            // participating threads read initial accumulator\n            {\n                if (slt32(local_tid_21827, sext_i64_i32(segred_tblock_sizze_20843))) {\n                    eta_p_21837 = ((__local int64_t *) red_arr_i64_mem_21831)[sext_i32_i64(local_tid_21827 + offset_21852)];\n                }\n            }\n            offset_21",
                                    "852 = 1;\n            while (slt32(offset_21852, wave_sizze_21829)) {\n                if (slt32(local_tid_21827 + offset_21852, sext_i64_i32(segred_tblock_sizze_20843)) && ((local_tid_21827 - squot32(local_tid_21827, wave_sizze_21829) * wave_sizze_21829) & (2 * offset_21852 - 1)) == 0) {\n                    // read array element\n                    {\n                        eta_p_21838 = ((volatile __local int64_t *) red_arr_i64_mem_21831)[sext_i32_i64(local_tid_21827 + offset_21852)];\n                    }\n                    // apply reduction operation\n                    {\n                        int64_t defunc_0_op_res_21839 = add64(eta_p_21837, eta_p_21838);\n                        \n                        eta_p_21837 = defunc_0_op_res_21839;\n                    }\n                    // write result of operation\n                    {\n                        ((volatile __local int64_t *) red_arr_i64_mem_21831)[sext_i32_i64(local_tid_21827)] = eta_p_21837;\n                    }\n                }\n                offset_21852 *= 2;\n            }\n            while (slt32(skip_waves_21853, squot32(sext_i64_i32(segred_tblock_sizze_20843) + wave_sizze_21829 - 1, wave_sizze_21829))) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                offset_21852 = skip_waves_21853 * wave_sizze_21829;\n                if (slt32(local_tid_21827 + offset_21852, sext_i64_i32(segred_tblock_sizze_20843)) && ((local_tid_21827 - squot32(local_tid_21827, wave_sizze_21829) * wave_sizze_21829) == 0 && (squot32(local_tid_21827, wave_sizze_21829) & (2 * skip_waves_21853 - 1)) == 0)) {\n                    // read array element\n                    {\n                        eta_p_21838 = ((__local int64_t *) red_arr_i64_mem_21831)[sext_i32_i64(local_tid_21827 + offset_21852)];\n                    }\n                    // apply reduction operation\n                    {\n                        int64_t defunc_0_op_res_21839 = add64(eta_p_21837, eta_p_21838);\n                        \n          ", "              eta_p_21837 = defunc_0_op_res_21839;\n                    }\n                    // write result of operation\n                    {\n                        ((__local int64_t *) red_arr_i64_mem_21831)[sext_i32_i64(local_tid_21827)] = eta_p_21837;\n                    }\n                }\n                skip_waves_21853 *= 2;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // and back to memory with the final result\n            {\n                if (local_tid_21827 == 0) {\n                    ((__global int64_t *) mem_21325)[(int64_t) 0] = eta_p_21837;\n                }\n            }\n        }\n    }\n    \n  error_5:\n    return;\n    #undef segred_tblock_sizze_20843\n    #undef chunk_sizze_21820\n}\nFUTHARK_KERNEL_SIZED(mainzisegscan_20840_dim1, 1, 1)\nvoid mainzisegscan_20840(__global int *global_failure, int64_t dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, int8_t index_primexp_18769, int64_t num_tblocks_20837, int64_t num_virt_blocks_21683, int64_t num_virt_threads_21684, __global unsigned char *mem_21310, __global unsigned char *mem_21319, __global unsigned char *mem_21321, __global unsigned char *mem_21323, __global unsigned char *status_flags_mem_21685, __global unsigned char *aggregates_mem_21707, __global unsigned char *incprefixes_mem_21709, __global unsigned char *global_dynid_mem_21711)\n{\n    #define segscan_tblock_sizze_20835 (mainzisegscan_20840zisegscan_tblock_sizze_20835)\n    #define chunk_sizze_21682 (mainzisegscan_20840zichunk_sizze_21682)\n    \n    volatile __local unsigned char *local_mem_21741_backing_0 = &shared_mem[0];\n    const int64_t local_mem_21741_backing_0_offset = 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_20835), chunk_sizze_21682 * segscan_tblock_sizze_20835 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_20835), chunk_sizze_21682 * segscan_tblock_sizze_20835 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    \n    if (*globa", "l_failure >= 0)\n        return;\n    \n    int32_t local_tid_21734;\n    int32_t tblock_sizze_21737;\n    int32_t wave_sizze_21736;\n    int32_t block_id_21735;\n    int32_t global_tid_21733;\n    int64_t phys_tid_20840;\n    int32_t chunk_sizze_32b_21738;\n    int64_t byte_offsets_21739;\n    int64_t warp_byte_offset_21740;\n    __local unsigned char *local_mem_21741;\n    int64_t trans_arr_len_21742;\n    int64_t phys_block_id_21748;\n    int64_t virtloop_bound_21749;\n    \n    local_tid_21734 = get_local_id(0);\n    tblock_sizze_21737 = get_local_size(0);\n    wave_sizze_21736 = LOCKSTEP_WIDTH;\n    block_id_21735 = get_tblock_id(0);\n    global_tid_21733 = block_id_21735 * tblock_sizze_21737 + local_tid_21734;\n    phys_tid_20840 = sext_i32_i64(global_tid_21733);\n    chunk_sizze_32b_21738 = sext_i64_i32(chunk_sizze_21682);\n    byte_offsets_21739 = segscan_tblock_sizze_20835 * (int64_t) 8;\n    warp_byte_offset_21740 = (int64_t) 288;\n    // Allocate reusable shared memory\n    { }\n    local_mem_21741 = (__local unsigned char *) local_mem_21741_backing_0;\n    trans_arr_len_21742 = chunk_sizze_21682 * segscan_tblock_sizze_20835;\n    phys_block_id_21748 = get_tblock_id(0);\n    virtloop_bound_21749 = sdiv_up64(num_virt_blocks_21683 - phys_block_id_21748, num_tblocks_20837);\n    for (int64_t virtloop_i_21750 = 0; virtloop_i_21750 < virtloop_bound_21749; virtloop_i_21750++) {\n        int64_t dynamic_id_21751;\n        int64_t block_offset_21752;\n        int64_t sgm_idx_21753;\n        int32_t boundary_21754;\n        int32_t segsizze_compact_21755;\n        int64_t private_mem_21756[chunk_sizze_21682];\n        int64_t thd_offset_21758;\n        int64_t acc_21774;\n        int64_t prefix_21784;\n        bool block_new_sgm_21785;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_21734 == 0) {\n                dynamic_id_21751 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_21711)[(int64_t) 0], (int) 1);\n                /",
                                    "/ Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_21741)[(int64_t) 0] = dynamic_id_21751;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_21751 == num_virt_blocks_21683 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_21711)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_21751 = ((__local int32_t *) local_mem_21741)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_21752 = dynamic_id_21751 * chunk_sizze_21682 * segscan_tblock_sizze_20835;\n        sgm_idx_21753 = smod64(block_offset_21752, dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685);\n        boundary_21754 = sext_i64_i32(smin64(chunk_sizze_21682 * segscan_tblock_sizze_20835, dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685 - sgm_idx_21753));\n        segsizze_compact_21755 = sext_i64_i32(smin64(chunk_sizze_21682 * segscan_tblock_sizze_20835, dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685));\n        thd_offset_21758 = block_offset_21752 + sext_i32_i64(local_tid_21734);\n        // Load and map\n        {\n            for (int64_t i_21759 = 0; i_21759 < chunk_sizze_21682; i_21759++) {\n                int64_t virt_tid_21760 = thd_offset_21758 + i_21759 * segscan_tblock_sizze_20835;\n                int64_t slice_21761 = dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685;\n                int64_t gtid_20839 = virt_tid_21760;\n                int64_t remnant_21762 = virt_tid_21760 - gtid_20839;\n                \n                if (slt64(virt_tid_21760, dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685)) {\n                    int8_t eta_p_19750 = ((__global int8_t *) mem_21310)[gtid_20839];\n                    bool lifted_lambda_res_19751 = eta_p_19750 == index_primexp_18769;\n                    int64_t bool_res_19", "753 = btoi_bool_i64(lifted_lambda_res_19751);\n                    \n                    ((__global int64_t *) mem_21321)[gtid_20839] = bool_res_19753;\n                    ((__global int64_t *) mem_21323)[gtid_20839] = bool_res_19753;\n                    private_mem_21756[i_21759] = bool_res_19753;\n                } else {\n                    private_mem_21756[i_21759] = (int64_t) 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_21763 = 0; i_21763 < chunk_sizze_21682; i_21763++) {\n                int64_t sharedIdx_21764 = sext_i32_i64(local_tid_21734) + i_21763 * segscan_tblock_sizze_20835;\n                int64_t tmp_21765 = private_mem_21756[i_21763];\n                \n                ((__local int64_t *) local_mem_21741)[sharedIdx_21764] = tmp_21765;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_21766 = 0; i_21766 < chunk_sizze_21682; i_21766++) {\n                int64_t sharedIdx_21767 = sext_i32_i64(local_tid_21734) * chunk_sizze_21682 + i_21766;\n                int64_t tmp_21768 = ((__local int64_t *) local_mem_21741)[sharedIdx_21767];\n                \n                private_mem_21756[i_21766] = tmp_21768;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_21769 = 0; i_21769 < chunk_sizze_21682 - (int64_t) 1; i_21769++) {\n                int64_t eta_p_19694;\n                int64_t eta_p_19695;\n                \n                eta_p_19694 = private_mem_21756[i_21769];\n                eta_p_19695 = private_mem_21756[i_21769 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_19696 = add64(eta_p_19694, eta_p_19695);\n                \n                private_mem_21756[i_21769 + (int64_t) 1] = defunc_0_op_res_19696;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_21770 = privat", "e_mem_21756[chunk_sizze_21682 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_21741)[sext_i32_i64(local_tid_21734)] = tmp_21770;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_21771;\n            int64_t eta_p_21772;\n            int64_t eta_p_21775;\n            int64_t eta_p_21776;\n            bool ltid_in_bounds_21778 = slt64(sext_i32_i64(local_tid_21734), num_virt_threads_21684);\n            int32_t skip_threads_21779;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_21778) {\n                    eta_p_21772 = ((volatile __local int64_t *) local_mem_21741)[sext_i32_i64(local_tid_21734)];\n                    if ((local_tid_21734 - squot32(local_tid_21734, 32) * 32) == 0) {\n                        eta_p_21771 = eta_p_21772;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_21779 = 1;\n                while (slt32(skip_threads_21779, 32)) {\n                    bool thread_active_21780 = sle32(skip_threads_21779, local_tid_21734 - squot32(local_tid_21734, 32) * 32) && ltid_in_bounds_21778;\n                    \n                    if (thread_active_21780) {\n                        // read operands\n                        {\n                            eta_p_21771 = ((volatile __local int64_t *) local_mem_21741)[sext_i32_i64(local_tid_21734) - sext_i32_i64(skip_threads_21779)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_21780) {\n                            int64_t defunc_0_op_res_21773 = add64(eta_p_21771, eta_p_21772);\n                            \n                            eta_p_21771 = defunc_0_op_res_21773;\n                        }\n                    }\n                    if (sle32(wave_sizze_2",
                                    "1736, skip_threads_21779)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_21780) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_21741)[sext_i32_i64(local_tid_21734)] = eta_p_21771;\n                            eta_p_21772 = eta_p_21771;\n                        }\n                    }\n                    if (sle32(wave_sizze_21736, skip_threads_21779)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_21779 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_21734 - squot32(local_tid_21734, 32) * 32) == 31 && ltid_in_bounds_21778) {\n                    ((volatile __local int64_t *) local_mem_21741)[sext_i32_i64(squot32(local_tid_21734, 32))] = eta_p_21771;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_21781;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_21734, 32) == 0 && ltid_in_bounds_21778) {\n                        eta_p_21776 = ((volatile __local int64_t *) local_mem_21741)[sext_i32_i64(local_tid_21734)];\n                        if ((local_tid_21734 - squot32(local_tid_21734, 32) * 32) == 0) {\n                            eta_p_21775 = eta_p_21776;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_21781 = 1;\n                    while (slt32(skip_threads_21781, 32)) {\n                        bool thread_active_21782 = sle32(skip_thr", "eads_21781, local_tid_21734 - squot32(local_tid_21734, 32) * 32) && (squot32(local_tid_21734, 32) == 0 && ltid_in_bounds_21778);\n                        \n                        if (thread_active_21782) {\n                            // read operands\n                            {\n                                eta_p_21775 = ((volatile __local int64_t *) local_mem_21741)[sext_i32_i64(local_tid_21734) - sext_i32_i64(skip_threads_21781)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_21782) {\n                                int64_t defunc_0_op_res_21777 = add64(eta_p_21775, eta_p_21776);\n                                \n                                eta_p_21775 = defunc_0_op_res_21777;\n                            }\n                        }\n                        if (sle32(wave_sizze_21736, skip_threads_21781)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_21782) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_21741)[sext_i32_i64(local_tid_21734)] = eta_p_21775;\n                                eta_p_21776 = eta_p_21775;\n                            }\n                        }\n                        if (sle32(wave_sizze_21736, skip_threads_21781)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_21781 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_21783 = squot32(local_tid_21734, 32) == 0 || !ltid_in_bounds_21778;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_21783) {\n    ", "                    eta_p_21772 = eta_p_21771;\n                        eta_p_21771 = ((__local int64_t *) local_mem_21741)[sext_i32_i64(squot32(local_tid_21734, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_21783) {\n                        int64_t defunc_0_op_res_21773 = add64(eta_p_21771, eta_p_21772);\n                        \n                        eta_p_21771 = defunc_0_op_res_21773;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_21783) {\n                        ((__local int64_t *) local_mem_21741)[sext_i32_i64(local_tid_21734)] = eta_p_21771;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_21734, 32) == 0 && ltid_in_bounds_21778) {\n                    ((__local int64_t *) local_mem_21741)[sext_i32_i64(local_tid_21734)] = eta_p_21772;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_21734 == 0) {\n                acc_21774 = ((__local int64_t *) local_mem_21741)[segscan_tblock_sizze_20835 - (int64_t) 1];\n            } else {\n                acc_21774 = ((__local int64_t *) local_mem_21741)[sext_i32_i64(local_tid_21734) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_21784 = (int64_t) 0;\n        block_new_sgm_21785 = sgm_idx_21753 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_21785 && local_tid_21734 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_21709)[dynamic_id_21751] = acc_21774;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_21685)[dynamic_id_21751] = (int8_t) 2;\n   ",
                                    "             acc_21774 = (int64_t) 0;\n            }\n            if (!block_new_sgm_21785 && slt32(local_tid_21734, wave_sizze_21736)) {\n                if (local_tid_21734 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_21707)[dynamic_id_21751] = acc_21774;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_21685)[dynamic_id_21751] = (int8_t) 1;\n                    \n                    int8_t tmp_21786 = ((volatile __global int8_t *) status_flags_mem_21685)[dynamic_id_21751 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_21741)[(int64_t) 0] = tmp_21786;\n                }\n                mem_fence_local();\n                \n                int8_t status_21787 = ((__local int8_t *) local_mem_21741)[(int64_t) 0];\n                \n                if (status_21787 == (int8_t) 2) {\n                    if (local_tid_21734 == 0) {\n                        prefix_21784 = ((volatile __global int64_t *) incprefixes_mem_21709)[dynamic_id_21751 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_21788 = sext_i64_i32(dynamic_id_21751 - sext_i32_i64(wave_sizze_21736));\n                    \n                    while (slt32(wave_sizze_21736 * -1, readOffset_21788)) {\n                        int32_t read_i_21789 = readOffset_21788 + local_tid_21734;\n                        int64_t aggr_21790 = (int64_t) 0;\n                        int8_t flag_21791 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_21789)) {\n                            flag_21791 = ((volatile __global int8_t *) status_flags_mem_21685)[sext_i32_i64(read_i_21789)];\n                            if (flag_21791 == (int8_t) 2) {\n                                aggr_21790 = ((volatile __global int64_t *) incprefixes_mem_21709)[sext_i32_i64(read_i_21789)];\n                            } else if (flag_21791 == (int8_t) 1) ", "{\n                                aggr_21790 = ((volatile __global int64_t *) aggregates_mem_21707)[sext_i32_i64(read_i_21789)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_21741)[(int64_t) 4 + sext_i32_i64(local_tid_21734)] = aggr_21790;\n                        ((__local int8_t *) local_mem_21741)[sext_i32_i64(local_tid_21734)] = flag_21791;\n                        flag_21791 = ((__local int8_t *) local_mem_21741)[sext_i32_i64(wave_sizze_21736) - (int64_t) 1];\n                        if (slt8(flag_21791, (int8_t) 2)) {\n                            int8_t flg_x_21795;\n                            int8_t flg_y_21796;\n                            int64_t eta_p_21792;\n                            int64_t eta_p_21793;\n                            int32_t skip_threads_21797;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_21796 = ((volatile __local int8_t *) local_mem_21741)[sext_i32_i64(local_tid_21734)];\n                                eta_p_21793 = ((volatile __local int64_t *) local_mem_21741)[(int64_t) 4 + sext_i32_i64(local_tid_21734)];\n                                if ((local_tid_21734 - squot32(local_tid_21734, 32) * 32) == 0) {\n                                    eta_p_21792 = eta_p_21793;\n                                    flg_x_21795 = flg_y_21796;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_21797 = 1;\n                                while (slt32(skip_threads_21797, 32)) {\n                                    if (sle32(skip_threads_21797, local_tid_21734 - squot32(local_tid_21734, 32) * 32)) {\n                                        // read operands\n                                        {\n                                ", "            flg_x_21795 = ((volatile __local int8_t *) local_mem_21741)[sext_i32_i64(local_tid_21734) - sext_i32_i64(skip_threads_21797)];\n                                            eta_p_21792 = ((volatile __local int64_t *) local_mem_21741)[(int64_t) 4 + (sext_i32_i64(local_tid_21734) - sext_i32_i64(skip_threads_21797))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_21796 == (int8_t) 2 || flg_y_21796 == (int8_t) 0) {\n                                                flg_x_21795 = flg_y_21796;\n                                                eta_p_21792 = eta_p_21793;\n                                            } else {\n                                                int64_t defunc_0_op_res_21794 = add64(eta_p_21792, eta_p_21793);\n                                                \n                                                eta_p_21792 = defunc_0_op_res_21794;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_21741)[sext_i32_i64(local_tid_21734)] = flg_x_21795;\n                                            flg_y_21796 = flg_x_21795;\n                                            ((volatile __local int64_t *) local_mem_21741)[(int64_t) 4 + sext_i32_i64(local_tid_21734)] = eta_p_21792;\n                                            eta_p_21793 = eta_p_21792;\n                                        }\n                                    }\n                                    skip_threads_21797 *= 2;\n                                }\n                            }\n                        }\n                        flag_21791 = ((__local int8_t *) local_mem_21741)[sext_i32_i64(wave_sizze_21736) - (int64_t) 1];\n     ",
                                    "                   aggr_21790 = ((__local int64_t *) local_mem_21741)[(int64_t) 4 + (sext_i32_i64(wave_sizze_21736) - (int64_t) 1)];\n                        if (flag_21791 == (int8_t) 2) {\n                            readOffset_21788 = wave_sizze_21736 * -1;\n                        } else if (flag_21791 == (int8_t) 1) {\n                            readOffset_21788 -= wave_sizze_21736;\n                        }\n                        if (slt8((int8_t) 0, flag_21791)) {\n                            int64_t eta_p_21798 = aggr_21790;\n                            int64_t eta_p_21799 = prefix_21784;\n                            int64_t defunc_0_op_res_21800 = add64(eta_p_21798, eta_p_21799);\n                            \n                            prefix_21784 = defunc_0_op_res_21800;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_21734 == 0) {\n                    if (boundary_21754 == sext_i64_i32(segscan_tblock_sizze_20835 * chunk_sizze_21682)) {\n                        int64_t eta_p_21801 = prefix_21784;\n                        int64_t eta_p_21802 = acc_21774;\n                        int64_t defunc_0_op_res_21803 = add64(eta_p_21801, eta_p_21802);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_21709)[dynamic_id_21751] = defunc_0_op_res_21803;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_21685)[dynamic_id_21751] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_21741)[(int64_t) 4] = prefix_21784;\n                    acc_21774 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_21751 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_21784 = ((__local int64_t *) local_mem_21741)[(int64_t) 4];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        ", "// Distribute results\n        {\n            int64_t eta_p_21804;\n            int64_t eta_p_21805;\n            int64_t eta_p_21807 = prefix_21784;\n            int64_t eta_p_21808 = acc_21774;\n            \n            if (slt32(local_tid_21734 * chunk_sizze_32b_21738, boundary_21754) && !block_new_sgm_21785) {\n                int64_t defunc_0_op_res_21809 = add64(eta_p_21807, eta_p_21808);\n                \n                eta_p_21804 = defunc_0_op_res_21809;\n            } else {\n                eta_p_21804 = acc_21774;\n            }\n            \n            int32_t stopping_point_21810 = segsizze_compact_21755 - srem32(local_tid_21734 * chunk_sizze_32b_21738 - 1 + segsizze_compact_21755 - boundary_21754, segsizze_compact_21755);\n            \n            for (int64_t i_21811 = 0; i_21811 < chunk_sizze_21682; i_21811++) {\n                if (slt32(sext_i64_i32(i_21811), stopping_point_21810 - 1)) {\n                    eta_p_21805 = private_mem_21756[i_21811];\n                    \n                    int64_t defunc_0_op_res_21806 = add64(eta_p_21804, eta_p_21805);\n                    \n                    private_mem_21756[i_21811] = defunc_0_op_res_21806;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_21812 = 0; i_21812 < chunk_sizze_21682; i_21812++) {\n                int64_t sharedIdx_21813 = sext_i32_i64(local_tid_21734) * chunk_sizze_21682 + i_21812;\n                int64_t tmp_21814 = private_mem_21756[i_21812];\n                \n                ((__local int64_t *) local_mem_21741)[sharedIdx_21813] = tmp_21814;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_21815 = 0; i_21815 < chunk_sizze_21682; i_21815++) {\n                int64_t flat_idx_21816 = thd_offset_21758 + i_21815 * segscan_tblock_sizze_20835;\n                int64_t slice_21817 = dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685;\n                int64_", "t gtid_20839 = flat_idx_21816;\n                int64_t remnant_21818 = flat_idx_21816 - gtid_20839;\n                \n                if (slt64(flat_idx_21816, dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685)) {\n                    int64_t tmp_21819 = ((__local int64_t *) local_mem_21741)[flat_idx_21816 - block_offset_21752];\n                    \n                    ((__global int64_t *) mem_21319)[gtid_20839] = tmp_21819;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_20835\n    #undef chunk_sizze_21682\n}\nFUTHARK_KERNEL_SIZED(mainzisegscan_20943_dim1, 1, 1)\nvoid mainzisegscan_20943(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, int64_t deepen_step_res_18845, int64_t zl_rhs_18853, int64_t num_tblocks_20940, int64_t num_virt_blocks_21916, int64_t num_virt_threads_21917, __global unsigned char *ext_mem_21376, __global unsigned char *mem_21379, __global unsigned char *mem_21381, __global unsigned char *mem_21383, __global unsigned char *status_flags_mem_21918, __global unsigned char *aggregates_mem_21920, __global unsigned char *incprefixes_mem_21922, __global unsigned char *global_dynid_mem_21924)\n{\n    #define segscan_tblock_sizze_20938 (mainzisegscan_20943zisegscan_tblock_sizze_20938)\n    #define chunk_sizze_21915 (mainzisegscan_20943zichunk_sizze_21915)\n    \n    volatile __local unsigned char *local_mem_21934_backing_0 = &shared_mem[0];\n    const int64_t local_mem_21934_backing_0_offset = 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_20938), chunk_sizze_21915 * segscan_tblock_sizze_20938 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_20938), chunk_sizze_21915 * segscan_tblock_sizze_20938 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n",
                                    "    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_21927;\n    int32_t tblock_sizze_21930;\n    int32_t wave_sizze_21929;\n    int32_t block_id_21928;\n    int32_t global_tid_21926;\n    int64_t phys_tid_20943;\n    int32_t chunk_sizze_32b_21931;\n    int64_t byte_offsets_21932;\n    int64_t warp_byte_offset_21933;\n    __local unsigned char *local_mem_21934;\n    int64_t trans_arr_len_21935;\n    int64_t phys_block_id_21941;\n    int64_t virtloop_bound_21942;\n    \n    local_tid_21927 = get_local_id(0);\n    tblock_sizze_21930 = get_local_size(0);\n    wave_sizze_21929 = LOCKSTEP_WIDTH;\n    block_id_21928 = get_tblock_id(0);\n    global_tid_21926 = block_id_21928 * tblock_sizze_21930 + local_tid_21927;\n    phys_tid_20943 = sext_i32_i64(global_tid_21926);\n    chunk_sizze_32b_21931 = sext_i64_i32(chunk_sizze_21915);\n    byte_offsets_21932 = segscan_tblock_sizze_20938 * (int64_t) 8;\n    warp_byte_offset_21933 = (int64_t) 288;\n    // Allocate reusable shared memory\n    { }\n    local_mem_21934 = (__local unsigned char *) local_mem_21934_backing_0;\n    trans_arr_len_21935 = chunk_sizze_21915 * segscan_tblock_sizze_20938;\n    phys_block_id_21941 = get_tblock_id(0);\n    virtloop_bound_21942 = sdiv_up64(num_virt_blocks_21916 - phys_block_id_21941, num_tblocks_20940);\n    for (int64_t virtloop_i_21943 = 0; virtloop_i_21943 < virtloop_bound_21942; virtloop_i_21943++) {\n        int64_t dynamic_id_21944;\n        int64_t block_offset_21945;\n        int64_t sgm_idx_21946;\n        int32_t boundary_21947;\n        int32_t segsizze_compact_21948;\n        int64_t private_mem_21949[chunk_sizze_21915];\n        int64_t thd_offset_21951;\n        int64_t acc_21967;\n        int64_t prefix_21977;\n        bool block_new_sgm_21978;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_2192", "7 == 0) {\n                dynamic_id_21944 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_21924)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_21934)[(int64_t) 0] = dynamic_id_21944;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_21944 == num_virt_blocks_21916 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_21924)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_21944 = ((__local int32_t *) local_mem_21934)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_21945 = dynamic_id_21944 * chunk_sizze_21915 * segscan_tblock_sizze_20938;\n        sgm_idx_21946 = smod64(block_offset_21945, deepen_step_res_18845);\n        boundary_21947 = sext_i64_i32(smin64(chunk_sizze_21915 * segscan_tblock_sizze_20938, deepen_step_res_18845 - sgm_idx_21946));\n        segsizze_compact_21948 = sext_i64_i32(smin64(chunk_sizze_21915 * segscan_tblock_sizze_20938, deepen_step_res_18845));\n        thd_offset_21951 = block_offset_21945 + sext_i32_i64(local_tid_21927);\n        // Load and map\n        {\n            for (int64_t i_21952 = 0; i_21952 < chunk_sizze_21915; i_21952++) {\n                int64_t virt_tid_21953 = thd_offset_21951 + i_21952 * segscan_tblock_sizze_20938;\n                int64_t slice_21954 = deepen_step_res_18845;\n                int64_t gtid_20942 = virt_tid_21953;\n                int64_t remnant_21955 = virt_tid_21953 - gtid_20942;\n                \n                if (slt64(virt_tid_21953, deepen_step_res_18845)) {\n                    int64_t tmp_19468 = ((__global int64_t *) ext_mem_21376)[gtid_20942];\n                    bool cond_19469 = slt64(gtid_20942, zl_rhs_18853);\n                    int64_t tmp_19470;\n  ", "                  \n                    if (cond_19469) {\n                        int64_t tmp_19963 = add64((int64_t) 1, gtid_20942);\n                        bool x_19964 = sle64((int64_t) 0, tmp_19963);\n                        bool y_19965 = slt64(tmp_19963, deepen_step_res_18845);\n                        bool bounds_check_19966 = x_19964 && y_19965;\n                        bool index_certs_19967;\n                        \n                        if (!bounds_check_19966) {\n                            {\n                                if (atomic_cmpxchg_i32_global(global_failure, -1, 1) == -1) {\n                                    global_failure_args[0] = (int64_t) tmp_19963;\n                                    global_failure_args[1] = (int64_t) deepen_step_res_18845;\n                                    ;\n                                }\n                                local_failure = 1;\n                                goto error_0;\n                            }\n                        }\n                        \n                        int64_t tmp_t_res_19968 = ((__global int64_t *) ext_mem_21376)[tmp_19963];\n                        \n                        tmp_19470 = tmp_t_res_19968;\n                    } else {\n                        tmp_19470 = dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685;\n                    }\n                    \n                    int64_t zg_lhs_19479 = sub64(tmp_19470, tmp_19468);\n                    bool lifted_lambda_res_19480 = slt64((int64_t) 2, zg_lhs_19479);\n                    int64_t defunc_0_f_res_19481 = btoi_bool_i64(lifted_lambda_res_19480);\n                    \n                    ((__global int64_t *) mem_21381)[gtid_20942] = defunc_0_f_res_19481;\n                    ((__global int64_t *) mem_21383)[gtid_20942] = tmp_19470;\n                    private_mem_21949[i_21952] = defunc_0_f_res_19481;\n                } else {\n                    private_mem_21949[i_21952] = (int64_t) 0;\n                }\n            }\n        }",
                                    "\n        \n      error_0:\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_21956 = 0; i_21956 < chunk_sizze_21915; i_21956++) {\n                int64_t sharedIdx_21957 = sext_i32_i64(local_tid_21927) + i_21956 * segscan_tblock_sizze_20938;\n                int64_t tmp_21958 = private_mem_21949[i_21956];\n                \n                ((__local int64_t *) local_mem_21934)[sharedIdx_21957] = tmp_21958;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_21959 = 0; i_21959 < chunk_sizze_21915; i_21959++) {\n                int64_t sharedIdx_21960 = sext_i32_i64(local_tid_21927) * chunk_sizze_21915 + i_21959;\n                int64_t tmp_21961 = ((__local int64_t *) local_mem_21934)[sharedIdx_21960];\n                \n                private_mem_21949[i_21959] = tmp_21961;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_21962 = 0; i_21962 < chunk_sizze_21915 - (int64_t) 1; i_21962++) {\n                int64_t eta_p_18878;\n                int64_t eta_p_18879;\n                \n                eta_p_18878 = private_mem_21949[i_21962];\n                eta_p_18879 = private_mem_21949[i_21962 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_18880 = add64(eta_p_18878, eta_p_18879);\n                \n                private_mem_21949[i_21962 + (int64_t) 1] = defunc_0_op_res_18880;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_21963 = private_mem_21949[chunk_sizze_21915 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_21934)[sext_i32_i64(local_tid_21927)] = tmp_21963;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_21964;\n            int64_t eta_p_21", "965;\n            int64_t eta_p_21968;\n            int64_t eta_p_21969;\n            bool ltid_in_bounds_21971 = slt64(sext_i32_i64(local_tid_21927), num_virt_threads_21917);\n            int32_t skip_threads_21972;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_21971) {\n                    eta_p_21965 = ((volatile __local int64_t *) local_mem_21934)[sext_i32_i64(local_tid_21927)];\n                    if ((local_tid_21927 - squot32(local_tid_21927, 32) * 32) == 0) {\n                        eta_p_21964 = eta_p_21965;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_21972 = 1;\n                while (slt32(skip_threads_21972, 32)) {\n                    bool thread_active_21973 = sle32(skip_threads_21972, local_tid_21927 - squot32(local_tid_21927, 32) * 32) && ltid_in_bounds_21971;\n                    \n                    if (thread_active_21973) {\n                        // read operands\n                        {\n                            eta_p_21964 = ((volatile __local int64_t *) local_mem_21934)[sext_i32_i64(local_tid_21927) - sext_i32_i64(skip_threads_21972)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_21973) {\n                            int64_t defunc_0_op_res_21966 = add64(eta_p_21964, eta_p_21965);\n                            \n                            eta_p_21964 = defunc_0_op_res_21966;\n                        }\n                    }\n                    if (sle32(wave_sizze_21929, skip_threads_21972)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_21973) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_21934)[sext_i32_i64(local_tid_2", "1927)] = eta_p_21964;\n                            eta_p_21965 = eta_p_21964;\n                        }\n                    }\n                    if (sle32(wave_sizze_21929, skip_threads_21972)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_21972 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_21927 - squot32(local_tid_21927, 32) * 32) == 31 && ltid_in_bounds_21971) {\n                    ((volatile __local int64_t *) local_mem_21934)[sext_i32_i64(squot32(local_tid_21927, 32))] = eta_p_21964;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_21974;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_21927, 32) == 0 && ltid_in_bounds_21971) {\n                        eta_p_21969 = ((volatile __local int64_t *) local_mem_21934)[sext_i32_i64(local_tid_21927)];\n                        if ((local_tid_21927 - squot32(local_tid_21927, 32) * 32) == 0) {\n                            eta_p_21968 = eta_p_21969;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_21974 = 1;\n                    while (slt32(skip_threads_21974, 32)) {\n                        bool thread_active_21975 = sle32(skip_threads_21974, local_tid_21927 - squot32(local_tid_21927, 32) * 32) && (squot32(local_tid_21927, 32) == 0 && ltid_in_bounds_21971);\n                        \n                        if (thread_active_21975) {\n                            // read operands\n                            {\n                                eta_p",
                                    "_21968 = ((volatile __local int64_t *) local_mem_21934)[sext_i32_i64(local_tid_21927) - sext_i32_i64(skip_threads_21974)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_21975) {\n                                int64_t defunc_0_op_res_21970 = add64(eta_p_21968, eta_p_21969);\n                                \n                                eta_p_21968 = defunc_0_op_res_21970;\n                            }\n                        }\n                        if (sle32(wave_sizze_21929, skip_threads_21974)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_21975) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_21934)[sext_i32_i64(local_tid_21927)] = eta_p_21968;\n                                eta_p_21969 = eta_p_21968;\n                            }\n                        }\n                        if (sle32(wave_sizze_21929, skip_threads_21974)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_21974 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_21976 = squot32(local_tid_21927, 32) == 0 || !ltid_in_bounds_21971;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_21976) {\n                        eta_p_21965 = eta_p_21964;\n                        eta_p_21964 = ((__local int64_t *) local_mem_21934)[sext_i32_i64(squot32(local_tid_21927, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_219", "76) {\n                        int64_t defunc_0_op_res_21966 = add64(eta_p_21964, eta_p_21965);\n                        \n                        eta_p_21964 = defunc_0_op_res_21966;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_21976) {\n                        ((__local int64_t *) local_mem_21934)[sext_i32_i64(local_tid_21927)] = eta_p_21964;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_21927, 32) == 0 && ltid_in_bounds_21971) {\n                    ((__local int64_t *) local_mem_21934)[sext_i32_i64(local_tid_21927)] = eta_p_21965;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_21927 == 0) {\n                acc_21967 = ((__local int64_t *) local_mem_21934)[segscan_tblock_sizze_20938 - (int64_t) 1];\n            } else {\n                acc_21967 = ((__local int64_t *) local_mem_21934)[sext_i32_i64(local_tid_21927) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_21977 = (int64_t) 0;\n        block_new_sgm_21978 = sgm_idx_21946 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_21978 && local_tid_21927 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_21922)[dynamic_id_21944] = acc_21967;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_21918)[dynamic_id_21944] = (int8_t) 2;\n                acc_21967 = (int64_t) 0;\n            }\n            if (!block_new_sgm_21978 && slt32(local_tid_21927, wave_sizze_21929)) {\n                if (local_tid_21927 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_21920)[dynamic_id_21944] = acc_21967;\n                    mem_fence_glo", "bal();\n                    ((volatile __global int8_t *) status_flags_mem_21918)[dynamic_id_21944] = (int8_t) 1;\n                    \n                    int8_t tmp_21979 = ((volatile __global int8_t *) status_flags_mem_21918)[dynamic_id_21944 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_21934)[(int64_t) 0] = tmp_21979;\n                }\n                mem_fence_local();\n                \n                int8_t status_21980 = ((__local int8_t *) local_mem_21934)[(int64_t) 0];\n                \n                if (status_21980 == (int8_t) 2) {\n                    if (local_tid_21927 == 0) {\n                        prefix_21977 = ((volatile __global int64_t *) incprefixes_mem_21922)[dynamic_id_21944 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_21981 = sext_i64_i32(dynamic_id_21944 - sext_i32_i64(wave_sizze_21929));\n                    \n                    while (slt32(wave_sizze_21929 * -1, readOffset_21981)) {\n                        int32_t read_i_21982 = readOffset_21981 + local_tid_21927;\n                        int64_t aggr_21983 = (int64_t) 0;\n                        int8_t flag_21984 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_21982)) {\n                            flag_21984 = ((volatile __global int8_t *) status_flags_mem_21918)[sext_i32_i64(read_i_21982)];\n                            if (flag_21984 == (int8_t) 2) {\n                                aggr_21983 = ((volatile __global int64_t *) incprefixes_mem_21922)[sext_i32_i64(read_i_21982)];\n                            } else if (flag_21984 == (int8_t) 1) {\n                                aggr_21983 = ((volatile __global int64_t *) aggregates_mem_21920)[sext_i32_i64(read_i_21982)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_21934)[(int64_t) 4 + sext_i32_i64(local_tid_21927)] = aggr_21983;\n           ",
                                    "             ((__local int8_t *) local_mem_21934)[sext_i32_i64(local_tid_21927)] = flag_21984;\n                        flag_21984 = ((__local int8_t *) local_mem_21934)[sext_i32_i64(wave_sizze_21929) - (int64_t) 1];\n                        if (slt8(flag_21984, (int8_t) 2)) {\n                            int8_t flg_x_21988;\n                            int8_t flg_y_21989;\n                            int64_t eta_p_21985;\n                            int64_t eta_p_21986;\n                            int32_t skip_threads_21990;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_21989 = ((volatile __local int8_t *) local_mem_21934)[sext_i32_i64(local_tid_21927)];\n                                eta_p_21986 = ((volatile __local int64_t *) local_mem_21934)[(int64_t) 4 + sext_i32_i64(local_tid_21927)];\n                                if ((local_tid_21927 - squot32(local_tid_21927, 32) * 32) == 0) {\n                                    eta_p_21985 = eta_p_21986;\n                                    flg_x_21988 = flg_y_21989;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_21990 = 1;\n                                while (slt32(skip_threads_21990, 32)) {\n                                    if (sle32(skip_threads_21990, local_tid_21927 - squot32(local_tid_21927, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_21988 = ((volatile __local int8_t *) local_mem_21934)[sext_i32_i64(local_tid_21927) - sext_i32_i64(skip_threads_21990)];\n                                            eta_p_21985 = ((volatile __local int64_t *) local_mem_21934)[(int64_t) 4 + (sext_i32_i64(local_tid_21927) - sext_i32_i64(skip_threads_", "21990))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_21989 == (int8_t) 2 || flg_y_21989 == (int8_t) 0) {\n                                                flg_x_21988 = flg_y_21989;\n                                                eta_p_21985 = eta_p_21986;\n                                            } else {\n                                                int64_t defunc_0_op_res_21987 = add64(eta_p_21985, eta_p_21986);\n                                                \n                                                eta_p_21985 = defunc_0_op_res_21987;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_21934)[sext_i32_i64(local_tid_21927)] = flg_x_21988;\n                                            flg_y_21989 = flg_x_21988;\n                                            ((volatile __local int64_t *) local_mem_21934)[(int64_t) 4 + sext_i32_i64(local_tid_21927)] = eta_p_21985;\n                                            eta_p_21986 = eta_p_21985;\n                                        }\n                                    }\n                                    skip_threads_21990 *= 2;\n                                }\n                            }\n                        }\n                        flag_21984 = ((__local int8_t *) local_mem_21934)[sext_i32_i64(wave_sizze_21929) - (int64_t) 1];\n                        aggr_21983 = ((__local int64_t *) local_mem_21934)[(int64_t) 4 + (sext_i32_i64(wave_sizze_21929) - (int64_t) 1)];\n                        if (flag_21984 == (int8_t) 2) {\n                            readOffset_21981 = wave_sizze_21929 * -1;\n                        } else if (flag_21984 == (int8_t) ", "1) {\n                            readOffset_21981 -= wave_sizze_21929;\n                        }\n                        if (slt8((int8_t) 0, flag_21984)) {\n                            int64_t eta_p_21991 = aggr_21983;\n                            int64_t eta_p_21992 = prefix_21977;\n                            int64_t defunc_0_op_res_21993 = add64(eta_p_21991, eta_p_21992);\n                            \n                            prefix_21977 = defunc_0_op_res_21993;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_21927 == 0) {\n                    if (boundary_21947 == sext_i64_i32(segscan_tblock_sizze_20938 * chunk_sizze_21915)) {\n                        int64_t eta_p_21994 = prefix_21977;\n                        int64_t eta_p_21995 = acc_21967;\n                        int64_t defunc_0_op_res_21996 = add64(eta_p_21994, eta_p_21995);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_21922)[dynamic_id_21944] = defunc_0_op_res_21996;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_21918)[dynamic_id_21944] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_21934)[(int64_t) 4] = prefix_21977;\n                    acc_21967 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_21944 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_21977 = ((__local int64_t *) local_mem_21934)[(int64_t) 4];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_21997;\n            int64_t eta_p_21998;\n            int64_t eta_p_22000 = prefix_21977;\n            int64_t eta_p_22001 = acc_21967;\n            \n            if (slt32(local_tid_21927 * chunk_sizze_32b_21931, boundary_21947) && !block_new_sgm_21978) {\n       ",
                                    "         int64_t defunc_0_op_res_22002 = add64(eta_p_22000, eta_p_22001);\n                \n                eta_p_21997 = defunc_0_op_res_22002;\n            } else {\n                eta_p_21997 = acc_21967;\n            }\n            \n            int32_t stopping_point_22003 = segsizze_compact_21948 - srem32(local_tid_21927 * chunk_sizze_32b_21931 - 1 + segsizze_compact_21948 - boundary_21947, segsizze_compact_21948);\n            \n            for (int64_t i_22004 = 0; i_22004 < chunk_sizze_21915; i_22004++) {\n                if (slt32(sext_i64_i32(i_22004), stopping_point_22003 - 1)) {\n                    eta_p_21998 = private_mem_21949[i_22004];\n                    \n                    int64_t defunc_0_op_res_21999 = add64(eta_p_21997, eta_p_21998);\n                    \n                    private_mem_21949[i_22004] = defunc_0_op_res_21999;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_22005 = 0; i_22005 < chunk_sizze_21915; i_22005++) {\n                int64_t sharedIdx_22006 = sext_i32_i64(local_tid_21927) * chunk_sizze_21915 + i_22005;\n                int64_t tmp_22007 = private_mem_21949[i_22005];\n                \n                ((__local int64_t *) local_mem_21934)[sharedIdx_22006] = tmp_22007;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_22008 = 0; i_22008 < chunk_sizze_21915; i_22008++) {\n                int64_t flat_idx_22009 = thd_offset_21951 + i_22008 * segscan_tblock_sizze_20938;\n                int64_t slice_22010 = deepen_step_res_18845;\n                int64_t gtid_20942 = flat_idx_22009;\n                int64_t remnant_22011 = flat_idx_22009 - gtid_20942;\n                \n                if (slt64(flat_idx_22009, deepen_step_res_18845)) {\n                    int64_t tmp_22012 = ((__local int64_t *) local_mem_21934)[flat_idx_22009 - block_offset_21945];\n                    \n                    ((__g", "lobal int64_t *) mem_21379)[gtid_20942] = tmp_22012;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_20938\n    #undef chunk_sizze_21915\n}\nFUTHARK_KERNEL_SIZED(mainzisegscan_20982_dim1, 1, 1)\nvoid mainzisegscan_20982(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t loop_dz2088U_18952, int64_t zl_rhs_18961, int64_t num_tblocks_20979, int64_t num_virt_blocks_22054, int64_t num_virt_threads_22055, __global unsigned char *mem_param_21432, __global unsigned char *mem_21438, __global unsigned char *mem_21440, __global unsigned char *mem_21442, __global unsigned char *status_flags_mem_22056, __global unsigned char *aggregates_mem_22058, __global unsigned char *incprefixes_mem_22060, __global unsigned char *global_dynid_mem_22062)\n{\n    #define segscan_tblock_sizze_20977 (mainzisegscan_20982zisegscan_tblock_sizze_20977)\n    #define chunk_sizze_22053 (mainzisegscan_20982zichunk_sizze_22053)\n    \n    volatile __local unsigned char *local_mem_22072_backing_0 = &shared_mem[0];\n    const int64_t local_mem_22072_backing_0_offset = 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_20977), chunk_sizze_22053 * segscan_tblock_sizze_20977 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_20977), chunk_sizze_22053 * segscan_tblock_sizze_20977 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_22065;\n    int32_t tblock_sizze_22068;\n    int32_t wave_sizze_22067;\n    int32_t block_id_22066;\n    int32_t global_tid_22064;\n    int64_t phys_tid_20982;\n    int32_t chunk_sizze_32b_22069;\n    int64_t byte_offsets_22070", ";\n    int64_t warp_byte_offset_22071;\n    __local unsigned char *local_mem_22072;\n    int64_t trans_arr_len_22073;\n    int64_t phys_block_id_22079;\n    int64_t virtloop_bound_22080;\n    \n    local_tid_22065 = get_local_id(0);\n    tblock_sizze_22068 = get_local_size(0);\n    wave_sizze_22067 = LOCKSTEP_WIDTH;\n    block_id_22066 = get_tblock_id(0);\n    global_tid_22064 = block_id_22066 * tblock_sizze_22068 + local_tid_22065;\n    phys_tid_20982 = sext_i32_i64(global_tid_22064);\n    chunk_sizze_32b_22069 = sext_i64_i32(chunk_sizze_22053);\n    byte_offsets_22070 = segscan_tblock_sizze_20977 * (int64_t) 8;\n    warp_byte_offset_22071 = (int64_t) 288;\n    // Allocate reusable shared memory\n    { }\n    local_mem_22072 = (__local unsigned char *) local_mem_22072_backing_0;\n    trans_arr_len_22073 = chunk_sizze_22053 * segscan_tblock_sizze_20977;\n    phys_block_id_22079 = get_tblock_id(0);\n    virtloop_bound_22080 = sdiv_up64(num_virt_blocks_22054 - phys_block_id_22079, num_tblocks_20979);\n    for (int64_t virtloop_i_22081 = 0; virtloop_i_22081 < virtloop_bound_22080; virtloop_i_22081++) {\n        int64_t dynamic_id_22082;\n        int64_t block_offset_22083;\n        int64_t sgm_idx_22084;\n        int32_t boundary_22085;\n        int32_t segsizze_compact_22086;\n        int64_t private_mem_22087[chunk_sizze_22053];\n        int64_t thd_offset_22089;\n        int64_t acc_22105;\n        int64_t prefix_22115;\n        bool block_new_sgm_22116;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_22065 == 0) {\n                dynamic_id_22082 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_22062)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_22072)[(int64_t) 0] = dynamic_id_22082;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    i",
                                    "f (dynamic_id_22082 == num_virt_blocks_22054 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_22062)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_22082 = ((__local int32_t *) local_mem_22072)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_22083 = dynamic_id_22082 * chunk_sizze_22053 * segscan_tblock_sizze_20977;\n        sgm_idx_22084 = smod64(block_offset_22083, loop_dz2088U_18952);\n        boundary_22085 = sext_i64_i32(smin64(chunk_sizze_22053 * segscan_tblock_sizze_20977, loop_dz2088U_18952 - sgm_idx_22084));\n        segsizze_compact_22086 = sext_i64_i32(smin64(chunk_sizze_22053 * segscan_tblock_sizze_20977, loop_dz2088U_18952));\n        thd_offset_22089 = block_offset_22083 + sext_i32_i64(local_tid_22065);\n        // Load and map\n        {\n            for (int64_t i_22090 = 0; i_22090 < chunk_sizze_22053; i_22090++) {\n                int64_t virt_tid_22091 = thd_offset_22089 + i_22090 * segscan_tblock_sizze_20977;\n                int64_t slice_22092 = loop_dz2088U_18952;\n                int64_t gtid_20981 = virt_tid_22091;\n                int64_t remnant_22093 = virt_tid_22091 - gtid_20981;\n                \n                if (slt64(virt_tid_22091, loop_dz2088U_18952)) {\n                    int64_t tmp_19878 = ((__global int64_t *) mem_param_21432)[gtid_20981];\n                    bool cond_19879 = slt64(gtid_20981, zl_rhs_18961);\n                    int64_t tmp_19880;\n                    \n                    if (cond_19879) {\n                        int64_t tmp_19979 = add64((int64_t) 1, gtid_20981);\n                        bool x_19980 = sle64((int64_t) 0, tmp_19979);\n                        bool y_19981 = slt64(tmp_19979, loop_dz2088U_18952);\n                        bool bounds_check_19982 = x_19980 && y_19981;\n                        bool index_certs_19983;\n                        \n                        if (!", "bounds_check_19982) {\n                            {\n                                if (atomic_cmpxchg_i32_global(global_failure, -1, 2) == -1) {\n                                    global_failure_args[0] = (int64_t) tmp_19979;\n                                    global_failure_args[1] = (int64_t) loop_dz2088U_18952;\n                                    ;\n                                }\n                                local_failure = 1;\n                                goto error_0;\n                            }\n                        }\n                        \n                        int64_t tmp_t_res_19984 = ((__global int64_t *) mem_param_21432)[tmp_19979];\n                        \n                        tmp_19880 = tmp_t_res_19984;\n                    } else {\n                        tmp_19880 = (int64_t) 8;\n                    }\n                    \n                    int64_t zg_lhs_19889 = sub64(tmp_19880, tmp_19878);\n                    bool lifted_lambda_res_19890 = slt64((int64_t) 2, zg_lhs_19889);\n                    int64_t defunc_0_f_res_19891 = btoi_bool_i64(lifted_lambda_res_19890);\n                    \n                    ((__global int64_t *) mem_21440)[gtid_20981] = defunc_0_f_res_19891;\n                    ((__global int64_t *) mem_21442)[gtid_20981] = tmp_19880;\n                    private_mem_22087[i_22090] = defunc_0_f_res_19891;\n                } else {\n                    private_mem_22087[i_22090] = (int64_t) 0;\n                }\n            }\n        }\n        \n      error_0:\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_22094 = 0; i_22094 < chunk_sizze_22053; i_22094++) {\n                int64_t sharedIdx_22095 = sext_i32_i64(local_tid_22065) + i_22094 * segscan_tblock_sizze_20977;\n                int64_t tmp_22096 = private_mem_22087[i_22094];\n                \n                ((__local int64_", "t *) local_mem_22072)[sharedIdx_22095] = tmp_22096;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_22097 = 0; i_22097 < chunk_sizze_22053; i_22097++) {\n                int64_t sharedIdx_22098 = sext_i32_i64(local_tid_22065) * chunk_sizze_22053 + i_22097;\n                int64_t tmp_22099 = ((__local int64_t *) local_mem_22072)[sharedIdx_22098];\n                \n                private_mem_22087[i_22097] = tmp_22099;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_22100 = 0; i_22100 < chunk_sizze_22053 - (int64_t) 1; i_22100++) {\n                int64_t eta_p_18986;\n                int64_t eta_p_18987;\n                \n                eta_p_18986 = private_mem_22087[i_22100];\n                eta_p_18987 = private_mem_22087[i_22100 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_18988 = add64(eta_p_18986, eta_p_18987);\n                \n                private_mem_22087[i_22100 + (int64_t) 1] = defunc_0_op_res_18988;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_22101 = private_mem_22087[chunk_sizze_22053 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_22072)[sext_i32_i64(local_tid_22065)] = tmp_22101;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_22102;\n            int64_t eta_p_22103;\n            int64_t eta_p_22106;\n            int64_t eta_p_22107;\n            bool ltid_in_bounds_22109 = slt64(sext_i32_i64(local_tid_22065), num_virt_threads_22055);\n            int32_t skip_threads_22110;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_22109) {\n                    eta_p_22103 = ((volatile __local int64_t *) local_mem_22072)[sext_i32_i64(local_tid_22065)];\n                    if ((local_tid_22065 - squot32(loca",
                                    "l_tid_22065, 32) * 32) == 0) {\n                        eta_p_22102 = eta_p_22103;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_22110 = 1;\n                while (slt32(skip_threads_22110, 32)) {\n                    bool thread_active_22111 = sle32(skip_threads_22110, local_tid_22065 - squot32(local_tid_22065, 32) * 32) && ltid_in_bounds_22109;\n                    \n                    if (thread_active_22111) {\n                        // read operands\n                        {\n                            eta_p_22102 = ((volatile __local int64_t *) local_mem_22072)[sext_i32_i64(local_tid_22065) - sext_i32_i64(skip_threads_22110)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_22111) {\n                            int64_t defunc_0_op_res_22104 = add64(eta_p_22102, eta_p_22103);\n                            \n                            eta_p_22102 = defunc_0_op_res_22104;\n                        }\n                    }\n                    if (sle32(wave_sizze_22067, skip_threads_22110)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_22111) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_22072)[sext_i32_i64(local_tid_22065)] = eta_p_22102;\n                            eta_p_22103 = eta_p_22102;\n                        }\n                    }\n                    if (sle32(wave_sizze_22067, skip_threads_22110)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_22110 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ", "((local_tid_22065 - squot32(local_tid_22065, 32) * 32) == 31 && ltid_in_bounds_22109) {\n                    ((volatile __local int64_t *) local_mem_22072)[sext_i32_i64(squot32(local_tid_22065, 32))] = eta_p_22102;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_22112;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_22065, 32) == 0 && ltid_in_bounds_22109) {\n                        eta_p_22107 = ((volatile __local int64_t *) local_mem_22072)[sext_i32_i64(local_tid_22065)];\n                        if ((local_tid_22065 - squot32(local_tid_22065, 32) * 32) == 0) {\n                            eta_p_22106 = eta_p_22107;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_22112 = 1;\n                    while (slt32(skip_threads_22112, 32)) {\n                        bool thread_active_22113 = sle32(skip_threads_22112, local_tid_22065 - squot32(local_tid_22065, 32) * 32) && (squot32(local_tid_22065, 32) == 0 && ltid_in_bounds_22109);\n                        \n                        if (thread_active_22113) {\n                            // read operands\n                            {\n                                eta_p_22106 = ((volatile __local int64_t *) local_mem_22072)[sext_i32_i64(local_tid_22065) - sext_i32_i64(skip_threads_22112)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_22113) {\n                                int64_t defunc_0_op_res_22108 = add64(eta_p_22106, eta_p_22107);\n                                \n                                eta_p_22106 = defunc_0_op_res", "_22108;\n                            }\n                        }\n                        if (sle32(wave_sizze_22067, skip_threads_22112)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_22113) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_22072)[sext_i32_i64(local_tid_22065)] = eta_p_22106;\n                                eta_p_22107 = eta_p_22106;\n                            }\n                        }\n                        if (sle32(wave_sizze_22067, skip_threads_22112)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_22112 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_22114 = squot32(local_tid_22065, 32) == 0 || !ltid_in_bounds_22109;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_22114) {\n                        eta_p_22103 = eta_p_22102;\n                        eta_p_22102 = ((__local int64_t *) local_mem_22072)[sext_i32_i64(squot32(local_tid_22065, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_22114) {\n                        int64_t defunc_0_op_res_22104 = add64(eta_p_22102, eta_p_22103);\n                        \n                        eta_p_22102 = defunc_0_op_res_22104;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_22114) {\n                        ((__local int64_t *) local_mem_22072)[sext_i32_i64(local_tid_22065)] = eta_p_22102;\n                    }\n                }\n            }\n           ",
                                    " barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_22065, 32) == 0 && ltid_in_bounds_22109) {\n                    ((__local int64_t *) local_mem_22072)[sext_i32_i64(local_tid_22065)] = eta_p_22103;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_22065 == 0) {\n                acc_22105 = ((__local int64_t *) local_mem_22072)[segscan_tblock_sizze_20977 - (int64_t) 1];\n            } else {\n                acc_22105 = ((__local int64_t *) local_mem_22072)[sext_i32_i64(local_tid_22065) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_22115 = (int64_t) 0;\n        block_new_sgm_22116 = sgm_idx_22084 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_22116 && local_tid_22065 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_22060)[dynamic_id_22082] = acc_22105;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_22056)[dynamic_id_22082] = (int8_t) 2;\n                acc_22105 = (int64_t) 0;\n            }\n            if (!block_new_sgm_22116 && slt32(local_tid_22065, wave_sizze_22067)) {\n                if (local_tid_22065 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_22058)[dynamic_id_22082] = acc_22105;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_22056)[dynamic_id_22082] = (int8_t) 1;\n                    \n                    int8_t tmp_22117 = ((volatile __global int8_t *) status_flags_mem_22056)[dynamic_id_22082 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_22072)[(int64_t) 0] = tmp_22117;\n                }\n                mem_fence_local();\n                \n                int8_t status_22118 = ((__local int8_", "t *) local_mem_22072)[(int64_t) 0];\n                \n                if (status_22118 == (int8_t) 2) {\n                    if (local_tid_22065 == 0) {\n                        prefix_22115 = ((volatile __global int64_t *) incprefixes_mem_22060)[dynamic_id_22082 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_22119 = sext_i64_i32(dynamic_id_22082 - sext_i32_i64(wave_sizze_22067));\n                    \n                    while (slt32(wave_sizze_22067 * -1, readOffset_22119)) {\n                        int32_t read_i_22120 = readOffset_22119 + local_tid_22065;\n                        int64_t aggr_22121 = (int64_t) 0;\n                        int8_t flag_22122 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_22120)) {\n                            flag_22122 = ((volatile __global int8_t *) status_flags_mem_22056)[sext_i32_i64(read_i_22120)];\n                            if (flag_22122 == (int8_t) 2) {\n                                aggr_22121 = ((volatile __global int64_t *) incprefixes_mem_22060)[sext_i32_i64(read_i_22120)];\n                            } else if (flag_22122 == (int8_t) 1) {\n                                aggr_22121 = ((volatile __global int64_t *) aggregates_mem_22058)[sext_i32_i64(read_i_22120)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_22072)[(int64_t) 4 + sext_i32_i64(local_tid_22065)] = aggr_22121;\n                        ((__local int8_t *) local_mem_22072)[sext_i32_i64(local_tid_22065)] = flag_22122;\n                        flag_22122 = ((__local int8_t *) local_mem_22072)[sext_i32_i64(wave_sizze_22067) - (int64_t) 1];\n                        if (slt8(flag_22122, (int8_t) 2)) {\n                            int8_t flg_x_22126;\n                            int8_t flg_y_22127;\n                            int64_t eta_p_22123;\n                            int64_t eta_p_22124;\n                          ", "  int32_t skip_threads_22128;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_22127 = ((volatile __local int8_t *) local_mem_22072)[sext_i32_i64(local_tid_22065)];\n                                eta_p_22124 = ((volatile __local int64_t *) local_mem_22072)[(int64_t) 4 + sext_i32_i64(local_tid_22065)];\n                                if ((local_tid_22065 - squot32(local_tid_22065, 32) * 32) == 0) {\n                                    eta_p_22123 = eta_p_22124;\n                                    flg_x_22126 = flg_y_22127;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_22128 = 1;\n                                while (slt32(skip_threads_22128, 32)) {\n                                    if (sle32(skip_threads_22128, local_tid_22065 - squot32(local_tid_22065, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_22126 = ((volatile __local int8_t *) local_mem_22072)[sext_i32_i64(local_tid_22065) - sext_i32_i64(skip_threads_22128)];\n                                            eta_p_22123 = ((volatile __local int64_t *) local_mem_22072)[(int64_t) 4 + (sext_i32_i64(local_tid_22065) - sext_i32_i64(skip_threads_22128))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_22127 == (int8_t) 2 || flg_y_22127 == (int8_t) 0) {\n                                                flg_x_22126 = flg_y_22127;\n                                                eta_p_22123 = eta_p_22124;\n                                            } else {\n                                ",
                                    "                int64_t defunc_0_op_res_22125 = add64(eta_p_22123, eta_p_22124);\n                                                \n                                                eta_p_22123 = defunc_0_op_res_22125;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_22072)[sext_i32_i64(local_tid_22065)] = flg_x_22126;\n                                            flg_y_22127 = flg_x_22126;\n                                            ((volatile __local int64_t *) local_mem_22072)[(int64_t) 4 + sext_i32_i64(local_tid_22065)] = eta_p_22123;\n                                            eta_p_22124 = eta_p_22123;\n                                        }\n                                    }\n                                    skip_threads_22128 *= 2;\n                                }\n                            }\n                        }\n                        flag_22122 = ((__local int8_t *) local_mem_22072)[sext_i32_i64(wave_sizze_22067) - (int64_t) 1];\n                        aggr_22121 = ((__local int64_t *) local_mem_22072)[(int64_t) 4 + (sext_i32_i64(wave_sizze_22067) - (int64_t) 1)];\n                        if (flag_22122 == (int8_t) 2) {\n                            readOffset_22119 = wave_sizze_22067 * -1;\n                        } else if (flag_22122 == (int8_t) 1) {\n                            readOffset_22119 -= wave_sizze_22067;\n                        }\n                        if (slt8((int8_t) 0, flag_22122)) {\n                            int64_t eta_p_22129 = aggr_22121;\n                            int64_t eta_p_22130 = prefix_22115;\n                            int64_t defunc_0_op_res_22131 = add64(eta_p_22129, eta_p_22130);\n                            \n                            prefix_22115 = defunc_0_op_res_22131;\n                        }", "\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_22065 == 0) {\n                    if (boundary_22085 == sext_i64_i32(segscan_tblock_sizze_20977 * chunk_sizze_22053)) {\n                        int64_t eta_p_22132 = prefix_22115;\n                        int64_t eta_p_22133 = acc_22105;\n                        int64_t defunc_0_op_res_22134 = add64(eta_p_22132, eta_p_22133);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_22060)[dynamic_id_22082] = defunc_0_op_res_22134;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_22056)[dynamic_id_22082] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_22072)[(int64_t) 4] = prefix_22115;\n                    acc_22105 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_22082 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_22115 = ((__local int64_t *) local_mem_22072)[(int64_t) 4];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_22135;\n            int64_t eta_p_22136;\n            int64_t eta_p_22138 = prefix_22115;\n            int64_t eta_p_22139 = acc_22105;\n            \n            if (slt32(local_tid_22065 * chunk_sizze_32b_22069, boundary_22085) && !block_new_sgm_22116) {\n                int64_t defunc_0_op_res_22140 = add64(eta_p_22138, eta_p_22139);\n                \n                eta_p_22135 = defunc_0_op_res_22140;\n            } else {\n                eta_p_22135 = acc_22105;\n            }\n            \n            int32_t stopping_point_22141 = segsizze_compact_22086 - srem32(local_tid_22065 * chunk_sizze_32b_22069 - 1 + segsizze_compact_22086 - boundary_22085, segsizze_compact_22086);\n            \n            for (int64_t i_22142 = 0; i_22142 < chunk_sizze_220", "53; i_22142++) {\n                if (slt32(sext_i64_i32(i_22142), stopping_point_22141 - 1)) {\n                    eta_p_22136 = private_mem_22087[i_22142];\n                    \n                    int64_t defunc_0_op_res_22137 = add64(eta_p_22135, eta_p_22136);\n                    \n                    private_mem_22087[i_22142] = defunc_0_op_res_22137;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_22143 = 0; i_22143 < chunk_sizze_22053; i_22143++) {\n                int64_t sharedIdx_22144 = sext_i32_i64(local_tid_22065) * chunk_sizze_22053 + i_22143;\n                int64_t tmp_22145 = private_mem_22087[i_22143];\n                \n                ((__local int64_t *) local_mem_22072)[sharedIdx_22144] = tmp_22145;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_22146 = 0; i_22146 < chunk_sizze_22053; i_22146++) {\n                int64_t flat_idx_22147 = thd_offset_22089 + i_22146 * segscan_tblock_sizze_20977;\n                int64_t slice_22148 = loop_dz2088U_18952;\n                int64_t gtid_20981 = flat_idx_22147;\n                int64_t remnant_22149 = flat_idx_22147 - gtid_20981;\n                \n                if (slt64(flat_idx_22147, loop_dz2088U_18952)) {\n                    int64_t tmp_22150 = ((__local int64_t *) local_mem_22072)[flat_idx_22147 - block_offset_22083];\n                    \n                    ((__global int64_t *) mem_21438)[gtid_20981] = tmp_22150;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_20977\n    #undef chunk_sizze_22053\n}\n", NULL};
// Start of gpu_prototypes.h

// Constants used for transpositions.  In principle these should be configurable.
#define TR_BLOCK_DIM 16
#define TR_TILE_DIM (TR_BLOCK_DIM*2)
#define TR_ELEMS_PER_THREAD 8

// Config stuff included in every GPU backend.
struct gpu_config {
  size_t default_block_size;
  size_t default_grid_size;
  size_t default_tile_size;
  size_t default_reg_tile_size;
  size_t default_cache;
  size_t default_shared_memory;
  size_t default_registers;
  size_t default_threshold;

  int default_block_size_changed;
  int default_grid_size_changed;
  int default_tile_size_changed;
};

// The following are dummy sizes that mean the concrete defaults
// will be set during initialisation via hardware-inspection-based
// heuristics.
struct gpu_config gpu_config_initial = {
  0
};

// Must be defined by the user.
static int gpu_macros(struct futhark_context *ctx, char*** names, int64_t** values);

static void gpu_init_log(struct futhark_context *ctx);
struct builtin_kernels* init_builtin_kernels(struct futhark_context* ctx);
void free_builtin_kernels(struct futhark_context* ctx, struct builtin_kernels* kernels);
static int gpu_free_all(struct futhark_context *ctx);

// End of gpu_prototypes.h

// Start of backends/cuda.h.

// Forward declarations.
// Invoked by setup_opencl() after the platform and device has been
// found, but before the program is loaded.  Its intended use is to
// tune constants based on the selected platform and device.
static void set_tuning_params(struct futhark_context* ctx);
static char* get_failure_msg(int failure_idx, int64_t args[]);

#define CUDA_SUCCEED_FATAL(x) cuda_api_succeed_fatal(x, #x, __FILE__, __LINE__)
#define CUDA_SUCCEED_NONFATAL(x) cuda_api_succeed_nonfatal(x, #x, __FILE__, __LINE__)
#define NVRTC_SUCCEED_FATAL(x) nvrtc_api_succeed_fatal(x, #x, __FILE__, __LINE__)
#define NVRTC_SUCCEED_NONFATAL(x) nvrtc_api_succeed_nonfatal(x, #x, __FILE__, __LINE__)
// Take care not to override an existing error.
#define CUDA_SUCCEED_OR_RETURN(e) {             \
    char *serror = CUDA_SUCCEED_NONFATAL(e);    \
    if (serror) {                               \
      if (!ctx->error) {                        \
        ctx->error = serror;                    \
      } else {                                  \
        free(serror);                           \
      }                                         \
      return bad;                               \
    }                                           \
  }

// CUDA_SUCCEED_OR_RETURN returns the value of the variable 'bad' in
// scope.  By default, it will be this one.  Create a local variable
// of some other type if needed.  This is a bit of a hack, but it
// saves effort in the code generator.
static const int bad = 1;

static inline void cuda_api_succeed_fatal(CUresult res, const char *call,
                                          const char *file, int line) {
  if (res != CUDA_SUCCESS) {
    const char *err_str;
    cuGetErrorString(res, &err_str);
    if (err_str == NULL) { err_str = "Unknown"; }
    futhark_panic(-1, "%s:%d: CUDA call\n  %s\nfailed with error code %d (%s)\n",
                  file, line, call, res, err_str);
  }
}

static char* cuda_api_succeed_nonfatal(CUresult res, const char *call,
                                       const char *file, int line) {
  if (res != CUDA_SUCCESS) {
    const char *err_str;
    cuGetErrorString(res, &err_str);
    if (err_str == NULL) { err_str = "Unknown"; }
    return msgprintf("%s:%d: CUDA call\n  %s\nfailed with error code %d (%s)\n",
                     file, line, call, res, err_str);
  } else {
    return NULL;
  }
}

static inline void nvrtc_api_succeed_fatal(nvrtcResult res, const char *call,
                                           const char *file, int line) {
  if (res != NVRTC_SUCCESS) {
    const char *err_str = nvrtcGetErrorString(res);
    futhark_panic(-1, "%s:%d: NVRTC call\n  %s\nfailed with error code %d (%s)\n",
                  file, line, call, res, err_str);
  }
}

static char* nvrtc_api_succeed_nonfatal(nvrtcResult res, const char *call,
                                        const char *file, int line) {
  if (res != NVRTC_SUCCESS) {
    const char *err_str = nvrtcGetErrorString(res);
    return msgprintf("%s:%d: NVRTC call\n  %s\nfailed with error code %d (%s)\n",
                     file, line, call, res, err_str);
  } else {
    return NULL;
  }
}

struct futhark_context_config {
  int in_use;
  int debugging;
  int profiling;
  int logging;
  char* cache_fname;
  int num_tuning_params;
  int64_t *tuning_params;
  const char** tuning_param_names;
  const char** tuning_param_vars;
  const char** tuning_param_classes;
  // Uniform fields above.

  char* program;
  int num_nvrtc_opts;
  char* *nvrtc_opts;

  char* preferred_device;
  int preferred_device_num;

  int unified_memory;

  char* dump_ptx_to;
  char* load_ptx_from;

  struct gpu_config gpu;
};

static void backend_context_config_setup(struct futhark_context_config *cfg) {
  cfg->num_nvrtc_opts = 0;
  cfg->nvrtc_opts = (char**) malloc(sizeof(char*));
  cfg->nvrtc_opts[0] = NULL;

  cfg->program = strconcat(gpu_program);

  cfg->preferred_device_num = 0;
  cfg->preferred_device = strdup("");

  cfg->dump_ptx_to = NULL;
  cfg->load_ptx_from = NULL;

  cfg->unified_memory = 2;

  cfg->gpu = gpu_config_initial;
  cfg->gpu.default_block_size = 256;
  cfg->gpu.default_tile_size = 32;
  cfg->gpu.default_reg_tile_size = 2;
  cfg->gpu.default_threshold = 32*1024;
}

static void backend_context_config_teardown(struct futhark_context_config* cfg) {
  for (int i = 0; i < cfg->num_nvrtc_opts; i++) {
    free(cfg->nvrtc_opts[i]);
  }
  free(cfg->nvrtc_opts);
  free(cfg->dump_ptx_to);
  free(cfg->load_ptx_from);
  free(cfg->preferred_device);
  free(cfg->program);
}

void futhark_context_config_add_nvrtc_option(struct futhark_context_config *cfg, const char *opt) {
  cfg->nvrtc_opts[cfg->num_nvrtc_opts] = strdup(opt);
  cfg->num_nvrtc_opts++;
  cfg->nvrtc_opts = (char **) realloc(cfg->nvrtc_opts, (cfg->num_nvrtc_opts + 1) * sizeof(char *));
  cfg->nvrtc_opts[cfg->num_nvrtc_opts] = NULL;
}

void futhark_context_config_set_device(struct futhark_context_config *cfg, const char *s) {
  int x = 0;
  if (*s == '#') {
    s++;
    while (isdigit(*s)) {
      x = x * 10 + (*s++)-'0';
    }
    // Skip trailing spaces.
    while (isspace(*s)) {
      s++;
    }
  }
  free(cfg->preferred_device);
  cfg->preferred_device = strdup(s);
  cfg->preferred_device_num = x;
}

const char* futhark_context_config_get_program(struct futhark_context_config *cfg) {
  return cfg->program;
}

void futhark_context_config_set_program(struct futhark_context_config *cfg, const char *s) {
  free(cfg->program);
  cfg->program = strdup(s);
}

void futhark_context_config_dump_ptx_to(struct futhark_context_config *cfg, const char *path) {
  free(cfg->dump_ptx_to);
  cfg->dump_ptx_to = strdup(path);
}

void futhark_context_config_load_ptx_from(struct futhark_context_config *cfg, const char *path) {
  free(cfg->load_ptx_from);
  cfg->load_ptx_from = strdup(path);
}

void futhark_context_config_set_unified_memory(struct futhark_context_config* cfg, int flag) {
  cfg->unified_memory = flag;
}

// A record of something that happened.
struct profiling_record {
  cudaEvent_t *events; // Points to two events.
  const char *name;
};

struct futhark_context {
  struct futhark_context_config* cfg;
  int detail_memory;
  int debugging;
  int profiling;
  int profiling_paused;
  int logging;
  lock_t lock;
  char *error;
  lock_t error_lock;
  FILE *log;
  struct constants *constants;
  struct free_list free_list;
  struct event_list event_list;
  int64_t peak_mem_usage_default;
  int64_t cur_mem_usage_default;
  struct program* program;
  bool program_initialised;
  // Uniform fields above.

  CUdeviceptr global_failure;
  CUdeviceptr global_failure_args;
  struct tuning_params tuning_params;
  // True if a potentially failing kernel has been enqueued.
  int32_t failure_is_an_option;
  int total_runs;
  long int total_runtime;
  int64_t peak_mem_usage_device;
  int64_t cur_mem_usage_device;

  CUdevice dev;
  CUcontext cu_ctx;
  CUmodule module;
  CUstream stream;

  struct free_list gpu_free_list;

  size_t max_thread_block_size;
  size_t max_grid_size;
  size_t max_tile_size;
  size_t max_threshold;
  size_t max_shared_memory;
  size_t max_bespoke;
  size_t max_registers;
  size_t max_cache;

  size_t lockstep_width;

  struct builtin_kernels* kernels;
};

#define CU_DEV_ATTR(x) (CU_DEVICE_ATTRIBUTE_##x)
#define device_query(dev,attrib) _device_query(dev, CU_DEV_ATTR(attrib))
static int _device_query(CUdevice dev, CUdevice_attribute attrib) {
  int val;
  CUDA_SUCCEED_FATAL(cuDeviceGetAttribute(&val, attrib, dev));
  return val;
}

#define CU_FUN_ATTR(x) (CU_FUNC_ATTRIBUTE_##x)
#define function_query(fn,attrib) _function_query(dev, CU_FUN_ATTR(attrib))
static int _function_query(CUfunction dev, CUfunction_attribute attrib) {
  int val;
  CUDA_SUCCEED_FATAL(cuFuncGetAttribute(&val, attrib, dev));
  return val;
}

static int cuda_device_setup(struct futhark_context *ctx) {
  struct futhark_context_config *cfg = ctx->cfg;
  char name[256];
  int count, chosen = -1, best_cc = -1;
  int cc_major_best = 0, cc_minor_best = 0;
  int cc_major = 0, cc_minor = 0;
  CUdevice dev;

  CUDA_SUCCEED_FATAL(cuDeviceGetCount(&count));
  if (count == 0) { return 1; }

  int num_device_matches = 0;

  // XXX: Current device selection policy is to choose the device with the
  // highest compute capability (if no preferred device is set).
  // This should maybe be changed, since greater compute capability is not
  // necessarily an indicator of better performance.
  for (int i = 0; i < count; i++) {
    CUDA_SUCCEED_FATAL(cuDeviceGet(&dev, i));

    cc_major = device_query(dev, COMPUTE_CAPABILITY_MAJOR);
    cc_minor = device_query(dev, COMPUTE_CAPABILITY_MINOR);

    CUDA_SUCCEED_FATAL(cuDeviceGetName(name, sizeof(name) - 1, dev));
    name[sizeof(name) - 1] = 0;

    if (cfg->logging) {
      fprintf(ctx->log, "Device #%d: name=\"%s\", compute capability=%d.%d\n",
              i, name, cc_major, cc_minor);
    }

    if (device_query(dev, COMPUTE_MODE) == CU_COMPUTEMODE_PROHIBITED) {
      if (cfg->logging) {
        fprintf(ctx->log, "Device #%d is compute-prohibited, ignoring\n", i);
      }
      continue;
    }

    if (best_cc == -1 || cc_major > cc_major_best ||
        (cc_major == cc_major_best && cc_minor > cc_minor_best)) {
      best_cc = i;
      cc_major_best = cc_major;
      cc_minor_best = cc_minor;
    }

    if (strstr(name, cfg->preferred_device) != NULL &&
        num_device_matches++ == cfg->preferred_device_num) {
      chosen = i;
      break;
    }
  }

  if (chosen == -1) { chosen = best_cc; }
  if (chosen == -1) { return 1; }

  if (cfg->logging) {
    fprintf(ctx->log, "Using device #%d\n", chosen);
  }

  CUDA_SUCCEED_FATAL(cuDeviceGet(&ctx->dev, chosen));
  return 0;
}

static const char *cuda_nvrtc_get_arch(CUdevice dev) {
  static struct {
    int major;
    int minor;
    const char *arch_str;
  } const x[] = {
    { 3, 0, "compute_30" },
    { 3, 2, "compute_32" },
    { 3, 5, "compute_35" },
    { 3, 7, "compute_37" },
    { 5, 0, "compute_50" },
    { 5, 2, "compute_52" },
    { 5, 3, "compute_53" },
    { 6, 0, "compute_60" },
    { 6, 1, "compute_61" },
    { 6, 2, "compute_62" },
    { 7, 0, "compute_70" },
    { 7, 2, "compute_72" },
    { 7, 5, "compute_75" },
    { 8, 0, "compute_80" },
    { 8, 6, "compute_80" },
    { 8, 7, "compute_80" }
  };

  int major = device_query(dev, COMPUTE_CAPABILITY_MAJOR);
  int minor = device_query(dev, COMPUTE_CAPABILITY_MINOR);

  int chosen = -1;
  int num_archs = sizeof(x)/sizeof(x[0]);
  for (int i = 0; i < num_archs; i++) {
    if (x[i].major < major || (x[i].major == major && x[i].minor <= minor)) {
      chosen = i;
    } else {
      break;
    }
  }

  if (chosen == -1) {
    futhark_panic(-1, "Unsupported compute capability %d.%d\n", major, minor);
  }

  if (x[chosen].major != major || x[chosen].minor != minor) {
    fprintf(stderr,
            "Warning: device compute capability is %d.%d, but newest supported by Futhark is %d.%d.\n",
            major, minor, x[chosen].major, x[chosen].minor);
  }

  return x[chosen].arch_str;
}

static void cuda_nvrtc_mk_build_options(struct futhark_context *ctx, const char *extra_opts[],
                                        char*** opts_out, size_t *n_opts) {
  int arch_set = 0, num_extra_opts;
  struct futhark_context_config *cfg = ctx->cfg;

  char** macro_names;
  int64_t* macro_vals;
  int num_macros = gpu_macros(ctx, &macro_names, &macro_vals);

  // nvrtc cannot handle multiple -arch options.  Hence, if one of the
  // extra_opts is -arch, we have to be careful not to do our usual
  // automatic generation.
  for (num_extra_opts = 0; extra_opts[num_extra_opts] != NULL; num_extra_opts++) {
    if (strstr(extra_opts[num_extra_opts], "-arch")
        == extra_opts[num_extra_opts] ||
        strstr(extra_opts[num_extra_opts], "--gpu-architecture")
        == extra_opts[num_extra_opts]) {
      arch_set = 1;
    }
  }

  size_t i = 0, n_opts_alloc = 20 + num_macros + num_extra_opts + cfg->num_tuning_params;
  char **opts = (char**) malloc(n_opts_alloc * sizeof(char *));
  if (!arch_set) {
    opts[i++] = strdup("-arch");
    opts[i++] = strdup(cuda_nvrtc_get_arch(ctx->dev));
  }
  opts[i++] = strdup("-default-device");
  if (cfg->debugging) {
    opts[i++] = strdup("-G");
    opts[i++] = strdup("-lineinfo");
  } else {
    opts[i++] = strdup("--disable-warnings");
  }
  opts[i++] = msgprintf("-D%s=%d",
                        "max_thread_block_size",
                        (int)ctx->max_thread_block_size);
  opts[i++] = msgprintf("-D%s=%d",
                        "max_shared_memory",
                        (int)ctx->max_shared_memory);
  opts[i++] = msgprintf("-D%s=%d",
                        "max_registers",
                        (int)ctx->max_registers);

  for (int j = 0; j < num_macros; j++) {
    opts[i++] = msgprintf("-D%s=%zu", macro_names[j], macro_vals[j]);
  }

  for (int j = 0; j < cfg->num_tuning_params; j++) {
    opts[i++] = msgprintf("-D%s=%zu", cfg->tuning_param_vars[j],
                          cfg->tuning_params[j]);
  }
  opts[i++] = msgprintf("-DLOCKSTEP_WIDTH=%zu", ctx->lockstep_width);
  opts[i++] = msgprintf("-DMAX_THREADS_PER_BLOCK=%zu", ctx->max_thread_block_size);

  // Time for the best lines of the code in the entire compiler.
  if (getenv("CUDA_HOME") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_HOME"));
  }
  if (getenv("CUDA_ROOT") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_ROOT"));
  }
  if (getenv("CUDA_PATH") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_PATH"));
  }
  opts[i++] = msgprintf("-I/usr/local/cuda/include");
  opts[i++] = msgprintf("-I/usr/include");

  for (int j = 0; extra_opts[j] != NULL; j++) {
    opts[i++] = strdup(extra_opts[j]);
  }

  opts[i++] = msgprintf("-DTR_BLOCK_DIM=%d", TR_BLOCK_DIM);
  opts[i++] = msgprintf("-DTR_TILE_DIM=%d", TR_TILE_DIM);
  opts[i++] = msgprintf("-DTR_ELEMS_PER_THREAD=%d", TR_ELEMS_PER_THREAD);

  free(macro_names);
  free(macro_vals);

  *n_opts = i;
  *opts_out = opts;
}

static char* cuda_nvrtc_build(const char *src, const char *opts[], size_t n_opts,
                              char **ptx) {
  nvrtcProgram prog;
  char *problem = NULL;

  problem = NVRTC_SUCCEED_NONFATAL(nvrtcCreateProgram(&prog, src, "futhark-cuda", 0, NULL, NULL));

  if (problem) {
    return problem;
  }

  nvrtcResult res = nvrtcCompileProgram(prog, n_opts, opts);
  if (res != NVRTC_SUCCESS) {
    size_t log_size;
    if (nvrtcGetProgramLogSize(prog, &log_size) == NVRTC_SUCCESS) {
      char *log = (char*) malloc(log_size);
      if (nvrtcGetProgramLog(prog, log) == NVRTC_SUCCESS) {
        problem = msgprintf("NVRTC compilation failed.\n\n%s\n", log);
      } else {
        problem = msgprintf("Could not retrieve compilation log\n");
      }
      free(log);
    }
    return problem;
  }

  size_t ptx_size;
  NVRTC_SUCCEED_FATAL(nvrtcGetPTXSize(prog, &ptx_size));
  *ptx = (char*) malloc(ptx_size);
  NVRTC_SUCCEED_FATAL(nvrtcGetPTX(prog, *ptx));

  NVRTC_SUCCEED_FATAL(nvrtcDestroyProgram(&prog));

  return NULL;
}

static void cuda_load_ptx_from_cache(struct futhark_context_config *cfg,
                                     const char *src,
                                     const char *opts[], size_t n_opts,
                                     struct cache_hash *h, const char *cache_fname,
                                     char **ptx) {
  if (cfg->logging) {
    fprintf(stderr, "Restoring cache from from %s...\n", cache_fname);
  }
  cache_hash_init(h);
  for (size_t i = 0; i < n_opts; i++) {
    cache_hash(h, opts[i], strlen(opts[i]));
  }
  cache_hash(h, src, strlen(src));
  size_t ptxsize;
  errno = 0;
  if (cache_restore(cache_fname, h, (unsigned char**)ptx, &ptxsize) != 0) {
    if (cfg->logging) {
      fprintf(stderr, "Failed to restore cache (errno: %s)\n", strerror(errno));
    }
  }
}

static void cuda_size_setup(struct futhark_context *ctx)
{
  struct futhark_context_config *cfg = ctx->cfg;
  if (cfg->gpu.default_block_size > ctx->max_thread_block_size) {
    if (cfg->gpu.default_block_size_changed) {
      fprintf(stderr,
              "Note: Device limits default block size to %zu (down from %zu).\n",
              ctx->max_thread_block_size, cfg->gpu.default_block_size);
    }
    cfg->gpu.default_block_size = ctx->max_thread_block_size;
  }
  if (cfg->gpu.default_grid_size > ctx->max_grid_size) {
    if (cfg->gpu.default_grid_size_changed) {
      fprintf(stderr,
              "Note: Device limits default grid size to %zu (down from %zu).\n",
              ctx->max_grid_size, cfg->gpu.default_grid_size);
    }
    cfg->gpu.default_grid_size = ctx->max_grid_size;
  }
  if (cfg->gpu.default_tile_size > ctx->max_tile_size) {
    if (cfg->gpu.default_tile_size_changed) {
      fprintf(stderr,
              "Note: Device limits default tile size to %zu (down from %zu).\n",
              ctx->max_tile_size, cfg->gpu.default_tile_size);
    }
    cfg->gpu.default_tile_size = ctx->max_tile_size;
  }

  if (!cfg->gpu.default_grid_size_changed) {
    cfg->gpu.default_grid_size =
      (device_query(ctx->dev, MULTIPROCESSOR_COUNT) *
       device_query(ctx->dev, MAX_THREADS_PER_MULTIPROCESSOR))
      / cfg->gpu.default_block_size;
  }

  for (int i = 0; i < cfg->num_tuning_params; i++) {
    const char *size_class = cfg->tuning_param_classes[i];
    int64_t *size_value = &cfg->tuning_params[i];
    const char* size_name = cfg->tuning_param_names[i];
    int64_t max_value = 0, default_value = 0;

    if (strstr(size_class, "thread_block_size") == size_class) {
      max_value = ctx->max_thread_block_size;
      default_value = cfg->gpu.default_block_size;
    } else if (strstr(size_class, "grid_size") == size_class) {
      max_value = ctx->max_grid_size;
      default_value = cfg->gpu.default_grid_size;
      // XXX: as a quick and dirty hack, use twice as many threads for
      // histograms by default.  We really should just be smarter
      // about sizes somehow.
      if (strstr(size_name, ".seghist_") != NULL) {
        default_value *= 2;
      }
    } else if (strstr(size_class, "tile_size") == size_class) {
      max_value = ctx->max_tile_size;
      default_value = cfg->gpu.default_tile_size;
    } else if (strstr(size_class, "reg_tile_size") == size_class) {
      max_value = 0; // No limit.
      default_value = cfg->gpu.default_reg_tile_size;
    } else if (strstr(size_class, "shared_memory") == size_class) {
      max_value = ctx->max_shared_memory;
      default_value = ctx->max_shared_memory;
    } else if (strstr(size_class, "cache") == size_class) {
      max_value = ctx->max_cache;
      default_value = ctx->max_cache;
    } else if (strstr(size_class, "threshold") == size_class) {
      // Threshold can be as large as it takes.
      default_value = cfg->gpu.default_threshold;
    } else {
      // Bespoke sizes have no limit or default.
    }

    if (*size_value == 0) {
      *size_value = default_value;
    } else if (max_value > 0 && *size_value > max_value) {
      fprintf(stderr, "Note: Device limits %s to %zu (down from %zu)\n",
              size_name, max_value, *size_value);
      *size_value = max_value;
    }
  }
}

static char* cuda_module_setup(struct futhark_context *ctx,
                               const char *src,
                               const char *extra_opts[],
                               const char* cache_fname) {
  char *ptx = NULL;
  struct futhark_context_config *cfg = ctx->cfg;

  if (cfg->load_ptx_from) {
    ptx = slurp_file(cfg->load_ptx_from, NULL);
  }

  char **opts;
  size_t n_opts;
  cuda_nvrtc_mk_build_options(ctx, extra_opts, &opts, &n_opts);

  if (cfg->logging) {
    fprintf(stderr, "NVRTC compile options:\n");
    for (size_t j = 0; j < n_opts; j++) {
      fprintf(stderr, "\t%s\n", opts[j]);
    }
    fprintf(stderr, "\n");
  }

  struct cache_hash h;
  int loaded_ptx_from_cache = 0;
  if (cache_fname != NULL) {
    cuda_load_ptx_from_cache(cfg, src, (const char**)opts, n_opts, &h, cache_fname, &ptx);

    if (ptx != NULL) {
      if (cfg->logging) {
        fprintf(stderr, "Restored PTX from cache; now loading module...\n");
      }
      if (cuModuleLoadData(&ctx->module, ptx) == CUDA_SUCCESS) {
        if (cfg->logging) {
          fprintf(stderr, "Success!\n");
        }
        loaded_ptx_from_cache = 1;
      } else {
        if (cfg->logging) {
          fprintf(stderr, "Failed!\n");
        }
        free(ptx);
        ptx = NULL;
      }
    }
  }

  if (ptx == NULL) {
    char* problem = cuda_nvrtc_build(src, (const char**)opts, n_opts, &ptx);
    if (problem != NULL) {
      return problem;
    }
  }

  if (cfg->dump_ptx_to != NULL) {
    dump_file(cfg->dump_ptx_to, ptx, strlen(ptx));
  }

  if (!loaded_ptx_from_cache) {
    CUDA_SUCCEED_FATAL(cuModuleLoadData(&ctx->module, ptx));
  }

  if (cache_fname != NULL && !loaded_ptx_from_cache) {
    if (cfg->logging) {
      fprintf(stderr, "Caching PTX in %s...\n", cache_fname);
    }
    errno = 0;
    if (cache_store(cache_fname, &h, (const unsigned char*)ptx, strlen(ptx)) != 0) {
      fprintf(stderr, "Failed to cache PTX: %s\n", strerror(errno));
    }
  }

  for (size_t i = 0; i < n_opts; i++) {
    free((char *)opts[i]);
  }
  free(opts);
  free(ptx);

  return NULL;
}

struct cuda_event {
  cudaEvent_t start;
  cudaEvent_t end;
};

static struct cuda_event* cuda_event_new(struct futhark_context* ctx) {
  if (ctx->profiling && !ctx->profiling_paused) {
    struct cuda_event* e = malloc(sizeof(struct cuda_event));
    cudaEventCreate(&e->start);
    cudaEventCreate(&e->end);
    return e;
  } else {
    return NULL;
  }
}

static int cuda_event_report(struct str_builder* sb, struct cuda_event* e) {
  float ms;
  CUresult err;
  if ((err = cuEventElapsedTime(&ms, e->start, e->end)) != CUDA_SUCCESS) {
    return err;
  }

  // CUDA provides milisecond resolution, but we want microseconds.
  str_builder(sb, ",\"duration\":%f", ms*1000);

  if ((err = cuEventDestroy(e->start)) != CUDA_SUCCESS) {
    return 1;
  }

  if ((err = cuEventDestroy(e->end)) != CUDA_SUCCESS) {
    return 1;
  }

  free(e);

  return 0;
}

int futhark_context_sync(struct futhark_context* ctx) {
  CUDA_SUCCEED_OR_RETURN(cuCtxPushCurrent(ctx->cu_ctx));
  CUDA_SUCCEED_OR_RETURN(cuCtxSynchronize());
  if (ctx->failure_is_an_option) {
    // Check for any delayed error.
    int32_t failure_idx;
    CUDA_SUCCEED_OR_RETURN(
                           cuMemcpyDtoH(&failure_idx,
                                        ctx->global_failure,
                                        sizeof(int32_t)));
    ctx->failure_is_an_option = 0;

    if (failure_idx >= 0) {
      // We have to clear global_failure so that the next entry point
      // is not considered a failure from the start.
      int32_t no_failure = -1;
      CUDA_SUCCEED_OR_RETURN(
                             cuMemcpyHtoD(ctx->global_failure,
                                          &no_failure,
                                          sizeof(int32_t)));

      int64_t args[max_failure_args+1];
      CUDA_SUCCEED_OR_RETURN(
                             cuMemcpyDtoH(&args,
                                          ctx->global_failure_args,
                                          sizeof(args)));

      ctx->error = get_failure_msg(failure_idx, args);

      return FUTHARK_PROGRAM_ERROR;
    }
  }

  CUDA_SUCCEED_OR_RETURN(cuCtxPopCurrent(&ctx->cu_ctx));
  return 0;
}

struct builtin_kernels* init_builtin_kernels(struct futhark_context* ctx);
void free_builtin_kernels(struct futhark_context* ctx, struct builtin_kernels* kernels);

int backend_context_setup(struct futhark_context* ctx) {
  ctx->failure_is_an_option = 0;
  ctx->total_runs = 0;
  ctx->total_runtime = 0;
  ctx->peak_mem_usage_device = 0;
  ctx->cur_mem_usage_device = 0;
  ctx->kernels = NULL;

  CUDA_SUCCEED_FATAL(cuInit(0));
  if (cuda_device_setup(ctx) != 0) {
    futhark_panic(-1, "No suitable CUDA device found.\n");
  }
  CUDA_SUCCEED_FATAL(cuCtxCreate(&ctx->cu_ctx, 0, ctx->dev));

  free_list_init(&ctx->gpu_free_list);

  if (ctx->cfg->unified_memory == 2) {
    ctx->cfg->unified_memory = device_query(ctx->dev, MANAGED_MEMORY);
  }

  if (ctx->cfg->logging) {
    if (ctx->cfg->unified_memory) {
      fprintf(ctx->log, "Using managed memory\n");
    } else {
      fprintf(ctx->log, "Using unmanaged memory\n");
    }
  }

  ctx->max_thread_block_size = device_query(ctx->dev, MAX_THREADS_PER_BLOCK);
  ctx->max_grid_size = device_query(ctx->dev, MAX_GRID_DIM_X);
  ctx->max_tile_size = sqrt(ctx->max_thread_block_size);
  ctx->max_threshold = 1U<<31; // No limit.
  ctx->max_bespoke = 1U<<31; // No limit.

  if (ctx->cfg->gpu.default_registers != 0) {
    ctx->max_registers = ctx->cfg->gpu.default_registers;
  } else {
    ctx->max_registers = device_query(ctx->dev, MAX_REGISTERS_PER_BLOCK);
  }

  if (ctx->cfg->gpu.default_shared_memory != 0) {
    ctx->max_shared_memory = ctx->cfg->gpu.default_shared_memory;
  } else {
    // MAX_SHARED_MEMORY_PER_BLOCK gives bogus numbers (48KiB); probably
    // for backwards compatibility.  Add _OPTIN and you seem to get the
    // right number.
    ctx->max_shared_memory = device_query(ctx->dev, MAX_SHARED_MEMORY_PER_BLOCK_OPTIN);
#if CUDART_VERSION >= 12000
    ctx->max_shared_memory -= device_query(ctx->dev, RESERVED_SHARED_MEMORY_PER_BLOCK);
#endif
  }

  if (ctx->cfg->gpu.default_cache != 0) {
    ctx->max_cache = ctx->cfg->gpu.default_cache;
  } else {
    ctx->max_cache = device_query(ctx->dev, L2_CACHE_SIZE);
  }

  ctx->lockstep_width = device_query(ctx->dev, WARP_SIZE);
  CUDA_SUCCEED_FATAL(cuStreamCreate(&ctx->stream, CU_STREAM_DEFAULT));
  cuda_size_setup(ctx);

  gpu_init_log(ctx);

  ctx->error = cuda_module_setup(ctx,
                                 ctx->cfg->program,
                                 (const char**)ctx->cfg->nvrtc_opts,
                                 ctx->cfg->cache_fname);

  if (ctx->error != NULL) {
    futhark_panic(1, "During CUDA initialisation:\n%s\n", ctx->error);
  }

  int32_t no_error = -1;
  CUDA_SUCCEED_FATAL(cuMemAlloc(&ctx->global_failure, sizeof(no_error)));
  CUDA_SUCCEED_FATAL(cuMemcpyHtoD(ctx->global_failure, &no_error, sizeof(no_error)));
  // The +1 is to avoid zero-byte allocations.
  CUDA_SUCCEED_FATAL(cuMemAlloc(&ctx->global_failure_args, sizeof(int64_t)*(max_failure_args+1)));

  if ((ctx->kernels = init_builtin_kernels(ctx)) == NULL) {
    return 1;
  }

  return 0;
}

void backend_context_teardown(struct futhark_context* ctx) {
  if (ctx->kernels != NULL) {
    free_builtin_kernels(ctx, ctx->kernels);
    cuMemFree(ctx->global_failure);
    cuMemFree(ctx->global_failure_args);
    CUDA_SUCCEED_FATAL(gpu_free_all(ctx));
    CUDA_SUCCEED_FATAL(cuStreamDestroy(ctx->stream));
    CUDA_SUCCEED_FATAL(cuModuleUnload(ctx->module));
    CUDA_SUCCEED_FATAL(cuCtxDestroy(ctx->cu_ctx));
  }
  free_list_destroy(&ctx->gpu_free_list);
}

// GPU ABSTRACTION LAYER

// Types.

typedef CUfunction gpu_kernel;
typedef CUdeviceptr gpu_mem;

static void gpu_create_kernel(struct futhark_context *ctx,
                              gpu_kernel* kernel,
                              const char* name) {
  if (ctx->debugging) {
    fprintf(ctx->log, "Creating kernel %s.\n", name);
  }
  CUDA_SUCCEED_FATAL(cuModuleGetFunction(kernel, ctx->module, name));
  // Unless the below is set, the kernel is limited to 48KiB of memory.
  CUDA_SUCCEED_FATAL(cuFuncSetAttribute(*kernel,
                                        cudaFuncAttributeMaxDynamicSharedMemorySize,
                                        ctx->max_shared_memory));
}

static void gpu_free_kernel(struct futhark_context *ctx,
                            gpu_kernel kernel) {
  (void)ctx;
  (void)kernel;
}

static int gpu_scalar_to_device(struct futhark_context* ctx,
                                gpu_mem dst, size_t offset, size_t size,
                                void *src) {
  struct cuda_event *event = cuda_event_new(ctx);
  if (event != NULL) {
    add_event(ctx,
              "copy_scalar_to_dev",
              strdup(""),
              event,
              (event_report_fn)cuda_event_report);
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
  }
  CUDA_SUCCEED_OR_RETURN(cuMemcpyHtoD(dst + offset, src, size));
  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }
  return FUTHARK_SUCCESS;
}

static int gpu_scalar_from_device(struct futhark_context* ctx,
                                  void *dst,
                                  gpu_mem src, size_t offset, size_t size) {
  struct cuda_event *event = cuda_event_new(ctx);
  if (event != NULL) {
    add_event(ctx,
              "copy_scalar_from_dev",
              strdup(""),
              event,
              (event_report_fn)cuda_event_report);
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
  }
  CUDA_SUCCEED_OR_RETURN(cuMemcpyDtoH(dst, src + offset, size));
  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }
  return FUTHARK_SUCCESS;
}

static int gpu_memcpy(struct futhark_context* ctx,
                      gpu_mem dst, int64_t dst_offset,
                      gpu_mem src, int64_t src_offset,
                      int64_t nbytes) {
  struct cuda_event *event = cuda_event_new(ctx);
  if (event != NULL) {
    add_event(ctx,
              "copy_dev_to_dev",
              strdup(""),
              event,
              (event_report_fn)cuda_event_report);
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
  }
  CUDA_SUCCEED_OR_RETURN(cuMemcpyAsync(dst+dst_offset, src+src_offset, nbytes, ctx->stream));
  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }
  return FUTHARK_SUCCESS;
}

static int memcpy_host2gpu(struct futhark_context* ctx, bool sync,
                           gpu_mem dst, int64_t dst_offset,
                           const unsigned char* src, int64_t src_offset,
                           int64_t nbytes) {
  if (nbytes > 0) {
    struct cuda_event *event = cuda_event_new(ctx);
    if (event != NULL) {
      add_event(ctx,
                "copy_host_to_dev",
                strdup(""),
                event,
                (event_report_fn)cuda_event_report);
      CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
    }
    if (sync) {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyHtoD(dst + dst_offset, src + src_offset, nbytes));
    } else {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyHtoDAsync(dst + dst_offset, src + src_offset, nbytes, ctx->stream));
    }
    if (event != NULL) {
      CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
    }
  }
  return FUTHARK_SUCCESS;
}

static int memcpy_gpu2host(struct futhark_context* ctx, bool sync,
                           unsigned char* dst, int64_t dst_offset,
                           gpu_mem src, int64_t src_offset,
                           int64_t nbytes) {
  if (nbytes > 0) {
    struct cuda_event *event = cuda_event_new(ctx);
    if (event != NULL) {
      add_event(ctx,
                "copy_dev_to_host",
                strdup(""),
                event,
                (event_report_fn)cuda_event_report);
      CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
    }
    if (sync) {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyDtoH(dst + dst_offset, src + src_offset, nbytes));
    } else {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyDtoHAsync(dst + dst_offset, src + src_offset, nbytes, ctx->stream));
    }
    if (event != NULL) {
      CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
    }
    if (sync &&
        ctx->failure_is_an_option &&
        futhark_context_sync(ctx) != 0) {
      return 1;
    }
  }
  return FUTHARK_SUCCESS;
}

static int gpu_launch_kernel(struct futhark_context* ctx,
                             gpu_kernel kernel, const char *name,
                             const int32_t grid[3],
                             const int32_t block[3],
                             unsigned int shared_mem_bytes,
                             int num_args,
                             void* args[num_args],
                             size_t args_sizes[num_args]) {
  (void) args_sizes;

  if (shared_mem_bytes > ctx->max_shared_memory) {
    set_error(ctx, msgprintf("Kernel %s with %d bytes of memory exceeds device limit of %d\n",
                             name, shared_mem_bytes, (int)ctx->max_shared_memory));
    return 1;
  }

  int64_t time_start = 0, time_end = 0;
  if (ctx->debugging) {
    time_start = get_wall_time();
  }

  struct cuda_event *event = cuda_event_new(ctx);

  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
    add_event(ctx,
              name,
              msgprintf("Kernel %s with\n"
                        "  grid=(%d,%d,%d)\n"
                        "  block=(%d,%d,%d)\n"
                        "  shared memory=%d",
                        name,
                        grid[0], grid[1], grid[2],
                        block[0], block[1], block[2],
                        shared_mem_bytes),
              event,
              (event_report_fn)cuda_event_report);
  }

  CUDA_SUCCEED_OR_RETURN
    (cuLaunchKernel(kernel,
                    grid[0], grid[1], grid[2],
                    block[0], block[1], block[2],
                    shared_mem_bytes, ctx->stream,
                    args, NULL));

  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }

  if (ctx->debugging) {
    CUDA_SUCCEED_FATAL(cuCtxSynchronize());
    time_end = get_wall_time();
    long int time_diff = time_end - time_start;
    fprintf(ctx->log, "  runtime: %ldus\n", time_diff);
  }
  if (ctx->logging) {
    fprintf(ctx->log, "\n");
  }

  return FUTHARK_SUCCESS;
}

static int gpu_alloc_actual(struct futhark_context *ctx, size_t size, gpu_mem *mem_out) {
  CUresult res;
  if (ctx->cfg->unified_memory) {
    res = cuMemAllocManaged(mem_out, size, CU_MEM_ATTACH_GLOBAL);
  } else {
    res = cuMemAlloc(mem_out, size);
  }

  if (res == CUDA_ERROR_OUT_OF_MEMORY) {
    return FUTHARK_OUT_OF_MEMORY;
  }

  CUDA_SUCCEED_OR_RETURN(res);
  return FUTHARK_SUCCESS;
}

static int gpu_free_actual(struct futhark_context *ctx, gpu_mem mem) {
  (void)ctx;
  CUDA_SUCCEED_OR_RETURN(cuMemFree(mem));
  return FUTHARK_SUCCESS;
}

// End of backends/cuda.h.

// Start of gpu.h

// Generic functions that use our tiny GPU abstraction layer.  The
// entire context must be defined before this header is included.  In
// particular we expect the following functions to be available:

static int gpu_free_actual(struct futhark_context *ctx, gpu_mem mem);
static int gpu_alloc_actual(struct futhark_context *ctx, size_t size, gpu_mem *mem_out);
int gpu_launch_kernel(struct futhark_context* ctx,
                      gpu_kernel kernel, const char *name,
                      const int32_t grid[3],
                      const int32_t block[3],
                      unsigned int shared_mem_bytes,
                      int num_args,
                      void* args[num_args],
                      size_t args_sizes[num_args]);
int gpu_memcpy(struct futhark_context* ctx,
               gpu_mem dst, int64_t dst_offset,
               gpu_mem src, int64_t src_offset,
               int64_t nbytes);
int gpu_scalar_from_device(struct futhark_context* ctx,
                           void *dst,
                           gpu_mem src, size_t offset, size_t size);
int gpu_scalar_to_device(struct futhark_context* ctx,
                         gpu_mem dst, size_t offset, size_t size,
                         void *src);
void gpu_create_kernel(struct futhark_context *ctx,
                       gpu_kernel* kernel,
                       const char* name);

static void gpu_init_log(struct futhark_context *ctx) {
  if (ctx->cfg->logging) {
    fprintf(ctx->log, "Default block size: %ld\n", (long)ctx->cfg->gpu.default_block_size);
    fprintf(ctx->log, "Default grid size: %ld\n", (long)ctx->cfg->gpu.default_grid_size);
    fprintf(ctx->log, "Default tile size: %ld\n", (long)ctx->cfg->gpu.default_tile_size);
    fprintf(ctx->log, "Default register tile size: %ld\n", (long)ctx->cfg->gpu.default_reg_tile_size);
    fprintf(ctx->log, "Default cache: %ld\n", (long)ctx->cfg->gpu.default_cache);
    fprintf(ctx->log, "Default registers: %ld\n", (long)ctx->cfg->gpu.default_registers);
    fprintf(ctx->log, "Default threshold: %ld\n", (long)ctx->cfg->gpu.default_threshold);
    fprintf(ctx->log, "Max thread block size: %ld\n", (long)ctx->max_thread_block_size);
    fprintf(ctx->log, "Max grid size: %ld\n", (long)ctx->max_grid_size);
    fprintf(ctx->log, "Max tile size: %ld\n", (long)ctx->max_tile_size);
    fprintf(ctx->log, "Max threshold: %ld\n", (long)ctx->max_threshold);
    fprintf(ctx->log, "Max shared memory: %ld\n", (long)ctx->max_shared_memory);
    fprintf(ctx->log, "Max registers: %ld\n", (long)ctx->max_registers);
    fprintf(ctx->log, "Max cache: %ld\n", (long)ctx->max_cache);
    fprintf(ctx->log, "Lockstep width: %ld\n", (long)ctx->lockstep_width);
  }
}

// Generic GPU command line options.

void futhark_context_config_set_default_thread_block_size(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_block_size = size;
  cfg->gpu.default_block_size_changed = 1;
}

void futhark_context_config_set_default_group_size(struct futhark_context_config *cfg, int size) {
  futhark_context_config_set_default_thread_block_size(cfg, size);
}

void futhark_context_config_set_default_grid_size(struct futhark_context_config *cfg, int num) {
  cfg->gpu.default_grid_size = num;
  cfg->gpu.default_grid_size_changed = 1;
}

void futhark_context_config_set_default_num_groups(struct futhark_context_config *cfg, int num) {
  futhark_context_config_set_default_grid_size(cfg, num);
}

void futhark_context_config_set_default_tile_size(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_tile_size = size;
  cfg->gpu.default_tile_size_changed = 1;
}

void futhark_context_config_set_default_reg_tile_size(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_reg_tile_size = size;
}

void futhark_context_config_set_default_cache(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_cache = size;
}

void futhark_context_config_set_default_registers(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_registers = size;
}

void futhark_context_config_set_default_threshold(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_threshold = size;
}

int futhark_context_config_set_tuning_param(struct futhark_context_config *cfg,
                                            const char *param_name,
                                            size_t new_value) {
  for (int i = 0; i < cfg->num_tuning_params; i++) {
    if (strcmp(param_name, cfg->tuning_param_names[i]) == 0) {
      cfg->tuning_params[i] = new_value;
      return 0;
    }
  }
  if (strcmp(param_name, "default_thread_block_size") == 0 ||
      strcmp(param_name, "default_group_size") == 0) {
    cfg->gpu.default_block_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_grid_size") == 0 ||
      strcmp(param_name, "default_num_groups") == 0) {
    cfg->gpu.default_grid_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_threshold") == 0) {
    cfg->gpu.default_threshold = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_tile_size") == 0) {
    cfg->gpu.default_tile_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_reg_tile_size") == 0) {
    cfg->gpu.default_reg_tile_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_cache") == 0) {
    cfg->gpu.default_cache = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_shared_memory") == 0) {
    cfg->gpu.default_shared_memory = new_value;
    return 0;
  }

  return 1;
}

// End of GPU command line optiopns.

// Max number of thead blocks we allow along the second or third
// dimension for transpositions.
#define MAX_TR_THREAD_BLOCKS 65535

struct builtin_kernels {
  // We have a lot of ways to transpose arrays.
  gpu_kernel map_transpose_1b;
  gpu_kernel map_transpose_1b_low_height;
  gpu_kernel map_transpose_1b_low_width;
  gpu_kernel map_transpose_1b_small;
  gpu_kernel map_transpose_1b_large;
  gpu_kernel map_transpose_2b;
  gpu_kernel map_transpose_2b_low_height;
  gpu_kernel map_transpose_2b_low_width;
  gpu_kernel map_transpose_2b_small;
  gpu_kernel map_transpose_2b_large;
  gpu_kernel map_transpose_4b;
  gpu_kernel map_transpose_4b_low_height;
  gpu_kernel map_transpose_4b_low_width;
  gpu_kernel map_transpose_4b_small;
  gpu_kernel map_transpose_4b_large;
  gpu_kernel map_transpose_8b;
  gpu_kernel map_transpose_8b_low_height;
  gpu_kernel map_transpose_8b_low_width;
  gpu_kernel map_transpose_8b_small;
  gpu_kernel map_transpose_8b_large;

  // And a few ways of copying.
  gpu_kernel lmad_copy_1b;
  gpu_kernel lmad_copy_2b;
  gpu_kernel lmad_copy_4b;
  gpu_kernel lmad_copy_8b;
};

struct builtin_kernels* init_builtin_kernels(struct futhark_context* ctx) {
  struct builtin_kernels *kernels = malloc(sizeof(struct builtin_kernels));
  gpu_create_kernel(ctx, &kernels->map_transpose_1b, "map_transpose_1b");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_large, "map_transpose_1b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_low_height, "map_transpose_1b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_low_width, "map_transpose_1b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_small, "map_transpose_1b_small");

  gpu_create_kernel(ctx, &kernels->map_transpose_2b, "map_transpose_2b");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_large, "map_transpose_2b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_low_height, "map_transpose_2b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_low_width, "map_transpose_2b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_small, "map_transpose_2b_small");

  gpu_create_kernel(ctx, &kernels->map_transpose_4b, "map_transpose_4b");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_large, "map_transpose_4b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_low_height, "map_transpose_4b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_low_width, "map_transpose_4b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_small, "map_transpose_4b_small");

  gpu_create_kernel(ctx, &kernels->map_transpose_8b, "map_transpose_8b");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_large, "map_transpose_8b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_low_height, "map_transpose_8b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_low_width, "map_transpose_8b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_small, "map_transpose_8b_small");

  gpu_create_kernel(ctx, &kernels->lmad_copy_1b, "lmad_copy_1b");
  gpu_create_kernel(ctx, &kernels->lmad_copy_2b, "lmad_copy_2b");
  gpu_create_kernel(ctx, &kernels->lmad_copy_4b, "lmad_copy_4b");
  gpu_create_kernel(ctx, &kernels->lmad_copy_8b, "lmad_copy_8b");

  return kernels;
}

void free_builtin_kernels(struct futhark_context* ctx, struct builtin_kernels* kernels) {
  gpu_free_kernel(ctx, kernels->map_transpose_1b);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_small);

  gpu_free_kernel(ctx, kernels->map_transpose_2b);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_small);

  gpu_free_kernel(ctx, kernels->map_transpose_4b);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_small);

  gpu_free_kernel(ctx, kernels->map_transpose_8b);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_small);

  gpu_free_kernel(ctx, kernels->lmad_copy_1b);
  gpu_free_kernel(ctx, kernels->lmad_copy_2b);
  gpu_free_kernel(ctx, kernels->lmad_copy_4b);
  gpu_free_kernel(ctx, kernels->lmad_copy_8b);

  free(kernels);
}

static int gpu_alloc(struct futhark_context *ctx, FILE *log,
                     size_t min_size, const char *tag,
                     gpu_mem *mem_out, size_t *size_out) {
  if (min_size < sizeof(int)) {
    min_size = sizeof(int);
  }

  gpu_mem* memptr;
  if (free_list_find(&ctx->gpu_free_list, min_size, tag, size_out, (fl_mem*)&memptr) == 0) {
    // Successfully found a free block.  Is it big enough?
    if (*size_out >= min_size) {
      if (ctx->cfg->debugging) {
        fprintf(log, "No need to allocate: Found a block in the free list.\n");
      }
      *mem_out = *memptr;
      free(memptr);
      return FUTHARK_SUCCESS;
    } else {
      if (ctx->cfg->debugging) {
        fprintf(log, "Found a free block, but it was too small.\n");
      }
      int error = gpu_free_actual(ctx, *memptr);
      free(memptr);
      if (error != FUTHARK_SUCCESS) {
        return error;
      }
    }
  }

  *size_out = min_size;

  // We have to allocate a new block from the driver.  If the
  // allocation does not succeed, then we might be in an out-of-memory
  // situation.  We now start freeing things from the free list until
  // we think we have freed enough that the allocation will succeed.
  // Since we don't know how far the allocation is from fitting, we
  // have to check after every deallocation.  This might be pretty
  // expensive.  Let's hope that this case is hit rarely.

  if (ctx->cfg->debugging) {
    fprintf(log, "Actually allocating the desired block.\n");
  }

  int error = gpu_alloc_actual(ctx, min_size, mem_out);

  while (error == FUTHARK_OUT_OF_MEMORY) {
    if (ctx->cfg->debugging) {
      fprintf(log, "Out of GPU memory: releasing entry from the free list...\n");
    }
    gpu_mem* memptr;
    if (free_list_first(&ctx->gpu_free_list, (fl_mem*)&memptr) == 0) {
      gpu_mem mem = *memptr;
      free(memptr);
      error = gpu_free_actual(ctx, mem);
      if (error != FUTHARK_SUCCESS) {
        return error;
      }
    } else {
      break;
    }
    error = gpu_alloc_actual(ctx, min_size, mem_out);
  }

  return error;
}

static int gpu_free(struct futhark_context *ctx,
                    gpu_mem mem, size_t size, const char *tag) {
  gpu_mem* memptr = malloc(sizeof(gpu_mem));
  *memptr = mem;
  free_list_insert(&ctx->gpu_free_list, size, (fl_mem)memptr, tag);
  return FUTHARK_SUCCESS;
}

static int gpu_free_all(struct futhark_context *ctx) {
  free_list_pack(&ctx->gpu_free_list);
  gpu_mem* memptr;
  while (free_list_first(&ctx->gpu_free_list, (fl_mem*)&memptr) == 0) {
    gpu_mem mem = *memptr;
    free(memptr);
    int error = gpu_free_actual(ctx, mem);
    if (error != FUTHARK_SUCCESS) {
      return error;
    }
  }

  return FUTHARK_SUCCESS;
}

static int gpu_map_transpose(struct futhark_context* ctx,
                             gpu_kernel kernel_default,
                             gpu_kernel kernel_low_height,
                             gpu_kernel kernel_low_width,
                             gpu_kernel kernel_small,
                             gpu_kernel kernel_large,
                             const char *name, size_t elem_size,
                             gpu_mem dst, int64_t dst_offset,
                             gpu_mem src, int64_t src_offset,
                             int64_t k, int64_t n, int64_t m) {
  int64_t mulx = TR_BLOCK_DIM / n;
  int64_t muly = TR_BLOCK_DIM / m;
  int32_t mulx32 = mulx;
  int32_t muly32 = muly;
  int32_t k32 = k;
  int32_t n32 = n;
  int32_t m32 = m;

  gpu_kernel kernel = kernel_default;
  int32_t grid[3];
  int32_t block[3];

  void* args[11];
  size_t args_sizes[11] = {
    sizeof(gpu_mem), sizeof(int64_t),
    sizeof(gpu_mem), sizeof(int64_t),
    sizeof(int32_t),
    sizeof(int32_t),
    sizeof(int32_t),
    sizeof(int32_t),
    sizeof(int32_t)
  };

  args[0] = &dst;
  args[1] = &dst_offset;
  args[2] = &src;
  args[3] = &src_offset;
  args[7] = &mulx;
  args[8] = &muly;

  if (dst_offset + k * n * m <= 2147483647L &&
      src_offset + k * n * m <= 2147483647L) {
    if (m <= TR_BLOCK_DIM/2 && n <= TR_BLOCK_DIM/2) {
      if (ctx->logging) { fprintf(ctx->log, "Using small kernel\n"); }
      kernel = kernel_small;
      grid[0] = ((k * n * m) + (TR_BLOCK_DIM*TR_BLOCK_DIM) - 1) / (TR_BLOCK_DIM*TR_BLOCK_DIM);
      grid[1] = 1;
      grid[2] = 1;
      block[0] = TR_BLOCK_DIM*TR_BLOCK_DIM;
      block[1] = 1;
      block[2] = 1;
    } else if (m <= TR_BLOCK_DIM/2 && TR_BLOCK_DIM < n) {
      if (ctx->logging) { fprintf(ctx->log, "Using low-width kernel\n"); }
      kernel = kernel_low_width;
      int64_t x_elems = m;
      int64_t y_elems = (n + muly - 1) / muly;
      grid[0] = (x_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[1] = (y_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[2] = k;
      block[0] = TR_BLOCK_DIM;
      block[1] = TR_BLOCK_DIM;
      block[2] = 1;
    } else if (n <= TR_BLOCK_DIM/2 && TR_BLOCK_DIM < m) {
      if (ctx->logging) { fprintf(ctx->log, "Using low-height kernel\n"); }
      kernel = kernel_low_height;
      int64_t x_elems = (m + mulx - 1) / mulx;
      int64_t y_elems = n;
      grid[0] = (x_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[1] = (y_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[2] = k;
      block[0] = TR_BLOCK_DIM;
      block[1] = TR_BLOCK_DIM;
      block[2] = 1;
    } else {
      if (ctx->logging) { fprintf(ctx->log, "Using default kernel\n"); }
      kernel = kernel_default;
      grid[0] = (m+TR_TILE_DIM-1)/TR_TILE_DIM;
      grid[1] = (n+TR_TILE_DIM-1)/TR_TILE_DIM;
      grid[2] = k;
      block[0] = TR_TILE_DIM;
      block[1] = TR_TILE_DIM/TR_ELEMS_PER_THREAD;
      block[2] = 1;
    }
    args[4] = &k32;
    args[5] = &m32;
    args[6] = &n32;
    args[7] = &mulx32;
    args[8] = &muly32;
  } else {
    if (ctx->logging) { fprintf(ctx->log, "Using large kernel\n"); }
    kernel = kernel_large;
    grid[0] = (m+TR_TILE_DIM-1)/TR_TILE_DIM;
    grid[1] = (n+TR_TILE_DIM-1)/TR_TILE_DIM;
    grid[2] = k;
    block[0] = TR_TILE_DIM;
    block[1] = TR_TILE_DIM/TR_ELEMS_PER_THREAD;
    block[2] = 1;
    args[4] = &k;
    args[5] = &m;
    args[6] = &n;
    args[7] = &mulx;
    args[8] = &muly;
    args_sizes[4] = sizeof(int64_t);
    args_sizes[5] = sizeof(int64_t);
    args_sizes[6] = sizeof(int64_t);
    args_sizes[7] = sizeof(int64_t);
    args_sizes[8] = sizeof(int64_t);
  }

  // Cap the number of thead blocks we launch and figure out how many
  // repeats we need alongside each dimension.
  int32_t repeat_1 = grid[1] / MAX_TR_THREAD_BLOCKS;
  int32_t repeat_2 = grid[2] / MAX_TR_THREAD_BLOCKS;
  grid[1] = repeat_1 > 0 ? MAX_TR_THREAD_BLOCKS : grid[1];
  grid[2] = repeat_2 > 0 ? MAX_TR_THREAD_BLOCKS : grid[2];
  args[9] = &repeat_1;
  args[10] = &repeat_2;
  args_sizes[9] = sizeof(repeat_1);
  args_sizes[10] = sizeof(repeat_2);

  if (ctx->logging) {
    fprintf(ctx->log, "\n");
  }

  return gpu_launch_kernel(ctx, kernel, name, grid, block,
                           TR_TILE_DIM*(TR_TILE_DIM+1)*elem_size,
                           sizeof(args)/sizeof(args[0]), args, args_sizes);
}

#define GEN_MAP_TRANSPOSE_GPU2GPU(NAME, ELEM_TYPE)                      \
  static int map_transpose_gpu2gpu_##NAME                               \
  (struct futhark_context* ctx,                                         \
   gpu_mem dst, int64_t dst_offset,                                     \
   gpu_mem src, int64_t src_offset,                                     \
   int64_t k, int64_t m, int64_t n)                                     \
  {                                                                     \
    return                                                              \
      gpu_map_transpose                                                 \
      (ctx,                                                             \
       ctx->kernels->map_transpose_##NAME,                              \
       ctx->kernels->map_transpose_##NAME##_low_height,                 \
       ctx->kernels->map_transpose_##NAME##_low_width,                  \
       ctx->kernels->map_transpose_##NAME##_small,                      \
       ctx->kernels->map_transpose_##NAME##_large,                      \
       "map_transpose_" #NAME, sizeof(ELEM_TYPE),                       \
       dst, dst_offset, src, src_offset,                                \
       k, n, m);                                                        \
  }

static int gpu_lmad_copy(struct futhark_context* ctx,
                         gpu_kernel kernel, int r,
                         gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],
                         gpu_mem src, int64_t src_offset, int64_t src_strides[r],
                         int64_t shape[r]) {
  if (r > 8) {
    set_error(ctx, strdup("Futhark runtime limitation:\nCannot copy array of greater than rank 8.\n"));
    return 1;
  }

  int64_t n = 1;
  for (int i = 0; i < r; i++) { n *= shape[i]; }

  void* args[6+(8*3)];
  size_t args_sizes[6+(8*3)];

  args[0] = &dst;
  args_sizes[0] = sizeof(gpu_mem);
  args[1] = &dst_offset;
  args_sizes[1] = sizeof(dst_offset);
  args[2] = &src;
  args_sizes[2] = sizeof(gpu_mem);
  args[3] = &src_offset;
  args_sizes[3] = sizeof(src_offset);
  args[4] = &n;
  args_sizes[4] = sizeof(n);
  args[5] = &r;
  args_sizes[5] = sizeof(r);

  int64_t zero = 0;

  for (int i = 0; i < 8; i++) {
    args_sizes[6+i*3] = sizeof(int64_t);
    args_sizes[6+i*3+1] = sizeof(int64_t);
    args_sizes[6+i*3+2] = sizeof(int64_t);
    if (i < r) {
      args[6+i*3] = &shape[i];
      args[6+i*3+1] = &dst_strides[i];
      args[6+i*3+2] = &src_strides[i];
    } else {
      args[6+i*3] = &zero;
      args[6+i*3+1] = &zero;
      args[6+i*3+2] = &zero;
    }
  }
  const size_t w = 256; // XXX: hardcoded thread block size.

  return gpu_launch_kernel(ctx, kernel, "copy_lmad_dev_to_dev",
                           (const int32_t[3]) {(n+w-1)/w,1,1},
                           (const int32_t[3]) {w,1,1},
                           0, 6+(8*3), args, args_sizes);
}

#define GEN_LMAD_COPY_ELEMENTS_GPU2GPU(NAME, ELEM_TYPE)                 \
  static int lmad_copy_elements_gpu2gpu_##NAME                          \
  (struct futhark_context* ctx,                                         \
   int r,                                                               \
   gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],             \
   gpu_mem src, int64_t src_offset, int64_t src_strides[r],             \
   int64_t shape[r]) {                                                  \
    return gpu_lmad_copy(ctx, ctx->kernels->lmad_copy_##NAME, r,        \
                         dst, dst_offset, dst_strides,                  \
                         src, src_offset, src_strides,                  \
                         shape);                                        \
  }                                                                     \

#define GEN_LMAD_COPY_GPU2GPU(NAME, ELEM_TYPE)                          \
  static int lmad_copy_gpu2gpu_##NAME                                   \
  (struct futhark_context* ctx,                                         \
   int r,                                                               \
   gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],             \
   gpu_mem src, int64_t src_offset, int64_t src_strides[r],             \
   int64_t shape[r]) {                                                  \
    log_copy(ctx, "GPU to GPU", r, dst_offset, dst_strides,             \
             src_offset, src_strides, shape);                           \
    int64_t size = 1;                                                   \
    for (int i = 0; i < r; i++) { size *= shape[i]; }                   \
    if (size == 0) { return FUTHARK_SUCCESS; }                          \
    int64_t k, n, m;                                                    \
    if (lmad_map_tr(&k, &n, &m,                                         \
                       r, dst_strides, src_strides, shape)) {           \
      log_transpose(ctx, k, n, m);                                      \
      return map_transpose_gpu2gpu_##NAME                               \
        (ctx, dst, dst_offset, src, src_offset, k, n, m);               \
    } else if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {   \
      if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}        \
      return gpu_memcpy(ctx,                                            \
                        dst, dst_offset*sizeof(ELEM_TYPE),              \
                        src, src_offset*sizeof(ELEM_TYPE),              \
                        size * sizeof(ELEM_TYPE));                      \
    } else {                                                            \
      if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}     \
      return lmad_copy_elements_gpu2gpu_##NAME                          \
        (ctx, r,                                                        \
         dst, dst_offset, dst_strides,                                  \
         src, src_offset, src_strides,                                  \
         shape);                                                        \
    }                                                                   \
  }

static int
lmad_copy_elements_host2gpu(struct futhark_context *ctx, size_t elem_size,
                            int r,
                            gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],
                            unsigned char* src, int64_t src_offset, int64_t src_strides[r],
                            int64_t shape[r]) {
  (void)ctx; (void)elem_size; (void)r;
  (void)dst; (void)dst_offset; (void)dst_strides;
  (void)src; (void)src_offset; (void)src_strides;
  (void)shape;
  set_error(ctx, strdup("Futhark runtime limitation:\nCannot copy unstructured array from host to GPU.\n"));
  return 1;
}

static int
lmad_copy_elements_gpu2host (struct futhark_context *ctx, size_t elem_size,
                             int r,
                             unsigned char* dst, int64_t dst_offset, int64_t dst_strides[r],
                             gpu_mem src, int64_t src_offset, int64_t src_strides[r],
                             int64_t shape[r]) {
  (void)ctx; (void)elem_size; (void)r;
  (void)dst; (void)dst_offset; (void)dst_strides;
  (void)src; (void)src_offset; (void)src_strides;
  (void)shape;
  set_error(ctx, strdup("Futhark runtime limitation:\nCannot copy unstructured array from GPU to host.\n"));
  return 1;
}

#define GEN_LMAD_COPY_ELEMENTS_HOSTGPU(NAME, ELEM_TYPE)                 \
  static int lmad_copy_elements_gpu2gpu_##NAME                          \
  (struct futhark_context* ctx,                                         \
   int r,                                                               \
   gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],             \
   gpu_mem src, int64_t src_offset, int64_t src_strides[r],             \
   int64_t shape[r]) {                                                  \
    return (ctx, ctx->kernels->lmad_copy_##NAME, r,                     \
                         dst, dst_offset, dst_strides,                  \
                         src, src_offset, src_strides,                  \
                         shape);                                        \
  }                                                                     \


static int lmad_copy_host2gpu(struct futhark_context* ctx, size_t elem_size, bool sync,
                              int r,
                              gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],
                              unsigned char* src, int64_t src_offset, int64_t src_strides[r],
                              int64_t shape[r]) {
  log_copy(ctx, "Host to GPU", r, dst_offset, dst_strides,
           src_offset, src_strides, shape);
  int64_t size = elem_size;
  for (int i = 0; i < r; i++) { size *= shape[i]; }
  if (size == 0) { return FUTHARK_SUCCESS; }
  int64_t k, n, m;
  if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {
    if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}
    return memcpy_host2gpu(ctx, sync,
                           dst, dst_offset*elem_size,
                           src, src_offset*elem_size,
                           size);
  } else {
    if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}
    int error;
    error = lmad_copy_elements_host2gpu
      (ctx, elem_size, r,
       dst, dst_offset, dst_strides,
       src, src_offset, src_strides,
       shape);
    if (error == 0 && sync) {
      error = futhark_context_sync(ctx);
    }
    return error;
  }
}

static int lmad_copy_gpu2host(struct futhark_context* ctx, size_t elem_size, bool sync,
                              int r,
                              unsigned char* dst, int64_t dst_offset, int64_t dst_strides[r],
                              gpu_mem src, int64_t src_offset, int64_t src_strides[r],
                              int64_t shape[r]) {
  log_copy(ctx, "Host to GPU", r, dst_offset, dst_strides,
           src_offset, src_strides, shape);
  int64_t size = elem_size;
  for (int i = 0; i < r; i++) { size *= shape[i]; }
  if (size == 0) { return FUTHARK_SUCCESS; }
  int64_t k, n, m;
  if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {
    if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}
    return memcpy_gpu2host(ctx, sync,
                           dst, dst_offset*elem_size,
                           src, src_offset*elem_size,
                           size);
  } else {
    if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}
    int error;
    error = lmad_copy_elements_gpu2host
      (ctx, elem_size, r,
       dst, dst_offset, dst_strides,
       src, src_offset, src_strides,
       shape);
    if (error == 0 && sync) {
      error = futhark_context_sync(ctx);
    }
    return error;
  }
}

GEN_MAP_TRANSPOSE_GPU2GPU(1b, uint8_t)
GEN_MAP_TRANSPOSE_GPU2GPU(2b, uint16_t)
GEN_MAP_TRANSPOSE_GPU2GPU(4b, uint32_t)
GEN_MAP_TRANSPOSE_GPU2GPU(8b, uint64_t)

GEN_LMAD_COPY_ELEMENTS_GPU2GPU(1b, uint8_t)
GEN_LMAD_COPY_ELEMENTS_GPU2GPU(2b, uint16_t)
GEN_LMAD_COPY_ELEMENTS_GPU2GPU(4b, uint32_t)
GEN_LMAD_COPY_ELEMENTS_GPU2GPU(8b, uint64_t)

GEN_LMAD_COPY_GPU2GPU(1b, uint8_t)
GEN_LMAD_COPY_GPU2GPU(2b, uint16_t)
GEN_LMAD_COPY_GPU2GPU(4b, uint32_t)
GEN_LMAD_COPY_GPU2GPU(8b, uint64_t)

// End of gpu.h

static int gpu_macros(struct futhark_context *ctx, char ***names_out, int64_t **values_out)
{
    int num_macros = 67;
    char **names = malloc(num_macros * sizeof(char *));
    int64_t *values = malloc(num_macros * sizeof(int64_t));
    
    {
        names[0] = "getPartitionBounds_8487zisegmap_20768_dim1";
        values[0] = *ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20770;
    }
    {
        names[1] = "getPartitionBounds_8487zisegmap_20768zisegmap_tblock_sizze_20771";
        values[1] = *ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20770;
    }
    {
        names[2] = "getPartitionBounds_8487zisegscan_20760_dim1";
        values[2] = *ctx->tuning_params.getPartitionBounds_8487zisegscan_tblock_sizze_20524;
    }
    {
        names[3] = "getPartitionBounds_8487zisegscan_20760zisegscan_tblock_sizze_20755";
        values[3] = *ctx->tuning_params.getPartitionBounds_8487zisegscan_tblock_sizze_20524;
    }
    {
        names[4] = "getPartitionBounds_8487zisegscan_20760zichunk_sizze_21918";
        values[4] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[5] = "getPartitionBounds_8487zisegmap_20749_dim1";
        values[5] = *ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20256;
    }
    {
        names[6] = "getPartitionBounds_8487zisegmap_20749zisegmap_tblock_sizze_20745";
        values[6] = *ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20256;
    }
    {
        names[7] = "getPartitionBounds_8487zisegred_large_20734_dim1";
        values[7] = *ctx->tuning_params.getPartitionBounds_8487zisegred_tblock_sizze_20268;
    }
    {
        names[8] = "getPartitionBounds_8487zisegred_large_20734zisegred_tblock_sizze_20728";
        values[8] = *ctx->tuning_params.getPartitionBounds_8487zisegred_tblock_sizze_20268;
    }
    {
        names[9] = "getPartitionBounds_8487zisegred_large_20734zichunk_sizze_21831";
        values[9] = (int64_t) 1;
    }
    {
        names[10] = "getPartitionBounds_8487zisegred_small_20734_dim1";
        values[10] = *ctx->tuning_params.getPartitionBounds_8487zisegred_tblock_sizze_20268;
    }
    {
        names[11] = "getPartitionBounds_8487zisegred_small_20734zisegred_tblock_sizze_20728";
        values[11] = *ctx->tuning_params.getPartitionBounds_8487zisegred_tblock_sizze_20268;
    }
    {
        names[12] = "getPartitionBounds_8487zisegmap_20711_dim1";
        values[12] = *ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20292;
    }
    {
        names[13] = "getPartitionBounds_8487zisegmap_20711zisegmap_tblock_sizze_20705";
        values[13] = *ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20292;
    }
    {
        names[14] = "getPartitionBounds_8487zisegmap_20693_dim1";
        values[14] = *ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20328;
    }
    {
        names[15] = "getPartitionBounds_8487zisegmap_20693zisegmap_tblock_sizze_20687";
        values[15] = *ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20328;
    }
    {
        names[16] = "getPartitionBounds_8487zisegmap_20677_dim1";
        values[16] = *ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20367;
    }
    {
        names[17] = "getPartitionBounds_8487zisegmap_20677zisegmap_tblock_sizze_20672";
        values[17] = *ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20367;
    }
    {
        names[18] = "getPartitionBounds_8487zisegmap_20666_dim1";
        values[18] = *ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20383;
    }
    {
        names[19] = "getPartitionBounds_8487zisegmap_20666zisegmap_tblock_sizze_20661";
        values[19] = *ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20383;
    }
    {
        names[20] = "getPartitionBounds_8487zisegmap_20648_dim1";
        values[20] = *ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20395;
    }
    {
        names[21] = "getPartitionBounds_8487zisegmap_20648zisegmap_tblock_sizze_20642";
        values[21] = *ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20395;
    }
    {
        names[22] = "getPartitionBounds_8487zisegmap_20546_dim1";
        values[22] = *ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20100;
    }
    {
        names[23] = "getPartitionBounds_8487zisegmap_20546zisegmap_tblock_sizze_20542";
        values[23] = *ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20100;
    }
    {
        names[24] = "mainzisegmap_21203_dim1";
        values[24] = *ctx->tuning_params.mainzisegmap_tblock_sizze_21189;
    }
    {
        names[25] = "mainzisegmap_21203zisegmap_tblock_sizze_21199";
        values[25] = *ctx->tuning_params.mainzisegmap_tblock_sizze_21189;
    }
    {
        names[26] = "mainzisegmap_21179_dim1";
        values[26] = *ctx->tuning_params.mainzisegmap_tblock_sizze_21181;
    }
    {
        names[27] = "mainzisegmap_21179zisegmap_tblock_sizze_21182";
        values[27] = *ctx->tuning_params.mainzisegmap_tblock_sizze_21181;
    }
    {
        names[28] = "mainzisegmap_21171_dim1";
        values[28] = *ctx->tuning_params.mainzisegmap_tblock_sizze_21173;
    }
    {
        names[29] = "mainzisegmap_21171zisegmap_tblock_sizze_21174";
        values[29] = *ctx->tuning_params.mainzisegmap_tblock_sizze_21173;
    }
    {
        names[30] = "mainzisegmap_21161_dim1";
        values[30] = *ctx->tuning_params.mainzisegmap_tblock_sizze_21143;
    }
    {
        names[31] = "mainzisegmap_21161zisegmap_tblock_sizze_21157";
        values[31] = *ctx->tuning_params.mainzisegmap_tblock_sizze_21143;
    }
    {
        names[32] = "mainzisegmap_21113_dim1";
        values[32] = *ctx->tuning_params.mainzisegmap_tblock_sizze_21076;
    }
    {
        names[33] = "mainzisegmap_21113zisegmap_tblock_sizze_21108";
        values[33] = *ctx->tuning_params.mainzisegmap_tblock_sizze_21076;
    }
    {
        names[34] = "mainzisegmap_21047_dim1";
        values[34] = *ctx->tuning_params.mainzisegmap_tblock_sizze_21012;
    }
    {
        names[35] = "mainzisegmap_21047zisegmap_tblock_sizze_21043";
        values[35] = *ctx->tuning_params.mainzisegmap_tblock_sizze_21012;
    }
    {
        names[36] = "mainzisegmap_21006_dim1";
        values[36] = *ctx->tuning_params.mainzisegmap_tblock_sizze_20994;
    }
    {
        names[37] = "mainzisegmap_21006zisegmap_tblock_sizze_21002";
        values[37] = *ctx->tuning_params.mainzisegmap_tblock_sizze_20994;
    }
    {
        names[38] = "mainzisegmap_20984_dim1";
        values[38] = *ctx->tuning_params.mainzisegmap_tblock_sizze_20986;
    }
    {
        names[39] = "mainzisegmap_20984zisegmap_tblock_sizze_20987";
        values[39] = *ctx->tuning_params.mainzisegmap_tblock_sizze_20986;
    }
    {
        names[40] = "mainzisegscan_20982_dim1";
        values[40] = *ctx->tuning_params.mainzisegscan_tblock_sizze_20976;
    }
    {
        names[41] = "mainzisegscan_20982zisegscan_tblock_sizze_20977";
        values[41] = *ctx->tuning_params.mainzisegscan_tblock_sizze_20976;
    }
    {
        names[42] = "mainzisegscan_20982zichunk_sizze_22053";
        values[42] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[43] = "mainzisegmap_20970_dim1";
        values[43] = *ctx->tuning_params.mainzisegmap_tblock_sizze_20955;
    }
    {
        names[44] = "mainzisegmap_20970zisegmap_tblock_sizze_20965";
        values[44] = *ctx->tuning_params.mainzisegmap_tblock_sizze_20955;
    }
    {
        names[45] = "mainzisegmap_20945_dim1";
        values[45] = *ctx->tuning_params.mainzisegmap_tblock_sizze_20947;
    }
    {
        names[46] = "mainzisegmap_20945zisegmap_tblock_sizze_20948";
        values[46] = *ctx->tuning_params.mainzisegmap_tblock_sizze_20947;
    }
    {
        names[47] = "mainzisegscan_20943_dim1";
        values[47] = *ctx->tuning_params.mainzisegscan_tblock_sizze_20937;
    }
    {
        names[48] = "mainzisegscan_20943zisegscan_tblock_sizze_20938";
        values[48] = *ctx->tuning_params.mainzisegscan_tblock_sizze_20937;
    }
    {
        names[49] = "mainzisegscan_20943zichunk_sizze_21915";
        values[49] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[50] = "mainzisegmap_20929_dim1";
        values[50] = *ctx->tuning_params.mainzisegmap_tblock_sizze_20931;
    }
    {
        names[51] = "mainzisegmap_20929zisegmap_tblock_sizze_20932";
        values[51] = *ctx->tuning_params.mainzisegmap_tblock_sizze_20931;
    }
    {
        names[52] = "mainzisegmap_20918_dim1";
        values[52] = *ctx->tuning_params.mainzisegmap_tblock_sizze_20921;
    }
    {
        names[53] = "mainzisegmap_20918zisegmap_tblock_sizze_20922";
        values[53] = *ctx->tuning_params.mainzisegmap_tblock_sizze_20921;
    }
    {
        names[54] = "mainzisegmap_20905_dim1";
        values[54] = *ctx->tuning_params.mainzisegmap_tblock_sizze_20888;
    }
    {
        names[55] = "mainzisegmap_20905zisegmap_tblock_sizze_20900";
        values[55] = *ctx->tuning_params.mainzisegmap_tblock_sizze_20888;
    }
    {
        names[56] = "mainzigpuseq_21863_dim1";
        values[56] = (int64_t) 1;
    }
    {
        names[57] = "mainzisegmap_20872_dim1";
        values[57] = *ctx->tuning_params.mainzisegmap_tblock_sizze_20854;
    }
    {
        names[58] = "mainzisegmap_20872zisegmap_tblock_sizze_20868";
        values[58] = *ctx->tuning_params.mainzisegmap_tblock_sizze_20854;
    }
    {
        names[59] = "mainzisegred_nonseg_20850_dim1";
        values[59] = *ctx->tuning_params.mainzisegred_tblock_sizze_20842;
    }
    {
        names[60] = "mainzisegred_nonseg_20850zisegred_tblock_sizze_20843";
        values[60] = *ctx->tuning_params.mainzisegred_tblock_sizze_20842;
    }
    {
        names[61] = "mainzisegred_nonseg_20850zichunk_sizze_21820";
        values[61] = (int64_t) 1;
    }
    {
        names[62] = "mainzisegscan_20840_dim1";
        values[62] = *ctx->tuning_params.mainzisegscan_tblock_sizze_20834;
    }
    {
        names[63] = "mainzisegscan_20840zisegscan_tblock_sizze_20835";
        values[63] = *ctx->tuning_params.mainzisegscan_tblock_sizze_20834;
    }
    {
        names[64] = "mainzisegscan_20840zichunk_sizze_21682";
        values[64] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[65] = "mainzisegmap_20809_dim1";
        values[65] = *ctx->tuning_params.mainzisegmap_tblock_sizze_20778;
    }
    {
        names[66] = "mainzisegmap_20809zisegmap_tblock_sizze_20805";
        values[66] = *ctx->tuning_params.mainzisegmap_tblock_sizze_20778;
    }
    *names_out = names;
    *values_out = values;
    return num_macros;
}
static char *get_failure_msg(int failure_idx, int64_t args[])
{
    (void) args;
    switch (failure_idx) {
        
      case 0:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftHashJoin.fut:27:6-18\n", args[0], args[1]);
            break;
        }
        
      case 1:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftHashJoin.fut:122:67-81\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftHashJoin.fut:122:8-92\n   #3  ftHashJoin.fut:185:6-89\n   #4  ftHashJoin.fut:354:1-362:42\n", args[0], args[1]);
            break;
        }
        
      case 2:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftHashJoin.fut:200:55-62\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftHashJoin.fut:359:18-78\n   #3  ftHashJoin.fut:354:1-362:42\n", args[0], args[1]);
            break;
        }
        
      case 3:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftHashJoin.fut:238:63-69\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftHashJoin.fut:359:7-361:90\n   #3  ftHashJoin.fut:354:1-362:42\n", args[0], args[1]);
            break;
        }
        
      case 4:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftHashJoin.fut:27:6-18\n", args[0], args[1]);
            break;
        }
        
      case 5:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftHashJoin.fut:246:42-74\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftHashJoin.fut:244:10-251:8\n   #3  ftHashJoin.fut:359:7-361:90\n   #4  ftHashJoin.fut:354:1-362:42\n", args[0], args[1]);
            break;
        }
        
      case 6:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftHashJoin.fut:248:46-78\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftHashJoin.fut:244:10-251:8\n   #3  ftHashJoin.fut:359:7-361:90\n   #4  ftHashJoin.fut:354:1-362:42\n", args[0], args[1]);
            break;
        }
        
      case 7:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftHashJoin.fut:75:22-30\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftHashJoin.fut:75:8-44\n", args[0], args[1]);
            break;
        }
        
      case 8:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftHashJoin.fut:75:32-42\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftHashJoin.fut:75:8-44\n", args[0], args[1]);
            break;
        }
        
      case 9:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftHashJoin.fut:75:22-30\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftHashJoin.fut:75:8-44\n", args[0], args[1]);
            break;
        }
        
      case 10:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftHashJoin.fut:75:32-42\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftHashJoin.fut:75:8-44\n", args[0], args[1]);
            break;
        }
        
      case 11:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftHashJoin.fut:75:22-30\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftHashJoin.fut:75:8-44\n", args[0], args[1]);
            break;
        }
        
      case 12:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftHashJoin.fut:75:32-42\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftHashJoin.fut:75:8-44\n", args[0], args[1]);
            break;
        }
    }
    return strdup("Unknown error.  This is a compiler bug.");
}
struct program {
    int dummy;
    gpu_kernel builtinzhiota_i64ziiota_i64_21602;
    gpu_kernel builtinzhreplicate_boolzireplicate_22200;
    gpu_kernel builtinzhreplicate_i32zireplicate_21718;
    gpu_kernel builtinzhreplicate_i64zireplicate_21619;
    gpu_kernel builtinzhreplicate_i8zireplicate_21692;
    gpu_kernel getPartitionBounds_8487zisegmap_20546;
    gpu_kernel getPartitionBounds_8487zisegmap_20648;
    gpu_kernel getPartitionBounds_8487zisegmap_20666;
    gpu_kernel getPartitionBounds_8487zisegmap_20677;
    gpu_kernel getPartitionBounds_8487zisegmap_20693;
    gpu_kernel getPartitionBounds_8487zisegmap_20711;
    gpu_kernel getPartitionBounds_8487zisegmap_20749;
    gpu_kernel getPartitionBounds_8487zisegmap_20768;
    gpu_kernel getPartitionBounds_8487zisegmap_intrablock_20593;
    gpu_kernel getPartitionBounds_8487zisegred_large_20734;
    gpu_kernel getPartitionBounds_8487zisegred_small_20734;
    gpu_kernel getPartitionBounds_8487zisegscan_20760;
    gpu_kernel mainzigpuseq_21863;
    gpu_kernel mainzisegmap_20809;
    gpu_kernel mainzisegmap_20872;
    gpu_kernel mainzisegmap_20905;
    gpu_kernel mainzisegmap_20918;
    gpu_kernel mainzisegmap_20929;
    gpu_kernel mainzisegmap_20945;
    gpu_kernel mainzisegmap_20970;
    gpu_kernel mainzisegmap_20984;
    gpu_kernel mainzisegmap_21006;
    gpu_kernel mainzisegmap_21047;
    gpu_kernel mainzisegmap_21113;
    gpu_kernel mainzisegmap_21161;
    gpu_kernel mainzisegmap_21171;
    gpu_kernel mainzisegmap_21179;
    gpu_kernel mainzisegmap_21203;
    gpu_kernel mainzisegred_nonseg_20850;
    gpu_kernel mainzisegscan_20840;
    gpu_kernel mainzisegscan_20943;
    gpu_kernel mainzisegscan_20982;
};
static void setup_program(struct futhark_context *ctx)
{
    (void) ctx;
    
    int error = 0;
    
    (void) error;
    ctx->program = malloc(sizeof(struct program));
    gpu_create_kernel(ctx, &ctx->program->builtinzhiota_i64ziiota_i64_21602, "builtinzhiota_i64ziiota_i64_21602");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_boolzireplicate_22200, "builtinzhreplicate_boolzireplicate_22200");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_i32zireplicate_21718, "builtinzhreplicate_i32zireplicate_21718");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_i64zireplicate_21619, "builtinzhreplicate_i64zireplicate_21619");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_i8zireplicate_21692, "builtinzhreplicate_i8zireplicate_21692");
    gpu_create_kernel(ctx, &ctx->program->getPartitionBounds_8487zisegmap_20546, "getPartitionBounds_8487zisegmap_20546");
    gpu_create_kernel(ctx, &ctx->program->getPartitionBounds_8487zisegmap_20648, "getPartitionBounds_8487zisegmap_20648");
    gpu_create_kernel(ctx, &ctx->program->getPartitionBounds_8487zisegmap_20666, "getPartitionBounds_8487zisegmap_20666");
    gpu_create_kernel(ctx, &ctx->program->getPartitionBounds_8487zisegmap_20677, "getPartitionBounds_8487zisegmap_20677");
    gpu_create_kernel(ctx, &ctx->program->getPartitionBounds_8487zisegmap_20693, "getPartitionBounds_8487zisegmap_20693");
    gpu_create_kernel(ctx, &ctx->program->getPartitionBounds_8487zisegmap_20711, "getPartitionBounds_8487zisegmap_20711");
    gpu_create_kernel(ctx, &ctx->program->getPartitionBounds_8487zisegmap_20749, "getPartitionBounds_8487zisegmap_20749");
    gpu_create_kernel(ctx, &ctx->program->getPartitionBounds_8487zisegmap_20768, "getPartitionBounds_8487zisegmap_20768");
    gpu_create_kernel(ctx, &ctx->program->getPartitionBounds_8487zisegmap_intrablock_20593, "getPartitionBounds_8487zisegmap_intrablock_20593");
    gpu_create_kernel(ctx, &ctx->program->getPartitionBounds_8487zisegred_large_20734, "getPartitionBounds_8487zisegred_large_20734");
    gpu_create_kernel(ctx, &ctx->program->getPartitionBounds_8487zisegred_small_20734, "getPartitionBounds_8487zisegred_small_20734");
    gpu_create_kernel(ctx, &ctx->program->getPartitionBounds_8487zisegscan_20760, "getPartitionBounds_8487zisegscan_20760");
    gpu_create_kernel(ctx, &ctx->program->mainzigpuseq_21863, "mainzigpuseq_21863");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_20809, "mainzisegmap_20809");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_20872, "mainzisegmap_20872");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_20905, "mainzisegmap_20905");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_20918, "mainzisegmap_20918");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_20929, "mainzisegmap_20929");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_20945, "mainzisegmap_20945");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_20970, "mainzisegmap_20970");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_20984, "mainzisegmap_20984");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_21006, "mainzisegmap_21006");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_21047, "mainzisegmap_21047");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_21113, "mainzisegmap_21113");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_21161, "mainzisegmap_21161");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_21171, "mainzisegmap_21171");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_21179, "mainzisegmap_21179");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_21203, "mainzisegmap_21203");
    gpu_create_kernel(ctx, &ctx->program->mainzisegred_nonseg_20850, "mainzisegred_nonseg_20850");
    gpu_create_kernel(ctx, &ctx->program->mainzisegscan_20840, "mainzisegscan_20840");
    gpu_create_kernel(ctx, &ctx->program->mainzisegscan_20943, "mainzisegscan_20943");
    gpu_create_kernel(ctx, &ctx->program->mainzisegscan_20982, "mainzisegscan_20982");
}
static void teardown_program(struct futhark_context *ctx)
{
    (void) ctx;
    
    int error = 0;
    
    (void) error;
    gpu_free_kernel(ctx, ctx->program->builtinzhiota_i64ziiota_i64_21602);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_boolzireplicate_22200);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_i32zireplicate_21718);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_i64zireplicate_21619);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_i8zireplicate_21692);
    gpu_free_kernel(ctx, ctx->program->getPartitionBounds_8487zisegmap_20546);
    gpu_free_kernel(ctx, ctx->program->getPartitionBounds_8487zisegmap_20648);
    gpu_free_kernel(ctx, ctx->program->getPartitionBounds_8487zisegmap_20666);
    gpu_free_kernel(ctx, ctx->program->getPartitionBounds_8487zisegmap_20677);
    gpu_free_kernel(ctx, ctx->program->getPartitionBounds_8487zisegmap_20693);
    gpu_free_kernel(ctx, ctx->program->getPartitionBounds_8487zisegmap_20711);
    gpu_free_kernel(ctx, ctx->program->getPartitionBounds_8487zisegmap_20749);
    gpu_free_kernel(ctx, ctx->program->getPartitionBounds_8487zisegmap_20768);
    gpu_free_kernel(ctx, ctx->program->getPartitionBounds_8487zisegmap_intrablock_20593);
    gpu_free_kernel(ctx, ctx->program->getPartitionBounds_8487zisegred_large_20734);
    gpu_free_kernel(ctx, ctx->program->getPartitionBounds_8487zisegred_small_20734);
    gpu_free_kernel(ctx, ctx->program->getPartitionBounds_8487zisegscan_20760);
    gpu_free_kernel(ctx, ctx->program->mainzigpuseq_21863);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_20809);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_20872);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_20905);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_20918);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_20929);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_20945);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_20970);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_20984);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_21006);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_21047);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_21113);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_21161);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_21171);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_21179);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_21203);
    gpu_free_kernel(ctx, ctx->program->mainzisegred_nonseg_20850);
    gpu_free_kernel(ctx, ctx->program->mainzisegscan_20840);
    gpu_free_kernel(ctx, ctx->program->mainzisegscan_20943);
    gpu_free_kernel(ctx, ctx->program->mainzisegscan_20982);
    free(ctx->program);
}
static void set_tuning_params(struct futhark_context *ctx)
{
    (void) ctx;
    ctx->tuning_params.builtinzhiota_i64zitblock_sizze_21606 = &ctx->cfg->tuning_params[0];
    ctx->tuning_params.builtinzhreplicate_boolzitblock_sizze_22204 = &ctx->cfg->tuning_params[1];
    ctx->tuning_params.builtinzhreplicate_i32zitblock_sizze_21722 = &ctx->cfg->tuning_params[2];
    ctx->tuning_params.builtinzhreplicate_i64zitblock_sizze_21623 = &ctx->cfg->tuning_params[3];
    ctx->tuning_params.builtinzhreplicate_i8zitblock_sizze_21696 = &ctx->cfg->tuning_params[4];
    ctx->tuning_params.getPartitionBounds_8487zisegmap_num_tblocks_20294 = &ctx->cfg->tuning_params[5];
    ctx->tuning_params.getPartitionBounds_8487zisegmap_num_tblocks_20772 = &ctx->cfg->tuning_params[6];
    ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20100 = &ctx->cfg->tuning_params[7];
    ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20256 = &ctx->cfg->tuning_params[8];
    ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20292 = &ctx->cfg->tuning_params[9];
    ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20328 = &ctx->cfg->tuning_params[10];
    ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20367 = &ctx->cfg->tuning_params[11];
    ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20383 = &ctx->cfg->tuning_params[12];
    ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20395 = &ctx->cfg->tuning_params[13];
    ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20770 = &ctx->cfg->tuning_params[14];
    ctx->tuning_params.getPartitionBounds_8487zisegred_num_tblocks_20270 = &ctx->cfg->tuning_params[15];
    ctx->tuning_params.getPartitionBounds_8487zisegred_tblock_sizze_20268 = &ctx->cfg->tuning_params[16];
    ctx->tuning_params.getPartitionBounds_8487zisegscan_num_tblocks_20016 = &ctx->cfg->tuning_params[17];
    ctx->tuning_params.getPartitionBounds_8487zisegscan_num_tblocks_20526 = &ctx->cfg->tuning_params[18];
    ctx->tuning_params.getPartitionBounds_8487zisegscan_tblock_sizze_20014 = &ctx->cfg->tuning_params[19];
    ctx->tuning_params.getPartitionBounds_8487zisegscan_tblock_sizze_20524 = &ctx->cfg->tuning_params[20];
    ctx->tuning_params.getPartitionBounds_8487zisuff_intra_par_2 = &ctx->cfg->tuning_params[21];
    ctx->tuning_params.getPartitionBounds_8487zisuff_outer_par_1 = &ctx->cfg->tuning_params[22];
    ctx->tuning_params.getPartitionBounds_8487zisuff_outer_screma_0 = &ctx->cfg->tuning_params[23];
    ctx->tuning_params.mainzisegmap_num_tblocks_20923 = &ctx->cfg->tuning_params[24];
    ctx->tuning_params.mainzisegmap_num_tblocks_20933 = &ctx->cfg->tuning_params[25];
    ctx->tuning_params.mainzisegmap_num_tblocks_20949 = &ctx->cfg->tuning_params[26];
    ctx->tuning_params.mainzisegmap_num_tblocks_20988 = &ctx->cfg->tuning_params[27];
    ctx->tuning_params.mainzisegmap_num_tblocks_21175 = &ctx->cfg->tuning_params[28];
    ctx->tuning_params.mainzisegmap_num_tblocks_21183 = &ctx->cfg->tuning_params[29];
    ctx->tuning_params.mainzisegmap_tblock_sizze_20778 = &ctx->cfg->tuning_params[30];
    ctx->tuning_params.mainzisegmap_tblock_sizze_20854 = &ctx->cfg->tuning_params[31];
    ctx->tuning_params.mainzisegmap_tblock_sizze_20888 = &ctx->cfg->tuning_params[32];
    ctx->tuning_params.mainzisegmap_tblock_sizze_20921 = &ctx->cfg->tuning_params[33];
    ctx->tuning_params.mainzisegmap_tblock_sizze_20931 = &ctx->cfg->tuning_params[34];
    ctx->tuning_params.mainzisegmap_tblock_sizze_20947 = &ctx->cfg->tuning_params[35];
    ctx->tuning_params.mainzisegmap_tblock_sizze_20955 = &ctx->cfg->tuning_params[36];
    ctx->tuning_params.mainzisegmap_tblock_sizze_20986 = &ctx->cfg->tuning_params[37];
    ctx->tuning_params.mainzisegmap_tblock_sizze_20994 = &ctx->cfg->tuning_params[38];
    ctx->tuning_params.mainzisegmap_tblock_sizze_21012 = &ctx->cfg->tuning_params[39];
    ctx->tuning_params.mainzisegmap_tblock_sizze_21076 = &ctx->cfg->tuning_params[40];
    ctx->tuning_params.mainzisegmap_tblock_sizze_21143 = &ctx->cfg->tuning_params[41];
    ctx->tuning_params.mainzisegmap_tblock_sizze_21173 = &ctx->cfg->tuning_params[42];
    ctx->tuning_params.mainzisegmap_tblock_sizze_21181 = &ctx->cfg->tuning_params[43];
    ctx->tuning_params.mainzisegmap_tblock_sizze_21189 = &ctx->cfg->tuning_params[44];
    ctx->tuning_params.mainzisegred_num_tblocks_20844 = &ctx->cfg->tuning_params[45];
    ctx->tuning_params.mainzisegred_tblock_sizze_20842 = &ctx->cfg->tuning_params[46];
    ctx->tuning_params.mainzisegscan_num_tblocks_20836 = &ctx->cfg->tuning_params[47];
    ctx->tuning_params.mainzisegscan_num_tblocks_20939 = &ctx->cfg->tuning_params[48];
    ctx->tuning_params.mainzisegscan_num_tblocks_20978 = &ctx->cfg->tuning_params[49];
    ctx->tuning_params.mainzisegscan_tblock_sizze_20834 = &ctx->cfg->tuning_params[50];
    ctx->tuning_params.mainzisegscan_tblock_sizze_20937 = &ctx->cfg->tuning_params[51];
    ctx->tuning_params.mainzisegscan_tblock_sizze_20976 = &ctx->cfg->tuning_params[52];
}
int memblock_unref_device(struct futhark_context *ctx, struct memblock_device *block, const char *desc)
{
    if (block->references != NULL) {
        *block->references -= 1;
        if (ctx->detail_memory)
            fprintf(ctx->log, "Unreferencing block %s (allocated as %s) in %s: %d references remaining.\n", desc, block->desc, "space 'device'", *block->references);
        if (*block->references == 0) {
            ctx->cur_mem_usage_device -= block->size;
            (void) gpu_free(ctx, block->mem, block->size, desc);
            free(block->references);
            if (ctx->detail_memory)
                fprintf(ctx->log, "%lld bytes freed (now allocated: %lld bytes)\n", (long long) block->size, (long long) ctx->cur_mem_usage_device);
        }
        block->references = NULL;
    }
    return 0;
}
int memblock_alloc_device(struct futhark_context *ctx, struct memblock_device *block, int64_t size, const char *desc)
{
    if (size < 0)
        futhark_panic(1, "Negative allocation of %lld bytes attempted for %s in %s.\n", (long long) size, desc, "space 'device'", ctx->cur_mem_usage_device);
    
    int ret = memblock_unref_device(ctx, block, desc);
    
    if (ret != FUTHARK_SUCCESS)
        return ret;
    if (ctx->detail_memory)
        fprintf(ctx->log, "Allocating %lld bytes for %s in %s (currently allocated: %lld bytes).\n", (long long) size, desc, "space 'device'", (long long) ctx->cur_mem_usage_device);
    (void) gpu_alloc(ctx, ctx->log, (size_t) size, desc, &block->mem, (size_t *) &size);
    if (ctx->error == NULL) {
        block->references = (int *) malloc(sizeof(int));
        *block->references = 1;
        block->size = size;
        block->desc = desc;
        
        long long new_usage = ctx->cur_mem_usage_device + size;
        
        if (ctx->detail_memory)
            fprintf(ctx->log, "Received block of %lld bytes; now allocated: %lld bytes", (long long) block->size, new_usage);
        ctx->cur_mem_usage_device = new_usage;
        if (new_usage > ctx->peak_mem_usage_device) {
            ctx->peak_mem_usage_device = new_usage;
            if (ctx->detail_memory)
                fprintf(ctx->log, " (new peak).\n");
        } else if (ctx->detail_memory)
            fprintf(ctx->log, ".\n");
        return FUTHARK_SUCCESS;
    } else {
        // We are naively assuming that any memory allocation error is due to OOM.
        lock_lock(&ctx->error_lock);
        
        char *old_error = ctx->error;
        
        ctx->error = msgprintf("Failed to allocate memory in %s.\nAttempted allocation: %12lld bytes\nCurrently allocated:  %12lld bytes\n%s", "space 'device'", (long long) size, (long long) ctx->cur_mem_usage_device, old_error);
        free(old_error);
        lock_unlock(&ctx->error_lock);
        return FUTHARK_OUT_OF_MEMORY;
    }
}
int memblock_set_device(struct futhark_context *ctx, struct memblock_device *lhs, struct memblock_device *rhs, const char *lhs_desc)
{
    int ret = memblock_unref_device(ctx, lhs, lhs_desc);
    
    if (rhs->references != NULL)
        (*rhs->references)++;
    *lhs = *rhs;
    return ret;
}
int memblock_unref(struct futhark_context *ctx, struct memblock *block, const char *desc)
{
    if (block->references != NULL) {
        *block->references -= 1;
        if (ctx->detail_memory)
            fprintf(ctx->log, "Unreferencing block %s (allocated as %s) in %s: %d references remaining.\n", desc, block->desc, "default space", *block->references);
        if (*block->references == 0) {
            ctx->cur_mem_usage_default -= block->size;
            host_free(ctx, (size_t) block->size, desc, (void *) block->mem);
            free(block->references);
            if (ctx->detail_memory)
                fprintf(ctx->log, "%lld bytes freed (now allocated: %lld bytes)\n", (long long) block->size, (long long) ctx->cur_mem_usage_default);
        }
        block->references = NULL;
    }
    return 0;
}
int memblock_alloc(struct futhark_context *ctx, struct memblock *block, int64_t size, const char *desc)
{
    if (size < 0)
        futhark_panic(1, "Negative allocation of %lld bytes attempted for %s in %s.\n", (long long) size, desc, "default space", ctx->cur_mem_usage_default);
    
    int ret = memblock_unref(ctx, block, desc);
    
    if (ret != FUTHARK_SUCCESS)
        return ret;
    if (ctx->detail_memory)
        fprintf(ctx->log, "Allocating %lld bytes for %s in %s (currently allocated: %lld bytes).\n", (long long) size, desc, "default space", (long long) ctx->cur_mem_usage_default);
    host_alloc(ctx, (size_t) size, desc, (size_t *) &size, (void *) &block->mem);
    if (ctx->error == NULL) {
        block->references = (int *) malloc(sizeof(int));
        *block->references = 1;
        block->size = size;
        block->desc = desc;
        
        long long new_usage = ctx->cur_mem_usage_default + size;
        
        if (ctx->detail_memory)
            fprintf(ctx->log, "Received block of %lld bytes; now allocated: %lld bytes", (long long) block->size, new_usage);
        ctx->cur_mem_usage_default = new_usage;
        if (new_usage > ctx->peak_mem_usage_default) {
            ctx->peak_mem_usage_default = new_usage;
            if (ctx->detail_memory)
                fprintf(ctx->log, " (new peak).\n");
        } else if (ctx->detail_memory)
            fprintf(ctx->log, ".\n");
        return FUTHARK_SUCCESS;
    } else {
        // We are naively assuming that any memory allocation error is due to OOM.
        lock_lock(&ctx->error_lock);
        
        char *old_error = ctx->error;
        
        ctx->error = msgprintf("Failed to allocate memory in %s.\nAttempted allocation: %12lld bytes\nCurrently allocated:  %12lld bytes\n%s", "default space", (long long) size, (long long) ctx->cur_mem_usage_default, old_error);
        free(old_error);
        lock_unlock(&ctx->error_lock);
        return FUTHARK_OUT_OF_MEMORY;
    }
}
int memblock_set(struct futhark_context *ctx, struct memblock *lhs, struct memblock *rhs, const char *lhs_desc)
{
    int ret = memblock_unref(ctx, lhs, lhs_desc);
    
    if (rhs->references != NULL)
        (*rhs->references)++;
    *lhs = *rhs;
    return ret;
}
char *futhark_context_report(struct futhark_context *ctx)
{
    if (futhark_context_sync(ctx) != 0)
        return NULL;
    
    struct str_builder builder;
    
    str_builder_init(&builder);
    str_builder_char(&builder, '{');
    str_builder_str(&builder, "\"memory\":{");
    str_builder(&builder, "\"space 'device'\": %lld", (long long) ctx->peak_mem_usage_device);
    str_builder_char(&builder, ',');
    str_builder(&builder, "\"default space\": %lld", (long long) ctx->peak_mem_usage_default);
    str_builder_str(&builder, "},\"events\":[");
    if (report_events_in_list(&ctx->event_list, &builder) != 0) {
        free(builder.str);
        return NULL;
    } else {
        str_builder_str(&builder, "]}");
        return builder.str;
    }
}
int futhark_context_clear_caches(struct futhark_context *ctx)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    ctx->peak_mem_usage_device = 0;
    ctx->peak_mem_usage_default = 0;
    if (ctx->error == NULL)
        gpu_free_all(ctx);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ctx->error != NULL;
}

// Start of context.h

// Internal functions.

static void set_error(struct futhark_context* ctx, char *error) {
  lock_lock(&ctx->error_lock);
  if (ctx->error == NULL) {
    ctx->error = error;
  } else {
    free(error);
  }
  lock_unlock(&ctx->error_lock);
}

// XXX: should be static, but used in ispc_util.h
void lexical_realloc_error(struct futhark_context* ctx, size_t new_size) {
  set_error(ctx,
            msgprintf("Failed to allocate memory.\nAttempted allocation: %12lld bytes\n",
                      (long long) new_size));
}

static int lexical_realloc(struct futhark_context *ctx,
                           unsigned char **ptr,
                           int64_t *old_size,
                           int64_t new_size) {
  unsigned char *new = realloc(*ptr, (size_t)new_size);
  if (new == NULL) {
    lexical_realloc_error(ctx, new_size);
    return FUTHARK_OUT_OF_MEMORY;
  } else {
    *ptr = new;
    *old_size = new_size;
    return FUTHARK_SUCCESS;
  }
}

static void free_all_in_free_list(struct futhark_context* ctx) {
  fl_mem mem;
  free_list_pack(&ctx->free_list);
  while (free_list_first(&ctx->free_list, (fl_mem*)&mem) == 0) {
    free((void*)mem);
  }
}

static int is_small_alloc(size_t size) {
  return size < 1024*1024;
}

static void host_alloc(struct futhark_context* ctx,
                       size_t size, const char* tag, size_t* size_out, void** mem_out) {
  if (is_small_alloc(size) || free_list_find(&ctx->free_list, size, tag, size_out, (fl_mem*)mem_out) != 0) {
    *size_out = size;
    *mem_out = malloc(size);
  }
}

static void host_free(struct futhark_context* ctx,
                      size_t size, const char* tag, void* mem) {
  // Small allocations are handled by malloc()s own free list.  The
  // threshold here is kind of arbitrary, but seems to work OK.
  // Larger allocations are mmap()ed/munmapped() every time, which is
  // very slow, and Futhark programs tend to use a few very large
  // allocations.
  if (is_small_alloc(size)) {
    free(mem);
  } else {
    free_list_insert(&ctx->free_list, size, (fl_mem)mem, tag);
  }
}

static void add_event(struct futhark_context* ctx,
                      const char* name,
                      char* description,
                      void* data,
                      event_report_fn f) {
  if (ctx->logging) {
    fprintf(ctx->log, "Event: %s\n%s\n", name, description);
  }
  add_event_to_list(&ctx->event_list, name, description, data, f);
}

char *futhark_context_get_error(struct futhark_context *ctx) {
  char *error = ctx->error;
  ctx->error = NULL;
  return error;
}

void futhark_context_config_set_debugging(struct futhark_context_config *cfg, int flag) {
    cfg->profiling = cfg->logging = cfg->debugging = flag;
}

void futhark_context_config_set_profiling(struct futhark_context_config *cfg, int flag) {
    cfg->profiling = flag;
}

void futhark_context_config_set_logging(struct futhark_context_config *cfg, int flag) {
    cfg->logging = flag;
}

void futhark_context_config_set_cache_file(struct futhark_context_config *cfg, const char *f) {
  cfg->cache_fname = strdup(f);
}

int futhark_get_tuning_param_count(void) {
  return num_tuning_params;
}

const char *futhark_get_tuning_param_name(int i) {
  return tuning_param_names[i];
}

const char *futhark_get_tuning_param_class(int i) {
    return tuning_param_classes[i];
}

void futhark_context_set_logging_file(struct futhark_context *ctx, FILE *f){
  ctx->log = f;
}

void futhark_context_pause_profiling(struct futhark_context *ctx) {
  ctx->profiling_paused = 1;
}

void futhark_context_unpause_profiling(struct futhark_context *ctx) {
  ctx->profiling_paused = 0;
}

struct futhark_context_config* futhark_context_config_new(void) {
  struct futhark_context_config* cfg = malloc(sizeof(struct futhark_context_config));
  if (cfg == NULL) {
    return NULL;
  }
  cfg->in_use = 0;
  cfg->debugging = 0;
  cfg->profiling = 0;
  cfg->logging = 0;
  cfg->cache_fname = NULL;
  cfg->num_tuning_params = num_tuning_params;
  cfg->tuning_params = malloc(cfg->num_tuning_params * sizeof(int64_t));
  memcpy(cfg->tuning_params, tuning_param_defaults,
         cfg->num_tuning_params * sizeof(int64_t));
  cfg->tuning_param_names = tuning_param_names;
  cfg->tuning_param_vars = tuning_param_vars;
  cfg->tuning_param_classes = tuning_param_classes;
  backend_context_config_setup(cfg);
  return cfg;
}

void futhark_context_config_free(struct futhark_context_config* cfg) {
  assert(!cfg->in_use);
  backend_context_config_teardown(cfg);
  free(cfg->cache_fname);
  free(cfg->tuning_params);
  free(cfg);
}

struct futhark_context* futhark_context_new(struct futhark_context_config* cfg) {
  struct futhark_context* ctx = malloc(sizeof(struct futhark_context));
  if (ctx == NULL) {
    return NULL;
  }
  assert(!cfg->in_use);
  ctx->cfg = cfg;
  ctx->cfg->in_use = 1;
  ctx->program_initialised = false;
  create_lock(&ctx->error_lock);
  create_lock(&ctx->lock);
  free_list_init(&ctx->free_list);
  event_list_init(&ctx->event_list);
  ctx->peak_mem_usage_default = 0;
  ctx->cur_mem_usage_default = 0;
  ctx->constants = malloc(sizeof(struct constants));
  ctx->debugging = cfg->debugging;
  ctx->logging = cfg->logging;
  ctx->detail_memory = cfg->logging;
  ctx->profiling = cfg->profiling;
  ctx->profiling_paused = 0;
  ctx->error = NULL;
  ctx->log = stderr;
  set_tuning_params(ctx);
  if (backend_context_setup(ctx) == 0) {
    setup_program(ctx);
    init_constants(ctx);
    ctx->program_initialised = true;
    (void)futhark_context_clear_caches(ctx);
    (void)futhark_context_sync(ctx);
  }
  return ctx;
}

void futhark_context_free(struct futhark_context* ctx) {
  if (ctx->program_initialised) {
    free_constants(ctx);
    teardown_program(ctx);
  }
  backend_context_teardown(ctx);
  free_all_in_free_list(ctx);
  free_list_destroy(&ctx->free_list);
  event_list_free(&ctx->event_list);
  free(ctx->constants);
  free(ctx->error);
  free_lock(&ctx->lock);
  free_lock(&ctx->error_lock);
  ctx->cfg->in_use = 0;
  free(ctx);
}

// End of context.h

// Start of copy.h

// Cache-oblivious map-transpose function.
#define GEN_MAP_TRANSPOSE(NAME, ELEM_TYPE)                              \
  static void map_transpose_##NAME                                      \
  (ELEM_TYPE* dst, ELEM_TYPE* src,                                      \
   int64_t k, int64_t m, int64_t n,                                     \
   int64_t cb, int64_t ce, int64_t rb, int64_t re)                      \
  {                                                                     \
  int32_t r = re - rb;                                                  \
  int32_t c = ce - cb;                                                  \
  if (k == 1) {                                                         \
    if (r <= 64 && c <= 64) {                                           \
      for (int64_t j = 0; j < c; j++) {                                 \
        for (int64_t i = 0; i < r; i++) {                               \
          dst[(j + cb) * n + (i + rb)] = src[(i + rb) * m + (j + cb)];  \
        }                                                               \
      }                                                                 \
    } else if (c <= r) {                                                \
      map_transpose_##NAME(dst, src, k, m, n, cb, ce, rb, rb + r/2);    \
      map_transpose_##NAME(dst, src, k, m, n, cb, ce, rb + r/2, re);    \
    } else {                                                            \
      map_transpose_##NAME(dst, src, k, m, n, cb, cb + c/2, rb, re);    \
      map_transpose_##NAME(dst, src, k, m, n, cb + c/2, ce, rb, re);    \
    }                                                                   \
  } else {                                                              \
  for (int64_t i = 0; i < k; i++) {                                     \
    map_transpose_##NAME(dst + i * m * n, src + i * m * n, 1, m, n, cb, ce, rb, re); \
  }\
} \
}

// Straightforward LMAD copy function.
#define GEN_LMAD_COPY_ELEMENTS(NAME, ELEM_TYPE)                         \
  static void lmad_copy_elements_##NAME(int r,                          \
                                        ELEM_TYPE* dst, int64_t dst_strides[r], \
                                        ELEM_TYPE *src, int64_t src_strides[r], \
                                        int64_t shape[r]) {             \
    if (r == 1) {                                                       \
      for (int i = 0; i < shape[0]; i++) {                              \
        dst[i*dst_strides[0]] = src[i*src_strides[0]];                  \
      }                                                                 \
    } else if (r > 1) {                                                 \
      for (int i = 0; i < shape[0]; i++) {                              \
        lmad_copy_elements_##NAME(r-1,                                  \
                                  dst+i*dst_strides[0], dst_strides+1,  \
                                  src+i*src_strides[0], src_strides+1,  \
                                  shape+1);                             \
      }                                                                 \
    }                                                                   \
  }                                                                     \

// Check whether this LMAD can be seen as a transposed 2D array.  This
// is done by checking every possible splitting point.
static bool lmad_is_tr(int64_t *n_out, int64_t *m_out,
                       int r,
                       const int64_t strides[r],
                       const int64_t shape[r]) {
  for (int i = 1; i < r; i++) {
    int n = 1, m = 1;
    bool ok = true;
    int64_t expected = 1;
    // Check strides before 'i'.
    for (int j = i-1; j >= 0; j--) {
      ok = ok && strides[j] == expected;
      expected *= shape[j];
      n *= shape[j];
    }
    // Check strides after 'i'.
    for (int j = r-1; j >= i; j--) {
      ok = ok && strides[j] == expected;
      expected *= shape[j];
      m *= shape[j];
    }
    if (ok) {
      *n_out = n;
      *m_out = m;
      return true;
    }
  }
  return false;
}

// This function determines whether the a 'dst' LMAD is row-major and
// 'src' LMAD is column-major.  Both LMADs are for arrays of the same
// shape.  Both LMADs are allowed to have additional dimensions "on
// top".  Essentially, this function determines whether a copy from
// 'src' to 'dst' is a "map(transpose)" that we know how to implement
// efficiently.  The LMADs can have arbitrary rank, and the main
// challenge here is checking whether the src LMAD actually
// corresponds to a 2D column-major layout by morally collapsing
// dimensions.  There is a lot of looping here, but the actual trip
// count is going to be very low in practice.
//
// Returns true if this is indeed a map(transpose), and writes the
// number of arrays, and moral array size to appropriate output
// parameters.
static bool lmad_map_tr(int64_t *num_arrays_out, int64_t *n_out, int64_t *m_out,
                        int r,
                        const int64_t dst_strides[r],
                        const int64_t src_strides[r],
                        const int64_t shape[r]) {
  int64_t rowmajor_strides[r];
  rowmajor_strides[r-1] = 1;

  for (int i = r-2; i >= 0; i--) {
    rowmajor_strides[i] = rowmajor_strides[i+1] * shape[i+1];
  }

  // map_r will be the number of mapped dimensions on top.
  int map_r = 0;
  int64_t num_arrays = 1;
  for (int i = 0; i < r; i++) {
    if (dst_strides[i] != rowmajor_strides[i] ||
        src_strides[i] != rowmajor_strides[i]) {
      break;
    } else {
      num_arrays *= shape[i];
      map_r++;
    }
  }

  *num_arrays_out = num_arrays;

  if (r==map_r) {
    return false;
  }

  if (memcmp(&rowmajor_strides[map_r],
             &dst_strides[map_r],
             sizeof(int64_t)*(r-map_r)) == 0) {
    return lmad_is_tr(n_out, m_out, r-map_r, src_strides+map_r, shape+map_r);
  } else if (memcmp(&rowmajor_strides[map_r],
                    &src_strides[map_r],
                    sizeof(int64_t)*(r-map_r)) == 0) {
    return lmad_is_tr(m_out, n_out, r-map_r, dst_strides+map_r, shape+map_r);
  }
  return false;
}

// Check if the strides correspond to row-major strides of *any*
// permutation of the shape.  This is done by recursive search with
// backtracking.  This is worst-case exponential, but hopefully the
// arrays we encounter do not have that many dimensions.
static bool lmad_contiguous_search(int checked, int64_t expected,
                                   int r,
                                   int64_t strides[r], int64_t shape[r], bool used[r]) {
  for (int i = 0; i < r; i++) {
    for (int j = 0; j < r; j++) {
      if (!used[j] && strides[j] == expected && strides[j] >= 0) {
        used[j] = true;
        if (checked+1 == r ||
            lmad_contiguous_search(checked+1, expected * shape[j], r, strides, shape, used)) {
          return true;
        }
        used[j] = false;
      }
    }
  }
  return false;
}

// Does this LMAD correspond to an array with positive strides and no
// holes?
static bool lmad_contiguous(int r, int64_t strides[r], int64_t shape[r]) {
  bool used[r];
  for (int i = 0; i < r; i++) {
    used[i] = false;
  }
  return lmad_contiguous_search(0, 1, r, strides, shape, used);
}

// Does this copy correspond to something that could be done with a
// memcpy()-like operation?  I.e. do the LMADs actually represent the
// same in-memory layout and are they contiguous?
static bool lmad_memcpyable(int r,
                            int64_t dst_strides[r], int64_t src_strides[r], int64_t shape[r]) {
  if (!lmad_contiguous(r, dst_strides, shape)) {
    return false;
  }
  for (int i = 0; i < r; i++) {
    if (dst_strides[i] != src_strides[i] && shape[i] != 1) {
      return false;
    }
  }
  return true;
}


static void log_copy(struct futhark_context* ctx,
                     const char *kind, int r,
                     int64_t dst_offset, int64_t dst_strides[r],
                     int64_t src_offset, int64_t src_strides[r],
                     int64_t shape[r]) {
  if (ctx->logging) {
    fprintf(ctx->log, "\n# Copy %s\n", kind);
    fprintf(ctx->log, "Shape: ");
    for (int i = 0; i < r; i++) { fprintf(ctx->log, "[%ld]", (long int)shape[i]); }
    fprintf(ctx->log, "\n");
    fprintf(ctx->log, "Dst offset: %ld\n", (long int)dst_offset);
    fprintf(ctx->log, "Dst strides:");
    for (int i = 0; i < r; i++) { fprintf(ctx->log, " %ld", (long int)dst_strides[i]); }
    fprintf(ctx->log, "\n");
    fprintf(ctx->log, "Src offset: %ld\n", (long int)src_offset);
    fprintf(ctx->log, "Src strides:");
    for (int i = 0; i < r; i++) { fprintf(ctx->log, " %ld", (long int)src_strides[i]); }
    fprintf(ctx->log, "\n");
  }
}

static void log_transpose(struct futhark_context* ctx,
                          int64_t k, int64_t n, int64_t m) {
  if (ctx->logging) {
    fprintf(ctx->log, "## Transpose\n");
    fprintf(ctx->log, "Arrays     : %ld\n", (long int)k);
    fprintf(ctx->log, "X elements : %ld\n", (long int)m);
    fprintf(ctx->log, "Y elements : %ld\n", (long int)n);
    fprintf(ctx->log, "\n");
  }
}

#define GEN_LMAD_COPY(NAME, ELEM_TYPE)                                  \
  static void lmad_copy_##NAME                                          \
  (struct futhark_context *ctx, int r,                                  \
   ELEM_TYPE* dst, int64_t dst_offset, int64_t dst_strides[r],          \
   ELEM_TYPE *src, int64_t src_offset, int64_t src_strides[r],          \
   int64_t shape[r]) {                                                  \
    log_copy(ctx, "CPU to CPU", r, dst_offset, dst_strides,             \
             src_offset, src_strides, shape);                           \
    int64_t size = 1;                                                   \
    for (int i = 0; i < r; i++) { size *= shape[i]; }                   \
    if (size == 0) { return; }                                          \
    int64_t k, n, m;                                                    \
    if (lmad_map_tr(&k, &n, &m,                                         \
                    r, dst_strides, src_strides, shape)) {              \
      log_transpose(ctx, k, n, m);                                      \
      map_transpose_##NAME                                              \
        (dst+dst_offset, src+src_offset, k, n, m, 0, n, 0, m);          \
    } else if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {   \
      if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}          \
      memcpy(dst+dst_offset, src+src_offset, size*sizeof(*dst));        \
    } else {                                                            \
      if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}       \
      lmad_copy_elements_##NAME                                         \
        (r,                                                             \
         dst+dst_offset, dst_strides,                                   \
         src+src_offset, src_strides, shape);                           \
    }                                                                   \
  }

GEN_MAP_TRANSPOSE(1b, uint8_t)
GEN_MAP_TRANSPOSE(2b, uint16_t)
GEN_MAP_TRANSPOSE(4b, uint32_t)
GEN_MAP_TRANSPOSE(8b, uint64_t)

GEN_LMAD_COPY_ELEMENTS(1b, uint8_t)
GEN_LMAD_COPY_ELEMENTS(2b, uint16_t)
GEN_LMAD_COPY_ELEMENTS(4b, uint32_t)
GEN_LMAD_COPY_ELEMENTS(8b, uint64_t)

GEN_LMAD_COPY(1b, uint8_t)
GEN_LMAD_COPY(2b, uint16_t)
GEN_LMAD_COPY(4b, uint32_t)
GEN_LMAD_COPY(8b, uint64_t)

// End of copy.h

#define FUTHARK_FUN_ATTR static

FUTHARK_FUN_ATTR int futrts_builtinzhiota_i64(struct futhark_context *ctx, struct memblock_device mem_21597, int64_t n_21598, int64_t x_21599, int64_t s_21600);
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_bool(struct futhark_context *ctx, struct memblock_device mem_22195, int64_t num_elems_22196, bool val_22197);
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i32(struct futhark_context *ctx, struct memblock_device mem_21713, int64_t num_elems_21714, int32_t val_21715);
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i64(struct futhark_context *ctx, struct memblock_device mem_21614, int64_t num_elems_21615, int64_t val_21616);
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i8(struct futhark_context *ctx, struct memblock_device mem_21687, int64_t num_elems_21688, int8_t val_21689);
FUTHARK_FUN_ATTR int futrts_entry_main(struct futhark_context *ctx, struct memblock_device *mem_out_p_22277, struct memblock_device *mem_out_p_22278, struct memblock_device *mem_out_p_22279, int64_t *out_prim_out_22280, int32_t max_depth_16892);
FUTHARK_FUN_ATTR int futrts_getPartitionBounds_8487(struct futhark_context *ctx, struct memblock_device *mem_out_p_22289, struct memblock_device *mem_out_p_22290, int64_t *out_prim_out_22291, int64_t *out_prim_out_22292, int32_t *out_prim_out_22293, int32_t *out_prim_out_22294, int32_t *out_prim_out_22295, struct memblock_device pXs_mem_21265, int64_t n_14235, int64_t b_14236, int32_t curDepth_14237, int32_t i_14239, int32_t j_14240);
FUTHARK_FUN_ATTR int futrts_set_bit_2464(struct futhark_context *ctx, int8_t *out_prim_out_22297, int32_t bit_12481, int8_t x_12482, int32_t b_12483);

static int init_constants(struct futhark_context *ctx)
{
    (void) ctx;
    
    int err = 0;
    
    #define counters_mem_21821 (ctx->constants->counters_mem_21821)
    #define counters_mem_21866 (ctx->constants->counters_mem_21866)
    #define global_dynid_mem_21636 (ctx->constants->global_dynid_mem_21636)
    #define global_dynid_mem_21711 (ctx->constants->global_dynid_mem_21711)
    #define global_dynid_mem_21924 (ctx->constants->global_dynid_mem_21924)
    #define global_dynid_mem_21927 (ctx->constants->global_dynid_mem_21927)
    #define global_dynid_mem_22062 (ctx->constants->global_dynid_mem_22062)
    counters_mem_21821.references = NULL;
    counters_mem_21866.references = NULL;
    global_dynid_mem_21636.references = NULL;
    global_dynid_mem_21711.references = NULL;
    global_dynid_mem_21924.references = NULL;
    global_dynid_mem_21927.references = NULL;
    global_dynid_mem_22062.references = NULL;
    if (memblock_alloc_device(ctx, &global_dynid_mem_21636, (int64_t) 4, "global_dynid_mem_21636")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_21636, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_21866, (int64_t) 81920, "counters_mem_21866")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_21866, (int64_t) 20480, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_21927, (int64_t) 4, "global_dynid_mem_21927")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_21927, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_21711, (int64_t) 4, "global_dynid_mem_21711")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_21711, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_21821, (int64_t) 80, "counters_mem_21821")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_21821, (int64_t) 20, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_21924, (int64_t) 4, "global_dynid_mem_21924")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_21924, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_22062, (int64_t) 4, "global_dynid_mem_22062")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_22062, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    #undef counters_mem_21821
    #undef counters_mem_21866
    #undef global_dynid_mem_21636
    #undef global_dynid_mem_21711
    #undef global_dynid_mem_21924
    #undef global_dynid_mem_21927
    #undef global_dynid_mem_22062
    
  cleanup:
    return err;
}
static int free_constants(struct futhark_context *ctx)
{
    (void) ctx;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_21821, "ctx->constants->counters_mem_21821") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_21866, "ctx->constants->counters_mem_21866") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_21636, "ctx->constants->global_dynid_mem_21636") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_21711, "ctx->constants->global_dynid_mem_21711") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_21924, "ctx->constants->global_dynid_mem_21924") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_21927, "ctx->constants->global_dynid_mem_21927") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_22062, "ctx->constants->global_dynid_mem_22062") != 0)
        return 1;
    return 0;
}
static int gpu_kernel_builtinzhiota_i64ziiota_i64_21602(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhiota_i64ziiota_i64_21602, "builtin#iota_i64.iota_i64_21602", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_builtinzhreplicate_boolzireplicate_22200(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, bool arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_boolzireplicate_22200, "builtin#replicate_bool.replicate_22200", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_builtinzhreplicate_i32zireplicate_21718(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int32_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_i32zireplicate_21718, "builtin#replicate_i32.replicate_21718", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_builtinzhreplicate_i64zireplicate_21619(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_i64zireplicate_21619, "builtin#replicate_i64.replicate_21619", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_builtinzhreplicate_i8zireplicate_21692(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int8_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_i8zireplicate_21692, "builtin#replicate_i8.replicate_21692", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_20809(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int32_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_20809, "main.segmap_20809", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegscan_20840(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int8_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegscan_20840, "main.segscan_20840", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegred_nonseg_20850(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegred_nonseg_20850, "main.segred_nonseg_20850", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_20872(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_20872, "main.segmap_20872", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzigpuseq_21863(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, gpu_mem arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzigpuseq_21863, "main.gpuseq_21863", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_20905(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_20905, "main.segmap_20905", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_20918(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_20918, "main.segmap_20918", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_20929(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_20929, "main.segmap_20929", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegscan_20943(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[17] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13};
        size_t args_sizes[17] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegscan_20943, "main.segscan_20943", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 17, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_20945(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_20945, "main.segmap_20945", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_20970(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_20970, "main.segmap_20970", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegscan_20982(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[16] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[16] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegscan_20982, "main.segscan_20982", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 16, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_20984(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_20984, "main.segmap_20984", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_21006(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4};
        size_t args_sizes[6] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_21006, "main.segmap_21006", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_21047(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_21047, "main.segmap_21047", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_21113(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_21113, "main.segmap_21113", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_21161(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_21161, "main.segmap_21161", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_21171(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int32_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[10] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8};
        size_t args_sizes[10] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_21171, "main.segmap_21171", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 10, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_21179(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int32_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_21179, "main.segmap_21179", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_21203(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_21203, "main.segmap_21203", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_getPartitionBounds_8487zisegmap_20546(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int8_t arg5, int8_t arg6, int64_t arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[15] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11};
        size_t args_sizes[15] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11)};
        
        return gpu_launch_kernel(ctx, ctx->program->getPartitionBounds_8487zisegmap_20546, "getPartitionBounds_8487.segmap_20546", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 15, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_getPartitionBounds_8487zisegmap_intrablock_20593(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int8_t arg5, int8_t arg6, gpu_mem arg7, gpu_mem arg8)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8)};
        
        return gpu_launch_kernel(ctx, ctx->program->getPartitionBounds_8487zisegmap_intrablock_20593, "getPartitionBounds_8487.segmap_intrablock_20593", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_getPartitionBounds_8487zisegmap_20648(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->getPartitionBounds_8487zisegmap_20648, "getPartitionBounds_8487.segmap_20648", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_getPartitionBounds_8487zisegmap_20666(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4};
        size_t args_sizes[6] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4)};
        
        return gpu_launch_kernel(ctx, ctx->program->getPartitionBounds_8487zisegmap_20666, "getPartitionBounds_8487.segmap_20666", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_getPartitionBounds_8487zisegmap_20677(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4};
        size_t args_sizes[6] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4)};
        
        return gpu_launch_kernel(ctx, ctx->program->getPartitionBounds_8487zisegmap_20677, "getPartitionBounds_8487.segmap_20677", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_getPartitionBounds_8487zisegmap_20693(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->getPartitionBounds_8487zisegmap_20693, "getPartitionBounds_8487.segmap_20693", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_getPartitionBounds_8487zisegmap_20711(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int8_t arg4, int8_t arg5, int64_t arg6, int32_t arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[13] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11};
        size_t args_sizes[13] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11)};
        
        return gpu_launch_kernel(ctx, ctx->program->getPartitionBounds_8487zisegmap_20711, "getPartitionBounds_8487.segmap_20711", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 13, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_getPartitionBounds_8487zisegred_small_20734(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->getPartitionBounds_8487zisegred_small_20734, "getPartitionBounds_8487.segred_small_20734", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_getPartitionBounds_8487zisegred_large_20734(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[13] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11};
        size_t args_sizes[13] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11)};
        
        return gpu_launch_kernel(ctx, ctx->program->getPartitionBounds_8487zisegred_large_20734, "getPartitionBounds_8487.segred_large_20734", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 13, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_getPartitionBounds_8487zisegmap_20749(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->getPartitionBounds_8487zisegmap_20749, "getPartitionBounds_8487.segmap_20749", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_getPartitionBounds_8487zisegscan_20760(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->getPartitionBounds_8487zisegscan_20760, "getPartitionBounds_8487.segscan_20760", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_getPartitionBounds_8487zisegmap_20768(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->getPartitionBounds_8487zisegmap_20768, "getPartitionBounds_8487.segmap_20768", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
struct futhark_u8_2d {
    struct memblock_device mem;
    int64_t shape[2];
};
struct futhark_u8_2d *futhark_new_u8_2d(struct futhark_context *ctx, const uint8_t *data, int64_t dim0, int64_t dim1)
{
    int err = 0;
    struct futhark_u8_2d *bad = NULL;
    struct futhark_u8_2d *arr = (struct futhark_u8_2d *) malloc(sizeof(struct futhark_u8_2d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * dim1 * 1, "arr->mem"))
        err = 1;
    arr->shape[0] = dim0;
    arr->shape[1] = dim1;
    err = memcpy_host2gpu(ctx, false, arr->mem.mem, 0, (const unsigned char *) data, 0, (size_t) (dim0 * dim1) * 1);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    if (err != 0) {
        free(arr);
        return bad;
    }
    return arr;
}
struct futhark_u8_2d *futhark_new_raw_u8_2d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0, int64_t dim1)
{
    int err = 0;
    struct futhark_u8_2d *bad = NULL;
    struct futhark_u8_2d *arr = (struct futhark_u8_2d *) malloc(sizeof(struct futhark_u8_2d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    arr->mem.mem = data;
    arr->shape[0] = dim0;
    arr->shape[1] = dim1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_u8_2d(struct futhark_context *ctx, struct futhark_u8_2d *arr)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_u8_2d(struct futhark_context *ctx, struct futhark_u8_2d *arr, uint8_t *data)
{
    int err = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    err = memcpy_gpu2host(ctx, false, (unsigned char *) data, 0, arr->mem.mem, 0, (size_t) (arr->shape[0] * arr->shape[1]) * 1);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return err;
}
int futhark_index_u8_2d(struct futhark_context *ctx, uint8_t *out, struct futhark_u8_2d *arr, int64_t i0, int64_t i1)
{
    int err = 0;
    
    if ((i0 >= 0 && i0 < arr->shape[0]) && (i1 >= 0 && i1 < arr->shape[1])) {
        lock_lock(&ctx->lock);
        CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
        err = memcpy_gpu2host(ctx, false, (unsigned char *) out, 0, arr->mem.mem, 1 * (i0 * arr->shape[1] + i1 * 1), 1);
        CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
        lock_unlock(&ctx->lock);
    } else {
        err = 1;
        set_error(ctx, strdup("Index out of bounds."));
    }
    return err;
}
CUdeviceptr futhark_values_raw_u8_2d(struct futhark_context *ctx, struct futhark_u8_2d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_u8_2d(struct futhark_context *ctx, struct futhark_u8_2d *arr)
{
    (void) ctx;
    return arr->shape;
}
struct futhark_i64_1d {
    struct memblock_device mem;
    int64_t shape[1];
};
struct futhark_i64_1d *futhark_new_i64_1d(struct futhark_context *ctx, const int64_t *data, int64_t dim0)
{
    int err = 0;
    struct futhark_i64_1d *bad = NULL;
    struct futhark_i64_1d *arr = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * 8, "arr->mem"))
        err = 1;
    arr->shape[0] = dim0;
    err = memcpy_host2gpu(ctx, false, arr->mem.mem, 0, (const unsigned char *) data, 0, (size_t) dim0 * 8);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    if (err != 0) {
        free(arr);
        return bad;
    }
    return arr;
}
struct futhark_i64_1d *futhark_new_raw_i64_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0)
{
    int err = 0;
    struct futhark_i64_1d *bad = NULL;
    struct futhark_i64_1d *arr = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    arr->mem.mem = data;
    arr->shape[0] = dim0;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr, int64_t *data)
{
    int err = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    err = memcpy_gpu2host(ctx, false, (unsigned char *) data, 0, arr->mem.mem, 0, (size_t) arr->shape[0] * 8);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return err;
}
int futhark_index_i64_1d(struct futhark_context *ctx, int64_t *out, struct futhark_i64_1d *arr, int64_t i0)
{
    int err = 0;
    
    if (i0 >= 0 && i0 < arr->shape[0]) {
        lock_lock(&ctx->lock);
        CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
        err = memcpy_gpu2host(ctx, false, (unsigned char *) out, 0, arr->mem.mem, 8 * (i0 * 1), 8);
        CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
        lock_unlock(&ctx->lock);
    } else {
        err = 1;
        set_error(ctx, strdup("Index out of bounds."));
    }
    return err;
}
CUdeviceptr futhark_values_raw_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr)
{
    (void) ctx;
    return arr->shape;
}
struct futhark_bool_1d {
    struct memblock_device mem;
    int64_t shape[1];
};
struct futhark_bool_1d *futhark_new_bool_1d(struct futhark_context *ctx, const bool *data, int64_t dim0)
{
    int err = 0;
    struct futhark_bool_1d *bad = NULL;
    struct futhark_bool_1d *arr = (struct futhark_bool_1d *) malloc(sizeof(struct futhark_bool_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * 1, "arr->mem"))
        err = 1;
    arr->shape[0] = dim0;
    err = memcpy_host2gpu(ctx, false, arr->mem.mem, 0, (const unsigned char *) data, 0, (size_t) dim0 * 1);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    if (err != 0) {
        free(arr);
        return bad;
    }
    return arr;
}
struct futhark_bool_1d *futhark_new_raw_bool_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0)
{
    int err = 0;
    struct futhark_bool_1d *bad = NULL;
    struct futhark_bool_1d *arr = (struct futhark_bool_1d *) malloc(sizeof(struct futhark_bool_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    arr->mem.mem = data;
    arr->shape[0] = dim0;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_bool_1d(struct futhark_context *ctx, struct futhark_bool_1d *arr)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_bool_1d(struct futhark_context *ctx, struct futhark_bool_1d *arr, bool *data)
{
    int err = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    err = memcpy_gpu2host(ctx, false, (unsigned char *) data, 0, arr->mem.mem, 0, (size_t) arr->shape[0] * 1);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return err;
}
int futhark_index_bool_1d(struct futhark_context *ctx, bool *out, struct futhark_bool_1d *arr, int64_t i0)
{
    int err = 0;
    
    if (i0 >= 0 && i0 < arr->shape[0]) {
        lock_lock(&ctx->lock);
        CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
        err = memcpy_gpu2host(ctx, false, (unsigned char *) out, 0, arr->mem.mem, 1 * (i0 * 1), 1);
        CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
        lock_unlock(&ctx->lock);
    } else {
        err = 1;
        set_error(ctx, strdup("Index out of bounds."));
    }
    return err;
}
CUdeviceptr futhark_values_raw_bool_1d(struct futhark_context *ctx, struct futhark_bool_1d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_bool_1d(struct futhark_context *ctx, struct futhark_bool_1d *arr)
{
    (void) ctx;
    return arr->shape;
}

FUTHARK_FUN_ATTR int futrts_builtinzhiota_i64(struct futhark_context *ctx, struct memblock_device mem_21597, int64_t n_21598, int64_t x_21599, int64_t s_21600)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_21821 = ctx->constants->counters_mem_21821;
    struct memblock_device counters_mem_21866 = ctx->constants->counters_mem_21866;
    struct memblock_device global_dynid_mem_21636 = ctx->constants->global_dynid_mem_21636;
    struct memblock_device global_dynid_mem_21711 = ctx->constants->global_dynid_mem_21711;
    struct memblock_device global_dynid_mem_21924 = ctx->constants->global_dynid_mem_21924;
    struct memblock_device global_dynid_mem_21927 = ctx->constants->global_dynid_mem_21927;
    struct memblock_device global_dynid_mem_22062 = ctx->constants->global_dynid_mem_22062;
    int64_t tblock_sizze_21606;
    
    tblock_sizze_21606 = *ctx->tuning_params.builtinzhiota_i64zitblock_sizze_21606;
    
    int64_t virt_num_tblocks_21607 = sdiv_up64(n_21598, tblock_sizze_21606);
    int64_t num_tblocks_21608 = smin64(virt_num_tblocks_21607, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhiota_i64ziiota_i64_21602(ctx, num_tblocks_21608, 1, 1, tblock_sizze_21606, 1, 1, (int64_t) 0, n_21598, x_21599, s_21600, virt_num_tblocks_21607, num_tblocks_21608, mem_21597.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_bool(struct futhark_context *ctx, struct memblock_device mem_22195, int64_t num_elems_22196, bool val_22197)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_21821 = ctx->constants->counters_mem_21821;
    struct memblock_device counters_mem_21866 = ctx->constants->counters_mem_21866;
    struct memblock_device global_dynid_mem_21636 = ctx->constants->global_dynid_mem_21636;
    struct memblock_device global_dynid_mem_21711 = ctx->constants->global_dynid_mem_21711;
    struct memblock_device global_dynid_mem_21924 = ctx->constants->global_dynid_mem_21924;
    struct memblock_device global_dynid_mem_21927 = ctx->constants->global_dynid_mem_21927;
    struct memblock_device global_dynid_mem_22062 = ctx->constants->global_dynid_mem_22062;
    int64_t replicate_n_22199 = num_elems_22196;
    int64_t tblock_sizze_22204;
    
    tblock_sizze_22204 = *ctx->tuning_params.builtinzhreplicate_boolzitblock_sizze_22204;
    
    int64_t virt_num_tblocks_22205 = sdiv_up64(replicate_n_22199, tblock_sizze_22204);
    int64_t num_tblocks_22206 = smin64(virt_num_tblocks_22205, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_boolzireplicate_22200(ctx, num_tblocks_22206, 1, 1, tblock_sizze_22204, 1, 1, (int64_t) 0, num_elems_22196, val_22197, replicate_n_22199, virt_num_tblocks_22205, num_tblocks_22206, mem_22195.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i32(struct futhark_context *ctx, struct memblock_device mem_21713, int64_t num_elems_21714, int32_t val_21715)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_21821 = ctx->constants->counters_mem_21821;
    struct memblock_device counters_mem_21866 = ctx->constants->counters_mem_21866;
    struct memblock_device global_dynid_mem_21636 = ctx->constants->global_dynid_mem_21636;
    struct memblock_device global_dynid_mem_21711 = ctx->constants->global_dynid_mem_21711;
    struct memblock_device global_dynid_mem_21924 = ctx->constants->global_dynid_mem_21924;
    struct memblock_device global_dynid_mem_21927 = ctx->constants->global_dynid_mem_21927;
    struct memblock_device global_dynid_mem_22062 = ctx->constants->global_dynid_mem_22062;
    int64_t replicate_n_21717 = num_elems_21714;
    int64_t tblock_sizze_21722;
    
    tblock_sizze_21722 = *ctx->tuning_params.builtinzhreplicate_i32zitblock_sizze_21722;
    
    int64_t virt_num_tblocks_21723 = sdiv_up64(replicate_n_21717, tblock_sizze_21722);
    int64_t num_tblocks_21724 = smin64(virt_num_tblocks_21723, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_i32zireplicate_21718(ctx, num_tblocks_21724, 1, 1, tblock_sizze_21722, 1, 1, (int64_t) 0, num_elems_21714, val_21715, replicate_n_21717, virt_num_tblocks_21723, num_tblocks_21724, mem_21713.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i64(struct futhark_context *ctx, struct memblock_device mem_21614, int64_t num_elems_21615, int64_t val_21616)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_21821 = ctx->constants->counters_mem_21821;
    struct memblock_device counters_mem_21866 = ctx->constants->counters_mem_21866;
    struct memblock_device global_dynid_mem_21636 = ctx->constants->global_dynid_mem_21636;
    struct memblock_device global_dynid_mem_21711 = ctx->constants->global_dynid_mem_21711;
    struct memblock_device global_dynid_mem_21924 = ctx->constants->global_dynid_mem_21924;
    struct memblock_device global_dynid_mem_21927 = ctx->constants->global_dynid_mem_21927;
    struct memblock_device global_dynid_mem_22062 = ctx->constants->global_dynid_mem_22062;
    int64_t replicate_n_21618 = num_elems_21615;
    int64_t tblock_sizze_21623;
    
    tblock_sizze_21623 = *ctx->tuning_params.builtinzhreplicate_i64zitblock_sizze_21623;
    
    int64_t virt_num_tblocks_21624 = sdiv_up64(replicate_n_21618, tblock_sizze_21623);
    int64_t num_tblocks_21625 = smin64(virt_num_tblocks_21624, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_i64zireplicate_21619(ctx, num_tblocks_21625, 1, 1, tblock_sizze_21623, 1, 1, (int64_t) 0, num_elems_21615, val_21616, replicate_n_21618, virt_num_tblocks_21624, num_tblocks_21625, mem_21614.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i8(struct futhark_context *ctx, struct memblock_device mem_21687, int64_t num_elems_21688, int8_t val_21689)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_21821 = ctx->constants->counters_mem_21821;
    struct memblock_device counters_mem_21866 = ctx->constants->counters_mem_21866;
    struct memblock_device global_dynid_mem_21636 = ctx->constants->global_dynid_mem_21636;
    struct memblock_device global_dynid_mem_21711 = ctx->constants->global_dynid_mem_21711;
    struct memblock_device global_dynid_mem_21924 = ctx->constants->global_dynid_mem_21924;
    struct memblock_device global_dynid_mem_21927 = ctx->constants->global_dynid_mem_21927;
    struct memblock_device global_dynid_mem_22062 = ctx->constants->global_dynid_mem_22062;
    int64_t replicate_n_21691 = num_elems_21688;
    int64_t tblock_sizze_21696;
    
    tblock_sizze_21696 = *ctx->tuning_params.builtinzhreplicate_i8zitblock_sizze_21696;
    
    int64_t virt_num_tblocks_21697 = sdiv_up64(replicate_n_21691, tblock_sizze_21696);
    int64_t num_tblocks_21698 = smin64(virt_num_tblocks_21697, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_i8zireplicate_21692(ctx, num_tblocks_21698, 1, 1, tblock_sizze_21696, 1, 1, (int64_t) 0, num_elems_21688, val_21689, replicate_n_21691, virt_num_tblocks_21697, num_tblocks_21698, mem_21687.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_main(struct futhark_context *ctx, struct memblock_device *mem_out_p_22277, struct memblock_device *mem_out_p_22278, struct memblock_device *mem_out_p_22279, int64_t *out_prim_out_22280, int32_t max_depth_16892)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_21521;
    
    mem_21521.references = NULL;
    
    struct memblock_device mem_21512;
    
    mem_21512.references = NULL;
    
    struct memblock_device mem_21511;
    
    mem_21511.references = NULL;
    
    struct memblock_device mem_21504;
    
    mem_21504.references = NULL;
    
    struct memblock_device mem_21503;
    
    mem_21503.references = NULL;
    
    struct memblock_device mem_21498;
    
    mem_21498.references = NULL;
    
    struct memblock_device mem_21493;
    
    mem_21493.references = NULL;
    
    struct memblock_device mem_21491;
    
    mem_21491.references = NULL;
    
    struct memblock_device mem_21485;
    
    mem_21485.references = NULL;
    
    struct memblock_device mem_21484;
    
    mem_21484.references = NULL;
    
    struct memblock_device mem_21486;
    
    mem_21486.references = NULL;
    
    struct memblock_device ext_mem_21487;
    
    ext_mem_21487.references = NULL;
    
    struct memblock_device ext_mem_21488;
    
    ext_mem_21488.references = NULL;
    
    struct memblock_device mem_21482;
    
    mem_21482.references = NULL;
    
    struct memblock_device mem_param_tmp_22039;
    
    mem_param_tmp_22039.references = NULL;
    
    struct memblock_device mem_param_tmp_22038;
    
    mem_param_tmp_22038.references = NULL;
    
    struct memblock_device mem_param_tmp_22166;
    
    mem_param_tmp_22166.references = NULL;
    
    struct memblock_device mem_param_tmp_22165;
    
    mem_param_tmp_22165.references = NULL;
    
    struct memblock_device mem_21467;
    
    mem_21467.references = NULL;
    
    struct memblock_device mem_21465;
    
    mem_21465.references = NULL;
    
    struct memblock_device ext_mem_21459;
    
    ext_mem_21459.references = NULL;
    
    struct memblock_device ext_mem_21460;
    
    ext_mem_21460.references = NULL;
    
    struct memblock_device mem_21457;
    
    mem_21457.references = NULL;
    
    struct memblock_device mem_param_21455;
    
    mem_param_21455.references = NULL;
    
    struct memblock_device mem_param_21452;
    
    mem_param_21452.references = NULL;
    
    struct memblock_device ext_mem_21472;
    
    ext_mem_21472.references = NULL;
    
    struct memblock_device ext_mem_21473;
    
    ext_mem_21473.references = NULL;
    
    struct memblock_device mem_21448;
    
    mem_21448.references = NULL;
    
    struct memblock_device mem_21446;
    
    mem_21446.references = NULL;
    
    struct memblock_device mem_21444;
    
    mem_21444.references = NULL;
    
    struct memblock_device incprefixes_mem_22060;
    
    incprefixes_mem_22060.references = NULL;
    
    struct memblock_device aggregates_mem_22058;
    
    aggregates_mem_22058.references = NULL;
    
    struct memblock_device status_flags_mem_22056;
    
    status_flags_mem_22056.references = NULL;
    
    struct memblock_device mem_21442;
    
    mem_21442.references = NULL;
    
    struct memblock_device mem_21440;
    
    mem_21440.references = NULL;
    
    struct memblock_device mem_21438;
    
    mem_21438.references = NULL;
    
    struct memblock_device mem_param_21435;
    
    mem_param_21435.references = NULL;
    
    struct memblock_device mem_param_21432;
    
    mem_param_21432.references = NULL;
    
    struct memblock_device ext_mem_21478;
    
    ext_mem_21478.references = NULL;
    
    struct memblock_device ext_mem_21479;
    
    ext_mem_21479.references = NULL;
    
    struct memblock_device ext_mem_21428;
    
    ext_mem_21428.references = NULL;
    
    struct memblock_device ext_mem_21429;
    
    ext_mem_21429.references = NULL;
    
    struct memblock_device mem_21426;
    
    mem_21426.references = NULL;
    
    struct memblock_device mem_param_tmp_21637;
    
    mem_param_tmp_21637.references = NULL;
    
    struct memblock_device mem_param_tmp_21636;
    
    mem_param_tmp_21636.references = NULL;
    
    struct memblock_device mem_param_tmp_21635;
    
    mem_param_tmp_21635.references = NULL;
    
    struct memblock_device mem_param_tmp_21634;
    
    mem_param_tmp_21634.references = NULL;
    
    struct memblock_device mem_param_tmp_21648;
    
    mem_param_tmp_21648.references = NULL;
    
    struct memblock_device mem_param_tmp_21647;
    
    mem_param_tmp_21647.references = NULL;
    
    struct memblock_device mem_param_tmp_21646;
    
    mem_param_tmp_21646.references = NULL;
    
    struct memblock_device mem_param_tmp_21645;
    
    mem_param_tmp_21645.references = NULL;
    
    struct memblock_device mem_21399;
    
    mem_21399.references = NULL;
    
    struct memblock_device mem_21397;
    
    mem_21397.references = NULL;
    
    struct memblock_device mem_21390;
    
    mem_21390.references = NULL;
    
    struct memblock_device mem_21389;
    
    mem_21389.references = NULL;
    
    struct memblock_device mem_21387;
    
    mem_21387.references = NULL;
    
    struct memblock_device mem_21385;
    
    mem_21385.references = NULL;
    
    struct memblock_device incprefixes_mem_21922;
    
    incprefixes_mem_21922.references = NULL;
    
    struct memblock_device aggregates_mem_21920;
    
    aggregates_mem_21920.references = NULL;
    
    struct memblock_device status_flags_mem_21918;
    
    status_flags_mem_21918.references = NULL;
    
    struct memblock_device mem_21383;
    
    mem_21383.references = NULL;
    
    struct memblock_device mem_21381;
    
    mem_21381.references = NULL;
    
    struct memblock_device mem_21379;
    
    mem_21379.references = NULL;
    
    struct memblock_device ext_mem_21375;
    
    ext_mem_21375.references = NULL;
    
    struct memblock_device ext_mem_21376;
    
    ext_mem_21376.references = NULL;
    
    struct memblock_device mem_21373;
    
    mem_21373.references = NULL;
    
    struct memblock_device mem_param_tmp_21659;
    
    mem_param_tmp_21659.references = NULL;
    
    struct memblock_device mem_param_tmp_21658;
    
    mem_param_tmp_21658.references = NULL;
    
    struct memblock_device mem_21350;
    
    mem_21350.references = NULL;
    
    struct memblock_device mem_21348;
    
    mem_21348.references = NULL;
    
    struct memblock_device mem_21339;
    
    mem_21339.references = NULL;
    
    struct memblock_device mem_21337;
    
    mem_21337.references = NULL;
    
    struct memblock_device mem_param_tmp_21675;
    
    mem_param_tmp_21675.references = NULL;
    
    struct memblock_device mem_param_tmp_21674;
    
    mem_param_tmp_21674.references = NULL;
    
    struct memblock_device mem_21329;
    
    mem_21329.references = NULL;
    
    struct memblock_device mem_21328;
    
    mem_21328.references = NULL;
    
    struct memblock_device segred_tmp_mem_21823;
    
    segred_tmp_mem_21823.references = NULL;
    
    struct memblock_device incprefixes_mem_21709;
    
    incprefixes_mem_21709.references = NULL;
    
    struct memblock_device aggregates_mem_21707;
    
    aggregates_mem_21707.references = NULL;
    
    struct memblock_device status_flags_mem_21685;
    
    status_flags_mem_21685.references = NULL;
    
    struct memblock_device mem_param_21316;
    
    mem_param_21316.references = NULL;
    
    struct memblock_device mem_param_21313;
    
    mem_param_21313.references = NULL;
    
    struct memblock_device ext_mem_21334;
    
    ext_mem_21334.references = NULL;
    
    struct memblock_device ext_mem_21335;
    
    ext_mem_21335.references = NULL;
    
    struct memblock_device mem_param_21304;
    
    mem_param_21304.references = NULL;
    
    struct memblock_device mem_param_21301;
    
    mem_param_21301.references = NULL;
    
    struct memblock_device ext_mem_21370;
    
    ext_mem_21370.references = NULL;
    
    struct memblock_device ext_mem_21371;
    
    ext_mem_21371.references = NULL;
    
    struct memblock_device mem_21355;
    
    mem_21355.references = NULL;
    
    struct memblock_device mem_21353;
    
    mem_21353.references = NULL;
    
    struct memblock_device mem_21323;
    
    mem_21323.references = NULL;
    
    struct memblock_device mem_21321;
    
    mem_21321.references = NULL;
    
    struct memblock_device mem_21319;
    
    mem_21319.references = NULL;
    
    struct memblock_device mem_21310;
    
    mem_21310.references = NULL;
    
    struct memblock_device mem_21297;
    
    mem_21297.references = NULL;
    
    struct memblock_device mem_param_21295;
    
    mem_param_21295.references = NULL;
    
    struct memblock_device mem_param_21291;
    
    mem_param_21291.references = NULL;
    
    struct memblock_device mem_param_21288;
    
    mem_param_21288.references = NULL;
    
    struct memblock_device mem_param_21285;
    
    mem_param_21285.references = NULL;
    
    struct memblock_device ext_mem_21409;
    
    ext_mem_21409.references = NULL;
    
    struct memblock_device ext_mem_21410;
    
    ext_mem_21410.references = NULL;
    
    struct memblock_device ext_mem_21411;
    
    ext_mem_21411.references = NULL;
    
    struct memblock_device ext_mem_21412;
    
    ext_mem_21412.references = NULL;
    
    struct memblock_device mem_param_21282;
    
    mem_param_21282.references = NULL;
    
    struct memblock_device mem_param_21279;
    
    mem_param_21279.references = NULL;
    
    struct memblock_device mem_param_21276;
    
    mem_param_21276.references = NULL;
    
    struct memblock_device mem_param_21272;
    
    mem_param_21272.references = NULL;
    
    struct memblock_device ext_mem_21422;
    
    ext_mem_21422.references = NULL;
    
    struct memblock_device ext_mem_21423;
    
    ext_mem_21423.references = NULL;
    
    struct memblock_device ext_mem_21424;
    
    ext_mem_21424.references = NULL;
    
    struct memblock_device ext_mem_21425;
    
    ext_mem_21425.references = NULL;
    
    struct memblock_device mem_21325;
    
    mem_21325.references = NULL;
    
    struct memblock_device mem_21269;
    
    mem_21269.references = NULL;
    
    struct memblock_device mem_21268;
    
    mem_21268.references = NULL;
    
    struct memblock_device mem_21267;
    
    mem_21267.references = NULL;
    
    struct memblock_device mem_21266;
    
    mem_21266.references = NULL;
    
    struct memblock_device mem_21265;
    
    mem_21265.references = NULL;
    
    struct memblock_device mem_out_21594;
    
    mem_out_21594.references = NULL;
    
    struct memblock_device mem_out_21593;
    
    mem_out_21593.references = NULL;
    
    struct memblock_device mem_out_21592;
    
    mem_out_21592.references = NULL;
    
    struct memblock_device counters_mem_21821 = ctx->constants->counters_mem_21821;
    struct memblock_device counters_mem_21866 = ctx->constants->counters_mem_21866;
    struct memblock_device global_dynid_mem_21636 = ctx->constants->global_dynid_mem_21636;
    struct memblock_device global_dynid_mem_21711 = ctx->constants->global_dynid_mem_21711;
    struct memblock_device global_dynid_mem_21924 = ctx->constants->global_dynid_mem_21924;
    struct memblock_device global_dynid_mem_21927 = ctx->constants->global_dynid_mem_21927;
    struct memblock_device global_dynid_mem_22062 = ctx->constants->global_dynid_mem_22062;
    int64_t prim_out_21595;
    
    if (memblock_alloc_device(ctx, &mem_21265, (int64_t) 16, "mem_21265")) {
        err = 1;
        goto cleanup;
    }
    
    struct memblock mainzistatic_array_21596 = (struct memblock) {NULL, (unsigned char *) mainzistatic_array_realtype_22281, 0, "main.static_array_21596"};
    
    if ((err = lmad_copy_host2gpu(ctx, 1, true, 1, mem_21265.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mainzistatic_array_21596.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {(int64_t) 16})) != 0)
        goto cleanup;
    if (memblock_alloc_device(ctx, &mem_21266, (int64_t) 64, "mem_21266")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhiota_i64(ctx, mem_21266, (int64_t) 8, (int64_t) 0, (int64_t) 1) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_21267, (int64_t) 8, "mem_21267")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_21267, (int64_t) 1, (int64_t) 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_21268, (int64_t) 8, "mem_21268")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_21268, (int64_t) 1, (int64_t) 8) != 0) {
        err = 1;
        goto cleanup;
    }
    
    bool loop_cond_t_res_18656 = slt32(0, max_depth_16892);
    
    if (memblock_alloc_device(ctx, &mem_21269, (int64_t) 0, "mem_21269")) {
        err = 1;
        goto cleanup;
    }
    
    int64_t segmap_tblock_sizze_20805;
    
    segmap_tblock_sizze_20805 = *ctx->tuning_params.mainzisegmap_tblock_sizze_20778;
    
    int64_t segscan_tblock_sizze_20835;
    
    segscan_tblock_sizze_20835 = *ctx->tuning_params.mainzisegscan_tblock_sizze_20834;
    
    int64_t segred_tblock_sizze_20843;
    
    segred_tblock_sizze_20843 = *ctx->tuning_params.mainzisegred_tblock_sizze_20842;
    
    int64_t segmap_tblock_sizze_20868;
    
    segmap_tblock_sizze_20868 = *ctx->tuning_params.mainzisegmap_tblock_sizze_20854;
    
    int64_t segmap_tblock_sizze_20900;
    
    segmap_tblock_sizze_20900 = *ctx->tuning_params.mainzisegmap_tblock_sizze_20888;
    
    int64_t segmap_tblock_sizze_20922;
    
    segmap_tblock_sizze_20922 = *ctx->tuning_params.mainzisegmap_tblock_sizze_20921;
    
    int64_t segmap_tblock_sizze_20932;
    
    segmap_tblock_sizze_20932 = *ctx->tuning_params.mainzisegmap_tblock_sizze_20931;
    
    int64_t segscan_tblock_sizze_20938;
    
    segscan_tblock_sizze_20938 = *ctx->tuning_params.mainzisegscan_tblock_sizze_20937;
    
    int64_t segmap_tblock_sizze_20948;
    
    segmap_tblock_sizze_20948 = *ctx->tuning_params.mainzisegmap_tblock_sizze_20947;
    
    int64_t segmap_tblock_sizze_20965;
    
    segmap_tblock_sizze_20965 = *ctx->tuning_params.mainzisegmap_tblock_sizze_20955;
    if (memblock_alloc_device(ctx, &mem_21325, (int64_t) 8, "mem_21325")) {
        err = 1;
        goto cleanup;
    }
    
    int64_t partition_and_deepen_res_18658;
    bool partition_and_deepen_res_18659;
    int32_t partition_and_deepen_res_18660;
    int64_t loop_dz2087U_18665;
    bool loop_while_18666;
    int32_t p_18667;
    
    if (memblock_set_device(ctx, &mem_param_21272, &mem_21266, "mem_21266") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_21276, &mem_21265, "mem_21265") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_21279, &mem_21267, "mem_21267") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_21282, &mem_21268, "mem_21268") != 0)
        return 1;
    loop_dz2087U_18665 = (int64_t) 1;
    loop_while_18666 = loop_cond_t_res_18656;
    p_18667 = 0;
    while (loop_while_18666) {
        bool loop_nonempty_19289 = slt64((int64_t) 0, loop_dz2087U_18665);
        int32_t newDepth_18703 = add32(1, p_18667);
        int32_t new_i_18704 = mul32(4, p_18667);
        int32_t zm_lhs_18705 = mul32(4, newDepth_18703);
        int32_t new_j_18706 = sub32(zm_lhs_18705, 1);
        int32_t tmp_18707 = add32(2, new_i_18704);
        int64_t i_18708 = sext_i32_i64(new_i_18704);
        int64_t j_18709 = sext_i32_i64(new_j_18706);
        int64_t tmp_18710 = sext_i32_i64(tmp_18707);
        bool step_zzero_18711 = new_i_18704 == tmp_18707;
        bool bounds_invalid_upwards_18712 = slt32(new_j_18706, new_i_18704);
        bool range_invalid_18716 = step_zzero_18711 || bounds_invalid_upwards_18712;
        bool valid_18717 = !range_invalid_18716;
        bool loop_not_taken_19290 = !loop_nonempty_19289;
        bool protect_assert_disj_19291 = valid_18717 || loop_not_taken_19290;
        bool range_valid_c_18718;
        
        if (!protect_assert_disj_19291) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) i_18708, "..", (long long) tmp_18710, "...", (long long) j_18709, " is invalid.", "-> #0  ftHashJoin.fut:65:15-34\n   #1  ftHashJoin.fut:112:20-118:6\n   #2  ftHashJoin.fut:185:6-89\n   #3  ftHashJoin.fut:354:1-362:42\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int32_t distance_upwards_exclusive_18713 = sub32(new_j_18706, new_i_18704);
        int64_t distance_exclusive_18714 = sext_i32_i64(distance_upwards_exclusive_18713);
        int64_t distance_18715 = add64((int64_t) 1, distance_exclusive_18714);
        int64_t num_elems_18719 = sdiv_up64(distance_18715, (int64_t) 2);
        int64_t loopres_18672;
        int64_t loop_dz2081Uz2089U_18678;
        
        if (memblock_set_device(ctx, &mem_param_21285, &mem_21269, "mem_21269") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_21288, &mem_21269, "mem_21269") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_21291, &mem_param_21272, "mem_param_21272") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_21295, &mem_param_21276, "mem_param_21276") != 0)
            return 1;
        loop_dz2081Uz2089U_18678 = (int64_t) 0;
        for (int64_t i_18677 = 0; i_18677 < loop_dz2087U_18665; i_18677++) {
            int64_t read_res_22282;
            
            if ((err = gpu_scalar_from_device(ctx, &read_res_22282, mem_param_21279.mem, i_18677 * sizeof(int64_t), sizeof(int64_t))) != 0)
                goto cleanup;
            if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                err = 1;
                goto cleanup;
            }
            
            int64_t bounds_18683 = read_res_22282;
            int64_t read_res_22283;
            
            if ((err = gpu_scalar_from_device(ctx, &read_res_22283, mem_param_21282.mem, i_18677 * sizeof(int64_t), sizeof(int64_t))) != 0)
                goto cleanup;
            if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                err = 1;
                goto cleanup;
            }
            
            int64_t bounds_18684 = read_res_22283;
            int64_t dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685 = sub64(bounds_18684, bounds_18683);
            bool empty_slice_18686 = dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685 == (int64_t) 0;
            int64_t m_18687 = sub64(dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, (int64_t) 1);
            int64_t i_p_m_t_s_18688 = add64(bounds_18683, m_18687);
            bool zzero_leq_i_p_m_t_s_18689 = sle64((int64_t) 0, i_p_m_t_s_18688);
            bool i_p_m_t_s_leq_w_18690 = slt64(i_p_m_t_s_18688, (int64_t) 8);
            bool zzero_lte_i_18691 = sle64((int64_t) 0, bounds_18683);
            bool i_lte_j_18692 = sle64(bounds_18683, bounds_18684);
            bool y_18693 = i_p_m_t_s_leq_w_18690 && zzero_lte_i_18691;
            bool y_18694 = zzero_leq_i_p_m_t_s_18689 && y_18693;
            bool forwards_ok_18695 = i_lte_j_18692 && y_18694;
            bool ok_or_empty_18696 = empty_slice_18686 || forwards_ok_18695;
            bool index_certs_18697;
            
            if (!ok_or_empty_18696) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) bounds_18683, ":", (long long) bounds_18684, "] out of bounds for array of shape [", (long long) (int64_t) 8, "].", "-> #0  ftHashJoin.fut:145:21-47\n   #1  ftHashJoin.fut:185:6-89\n   #2  ftHashJoin.fut:354:1-362:42\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            
            int64_t bytes_21296 = (int64_t) 8 * dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685;
            
            if (memblock_alloc_device(ctx, &mem_21297, bytes_21296, "mem_21297")) {
                err = 1;
                goto cleanup;
            }
            if (futrts_builtinzhreplicate_i64(ctx, mem_21297, dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, (int64_t) 0) != 0) {
                err = 1;
                goto cleanup;
            }
            
            int64_t zm_lhs_18722 = add64((int64_t) 256, dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685);
            int64_t zs_lhs_18723 = sub64(zm_lhs_18722, (int64_t) 1);
            int64_t m_18729 = sdiv_safe64(zs_lhs_18723, (int64_t) 256);
            bool loop_cond_18730 = slt64((int64_t) 0, m_18729);
            int64_t segmap_usable_groups_20806 = sdiv_up_safe64(dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, segmap_tblock_sizze_20805);
            int64_t num_tblocks_20837;
            int64_t max_num_tblocks_21654;
            
            max_num_tblocks_21654 = *ctx->tuning_params.mainzisegscan_num_tblocks_20836;
            num_tblocks_20837 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, segscan_tblock_sizze_20835), max_num_tblocks_21654)));
            
            int64_t num_tblocks_20845;
            int64_t max_num_tblocks_21655;
            
            max_num_tblocks_21655 = *ctx->tuning_params.mainzisegred_num_tblocks_20844;
            num_tblocks_20845 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, segred_tblock_sizze_20843), max_num_tblocks_21655)));
            
            int64_t segmap_usable_groups_20869 = sdiv_up_safe64(dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, segmap_tblock_sizze_20868);
            int64_t segmap_usable_groups_20901 = sdiv_up_safe64(dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, segmap_tblock_sizze_20900);
            int64_t nest_sizze_20920 = (int64_t) 2 * dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685;
            int64_t num_tblocks_20924;
            int64_t max_num_tblocks_21656;
            
            max_num_tblocks_21656 = *ctx->tuning_params.mainzisegmap_num_tblocks_20923;
            num_tblocks_20924 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nest_sizze_20920, segmap_tblock_sizze_20922), max_num_tblocks_21656)));
            
            int64_t num_tblocks_20934;
            int64_t max_num_tblocks_21657;
            
            max_num_tblocks_21657 = *ctx->tuning_params.mainzisegmap_num_tblocks_20933;
            num_tblocks_20934 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, segmap_tblock_sizze_20932), max_num_tblocks_21657)));
            
            int64_t binop_y_21305 = (int64_t) 2 * bounds_18683;
            
            if (memblock_alloc_device(ctx, &mem_21310, dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, "mem_21310")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &mem_21319, bytes_21296, "mem_21319")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &mem_21321, bytes_21296, "mem_21321")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &mem_21323, bytes_21296, "mem_21323")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &mem_21353, bytes_21296, "mem_21353")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &mem_21355, bytes_21296, "mem_21355")) {
                err = 1;
                goto cleanup;
            }
            
            int64_t ext_21369;
            int64_t ext_21366;
            int64_t ctx_param_ext_21298;
            int64_t ctx_param_ext_21302;
            
            if (memblock_set_device(ctx, &mem_param_21301, &mem_param_21295, "mem_param_21295") != 0)
                return 1;
            if (memblock_set_device(ctx, &mem_param_21304, &mem_param_21291, "mem_param_21291") != 0)
                return 1;
            ctx_param_ext_21298 = binop_y_21305;
            ctx_param_ext_21302 = bounds_18683;
            for (int64_t i_18733 = 0; i_18733 < num_elems_18719; i_18733++) {
                int32_t binop_x_18736 = sext_i64_i32(i_18733);
                int32_t binop_x_18737 = mul32(2, binop_x_18736);
                int32_t index_primexp_18738 = add32(new_i_18704, binop_x_18737);
                int32_t zm_lhs_18739 = add32(2, index_primexp_18738);
                int32_t min_arg1_18740 = sub32(zm_lhs_18739, 1);
                int32_t min_res_18741 = smin32(new_j_18706, min_arg1_18740);
                int32_t zp_lhs_18742 = sub32(min_res_18741, index_primexp_18738);
                int32_t ij_bits_18743 = add32(1, zp_lhs_18742);
                int32_t up_to_18744 = shl32(1, ij_bits_18743);
                int64_t tmp_18745 = sext_i32_i64(zp_lhs_18742);
                bool bounds_invalid_upwards_18746 = slt32(zp_lhs_18742, 0);
                bool valid_18748 = !bounds_invalid_upwards_18746;
                bool range_valid_c_18749;
                
                if (!valid_18748) {
                    set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) (int64_t) 0, "...", (long long) tmp_18745, " is invalid.", "-> #0  ftbasics.fut:113:17-26\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftHashJoin.fut:53:87-90\n   #3  ftHashJoin.fut:66:6-70\n   #4  ftHashJoin.fut:112:20-118:6\n   #5  ftHashJoin.fut:185:6-89\n   #6  ftHashJoin.fut:354:1-362:42\n"));
                    err = FUTHARK_PROGRAM_ERROR;
                    goto cleanup;
                }
                
                int64_t up_to_18759 = sext_i32_i64(up_to_18744);
                bool bounds_invalid_upwards_18760 = slt32(up_to_18744, 0);
                bool valid_18761 = !bounds_invalid_upwards_18760;
                bool range_valid_c_18762;
                
                if (!valid_18761) {
                    set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) (int64_t) 0, "..<", (long long) up_to_18759, " is invalid.", "-> #0  ftbasics.fut:137:21-30\n   #1  ftHashJoin.fut:53:87-90\n   #2  ftHashJoin.fut:66:6-70\n   #3  ftHashJoin.fut:112:20-118:6\n   #4  ftHashJoin.fut:185:6-89\n   #5  ftHashJoin.fut:354:1-362:42\n"));
                    err = FUTHARK_PROGRAM_ERROR;
                    goto cleanup;
                }
                
                int64_t distance_18747 = add64((int64_t) 1, tmp_18745);
                
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_21664 = sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, segmap_tblock_sizze_20805));
                
                {
                    err = gpu_kernel_mainzisegmap_20809(ctx, segmap_usable_groups_20806, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_20778, 1, 1, (int64_t) 0, dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, index_primexp_18738, distance_18747, ctx_param_ext_21298, mem_param_21301.mem, mem_21310.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                ctx->failure_is_an_option = 1;
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                if (memblock_set_device(ctx, &mem_param_21313, &mem_21267, "mem_21267") != 0)
                    return 1;
                if (memblock_set_device(ctx, &mem_param_21316, &mem_21297, "mem_21297") != 0)
                    return 1;
                for (int64_t i_18765 = 0; i_18765 < up_to_18759; i_18765++) {
                    int32_t binop_x_18768 = sext_i64_i32(i_18765);
                    int8_t index_primexp_18769 = zext_i32_i8(binop_x_18768);
                    
                    if (slt64((int64_t) 0, dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685)) {
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "\n# SegScan");
                        
                        int64_t shared_memory_21678;
                        
                        shared_memory_21678 = ctx->max_shared_memory;
                        
                        int64_t thread_block_sizze_21679;
                        
                        thread_block_sizze_21679 = ctx->max_thread_block_size;
                        
                        int64_t registers_21680;
                        
                        registers_21680 = ctx->max_registers;
                        
                        int64_t thread_block_sizze_21681;
                        
                        thread_block_sizze_21681 = ctx->max_thread_block_size;
                        
                        int64_t chunk_sizze_21682 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_21678, thread_block_sizze_21679), (int64_t) 8), squot64(squot64(registers_21680, thread_block_sizze_21681) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
                        int64_t num_virt_blocks_21683 = sdiv_up64(dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, segscan_tblock_sizze_20835 * chunk_sizze_21682);
                        int64_t num_virt_threads_21684 = num_virt_blocks_21683 * segscan_tblock_sizze_20835;
                        
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_21682, '\n');
                        if (memblock_alloc_device(ctx, &status_flags_mem_21685, num_virt_blocks_21683, "status_flags_mem_21685")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_21685, num_virt_blocks_21683, (int8_t) 0) != 0) {
                            err = 1;
                            goto cleanup;
                        }
                        if (memblock_alloc_device(ctx, &aggregates_mem_21707, (int64_t) 8 * num_virt_blocks_21683, "aggregates_mem_21707")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (memblock_alloc_device(ctx, &incprefixes_mem_21709, (int64_t) 8 * num_virt_blocks_21683, "incprefixes_mem_21709")) {
                            err = 1;
                            goto cleanup;
                        }
                        {
                            err = gpu_kernel_mainzisegscan_20840(ctx, num_tblocks_20837, 1, 1, *ctx->tuning_params.mainzisegscan_tblock_sizze_20834, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_20835), chunk_sizze_21682 * segscan_tblock_sizze_20835 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_20835), chunk_sizze_21682 * segscan_tblock_sizze_20835 * (int64_t) 8), (int64_t) 8), (int64_t) 8), dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, index_primexp_18769, num_tblocks_20837, num_virt_blocks_21683, num_virt_threads_21684, mem_21310.mem, mem_21319.mem, mem_21321.mem, mem_21323.mem, status_flags_mem_21685.mem, aggregates_mem_21707.mem, incprefixes_mem_21709.mem, global_dynid_mem_21711.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "");
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegRed");
                    
                    int64_t chunk_sizze_21820 = (int64_t) 1;
                    
                    if (memblock_alloc_device(ctx, &segred_tmp_mem_21823, (int64_t) 8 * num_tblocks_20845, "segred_tmp_mem_21823")) {
                        err = 1;
                        goto cleanup;
                    }
                    
                    int64_t num_threads_21825 = num_tblocks_20845 * segred_tblock_sizze_20843;
                    
                    {
                        err = gpu_kernel_mainzisegred_nonseg_20850(ctx, num_tblocks_20845, 1, 1, *ctx->tuning_params.mainzisegred_tblock_sizze_20842, 1, 1, 8 + ((int64_t) 8 * segred_tblock_sizze_20843 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_20843, (int64_t) 8), (int64_t) 8)), dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, num_tblocks_20845, num_threads_21825, mem_21321.mem, mem_21325.mem, counters_mem_21821.mem, segred_tmp_mem_21823.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_alloc_device(ctx, &mem_21328, bytes_21296, "mem_21328")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t virt_num_tblocks_21854 = sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, segmap_tblock_sizze_20868));
                    
                    {
                        err = gpu_kernel_mainzisegmap_20872(ctx, segmap_usable_groups_20869, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_20854, 1, 1, (int64_t) 0, dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, mem_param_21313.mem, mem_param_21316.mem, mem_21319.mem, mem_21323.mem, mem_21328.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_alloc_device(ctx, &mem_21329, (int64_t) 8, "mem_21329")) {
                        err = 1;
                        goto cleanup;
                    }
                    {
                        err = gpu_kernel_mainzigpuseq_21863(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, mem_param_21313.mem, mem_21325.mem, mem_21329.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (memblock_set_device(ctx, &mem_param_tmp_21674, &mem_21329, "mem_21329") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &mem_param_tmp_21675, &mem_21328, "mem_21328") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &mem_param_21313, &mem_param_tmp_21674, "mem_param_tmp_21674") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &mem_param_21316, &mem_param_tmp_21675, "mem_param_tmp_21675") != 0)
                        return 1;
                }
                if (memblock_set_device(ctx, &ext_mem_21335, &mem_param_21313, "mem_param_21313") != 0)
                    return 1;
                if (memblock_set_device(ctx, &ext_mem_21334, &mem_param_21316, "mem_param_21316") != 0)
                    return 1;
                if (memblock_alloc_device(ctx, &mem_21337, nest_sizze_20920, "mem_21337")) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_1b(ctx, 2, mem_21337.mem, (int64_t) 0, (int64_t []) {(int64_t) 2, (int64_t) 1}, mem_param_21301.mem, ctx_param_ext_21298, (int64_t []) {(int64_t) 2, (int64_t) 1}, (int64_t []) {dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, (int64_t) 2})) != 0)
                    goto cleanup;
                if (memblock_alloc_device(ctx, &mem_21339, bytes_21296, "mem_21339")) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_21339.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_21304.mem, ctx_param_ext_21302, (int64_t []) {(int64_t) 1}, (int64_t []) {dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685})) != 0)
                    goto cleanup;
                
                bool partitioned_scatter_res_18801;
                int64_t partitioned_scatter_res_18804;
                bool loop_while_18805;
                int64_t p_18808;
                
                loop_while_18805 = loop_cond_18730;
                p_18808 = (int64_t) 0;
                while (loop_while_18805) {
                    int64_t lower_bound_18809 = mul64((int64_t) 256, p_18808);
                    int64_t min_arg1_18810 = add64((int64_t) 256, lower_bound_18809);
                    int64_t min_res_18811 = smin64(dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, min_arg1_18810);
                    int64_t j_m_i_18812 = sub64(min_res_18811, lower_bound_18809);
                    bool empty_slice_18813 = j_m_i_18812 == (int64_t) 0;
                    int64_t m_18814 = sub64(j_m_i_18812, (int64_t) 1);
                    int64_t i_p_m_t_s_18815 = add64(lower_bound_18809, m_18814);
                    bool zzero_leq_i_p_m_t_s_18816 = sle64((int64_t) 0, i_p_m_t_s_18815);
                    bool i_p_m_t_s_leq_w_18817 = slt64(i_p_m_t_s_18815, dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685);
                    bool zzero_lte_i_18818 = sle64((int64_t) 0, lower_bound_18809);
                    bool i_lte_j_18819 = sle64(lower_bound_18809, min_res_18811);
                    bool y_18820 = i_p_m_t_s_leq_w_18817 && zzero_lte_i_18818;
                    bool y_18821 = zzero_leq_i_p_m_t_s_18816 && y_18820;
                    bool forwards_ok_18822 = i_lte_j_18819 && y_18821;
                    bool ok_or_empty_18823 = empty_slice_18813 || forwards_ok_18822;
                    bool index_certs_18824;
                    
                    if (!ok_or_empty_18823) {
                        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) lower_bound_18809, ":", (long long) min_res_18811, "] out of bounds for array of shape [", (long long) dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, "].", "-> #0  ftbasics.fut:72:25-56\n   #1  ftHashJoin.fut:53:87-90\n   #2  ftHashJoin.fut:66:6-70\n   #3  ftHashJoin.fut:112:20-118:6\n   #4  ftHashJoin.fut:185:6-89\n   #5  ftHashJoin.fut:354:1-362:42\n"));
                        err = FUTHARK_PROGRAM_ERROR;
                        goto cleanup;
                    }
                    
                    int64_t bytes_21347 = (int64_t) 2 * j_m_i_18812;
                    int64_t bytes_21349 = (int64_t) 8 * j_m_i_18812;
                    
                    if (memblock_alloc_device(ctx, &mem_21348, bytes_21347, "mem_21348")) {
                        err = 1;
                        goto cleanup;
                    }
                    if ((err = lmad_copy_gpu2gpu_1b(ctx, 2, mem_21348.mem, (int64_t) 0, (int64_t []) {(int64_t) 2, (int64_t) 1}, mem_21337.mem, (int64_t) 0 + (int64_t) 2 * lower_bound_18809, (int64_t []) {(int64_t) 2, (int64_t) 1}, (int64_t []) {j_m_i_18812, (int64_t) 2})) != 0)
                        goto cleanup;
                    if (memblock_alloc_device(ctx, &mem_21350, bytes_21349, "mem_21350")) {
                        err = 1;
                        goto cleanup;
                    }
                    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_21350.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_21339.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_18809, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_18812})) != 0)
                        goto cleanup;
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t virt_num_tblocks_21873 = sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, segmap_tblock_sizze_20900));
                    
                    {
                        err = gpu_kernel_mainzisegmap_20905(ctx, segmap_usable_groups_20901, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_20888, 1, 1, (int64_t) 0, dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, lower_bound_18809, min_res_18811, ext_mem_21334.mem, mem_21353.mem, mem_21355.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t virt_num_tblocks_21882 = sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685 * (int64_t) 2, segmap_tblock_sizze_20922));
                    
                    {
                        err = gpu_kernel_mainzisegmap_20918(ctx, num_tblocks_20924, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_20921, 1, 1, (int64_t) 0, dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, j_m_i_18812, num_tblocks_20924, ctx_param_ext_21298, virt_num_tblocks_21882, mem_param_21301.mem, mem_21348.mem, mem_21353.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t virt_num_tblocks_21897 = sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, segmap_tblock_sizze_20932));
                    
                    {
                        err = gpu_kernel_mainzisegmap_20929(ctx, num_tblocks_20934, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_20931, 1, 1, (int64_t) 0, dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, j_m_i_18812, num_tblocks_20934, ctx_param_ext_21302, virt_num_tblocks_21897, mem_param_21304.mem, mem_21350.mem, mem_21355.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    
                    int64_t tmp_18836 = add64((int64_t) 1, p_18808);
                    
                    if ((err = lmad_copy_gpu2gpu_1b(ctx, 2, mem_21337.mem, (int64_t) 2 * lower_bound_18809, (int64_t []) {(int64_t) 2, (int64_t) 1}, mem_21348.mem, (int64_t) 0, (int64_t []) {(int64_t) 2, (int64_t) 1}, (int64_t []) {j_m_i_18812, (int64_t) 2})) != 0)
                        goto cleanup;
                    if (memblock_unref_device(ctx, &mem_21348, "mem_21348") != 0)
                        return 1;
                    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_21339.mem, lower_bound_18809, (int64_t []) {(int64_t) 1}, mem_21350.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_18812})) != 0)
                        goto cleanup;
                    if (memblock_unref_device(ctx, &mem_21350, "mem_21350") != 0)
                        return 1;
                    
                    bool loop_cond_18844 = slt64(tmp_18836, m_18729);
                    bool loop_while_tmp_21869 = loop_cond_18844;
                    int64_t p_tmp_21872 = tmp_18836;
                    
                    loop_while_18805 = loop_while_tmp_21869;
                    p_18808 = p_tmp_21872;
                }
                partitioned_scatter_res_18801 = loop_while_18805;
                partitioned_scatter_res_18804 = p_18808;
                if (memblock_unref_device(ctx, &ext_mem_21334, "ext_mem_21334") != 0)
                    return 1;
                if (memblock_set_device(ctx, &mem_param_tmp_21658, &mem_21337, "mem_21337") != 0)
                    return 1;
                if (memblock_set_device(ctx, &mem_param_tmp_21659, &mem_21339, "mem_21339") != 0)
                    return 1;
                
                int64_t ctx_param_ext_tmp_21660 = (int64_t) 0;
                int64_t ctx_param_ext_tmp_21661 = (int64_t) 0;
                
                if (memblock_set_device(ctx, &mem_param_21301, &mem_param_tmp_21658, "mem_param_tmp_21658") != 0)
                    return 1;
                if (memblock_set_device(ctx, &mem_param_21304, &mem_param_tmp_21659, "mem_param_tmp_21659") != 0)
                    return 1;
                ctx_param_ext_21298 = ctx_param_ext_tmp_21660;
                ctx_param_ext_21302 = ctx_param_ext_tmp_21661;
            }
            if (memblock_set_device(ctx, &ext_mem_21371, &mem_param_21301, "mem_param_21301") != 0)
                return 1;
            if (memblock_set_device(ctx, &ext_mem_21370, &mem_param_21304, "mem_param_21304") != 0)
                return 1;
            ext_21369 = ctx_param_ext_21298;
            ext_21366 = ctx_param_ext_21302;
            if (memblock_unref_device(ctx, &mem_21297, "mem_21297") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_21310, "mem_21310") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_21319, "mem_21319") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_21321, "mem_21321") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_21323, "mem_21323") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_21353, "mem_21353") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_21355, "mem_21355") != 0)
                return 1;
            if (memblock_alloc_device(ctx, &mem_21373, nest_sizze_20920, "mem_21373")) {
                err = 1;
                goto cleanup;
            }
            if ((err = lmad_copy_gpu2gpu_1b(ctx, 2, mem_21373.mem, (int64_t) 0, (int64_t []) {(int64_t) 2, (int64_t) 1}, ext_mem_21371.mem, ext_21369, (int64_t []) {(int64_t) 2, (int64_t) 1}, (int64_t []) {dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, (int64_t) 2})) != 0)
                goto cleanup;
            
            int64_t deepen_step_res_18845;
            int64_t deepen_step_res_18846;
            int32_t deepen_step_res_18849;
            int32_t deepen_step_res_18850;
            int32_t deepen_step_res_18851;
            
            if (futrts_getPartitionBounds_8487(ctx, &ext_mem_21376, &ext_mem_21375, &deepen_step_res_18845, &deepen_step_res_18846, &deepen_step_res_18849, &deepen_step_res_18850, &deepen_step_res_18851, mem_21373, dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, (int64_t) 2, newDepth_18703, new_i_18704, new_j_18706) != 0) {
                err = 1;
                goto cleanup;
            }
            if (memblock_unref_device(ctx, &mem_21373, "mem_21373") != 0)
                return 1;
            
            int64_t zl_rhs_18853 = sub64(deepen_step_res_18845, (int64_t) 1);
            int64_t num_tblocks_20940;
            int64_t max_num_tblocks_21910;
            
            max_num_tblocks_21910 = *ctx->tuning_params.mainzisegscan_num_tblocks_20939;
            num_tblocks_20940 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(deepen_step_res_18845, segscan_tblock_sizze_20938), max_num_tblocks_21910)));
            
            int64_t bytes_21378 = (int64_t) 8 * deepen_step_res_18845;
            
            if (memblock_alloc_device(ctx, &mem_21379, bytes_21378, "mem_21379")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &mem_21381, bytes_21378, "mem_21381")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &mem_21383, bytes_21378, "mem_21383")) {
                err = 1;
                goto cleanup;
            }
            if (slt64((int64_t) 0, deepen_step_res_18845)) {
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegScan");
                
                int64_t shared_memory_21911;
                
                shared_memory_21911 = ctx->max_shared_memory;
                
                int64_t thread_block_sizze_21912;
                
                thread_block_sizze_21912 = ctx->max_thread_block_size;
                
                int64_t registers_21913;
                
                registers_21913 = ctx->max_registers;
                
                int64_t thread_block_sizze_21914;
                
                thread_block_sizze_21914 = ctx->max_thread_block_size;
                
                int64_t chunk_sizze_21915 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_21911, thread_block_sizze_21912), (int64_t) 8), squot64(squot64(registers_21913, thread_block_sizze_21914) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
                int64_t num_virt_blocks_21916 = sdiv_up64(deepen_step_res_18845, segscan_tblock_sizze_20938 * chunk_sizze_21915);
                int64_t num_virt_threads_21917 = num_virt_blocks_21916 * segscan_tblock_sizze_20938;
                
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_21915, '\n');
                if (memblock_alloc_device(ctx, &status_flags_mem_21918, num_virt_blocks_21916, "status_flags_mem_21918")) {
                    err = 1;
                    goto cleanup;
                }
                if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_21918, num_virt_blocks_21916, (int8_t) 0) != 0) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &aggregates_mem_21920, (int64_t) 8 * num_virt_blocks_21916, "aggregates_mem_21920")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &incprefixes_mem_21922, (int64_t) 8 * num_virt_blocks_21916, "incprefixes_mem_21922")) {
                    err = 1;
                    goto cleanup;
                }
                {
                    err = gpu_kernel_mainzisegscan_20943(ctx, num_tblocks_20940, 1, 1, *ctx->tuning_params.mainzisegscan_tblock_sizze_20937, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_20938), chunk_sizze_21915 * segscan_tblock_sizze_20938 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_20938), chunk_sizze_21915 * segscan_tblock_sizze_20938 * (int64_t) 8), (int64_t) 8), (int64_t) 8), dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, deepen_step_res_18845, zl_rhs_18853, num_tblocks_20940, num_virt_blocks_21916, num_virt_threads_21917, ext_mem_21376.mem, mem_21379.mem, mem_21381.mem, mem_21383.mem, status_flags_mem_21918.mem, aggregates_mem_21920.mem, incprefixes_mem_21922.mem, global_dynid_mem_21924.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                ctx->failure_is_an_option = 1;
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
            }
            
            bool cond_18881 = deepen_step_res_18845 == (int64_t) 0;
            bool x_18882 = !cond_18881;
            bool x_18883 = sle64((int64_t) 0, zl_rhs_18853);
            bool y_18884 = slt64(zl_rhs_18853, deepen_step_res_18845);
            bool bounds_check_18885 = x_18883 && y_18884;
            bool protect_assert_disj_18886 = cond_18881 || bounds_check_18885;
            bool index_certs_18887;
            
            if (!protect_assert_disj_18886) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) zl_rhs_18853, "] out of bounds for array of shape [", (long long) deepen_step_res_18845, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftHashJoin.fut:123:8-49\n   #3  ftHashJoin.fut:185:6-89\n   #4  ftHashJoin.fut:354:1-362:42\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            
            int64_t m_f_res_18888;
            
            if (x_18882) {
                int64_t read_res_22284;
                
                if ((err = gpu_scalar_from_device(ctx, &read_res_22284, mem_21379.mem, zl_rhs_18853 * sizeof(int64_t), sizeof(int64_t))) != 0)
                    goto cleanup;
                if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                    err = 1;
                    goto cleanup;
                }
                
                int64_t x_19969 = read_res_22284;
                
                m_f_res_18888 = x_19969;
            } else {
                m_f_res_18888 = (int64_t) 0;
            }
            
            int64_t m_18890;
            
            if (cond_18881) {
                m_18890 = (int64_t) 0;
            } else {
                m_18890 = m_f_res_18888;
            }
            
            int64_t m_18900 = sub64(m_18890, (int64_t) 1);
            bool i_p_m_t_s_leq_w_18902 = slt64(m_18900, deepen_step_res_18845);
            bool zzero_leq_i_p_m_t_s_18901 = sle64((int64_t) 0, m_18900);
            bool y_18904 = zzero_leq_i_p_m_t_s_18901 && i_p_m_t_s_leq_w_18902;
            bool i_lte_j_18903 = sle64((int64_t) 0, m_18890);
            bool forwards_ok_18905 = i_lte_j_18903 && y_18904;
            bool eq_x_zz_18897 = (int64_t) 0 == m_f_res_18888;
            bool p_and_eq_x_y_18898 = x_18882 && eq_x_zz_18897;
            bool empty_slice_18899 = cond_18881 || p_and_eq_x_y_18898;
            bool ok_or_empty_18906 = empty_slice_18899 || forwards_ok_18905;
            bool index_certs_18907;
            
            if (!ok_or_empty_18906) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_18890, "] out of bounds for array of shape [", (long long) deepen_step_res_18845, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftHashJoin.fut:123:8-49\n   #3  ftHashJoin.fut:185:6-89\n   #4  ftHashJoin.fut:354:1-362:42\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            
            int64_t bytes_21384 = (int64_t) 8 * m_18890;
            int64_t conc_tmp_18929 = loop_dz2081Uz2089U_18678 + m_18890;
            int64_t bytes_21396 = (int64_t) 8 * conc_tmp_18929;
            
            if (memblock_alloc_device(ctx, &mem_21385, bytes_21384, "mem_21385")) {
                err = 1;
                goto cleanup;
            }
            if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_21385.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_21383.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_18890})) != 0)
                goto cleanup;
            if (memblock_alloc_device(ctx, &mem_21387, bytes_21384, "mem_21387")) {
                err = 1;
                goto cleanup;
            }
            if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_21387.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_21376.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_18890})) != 0)
                goto cleanup;
            
            int64_t num_tblocks_20950;
            int64_t max_num_tblocks_22013;
            
            max_num_tblocks_22013 = *ctx->tuning_params.mainzisegmap_num_tblocks_20949;
            num_tblocks_20950 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(deepen_step_res_18845, segmap_tblock_sizze_20948), max_num_tblocks_22013)));
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegMap");
            
            int32_t virt_num_tblocks_22014 = sext_i64_i32(sdiv_up64(deepen_step_res_18845, segmap_tblock_sizze_20948));
            
            {
                err = gpu_kernel_mainzisegmap_20945(ctx, num_tblocks_20950, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_20947, 1, 1, (int64_t) 0, deepen_step_res_18845, m_18890, num_tblocks_20950, virt_num_tblocks_22014, ext_mem_21376.mem, mem_21379.mem, mem_21381.mem, mem_21383.mem, mem_21385.mem, mem_21387.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
            if (memblock_unref_device(ctx, &ext_mem_21376, "ext_mem_21376") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_21379, "mem_21379") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_21381, "mem_21381") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_21383, "mem_21383") != 0)
                return 1;
            if (memblock_alloc_device(ctx, &mem_21389, (int64_t) 16, "mem_21389")) {
                err = 1;
                goto cleanup;
            }
            if ((err = lmad_copy_gpu2gpu_1b(ctx, 2, mem_21389.mem, (int64_t) 0, (int64_t []) {(int64_t) 2, (int64_t) 1}, mem_param_21295.mem, (int64_t) 0, (int64_t []) {(int64_t) 2, (int64_t) 1}, (int64_t []) {(int64_t) 8, (int64_t) 2})) != 0)
                goto cleanup;
            if ((err = lmad_copy_gpu2gpu_1b(ctx, 2, mem_21389.mem, (int64_t) 2 * bounds_18683, (int64_t []) {(int64_t) 2, (int64_t) 1}, ext_mem_21371.mem, ext_21369, (int64_t []) {(int64_t) 2, (int64_t) 1}, (int64_t []) {dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685, (int64_t) 2})) != 0)
                goto cleanup;
            if (memblock_unref_device(ctx, &ext_mem_21371, "ext_mem_21371") != 0)
                return 1;
            if (memblock_alloc_device(ctx, &mem_21390, (int64_t) 64, "mem_21390")) {
                err = 1;
                goto cleanup;
            }
            if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_21390.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_21291.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {(int64_t) 8})) != 0)
                goto cleanup;
            if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_21390.mem, bounds_18683, (int64_t []) {(int64_t) 1}, ext_mem_21370.mem, ext_21366, (int64_t []) {(int64_t) 1}, (int64_t []) {dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_18685})) != 0)
                goto cleanup;
            if (memblock_unref_device(ctx, &ext_mem_21370, "ext_mem_21370") != 0)
                return 1;
            
            int64_t segmap_usable_groups_20966 = sdiv_up64(m_18890, segmap_tblock_sizze_20965);
            
            if (memblock_alloc_device(ctx, &mem_21397, bytes_21396, "mem_21397")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &mem_21399, bytes_21396, "mem_21399")) {
                err = 1;
                goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegMap");
            
            int32_t virt_num_tblocks_22027 = sext_i64_i32(sdiv_up64(m_18890, segmap_tblock_sizze_20965));
            
            {
                err = gpu_kernel_mainzisegmap_20970(ctx, segmap_usable_groups_20966, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_20955, 1, 1, (int64_t) 0, loop_dz2081Uz2089U_18678, bounds_18683, m_18890, mem_21385.mem, mem_21387.mem, mem_21397.mem, mem_21399.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
            if (memblock_unref_device(ctx, &mem_21385, "mem_21385") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_21387, "mem_21387") != 0)
                return 1;
            
            int64_t tmp_offs_22036 = (int64_t) 0;
            
            if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_21397.mem, tmp_offs_22036, (int64_t []) {(int64_t) 1}, mem_param_21285.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {loop_dz2081Uz2089U_18678})) != 0)
                goto cleanup;
            tmp_offs_22036 += loop_dz2081Uz2089U_18678;
            if (!(tmp_offs_22036 == loop_dz2081Uz2089U_18678)) {
                if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_21397.mem, tmp_offs_22036, (int64_t []) {(int64_t) 1}, mem_21397.mem, loop_dz2081Uz2089U_18678, (int64_t []) {(int64_t) 1}, (int64_t []) {m_18890})) != 0)
                    goto cleanup;
            }
            tmp_offs_22036 += m_18890;
            
            int64_t tmp_offs_22037 = (int64_t) 0;
            
            if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_21399.mem, tmp_offs_22037, (int64_t []) {(int64_t) 1}, mem_param_21288.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {loop_dz2081Uz2089U_18678})) != 0)
                goto cleanup;
            tmp_offs_22037 += loop_dz2081Uz2089U_18678;
            if (!(tmp_offs_22037 == loop_dz2081Uz2089U_18678)) {
                if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_21399.mem, tmp_offs_22037, (int64_t []) {(int64_t) 1}, mem_21399.mem, loop_dz2081Uz2089U_18678, (int64_t []) {(int64_t) 1}, (int64_t []) {m_18890})) != 0)
                    goto cleanup;
            }
            tmp_offs_22037 += m_18890;
            if (memblock_set_device(ctx, &mem_param_tmp_21645, &mem_21397, "mem_21397") != 0)
                return 1;
            if (memblock_set_device(ctx, &mem_param_tmp_21646, &mem_21399, "mem_21399") != 0)
                return 1;
            if (memblock_set_device(ctx, &mem_param_tmp_21647, &mem_21390, "mem_21390") != 0)
                return 1;
            if (memblock_set_device(ctx, &mem_param_tmp_21648, &mem_21389, "mem_21389") != 0)
                return 1;
            
            int64_t loop_dz2081Uz2089U_tmp_21649 = conc_tmp_18929;
            
            if (memblock_set_device(ctx, &mem_param_21285, &mem_param_tmp_21645, "mem_param_tmp_21645") != 0)
                return 1;
            if (memblock_set_device(ctx, &mem_param_21288, &mem_param_tmp_21646, "mem_param_tmp_21646") != 0)
                return 1;
            if (memblock_set_device(ctx, &mem_param_21291, &mem_param_tmp_21647, "mem_param_tmp_21647") != 0)
                return 1;
            if (memblock_set_device(ctx, &mem_param_21295, &mem_param_tmp_21648, "mem_param_tmp_21648") != 0)
                return 1;
            loop_dz2081Uz2089U_18678 = loop_dz2081Uz2089U_tmp_21649;
        }
        if (memblock_set_device(ctx, &ext_mem_21412, &mem_param_21285, "mem_param_21285") != 0)
            return 1;
        if (memblock_set_device(ctx, &ext_mem_21411, &mem_param_21288, "mem_param_21288") != 0)
            return 1;
        if (memblock_set_device(ctx, &ext_mem_21410, &mem_param_21291, "mem_param_21291") != 0)
            return 1;
        if (memblock_set_device(ctx, &ext_mem_21409, &mem_param_21295, "mem_param_21295") != 0)
            return 1;
        loopres_18672 = loop_dz2081Uz2089U_18678;
        
        bool cond_18933 = slt64((int64_t) 0, loopres_18672);
        bool loop_cond_t_res_18934 = slt32(newDepth_18703, max_depth_16892);
        bool x_18935 = cond_18933 && loop_cond_t_res_18934;
        
        if (memblock_set_device(ctx, &mem_param_tmp_21634, &ext_mem_21410, "ext_mem_21410") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_21635, &ext_mem_21409, "ext_mem_21409") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_21636, &ext_mem_21412, "ext_mem_21412") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_21637, &ext_mem_21411, "ext_mem_21411") != 0)
            return 1;
        
        int64_t loop_dz2087U_tmp_21638 = loopres_18672;
        bool loop_while_tmp_21639 = x_18935;
        int32_t p_tmp_21640 = newDepth_18703;
        
        if (memblock_set_device(ctx, &mem_param_21272, &mem_param_tmp_21634, "mem_param_tmp_21634") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_21276, &mem_param_tmp_21635, "mem_param_tmp_21635") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_21279, &mem_param_tmp_21636, "mem_param_tmp_21636") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_21282, &mem_param_tmp_21637, "mem_param_tmp_21637") != 0)
            return 1;
        loop_dz2087U_18665 = loop_dz2087U_tmp_21638;
        loop_while_18666 = loop_while_tmp_21639;
        p_18667 = p_tmp_21640;
    }
    if (memblock_set_device(ctx, &ext_mem_21425, &mem_param_21272, "mem_param_21272") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_21424, &mem_param_21276, "mem_param_21276") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_21423, &mem_param_21279, "mem_param_21279") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_21422, &mem_param_21282, "mem_param_21282") != 0)
        return 1;
    partition_and_deepen_res_18658 = loop_dz2087U_18665;
    partition_and_deepen_res_18659 = loop_while_18666;
    partition_and_deepen_res_18660 = p_18667;
    if (memblock_unref_device(ctx, &mem_21265, "mem_21265") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_21266, "mem_21266") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_21267, "mem_21267") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_21268, "mem_21268") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_21269, "mem_21269") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_21325, "mem_21325") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_21426, (int64_t) 16, "mem_21426")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_1b(ctx, 2, mem_21426.mem, (int64_t) 0, (int64_t []) {(int64_t) 2, (int64_t) 1}, ext_mem_21424.mem, (int64_t) 0, (int64_t []) {(int64_t) 2, (int64_t) 1}, (int64_t []) {(int64_t) 8, (int64_t) 2})) != 0)
        goto cleanup;
    
    int64_t calc_partitions_from_partitioned_set_res_18936;
    int64_t calc_partitions_from_partitioned_set_res_18937;
    int32_t calc_partitions_from_partitioned_set_res_18940;
    int32_t calc_partitions_from_partitioned_set_res_18941;
    int32_t calc_partitions_from_partitioned_set_res_18942;
    
    if (futrts_getPartitionBounds_8487(ctx, &ext_mem_21429, &ext_mem_21428, &calc_partitions_from_partitioned_set_res_18936, &calc_partitions_from_partitioned_set_res_18937, &calc_partitions_from_partitioned_set_res_18940, &calc_partitions_from_partitioned_set_res_18941, &calc_partitions_from_partitioned_set_res_18942, mem_21426, (int64_t) 8, (int64_t) 2, 1, 0, 3) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_unref_device(ctx, &mem_21426, "mem_21426") != 0)
        return 1;
    
    bool cond_18943 = slt32(calc_partitions_from_partitioned_set_res_18940, max_depth_16892);
    int64_t segscan_tblock_sizze_20977;
    
    segscan_tblock_sizze_20977 = *ctx->tuning_params.mainzisegscan_tblock_sizze_20976;
    
    int64_t segmap_tblock_sizze_20987;
    
    segmap_tblock_sizze_20987 = *ctx->tuning_params.mainzisegmap_tblock_sizze_20986;
    
    int64_t segmap_tblock_sizze_21002;
    
    segmap_tblock_sizze_21002 = *ctx->tuning_params.mainzisegmap_tblock_sizze_20994;
    
    int64_t calc_partitions_from_partitioned_set_res_18944;
    int64_t calc_partitions_from_partitioned_set_res_18945;
    bool calc_partitions_from_partitioned_set_res_18946;
    int32_t calc_partitions_from_partitioned_set_res_18949;
    int32_t calc_partitions_from_partitioned_set_res_18950;
    int32_t calc_partitions_from_partitioned_set_res_18951;
    int64_t loop_dz2088U_18952;
    int64_t loop_dz2089U_18953;
    bool loop_while_18954;
    int32_t p_18957;
    int32_t p_18958;
    int32_t p_18959;
    
    if (memblock_set_device(ctx, &mem_param_21432, &ext_mem_21429, "ext_mem_21429") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_21435, &ext_mem_21428, "ext_mem_21428") != 0)
        return 1;
    loop_dz2088U_18952 = calc_partitions_from_partitioned_set_res_18936;
    loop_dz2089U_18953 = calc_partitions_from_partitioned_set_res_18937;
    loop_while_18954 = cond_18943;
    p_18957 = calc_partitions_from_partitioned_set_res_18940;
    p_18958 = calc_partitions_from_partitioned_set_res_18941;
    p_18959 = calc_partitions_from_partitioned_set_res_18942;
    while (loop_while_18954) {
        int64_t zl_rhs_18961 = sub64(loop_dz2088U_18952, (int64_t) 1);
        int64_t num_tblocks_20979;
        int64_t max_num_tblocks_22048;
        
        max_num_tblocks_22048 = *ctx->tuning_params.mainzisegscan_num_tblocks_20978;
        num_tblocks_20979 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(loop_dz2088U_18952, segscan_tblock_sizze_20977), max_num_tblocks_22048)));
        
        int64_t bytes_21437 = (int64_t) 8 * loop_dz2088U_18952;
        
        if (memblock_alloc_device(ctx, &mem_21438, bytes_21437, "mem_21438")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_21440, bytes_21437, "mem_21440")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_21442, bytes_21437, "mem_21442")) {
            err = 1;
            goto cleanup;
        }
        if (slt64((int64_t) 0, loop_dz2088U_18952)) {
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegScan");
            
            int64_t shared_memory_22049;
            
            shared_memory_22049 = ctx->max_shared_memory;
            
            int64_t thread_block_sizze_22050;
            
            thread_block_sizze_22050 = ctx->max_thread_block_size;
            
            int64_t registers_22051;
            
            registers_22051 = ctx->max_registers;
            
            int64_t thread_block_sizze_22052;
            
            thread_block_sizze_22052 = ctx->max_thread_block_size;
            
            int64_t chunk_sizze_22053 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_22049, thread_block_sizze_22050), (int64_t) 8), squot64(squot64(registers_22051, thread_block_sizze_22052) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
            int64_t num_virt_blocks_22054 = sdiv_up64(loop_dz2088U_18952, segscan_tblock_sizze_20977 * chunk_sizze_22053);
            int64_t num_virt_threads_22055 = num_virt_blocks_22054 * segscan_tblock_sizze_20977;
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_22053, '\n');
            if (memblock_alloc_device(ctx, &status_flags_mem_22056, num_virt_blocks_22054, "status_flags_mem_22056")) {
                err = 1;
                goto cleanup;
            }
            if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_22056, num_virt_blocks_22054, (int8_t) 0) != 0) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &aggregates_mem_22058, (int64_t) 8 * num_virt_blocks_22054, "aggregates_mem_22058")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &incprefixes_mem_22060, (int64_t) 8 * num_virt_blocks_22054, "incprefixes_mem_22060")) {
                err = 1;
                goto cleanup;
            }
            {
                err = gpu_kernel_mainzisegscan_20982(ctx, num_tblocks_20979, 1, 1, *ctx->tuning_params.mainzisegscan_tblock_sizze_20976, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_20977), chunk_sizze_22053 * segscan_tblock_sizze_20977 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_20977), chunk_sizze_22053 * segscan_tblock_sizze_20977 * (int64_t) 8), (int64_t) 8), (int64_t) 8), loop_dz2088U_18952, zl_rhs_18961, num_tblocks_20979, num_virt_blocks_22054, num_virt_threads_22055, mem_param_21432.mem, mem_21438.mem, mem_21440.mem, mem_21442.mem, status_flags_mem_22056.mem, aggregates_mem_22058.mem, incprefixes_mem_22060.mem, global_dynid_mem_22062.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            ctx->failure_is_an_option = 1;
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
        }
        
        bool cond_18989 = loop_dz2088U_18952 == (int64_t) 0;
        bool x_18990 = !cond_18989;
        bool x_18991 = sle64((int64_t) 0, zl_rhs_18961);
        bool y_18992 = slt64(zl_rhs_18961, loop_dz2088U_18952);
        bool bounds_check_18993 = x_18991 && y_18992;
        bool protect_assert_disj_18994 = cond_18989 || bounds_check_18993;
        bool index_certs_18995;
        
        if (!protect_assert_disj_18994) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) zl_rhs_18961, "] out of bounds for array of shape [", (long long) loop_dz2088U_18952, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftHashJoin.fut:359:18-78\n   #3  ftHashJoin.fut:354:1-362:42\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t m_f_res_18996;
        
        if (x_18990) {
            int64_t read_res_22285;
            
            if ((err = gpu_scalar_from_device(ctx, &read_res_22285, mem_21438.mem, zl_rhs_18961 * sizeof(int64_t), sizeof(int64_t))) != 0)
                goto cleanup;
            if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                err = 1;
                goto cleanup;
            }
            
            int64_t x_19985 = read_res_22285;
            
            m_f_res_18996 = x_19985;
        } else {
            m_f_res_18996 = (int64_t) 0;
        }
        
        int64_t m_18998;
        
        if (cond_18989) {
            m_18998 = (int64_t) 0;
        } else {
            m_18998 = m_f_res_18996;
        }
        
        int64_t m_19008 = sub64(m_18998, (int64_t) 1);
        bool i_p_m_t_s_leq_w_19010 = slt64(m_19008, loop_dz2088U_18952);
        bool zzero_leq_i_p_m_t_s_19009 = sle64((int64_t) 0, m_19008);
        bool y_19012 = zzero_leq_i_p_m_t_s_19009 && i_p_m_t_s_leq_w_19010;
        bool i_lte_j_19011 = sle64((int64_t) 0, m_18998);
        bool forwards_ok_19013 = i_lte_j_19011 && y_19012;
        bool eq_x_zz_19005 = (int64_t) 0 == m_f_res_18996;
        bool p_and_eq_x_y_19006 = x_18990 && eq_x_zz_19005;
        bool empty_slice_19007 = cond_18989 || p_and_eq_x_y_19006;
        bool ok_or_empty_19014 = empty_slice_19007 || forwards_ok_19013;
        bool index_certs_19015;
        
        if (!ok_or_empty_19014) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_18998, "] out of bounds for array of shape [", (long long) loop_dz2088U_18952, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftHashJoin.fut:359:18-78\n   #3  ftHashJoin.fut:354:1-362:42\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t bytes_21443 = (int64_t) 8 * m_18998;
        
        if (memblock_alloc_device(ctx, &mem_21444, bytes_21443, "mem_21444")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhiota_i64(ctx, mem_21444, m_18998, (int64_t) 0, (int64_t) 1) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_21446, bytes_21443, "mem_21446")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_21446.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_21442.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_18998})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_21448, bytes_21443, "mem_21448")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_21448.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_21432.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_18998})) != 0)
            goto cleanup;
        
        int64_t num_tblocks_20989;
        int64_t max_num_tblocks_22151;
        
        max_num_tblocks_22151 = *ctx->tuning_params.mainzisegmap_num_tblocks_20988;
        num_tblocks_20989 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(loop_dz2088U_18952, segmap_tblock_sizze_20987), max_num_tblocks_22151)));
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_22152 = sext_i64_i32(sdiv_up64(loop_dz2088U_18952, segmap_tblock_sizze_20987));
        
        {
            err = gpu_kernel_mainzisegmap_20984(ctx, num_tblocks_20989, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_20986, 1, 1, (int64_t) 0, loop_dz2088U_18952, m_18998, num_tblocks_20989, virt_num_tblocks_22152, mem_param_21432.mem, mem_21438.mem, mem_21440.mem, mem_21442.mem, mem_21444.mem, mem_21446.mem, mem_21448.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if (memblock_unref_device(ctx, &mem_21438, "mem_21438") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21440, "mem_21440") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21442, "mem_21442") != 0)
            return 1;
        
        int32_t new_i_19028 = mul32(4, p_18957);
        int32_t zt_rhs_19029 = add32(1, p_18957);
        int32_t zm_lhs_19030 = mul32(4, zt_rhs_19029);
        int32_t new_j_19031 = sub32(zm_lhs_19030, 1);
        int64_t loopres_19032;
        int64_t loopres_19033;
        int32_t loopres_19036;
        int32_t loopres_19037;
        int32_t loopres_19038;
        int64_t loop_dz2084Uz2089U_19040;
        int64_t loop_dz2085Uz2080U_19041;
        int32_t q_19044;
        int32_t q_19045;
        int32_t q_19046;
        
        if (memblock_set_device(ctx, &mem_param_21452, &mem_param_21432, "mem_param_21432") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_21455, &mem_param_21435, "mem_param_21435") != 0)
            return 1;
        loop_dz2084Uz2089U_19040 = loop_dz2088U_18952;
        loop_dz2085Uz2080U_19041 = loop_dz2089U_18953;
        q_19044 = p_18957;
        q_19045 = p_18958;
        q_19046 = p_18959;
        for (int64_t i_19039 = 0; i_19039 < m_18998; i_19039++) {
            int64_t read_res_22286;
            
            if ((err = gpu_scalar_from_device(ctx, &read_res_22286, mem_21448.mem, i_19039 * sizeof(int64_t), sizeof(int64_t))) != 0)
                goto cleanup;
            if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                err = 1;
                goto cleanup;
            }
            
            int64_t bounds_19047 = read_res_22286;
            int64_t read_res_22287;
            
            if ((err = gpu_scalar_from_device(ctx, &read_res_22287, mem_21446.mem, i_19039 * sizeof(int64_t), sizeof(int64_t))) != 0)
                goto cleanup;
            if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                err = 1;
                goto cleanup;
            }
            
            int64_t bounds_19048 = read_res_22287;
            int64_t read_res_22288;
            
            if ((err = gpu_scalar_from_device(ctx, &read_res_22288, mem_21444.mem, i_19039 * sizeof(int64_t), sizeof(int64_t))) != 0)
                goto cleanup;
            if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                err = 1;
                goto cleanup;
            }
            
            int64_t bounds_19049 = read_res_22288;
            int64_t dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_19050 = sub64(bounds_19048, bounds_19047);
            bool empty_slice_19051 = dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_19050 == (int64_t) 0;
            int64_t m_19052 = sub64(dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_19050, (int64_t) 1);
            int64_t i_p_m_t_s_19053 = add64(bounds_19047, m_19052);
            bool zzero_leq_i_p_m_t_s_19054 = sle64((int64_t) 0, i_p_m_t_s_19053);
            bool i_p_m_t_s_leq_w_19055 = slt64(i_p_m_t_s_19053, (int64_t) 8);
            bool zzero_lte_i_19056 = sle64((int64_t) 0, bounds_19047);
            bool i_lte_j_19057 = sle64(bounds_19047, bounds_19048);
            bool y_19058 = i_p_m_t_s_leq_w_19055 && zzero_lte_i_19056;
            bool y_19059 = zzero_leq_i_p_m_t_s_19054 && y_19058;
            bool forwards_ok_19060 = i_lte_j_19057 && y_19059;
            bool ok_or_empty_19061 = empty_slice_19051 || forwards_ok_19060;
            bool index_certs_19062;
            
            if (!ok_or_empty_19061) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) bounds_19047, ":", (long long) bounds_19048, "] out of bounds for array of shape [", (long long) (int64_t) 8, "].", "-> #0  ftHashJoin.fut:206:21-43\n   #1  ftHashJoin.fut:359:18-78\n   #2  ftHashJoin.fut:354:1-362:42\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            
            int64_t bytes_21456 = (int64_t) 2 * dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_19050;
            
            if (memblock_alloc_device(ctx, &mem_21457, bytes_21456, "mem_21457")) {
                err = 1;
                goto cleanup;
            }
            if ((err = lmad_copy_gpu2gpu_1b(ctx, 2, mem_21457.mem, (int64_t) 0, (int64_t []) {(int64_t) 2, (int64_t) 1}, ext_mem_21424.mem, (int64_t) 0 + (int64_t) 2 * bounds_19047, (int64_t []) {(int64_t) 2, (int64_t) 1}, (int64_t []) {dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_19050, (int64_t) 2})) != 0)
                goto cleanup;
            
            int64_t loopres_19064;
            int64_t loopres_19065;
            int32_t loopres_19068;
            int32_t loopres_19069;
            int32_t loopres_19070;
            
            if (futrts_getPartitionBounds_8487(ctx, &ext_mem_21460, &ext_mem_21459, &loopres_19064, &loopres_19065, &loopres_19068, &loopres_19069, &loopres_19070, mem_21457, dzlz7bUZLzmZRz20Uboundszi1z20Uboundszi0z7dUzg_19050, (int64_t) 2, zt_rhs_19029, new_i_19028, new_j_19031) != 0) {
                err = 1;
                goto cleanup;
            }
            if (memblock_unref_device(ctx, &mem_21457, "mem_21457") != 0)
                return 1;
            
            bool empty_slice_19071 = bounds_19049 == (int64_t) 0;
            int64_t m_19072 = sub64(bounds_19049, (int64_t) 1);
            bool zzero_leq_i_p_m_t_s_19073 = sle64((int64_t) 0, m_19072);
            bool i_p_m_t_s_leq_w_19074 = slt64(m_19072, loop_dz2084Uz2089U_19040);
            bool i_lte_j_19075 = sle64((int64_t) 0, bounds_19049);
            bool y_19076 = zzero_leq_i_p_m_t_s_19073 && i_p_m_t_s_leq_w_19074;
            bool forwards_ok_19077 = i_lte_j_19075 && y_19076;
            bool ok_or_empty_19078 = empty_slice_19071 || forwards_ok_19077;
            bool index_certs_19079;
            
            if (!ok_or_empty_19078) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) (int64_t) 0, ":", (long long) bounds_19049, "] out of bounds for array of shape [", (long long) loop_dz2084Uz2089U_19040, "].", "-> #0  ftHashJoin.fut:215:18-36\n   #1  ftHashJoin.fut:359:18-78\n   #2  ftHashJoin.fut:354:1-362:42\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            
            int64_t conc_tmp_19084 = bounds_19049 + loopres_19064;
            int64_t zpzp_rhs_19085 = add64((int64_t) 1, bounds_19049);
            int64_t j_m_i_19086 = sub64(loop_dz2084Uz2089U_19040, zpzp_rhs_19085);
            bool empty_slice_19087 = j_m_i_19086 == (int64_t) 0;
            int64_t m_19088 = sub64(j_m_i_19086, (int64_t) 1);
            int64_t i_p_m_t_s_19089 = add64(zpzp_rhs_19085, m_19088);
            bool zzero_leq_i_p_m_t_s_19090 = sle64((int64_t) 0, i_p_m_t_s_19089);
            bool i_p_m_t_s_leq_w_19091 = slt64(i_p_m_t_s_19089, loop_dz2084Uz2089U_19040);
            bool zzero_lte_i_19092 = sle64((int64_t) 0, zpzp_rhs_19085);
            bool i_lte_j_19093 = sle64(zpzp_rhs_19085, loop_dz2084Uz2089U_19040);
            bool y_19094 = i_p_m_t_s_leq_w_19091 && zzero_lte_i_19092;
            bool y_19095 = zzero_leq_i_p_m_t_s_19090 && y_19094;
            bool forwards_ok_19096 = i_lte_j_19093 && y_19095;
            bool ok_or_empty_19097 = empty_slice_19087 || forwards_ok_19096;
            bool index_certs_19098;
            
            if (!ok_or_empty_19097) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) zpzp_rhs_19085, ":", (long long) loop_dz2084Uz2089U_19040, "] out of bounds for array of shape [", (long long) loop_dz2084Uz2089U_19040, "].", "-> #0  ftHashJoin.fut:215:90-126\n   #1  ftHashJoin.fut:359:18-78\n   #2  ftHashJoin.fut:354:1-362:42\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            
            int64_t conc_tmp_19100 = conc_tmp_19084 + j_m_i_19086;
            int64_t bytes_21464 = (int64_t) 8 * conc_tmp_19100;
            bool i_p_m_t_s_leq_w_19102 = slt64(m_19072, loop_dz2085Uz2080U_19041);
            bool y_19103 = zzero_leq_i_p_m_t_s_19073 && i_p_m_t_s_leq_w_19102;
            bool ok_or_empty_19104 = empty_slice_19071 || y_19103;
            bool index_certs_19105;
            
            if (!ok_or_empty_19104) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) (int64_t) 0, ":", (long long) bounds_19049, "] out of bounds for array of shape [", (long long) loop_dz2085Uz2080U_19041, "].", "-> #0  ftHashJoin.fut:216:18-36\n   #1  ftHashJoin.fut:359:18-78\n   #2  ftHashJoin.fut:354:1-362:42\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            
            int64_t conc_tmp_19107 = bounds_19049 + loopres_19065;
            int64_t j_m_i_19108 = sub64(loop_dz2085Uz2080U_19041, zpzp_rhs_19085);
            bool empty_slice_19109 = j_m_i_19108 == (int64_t) 0;
            int64_t m_19110 = sub64(j_m_i_19108, (int64_t) 1);
            int64_t i_p_m_t_s_19111 = add64(zpzp_rhs_19085, m_19110);
            bool zzero_leq_i_p_m_t_s_19112 = sle64((int64_t) 0, i_p_m_t_s_19111);
            bool i_p_m_t_s_leq_w_19113 = slt64(i_p_m_t_s_19111, loop_dz2085Uz2080U_19041);
            bool i_lte_j_19114 = sle64(zpzp_rhs_19085, loop_dz2085Uz2080U_19041);
            bool y_19115 = zzero_lte_i_19092 && i_p_m_t_s_leq_w_19113;
            bool y_19116 = zzero_leq_i_p_m_t_s_19112 && y_19115;
            bool forwards_ok_19117 = i_lte_j_19114 && y_19116;
            bool ok_or_empty_19118 = empty_slice_19109 || forwards_ok_19117;
            bool index_certs_19119;
            
            if (!ok_or_empty_19118) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) zpzp_rhs_19085, ":", (long long) loop_dz2085Uz2080U_19041, "] out of bounds for array of shape [", (long long) loop_dz2085Uz2080U_19041, "].", "-> #0  ftHashJoin.fut:216:62-98\n   #1  ftHashJoin.fut:359:18-78\n   #2  ftHashJoin.fut:354:1-362:42\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            
            int64_t conc_tmp_19121 = conc_tmp_19107 + j_m_i_19108;
            int64_t bytes_21466 = (int64_t) 4 * conc_tmp_19121;
            int64_t segmap_usable_groups_21003 = sdiv_up64(loopres_19064, segmap_tblock_sizze_21002);
            
            if (memblock_alloc_device(ctx, &mem_21465, bytes_21464, "mem_21465")) {
                err = 1;
                goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegMap");
            
            int32_t virt_num_tblocks_22174 = sext_i64_i32(sdiv_up64(loopres_19064, segmap_tblock_sizze_21002));
            
            {
                err = gpu_kernel_mainzisegmap_21006(ctx, segmap_usable_groups_21003, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_20994, 1, 1, (int64_t) 0, bounds_19047, bounds_19049, loopres_19064, ext_mem_21460.mem, mem_21465.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
            if (memblock_unref_device(ctx, &ext_mem_21460, "ext_mem_21460") != 0)
                return 1;
            
            int64_t tmp_offs_22183 = (int64_t) 0;
            
            if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_21465.mem, tmp_offs_22183, (int64_t []) {(int64_t) 1}, mem_param_21452.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {bounds_19049})) != 0)
                goto cleanup;
            tmp_offs_22183 += bounds_19049;
            if (!(tmp_offs_22183 == bounds_19049)) {
                if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_21465.mem, tmp_offs_22183, (int64_t []) {(int64_t) 1}, mem_21465.mem, bounds_19049, (int64_t []) {(int64_t) 1}, (int64_t []) {loopres_19064})) != 0)
                    goto cleanup;
            }
            tmp_offs_22183 += loopres_19064;
            if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_21465.mem, tmp_offs_22183, (int64_t []) {(int64_t) 1}, mem_param_21452.mem, (int64_t) 0 + (int64_t) 1 * zpzp_rhs_19085, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_19086})) != 0)
                goto cleanup;
            tmp_offs_22183 += j_m_i_19086;
            if (memblock_alloc_device(ctx, &mem_21467, bytes_21466, "mem_21467")) {
                err = 1;
                goto cleanup;
            }
            
            int64_t tmp_offs_22184 = (int64_t) 0;
            
            if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_21467.mem, tmp_offs_22184, (int64_t []) {(int64_t) 1}, mem_param_21455.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {bounds_19049})) != 0)
                goto cleanup;
            tmp_offs_22184 += bounds_19049;
            if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_21467.mem, tmp_offs_22184, (int64_t []) {(int64_t) 1}, ext_mem_21459.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {loopres_19065})) != 0)
                goto cleanup;
            tmp_offs_22184 += loopres_19065;
            if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_21467.mem, tmp_offs_22184, (int64_t []) {(int64_t) 1}, mem_param_21455.mem, (int64_t) 0 + (int64_t) 1 * zpzp_rhs_19085, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_19108})) != 0)
                goto cleanup;
            tmp_offs_22184 += j_m_i_19108;
            if (memblock_unref_device(ctx, &ext_mem_21459, "ext_mem_21459") != 0)
                return 1;
            if (memblock_set_device(ctx, &mem_param_tmp_22165, &mem_21465, "mem_21465") != 0)
                return 1;
            if (memblock_set_device(ctx, &mem_param_tmp_22166, &mem_21467, "mem_21467") != 0)
                return 1;
            
            int64_t loop_dz2084Uz2089U_tmp_22167 = conc_tmp_19100;
            int64_t loop_dz2085Uz2080U_tmp_22168 = conc_tmp_19121;
            int32_t q_tmp_22171 = zt_rhs_19029;
            int32_t q_tmp_22172 = 4;
            int32_t q_tmp_22173 = 2;
            
            if (memblock_set_device(ctx, &mem_param_21452, &mem_param_tmp_22165, "mem_param_tmp_22165") != 0)
                return 1;
            if (memblock_set_device(ctx, &mem_param_21455, &mem_param_tmp_22166, "mem_param_tmp_22166") != 0)
                return 1;
            loop_dz2084Uz2089U_19040 = loop_dz2084Uz2089U_tmp_22167;
            loop_dz2085Uz2080U_19041 = loop_dz2085Uz2080U_tmp_22168;
            q_19044 = q_tmp_22171;
            q_19045 = q_tmp_22172;
            q_19046 = q_tmp_22173;
        }
        if (memblock_set_device(ctx, &ext_mem_21473, &mem_param_21452, "mem_param_21452") != 0)
            return 1;
        if (memblock_set_device(ctx, &ext_mem_21472, &mem_param_21455, "mem_param_21455") != 0)
            return 1;
        loopres_19032 = loop_dz2084Uz2089U_19040;
        loopres_19033 = loop_dz2085Uz2080U_19041;
        loopres_19036 = q_19044;
        loopres_19037 = q_19045;
        loopres_19038 = q_19046;
        if (memblock_unref_device(ctx, &mem_21444, "mem_21444") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21446, "mem_21446") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21448, "mem_21448") != 0)
            return 1;
        
        bool tmp_19123 = slt64((int64_t) 0, m_18998);
        bool cond_19124 = slt32(loopres_19036, max_depth_16892);
        bool x_19125 = tmp_19123 && cond_19124;
        
        if (memblock_set_device(ctx, &mem_param_tmp_22038, &ext_mem_21473, "ext_mem_21473") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_22039, &ext_mem_21472, "ext_mem_21472") != 0)
            return 1;
        
        int64_t loop_dz2088U_tmp_22040 = loopres_19032;
        int64_t loop_dz2089U_tmp_22041 = loopres_19033;
        bool loop_while_tmp_22042 = x_19125;
        int32_t p_tmp_22045 = loopres_19036;
        int32_t p_tmp_22046 = loopres_19037;
        int32_t p_tmp_22047 = loopres_19038;
        
        if (memblock_set_device(ctx, &mem_param_21432, &mem_param_tmp_22038, "mem_param_tmp_22038") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_21435, &mem_param_tmp_22039, "mem_param_tmp_22039") != 0)
            return 1;
        loop_dz2088U_18952 = loop_dz2088U_tmp_22040;
        loop_dz2089U_18953 = loop_dz2089U_tmp_22041;
        loop_while_18954 = loop_while_tmp_22042;
        p_18957 = p_tmp_22045;
        p_18958 = p_tmp_22046;
        p_18959 = p_tmp_22047;
    }
    if (memblock_set_device(ctx, &ext_mem_21479, &mem_param_21432, "mem_param_21432") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_21478, &mem_param_21435, "mem_param_21435") != 0)
        return 1;
    calc_partitions_from_partitioned_set_res_18944 = loop_dz2088U_18952;
    calc_partitions_from_partitioned_set_res_18945 = loop_dz2089U_18953;
    calc_partitions_from_partitioned_set_res_18946 = loop_while_18954;
    calc_partitions_from_partitioned_set_res_18949 = p_18957;
    calc_partitions_from_partitioned_set_res_18950 = p_18958;
    calc_partitions_from_partitioned_set_res_18951 = p_18959;
    if (memblock_unref_device(ctx, &ext_mem_21428, "ext_mem_21428") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_21429, "ext_mem_21429") != 0)
        return 1;
    
    int64_t i32_res_19126 = sext_i32_i64(calc_partitions_from_partitioned_set_res_18950);
    bool nonnegative_19127 = sle64((int64_t) 0, i32_res_19126);
    bool nonzzero_cert_19128;
    
    if (!nonnegative_19127) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "negative exponent", "-> #0  ftHashJoin.fut:255:72-77\n   #1  ftHashJoin.fut:359:7-361:90\n   #2  ftHashJoin.fut:354:1-362:42\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t dzlz7bUZLztztZRz20U2z20Ursz7dUzg_19129 = shl64((int64_t) 1, i32_res_19126);
    int32_t get_radix_arg1_19130 = sub32(calc_partitions_from_partitioned_set_res_18950, 1);
    int64_t tmp_19131 = sext_i32_i64(get_radix_arg1_19130);
    bool bounds_invalid_upwards_19132 = slt32(get_radix_arg1_19130, 0);
    bool valid_19134 = !bounds_invalid_upwards_19132;
    bool range_valid_c_19135;
    
    if (!valid_19134) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) (int64_t) 0, "...", (long long) tmp_19131, " is invalid.", "-> #0  ftbasics.fut:113:17-26\n   #1  ftHashJoin.fut:238:63-69\n   #2  /prelude/functional.fut:9:44-45\n   #3  ftHashJoin.fut:359:7-361:90\n   #4  ftHashJoin.fut:354:1-362:42\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_21481 = (int64_t) 8 * calc_partitions_from_partitioned_set_res_18944;
    int64_t bytes_21492 = (int64_t) 8 * dzlz7bUZLztztZRz20U2z20Ursz7dUzg_19129;
    int64_t distance_19133 = add64((int64_t) 1, tmp_19131);
    int64_t segmap_tblock_sizze_21043;
    
    segmap_tblock_sizze_21043 = *ctx->tuning_params.mainzisegmap_tblock_sizze_21012;
    
    int64_t segmap_usable_groups_21044 = sdiv_up64(calc_partitions_from_partitioned_set_res_18944, segmap_tblock_sizze_21043);
    
    if (memblock_alloc_device(ctx, &mem_21482, bytes_21481, "mem_21482")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_22185 = sext_i64_i32(sdiv_up64(calc_partitions_from_partitioned_set_res_18944, segmap_tblock_sizze_21043));
    
    {
        err = gpu_kernel_mainzisegmap_21047(ctx, segmap_usable_groups_21044, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_21012, 1, 1, (int64_t) 0, calc_partitions_from_partitioned_set_res_18944, distance_19133, ext_mem_21424.mem, ext_mem_21479.mem, mem_21482.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    ctx->failure_is_an_option = 1;
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    bool cond_19152 = calc_partitions_from_partitioned_set_res_18949 == 1;
    
    if (cond_19152) {
        if (memblock_alloc_device(ctx, &mem_21486, calc_partitions_from_partitioned_set_res_18944, "mem_21486")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_bool(ctx, mem_21486, calc_partitions_from_partitioned_set_res_18944, 1) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_21488, &mem_21486, "mem_21486") != 0)
            return 1;
        if (memblock_set_device(ctx, &ext_mem_21487, &mem_21486, "mem_21486") != 0)
            return 1;
    } else {
        int64_t zeze_rhs_19157 = sub64(calc_partitions_from_partitioned_set_res_18944, (int64_t) 1);
        int64_t segmap_tblock_sizze_21108;
        
        segmap_tblock_sizze_21108 = *ctx->tuning_params.mainzisegmap_tblock_sizze_21076;
        
        int64_t segmap_usable_groups_21109 = sdiv_up64(calc_partitions_from_partitioned_set_res_18944, segmap_tblock_sizze_21108);
        
        if (memblock_alloc_device(ctx, &mem_21484, calc_partitions_from_partitioned_set_res_18944, "mem_21484")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_21485, calc_partitions_from_partitioned_set_res_18944, "mem_21485")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_22215 = sext_i64_i32(sdiv_up64(calc_partitions_from_partitioned_set_res_18944, segmap_tblock_sizze_21108));
        
        {
            err = gpu_kernel_mainzisegmap_21113(ctx, segmap_usable_groups_21109, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_21076, 1, 1, (int64_t) 0, calc_partitions_from_partitioned_set_res_18944, zeze_rhs_19157, mem_21482.mem, mem_21484.mem, mem_21485.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if (memblock_set_device(ctx, &ext_mem_21488, &mem_21484, "mem_21484") != 0)
            return 1;
        if (memblock_set_device(ctx, &ext_mem_21487, &mem_21485, "mem_21485") != 0)
            return 1;
    }
    
    int64_t segmap_tblock_sizze_21157;
    
    segmap_tblock_sizze_21157 = *ctx->tuning_params.mainzisegmap_tblock_sizze_21143;
    
    int64_t segmap_usable_groups_21158 = sdiv_up64(calc_partitions_from_partitioned_set_res_18944, segmap_tblock_sizze_21157);
    
    if (memblock_alloc_device(ctx, &mem_21491, bytes_21481, "mem_21491")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_22224 = sext_i64_i32(sdiv_up64(calc_partitions_from_partitioned_set_res_18944, segmap_tblock_sizze_21157));
    
    {
        err = gpu_kernel_mainzisegmap_21161(ctx, segmap_usable_groups_21158, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_21143, 1, 1, (int64_t) 0, calc_partitions_from_partitioned_set_res_18944, mem_21482.mem, ext_mem_21488.mem, mem_21491.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_21482, "mem_21482") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_21493, bytes_21492, "mem_21493")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_21493, dzlz7bUZLztztZRz20U2z20Ursz7dUzg_19129, (int64_t) -1) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t zm_lhs_19197 = add64((int64_t) 256, dzlz7bUZLztztZRz20U2z20Ursz7dUzg_19129);
    int64_t zs_lhs_19198 = sub64(zm_lhs_19197, (int64_t) 1);
    int64_t m_19199 = sdiv64(zs_lhs_19198, (int64_t) 256);
    bool loop_cond_19200 = slt64((int64_t) 0, m_19199);
    int64_t segmap_tblock_sizze_21174;
    
    segmap_tblock_sizze_21174 = *ctx->tuning_params.mainzisegmap_tblock_sizze_21173;
    
    int64_t num_tblocks_21176;
    int64_t max_num_tblocks_22233;
    
    max_num_tblocks_22233 = *ctx->tuning_params.mainzisegmap_num_tblocks_21175;
    num_tblocks_21176 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(calc_partitions_from_partitioned_set_res_18944, segmap_tblock_sizze_21174), max_num_tblocks_22233)));
    
    bool partitioned_scatter_res_19201;
    int64_t partitioned_scatter_res_19203;
    bool loop_while_19204;
    int64_t p_19206;
    
    loop_while_19204 = loop_cond_19200;
    p_19206 = (int64_t) 0;
    while (loop_while_19204) {
        int64_t lower_bound_19207 = mul64((int64_t) 256, p_19206);
        int64_t min_arg1_19208 = add64((int64_t) 256, lower_bound_19207);
        int64_t min_res_19209 = smin64(dzlz7bUZLztztZRz20U2z20Ursz7dUzg_19129, min_arg1_19208);
        int64_t j_m_i_19210 = sub64(min_res_19209, lower_bound_19207);
        bool empty_slice_19211 = j_m_i_19210 == (int64_t) 0;
        int64_t m_19212 = sub64(j_m_i_19210, (int64_t) 1);
        int64_t i_p_m_t_s_19213 = add64(lower_bound_19207, m_19212);
        bool zzero_leq_i_p_m_t_s_19214 = sle64((int64_t) 0, i_p_m_t_s_19213);
        bool i_p_m_t_s_leq_w_19215 = slt64(i_p_m_t_s_19213, dzlz7bUZLztztZRz20U2z20Ursz7dUzg_19129);
        bool zzero_lte_i_19216 = sle64((int64_t) 0, lower_bound_19207);
        bool i_lte_j_19217 = sle64(lower_bound_19207, min_res_19209);
        bool y_19218 = i_p_m_t_s_leq_w_19215 && zzero_lte_i_19216;
        bool y_19219 = zzero_leq_i_p_m_t_s_19214 && y_19218;
        bool forwards_ok_19220 = i_lte_j_19217 && y_19219;
        bool ok_or_empty_19221 = empty_slice_19211 || forwards_ok_19220;
        bool index_certs_19222;
        
        if (!ok_or_empty_19221) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) lower_bound_19207, ":", (long long) min_res_19209, "] out of bounds for array of shape [", (long long) dzlz7bUZLztztZRz20U2z20Ursz7dUzg_19129, "].", "-> #0  ftbasics.fut:72:25-56\n   #1  ftHashJoin.fut:359:7-361:90\n   #2  ftHashJoin.fut:354:1-362:42\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t bytes_21497 = (int64_t) 8 * j_m_i_19210;
        
        if (memblock_alloc_device(ctx, &mem_21498, bytes_21497, "mem_21498")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_21498.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_21493.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_19207, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_19210})) != 0)
            goto cleanup;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_22237 = sext_i64_i32(sdiv_up64(calc_partitions_from_partitioned_set_res_18944, segmap_tblock_sizze_21174));
        
        {
            err = gpu_kernel_mainzisegmap_21171(ctx, num_tblocks_21176, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_21173, 1, 1, (int64_t) 0, calc_partitions_from_partitioned_set_res_18944, lower_bound_19207, min_res_19209, j_m_i_19210, num_tblocks_21176, virt_num_tblocks_22237, ext_mem_21479.mem, mem_21491.mem, mem_21498.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t tmp_19232 = add64((int64_t) 1, p_19206);
        
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_21493.mem, lower_bound_19207, (int64_t []) {(int64_t) 1}, mem_21498.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_19210})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_21498, "mem_21498") != 0)
            return 1;
        
        bool loop_cond_19237 = slt64(tmp_19232, m_19199);
        bool loop_while_tmp_22234 = loop_cond_19237;
        int64_t p_tmp_22236 = tmp_19232;
        
        loop_while_19204 = loop_while_tmp_22234;
        p_19206 = p_tmp_22236;
    }
    partitioned_scatter_res_19201 = loop_while_19204;
    partitioned_scatter_res_19203 = p_19206;
    if (memblock_unref_device(ctx, &ext_mem_21479, "ext_mem_21479") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_21503, dzlz7bUZLztztZRz20U2z20Ursz7dUzg_19129, "mem_21503")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_bool(ctx, mem_21503, dzlz7bUZLztztZRz20U2z20Ursz7dUzg_19129, 1) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_21504, dzlz7bUZLztztZRz20U2z20Ursz7dUzg_19129, "mem_21504")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_bool(ctx, mem_21504, dzlz7bUZLztztZRz20U2z20Ursz7dUzg_19129, 1) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t segmap_tblock_sizze_21182;
    
    segmap_tblock_sizze_21182 = *ctx->tuning_params.mainzisegmap_tblock_sizze_21181;
    
    int64_t num_tblocks_21184;
    int64_t max_num_tblocks_22250;
    
    max_num_tblocks_22250 = *ctx->tuning_params.mainzisegmap_num_tblocks_21183;
    num_tblocks_21184 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(calc_partitions_from_partitioned_set_res_18944, segmap_tblock_sizze_21182), max_num_tblocks_22250)));
    
    bool partitioned_scatter_res_19240;
    int64_t partitioned_scatter_res_19243;
    bool loop_while_19244;
    int64_t p_19247;
    
    loop_while_19244 = loop_cond_19200;
    p_19247 = (int64_t) 0;
    while (loop_while_19244) {
        int64_t lower_bound_19248 = mul64((int64_t) 256, p_19247);
        int64_t min_arg1_19249 = add64((int64_t) 256, lower_bound_19248);
        int64_t min_res_19250 = smin64(dzlz7bUZLztztZRz20U2z20Ursz7dUzg_19129, min_arg1_19249);
        int64_t j_m_i_19251 = sub64(min_res_19250, lower_bound_19248);
        bool empty_slice_19252 = j_m_i_19251 == (int64_t) 0;
        int64_t m_19253 = sub64(j_m_i_19251, (int64_t) 1);
        int64_t i_p_m_t_s_19254 = add64(lower_bound_19248, m_19253);
        bool zzero_leq_i_p_m_t_s_19255 = sle64((int64_t) 0, i_p_m_t_s_19254);
        bool i_p_m_t_s_leq_w_19256 = slt64(i_p_m_t_s_19254, dzlz7bUZLztztZRz20U2z20Ursz7dUzg_19129);
        bool zzero_lte_i_19257 = sle64((int64_t) 0, lower_bound_19248);
        bool i_lte_j_19258 = sle64(lower_bound_19248, min_res_19250);
        bool y_19259 = i_p_m_t_s_leq_w_19256 && zzero_lte_i_19257;
        bool y_19260 = zzero_leq_i_p_m_t_s_19255 && y_19259;
        bool forwards_ok_19261 = i_lte_j_19258 && y_19260;
        bool ok_or_empty_19262 = empty_slice_19252 || forwards_ok_19261;
        bool index_certs_19263;
        
        if (!ok_or_empty_19262) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) lower_bound_19248, ":", (long long) min_res_19250, "] out of bounds for array of shape [", (long long) dzlz7bUZLztztZRz20U2z20Ursz7dUzg_19129, "].", "-> #0  ftbasics.fut:72:25-56\n   #1  ftHashJoin.fut:359:7-361:90\n   #2  ftHashJoin.fut:354:1-362:42\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_21511, j_m_i_19251, "mem_21511")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_1b(ctx, 1, mem_21511.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_21503.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_19248, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_19251})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_21511, "mem_21511") != 0)
            return 1;
        if (memblock_alloc_device(ctx, &mem_21512, j_m_i_19251, "mem_21512")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_1b(ctx, 1, mem_21512.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_21504.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_19248, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_19251})) != 0)
            goto cleanup;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_22255 = sext_i64_i32(sdiv_up64(calc_partitions_from_partitioned_set_res_18944, segmap_tblock_sizze_21182));
        
        {
            err = gpu_kernel_mainzisegmap_21179(ctx, num_tblocks_21184, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_21181, 1, 1, (int64_t) 0, calc_partitions_from_partitioned_set_res_18944, lower_bound_19248, min_res_19250, j_m_i_19251, num_tblocks_21184, virt_num_tblocks_22255, ext_mem_21487.mem, ext_mem_21488.mem, mem_21491.mem, mem_21503.mem, mem_21512.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t tmp_19275 = add64((int64_t) 1, p_19247);
        
        if ((err = lmad_copy_gpu2gpu_1b(ctx, 1, mem_21504.mem, lower_bound_19248, (int64_t []) {(int64_t) 1}, mem_21512.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_19251})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_21512, "mem_21512") != 0)
            return 1;
        
        bool loop_cond_19283 = slt64(tmp_19275, m_19199);
        bool loop_while_tmp_22251 = loop_cond_19283;
        int64_t p_tmp_22254 = tmp_19275;
        
        loop_while_19244 = loop_while_tmp_22251;
        p_19247 = p_tmp_22254;
    }
    partitioned_scatter_res_19240 = loop_while_19244;
    partitioned_scatter_res_19243 = p_19247;
    if (memblock_unref_device(ctx, &ext_mem_21487, "ext_mem_21487") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_21488, "ext_mem_21488") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_21491, "mem_21491") != 0)
        return 1;
    
    int64_t segmap_tblock_sizze_21199;
    
    segmap_tblock_sizze_21199 = *ctx->tuning_params.mainzisegmap_tblock_sizze_21189;
    
    int64_t segmap_usable_groups_21200 = sdiv_up64(dzlz7bUZLztztZRz20U2z20Ursz7dUzg_19129, segmap_tblock_sizze_21199);
    
    if (memblock_alloc_device(ctx, &mem_21521, dzlz7bUZLztztZRz20U2z20Ursz7dUzg_19129, "mem_21521")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_22268 = sext_i64_i32(sdiv_up64(dzlz7bUZLztztZRz20U2z20Ursz7dUzg_19129, segmap_tblock_sizze_21199));
    
    {
        err = gpu_kernel_mainzisegmap_21203(ctx, segmap_usable_groups_21200, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_21189, 1, 1, (int64_t) 0, dzlz7bUZLztztZRz20U2z20Ursz7dUzg_19129, mem_21503.mem, mem_21504.mem, mem_21521.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_21503, "mem_21503") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_21504, "mem_21504") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_21592, &ext_mem_21424, "ext_mem_21424") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_21593, &mem_21493, "mem_21493") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_21594, &mem_21521, "mem_21521") != 0)
        return 1;
    prim_out_21595 = dzlz7bUZLztztZRz20U2z20Ursz7dUzg_19129;
    if (memblock_set_device(ctx, &*mem_out_p_22277, &mem_out_21592, "mem_out_21592") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_22278, &mem_out_21593, "mem_out_21593") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_22279, &mem_out_21594, "mem_out_21594") != 0)
        return 1;
    *out_prim_out_22280 = prim_out_21595;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_21521, "mem_21521") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21512, "mem_21512") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21511, "mem_21511") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21504, "mem_21504") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21503, "mem_21503") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21498, "mem_21498") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21493, "mem_21493") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21491, "mem_21491") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21485, "mem_21485") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21484, "mem_21484") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21486, "mem_21486") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_21487, "ext_mem_21487") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_21488, "ext_mem_21488") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21482, "mem_21482") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_22039, "mem_param_tmp_22039") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_22038, "mem_param_tmp_22038") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_22166, "mem_param_tmp_22166") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_22165, "mem_param_tmp_22165") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21467, "mem_21467") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21465, "mem_21465") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_21459, "ext_mem_21459") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_21460, "ext_mem_21460") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21457, "mem_21457") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_21455, "mem_param_21455") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_21452, "mem_param_21452") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_21472, "ext_mem_21472") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_21473, "ext_mem_21473") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21448, "mem_21448") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21446, "mem_21446") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21444, "mem_21444") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_22060, "incprefixes_mem_22060") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_22058, "aggregates_mem_22058") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_22056, "status_flags_mem_22056") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21442, "mem_21442") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21440, "mem_21440") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21438, "mem_21438") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_21435, "mem_param_21435") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_21432, "mem_param_21432") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_21478, "ext_mem_21478") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_21479, "ext_mem_21479") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_21428, "ext_mem_21428") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_21429, "ext_mem_21429") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21426, "mem_21426") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_21637, "mem_param_tmp_21637") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_21636, "mem_param_tmp_21636") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_21635, "mem_param_tmp_21635") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_21634, "mem_param_tmp_21634") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_21648, "mem_param_tmp_21648") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_21647, "mem_param_tmp_21647") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_21646, "mem_param_tmp_21646") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_21645, "mem_param_tmp_21645") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21399, "mem_21399") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21397, "mem_21397") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21390, "mem_21390") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21389, "mem_21389") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21387, "mem_21387") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21385, "mem_21385") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_21922, "incprefixes_mem_21922") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_21920, "aggregates_mem_21920") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_21918, "status_flags_mem_21918") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21383, "mem_21383") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21381, "mem_21381") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21379, "mem_21379") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_21375, "ext_mem_21375") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_21376, "ext_mem_21376") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21373, "mem_21373") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_21659, "mem_param_tmp_21659") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_21658, "mem_param_tmp_21658") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21350, "mem_21350") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21348, "mem_21348") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21339, "mem_21339") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21337, "mem_21337") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_21675, "mem_param_tmp_21675") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_21674, "mem_param_tmp_21674") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21329, "mem_21329") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21328, "mem_21328") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_21823, "segred_tmp_mem_21823") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_21709, "incprefixes_mem_21709") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_21707, "aggregates_mem_21707") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_21685, "status_flags_mem_21685") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_21316, "mem_param_21316") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_21313, "mem_param_21313") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_21334, "ext_mem_21334") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_21335, "ext_mem_21335") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_21304, "mem_param_21304") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_21301, "mem_param_21301") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_21370, "ext_mem_21370") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_21371, "ext_mem_21371") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21355, "mem_21355") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21353, "mem_21353") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21323, "mem_21323") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21321, "mem_21321") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21319, "mem_21319") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21310, "mem_21310") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21297, "mem_21297") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_21295, "mem_param_21295") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_21291, "mem_param_21291") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_21288, "mem_param_21288") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_21285, "mem_param_21285") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_21409, "ext_mem_21409") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_21410, "ext_mem_21410") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_21411, "ext_mem_21411") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_21412, "ext_mem_21412") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_21282, "mem_param_21282") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_21279, "mem_param_21279") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_21276, "mem_param_21276") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_21272, "mem_param_21272") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_21422, "ext_mem_21422") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_21423, "ext_mem_21423") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_21424, "ext_mem_21424") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_21425, "ext_mem_21425") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21325, "mem_21325") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21269, "mem_21269") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21268, "mem_21268") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21267, "mem_21267") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21266, "mem_21266") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21265, "mem_21265") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_21594, "mem_out_21594") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_21593, "mem_out_21593") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_21592, "mem_out_21592") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_getPartitionBounds_8487(struct futhark_context *ctx, struct memblock_device *mem_out_p_22289, struct memblock_device *mem_out_p_22290, int64_t *out_prim_out_22291, int64_t *out_prim_out_22292, int32_t *out_prim_out_22293, int32_t *out_prim_out_22294, int32_t *out_prim_out_22295, struct memblock_device pXs_mem_21265, int64_t n_14235, int64_t b_14236, int32_t curDepth_14237, int32_t i_14239, int32_t j_14240)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_21383;
    
    mem_21383.references = NULL;
    
    struct memblock_device mem_21381;
    
    mem_21381.references = NULL;
    
    struct memblock_device mem_21377;
    
    mem_21377.references = NULL;
    
    struct memblock_device incprefixes_mem_21925;
    
    incprefixes_mem_21925.references = NULL;
    
    struct memblock_device aggregates_mem_21923;
    
    aggregates_mem_21923.references = NULL;
    
    struct memblock_device status_flags_mem_21921;
    
    status_flags_mem_21921.references = NULL;
    
    struct memblock_device mem_21344;
    
    mem_21344.references = NULL;
    
    struct memblock_device mem_21341;
    
    mem_21341.references = NULL;
    
    struct memblock_device mem_21305;
    
    mem_21305.references = NULL;
    
    struct memblock_device segred_tmp_mem_21864;
    
    segred_tmp_mem_21864.references = NULL;
    
    struct memblock_device mem_21302;
    
    mem_21302.references = NULL;
    
    struct memblock_device mem_21300;
    
    mem_21300.references = NULL;
    
    struct memblock_device mem_21290;
    
    mem_21290.references = NULL;
    
    struct memblock_device mem_21279;
    
    mem_21279.references = NULL;
    
    struct memblock_device mem_21277;
    
    mem_21277.references = NULL;
    
    struct memblock_device mem_21274;
    
    mem_21274.references = NULL;
    
    struct memblock_device mem_21271;
    
    mem_21271.references = NULL;
    
    struct memblock_device mem_21268;
    
    mem_21268.references = NULL;
    
    struct memblock_device mem_21267;
    
    mem_21267.references = NULL;
    
    struct memblock_device mem_21310;
    
    mem_21310.references = NULL;
    
    struct memblock_device ext_mem_21311;
    
    ext_mem_21311.references = NULL;
    
    struct memblock_device color_21559;
    
    color_21559.references = NULL;
    
    struct memblock_device color_21558;
    
    color_21558.references = NULL;
    
    struct memblock_device mem_21338;
    
    mem_21338.references = NULL;
    
    struct memblock_device mem_21321;
    
    mem_21321.references = NULL;
    
    struct memblock_device ext_mem_21339;
    
    ext_mem_21339.references = NULL;
    
    struct memblock_device ext_mem_21374;
    
    ext_mem_21374.references = NULL;
    
    struct memblock_device ext_mem_21375;
    
    ext_mem_21375.references = NULL;
    
    struct memblock_device mem_out_21593;
    
    mem_out_21593.references = NULL;
    
    struct memblock_device mem_out_21592;
    
    mem_out_21592.references = NULL;
    
    struct memblock_device counters_mem_21821 = ctx->constants->counters_mem_21821;
    struct memblock_device counters_mem_21866 = ctx->constants->counters_mem_21866;
    struct memblock_device global_dynid_mem_21636 = ctx->constants->global_dynid_mem_21636;
    struct memblock_device global_dynid_mem_21711 = ctx->constants->global_dynid_mem_21711;
    struct memblock_device global_dynid_mem_21924 = ctx->constants->global_dynid_mem_21924;
    struct memblock_device global_dynid_mem_21927 = ctx->constants->global_dynid_mem_21927;
    struct memblock_device global_dynid_mem_22062 = ctx->constants->global_dynid_mem_22062;
    int64_t prim_out_21594;
    int64_t prim_out_21595;
    int32_t prim_out_21596;
    int32_t prim_out_21597;
    int32_t prim_out_21598;
    int64_t dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241 = sub64(n_14235, (int64_t) 1);
    bool bounds_invalid_upwards_14245 = slt64(n_14235, (int64_t) 1);
    bool valid_14250 = !bounds_invalid_upwards_14245;
    bool range_valid_c_14251;
    
    if (!valid_14250) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) (int64_t) 1, "..<", (long long) n_14235, " is invalid.", "-> #0  ftHashJoin.fut:74:23-28\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int32_t zm_rhs_19305 = sdiv32(j_14240, 8);
    int32_t i64_res_19300 = sext_i64_i32(b_14236);
    int32_t zm_lhs_19306 = sub32(i64_res_19300, zm_rhs_19305);
    int32_t i32_arg0_19307 = sub32(zm_lhs_19306, 1);
    int64_t i32_res_19308 = sext_i32_i64(i32_arg0_19307);
    bool y_19333 = slt64(i32_res_19308, b_14236);
    bool x_19332 = sle64((int64_t) 0, i32_res_19308);
    bool bounds_check_19334 = x_19332 && y_19333;
    bool index_certs_19335;
    
    if (!bounds_check_19334) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) i32_res_19308, "] out of bounds for array of shape [", (long long) b_14236, "].", "-> #0  ftHashJoin.fut:43:38-54\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int32_t zm_rhs_19301 = sdiv32(i_14239, 8);
    int32_t zm_lhs_19302 = sub32(i64_res_19300, zm_rhs_19301);
    int32_t i32_arg0_19303 = sub32(zm_lhs_19302, 1);
    int64_t i32_res_19304 = sext_i32_i64(i32_arg0_19303);
    bool y_19326 = slt64(i32_res_19304, b_14236);
    bool x_19325 = sle64((int64_t) 0, i32_res_19304);
    bool bounds_check_19327 = x_19325 && y_19326;
    bool index_certs_19328;
    
    if (!bounds_check_19327) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) i32_res_19304, "] out of bounds for array of shape [", (long long) b_14236, "].", "-> #0  ftHashJoin.fut:42:48-64\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int32_t lastBit_19310 = smod32(j_14240, 8);
    int32_t zm_lhs_19313 = sub32(8, lastBit_19310);
    int32_t i32_arg0_19314 = sub32(zm_lhs_19313, 1);
    int8_t unsign_arg0_19315 = zext_i32_i8(i32_arg0_19314);
    int8_t unsign_arg0_19316 = lshr8((int8_t) -1, unsign_arg0_19315);
    int32_t firstBit_19309 = smod32(i_14239, 8);
    int8_t unsign_arg0_19311 = zext_i32_i8(firstBit_19309);
    int8_t first_bitMask_19312 = shl8((int8_t) -1, unsign_arg0_19311);
    bool suff_outer_screma_20012;
    
    suff_outer_screma_20012 = *ctx->tuning_params.getPartitionBounds_8487zisuff_outer_screma_0 <= dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241;
    if (ctx->logging)
        fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "getPartitionBounds_8487.suff_outer_screma_0", (long) dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, suff_outer_screma_20012 ? "true" : "false");
    
    bool suff_outer_par_20532;
    
    suff_outer_par_20532 = *ctx->tuning_params.getPartitionBounds_8487zisuff_outer_par_1 <= dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241;
    if (ctx->logging)
        fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "getPartitionBounds_8487.suff_outer_par_1", (long) dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, suff_outer_par_20532 ? "true" : "false");
    
    int64_t max_tblock_sizze_20535;
    
    max_tblock_sizze_20535 = ctx->max_thread_block_size;
    
    bool fits_20536 = sle64(b_14236, max_tblock_sizze_20535);
    bool suff_intra_par_20538;
    
    suff_intra_par_20538 = *ctx->tuning_params.getPartitionBounds_8487zisuff_intra_par_2 <= b_14236;
    if (ctx->logging)
        fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "getPartitionBounds_8487.suff_intra_par_2", (long) b_14236, suff_intra_par_20538 ? "true" : "false");
    
    bool intra_suff_and_fits_20539 = fits_20536 && suff_intra_par_20538;
    int64_t segmap_tblock_sizze_20642;
    
    segmap_tblock_sizze_20642 = *ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20395;
    
    int64_t segmap_usable_groups_20643 = sdiv_up_safe64(dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, segmap_tblock_sizze_20642);
    int64_t nest_sizze_20660 = b_14236 * dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241;
    int64_t segmap_tblock_sizze_20661;
    
    segmap_tblock_sizze_20661 = *ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20383;
    
    int64_t segmap_usable_groups_20662 = sdiv_up_safe64(nest_sizze_20660, segmap_tblock_sizze_20661);
    int64_t segmap_tblock_sizze_20672;
    
    segmap_tblock_sizze_20672 = *ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20367;
    
    int64_t segmap_usable_groups_20673 = sdiv_up_safe64(nest_sizze_20660, segmap_tblock_sizze_20672);
    int64_t segmap_tblock_sizze_20687;
    
    segmap_tblock_sizze_20687 = *ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20328;
    
    int64_t segmap_usable_groups_20688 = sdiv_up_safe64(nest_sizze_20660, segmap_tblock_sizze_20687);
    int64_t segmap_tblock_sizze_20705;
    
    segmap_tblock_sizze_20705 = *ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20292;
    
    int64_t num_tblocks_20706;
    int64_t max_num_tblocks_21599;
    
    max_num_tblocks_21599 = *ctx->tuning_params.getPartitionBounds_8487zisegmap_num_tblocks_20294;
    num_tblocks_20706 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, segmap_tblock_sizze_20705), max_num_tblocks_21599)));
    
    int64_t segred_tblock_sizze_20728;
    
    segred_tblock_sizze_20728 = *ctx->tuning_params.getPartitionBounds_8487zisegred_tblock_sizze_20268;
    
    int64_t num_tblocks_20729;
    int64_t max_num_tblocks_21600;
    
    max_num_tblocks_21600 = *ctx->tuning_params.getPartitionBounds_8487zisegred_num_tblocks_20270;
    num_tblocks_20729 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nest_sizze_20660, segred_tblock_sizze_20728), max_num_tblocks_21600)));
    
    int64_t segmap_tblock_sizze_20745;
    
    segmap_tblock_sizze_20745 = *ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20256;
    
    int64_t segmap_usable_groups_20746 = sdiv_up_safe64(dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, segmap_tblock_sizze_20745);
    int64_t segmap_tblock_sizze_20542;
    
    segmap_tblock_sizze_20542 = *ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20100;
    
    int64_t segmap_usable_groups_20543 = sdiv_up_safe64(dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, segmap_tblock_sizze_20542);
    int64_t segscan_tblock_sizze_20755;
    
    segscan_tblock_sizze_20755 = *ctx->tuning_params.getPartitionBounds_8487zisegscan_tblock_sizze_20524;
    
    int64_t num_tblocks_20756;
    int64_t max_num_tblocks_21601;
    
    max_num_tblocks_21601 = *ctx->tuning_params.getPartitionBounds_8487zisegscan_num_tblocks_20526;
    num_tblocks_20756 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, segscan_tblock_sizze_20755), max_num_tblocks_21601)));
    
    int64_t segscan_tblock_sizze_20022;
    
    segscan_tblock_sizze_20022 = *ctx->tuning_params.getPartitionBounds_8487zisegscan_tblock_sizze_20014;
    
    int64_t num_tblocks_20023;
    int64_t max_num_tblocks_21602;
    
    max_num_tblocks_21602 = *ctx->tuning_params.getPartitionBounds_8487zisegscan_num_tblocks_20016;
    num_tblocks_20023 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, segscan_tblock_sizze_20022), max_num_tblocks_21602)));
    
    int64_t binop_y_21281 = dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241 - (int64_t) 1;
    int64_t binop_x_21283 = smax64((int64_t) 0, binop_y_21281);
    int64_t binop_y_21284 = b_14236 - (int64_t) 1;
    int64_t binop_x_21285 = smax64((int64_t) 0, binop_y_21284);
    int64_t binop_y_21286 = dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241 * binop_x_21285;
    int64_t binop_y_21287 = smax64((int64_t) 0, binop_y_21286);
    int64_t binop_y_21288 = binop_x_21283 + binop_y_21287;
    int64_t bytes_21289 = (int64_t) 1 + binop_y_21288;
    int64_t bytes_21304 = (int64_t) 8 * dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241;
    int64_t binop_x_21314 = smax64((int64_t) 0, dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241);
    int64_t binop_y_21317 = n_14235 * binop_x_21285;
    int64_t binop_y_21318 = smax64((int64_t) 0, binop_y_21317);
    int64_t binop_y_21319 = binop_x_21314 + binop_y_21318;
    int64_t bytes_21320 = (int64_t) 1 + binop_y_21319;
    int64_t num_threads_21577 = segmap_tblock_sizze_20542 * segmap_usable_groups_20543;
    int64_t total_sizze_21578 = b_14236 * num_threads_21577;
    int64_t total_sizze_21579 = b_14236 * num_threads_21577;
    int64_t num_threads_21562 = segscan_tblock_sizze_20022 * num_tblocks_20023;
    int64_t total_sizze_21563 = b_14236 * num_threads_21562;
    int64_t total_sizze_21564 = b_14236 * num_threads_21562;
    int64_t shared_memory_capacity_21913;
    
    shared_memory_capacity_21913 = ctx->max_shared_memory;
    if (suff_outer_par_20532 && sle64((int64_t) 0, shared_memory_capacity_21913)) {
        if (memblock_alloc_device(ctx, &mem_21321, bytes_21320, "mem_21321")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_1b(ctx, 2, mem_21321.mem, (int64_t) 0, (int64_t []) {(int64_t) 1, n_14235}, pXs_mem_21265.mem, (int64_t) 0, (int64_t []) {b_14236, (int64_t) 1}, (int64_t []) {n_14235, b_14236})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_21338, bytes_21304, "mem_21338")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &color_21558, total_sizze_21578, "color_21558")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &color_21559, total_sizze_21579, "color_21559")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_21748 = sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, segmap_tblock_sizze_20542));
        
        {
            err = gpu_kernel_getPartitionBounds_8487zisegmap_20546(ctx, segmap_usable_groups_20543, 1, 1, *ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20100, 1, 1, (int64_t) 0, n_14235, b_14236, dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, i32_res_19304, i32_res_19308, first_bitMask_19312, unsign_arg0_19316, num_threads_21577, mem_21321.mem, mem_21338.mem, color_21558.mem, color_21559.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if (memblock_unref_device(ctx, &mem_21321, "mem_21321") != 0)
            return 1;
        if (memblock_unref_device(ctx, &color_21558, "color_21558") != 0)
            return 1;
        if (memblock_unref_device(ctx, &color_21559, "color_21559") != 0)
            return 1;
        if (memblock_set_device(ctx, &ext_mem_21339, &mem_21338, "mem_21338") != 0)
            return 1;
    } else {
        int64_t shared_memory_capacity_21912;
        
        shared_memory_capacity_21912 = ctx->max_shared_memory;
        if (intra_suff_and_fits_20539 && sle64(sdiv_up64(b_14236, (int64_t) 8) * (int64_t) 8 + sdiv_up64(b_14236, (int64_t) 8) * (int64_t) 8 + sdiv_up64(b_14236, (int64_t) 8) * (int64_t) 8, shared_memory_capacity_21912)) {
            if (memblock_alloc_device(ctx, &mem_21310, bytes_21304, "mem_21310")) {
                err = 1;
                goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegMap");
            
            int32_t num_chunks_21760 = sext_i64_i32(sdiv_up64(b_14236, b_14236));
            int32_t virt_num_tblocks_21761 = sext_i64_i32(dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241);
            
            {
                err = gpu_kernel_getPartitionBounds_8487zisegmap_intrablock_20593(ctx, dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, 1, 1, b_14236, 1, 1, b_14236 + srem64((int64_t) 8 - srem64(b_14236, (int64_t) 8), (int64_t) 8) + (b_14236 + srem64((int64_t) 8 - srem64(b_14236, (int64_t) 8), (int64_t) 8)) + (b_14236 + srem64((int64_t) 8 - srem64(b_14236, (int64_t) 8), (int64_t) 8)), n_14235, b_14236, dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, i32_res_19304, i32_res_19308, first_bitMask_19312, unsign_arg0_19316, pXs_mem_21265.mem, mem_21310.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            ctx->failure_is_an_option = 1;
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
            if (memblock_set_device(ctx, &ext_mem_21311, &mem_21310, "mem_21310") != 0)
                return 1;
        } else {
            if (memblock_alloc_device(ctx, &mem_21267, (int64_t) 0, "mem_21267")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &mem_21268, (int64_t) 0, "mem_21268")) {
                err = 1;
                goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegMap");
            
            int32_t virt_num_tblocks_21776 = sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, segmap_tblock_sizze_20642));
            
            {
                err = gpu_kernel_getPartitionBounds_8487zisegmap_20648(ctx, segmap_usable_groups_20643, 1, 1, *ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20395, 1, 1, (int64_t) 0, n_14235, dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, mem_21267.mem, mem_21268.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            ctx->failure_is_an_option = 1;
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
            if (memblock_alloc_device(ctx, &mem_21271, nest_sizze_20660, "mem_21271")) {
                err = 1;
                goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegMap");
            
            int32_t virt_num_tblocks_21785 = sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241 * b_14236, segmap_tblock_sizze_20661));
            
            {
                err = gpu_kernel_getPartitionBounds_8487zisegmap_20666(ctx, segmap_usable_groups_20662, 1, 1, *ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20383, 1, 1, (int64_t) 0, b_14236, dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, pXs_mem_21265.mem, mem_21267.mem, mem_21271.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
            if (memblock_unref_device(ctx, &mem_21267, "mem_21267") != 0)
                return 1;
            if (memblock_alloc_device(ctx, &mem_21274, nest_sizze_20660, "mem_21274")) {
                err = 1;
                goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegMap");
            
            int32_t virt_num_tblocks_21796 = sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241 * b_14236, segmap_tblock_sizze_20672));
            
            {
                err = gpu_kernel_getPartitionBounds_8487zisegmap_20677(ctx, segmap_usable_groups_20673, 1, 1, *ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20367, 1, 1, (int64_t) 0, b_14236, dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, pXs_mem_21265.mem, mem_21268.mem, mem_21274.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
            if (memblock_unref_device(ctx, &mem_21268, "mem_21268") != 0)
                return 1;
            if (memblock_alloc_device(ctx, &mem_21277, nest_sizze_20660, "mem_21277")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &mem_21279, nest_sizze_20660, "mem_21279")) {
                err = 1;
                goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegMap");
            
            int32_t virt_num_tblocks_21807 = sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241 * b_14236, segmap_tblock_sizze_20687));
            
            {
                err = gpu_kernel_getPartitionBounds_8487zisegmap_20693(ctx, segmap_usable_groups_20688, 1, 1, *ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20328, 1, 1, (int64_t) 0, b_14236, dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, i32_res_19304, i32_res_19308, mem_21271.mem, mem_21274.mem, mem_21277.mem, mem_21279.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
            if (memblock_unref_device(ctx, &mem_21271, "mem_21271") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_21274, "mem_21274") != 0)
                return 1;
            if (memblock_alloc_device(ctx, &mem_21290, bytes_21289, "mem_21290")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &mem_21300, bytes_21289, "mem_21300")) {
                err = 1;
                goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegMap");
            
            int32_t virt_num_tblocks_21818 = sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, segmap_tblock_sizze_20705));
            
            {
                err = gpu_kernel_getPartitionBounds_8487zisegmap_20711(ctx, num_tblocks_20706, 1, 1, *ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20292, 1, 1, (int64_t) 0, b_14236, dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, i32_res_19304, i32_res_19308, first_bitMask_19312, unsign_arg0_19316, num_tblocks_20706, virt_num_tblocks_21818, mem_21277.mem, mem_21279.mem, mem_21290.mem, mem_21300.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
            if (memblock_unref_device(ctx, &mem_21277, "mem_21277") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_21279, "mem_21279") != 0)
                return 1;
            if (memblock_alloc_device(ctx, &mem_21302, dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, "mem_21302")) {
                err = 1;
                goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegRed");
            
            int64_t chunk_sizze_21831 = (int64_t) 1;
            
            if (slt64(b_14236 * (int64_t) 2, segred_tblock_sizze_20728 * chunk_sizze_21831)) {
                int64_t segment_sizze_nonzzero_21832 = smax64((int64_t) 1, b_14236);
                int64_t num_threads_21833 = segred_tblock_sizze_20728 * segred_tblock_sizze_20728;
                
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "# SegRed-small");
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) b_14236, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "segments_per_block", (long long) squot64(segred_tblock_sizze_20728, segment_sizze_nonzzero_21832), '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "required_blocks", (long long) sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, squot64(segred_tblock_sizze_20728, segment_sizze_nonzzero_21832))), '\n');
                {
                    err = gpu_kernel_getPartitionBounds_8487zisegred_small_20734(ctx, num_tblocks_20729, 1, 1, *ctx->tuning_params.getPartitionBounds_8487zisegred_tblock_sizze_20268, 1, 1, segred_tblock_sizze_20728 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_20728, (int64_t) 8), (int64_t) 8), b_14236, dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, num_tblocks_20729, segment_sizze_nonzzero_21832, mem_21290.mem, mem_21300.mem, mem_21302.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
            } else {
                int64_t blocks_per_segment_21860 = sdiv_up64(num_tblocks_20729, smax64((int64_t) 1, dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241));
                int64_t q_21861 = sdiv_up64(b_14236, segred_tblock_sizze_20728 * blocks_per_segment_21860 * chunk_sizze_21831);
                int64_t num_virtblocks_21862 = blocks_per_segment_21860 * dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241;
                int64_t threads_per_segment_21863 = blocks_per_segment_21860 * segred_tblock_sizze_20728;
                
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "# SegRed-large");
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) b_14236, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "num_virtblocks", (long long) num_virtblocks_21862, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "num_tblocks", (long long) num_tblocks_20729, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "tblock_size", (long long) segred_tblock_sizze_20728, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "q", (long long) q_21861, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "blocks_per_segment", (long long) blocks_per_segment_21860, '\n');
                if (memblock_alloc_device(ctx, &segred_tmp_mem_21864, num_virtblocks_21862, "segred_tmp_mem_21864")) {
                    err = 1;
                    goto cleanup;
                }
                {
                    err = gpu_kernel_getPartitionBounds_8487zisegred_large_20734(ctx, num_tblocks_20729, 1, 1, *ctx->tuning_params.getPartitionBounds_8487zisegred_tblock_sizze_20268, 1, 1, 8 + (segred_tblock_sizze_20728 + srem64((int64_t) 8 - srem64(segred_tblock_sizze_20728, (int64_t) 8), (int64_t) 8)), b_14236, dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, num_tblocks_20729, blocks_per_segment_21860, q_21861, num_virtblocks_21862, threads_per_segment_21863, mem_21290.mem, mem_21300.mem, mem_21302.mem, segred_tmp_mem_21864.mem, counters_mem_21866.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
            if (memblock_unref_device(ctx, &mem_21290, "mem_21290") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_21300, "mem_21300") != 0)
                return 1;
            if (memblock_alloc_device(ctx, &mem_21305, bytes_21304, "mem_21305")) {
                err = 1;
                goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegMap");
            
            int32_t virt_num_tblocks_21903 = sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, segmap_tblock_sizze_20745));
            
            {
                err = gpu_kernel_getPartitionBounds_8487zisegmap_20749(ctx, segmap_usable_groups_20746, 1, 1, *ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20256, 1, 1, (int64_t) 0, dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, mem_21302.mem, mem_21305.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
            if (memblock_unref_device(ctx, &mem_21302, "mem_21302") != 0)
                return 1;
            if (memblock_set_device(ctx, &ext_mem_21311, &mem_21305, "mem_21305") != 0)
                return 1;
        }
        if (memblock_set_device(ctx, &ext_mem_21339, &ext_mem_21311, "ext_mem_21311") != 0)
            return 1;
    }
    if (memblock_alloc_device(ctx, &mem_21341, bytes_21304, "mem_21341")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_21341.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_21339.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241})) != 0)
        goto cleanup;
    if (memblock_alloc_device(ctx, &mem_21344, bytes_21304, "mem_21344")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_21914;
        
        shared_memory_21914 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_21915;
        
        thread_block_sizze_21915 = ctx->max_thread_block_size;
        
        int64_t registers_21916;
        
        registers_21916 = ctx->max_registers;
        
        int64_t thread_block_sizze_21917;
        
        thread_block_sizze_21917 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_21918 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_21914, thread_block_sizze_21915), (int64_t) 8), squot64(squot64(registers_21916, thread_block_sizze_21917) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
        int64_t num_virt_blocks_21919 = sdiv_up64(dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, segscan_tblock_sizze_20755 * chunk_sizze_21918);
        int64_t num_virt_threads_21920 = num_virt_blocks_21919 * segscan_tblock_sizze_20755;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_21918, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_21921, num_virt_blocks_21919, "status_flags_mem_21921")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_21921, num_virt_blocks_21919, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_21923, (int64_t) 8 * num_virt_blocks_21919, "aggregates_mem_21923")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_21925, (int64_t) 8 * num_virt_blocks_21919, "incprefixes_mem_21925")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_getPartitionBounds_8487zisegscan_20760(ctx, num_tblocks_20756, 1, 1, *ctx->tuning_params.getPartitionBounds_8487zisegscan_tblock_sizze_20524, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_20755), chunk_sizze_21918 * segscan_tblock_sizze_20755 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_20755), chunk_sizze_21918 * segscan_tblock_sizze_20755 * (int64_t) 8), (int64_t) 8), (int64_t) 8), dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, num_tblocks_20756, num_virt_blocks_21919, num_virt_threads_21920, ext_mem_21339.mem, mem_21344.mem, status_flags_mem_21921.mem, aggregates_mem_21923.mem, incprefixes_mem_21925.mem, global_dynid_mem_21927.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    if (memblock_unref_device(ctx, &ext_mem_21339, "ext_mem_21339") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_21375, &mem_21344, "mem_21344") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_21374, &mem_21341, "mem_21341") != 0)
        return 1;
    
    bool cond_18085 = dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241 == (int64_t) 0;
    bool x_18086 = !cond_18085;
    bool x_18088 = sle64((int64_t) 0, binop_y_21281);
    bool y_18089 = slt64(binop_y_21281, dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241);
    bool bounds_check_18090 = x_18088 && y_18089;
    bool protect_assert_disj_18091 = cond_18085 || bounds_check_18090;
    bool index_certs_18092;
    
    if (!protect_assert_disj_18091) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) binop_y_21281, "] out of bounds for array of shape [", (long long) dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t m_f_res_18093;
    
    if (x_18086) {
        int64_t read_res_22296;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_22296, ext_mem_21375.mem, binop_y_21281 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_19573 = read_res_22296;
        
        m_f_res_18093 = x_19573;
    } else {
        m_f_res_18093 = (int64_t) 0;
    }
    
    int64_t m_18095;
    
    if (cond_18085) {
        m_18095 = (int64_t) 0;
    } else {
        m_18095 = m_f_res_18093;
    }
    
    int64_t m_18105 = sub64(m_18095, (int64_t) 1);
    bool i_p_m_t_s_leq_w_18107 = slt64(m_18105, dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241);
    bool zzero_leq_i_p_m_t_s_18106 = sle64((int64_t) 0, m_18105);
    bool y_18109 = zzero_leq_i_p_m_t_s_18106 && i_p_m_t_s_leq_w_18107;
    bool i_lte_j_18108 = sle64((int64_t) 0, m_18095);
    bool forwards_ok_18110 = i_lte_j_18108 && y_18109;
    bool eq_x_zz_18102 = (int64_t) 0 == m_f_res_18093;
    bool p_and_eq_x_y_18103 = x_18086 && eq_x_zz_18102;
    bool empty_slice_18104 = cond_18085 || p_and_eq_x_y_18103;
    bool ok_or_empty_18111 = empty_slice_18104 || forwards_ok_18110;
    bool index_certs_18112;
    
    if (!ok_or_empty_18111) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_18095, "] out of bounds for array of shape [", (long long) dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_21376 = (int64_t) 8 * m_18095;
    int64_t conc_tmp_17002 = (int64_t) 1 + m_18095;
    int64_t bytes_21380 = (int64_t) 8 * conc_tmp_17002;
    int64_t bytes_21382 = (int64_t) 4 * conc_tmp_17002;
    
    if (memblock_alloc_device(ctx, &mem_21377, bytes_21376, "mem_21377")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhiota_i64(ctx, mem_21377, m_18095, (int64_t) 1, (int64_t) 1) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t segmap_tblock_sizze_20771;
    
    segmap_tblock_sizze_20771 = *ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20770;
    
    int64_t num_tblocks_20773;
    int64_t max_num_tblocks_22033;
    
    max_num_tblocks_22033 = *ctx->tuning_params.getPartitionBounds_8487zisegmap_num_tblocks_20772;
    num_tblocks_20773 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, segmap_tblock_sizze_20771), max_num_tblocks_22033)));
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_22034 = sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, segmap_tblock_sizze_20771));
    
    {
        err = gpu_kernel_getPartitionBounds_8487zisegmap_20768(ctx, num_tblocks_20773, 1, 1, *ctx->tuning_params.getPartitionBounds_8487zisegmap_tblock_sizze_20770, 1, 1, (int64_t) 0, dzlz7bUZLzmZRz20Unz20U1z7dUzg_14241, m_18095, num_tblocks_20773, virt_num_tblocks_22034, ext_mem_21374.mem, ext_mem_21375.mem, mem_21377.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &ext_mem_21374, "ext_mem_21374") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_21375, "ext_mem_21375") != 0)
        return 1;
    
    int32_t zp_lhs_14375 = sub32(j_14240, i_14239);
    int32_t tmp_14377 = add32(1, zp_lhs_14375);
    
    if (memblock_alloc_device(ctx, &mem_21381, bytes_21380, "mem_21381")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_21381, (int64_t) 1, (int64_t) 0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t tmp_offs_22067 = (int64_t) 0;
    
    if (!(tmp_offs_22067 == (int64_t) 0)) {
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_21381.mem, tmp_offs_22067, (int64_t []) {(int64_t) 1}, mem_21381.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {(int64_t) 1})) != 0)
            goto cleanup;
    }
    tmp_offs_22067 += (int64_t) 1;
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_21381.mem, tmp_offs_22067, (int64_t []) {(int64_t) 1}, mem_21377.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_18095})) != 0)
        goto cleanup;
    tmp_offs_22067 += m_18095;
    if (memblock_unref_device(ctx, &mem_21377, "mem_21377") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_21383, bytes_21382, "mem_21383")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, mem_21383, conc_tmp_17002, curDepth_14237) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_set_device(ctx, &mem_out_21592, &mem_21381, "mem_21381") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_21593, &mem_21383, "mem_21383") != 0)
        return 1;
    prim_out_21594 = conc_tmp_17002;
    prim_out_21595 = conc_tmp_17002;
    prim_out_21596 = curDepth_14237;
    prim_out_21597 = tmp_14377;
    prim_out_21598 = i64_res_19300;
    if (memblock_set_device(ctx, &*mem_out_p_22289, &mem_out_21592, "mem_out_21592") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_22290, &mem_out_21593, "mem_out_21593") != 0)
        return 1;
    *out_prim_out_22291 = prim_out_21594;
    *out_prim_out_22292 = prim_out_21595;
    *out_prim_out_22293 = prim_out_21596;
    *out_prim_out_22294 = prim_out_21597;
    *out_prim_out_22295 = prim_out_21598;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_21383, "mem_21383") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21381, "mem_21381") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21377, "mem_21377") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_21925, "incprefixes_mem_21925") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_21923, "aggregates_mem_21923") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_21921, "status_flags_mem_21921") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21344, "mem_21344") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21341, "mem_21341") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21305, "mem_21305") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_21864, "segred_tmp_mem_21864") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21302, "mem_21302") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21300, "mem_21300") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21290, "mem_21290") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21279, "mem_21279") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21277, "mem_21277") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21274, "mem_21274") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21271, "mem_21271") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21268, "mem_21268") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21267, "mem_21267") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21310, "mem_21310") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_21311, "ext_mem_21311") != 0)
            return 1;
        if (memblock_unref_device(ctx, &color_21559, "color_21559") != 0)
            return 1;
        if (memblock_unref_device(ctx, &color_21558, "color_21558") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21338, "mem_21338") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_21321, "mem_21321") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_21339, "ext_mem_21339") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_21374, "ext_mem_21374") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_21375, "ext_mem_21375") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_21593, "mem_out_21593") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_21592, "mem_out_21592") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_set_bit_2464(struct futhark_context *ctx, int8_t *out_prim_out_22297, int32_t bit_12481, int8_t x_12482, int32_t b_12483)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_21821 = ctx->constants->counters_mem_21821;
    struct memblock_device counters_mem_21866 = ctx->constants->counters_mem_21866;
    struct memblock_device global_dynid_mem_21636 = ctx->constants->global_dynid_mem_21636;
    struct memblock_device global_dynid_mem_21711 = ctx->constants->global_dynid_mem_21711;
    struct memblock_device global_dynid_mem_21924 = ctx->constants->global_dynid_mem_21924;
    struct memblock_device global_dynid_mem_21927 = ctx->constants->global_dynid_mem_21927;
    struct memblock_device global_dynid_mem_22062 = ctx->constants->global_dynid_mem_22062;
    int8_t prim_out_21592;
    int32_t i32_arg0_12484 = shl32(1, bit_12481);
    int32_t i32_arg_12486 = ~i32_arg0_12484;
    int8_t unsign_arg0_17007 = zext_i32_i8(i32_arg_12486);
    int8_t unsign_arg0_19298 = x_12482 & unsign_arg0_17007;
    int32_t i32_arg0_12491 = shl32(b_12483, bit_12481);
    int8_t unsign_arg0_17009 = zext_i32_i8(i32_arg0_12491);
    int8_t unsign_arg0_17012 = unsign_arg0_17009 | unsign_arg0_19298;
    
    prim_out_21592 = unsign_arg0_17012;
    *out_prim_out_22297 = prim_out_21592;
    
  cleanup:
    { }
    return err;
}

int futhark_entry_main(struct futhark_context *ctx, struct futhark_u8_2d **out0, struct futhark_i64_1d **out1, struct futhark_bool_1d **out2, const int32_t in0)
{
    int32_t max_depth_16892 = 0;
    int64_t prim_out_21595 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_21594;
    
    mem_out_21594.references = NULL;
    
    struct memblock_device mem_out_21593;
    
    mem_out_21593.references = NULL;
    
    struct memblock_device mem_out_21592;
    
    mem_out_21592.references = NULL;
    max_depth_16892 = in0;
    if (ret == 0) {
        ret = futrts_entry_main(ctx, &mem_out_21592, &mem_out_21593, &mem_out_21594, &prim_out_21595, max_depth_16892);
        if (ret == 0) {
            struct memblock_device counters_mem_21821 = ctx->constants->counters_mem_21821;
            struct memblock_device counters_mem_21866 = ctx->constants->counters_mem_21866;
            struct memblock_device global_dynid_mem_21636 = ctx->constants->global_dynid_mem_21636;
            struct memblock_device global_dynid_mem_21711 = ctx->constants->global_dynid_mem_21711;
            struct memblock_device global_dynid_mem_21924 = ctx->constants->global_dynid_mem_21924;
            struct memblock_device global_dynid_mem_21927 = ctx->constants->global_dynid_mem_21927;
            struct memblock_device global_dynid_mem_22062 = ctx->constants->global_dynid_mem_22062;
            
            assert((*out0 = (struct futhark_u8_2d *) malloc(sizeof(struct futhark_u8_2d))) != NULL);
            (*out0)->mem = mem_out_21592;
            (*out0)->shape[0] = (int64_t) 8;
            (*out0)->shape[1] = (int64_t) 2;
            assert((*out1 = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d))) != NULL);
            (*out1)->mem = mem_out_21593;
            (*out1)->shape[0] = prim_out_21595;
            assert((*out2 = (struct futhark_bool_1d *) malloc(sizeof(struct futhark_bool_1d))) != NULL);
            (*out2)->mem = mem_out_21594;
            (*out2)->shape[0] = prim_out_21595;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
  
