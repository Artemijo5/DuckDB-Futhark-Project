// Generated by Futhark 0.26.0 (prerelease - include info below when reporting bugs).
// git: 1de4f0c (Fri Jan 24 11:10:52 2025 +0100)
// Compiled with GHC 9.4.8.

// We need to define _GNU_SOURCE before
// _any_ headers files are imported to get
// the usage statistics of a thread (i.e. have RUSAGE_THREAD) on GNU/Linux
// https://manpages.courier-mta.org/htmlman2/getrusage.2.html
#ifndef _GNU_SOURCE // Avoid possible double-definition warning.
#define _GNU_SOURCE
#endif

#ifdef __clang__
#pragma clang diagnostic ignored "-Wunused-function"
#pragma clang diagnostic ignored "-Wunused-variable"
#pragma clang diagnostic ignored "-Wunused-const-variable"
#pragma clang diagnostic ignored "-Wparentheses"
#pragma clang diagnostic ignored "-Wunused-label"
#pragma clang diagnostic ignored "-Wunused-but-set-variable"
#elif __GNUC__
#pragma GCC diagnostic ignored "-Wunused-function"
#pragma GCC diagnostic ignored "-Wunused-variable"
#pragma GCC diagnostic ignored "-Wunused-const-variable"
#pragma GCC diagnostic ignored "-Wparentheses"
#pragma GCC diagnostic ignored "-Wunused-label"
#pragma GCC diagnostic ignored "-Wunused-but-set-variable"
#endif

// Headers
#include <stdint.h>
#include <stddef.h>
#include <stdbool.h>
#include <stdio.h>
#include <float.h>

#include <cuda.h>
#include <cuda_runtime.h>
#include <nvrtc.h>

#ifdef __cplusplus
extern "C" {
#endif

// Initialisation
struct futhark_context_config;
struct futhark_context_config *futhark_context_config_new(void);
void futhark_context_config_free(struct futhark_context_config *cfg);
int futhark_context_config_set_tuning_param(struct futhark_context_config *cfg, const char *param_name, size_t new_value);
struct futhark_context;
struct futhark_context *futhark_context_new(struct futhark_context_config *cfg);
void futhark_context_free(struct futhark_context *cfg);
void futhark_context_config_set_default_thread_block_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_grid_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_group_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_num_groups(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_tile_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_reg_tile_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_registers(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_cache(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_threshold(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_unified_memory(struct futhark_context_config *cfg, int flag);
void futhark_context_config_add_nvrtc_option(struct futhark_context_config *cfg, const char *opt);
void futhark_context_config_set_device(struct futhark_context_config *cfg, const char *s);
const char *futhark_context_config_get_program(struct futhark_context_config *cfg);
void futhark_context_config_set_program(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_dump_ptx_to(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_load_ptx_from(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_set_debugging(struct futhark_context_config *cfg, int flag);
void futhark_context_config_set_profiling(struct futhark_context_config *cfg, int flag);
void futhark_context_config_set_logging(struct futhark_context_config *cfg, int flag);
int futhark_get_tuning_param_count(void);
const char *futhark_get_tuning_param_name(int);
const char *futhark_get_tuning_param_class(int);

// Arrays
struct futhark_i32_1d;
struct futhark_i32_1d *futhark_new_i32_1d(struct futhark_context *ctx, const int32_t *data, int64_t dim0);
struct futhark_i32_1d *futhark_new_raw_i32_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0);
int futhark_free_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr);
int futhark_values_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr, int32_t *data);
int futhark_index_i32_1d(struct futhark_context *ctx, int32_t *out, struct futhark_i32_1d *arr, int64_t i0);
CUdeviceptr futhark_values_raw_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr);
const int64_t *futhark_shape_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr);
struct futhark_i64_1d;
struct futhark_i64_1d *futhark_new_i64_1d(struct futhark_context *ctx, const int64_t *data, int64_t dim0);
struct futhark_i64_1d *futhark_new_raw_i64_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0);
int futhark_free_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr);
int futhark_values_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr, int64_t *data);
int futhark_index_i64_1d(struct futhark_context *ctx, int64_t *out, struct futhark_i64_1d *arr, int64_t i0);
CUdeviceptr futhark_values_raw_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr);
const int64_t *futhark_shape_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr);

// Opaque values
struct futhark_opaque_joinPairs_int;
int futhark_free_opaque_joinPairs_int(struct futhark_context *ctx, struct futhark_opaque_joinPairs_int *obj);
int futhark_store_opaque_joinPairs_int(struct futhark_context *ctx, const struct futhark_opaque_joinPairs_int *obj, void **p, size_t *n);
struct futhark_opaque_joinPairs_int *futhark_restore_opaque_joinPairs_int(struct futhark_context *ctx, const void *p);
int futhark_project_opaque_joinPairs_int_ix(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_int *obj);
int futhark_project_opaque_joinPairs_int_iy(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_int *obj);
int futhark_project_opaque_joinPairs_int_vs(struct futhark_context *ctx, struct futhark_i32_1d **out, const struct futhark_opaque_joinPairs_int *obj);
int futhark_new_opaque_joinPairs_int(struct futhark_context *ctx, struct futhark_opaque_joinPairs_int **out, const struct futhark_i64_1d *f_ix, const struct futhark_i64_1d *f_iy, const struct futhark_i32_1d *f_vs);

// Entry points
int futhark_entry_inner_SMJ_int(struct futhark_context *ctx, struct futhark_opaque_joinPairs_int **out0, const struct futhark_i32_1d *in0, const struct futhark_i32_1d *in1, const int64_t in2, const int64_t in3, const int64_t in4, const int64_t in5, const int64_t in6, const int64_t in7);

// Miscellaneous
int futhark_context_sync(struct futhark_context *ctx);
void futhark_context_config_set_cache_file(struct futhark_context_config *cfg, const char *f);
char *futhark_context_get_error(struct futhark_context *ctx);
void futhark_context_set_logging_file(struct futhark_context *ctx, FILE *f);
void futhark_context_pause_profiling(struct futhark_context *ctx);
void futhark_context_unpause_profiling(struct futhark_context *ctx);
char *futhark_context_report(struct futhark_context *ctx);
int futhark_context_clear_caches(struct futhark_context *ctx);
#define FUTHARK_BACKEND_cuda
#define FUTHARK_SUCCESS 0
#define FUTHARK_PROGRAM_ERROR 2
#define FUTHARK_OUT_OF_MEMORY 3

#ifdef __cplusplus
}
#endif

#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <math.h>
#include <stdint.h>
// If NDEBUG is set, the assert() macro will do nothing. Since Futhark
// (unfortunately) makes use of assert() for error detection (and even some
// side effects), we want to avoid that.
#undef NDEBUG
#include <assert.h>
#include <stdarg.h>
#define SCALAR_FUN_ATTR static inline
// Start of util.h.
//
// Various helper functions that are useful in all generated C code.

#include <errno.h>
#include <string.h>

static const char *fut_progname = "(embedded Futhark)";

static void futhark_panic(int eval, const char *fmt, ...) __attribute__((noreturn));
static char* msgprintf(const char *s, ...);
static void* slurp_file(const char *filename, size_t *size);
static int dump_file(const char *file, const void *buf, size_t n);
struct str_builder;
static void str_builder_init(struct str_builder *b);
static void str_builder(struct str_builder *b, const char *s, ...);
static char *strclone(const char *str);

static void futhark_panic(int eval, const char *fmt, ...) {
  va_list ap;
  va_start(ap, fmt);
  fprintf(stderr, "%s: ", fut_progname);
  vfprintf(stderr, fmt, ap);
  va_end(ap);
  exit(eval);
}

// For generating arbitrary-sized error messages.  It is the callers
// responsibility to free the buffer at some point.
static char* msgprintf(const char *s, ...) {
  va_list vl;
  va_start(vl, s);
  size_t needed = 1 + (size_t)vsnprintf(NULL, 0, s, vl);
  char *buffer = (char*) malloc(needed);
  va_start(vl, s); // Must re-init.
  vsnprintf(buffer, needed, s, vl);
  return buffer;
}

static inline void check_err(int errval, int sets_errno, const char *fun, int line,
                             const char *msg, ...) {
  if (errval) {
    char errnum[10];

    va_list vl;
    va_start(vl, msg);

    fprintf(stderr, "ERROR: ");
    vfprintf(stderr, msg, vl);
    fprintf(stderr, " in %s() at line %d with error code %s\n",
            fun, line,
            sets_errno ? strerror(errno) : errnum);
    exit(errval);
  }
}

#define CHECK_ERR(err, ...) check_err(err, 0, __func__, __LINE__, __VA_ARGS__)
#define CHECK_ERRNO(err, ...) check_err(err, 1, __func__, __LINE__, __VA_ARGS__)

// Read the rest of an open file into a NUL-terminated string; returns
// NULL on error.
static void* fslurp_file(FILE *f, size_t *size) {
  long start = ftell(f);
  fseek(f, 0, SEEK_END);
  long src_size = ftell(f)-start;
  fseek(f, start, SEEK_SET);
  unsigned char *s = (unsigned char*) malloc((size_t)src_size + 1);
  if (fread(s, 1, (size_t)src_size, f) != (size_t)src_size) {
    free(s);
    s = NULL;
  } else {
    s[src_size] = '\0';
  }

  if (size) {
    *size = (size_t)src_size;
  }

  return s;
}

// Read a file into a NUL-terminated string; returns NULL on error.
static void* slurp_file(const char *filename, size_t *size) {
  FILE *f = fopen(filename, "rb"); // To avoid Windows messing with linebreaks.
  if (f == NULL) return NULL;
  unsigned char *s = fslurp_file(f, size);
  fclose(f);
  return s;
}

// Dump 'n' bytes from 'buf' into the file at the designated location.
// Returns 0 on success.
static int dump_file(const char *file, const void *buf, size_t n) {
  FILE *f = fopen(file, "w");

  if (f == NULL) {
    return 1;
  }

  if (fwrite(buf, sizeof(char), n, f) != n) {
    return 1;
  }

  if (fclose(f) != 0) {
    return 1;
  }

  return 0;
}

struct str_builder {
  char *str;
  size_t capacity; // Size of buffer.
  size_t used; // Bytes used, *not* including final zero.
};

static void str_builder_init(struct str_builder *b) {
  b->capacity = 10;
  b->used = 0;
  b->str = malloc(b->capacity);
  b->str[0] = 0;
}

static void str_builder(struct str_builder *b, const char *s, ...) {
  va_list vl;
  va_start(vl, s);
  size_t needed = (size_t)vsnprintf(NULL, 0, s, vl);

  while (b->capacity < b->used + needed + 1) {
    b->capacity *= 2;
    b->str = realloc(b->str, b->capacity);
  }

  va_start(vl, s); // Must re-init.
  vsnprintf(b->str+b->used, b->capacity-b->used, s, vl);
  b->used += needed;
}

static void str_builder_str(struct str_builder *b, const char *s) {
  size_t needed = strlen(s);
  if (b->capacity < b->used + needed + 1) {
    b->capacity *= 2;
    b->str = realloc(b->str, b->capacity);
  }
  strcpy(b->str+b->used, s);
  b->used += needed;
}

static void str_builder_char(struct str_builder *b, char c) {
  size_t needed = 1;
  if (b->capacity < b->used + needed + 1) {
    b->capacity *= 2;
    b->str = realloc(b->str, b->capacity);
  }
  b->str[b->used] = c;
  b->str[b->used+1] = 0;
  b->used += needed;
}

static void str_builder_json_str(struct str_builder* sb, const char* s) {
  str_builder_char(sb, '"');
  for (int j = 0; s[j]; j++) {
    char c = s[j];
    switch (c) {
    case '\n':
      str_builder_str(sb, "\\n");
      break;
    case '"':
      str_builder_str(sb, "\\\"");
      break;
    default:
      str_builder_char(sb, c);
    }
  }
  str_builder_char(sb, '"');
}

static char *strclone(const char *str) {
  size_t size = strlen(str) + 1;
  char *copy = (char*) malloc(size);
  if (copy == NULL) {
    return NULL;
  }

  memcpy(copy, str, size);
  return copy;
}

// Assumes NULL-terminated.
static char *strconcat(const char *src_fragments[]) {
  size_t src_len = 0;
  const char **p;

  for (p = src_fragments; *p; p++) {
    src_len += strlen(*p);
  }

  char *src = (char*) malloc(src_len + 1);
  size_t n = 0;
  for (p = src_fragments; *p; p++) {
    strcpy(src + n, *p);
    n += strlen(*p);
  }

  return src;
}

// End of util.h.
// Start of cache.h

#define CACHE_HASH_SIZE 8 // In 32-bit words.

struct cache_hash {
  uint32_t hash[CACHE_HASH_SIZE];
};

// Initialise a blank cache.
static void cache_hash_init(struct cache_hash *c);

// Hash some bytes and add them to the accumulated hash.
static void cache_hash(struct cache_hash *out, const char *in, size_t n);

// Try to restore cache contents from a file with the given name.
// Assumes the cache is invalid if it contains the given hash.
// Allocates memory and reads the cache conents, which is returned in
// *buf with size *buflen.  If the cache is successfully loaded, this
// function returns 0.  Otherwise it returns nonzero.  Errno is set if
// the failure to load the cache is due to anything except invalid
// cache conents.  Note that failing to restore the cache is not
// necessarily a problem: it might just be invalid or not created yet.
static int cache_restore(const char *fname, const struct cache_hash *hash,
                         unsigned char **buf, size_t *buflen);

// Store cache contents in the given file, with the given hash.
static int cache_store(const char *fname, const struct cache_hash *hash,
                       const unsigned char *buf, size_t buflen);

// Now for the implementation.

static void cache_hash_init(struct cache_hash *c) {
  memset(c->hash, 0, CACHE_HASH_SIZE * sizeof(uint32_t));
}

static void cache_hash(struct cache_hash *out, const char *in, size_t n) {
  // Adaptation of djb2 for larger output size by storing intermediate
  // states.
  uint32_t hash = 5381;
  for (size_t i = 0; i < n; i++) {
    hash = ((hash << 5) + hash) + in[i];
    out->hash[i % CACHE_HASH_SIZE] ^= hash;
  }
}

#define CACHE_HEADER_SIZE 8
static const char cache_header[CACHE_HEADER_SIZE] = "FUTHARK\0";

static int cache_restore(const char *fname, const struct cache_hash *hash,
                         unsigned char **buf, size_t *buflen) {
  FILE *f = fopen(fname, "rb");

  if (f == NULL) {
    return 1;
  }

  char f_header[CACHE_HEADER_SIZE];

  if (fread(f_header, sizeof(char), CACHE_HEADER_SIZE, f) != CACHE_HEADER_SIZE) {
    goto error;
  }

  if (memcmp(f_header, cache_header, CACHE_HEADER_SIZE) != 0) {
    goto error;
  }

  if (fseek(f, 0, SEEK_END) != 0) {
    goto error;
  }
  int64_t f_size = (int64_t)ftell(f);
  if (fseek(f, CACHE_HEADER_SIZE, SEEK_SET) != 0) {
    goto error;
  }

  int64_t expected_size;

  if (fread(&expected_size, sizeof(int64_t), 1, f) != 1) {
    goto error;
  }

  if (f_size != expected_size) {
    errno = 0;
    goto error;
  }

  int32_t f_hash[CACHE_HASH_SIZE];

  if (fread(f_hash, sizeof(int32_t), CACHE_HASH_SIZE, f) != CACHE_HASH_SIZE) {
    goto error;
  }

  if (memcmp(f_hash, hash->hash, CACHE_HASH_SIZE) != 0) {
    errno = 0;
    goto error;
  }

  *buflen = f_size - CACHE_HEADER_SIZE - sizeof(int64_t) - CACHE_HASH_SIZE*sizeof(int32_t);
  *buf = malloc(*buflen);
  if (fread(*buf, sizeof(char), *buflen, f) != *buflen) {
    free(*buf);
    goto error;
  }

  fclose(f);

  return 0;

 error:
  fclose(f);
  return 1;
}

static int cache_store(const char *fname, const struct cache_hash *hash,
                       const unsigned char *buf, size_t buflen) {
  FILE *f = fopen(fname, "wb");

  if (f == NULL) {
    return 1;
  }

  if (fwrite(cache_header, CACHE_HEADER_SIZE, 1, f) != 1) {
    goto error;
  }

  int64_t size = CACHE_HEADER_SIZE + sizeof(int64_t) + CACHE_HASH_SIZE*sizeof(int32_t) + buflen;

  if (fwrite(&size, sizeof(size), 1, f) != 1) {
    goto error;
  }

  if (fwrite(hash->hash, sizeof(int32_t), CACHE_HASH_SIZE, f) != CACHE_HASH_SIZE) {
    goto error;
  }

  if (fwrite(buf, sizeof(unsigned char), buflen, f) != buflen) {
    goto error;
  }

  fclose(f);

  return 0;

 error:
  fclose(f);
  return 1;
}

// End of cache.h
// Start of half.h.

// Conversion functions are from http://half.sourceforge.net/, but
// translated to C.
//
// Copyright (c) 2012-2021 Christian Rau
//
// Permission is hereby granted, free of charge, to any person obtaining a copy
// of this software and associated documentation files (the "Software"), to deal
// in the Software without restriction, including without limitation the rights
// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
// copies of the Software, and to permit persons to whom the Software is
// furnished to do so, subject to the following conditions:
//
// The above copyright notice and this permission notice shall be included in
// all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
// THE SOFTWARE.

#ifndef __OPENCL_VERSION__
#define __constant
#endif

__constant static const uint16_t base_table[512] = {
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0001, 0x0002, 0x0004, 0x0008, 0x0010, 0x0020, 0x0040, 0x0080, 0x0100,
  0x0200, 0x0400, 0x0800, 0x0C00, 0x1000, 0x1400, 0x1800, 0x1C00, 0x2000, 0x2400, 0x2800, 0x2C00, 0x3000, 0x3400, 0x3800, 0x3C00,
  0x4000, 0x4400, 0x4800, 0x4C00, 0x5000, 0x5400, 0x5800, 0x5C00, 0x6000, 0x6400, 0x6800, 0x6C00, 0x7000, 0x7400, 0x7800, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8001, 0x8002, 0x8004, 0x8008, 0x8010, 0x8020, 0x8040, 0x8080, 0x8100,
  0x8200, 0x8400, 0x8800, 0x8C00, 0x9000, 0x9400, 0x9800, 0x9C00, 0xA000, 0xA400, 0xA800, 0xAC00, 0xB000, 0xB400, 0xB800, 0xBC00,
  0xC000, 0xC400, 0xC800, 0xCC00, 0xD000, 0xD400, 0xD800, 0xDC00, 0xE000, 0xE400, 0xE800, 0xEC00, 0xF000, 0xF400, 0xF800, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00 };

__constant static const unsigned char shift_table[512] = {
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13 };

__constant static const uint32_t mantissa_table[2048] = {
  0x00000000, 0x33800000, 0x34000000, 0x34400000, 0x34800000, 0x34A00000, 0x34C00000, 0x34E00000, 0x35000000, 0x35100000, 0x35200000, 0x35300000, 0x35400000, 0x35500000, 0x35600000, 0x35700000,
  0x35800000, 0x35880000, 0x35900000, 0x35980000, 0x35A00000, 0x35A80000, 0x35B00000, 0x35B80000, 0x35C00000, 0x35C80000, 0x35D00000, 0x35D80000, 0x35E00000, 0x35E80000, 0x35F00000, 0x35F80000,
  0x36000000, 0x36040000, 0x36080000, 0x360C0000, 0x36100000, 0x36140000, 0x36180000, 0x361C0000, 0x36200000, 0x36240000, 0x36280000, 0x362C0000, 0x36300000, 0x36340000, 0x36380000, 0x363C0000,
  0x36400000, 0x36440000, 0x36480000, 0x364C0000, 0x36500000, 0x36540000, 0x36580000, 0x365C0000, 0x36600000, 0x36640000, 0x36680000, 0x366C0000, 0x36700000, 0x36740000, 0x36780000, 0x367C0000,
  0x36800000, 0x36820000, 0x36840000, 0x36860000, 0x36880000, 0x368A0000, 0x368C0000, 0x368E0000, 0x36900000, 0x36920000, 0x36940000, 0x36960000, 0x36980000, 0x369A0000, 0x369C0000, 0x369E0000,
  0x36A00000, 0x36A20000, 0x36A40000, 0x36A60000, 0x36A80000, 0x36AA0000, 0x36AC0000, 0x36AE0000, 0x36B00000, 0x36B20000, 0x36B40000, 0x36B60000, 0x36B80000, 0x36BA0000, 0x36BC0000, 0x36BE0000,
  0x36C00000, 0x36C20000, 0x36C40000, 0x36C60000, 0x36C80000, 0x36CA0000, 0x36CC0000, 0x36CE0000, 0x36D00000, 0x36D20000, 0x36D40000, 0x36D60000, 0x36D80000, 0x36DA0000, 0x36DC0000, 0x36DE0000,
  0x36E00000, 0x36E20000, 0x36E40000, 0x36E60000, 0x36E80000, 0x36EA0000, 0x36EC0000, 0x36EE0000, 0x36F00000, 0x36F20000, 0x36F40000, 0x36F60000, 0x36F80000, 0x36FA0000, 0x36FC0000, 0x36FE0000,
  0x37000000, 0x37010000, 0x37020000, 0x37030000, 0x37040000, 0x37050000, 0x37060000, 0x37070000, 0x37080000, 0x37090000, 0x370A0000, 0x370B0000, 0x370C0000, 0x370D0000, 0x370E0000, 0x370F0000,
  0x37100000, 0x37110000, 0x37120000, 0x37130000, 0x37140000, 0x37150000, 0x37160000, 0x37170000, 0x37180000, 0x37190000, 0x371A0000, 0x371B0000, 0x371C0000, 0x371D0000, 0x371E0000, 0x371F0000,
  0x37200000, 0x37210000, 0x37220000, 0x37230000, 0x37240000, 0x37250000, 0x37260000, 0x37270000, 0x37280000, 0x37290000, 0x372A0000, 0x372B0000, 0x372C0000, 0x372D0000, 0x372E0000, 0x372F0000,
  0x37300000, 0x37310000, 0x37320000, 0x37330000, 0x37340000, 0x37350000, 0x37360000, 0x37370000, 0x37380000, 0x37390000, 0x373A0000, 0x373B0000, 0x373C0000, 0x373D0000, 0x373E0000, 0x373F0000,
  0x37400000, 0x37410000, 0x37420000, 0x37430000, 0x37440000, 0x37450000, 0x37460000, 0x37470000, 0x37480000, 0x37490000, 0x374A0000, 0x374B0000, 0x374C0000, 0x374D0000, 0x374E0000, 0x374F0000,
  0x37500000, 0x37510000, 0x37520000, 0x37530000, 0x37540000, 0x37550000, 0x37560000, 0x37570000, 0x37580000, 0x37590000, 0x375A0000, 0x375B0000, 0x375C0000, 0x375D0000, 0x375E0000, 0x375F0000,
  0x37600000, 0x37610000, 0x37620000, 0x37630000, 0x37640000, 0x37650000, 0x37660000, 0x37670000, 0x37680000, 0x37690000, 0x376A0000, 0x376B0000, 0x376C0000, 0x376D0000, 0x376E0000, 0x376F0000,
  0x37700000, 0x37710000, 0x37720000, 0x37730000, 0x37740000, 0x37750000, 0x37760000, 0x37770000, 0x37780000, 0x37790000, 0x377A0000, 0x377B0000, 0x377C0000, 0x377D0000, 0x377E0000, 0x377F0000,
  0x37800000, 0x37808000, 0x37810000, 0x37818000, 0x37820000, 0x37828000, 0x37830000, 0x37838000, 0x37840000, 0x37848000, 0x37850000, 0x37858000, 0x37860000, 0x37868000, 0x37870000, 0x37878000,
  0x37880000, 0x37888000, 0x37890000, 0x37898000, 0x378A0000, 0x378A8000, 0x378B0000, 0x378B8000, 0x378C0000, 0x378C8000, 0x378D0000, 0x378D8000, 0x378E0000, 0x378E8000, 0x378F0000, 0x378F8000,
  0x37900000, 0x37908000, 0x37910000, 0x37918000, 0x37920000, 0x37928000, 0x37930000, 0x37938000, 0x37940000, 0x37948000, 0x37950000, 0x37958000, 0x37960000, 0x37968000, 0x37970000, 0x37978000,
  0x37980000, 0x37988000, 0x37990000, 0x37998000, 0x379A0000, 0x379A8000, 0x379B0000, 0x379B8000, 0x379C0000, 0x379C8000, 0x379D0000, 0x379D8000, 0x379E0000, 0x379E8000, 0x379F0000, 0x379F8000,
  0x37A00000, 0x37A08000, 0x37A10000, 0x37A18000, 0x37A20000, 0x37A28000, 0x37A30000, 0x37A38000, 0x37A40000, 0x37A48000, 0x37A50000, 0x37A58000, 0x37A60000, 0x37A68000, 0x37A70000, 0x37A78000,
  0x37A80000, 0x37A88000, 0x37A90000, 0x37A98000, 0x37AA0000, 0x37AA8000, 0x37AB0000, 0x37AB8000, 0x37AC0000, 0x37AC8000, 0x37AD0000, 0x37AD8000, 0x37AE0000, 0x37AE8000, 0x37AF0000, 0x37AF8000,
  0x37B00000, 0x37B08000, 0x37B10000, 0x37B18000, 0x37B20000, 0x37B28000, 0x37B30000, 0x37B38000, 0x37B40000, 0x37B48000, 0x37B50000, 0x37B58000, 0x37B60000, 0x37B68000, 0x37B70000, 0x37B78000,
  0x37B80000, 0x37B88000, 0x37B90000, 0x37B98000, 0x37BA0000, 0x37BA8000, 0x37BB0000, 0x37BB8000, 0x37BC0000, 0x37BC8000, 0x37BD0000, 0x37BD8000, 0x37BE0000, 0x37BE8000, 0x37BF0000, 0x37BF8000,
  0x37C00000, 0x37C08000, 0x37C10000, 0x37C18000, 0x37C20000, 0x37C28000, 0x37C30000, 0x37C38000, 0x37C40000, 0x37C48000, 0x37C50000, 0x37C58000, 0x37C60000, 0x37C68000, 0x37C70000, 0x37C78000,
  0x37C80000, 0x37C88000, 0x37C90000, 0x37C98000, 0x37CA0000, 0x37CA8000, 0x37CB0000, 0x37CB8000, 0x37CC0000, 0x37CC8000, 0x37CD0000, 0x37CD8000, 0x37CE0000, 0x37CE8000, 0x37CF0000, 0x37CF8000,
  0x37D00000, 0x37D08000, 0x37D10000, 0x37D18000, 0x37D20000, 0x37D28000, 0x37D30000, 0x37D38000, 0x37D40000, 0x37D48000, 0x37D50000, 0x37D58000, 0x37D60000, 0x37D68000, 0x37D70000, 0x37D78000,
  0x37D80000, 0x37D88000, 0x37D90000, 0x37D98000, 0x37DA0000, 0x37DA8000, 0x37DB0000, 0x37DB8000, 0x37DC0000, 0x37DC8000, 0x37DD0000, 0x37DD8000, 0x37DE0000, 0x37DE8000, 0x37DF0000, 0x37DF8000,
  0x37E00000, 0x37E08000, 0x37E10000, 0x37E18000, 0x37E20000, 0x37E28000, 0x37E30000, 0x37E38000, 0x37E40000, 0x37E48000, 0x37E50000, 0x37E58000, 0x37E60000, 0x37E68000, 0x37E70000, 0x37E78000,
  0x37E80000, 0x37E88000, 0x37E90000, 0x37E98000, 0x37EA0000, 0x37EA8000, 0x37EB0000, 0x37EB8000, 0x37EC0000, 0x37EC8000, 0x37ED0000, 0x37ED8000, 0x37EE0000, 0x37EE8000, 0x37EF0000, 0x37EF8000,
  0x37F00000, 0x37F08000, 0x37F10000, 0x37F18000, 0x37F20000, 0x37F28000, 0x37F30000, 0x37F38000, 0x37F40000, 0x37F48000, 0x37F50000, 0x37F58000, 0x37F60000, 0x37F68000, 0x37F70000, 0x37F78000,
  0x37F80000, 0x37F88000, 0x37F90000, 0x37F98000, 0x37FA0000, 0x37FA8000, 0x37FB0000, 0x37FB8000, 0x37FC0000, 0x37FC8000, 0x37FD0000, 0x37FD8000, 0x37FE0000, 0x37FE8000, 0x37FF0000, 0x37FF8000,
  0x38000000, 0x38004000, 0x38008000, 0x3800C000, 0x38010000, 0x38014000, 0x38018000, 0x3801C000, 0x38020000, 0x38024000, 0x38028000, 0x3802C000, 0x38030000, 0x38034000, 0x38038000, 0x3803C000,
  0x38040000, 0x38044000, 0x38048000, 0x3804C000, 0x38050000, 0x38054000, 0x38058000, 0x3805C000, 0x38060000, 0x38064000, 0x38068000, 0x3806C000, 0x38070000, 0x38074000, 0x38078000, 0x3807C000,
  0x38080000, 0x38084000, 0x38088000, 0x3808C000, 0x38090000, 0x38094000, 0x38098000, 0x3809C000, 0x380A0000, 0x380A4000, 0x380A8000, 0x380AC000, 0x380B0000, 0x380B4000, 0x380B8000, 0x380BC000,
  0x380C0000, 0x380C4000, 0x380C8000, 0x380CC000, 0x380D0000, 0x380D4000, 0x380D8000, 0x380DC000, 0x380E0000, 0x380E4000, 0x380E8000, 0x380EC000, 0x380F0000, 0x380F4000, 0x380F8000, 0x380FC000,
  0x38100000, 0x38104000, 0x38108000, 0x3810C000, 0x38110000, 0x38114000, 0x38118000, 0x3811C000, 0x38120000, 0x38124000, 0x38128000, 0x3812C000, 0x38130000, 0x38134000, 0x38138000, 0x3813C000,
  0x38140000, 0x38144000, 0x38148000, 0x3814C000, 0x38150000, 0x38154000, 0x38158000, 0x3815C000, 0x38160000, 0x38164000, 0x38168000, 0x3816C000, 0x38170000, 0x38174000, 0x38178000, 0x3817C000,
  0x38180000, 0x38184000, 0x38188000, 0x3818C000, 0x38190000, 0x38194000, 0x38198000, 0x3819C000, 0x381A0000, 0x381A4000, 0x381A8000, 0x381AC000, 0x381B0000, 0x381B4000, 0x381B8000, 0x381BC000,
  0x381C0000, 0x381C4000, 0x381C8000, 0x381CC000, 0x381D0000, 0x381D4000, 0x381D8000, 0x381DC000, 0x381E0000, 0x381E4000, 0x381E8000, 0x381EC000, 0x381F0000, 0x381F4000, 0x381F8000, 0x381FC000,
  0x38200000, 0x38204000, 0x38208000, 0x3820C000, 0x38210000, 0x38214000, 0x38218000, 0x3821C000, 0x38220000, 0x38224000, 0x38228000, 0x3822C000, 0x38230000, 0x38234000, 0x38238000, 0x3823C000,
  0x38240000, 0x38244000, 0x38248000, 0x3824C000, 0x38250000, 0x38254000, 0x38258000, 0x3825C000, 0x38260000, 0x38264000, 0x38268000, 0x3826C000, 0x38270000, 0x38274000, 0x38278000, 0x3827C000,
  0x38280000, 0x38284000, 0x38288000, 0x3828C000, 0x38290000, 0x38294000, 0x38298000, 0x3829C000, 0x382A0000, 0x382A4000, 0x382A8000, 0x382AC000, 0x382B0000, 0x382B4000, 0x382B8000, 0x382BC000,
  0x382C0000, 0x382C4000, 0x382C8000, 0x382CC000, 0x382D0000, 0x382D4000, 0x382D8000, 0x382DC000, 0x382E0000, 0x382E4000, 0x382E8000, 0x382EC000, 0x382F0000, 0x382F4000, 0x382F8000, 0x382FC000,
  0x38300000, 0x38304000, 0x38308000, 0x3830C000, 0x38310000, 0x38314000, 0x38318000, 0x3831C000, 0x38320000, 0x38324000, 0x38328000, 0x3832C000, 0x38330000, 0x38334000, 0x38338000, 0x3833C000,
  0x38340000, 0x38344000, 0x38348000, 0x3834C000, 0x38350000, 0x38354000, 0x38358000, 0x3835C000, 0x38360000, 0x38364000, 0x38368000, 0x3836C000, 0x38370000, 0x38374000, 0x38378000, 0x3837C000,
  0x38380000, 0x38384000, 0x38388000, 0x3838C000, 0x38390000, 0x38394000, 0x38398000, 0x3839C000, 0x383A0000, 0x383A4000, 0x383A8000, 0x383AC000, 0x383B0000, 0x383B4000, 0x383B8000, 0x383BC000,
  0x383C0000, 0x383C4000, 0x383C8000, 0x383CC000, 0x383D0000, 0x383D4000, 0x383D8000, 0x383DC000, 0x383E0000, 0x383E4000, 0x383E8000, 0x383EC000, 0x383F0000, 0x383F4000, 0x383F8000, 0x383FC000,
  0x38400000, 0x38404000, 0x38408000, 0x3840C000, 0x38410000, 0x38414000, 0x38418000, 0x3841C000, 0x38420000, 0x38424000, 0x38428000, 0x3842C000, 0x38430000, 0x38434000, 0x38438000, 0x3843C000,
  0x38440000, 0x38444000, 0x38448000, 0x3844C000, 0x38450000, 0x38454000, 0x38458000, 0x3845C000, 0x38460000, 0x38464000, 0x38468000, 0x3846C000, 0x38470000, 0x38474000, 0x38478000, 0x3847C000,
  0x38480000, 0x38484000, 0x38488000, 0x3848C000, 0x38490000, 0x38494000, 0x38498000, 0x3849C000, 0x384A0000, 0x384A4000, 0x384A8000, 0x384AC000, 0x384B0000, 0x384B4000, 0x384B8000, 0x384BC000,
  0x384C0000, 0x384C4000, 0x384C8000, 0x384CC000, 0x384D0000, 0x384D4000, 0x384D8000, 0x384DC000, 0x384E0000, 0x384E4000, 0x384E8000, 0x384EC000, 0x384F0000, 0x384F4000, 0x384F8000, 0x384FC000,
  0x38500000, 0x38504000, 0x38508000, 0x3850C000, 0x38510000, 0x38514000, 0x38518000, 0x3851C000, 0x38520000, 0x38524000, 0x38528000, 0x3852C000, 0x38530000, 0x38534000, 0x38538000, 0x3853C000,
  0x38540000, 0x38544000, 0x38548000, 0x3854C000, 0x38550000, 0x38554000, 0x38558000, 0x3855C000, 0x38560000, 0x38564000, 0x38568000, 0x3856C000, 0x38570000, 0x38574000, 0x38578000, 0x3857C000,
  0x38580000, 0x38584000, 0x38588000, 0x3858C000, 0x38590000, 0x38594000, 0x38598000, 0x3859C000, 0x385A0000, 0x385A4000, 0x385A8000, 0x385AC000, 0x385B0000, 0x385B4000, 0x385B8000, 0x385BC000,
  0x385C0000, 0x385C4000, 0x385C8000, 0x385CC000, 0x385D0000, 0x385D4000, 0x385D8000, 0x385DC000, 0x385E0000, 0x385E4000, 0x385E8000, 0x385EC000, 0x385F0000, 0x385F4000, 0x385F8000, 0x385FC000,
  0x38600000, 0x38604000, 0x38608000, 0x3860C000, 0x38610000, 0x38614000, 0x38618000, 0x3861C000, 0x38620000, 0x38624000, 0x38628000, 0x3862C000, 0x38630000, 0x38634000, 0x38638000, 0x3863C000,
  0x38640000, 0x38644000, 0x38648000, 0x3864C000, 0x38650000, 0x38654000, 0x38658000, 0x3865C000, 0x38660000, 0x38664000, 0x38668000, 0x3866C000, 0x38670000, 0x38674000, 0x38678000, 0x3867C000,
  0x38680000, 0x38684000, 0x38688000, 0x3868C000, 0x38690000, 0x38694000, 0x38698000, 0x3869C000, 0x386A0000, 0x386A4000, 0x386A8000, 0x386AC000, 0x386B0000, 0x386B4000, 0x386B8000, 0x386BC000,
  0x386C0000, 0x386C4000, 0x386C8000, 0x386CC000, 0x386D0000, 0x386D4000, 0x386D8000, 0x386DC000, 0x386E0000, 0x386E4000, 0x386E8000, 0x386EC000, 0x386F0000, 0x386F4000, 0x386F8000, 0x386FC000,
  0x38700000, 0x38704000, 0x38708000, 0x3870C000, 0x38710000, 0x38714000, 0x38718000, 0x3871C000, 0x38720000, 0x38724000, 0x38728000, 0x3872C000, 0x38730000, 0x38734000, 0x38738000, 0x3873C000,
  0x38740000, 0x38744000, 0x38748000, 0x3874C000, 0x38750000, 0x38754000, 0x38758000, 0x3875C000, 0x38760000, 0x38764000, 0x38768000, 0x3876C000, 0x38770000, 0x38774000, 0x38778000, 0x3877C000,
  0x38780000, 0x38784000, 0x38788000, 0x3878C000, 0x38790000, 0x38794000, 0x38798000, 0x3879C000, 0x387A0000, 0x387A4000, 0x387A8000, 0x387AC000, 0x387B0000, 0x387B4000, 0x387B8000, 0x387BC000,
  0x387C0000, 0x387C4000, 0x387C8000, 0x387CC000, 0x387D0000, 0x387D4000, 0x387D8000, 0x387DC000, 0x387E0000, 0x387E4000, 0x387E8000, 0x387EC000, 0x387F0000, 0x387F4000, 0x387F8000, 0x387FC000,
  0x38000000, 0x38002000, 0x38004000, 0x38006000, 0x38008000, 0x3800A000, 0x3800C000, 0x3800E000, 0x38010000, 0x38012000, 0x38014000, 0x38016000, 0x38018000, 0x3801A000, 0x3801C000, 0x3801E000,
  0x38020000, 0x38022000, 0x38024000, 0x38026000, 0x38028000, 0x3802A000, 0x3802C000, 0x3802E000, 0x38030000, 0x38032000, 0x38034000, 0x38036000, 0x38038000, 0x3803A000, 0x3803C000, 0x3803E000,
  0x38040000, 0x38042000, 0x38044000, 0x38046000, 0x38048000, 0x3804A000, 0x3804C000, 0x3804E000, 0x38050000, 0x38052000, 0x38054000, 0x38056000, 0x38058000, 0x3805A000, 0x3805C000, 0x3805E000,
  0x38060000, 0x38062000, 0x38064000, 0x38066000, 0x38068000, 0x3806A000, 0x3806C000, 0x3806E000, 0x38070000, 0x38072000, 0x38074000, 0x38076000, 0x38078000, 0x3807A000, 0x3807C000, 0x3807E000,
  0x38080000, 0x38082000, 0x38084000, 0x38086000, 0x38088000, 0x3808A000, 0x3808C000, 0x3808E000, 0x38090000, 0x38092000, 0x38094000, 0x38096000, 0x38098000, 0x3809A000, 0x3809C000, 0x3809E000,
  0x380A0000, 0x380A2000, 0x380A4000, 0x380A6000, 0x380A8000, 0x380AA000, 0x380AC000, 0x380AE000, 0x380B0000, 0x380B2000, 0x380B4000, 0x380B6000, 0x380B8000, 0x380BA000, 0x380BC000, 0x380BE000,
  0x380C0000, 0x380C2000, 0x380C4000, 0x380C6000, 0x380C8000, 0x380CA000, 0x380CC000, 0x380CE000, 0x380D0000, 0x380D2000, 0x380D4000, 0x380D6000, 0x380D8000, 0x380DA000, 0x380DC000, 0x380DE000,
  0x380E0000, 0x380E2000, 0x380E4000, 0x380E6000, 0x380E8000, 0x380EA000, 0x380EC000, 0x380EE000, 0x380F0000, 0x380F2000, 0x380F4000, 0x380F6000, 0x380F8000, 0x380FA000, 0x380FC000, 0x380FE000,
  0x38100000, 0x38102000, 0x38104000, 0x38106000, 0x38108000, 0x3810A000, 0x3810C000, 0x3810E000, 0x38110000, 0x38112000, 0x38114000, 0x38116000, 0x38118000, 0x3811A000, 0x3811C000, 0x3811E000,
  0x38120000, 0x38122000, 0x38124000, 0x38126000, 0x38128000, 0x3812A000, 0x3812C000, 0x3812E000, 0x38130000, 0x38132000, 0x38134000, 0x38136000, 0x38138000, 0x3813A000, 0x3813C000, 0x3813E000,
  0x38140000, 0x38142000, 0x38144000, 0x38146000, 0x38148000, 0x3814A000, 0x3814C000, 0x3814E000, 0x38150000, 0x38152000, 0x38154000, 0x38156000, 0x38158000, 0x3815A000, 0x3815C000, 0x3815E000,
  0x38160000, 0x38162000, 0x38164000, 0x38166000, 0x38168000, 0x3816A000, 0x3816C000, 0x3816E000, 0x38170000, 0x38172000, 0x38174000, 0x38176000, 0x38178000, 0x3817A000, 0x3817C000, 0x3817E000,
  0x38180000, 0x38182000, 0x38184000, 0x38186000, 0x38188000, 0x3818A000, 0x3818C000, 0x3818E000, 0x38190000, 0x38192000, 0x38194000, 0x38196000, 0x38198000, 0x3819A000, 0x3819C000, 0x3819E000,
  0x381A0000, 0x381A2000, 0x381A4000, 0x381A6000, 0x381A8000, 0x381AA000, 0x381AC000, 0x381AE000, 0x381B0000, 0x381B2000, 0x381B4000, 0x381B6000, 0x381B8000, 0x381BA000, 0x381BC000, 0x381BE000,
  0x381C0000, 0x381C2000, 0x381C4000, 0x381C6000, 0x381C8000, 0x381CA000, 0x381CC000, 0x381CE000, 0x381D0000, 0x381D2000, 0x381D4000, 0x381D6000, 0x381D8000, 0x381DA000, 0x381DC000, 0x381DE000,
  0x381E0000, 0x381E2000, 0x381E4000, 0x381E6000, 0x381E8000, 0x381EA000, 0x381EC000, 0x381EE000, 0x381F0000, 0x381F2000, 0x381F4000, 0x381F6000, 0x381F8000, 0x381FA000, 0x381FC000, 0x381FE000,
  0x38200000, 0x38202000, 0x38204000, 0x38206000, 0x38208000, 0x3820A000, 0x3820C000, 0x3820E000, 0x38210000, 0x38212000, 0x38214000, 0x38216000, 0x38218000, 0x3821A000, 0x3821C000, 0x3821E000,
  0x38220000, 0x38222000, 0x38224000, 0x38226000, 0x38228000, 0x3822A000, 0x3822C000, 0x3822E000, 0x38230000, 0x38232000, 0x38234000, 0x38236000, 0x38238000, 0x3823A000, 0x3823C000, 0x3823E000,
  0x38240000, 0x38242000, 0x38244000, 0x38246000, 0x38248000, 0x3824A000, 0x3824C000, 0x3824E000, 0x38250000, 0x38252000, 0x38254000, 0x38256000, 0x38258000, 0x3825A000, 0x3825C000, 0x3825E000,
  0x38260000, 0x38262000, 0x38264000, 0x38266000, 0x38268000, 0x3826A000, 0x3826C000, 0x3826E000, 0x38270000, 0x38272000, 0x38274000, 0x38276000, 0x38278000, 0x3827A000, 0x3827C000, 0x3827E000,
  0x38280000, 0x38282000, 0x38284000, 0x38286000, 0x38288000, 0x3828A000, 0x3828C000, 0x3828E000, 0x38290000, 0x38292000, 0x38294000, 0x38296000, 0x38298000, 0x3829A000, 0x3829C000, 0x3829E000,
  0x382A0000, 0x382A2000, 0x382A4000, 0x382A6000, 0x382A8000, 0x382AA000, 0x382AC000, 0x382AE000, 0x382B0000, 0x382B2000, 0x382B4000, 0x382B6000, 0x382B8000, 0x382BA000, 0x382BC000, 0x382BE000,
  0x382C0000, 0x382C2000, 0x382C4000, 0x382C6000, 0x382C8000, 0x382CA000, 0x382CC000, 0x382CE000, 0x382D0000, 0x382D2000, 0x382D4000, 0x382D6000, 0x382D8000, 0x382DA000, 0x382DC000, 0x382DE000,
  0x382E0000, 0x382E2000, 0x382E4000, 0x382E6000, 0x382E8000, 0x382EA000, 0x382EC000, 0x382EE000, 0x382F0000, 0x382F2000, 0x382F4000, 0x382F6000, 0x382F8000, 0x382FA000, 0x382FC000, 0x382FE000,
  0x38300000, 0x38302000, 0x38304000, 0x38306000, 0x38308000, 0x3830A000, 0x3830C000, 0x3830E000, 0x38310000, 0x38312000, 0x38314000, 0x38316000, 0x38318000, 0x3831A000, 0x3831C000, 0x3831E000,
  0x38320000, 0x38322000, 0x38324000, 0x38326000, 0x38328000, 0x3832A000, 0x3832C000, 0x3832E000, 0x38330000, 0x38332000, 0x38334000, 0x38336000, 0x38338000, 0x3833A000, 0x3833C000, 0x3833E000,
  0x38340000, 0x38342000, 0x38344000, 0x38346000, 0x38348000, 0x3834A000, 0x3834C000, 0x3834E000, 0x38350000, 0x38352000, 0x38354000, 0x38356000, 0x38358000, 0x3835A000, 0x3835C000, 0x3835E000,
  0x38360000, 0x38362000, 0x38364000, 0x38366000, 0x38368000, 0x3836A000, 0x3836C000, 0x3836E000, 0x38370000, 0x38372000, 0x38374000, 0x38376000, 0x38378000, 0x3837A000, 0x3837C000, 0x3837E000,
  0x38380000, 0x38382000, 0x38384000, 0x38386000, 0x38388000, 0x3838A000, 0x3838C000, 0x3838E000, 0x38390000, 0x38392000, 0x38394000, 0x38396000, 0x38398000, 0x3839A000, 0x3839C000, 0x3839E000,
  0x383A0000, 0x383A2000, 0x383A4000, 0x383A6000, 0x383A8000, 0x383AA000, 0x383AC000, 0x383AE000, 0x383B0000, 0x383B2000, 0x383B4000, 0x383B6000, 0x383B8000, 0x383BA000, 0x383BC000, 0x383BE000,
  0x383C0000, 0x383C2000, 0x383C4000, 0x383C6000, 0x383C8000, 0x383CA000, 0x383CC000, 0x383CE000, 0x383D0000, 0x383D2000, 0x383D4000, 0x383D6000, 0x383D8000, 0x383DA000, 0x383DC000, 0x383DE000,
  0x383E0000, 0x383E2000, 0x383E4000, 0x383E6000, 0x383E8000, 0x383EA000, 0x383EC000, 0x383EE000, 0x383F0000, 0x383F2000, 0x383F4000, 0x383F6000, 0x383F8000, 0x383FA000, 0x383FC000, 0x383FE000,
  0x38400000, 0x38402000, 0x38404000, 0x38406000, 0x38408000, 0x3840A000, 0x3840C000, 0x3840E000, 0x38410000, 0x38412000, 0x38414000, 0x38416000, 0x38418000, 0x3841A000, 0x3841C000, 0x3841E000,
  0x38420000, 0x38422000, 0x38424000, 0x38426000, 0x38428000, 0x3842A000, 0x3842C000, 0x3842E000, 0x38430000, 0x38432000, 0x38434000, 0x38436000, 0x38438000, 0x3843A000, 0x3843C000, 0x3843E000,
  0x38440000, 0x38442000, 0x38444000, 0x38446000, 0x38448000, 0x3844A000, 0x3844C000, 0x3844E000, 0x38450000, 0x38452000, 0x38454000, 0x38456000, 0x38458000, 0x3845A000, 0x3845C000, 0x3845E000,
  0x38460000, 0x38462000, 0x38464000, 0x38466000, 0x38468000, 0x3846A000, 0x3846C000, 0x3846E000, 0x38470000, 0x38472000, 0x38474000, 0x38476000, 0x38478000, 0x3847A000, 0x3847C000, 0x3847E000,
  0x38480000, 0x38482000, 0x38484000, 0x38486000, 0x38488000, 0x3848A000, 0x3848C000, 0x3848E000, 0x38490000, 0x38492000, 0x38494000, 0x38496000, 0x38498000, 0x3849A000, 0x3849C000, 0x3849E000,
  0x384A0000, 0x384A2000, 0x384A4000, 0x384A6000, 0x384A8000, 0x384AA000, 0x384AC000, 0x384AE000, 0x384B0000, 0x384B2000, 0x384B4000, 0x384B6000, 0x384B8000, 0x384BA000, 0x384BC000, 0x384BE000,
  0x384C0000, 0x384C2000, 0x384C4000, 0x384C6000, 0x384C8000, 0x384CA000, 0x384CC000, 0x384CE000, 0x384D0000, 0x384D2000, 0x384D4000, 0x384D6000, 0x384D8000, 0x384DA000, 0x384DC000, 0x384DE000,
  0x384E0000, 0x384E2000, 0x384E4000, 0x384E6000, 0x384E8000, 0x384EA000, 0x384EC000, 0x384EE000, 0x384F0000, 0x384F2000, 0x384F4000, 0x384F6000, 0x384F8000, 0x384FA000, 0x384FC000, 0x384FE000,
  0x38500000, 0x38502000, 0x38504000, 0x38506000, 0x38508000, 0x3850A000, 0x3850C000, 0x3850E000, 0x38510000, 0x38512000, 0x38514000, 0x38516000, 0x38518000, 0x3851A000, 0x3851C000, 0x3851E000,
  0x38520000, 0x38522000, 0x38524000, 0x38526000, 0x38528000, 0x3852A000, 0x3852C000, 0x3852E000, 0x38530000, 0x38532000, 0x38534000, 0x38536000, 0x38538000, 0x3853A000, 0x3853C000, 0x3853E000,
  0x38540000, 0x38542000, 0x38544000, 0x38546000, 0x38548000, 0x3854A000, 0x3854C000, 0x3854E000, 0x38550000, 0x38552000, 0x38554000, 0x38556000, 0x38558000, 0x3855A000, 0x3855C000, 0x3855E000,
  0x38560000, 0x38562000, 0x38564000, 0x38566000, 0x38568000, 0x3856A000, 0x3856C000, 0x3856E000, 0x38570000, 0x38572000, 0x38574000, 0x38576000, 0x38578000, 0x3857A000, 0x3857C000, 0x3857E000,
  0x38580000, 0x38582000, 0x38584000, 0x38586000, 0x38588000, 0x3858A000, 0x3858C000, 0x3858E000, 0x38590000, 0x38592000, 0x38594000, 0x38596000, 0x38598000, 0x3859A000, 0x3859C000, 0x3859E000,
  0x385A0000, 0x385A2000, 0x385A4000, 0x385A6000, 0x385A8000, 0x385AA000, 0x385AC000, 0x385AE000, 0x385B0000, 0x385B2000, 0x385B4000, 0x385B6000, 0x385B8000, 0x385BA000, 0x385BC000, 0x385BE000,
  0x385C0000, 0x385C2000, 0x385C4000, 0x385C6000, 0x385C8000, 0x385CA000, 0x385CC000, 0x385CE000, 0x385D0000, 0x385D2000, 0x385D4000, 0x385D6000, 0x385D8000, 0x385DA000, 0x385DC000, 0x385DE000,
  0x385E0000, 0x385E2000, 0x385E4000, 0x385E6000, 0x385E8000, 0x385EA000, 0x385EC000, 0x385EE000, 0x385F0000, 0x385F2000, 0x385F4000, 0x385F6000, 0x385F8000, 0x385FA000, 0x385FC000, 0x385FE000,
  0x38600000, 0x38602000, 0x38604000, 0x38606000, 0x38608000, 0x3860A000, 0x3860C000, 0x3860E000, 0x38610000, 0x38612000, 0x38614000, 0x38616000, 0x38618000, 0x3861A000, 0x3861C000, 0x3861E000,
  0x38620000, 0x38622000, 0x38624000, 0x38626000, 0x38628000, 0x3862A000, 0x3862C000, 0x3862E000, 0x38630000, 0x38632000, 0x38634000, 0x38636000, 0x38638000, 0x3863A000, 0x3863C000, 0x3863E000,
  0x38640000, 0x38642000, 0x38644000, 0x38646000, 0x38648000, 0x3864A000, 0x3864C000, 0x3864E000, 0x38650000, 0x38652000, 0x38654000, 0x38656000, 0x38658000, 0x3865A000, 0x3865C000, 0x3865E000,
  0x38660000, 0x38662000, 0x38664000, 0x38666000, 0x38668000, 0x3866A000, 0x3866C000, 0x3866E000, 0x38670000, 0x38672000, 0x38674000, 0x38676000, 0x38678000, 0x3867A000, 0x3867C000, 0x3867E000,
  0x38680000, 0x38682000, 0x38684000, 0x38686000, 0x38688000, 0x3868A000, 0x3868C000, 0x3868E000, 0x38690000, 0x38692000, 0x38694000, 0x38696000, 0x38698000, 0x3869A000, 0x3869C000, 0x3869E000,
  0x386A0000, 0x386A2000, 0x386A4000, 0x386A6000, 0x386A8000, 0x386AA000, 0x386AC000, 0x386AE000, 0x386B0000, 0x386B2000, 0x386B4000, 0x386B6000, 0x386B8000, 0x386BA000, 0x386BC000, 0x386BE000,
  0x386C0000, 0x386C2000, 0x386C4000, 0x386C6000, 0x386C8000, 0x386CA000, 0x386CC000, 0x386CE000, 0x386D0000, 0x386D2000, 0x386D4000, 0x386D6000, 0x386D8000, 0x386DA000, 0x386DC000, 0x386DE000,
  0x386E0000, 0x386E2000, 0x386E4000, 0x386E6000, 0x386E8000, 0x386EA000, 0x386EC000, 0x386EE000, 0x386F0000, 0x386F2000, 0x386F4000, 0x386F6000, 0x386F8000, 0x386FA000, 0x386FC000, 0x386FE000,
  0x38700000, 0x38702000, 0x38704000, 0x38706000, 0x38708000, 0x3870A000, 0x3870C000, 0x3870E000, 0x38710000, 0x38712000, 0x38714000, 0x38716000, 0x38718000, 0x3871A000, 0x3871C000, 0x3871E000,
  0x38720000, 0x38722000, 0x38724000, 0x38726000, 0x38728000, 0x3872A000, 0x3872C000, 0x3872E000, 0x38730000, 0x38732000, 0x38734000, 0x38736000, 0x38738000, 0x3873A000, 0x3873C000, 0x3873E000,
  0x38740000, 0x38742000, 0x38744000, 0x38746000, 0x38748000, 0x3874A000, 0x3874C000, 0x3874E000, 0x38750000, 0x38752000, 0x38754000, 0x38756000, 0x38758000, 0x3875A000, 0x3875C000, 0x3875E000,
  0x38760000, 0x38762000, 0x38764000, 0x38766000, 0x38768000, 0x3876A000, 0x3876C000, 0x3876E000, 0x38770000, 0x38772000, 0x38774000, 0x38776000, 0x38778000, 0x3877A000, 0x3877C000, 0x3877E000,
  0x38780000, 0x38782000, 0x38784000, 0x38786000, 0x38788000, 0x3878A000, 0x3878C000, 0x3878E000, 0x38790000, 0x38792000, 0x38794000, 0x38796000, 0x38798000, 0x3879A000, 0x3879C000, 0x3879E000,
  0x387A0000, 0x387A2000, 0x387A4000, 0x387A6000, 0x387A8000, 0x387AA000, 0x387AC000, 0x387AE000, 0x387B0000, 0x387B2000, 0x387B4000, 0x387B6000, 0x387B8000, 0x387BA000, 0x387BC000, 0x387BE000,
  0x387C0000, 0x387C2000, 0x387C4000, 0x387C6000, 0x387C8000, 0x387CA000, 0x387CC000, 0x387CE000, 0x387D0000, 0x387D2000, 0x387D4000, 0x387D6000, 0x387D8000, 0x387DA000, 0x387DC000, 0x387DE000,
  0x387E0000, 0x387E2000, 0x387E4000, 0x387E6000, 0x387E8000, 0x387EA000, 0x387EC000, 0x387EE000, 0x387F0000, 0x387F2000, 0x387F4000, 0x387F6000, 0x387F8000, 0x387FA000, 0x387FC000, 0x387FE000 };
__constant static const uint32_t exponent_table[64] = {
  0x00000000, 0x00800000, 0x01000000, 0x01800000, 0x02000000, 0x02800000, 0x03000000, 0x03800000, 0x04000000, 0x04800000, 0x05000000, 0x05800000, 0x06000000, 0x06800000, 0x07000000, 0x07800000,
  0x08000000, 0x08800000, 0x09000000, 0x09800000, 0x0A000000, 0x0A800000, 0x0B000000, 0x0B800000, 0x0C000000, 0x0C800000, 0x0D000000, 0x0D800000, 0x0E000000, 0x0E800000, 0x0F000000, 0x47800000,
  0x80000000, 0x80800000, 0x81000000, 0x81800000, 0x82000000, 0x82800000, 0x83000000, 0x83800000, 0x84000000, 0x84800000, 0x85000000, 0x85800000, 0x86000000, 0x86800000, 0x87000000, 0x87800000,
  0x88000000, 0x88800000, 0x89000000, 0x89800000, 0x8A000000, 0x8A800000, 0x8B000000, 0x8B800000, 0x8C000000, 0x8C800000, 0x8D000000, 0x8D800000, 0x8E000000, 0x8E800000, 0x8F000000, 0xC7800000 };
__constant static const unsigned short offset_table[64] = {
  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024,
  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024 };

SCALAR_FUN_ATTR uint16_t float2halfbits(float value) {
  union { float x; uint32_t y; } u;
  u.x = value;
  uint32_t bits = u.y;

  uint16_t hbits = base_table[bits>>23] + (uint16_t)((bits&0x7FFFFF)>>shift_table[bits>>23]);;

  return hbits;
}

SCALAR_FUN_ATTR float halfbits2float(uint16_t value) {
  uint32_t bits = mantissa_table[offset_table[value>>10]+(value&0x3FF)] + exponent_table[value>>10];

  union { uint32_t x; float y; } u;
  u.x = bits;
  return u.y;
}

SCALAR_FUN_ATTR uint16_t halfbitsnextafter(uint16_t from, uint16_t to) {
  int fabs = from & 0x7FFF, tabs = to & 0x7FFF;
  if(fabs > 0x7C00 || tabs > 0x7C00) {
    return ((from&0x7FFF)>0x7C00) ? (from|0x200) : (to|0x200);
  }
  if(from == to || !(fabs|tabs)) {
    return to;
  }
  if(!fabs) {
    return (to&0x8000)+1;
  }
  unsigned int out =
    from +
    (((from>>15)^(unsigned int)((from^(0x8000|(0x8000-(from>>15))))<(to^(0x8000|(0x8000-(to>>15))))))<<1)
    - 1;
  return out;
}

// End of half.h.
// Start of timing.h.

// The function get_wall_time() returns the wall time in microseconds
// (with an unspecified offset).

#ifdef _WIN32

#include <windows.h>

static int64_t get_wall_time(void) {
  LARGE_INTEGER time,freq;
  assert(QueryPerformanceFrequency(&freq));
  assert(QueryPerformanceCounter(&time));
  return ((double)time.QuadPart / freq.QuadPart) * 1000000;
}

static int64_t get_wall_time_ns(void) {
  return get_wall_time() * 1000;
}

#else
// Assuming POSIX

#include <time.h>
#include <sys/time.h>

static int64_t get_wall_time(void) {
  struct timeval time;
  assert(gettimeofday(&time,NULL) == 0);
  return time.tv_sec * 1000000 + time.tv_usec;
}

static int64_t get_wall_time_ns(void) {
  struct timespec time;
  assert(clock_gettime(CLOCK_REALTIME, &time) == 0);
  return time.tv_sec * 1000000000 + time.tv_nsec;
}

#endif

// End of timing.h.
// Start of lock.h.

// A very simple cross-platform implementation of locks.  Uses
// pthreads on Unix and some Windows thing there.  Futhark's
// host-level code is not multithreaded, but user code may be, so we
// need some mechanism for ensuring atomic access to API functions.
// This is that mechanism.  It is not exposed to user code at all, so
// we do not have to worry about name collisions.

#ifdef _WIN32

typedef HANDLE lock_t;

static void create_lock(lock_t *lock) {
  *lock = CreateMutex(NULL,  // Default security attributes.
                      FALSE, // Initially unlocked.
                      NULL); // Unnamed.
}

static void lock_lock(lock_t *lock) {
  assert(WaitForSingleObject(*lock, INFINITE) == WAIT_OBJECT_0);
}

static void lock_unlock(lock_t *lock) {
  assert(ReleaseMutex(*lock));
}

static void free_lock(lock_t *lock) {
  CloseHandle(*lock);
}

#else
// Assuming POSIX

#include <pthread.h>

typedef pthread_mutex_t lock_t;

static void create_lock(lock_t *lock) {
  int r = pthread_mutex_init(lock, NULL);
  assert(r == 0);
}

static void lock_lock(lock_t *lock) {
  int r = pthread_mutex_lock(lock);
  assert(r == 0);
}

static void lock_unlock(lock_t *lock) {
  int r = pthread_mutex_unlock(lock);
  assert(r == 0);
}

static void free_lock(lock_t *lock) {
  // Nothing to do for pthreads.
  (void)lock;
}

#endif

// End of lock.h.
// Start of free_list.h.

typedef uintptr_t fl_mem;

// An entry in the free list.  May be invalid, to avoid having to
// deallocate entries as soon as they are removed.  There is also a
// tag, to help with memory reuse.
struct free_list_entry {
  size_t size;
  fl_mem mem;
  const char *tag;
  unsigned char valid;
};

struct free_list {
  struct free_list_entry *entries; // Pointer to entries.
  int capacity;                    // Number of entries.
  int used;                        // Number of valid entries.
  lock_t lock;                     // Thread safety.
};

static void free_list_init(struct free_list *l) {
  l->capacity = 30; // Picked arbitrarily.
  l->used = 0;
  l->entries = (struct free_list_entry*) malloc(sizeof(struct free_list_entry) * l->capacity);
  for (int i = 0; i < l->capacity; i++) {
    l->entries[i].valid = 0;
  }
  create_lock(&l->lock);
}

// Remove invalid entries from the free list.
static void free_list_pack(struct free_list *l) {
  lock_lock(&l->lock);
  int p = 0;
  for (int i = 0; i < l->capacity; i++) {
    if (l->entries[i].valid) {
      l->entries[p] = l->entries[i];
      if (i > p) {
        l->entries[i].valid = 0;
      }
      p++;
    }
  }

  // Now p is the number of used elements.  We don't want it to go
  // less than the default capacity (although in practice it's OK as
  // long as it doesn't become 1).
  if (p < 30) {
    p = 30;
  }
  l->entries = realloc(l->entries, p * sizeof(struct free_list_entry));
  l->capacity = p;
  lock_unlock(&l->lock);
}

static void free_list_destroy(struct free_list *l) {
  assert(l->used == 0);
  free(l->entries);
  free_lock(&l->lock);
}

// Not part of the interface, so no locking.
static int free_list_find_invalid(struct free_list *l) {
  int i;
  for (i = 0; i < l->capacity; i++) {
    if (!l->entries[i].valid) {
      break;
    }
  }
  return i;
}

static void free_list_insert(struct free_list *l, size_t size, fl_mem mem, const char *tag) {
  lock_lock(&l->lock);
  int i = free_list_find_invalid(l);

  if (i == l->capacity) {
    // List is full; so we have to grow it.
    int new_capacity = l->capacity * 2 * sizeof(struct free_list_entry);
    l->entries = realloc(l->entries, new_capacity);
    for (int j = 0; j < l->capacity; j++) {
      l->entries[j+l->capacity].valid = 0;
    }
    l->capacity *= 2;
  }

  // Now 'i' points to the first invalid entry.
  l->entries[i].valid = 1;
  l->entries[i].size = size;
  l->entries[i].mem = mem;
  l->entries[i].tag = tag;

  l->used++;
  lock_unlock(&l->lock);
}

// Determine whether this entry in the free list is acceptable for
// satisfying the request.  Not public, so no locking.
static bool free_list_acceptable(size_t size, const char* tag, struct free_list_entry *entry) {
  // We check not just the hard requirement (is the entry acceptable
  // and big enough?) but also put a cap on how much wasted space
  // (internal fragmentation) we allow.  This is necessarily a
  // heuristic, and a crude one.

  if (!entry->valid) {
    return false;
  }

  if (size > entry->size) {
    return false;
  }

  // We know the block fits.  Now the question is whether it is too
  // big.  Our policy is as follows:
  //
  // 1) We don't care about wasted space below 4096 bytes (to avoid
  // churn in tiny allocations).
  //
  // 2) If the tag matches, we allow _any_ amount of wasted space.
  //
  // 3) Otherwise we allow up to 50% wasted space.

  if (entry->size < 4096) {
    return true;
  }

  if (entry->tag == tag) {
    return true;
  }

  if (entry->size < size * 2) {
    return true;
  }

  return false;
}

// Find and remove a memory block of the indicated tag, or if that
// does not exist, another memory block with exactly the desired size.
// Returns 0 on success.
static int free_list_find(struct free_list *l, size_t size, const char *tag,
                          size_t *size_out, fl_mem *mem_out) {
  lock_lock(&l->lock);
  int size_match = -1;
  int i;
  int ret = 1;
  for (i = 0; i < l->capacity; i++) {
    if (free_list_acceptable(size, tag, &l->entries[i]) &&
        (size_match < 0 || l->entries[i].size < l->entries[size_match].size)) {
      // If this entry is valid, has sufficient size, and is smaller than the
      // best entry found so far, use this entry.
      size_match = i;
    }
  }

  if (size_match >= 0) {
    l->entries[size_match].valid = 0;
    *size_out = l->entries[size_match].size;
    *mem_out = l->entries[size_match].mem;
    l->used--;
    ret = 0;
  }
  lock_unlock(&l->lock);
  return ret;
}

// Remove the first block in the free list.  Returns 0 if a block was
// removed, and nonzero if the free list was already empty.
static int free_list_first(struct free_list *l, fl_mem *mem_out) {
  lock_lock(&l->lock);
  int ret = 1;
  for (int i = 0; i < l->capacity; i++) {
    if (l->entries[i].valid) {
      l->entries[i].valid = 0;
      *mem_out = l->entries[i].mem;
      l->used--;
      ret = 0;
      break;
    }
  }
  lock_unlock(&l->lock);
  return ret;
}

// End of free_list.h.
// Start of event_list.h

typedef int (*event_report_fn)(struct str_builder*, void*);

struct event {
  void* data;
  event_report_fn f;
  const char* name;
  char *description;
};

struct event_list {
  struct event *events;
  int num_events;
  int capacity;
};

static void event_list_init(struct event_list *l) {
  l->capacity = 100;
  l->num_events = 0;
  l->events = calloc(l->capacity, sizeof(struct event));
}

static void event_list_free(struct event_list *l) {
  free(l->events);
}

static void add_event_to_list(struct event_list *l,
                              const char* name,
                              char* description,
                              void* data,
                              event_report_fn f) {
  if (l->num_events == l->capacity) {
    l->capacity *= 2;
    l->events = realloc(l->events, l->capacity * sizeof(struct event));
  }
  l->events[l->num_events].name = name;
  l->events[l->num_events].description = description;
  l->events[l->num_events].data = data;
  l->events[l->num_events].f = f;
  l->num_events++;
}

static int report_events_in_list(struct event_list *l,
                                 struct str_builder* sb) {
  int ret = 0;
  for (int i = 0; i < l->num_events; i++) {
    if (i != 0) {
      str_builder_str(sb, ",");
    }
    str_builder_str(sb, "{\"name\":");
    str_builder_json_str(sb, l->events[i].name);
    str_builder_str(sb, ",\"description\":");
    str_builder_json_str(sb, l->events[i].description);
    free(l->events[i].description);
    if (l->events[i].f(sb, l->events[i].data) != 0) {
      ret = 1;
      break;
    }
    str_builder(sb, "}");
  }
  event_list_free(l);
  event_list_init(l);
  return ret;
}

// End of event_list.h

#ifdef _MSC_VER
#define inline __inline
#endif
#include <string.h>
#include <string.h>
#include <errno.h>
#include <assert.h>
#include <ctype.h>


#include <cuda.h>
#include <cuda_runtime.h>
#include <nvrtc.h>


#define FUTHARK_F64_ENABLED

// Start of scalar.h.

// Implementation of the primitive scalar operations.  Very
// repetitive.  This code is inserted directly into both CUDA and
// OpenCL programs, as well as the CPU code, so it has some #ifdefs to
// work everywhere.  Some operations are defined as macros because
// this allows us to use them as constant expressions in things like
// array sizes and static initialisers.

// Some of the #ifdefs are because OpenCL uses type-generic functions
// for some operations (e.g. sqrt), while C and CUDA sensibly use
// distinct functions for different precisions (e.g. sqrtf() and
// sqrt()).  This is quite annoying.  Due to C's unfortunate casting
// rules, it is also really easy to accidentally implement
// floating-point functions in the wrong precision, so be careful.

// Double-precision definitions are only included if the preprocessor
// macro FUTHARK_F64_ENABLED is set.

SCALAR_FUN_ATTR int32_t futrts_to_bits32(float x);
SCALAR_FUN_ATTR float futrts_from_bits32(int32_t x);

SCALAR_FUN_ATTR uint8_t add8(uint8_t x, uint8_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint16_t add16(uint16_t x, uint16_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint32_t add32(uint32_t x, uint32_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint64_t add64(uint64_t x, uint64_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint8_t sub8(uint8_t x, uint8_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint16_t sub16(uint16_t x, uint16_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint32_t sub32(uint32_t x, uint32_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint64_t sub64(uint64_t x, uint64_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint8_t mul8(uint8_t x, uint8_t y) {
  return x * y;
}

SCALAR_FUN_ATTR uint16_t mul16(uint16_t x, uint16_t y) {
  return x * y;
}

SCALAR_FUN_ATTR uint32_t mul32(uint32_t x, uint32_t y) {
  return x * y;
}

SCALAR_FUN_ATTR uint64_t mul64(uint64_t x, uint64_t y) {
  return x * y;
}

#if ISPC

SCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {
  // This strange pattern is used to prevent the ISPC compiler from
  // causing SIGFPEs and bogus results on divisions where inactive lanes
  // have 0-valued divisors. It ensures that any inactive lane instead
  // has a divisor of 1. https://github.com/ispc/ispc/issues/2292
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return x / ys;
}

SCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return x / ys;
}

SCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return x % ys;
}

SCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int8_t q = x / ys;
  int8_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int16_t q = x / ys;
  int16_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  int32_t q = x / ys;
  int32_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int64_t q = x / ys;
  int64_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {
  return sdiv8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {
  return sdiv16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {
  return sdiv32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {
  return sdiv64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int8_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int16_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int32_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int64_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : sdiv8(x, y);
}

SCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : sdiv16(x, y);
}

SCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : sdiv32(x, y);
}

SCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : sdiv64(x, y);
}

SCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {
  return sdiv_safe8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {
  return sdiv_safe16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {
  return sdiv_safe32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {
  return sdiv_safe64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : smod8(x, y);
}

SCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : smod16(x, y);
}

SCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : smod32(x, y);
}

SCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : smod64(x, y);
}

SCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

#else

SCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {
  int8_t q = x / y;
  int8_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {
  int16_t q = x / y;
  int16_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {
  int32_t q = x / y;
  int32_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {
  int64_t q = x / y;
  int64_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {
  return sdiv8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {
  return sdiv16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {
  return sdiv32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {
  return sdiv64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {
  int8_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {
  int16_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {
  int32_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {
  int64_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : sdiv8(x, y);
}

SCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : sdiv16(x, y);
}

SCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : sdiv32(x, y);
}

SCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : sdiv64(x, y);
}

SCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {
  return sdiv_safe8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {
  return sdiv_safe16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {
  return sdiv_safe32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {
  return sdiv_safe64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : smod8(x, y);
}

SCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : smod16(x, y);
}

SCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : smod32(x, y);
}

SCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : smod64(x, y);
}

SCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : x % y;
}

#endif

SCALAR_FUN_ATTR int8_t smin8(int8_t x, int8_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int16_t smin16(int16_t x, int16_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int32_t smin32(int32_t x, int32_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int64_t smin64(int64_t x, int64_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint8_t umin8(uint8_t x, uint8_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint16_t umin16(uint16_t x, uint16_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint32_t umin32(uint32_t x, uint32_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint64_t umin64(uint64_t x, uint64_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int8_t smax8(int8_t x, int8_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR int16_t smax16(int16_t x, int16_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR int32_t smax32(int32_t x, int32_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR int64_t smax64(int64_t x, int64_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint8_t umax8(uint8_t x, uint8_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint16_t umax16(uint16_t x, uint16_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint32_t umax32(uint32_t x, uint32_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint64_t umax64(uint64_t x, uint64_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint8_t shl8(uint8_t x, uint8_t y) {
  return (uint8_t)(x << y);
}

SCALAR_FUN_ATTR uint16_t shl16(uint16_t x, uint16_t y) {
  return (uint16_t)(x << y);
}

SCALAR_FUN_ATTR uint32_t shl32(uint32_t x, uint32_t y) {
  return x << y;
}

SCALAR_FUN_ATTR uint64_t shl64(uint64_t x, uint64_t y) {
  return x << y;
}

SCALAR_FUN_ATTR uint8_t lshr8(uint8_t x, uint8_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint16_t lshr16(uint16_t x, uint16_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint32_t lshr32(uint32_t x, uint32_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint64_t lshr64(uint64_t x, uint64_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int8_t ashr8(int8_t x, int8_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int16_t ashr16(int16_t x, int16_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int32_t ashr32(int32_t x, int32_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int64_t ashr64(int64_t x, int64_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint8_t and8(uint8_t x, uint8_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint16_t and16(uint16_t x, uint16_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint32_t and32(uint32_t x, uint32_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint64_t and64(uint64_t x, uint64_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint8_t or8(uint8_t x, uint8_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint16_t or16(uint16_t x, uint16_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint32_t or32(uint32_t x, uint32_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint64_t or64(uint64_t x, uint64_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint8_t xor8(uint8_t x, uint8_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR uint16_t xor16(uint16_t x, uint16_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR uint32_t xor32(uint32_t x, uint32_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR uint64_t xor64(uint64_t x, uint64_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR bool ult8(uint8_t x, uint8_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ult16(uint16_t x, uint16_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ult32(uint32_t x, uint32_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ult64(uint64_t x, uint64_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ule8(uint8_t x, uint8_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool ule16(uint16_t x, uint16_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool ule32(uint32_t x, uint32_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool ule64(uint64_t x, uint64_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool slt8(int8_t x, int8_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool slt16(int16_t x, int16_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool slt32(int32_t x, int32_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool slt64(int64_t x, int64_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool sle8(int8_t x, int8_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool sle16(int16_t x, int16_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool sle32(int32_t x, int32_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool sle64(int64_t x, int64_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR uint8_t pow8(uint8_t x, uint8_t y) {
  uint8_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint16_t pow16(uint16_t x, uint16_t y) {
  uint16_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint32_t pow32(uint32_t x, uint32_t y) {
  uint32_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint64_t pow64(uint64_t x, uint64_t y) {
  uint64_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR bool itob_i8_bool(int8_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR bool itob_i16_bool(int16_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR bool itob_i32_bool(int32_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR bool itob_i64_bool(int64_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR int8_t btoi_bool_i8(bool x) {
  return x;
}

SCALAR_FUN_ATTR int16_t btoi_bool_i16(bool x) {
  return x;
}

SCALAR_FUN_ATTR int32_t btoi_bool_i32(bool x) {
  return x;
}

SCALAR_FUN_ATTR int64_t btoi_bool_i64(bool x) {
  return x;
}

#define sext_i8_i8(x) ((int8_t) (int8_t) (x))
#define sext_i8_i16(x) ((int16_t) (int8_t) (x))
#define sext_i8_i32(x) ((int32_t) (int8_t) (x))
#define sext_i8_i64(x) ((int64_t) (int8_t) (x))
#define sext_i16_i8(x) ((int8_t) (int16_t) (x))
#define sext_i16_i16(x) ((int16_t) (int16_t) (x))
#define sext_i16_i32(x) ((int32_t) (int16_t) (x))
#define sext_i16_i64(x) ((int64_t) (int16_t) (x))
#define sext_i32_i8(x) ((int8_t) (int32_t) (x))
#define sext_i32_i16(x) ((int16_t) (int32_t) (x))
#define sext_i32_i32(x) ((int32_t) (int32_t) (x))
#define sext_i32_i64(x) ((int64_t) (int32_t) (x))
#define sext_i64_i8(x) ((int8_t) (int64_t) (x))
#define sext_i64_i16(x) ((int16_t) (int64_t) (x))
#define sext_i64_i32(x) ((int32_t) (int64_t) (x))
#define sext_i64_i64(x) ((int64_t) (int64_t) (x))
#define zext_i8_i8(x) ((int8_t) (uint8_t) (x))
#define zext_i8_i16(x) ((int16_t) (uint8_t) (x))
#define zext_i8_i32(x) ((int32_t) (uint8_t) (x))
#define zext_i8_i64(x) ((int64_t) (uint8_t) (x))
#define zext_i16_i8(x) ((int8_t) (uint16_t) (x))
#define zext_i16_i16(x) ((int16_t) (uint16_t) (x))
#define zext_i16_i32(x) ((int32_t) (uint16_t) (x))
#define zext_i16_i64(x) ((int64_t) (uint16_t) (x))
#define zext_i32_i8(x) ((int8_t) (uint32_t) (x))
#define zext_i32_i16(x) ((int16_t) (uint32_t) (x))
#define zext_i32_i32(x) ((int32_t) (uint32_t) (x))
#define zext_i32_i64(x) ((int64_t) (uint32_t) (x))
#define zext_i64_i8(x) ((int8_t) (uint64_t) (x))
#define zext_i64_i16(x) ((int16_t) (uint64_t) (x))
#define zext_i64_i32(x) ((int32_t) (uint64_t) (x))
#define zext_i64_i64(x) ((int64_t) (uint64_t) (x))

SCALAR_FUN_ATTR int8_t abs8(int8_t x) {
  return (int8_t)abs(x);
}

SCALAR_FUN_ATTR int16_t abs16(int16_t x) {
  return (int16_t)abs(x);
}

SCALAR_FUN_ATTR int32_t abs32(int32_t x) {
  return abs(x);
}

SCALAR_FUN_ATTR int64_t abs64(int64_t x) {
#if defined(__OPENCL_VERSION__) || defined(ISPC)
  return abs(x);
#else
  return llabs(x);
#endif
}

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {
  return popcount(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {
  return popcount(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {
  return popcount(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {
  return popcount(x);
}
#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {
  return __popc(zext_i8_i32(x));
}

SCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {
  return __popc(zext_i16_i32(x));
}

SCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {
  return __popc(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {
  return __popcll(x);
}

#else // Not OpenCL or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_popc8(uint8_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc16(uint16_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc32(uint32_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc64(uint64_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR uint8_t  futrts_umul_hi8 ( uint8_t a,  uint8_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint8_t  futrts_smul_hi8 ( int8_t a,  int8_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return mul_hi(a, b); }
#elif defined(__CUDA_ARCH__)
SCALAR_FUN_ATTR  uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return __umulhi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return __umul64hi(a, b); }
SCALAR_FUN_ATTR  uint8_t futrts_smul_hi8 ( int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return __mulhi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return __mul64hi(a, b); }
#elif ISPC
SCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) {
  uint64_t ah = a >> 32;
  uint64_t al = a & 0xffffffff;
  uint64_t bh = b >> 32;
  uint64_t bl = b & 0xffffffff;

  uint64_t p1 = al * bl;
  uint64_t p2 = al * bh;
  uint64_t p3 = ah * bl;
  uint64_t p4 = ah * bh;

  uint64_t p1h = p1 >> 32;
  uint64_t p2h = p2 >> 32;
  uint64_t p3h = p3 >> 32;
  uint64_t p2l = p2 & 0xffffffff;
  uint64_t p3l = p3 & 0xffffffff;

  uint64_t l = p1h + p2l + p3l;
  uint64_t m = (p2 >> 32) + (p3 >> 32);
  uint64_t h = (l >> 32) + m + p4;

  return h;
}
SCALAR_FUN_ATTR  int8_t futrts_smul_hi8 ( int8_t a,  int8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) {
  uint64_t ah = a >> 32;
  uint64_t al = a & 0xffffffff;
  uint64_t bh = b >> 32;
  uint64_t bl = b & 0xffffffff;

  uint64_t p1 =  al * bl;
  int64_t  p2 = al * bh;
  int64_t  p3 = ah * bl;
  uint64_t p4 =  ah * bh;

  uint64_t p1h = p1 >> 32;
  uint64_t p2h = p2 >> 32;
  uint64_t p3h = p3 >> 32;
  uint64_t p2l = p2 & 0xffffffff;
  uint64_t p3l = p3 & 0xffffffff;

  uint64_t l = p1h + p2l + p3l;
  uint64_t m = (p2 >> 32) + (p3 >> 32);
  uint64_t h = (l >> 32) + m + p4;

  return h;
}

#else // Not OpenCL, ISPC, or CUDA, but plain C.
SCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return ((__uint128_t)a) * ((__uint128_t)b) >> 64; }
SCALAR_FUN_ATTR int8_t futrts_smul_hi8(int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }
SCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }
SCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((int64_t)a) * ((int64_t)b) >> 32; }
SCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) { return ((__int128_t)a) * ((__int128_t)b) >> 64; }
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR  uint8_t futrts_umad_hi8 ( uint8_t a,  uint8_t b,  uint8_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR  uint8_t futrts_smad_hi8( int8_t a,  int8_t b,   int8_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return mad_hi(a, b, c); }
#else // Not OpenCL

SCALAR_FUN_ATTR  uint8_t futrts_umad_hi8( uint8_t a,  uint8_t b,  uint8_t c) { return futrts_umul_hi8(a, b) + c; }
SCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return futrts_umul_hi16(a, b) + c; }
SCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return futrts_umul_hi32(a, b) + c; }
SCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return futrts_umul_hi64(a, b) + c; }
SCALAR_FUN_ATTR  uint8_t futrts_smad_hi8 ( int8_t a,  int8_t b,  int8_t c) { return futrts_smul_hi8(a, b) + c; }
SCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return futrts_smul_hi16(a, b) + c; }
SCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return futrts_smul_hi32(a, b) + c; }
SCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return futrts_smul_hi64(a, b) + c; }
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return clz(x);
}

#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return __clz(zext_i8_i32(x)) - 24;
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return __clz(zext_i16_i32(x)) - 16;
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return __clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return __clzll(x);
}

#elif ISPC

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return count_leading_zeros((int32_t)(uint8_t)x)-24;
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return count_leading_zeros((int32_t)(uint16_t)x)-16;
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return count_leading_zeros(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return count_leading_zeros(x);
}

#else // Not OpenCL, ISPC or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return x == 0 ? 8 : __builtin_clz((uint32_t)zext_i8_i32(x)) - 24;
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return x == 0 ? 16 : __builtin_clz((uint32_t)zext_i16_i32(x)) - 16;
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return x == 0 ? 32 : __builtin_clz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return x == 0 ? 64 : __builtin_clzll((uint64_t)x);
}
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  int i = 0;
  for (; i < 8 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  int i = 0;
  for (; i < 16 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  int i = 0;
  for (; i < 32 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  int i = 0;
  for (; i < 64 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  int y = __ffs(x);
  return y == 0 ? 8 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  int y = __ffs(x);
  return y == 0 ? 16 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  int y = __ffs(x);
  return y == 0 ? 32 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  int y = __ffsll(x);
  return y == 0 ? 64 : y - 1;
}

#elif ISPC

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  return x == 0 ? 8 : count_trailing_zeros((int32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  return x == 0 ? 16 : count_trailing_zeros((int32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  return count_trailing_zeros(x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  return count_trailing_zeros(x);
}

#else // Not OpenCL or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  return x == 0 ? 8 : __builtin_ctz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  return x == 0 ? 16 : __builtin_ctz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  return x == 0 ? 32 : __builtin_ctz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  return x == 0 ? 64 : __builtin_ctzll((uint64_t)x);
}
#endif

SCALAR_FUN_ATTR float fdiv32(float x, float y) {
  return x / y;
}

SCALAR_FUN_ATTR float fadd32(float x, float y) {
  return x + y;
}

SCALAR_FUN_ATTR float fsub32(float x, float y) {
  return x - y;
}

SCALAR_FUN_ATTR float fmul32(float x, float y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt32(float x, float y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple32(float x, float y) {
  return x <= y;
}

SCALAR_FUN_ATTR float sitofp_i8_f32(int8_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float sitofp_i16_f32(int16_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float sitofp_i32_f32(int32_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float sitofp_i64_f32(int64_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i8_f32(uint8_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i16_f32(uint16_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i32_f32(uint32_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i64_f32(uint64_t x) {
  return (float) x;
}

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR float fabs32(float x) {
  return fabs(x);
}

SCALAR_FUN_ATTR float fmax32(float x, float y) {
  return fmax(x, y);
}

SCALAR_FUN_ATTR float fmin32(float x, float y) {
  return fmin(x, y);
}

SCALAR_FUN_ATTR float fpow32(float x, float y) {
  return pow(x, y);
}

#elif ISPC

SCALAR_FUN_ATTR float fabs32(float x) {
  return abs(x);
}

SCALAR_FUN_ATTR float fmax32(float x, float y) {
  return isnan(x) ? y : isnan(y) ? x : max(x, y);
}

SCALAR_FUN_ATTR float fmin32(float x, float y) {
  return isnan(x) ? y : isnan(y) ? x : min(x, y);
}

SCALAR_FUN_ATTR float fpow32(float a, float b) {
  float ret;
  foreach_active (i) {
      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));
      ret = insert(ret, i, r);
  }
  return ret;
}

#else // Not OpenCL, but CUDA or plain C.

SCALAR_FUN_ATTR float fabs32(float x) {
  return fabsf(x);
}

SCALAR_FUN_ATTR float fmax32(float x, float y) {
  return fmaxf(x, y);
}

SCALAR_FUN_ATTR float fmin32(float x, float y) {
  return fminf(x, y);
}

SCALAR_FUN_ATTR float fpow32(float x, float y) {
  return powf(x, y);
}
#endif

SCALAR_FUN_ATTR bool futrts_isnan32(float x) {
  return isnan(x);
}

#if ISPC

SCALAR_FUN_ATTR bool futrts_isinf32(float x) {
  return !isnan(x) && isnan(x - x);
}

SCALAR_FUN_ATTR bool futrts_isfinite32(float x) {
  return !isnan(x) && !futrts_isinf32(x);
}

#else

SCALAR_FUN_ATTR bool futrts_isinf32(float x) {
  return isinf(x);
}

#endif

SCALAR_FUN_ATTR int8_t fptosi_f32_i8(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f32_i16(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f32_i32(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f32_i64(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int64_t) x;
  };
}

SCALAR_FUN_ATTR uint8_t fptoui_f32_i8(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f32_i16(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f32_i32(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f32_i64(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f32_bool(float x) {
  return x != 0;
}

SCALAR_FUN_ATTR float btof_bool_f32(bool x) {
  return x ? 1 : 0;
}

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR float futrts_log32(float x) {
  return log(x);
}

SCALAR_FUN_ATTR float futrts_log2_32(float x) {
  return log2(x);
}

SCALAR_FUN_ATTR float futrts_log10_32(float x) {
  return log10(x);
}

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  return log1p(x);
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) {
  return sqrt(x);
}

SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  return cbrt(x);
}

SCALAR_FUN_ATTR float futrts_exp32(float x) {
  return exp(x);
}

SCALAR_FUN_ATTR float futrts_cos32(float x) {
  return cos(x);
}

SCALAR_FUN_ATTR float futrts_sin32(float x) {
  return sin(x);
}

SCALAR_FUN_ATTR float futrts_tan32(float x) {
  return tan(x);
}

SCALAR_FUN_ATTR float futrts_acos32(float x) {
  return acos(x);
}

SCALAR_FUN_ATTR float futrts_asin32(float x) {
  return asin(x);
}

SCALAR_FUN_ATTR float futrts_atan32(float x) {
  return atan(x);
}

SCALAR_FUN_ATTR float futrts_cosh32(float x) {
  return cosh(x);
}

SCALAR_FUN_ATTR float futrts_sinh32(float x) {
  return sinh(x);
}

SCALAR_FUN_ATTR float futrts_tanh32(float x) {
  return tanh(x);
}

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  return acosh(x);
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  return asinh(x);
}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  return atanh(x);
}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {
  return atan2(x, y);
}

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  return hypot(x, y);
}

SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  return tgamma(x);
}

SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  return lgamma(x);
}

SCALAR_FUN_ATTR float futrts_erf32(float x) {
  return erf(x);
}

SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  return erfc(x);
}

SCALAR_FUN_ATTR float fmod32(float x, float y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR float futrts_round32(float x) {
  return rint(x);
}

SCALAR_FUN_ATTR float futrts_floor32(float x) {
  return floor(x);
}

SCALAR_FUN_ATTR float futrts_ceil32(float x) {
  return ceil(x);
}

SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  return nextafter(x, y);
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return mix(v0, v1, t);
}

SCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {
  return ldexp(x, y);
}

SCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {
  return copysign(x, y);
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return mad(a, b, c);
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return fma(a, b, c);
}

#elif ISPC

SCALAR_FUN_ATTR float futrts_log32(float x) {
  return futrts_isfinite32(x) || (futrts_isinf32(x) && x < 0)? log(x) : x;
}

SCALAR_FUN_ATTR float futrts_log2_32(float x) {
  return futrts_log32(x) / log(2.0f);
}

SCALAR_FUN_ATTR float futrts_log10_32(float x) {
  return futrts_log32(x) / log(10.0f);
}

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  if(x == -1.0f || (futrts_isinf32(x) && x > 0.0f)) return x / 0.0f;
  float y = 1.0f + x;
  float z = y - 1.0f;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) {
  return sqrt(x);
}

extern "C" unmasked uniform float cbrtf(uniform float);
SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = cbrtf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float futrts_exp32(float x) {
  return exp(x);
}

SCALAR_FUN_ATTR float futrts_cos32(float x) {
  return cos(x);
}

SCALAR_FUN_ATTR float futrts_sin32(float x) {
  return sin(x);
}

SCALAR_FUN_ATTR float futrts_tan32(float x) {
  return tan(x);
}

SCALAR_FUN_ATTR float futrts_acos32(float x) {
  return acos(x);
}

SCALAR_FUN_ATTR float futrts_asin32(float x) {
  return asin(x);
}

SCALAR_FUN_ATTR float futrts_atan32(float x) {
  return atan(x);
}

SCALAR_FUN_ATTR float futrts_cosh32(float x) {
  return (exp(x)+exp(-x)) / 2.0f;
}

SCALAR_FUN_ATTR float futrts_sinh32(float x) {
  return (exp(x)-exp(-x)) / 2.0f;
}

SCALAR_FUN_ATTR float futrts_tanh32(float x) {
  return futrts_sinh32(x)/futrts_cosh32(x);
}

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  float f = x+sqrt(x*x-1);
  if(futrts_isfinite32(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  float f = x+sqrt(x*x+1);
  if(futrts_isfinite32(f)) return log(f);
  return f;

}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  float f = (1+x)/(1-x);
  if(futrts_isfinite32(f)) return log(f)/2.0f;
  return f;

}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {
  return (x == 0.0f && y == 0.0f) ? 0.0f : atan2(x, y);
}

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  if (futrts_isfinite32(x) && futrts_isfinite32(y)) {
    x = abs(x);
    y = abs(y);
    float a;
    float b;
    if (x >= y){
        a = x;
        b = y;
    } else {
        a = y;
        b = x;
    }
    if(b == 0){
      return a;
    }

    int e;
    float an;
    float bn;
    an = frexp (a, &e);
    bn = ldexp (b, - e);
    float cn;
    cn = sqrt (an * an + bn * bn);
    return ldexp (cn, e);
  } else {
    if (futrts_isinf32(x) || futrts_isinf32(y)) return INFINITY;
    else return x + y;
  }

}

extern "C" unmasked uniform float tgammaf(uniform float x);
SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = tgammaf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float lgammaf(uniform float x);
SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = lgammaf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float erff(uniform float x);
SCALAR_FUN_ATTR float futrts_erf32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = erff(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float erfcf(uniform float x);
SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = erfcf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float fmod32(float x, float y) {
  return x - y * trunc(x/y);
}

SCALAR_FUN_ATTR float futrts_round32(float x) {
  return round(x);
}

SCALAR_FUN_ATTR float futrts_floor32(float x) {
  return floor(x);
}

SCALAR_FUN_ATTR float futrts_ceil32(float x) {
  return ceil(x);
}

extern "C" unmasked uniform float nextafterf(uniform float x, uniform float y);
SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  float res;
  foreach_active (i) {
    uniform float r = nextafterf(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {
  return x * pow((double)2.0, (double)y);
}

SCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {
  int32_t xb = futrts_to_bits32(x);
  int32_t yb = futrts_to_bits32(y);
  return futrts_from_bits32((xb & ~(1<<31)) | (yb & (1<<31)));
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return a * b + c;
}

#else // Not OpenCL or ISPC, but CUDA or plain C.

SCALAR_FUN_ATTR float futrts_log32(float x) {
  return logf(x);
}

SCALAR_FUN_ATTR float futrts_log2_32(float x) {
  return log2f(x);
}

SCALAR_FUN_ATTR float futrts_log10_32(float x) {
  return log10f(x);
}

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  return log1pf(x);
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) {
  return sqrtf(x);
}

SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  return cbrtf(x);
}

SCALAR_FUN_ATTR float futrts_exp32(float x) {
  return expf(x);
}

SCALAR_FUN_ATTR float futrts_cos32(float x) {
  return cosf(x);
}

SCALAR_FUN_ATTR float futrts_sin32(float x) {
  return sinf(x);
}

SCALAR_FUN_ATTR float futrts_tan32(float x) {
  return tanf(x);
}

SCALAR_FUN_ATTR float futrts_acos32(float x) {
  return acosf(x);
}

SCALAR_FUN_ATTR float futrts_asin32(float x) {
  return asinf(x);
}

SCALAR_FUN_ATTR float futrts_atan32(float x) {
  return atanf(x);
}

SCALAR_FUN_ATTR float futrts_cosh32(float x) {
  return coshf(x);
}

SCALAR_FUN_ATTR float futrts_sinh32(float x) {
  return sinhf(x);
}

SCALAR_FUN_ATTR float futrts_tanh32(float x) {
  return tanhf(x);
}

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  return acoshf(x);
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  return asinhf(x);
}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  return atanhf(x);
}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {
  return atan2f(x, y);
}

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  return hypotf(x, y);
}

SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  return tgammaf(x);
}

SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  return lgammaf(x);
}

SCALAR_FUN_ATTR float futrts_erf32(float x) {
  return erff(x);
}

SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  return erfcf(x);
}

SCALAR_FUN_ATTR float fmod32(float x, float y) {
  return fmodf(x, y);
}

SCALAR_FUN_ATTR float futrts_round32(float x) {
  return rintf(x);
}

SCALAR_FUN_ATTR float futrts_floor32(float x) {
  return floorf(x);
}

SCALAR_FUN_ATTR float futrts_ceil32(float x) {
  return ceilf(x);
}

SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  return nextafterf(x, y);
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {
  return ldexpf(x, y);
}

SCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {
  return copysignf(x, y);
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return fmaf(a, b, c);
}
#endif

#if ISPC
SCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {
  return intbits(x);
}

SCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {
  return floatbits(x);
}
#else
SCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {
  union {
    float f;
    int32_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {
  union {
    int32_t f;
    float t;
  } p;

  p.f = x;
  return p.t;
}
#endif

SCALAR_FUN_ATTR float fsignum32(float x) {
  return futrts_isnan32(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);
}

#ifdef FUTHARK_F64_ENABLED

SCALAR_FUN_ATTR double futrts_from_bits64(int64_t x);
SCALAR_FUN_ATTR int64_t futrts_to_bits64(double x);

#if ISPC
SCALAR_FUN_ATTR bool futrts_isinf64(float x) {
  return !isnan(x) && isnan(x - x);
}

SCALAR_FUN_ATTR bool futrts_isfinite64(float x) {
  return !isnan(x) && !futrts_isinf64(x);
}

SCALAR_FUN_ATTR double fdiv64(double x, double y) {
  return x / y;
}

SCALAR_FUN_ATTR double fadd64(double x, double y) {
  return x + y;
}

SCALAR_FUN_ATTR double fsub64(double x, double y) {
  return x - y;
}

SCALAR_FUN_ATTR double fmul64(double x, double y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt64(double x, double y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple64(double x, double y) {
  return x <= y;
}

SCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double fabs64(double x) {
  return abs(x);
}

SCALAR_FUN_ATTR double fmax64(double x, double y) {
  return isnan(x) ? y : isnan(y) ? x : max(x, y);
}

SCALAR_FUN_ATTR double fmin64(double x, double y) {
  return isnan(x) ? y : isnan(y) ? x : min(x, y);
}

SCALAR_FUN_ATTR double fpow64(double a, double b) {
  float ret;
  foreach_active (i) {
      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));
      ret = insert(ret, i, r);
  }
  return ret;
}

SCALAR_FUN_ATTR double futrts_log64(double x) {
  return futrts_isfinite64(x) || (futrts_isinf64(x) && x < 0)? log(x) : x;
}

SCALAR_FUN_ATTR double futrts_log2_64(double x) {
  return futrts_log64(x)/log(2.0d);
}

SCALAR_FUN_ATTR double futrts_log10_64(double x) {
  return futrts_log64(x)/log(10.0d);
}

SCALAR_FUN_ATTR double futrts_log1p_64(double x) {
  if(x == -1.0d || (futrts_isinf64(x) && x > 0.0d)) return x / 0.0d;
  double y = 1.0d + x;
  double z = y - 1.0d;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR double futrts_sqrt64(double x) {
  return sqrt(x);
}

extern "C" unmasked uniform double cbrt(uniform double);
SCALAR_FUN_ATTR double futrts_cbrt64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = cbrtf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_exp64(double x) {
  return exp(x);
}

SCALAR_FUN_ATTR double futrts_cos64(double x) {
  return cos(x);
}

SCALAR_FUN_ATTR double futrts_sin64(double x) {
  return sin(x);
}

SCALAR_FUN_ATTR double futrts_tan64(double x) {
  return tan(x);
}

SCALAR_FUN_ATTR double futrts_acos64(double x) {
  return acos(x);
}

SCALAR_FUN_ATTR double futrts_asin64(double x) {
  return asin(x);
}

SCALAR_FUN_ATTR double futrts_atan64(double x) {
  return atan(x);
}

SCALAR_FUN_ATTR double futrts_cosh64(double x) {
  return (exp(x)+exp(-x)) / 2.0d;
}

SCALAR_FUN_ATTR double futrts_sinh64(double x) {
  return (exp(x)-exp(-x)) / 2.0d;
}

SCALAR_FUN_ATTR double futrts_tanh64(double x) {
  return futrts_sinh64(x)/futrts_cosh64(x);
}

SCALAR_FUN_ATTR double futrts_acosh64(double x) {
  double f = x+sqrt(x*x-1.0d);
  if(futrts_isfinite64(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR double futrts_asinh64(double x) {
  double f = x+sqrt(x*x+1.0d);
  if(futrts_isfinite64(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR double futrts_atanh64(double x) {
  double f = (1.0d+x)/(1.0d-x);
  if(futrts_isfinite64(f)) return log(f)/2.0d;
  return f;

}

SCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {
  return atan2(x, y);
}

extern "C" unmasked uniform double hypot(uniform double x, uniform double y);
SCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {
  double res;
  foreach_active (i) {
    uniform double r = hypot(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double tgamma(uniform double x);
SCALAR_FUN_ATTR double futrts_gamma64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = tgamma(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double lgamma(uniform double x);
SCALAR_FUN_ATTR double futrts_lgamma64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = lgamma(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double erf(uniform double x);
SCALAR_FUN_ATTR double futrts_erf64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = erf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double erfc(uniform double x);
SCALAR_FUN_ATTR double futrts_erfc64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = erfc(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {
  return a * b + c;
}

SCALAR_FUN_ATTR double futrts_round64(double x) {
  return round(x);
}

SCALAR_FUN_ATTR double futrts_ceil64(double x) {
  return ceil(x);
}

extern "C" unmasked uniform double nextafter(uniform float x, uniform double y);
SCALAR_FUN_ATTR float futrts_nextafter64(double x, double y) {
  double res;
  foreach_active (i) {
    uniform double r = nextafter(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_floor64(double x) {
  return floor(x);
}

SCALAR_FUN_ATTR bool futrts_isnan64(double x) {
  return isnan(x);
}

SCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int64_t) x;
  }
}

SCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f64_bool(double x) {
  return x != 0.0;
}

SCALAR_FUN_ATTR double btof_bool_f64(bool x) {
  return x ? 1.0 : 0.0;
}

SCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {
  int64_t res;
  foreach_active (i) {
    uniform double tmp = extract(x, i);
    uniform int64_t r = *((uniform int64_t* uniform)&tmp);
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {
  double res;
  foreach_active (i) {
    uniform int64_t tmp = extract(x, i);
    uniform double r = *((uniform double* uniform)&tmp);
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double fmod64(double x, double y) {
  return x - y * trunc(x/y);
}

SCALAR_FUN_ATTR double fsignum64(double x) {
  return futrts_isnan64(x) ? x : (x > 0 ? 1.0d : 0.0d) - (x < 0 ? 1.0d : 0.0d);
}

SCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {
  return x * pow((double)2.0, (double)y);
}

SCALAR_FUN_ATTR double futrts_copysign64(double x, double y) {
  int64_t xb = futrts_to_bits64(x);
  int64_t yb = futrts_to_bits64(y);
  return futrts_from_bits64((xb & ~(((int64_t)1)<<63)) | (yb & (((int64_t)1)<<63)));
}

SCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float fpconv_f32_f32(float x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f32_f64(float x) {
  return (double) x;
}

SCALAR_FUN_ATTR float fpconv_f64_f32(double x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f64_f64(double x) {
  return (double) x;
}

#else

SCALAR_FUN_ATTR double fdiv64(double x, double y) {
  return x / y;
}

SCALAR_FUN_ATTR double fadd64(double x, double y) {
  return x + y;
}

SCALAR_FUN_ATTR double fsub64(double x, double y) {
  return x - y;
}

SCALAR_FUN_ATTR double fmul64(double x, double y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt64(double x, double y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple64(double x, double y) {
  return x <= y;
}

SCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double fabs64(double x) {
  return fabs(x);
}

SCALAR_FUN_ATTR double fmax64(double x, double y) {
  return fmax(x, y);
}

SCALAR_FUN_ATTR double fmin64(double x, double y) {
  return fmin(x, y);
}

SCALAR_FUN_ATTR double fpow64(double x, double y) {
  return pow(x, y);
}

SCALAR_FUN_ATTR double futrts_log64(double x) {
  return log(x);
}

SCALAR_FUN_ATTR double futrts_log2_64(double x) {
  return log2(x);
}

SCALAR_FUN_ATTR double futrts_log10_64(double x) {
  return log10(x);
}

SCALAR_FUN_ATTR double futrts_log1p_64(double x) {
  return log1p(x);
}

SCALAR_FUN_ATTR double futrts_sqrt64(double x) {
  return sqrt(x);
}

SCALAR_FUN_ATTR double futrts_cbrt64(double x) {
  return cbrt(x);
}

SCALAR_FUN_ATTR double futrts_exp64(double x) {
  return exp(x);
}

SCALAR_FUN_ATTR double futrts_cos64(double x) {
  return cos(x);
}

SCALAR_FUN_ATTR double futrts_sin64(double x) {
  return sin(x);
}

SCALAR_FUN_ATTR double futrts_tan64(double x) {
  return tan(x);
}

SCALAR_FUN_ATTR double futrts_acos64(double x) {
  return acos(x);
}

SCALAR_FUN_ATTR double futrts_asin64(double x) {
  return asin(x);
}

SCALAR_FUN_ATTR double futrts_atan64(double x) {
  return atan(x);
}

SCALAR_FUN_ATTR double futrts_cosh64(double x) {
  return cosh(x);
}

SCALAR_FUN_ATTR double futrts_sinh64(double x) {
  return sinh(x);
}

SCALAR_FUN_ATTR double futrts_tanh64(double x) {
  return tanh(x);
}

SCALAR_FUN_ATTR double futrts_acosh64(double x) {
  return acosh(x);
}

SCALAR_FUN_ATTR double futrts_asinh64(double x) {
  return asinh(x);
}

SCALAR_FUN_ATTR double futrts_atanh64(double x) {
  return atanh(x);
}

SCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {
  return atan2(x, y);
}

SCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {
  return hypot(x, y);
}

SCALAR_FUN_ATTR double futrts_gamma64(double x) {
  return tgamma(x);
}

SCALAR_FUN_ATTR double futrts_lgamma64(double x) {
  return lgamma(x);
}

SCALAR_FUN_ATTR double futrts_erf64(double x) {
  return erf(x);
}

SCALAR_FUN_ATTR double futrts_erfc64(double x) {
  return erfc(x);
}

SCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {
  return fma(a, b, c);
}

SCALAR_FUN_ATTR double futrts_round64(double x) {
  return rint(x);
}

SCALAR_FUN_ATTR double futrts_ceil64(double x) {
  return ceil(x);
}

SCALAR_FUN_ATTR float futrts_nextafter64(float x, float y) {
  return nextafter(x, y);
}

SCALAR_FUN_ATTR double futrts_floor64(double x) {
  return floor(x);
}

SCALAR_FUN_ATTR bool futrts_isnan64(double x) {
  return isnan(x);
}

SCALAR_FUN_ATTR bool futrts_isinf64(double x) {
  return isinf(x);
}

SCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int64_t) x;
  }
}

SCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f64_bool(double x) {
  return x != 0;
}

SCALAR_FUN_ATTR double btof_bool_f64(bool x) {
  return x ? 1 : 0;
}

SCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {
  union {
    double f;
    int64_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {
  union {
    int64_t f;
    double t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR double fmod64(double x, double y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR double fsignum64(double x) {
  return futrts_isnan64(x) ? x : (x > 0) - (x < 0);
}

SCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {
#ifdef __OPENCL_VERSION__
  return mix(v0, v1, t);
#else
  return v0 + (v1 - v0) * t;
#endif
}

SCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {
  return ldexp(x, y);
}

SCALAR_FUN_ATTR float futrts_copysign64(double x, double y) {
  return copysign(x, y);
}

SCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {
#ifdef __OPENCL_VERSION__
  return mad(a, b, c);
#else
  return a * b + c;
#endif
}

SCALAR_FUN_ATTR float fpconv_f32_f32(float x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f32_f64(float x) {
  return (double) x;
}

SCALAR_FUN_ATTR float fpconv_f64_f32(double x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f64_f64(double x) {
  return (double) x;
}

#endif

#endif

// End of scalar.h.
// Start of scalar_f16.h.

// Half-precision is emulated if needed (e.g. in straight C) with the
// native type used if possible.  The emulation works by typedef'ing
// 'float' to 'f16', and then implementing all operations on single
// precision.  To cut down on duplication, we use the same code for
// those Futhark functions that require just operators or casts.  The
// in-memory representation for arrays will still be 16 bits even
// under emulation, so the compiler will have to be careful when
// generating reads or writes.

#if !defined(cl_khr_fp16) && !(defined(__CUDA_ARCH__) && __CUDA_ARCH__ >= 600) && !(defined(ISPC))
#define EMULATE_F16
#endif

#if !defined(EMULATE_F16) && defined(__OPENCL_VERSION__)
#pragma OPENCL EXTENSION cl_khr_fp16 : enable
#endif

#ifdef EMULATE_F16

// Note that the half-precision storage format is still 16 bits - the
// compiler will have to be real careful!
typedef float f16;

#elif ISPC
typedef float16 f16;

#else

#ifdef __CUDA_ARCH__
#include <cuda_fp16.h>
#endif

typedef half f16;

#endif

// Some of these functions convert to single precision because half
// precision versions are not available.

SCALAR_FUN_ATTR f16 fadd16(f16 x, f16 y) {
  return x + y;
}

SCALAR_FUN_ATTR f16 fsub16(f16 x, f16 y) {
  return x - y;
}

SCALAR_FUN_ATTR f16 fmul16(f16 x, f16 y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt16(f16 x, f16 y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple16(f16 x, f16 y) {
  return x <= y;
}

SCALAR_FUN_ATTR f16 sitofp_i8_f16(int8_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 sitofp_i16_f16(int16_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 sitofp_i32_f16(int32_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 sitofp_i64_f16(int64_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i8_f16(uint8_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i16_f16(uint16_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i32_f16(uint32_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i64_f16(uint64_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR int8_t fptosi_f16_i8(f16 x) {
  return (int8_t) (float) x;
}

SCALAR_FUN_ATTR int16_t fptosi_f16_i16(f16 x) {
  return (int16_t) x;
}

SCALAR_FUN_ATTR int32_t fptosi_f16_i32(f16 x) {
  return (int32_t) x;
}

SCALAR_FUN_ATTR int64_t fptosi_f16_i64(f16 x) {
  return (int64_t) x;
}

SCALAR_FUN_ATTR uint8_t fptoui_f16_i8(f16 x) {
  return (uint8_t) (float) x;
}

SCALAR_FUN_ATTR uint16_t fptoui_f16_i16(f16 x) {
  return (uint16_t) x;
}

SCALAR_FUN_ATTR uint32_t fptoui_f16_i32(f16 x) {
  return (uint32_t) x;
}

SCALAR_FUN_ATTR uint64_t fptoui_f16_i64(f16 x) {
  return (uint64_t) x;
}

SCALAR_FUN_ATTR bool ftob_f16_bool(f16 x) {
  return x != (f16)0;
}

SCALAR_FUN_ATTR f16 btof_bool_f16(bool x) {
  return x ? 1 : 0;
}

#ifndef EMULATE_F16
SCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {
  return isnan((float)x);
}

#ifdef __OPENCL_VERSION__

SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return fabs(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return fmax(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return fmin(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return pow(x, y);
}

#elif ISPC
SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return abs(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : max(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : min(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return pow(x, y);
}

#else // Assuming CUDA.

SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return fabsf(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return fmaxf(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return fminf(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return powf(x, y);
}
#endif

#if ISPC
SCALAR_FUN_ATTR bool futrts_isinf16(float x) {
  return !futrts_isnan16(x) && futrts_isnan16(x - x);
}
SCALAR_FUN_ATTR bool futrts_isfinite16(float x) {
  return !futrts_isnan16(x) && !futrts_isinf16(x);
}

#else

SCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {
  return isinf((float)x);
}
#endif

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return log(x);
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return log2(x);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return log10(x);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  return log1p(x);
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return sqrt(x);
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  return cbrt(x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return exp(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return cos(x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return sin(x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return tan(x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return acos(x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return asin(x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return atan(x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return cosh(x);
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return sinh(x);
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return tanh(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  return acosh(x);
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  return asinh(x);
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  return atanh(x);
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return atan2(x, y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return hypot(x, y);
}

SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  return tgamma(x);
}

SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  return lgamma(x);
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  return erf(x);
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  return erfc(x);
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return rint(x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return floor(x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return ceil(x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return nextafter(x, y);
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return mix(v0, v1, t);
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return ldexp(x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return copysign(x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return mad(a, b, c);
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return fma(a, b, c);
}
#elif ISPC

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return futrts_isfinite16(x) || (futrts_isinf16(x) && x < 0) ? log(x) : x;
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return futrts_log16(x) / log(2.0f16);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return futrts_log16(x) / log(10.0f16);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  if(x == -1.0f16 || (futrts_isinf16(x) && x > 0.0f16)) return x / 0.0f16;
  f16 y = 1.0f16 + x;
  f16 z = y - 1.0f16;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return (float16)sqrt((float)x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return exp(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return (float16)cos((float)x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return (float16)sin((float)x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return (float16)tan((float)x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return (float16)acos((float)x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return (float16)asin((float)x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return (float16)atan((float)x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return (exp(x)+exp(-x)) / 2.0f16;
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return (exp(x)-exp(-x)) / 2.0f16;
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return futrts_sinh16(x)/futrts_cosh16(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  float16 f = x+(float16)sqrt((float)(x*x-1));
  if(futrts_isfinite16(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  float16 f = x+(float16)sqrt((float)(x*x+1));
  if(futrts_isfinite16(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  float16 f = (1+x)/(1-x);
  if(futrts_isfinite16(f)) return log(f)/2.0f16;
  return f;
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return (float16)atan2((float)x, (float)y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return (float16)futrts_hypot32((float)x, (float)y);
}

extern "C" unmasked uniform float tgammaf(uniform float x);
SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  f16 res;
  foreach_active (i) {
    uniform f16 r = (f16)tgammaf(extract((float)x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float lgammaf(uniform float x);
SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  f16 res;
  foreach_active (i) {
    uniform f16 r = (f16)lgammaf(extract((float)x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  f16 res = (f16)futrts_cbrt32((float)x);
  return res;
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  f16 res = (f16)futrts_erf32((float)x);
  return res;
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  f16 res = (f16)futrts_erfc32((float)x);
  return res;
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return x - y * (float16)trunc((float) (x/y));
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return (float16)round((float)x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return (float16)floor((float)x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return (float16)ceil((float)x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return (float16)futrts_nextafter32((float)x, (float) y);
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return futrts_ldexp32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return futrts_copysign32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

#else // Assume CUDA.

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return hlog(x);
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return hlog2(x);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return hlog10(x);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  return (f16)log1pf((float)x);
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return hsqrt(x);
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  return cbrtf(x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return hexp(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return hcos(x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return hsin(x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return tanf(x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return acosf(x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return asinf(x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return atanf(x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return coshf(x);
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return sinhf(x);
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return tanhf(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  return acoshf(x);
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  return asinhf(x);
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  return atanhf(x);
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return atan2f(x, y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return hypotf(x, y);
}

SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  return tgammaf(x);
}

SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  return lgammaf(x);
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  return erff(x);
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  return erfcf(x);
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return fmodf(x, y);
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return rintf(x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return hfloor(x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return hceil(x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return __ushort_as_half(halfbitsnextafter(__half_as_ushort(x), __half_as_ushort(y)));
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return futrts_ldexp32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return futrts_copysign32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return fmaf(a, b, c);
}

#endif

// The CUDA __half type cannot be put in unions for some reason, so we
// use bespoke conversion functions instead.
#ifdef __CUDA_ARCH__
SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  return __half_as_ushort(x);
}
SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  return __ushort_as_half(x);
}
#elif ISPC

SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  varying int16_t y = *((varying int16_t * uniform)&x);
  return y;
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  varying f16 y = *((varying f16 * uniform)&x);
  return y;
}
#else
SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  union {
    f16 f;
    int16_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  union {
    int16_t f;
    f16 t;
  } p;

  p.f = x;
  return p.t;
}
#endif

#else // No native f16 - emulate.

SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return fabs32(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return fmax32(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return fmin32(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return fpow32(x, y);
}

SCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {
  return futrts_isnan32(x);
}

SCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {
  return futrts_isinf32(x);
}

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return futrts_log32(x);
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return futrts_log2_32(x);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return futrts_log10_32(x);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  return futrts_log1p_32(x);
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return futrts_sqrt32(x);
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  return futrts_cbrt32(x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return futrts_exp32(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return futrts_cos32(x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return futrts_sin32(x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return futrts_tan32(x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return futrts_acos32(x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return futrts_asin32(x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return futrts_atan32(x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return futrts_cosh32(x);
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return futrts_sinh32(x);
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return futrts_tanh32(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  return futrts_acosh32(x);
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  return futrts_asinh32(x);
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  return futrts_atanh32(x);
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return futrts_atan2_32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return futrts_hypot32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  return futrts_gamma32(x);
}

SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  return futrts_lgamma32(x);
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  return futrts_erf32(x);
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  return futrts_erfc32(x);
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return fmod32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return futrts_round32(x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return futrts_floor32(x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return futrts_ceil32(x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return halfbits2float(halfbitsnextafter(float2halfbits(x), float2halfbits(y)));
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return futrts_lerp32(v0, v1, t);
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return futrts_ldexp32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return futrts_copysign32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return futrts_mad32(a, b, c);
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return futrts_fma32(a, b, c);
}

// Even when we are using an OpenCL that does not support cl_khr_fp16,
// it must still support vload_half for actually creating a
// half-precision number, which can then be efficiently converted to a
// float.  Similarly for vstore_half.
#ifdef __OPENCL_VERSION__

SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  int16_t y;
  // Violating strict aliasing here.
  vstore_half((float)x, 0, (half*)&y);
  return y;
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  return (f16)vload_half(0, (half*)&x);
}

#else

SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  return (int16_t)float2halfbits(x);
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  return halfbits2float((uint16_t)x);
}

SCALAR_FUN_ATTR f16 fsignum16(f16 x) {
  return futrts_isnan16(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);
}

#endif

#endif

SCALAR_FUN_ATTR float fpconv_f16_f16(f16 x) {
  return x;
}

SCALAR_FUN_ATTR float fpconv_f16_f32(f16 x) {
  return x;
}

SCALAR_FUN_ATTR f16 fpconv_f32_f16(float x) {
  return (f16) x;
}

#ifdef FUTHARK_F64_ENABLED

SCALAR_FUN_ATTR double fpconv_f16_f64(f16 x) {
  return (double) x;
}

#if ISPC
SCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {
  return (f16) ((float)x);
}
#else
SCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {
  return (f16) x;
}
#endif
#endif


// End of scalar_f16.h.

// Start of context_prototypes.h
//
// Prototypes for the functions in context.h, or that will be called
// from those functions, that need to be available very early.

struct futhark_context_config;
struct futhark_context;

static void set_error(struct futhark_context* ctx, char *error);

// These are called in context/config new/free functions and contain
// shared setup.  They are generated by the compiler itself.
static int init_constants(struct futhark_context*);
static int free_constants(struct futhark_context*);
static void setup_program(struct futhark_context* ctx);
static void teardown_program(struct futhark_context *ctx);

// Allocate host memory.  Must be freed with host_free().
static void host_alloc(struct futhark_context* ctx, size_t size, const char* tag, size_t* size_out, void** mem_out);
// Allocate memory allocated with host_alloc().
static void host_free(struct futhark_context* ctx, size_t size, const char* tag, void* mem);

// Log that a copy has occurred.
static void log_copy(struct futhark_context* ctx,
                     const char *kind, int r,
                     int64_t dst_offset, int64_t dst_strides[r],
                     int64_t src_offset, int64_t src_strides[r],
                     int64_t shape[r]);

static void log_transpose(struct futhark_context* ctx,
                          int64_t k, int64_t m, int64_t n);

static bool lmad_map_tr(int64_t *num_arrays_out, int64_t *n_out, int64_t *m_out,
                        int r,
                        const int64_t dst_strides[r],
                        const int64_t src_strides[r],
                        const int64_t shape[r]);

static bool lmad_contiguous(int r, int64_t strides[r], int64_t shape[r]);

static bool lmad_memcpyable(int r,
                            int64_t dst_strides[r], int64_t src_strides[r], int64_t shape[r]);

static void add_event(struct futhark_context* ctx,
                      const char* name,
                      char* description,
                      void* data,
                      event_report_fn f);

// Functions that must be defined by the backend.
static void backend_context_config_setup(struct futhark_context_config* cfg);
static void backend_context_config_teardown(struct futhark_context_config* cfg);
static int backend_context_setup(struct futhark_context *ctx);
static void backend_context_teardown(struct futhark_context *ctx);

// End of of context_prototypes.h

struct memblock_device {
    int *references;
    CUdeviceptr mem;
    int64_t size;
    const char *desc;
};
struct memblock {
    int *references;
    unsigned char *mem;
    int64_t size;
    const char *desc;
};
struct constants {
    int dummy;
    struct memblock_device global_dynid_mem_27424;
    struct memblock_device global_dynid_mem_27545;
};
struct tuning_params {
    int dummy;
    int64_t *builtinzhiota_i64zitblock_sizze_27024;
    int64_t *builtinzhreplicate_i32zitblock_sizze_27053;
    int64_t *builtinzhreplicate_i64zitblock_sizze_27027;
    int64_t *builtinzhreplicate_i8zitblock_sizze_27409;
    int64_t *inner_SMJ_intzisegmap_num_tblocks_24589;
    int64_t *inner_SMJ_intzisegmap_num_tblocks_24631;
    int64_t *inner_SMJ_intzisegmap_num_tblocks_24639;
    int64_t *inner_SMJ_intzisegmap_tblock_sizze_23529;
    int64_t *inner_SMJ_intzisegmap_tblock_sizze_23946;
    int64_t *inner_SMJ_intzisegmap_tblock_sizze_24453;
    int64_t *inner_SMJ_intzisegmap_tblock_sizze_24475;
    int64_t *inner_SMJ_intzisegmap_tblock_sizze_24495;
    int64_t *inner_SMJ_intzisegmap_tblock_sizze_24517;
    int64_t *inner_SMJ_intzisegmap_tblock_sizze_24537;
    int64_t *inner_SMJ_intzisegmap_tblock_sizze_24559;
    int64_t *inner_SMJ_intzisegmap_tblock_sizze_24587;
    int64_t *inner_SMJ_intzisegmap_tblock_sizze_24603;
    int64_t *inner_SMJ_intzisegmap_tblock_sizze_24629;
    int64_t *inner_SMJ_intzisegmap_tblock_sizze_24637;
    int64_t *inner_SMJ_intzisegmap_tblock_sizze_24645;
    int64_t *inner_SMJ_intzisegscan_num_tblocks_24579;
    int64_t *inner_SMJ_intzisegscan_num_tblocks_24595;
    int64_t *inner_SMJ_intzisegscan_tblock_sizze_24577;
    int64_t *inner_SMJ_intzisegscan_tblock_sizze_24593;
    int64_t *inner_SMJ_intzisuff_outer_par_0;
    int64_t *inner_SMJ_intzisuff_outer_par_1;
    int64_t *inner_SMJ_intzitblock_sizze_27759;
    int64_t *inner_SMJ_intzitblock_sizze_27779;
    int64_t *inner_SMJ_intzitile_sizze_24676;
    int64_t *inner_SMJ_intzitile_sizze_25031;
    int64_t *inner_SMJ_intzitile_sizze_25386;
    int64_t *inner_SMJ_intzitile_sizze_25741;
};
static const int num_tuning_params = 32;
static const char *tuning_param_names[] = {"builtin#iota_i64.tblock_size_27024", "builtin#replicate_i32.tblock_size_27053", "builtin#replicate_i64.tblock_size_27027", "builtin#replicate_i8.tblock_size_27409", "inner_SMJ_int.segmap_num_tblocks_24589", "inner_SMJ_int.segmap_num_tblocks_24631", "inner_SMJ_int.segmap_num_tblocks_24639", "inner_SMJ_int.segmap_tblock_size_23529", "inner_SMJ_int.segmap_tblock_size_23946", "inner_SMJ_int.segmap_tblock_size_24453", "inner_SMJ_int.segmap_tblock_size_24475", "inner_SMJ_int.segmap_tblock_size_24495", "inner_SMJ_int.segmap_tblock_size_24517", "inner_SMJ_int.segmap_tblock_size_24537", "inner_SMJ_int.segmap_tblock_size_24559", "inner_SMJ_int.segmap_tblock_size_24587", "inner_SMJ_int.segmap_tblock_size_24603", "inner_SMJ_int.segmap_tblock_size_24629", "inner_SMJ_int.segmap_tblock_size_24637", "inner_SMJ_int.segmap_tblock_size_24645", "inner_SMJ_int.segscan_num_tblocks_24579", "inner_SMJ_int.segscan_num_tblocks_24595", "inner_SMJ_int.segscan_tblock_size_24577", "inner_SMJ_int.segscan_tblock_size_24593", "inner_SMJ_int.suff_outer_par_0", "inner_SMJ_int.suff_outer_par_1", "inner_SMJ_int.tblock_size_27759", "inner_SMJ_int.tblock_size_27779", "inner_SMJ_int.tile_size_24676", "inner_SMJ_int.tile_size_25031", "inner_SMJ_int.tile_size_25386", "inner_SMJ_int.tile_size_25741", NULL};
static const char *tuning_param_vars[] = {"builtinzhiota_i64zitblock_sizze_27024", "builtinzhreplicate_i32zitblock_sizze_27053", "builtinzhreplicate_i64zitblock_sizze_27027", "builtinzhreplicate_i8zitblock_sizze_27409", "inner_SMJ_intzisegmap_num_tblocks_24589", "inner_SMJ_intzisegmap_num_tblocks_24631", "inner_SMJ_intzisegmap_num_tblocks_24639", "inner_SMJ_intzisegmap_tblock_sizze_23529", "inner_SMJ_intzisegmap_tblock_sizze_23946", "inner_SMJ_intzisegmap_tblock_sizze_24453", "inner_SMJ_intzisegmap_tblock_sizze_24475", "inner_SMJ_intzisegmap_tblock_sizze_24495", "inner_SMJ_intzisegmap_tblock_sizze_24517", "inner_SMJ_intzisegmap_tblock_sizze_24537", "inner_SMJ_intzisegmap_tblock_sizze_24559", "inner_SMJ_intzisegmap_tblock_sizze_24587", "inner_SMJ_intzisegmap_tblock_sizze_24603", "inner_SMJ_intzisegmap_tblock_sizze_24629", "inner_SMJ_intzisegmap_tblock_sizze_24637", "inner_SMJ_intzisegmap_tblock_sizze_24645", "inner_SMJ_intzisegscan_num_tblocks_24579", "inner_SMJ_intzisegscan_num_tblocks_24595", "inner_SMJ_intzisegscan_tblock_sizze_24577", "inner_SMJ_intzisegscan_tblock_sizze_24593", "inner_SMJ_intzisuff_outer_par_0", "inner_SMJ_intzisuff_outer_par_1", "inner_SMJ_intzitblock_sizze_27759", "inner_SMJ_intzitblock_sizze_27779", "inner_SMJ_intzitile_sizze_24676", "inner_SMJ_intzitile_sizze_25031", "inner_SMJ_intzitile_sizze_25386", "inner_SMJ_intzitile_sizze_25741", NULL};
static const char *tuning_param_classes[] = {"thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "threshold(def, )", "threshold(def, )", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", NULL};
static int64_t tuning_param_defaults[] = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
static const int max_failure_args = 2;
static const int f64_required = 0;
static const char *gpu_program[] = {"#define FUTHARK_CUDA\n// start of prelude.cu\n\n#define SCALAR_FUN_ATTR __device__ static inline\n#define FUTHARK_FUN_ATTR __device__ static\n#define FUTHARK_F64_ENABLED\n\ntypedef char int8_t;\ntypedef short int16_t;\ntypedef int int32_t;\ntypedef long long int64_t;\ntypedef unsigned char uint8_t;\ntypedef unsigned short uint16_t;\ntypedef unsigned int uint32_t;\ntypedef unsigned long long uint64_t;\n\n#define __global\n#define __local\n#define __private\n#define __constant\n#define __write_only\n#define __read_only\n\nstatic inline __device__ int get_tblock_id(int d) {\n  switch (d) {\n  case 0: return blockIdx.x;\n  case 1: return blockIdx.y;\n  case 2: return blockIdx.z;\n  default: return 0;\n  }\n}\n\nstatic inline __device__ int get_num_tblocks(int d) {\n  switch(d) {\n  case 0: return gridDim.x;\n  case 1: return gridDim.y;\n  case 2: return gridDim.z;\n  default: return 0;\n  }\n}\n\nstatic inline __device__ int get_global_id(int d) {\n  switch (d) {\n    case 0: return threadIdx.x + blockIdx.x * blockDim.x;\n    case 1: return threadIdx.y + blockIdx.y * blockDim.y;\n    case 2: return threadIdx.z + blockIdx.z * blockDim.z;\n    default: return 0;\n  }\n}\n\nstatic inline __device__ int get_local_id(int d) {\n  switch (d) {\n    case 0: return threadIdx.x;\n    case 1: return threadIdx.y;\n    case 2: return threadIdx.z;\n    default: return 0;\n  }\n}\n\nstatic inline __device__ int get_local_size(int d) {\n  switch (d) {\n    case 0: return blockDim.x;\n    case 1: return blockDim.y;\n    case 2: return blockDim.z;\n    default: return 0;\n  }\n}\n\nstatic inline __device__ int get_global_size(int d) {\n  switch (d) {\n    case 0: return gridDim.x * blockDim.x;\n    case 1: return gridDim.y * blockDim.y;\n    case 2: return gridDim.z * blockDim.z;\n    default: return 0;\n  }\n}\n\n\n#define CLK_LOCAL_MEM_FENCE 1\n#define CLK_GLOBAL_MEM_FENCE 2\nstatic inline __device__ void barrier(int x) {\n  __syncthreads();\n}\nstatic inline __device__ void mem_fence_local() {\n  __threadfence_block();\n}\nstatic inline __device__ void mem_fence_global", "() {\n  __threadfence();\n}\n\nstatic inline __device__ void barrier_local() {\n  __syncthreads();\n}\n\n#define NAN (0.0/0.0)\n#define INFINITY (1.0/0.0)\nextern volatile __shared__ unsigned char shared_mem[];\n\n#define SHARED_MEM_PARAM\n#define FUTHARK_KERNEL extern \"C\" __global__ __launch_bounds__(MAX_THREADS_PER_BLOCK)\n#define FUTHARK_KERNEL_SIZED(a,b,c) extern \"C\" __global__ __launch_bounds__(a*b*c)\n\n// End of prelude.cu\n// Start of half.h.\n\n// Conversion functions are from http://half.sourceforge.net/, but\n// translated to C.\n//\n// Copyright (c) 2012-2021 Christian Rau\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in\n// all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n// THE SOFTWARE.\n\n#ifndef __OPENCL_VERSION__\n#define __constant\n#endif\n\n__constant static const uint16_t base_table[512] = {\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0", "000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0001, 0x0002, 0x0004, 0x0008, 0x0010, 0x0020, 0x0040, 0x0080, 0x0100,\n  0x0200, 0x0400, 0x0800, 0x0C00, 0x1000, 0x1400, 0x1800, 0x1C00, 0x2000, 0x2400, 0x2800, 0x2C00, 0x3000, 0x3400, 0x3800, 0x3C00,\n  0x4000, 0x4400, 0x4800, 0x4C00, 0x5000, 0x5400, 0x5800, 0x5C00, 0x6000, 0x6400, 0x6800, 0x6C00, 0x7000, 0x7400, 0x7800, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8",
                                    "000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8001, 0x8002, 0x8004, 0x8008, 0x8010, 0x8020, 0x8040, 0x8080, 0x8100,\n  0x8200, 0x8400, 0x8800, 0x8C00, 0x9000, 0x9400, 0x9800, 0x9C00, 0xA000, 0xA400, 0xA800, 0xAC00, 0xB000, 0xB400, 0xB800, 0xBC00,\n  0xC000, 0xC400, 0xC800, 0xCC00, 0xD000, 0xD400, 0xD800, 0xDC00, 0xE000, 0xE400, 0xE800, 0xEC00, 0xF000, 0xF400, 0xF800, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00 };\n\n__constant static const unsigned char shift_table[512] = {\n  24, 24, 24, 24, 24, 24,", " 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 2", "4, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13 };\n\n__constant static const uint32_t mantissa_table[2048] = {\n  0x00000000, 0x33800000, 0x34000000, 0x34400000, 0x34800000, 0x34A00000, 0x34C00000, 0x34E00000, 0x35000000, 0x35100000, 0x35200000, 0x35300000, 0x35400000, 0x35500000, 0x35600000, 0x35700000,\n  0x35800000, 0x35880000, 0x35900000, 0x35980000, 0x35A00000, 0x35A80000, 0x35B00000, 0x35B80000, 0x35C00000, 0x35C80000, 0x35D00000, 0x35D80000, 0x35E00000, 0x35E80000, 0x35F00000, 0x35F80000,\n  0x36000000, 0x36040000, 0x36080000, 0x360C0000, 0x36100000, 0x36140000, 0x36180000, 0x361C0000, 0x36200000, 0x36240000, 0x36280000, 0x362C0000, 0x36300000, 0x36340000, 0x36380000, 0x363C0000,\n  0x36400000, 0x36440000, 0x36480000, 0x364C0000, 0x36500000, 0x36540000, 0x36580000, 0x365C0000, 0x36600000, 0x36640000, 0x36680000, 0x366C0000, 0x36700000, 0x36740000, 0x36780000, 0x367C0000,\n  0x36800000, 0x36820000, 0x36840000, 0x36860000, 0x36880000, 0x368A0000, 0x368C0000, 0x368E0000, 0x36900000, 0x36920000, 0x36940000, 0x36960000, 0x36980000, 0x369A0000, 0x369C0000, 0x369E0000,\n  0x36A00000, 0x36A20000, 0x36A40000, 0x36A60000, 0x36A80000, 0x36AA0000, 0x36AC0000, 0x36AE0000, 0x36B00000, 0x36B20000, 0x36B40000, 0x36B60000, 0x36B80000, 0x36BA0000, 0x36BC0000, 0x36BE0000,\n  0x36C00000, 0x36C20000, 0x36C40000, 0x36C60000, 0x36C80000, 0x36CA0000, 0x36CC0000, 0x36CE0000, 0x36D00000, 0x36D20000, 0x36D40000, 0x36D60000, 0x36D80000, 0x36DA0000, 0x36DC0000, 0x36DE0000,\n  0x36E00000, 0x36E20000, 0x36E40000, 0x36E60000, 0x36E80000, 0x36EA0000, 0x36EC0000, 0x36EE0000, 0x36F00000, 0x36F20000, 0x36F40000, 0x36F60000, 0x36F80000, 0x36FA0000, 0x36FC0000, 0x36FE0000,\n  0x37000000, 0x37010000, 0x37020000, 0x37030000, 0x37040000, 0x37050000, 0x37060000, 0x37070000, 0x37080000, 0x37090000, 0x370A0000, 0x370B0000, 0x370C0000, 0x370D0000, 0x370E0000, 0x370F0000,\n  0x37100000, 0x37110000, 0x37120000, 0x37130000, 0x37140000, 0x37150000, 0x37160000, 0x37170000, 0x37180000, 0x37190000, 0x371A0000, 0x37",
                                    "1B0000, 0x371C0000, 0x371D0000, 0x371E0000, 0x371F0000,\n  0x37200000, 0x37210000, 0x37220000, 0x37230000, 0x37240000, 0x37250000, 0x37260000, 0x37270000, 0x37280000, 0x37290000, 0x372A0000, 0x372B0000, 0x372C0000, 0x372D0000, 0x372E0000, 0x372F0000,\n  0x37300000, 0x37310000, 0x37320000, 0x37330000, 0x37340000, 0x37350000, 0x37360000, 0x37370000, 0x37380000, 0x37390000, 0x373A0000, 0x373B0000, 0x373C0000, 0x373D0000, 0x373E0000, 0x373F0000,\n  0x37400000, 0x37410000, 0x37420000, 0x37430000, 0x37440000, 0x37450000, 0x37460000, 0x37470000, 0x37480000, 0x37490000, 0x374A0000, 0x374B0000, 0x374C0000, 0x374D0000, 0x374E0000, 0x374F0000,\n  0x37500000, 0x37510000, 0x37520000, 0x37530000, 0x37540000, 0x37550000, 0x37560000, 0x37570000, 0x37580000, 0x37590000, 0x375A0000, 0x375B0000, 0x375C0000, 0x375D0000, 0x375E0000, 0x375F0000,\n  0x37600000, 0x37610000, 0x37620000, 0x37630000, 0x37640000, 0x37650000, 0x37660000, 0x37670000, 0x37680000, 0x37690000, 0x376A0000, 0x376B0000, 0x376C0000, 0x376D0000, 0x376E0000, 0x376F0000,\n  0x37700000, 0x37710000, 0x37720000, 0x37730000, 0x37740000, 0x37750000, 0x37760000, 0x37770000, 0x37780000, 0x37790000, 0x377A0000, 0x377B0000, 0x377C0000, 0x377D0000, 0x377E0000, 0x377F0000,\n  0x37800000, 0x37808000, 0x37810000, 0x37818000, 0x37820000, 0x37828000, 0x37830000, 0x37838000, 0x37840000, 0x37848000, 0x37850000, 0x37858000, 0x37860000, 0x37868000, 0x37870000, 0x37878000,\n  0x37880000, 0x37888000, 0x37890000, 0x37898000, 0x378A0000, 0x378A8000, 0x378B0000, 0x378B8000, 0x378C0000, 0x378C8000, 0x378D0000, 0x378D8000, 0x378E0000, 0x378E8000, 0x378F0000, 0x378F8000,\n  0x37900000, 0x37908000, 0x37910000, 0x37918000, 0x37920000, 0x37928000, 0x37930000, 0x37938000, 0x37940000, 0x37948000, 0x37950000, 0x37958000, 0x37960000, 0x37968000, 0x37970000, 0x37978000,\n  0x37980000, 0x37988000, 0x37990000, 0x37998000, 0x379A0000, 0x379A8000, 0x379B0000, 0x379B8000, 0x379C0000, 0x379C8000, 0x379D0000, 0x379D8000, 0x379E0000, 0x379E8000, 0x379F0000, 0x379F8000,\n  0x", "37A00000, 0x37A08000, 0x37A10000, 0x37A18000, 0x37A20000, 0x37A28000, 0x37A30000, 0x37A38000, 0x37A40000, 0x37A48000, 0x37A50000, 0x37A58000, 0x37A60000, 0x37A68000, 0x37A70000, 0x37A78000,\n  0x37A80000, 0x37A88000, 0x37A90000, 0x37A98000, 0x37AA0000, 0x37AA8000, 0x37AB0000, 0x37AB8000, 0x37AC0000, 0x37AC8000, 0x37AD0000, 0x37AD8000, 0x37AE0000, 0x37AE8000, 0x37AF0000, 0x37AF8000,\n  0x37B00000, 0x37B08000, 0x37B10000, 0x37B18000, 0x37B20000, 0x37B28000, 0x37B30000, 0x37B38000, 0x37B40000, 0x37B48000, 0x37B50000, 0x37B58000, 0x37B60000, 0x37B68000, 0x37B70000, 0x37B78000,\n  0x37B80000, 0x37B88000, 0x37B90000, 0x37B98000, 0x37BA0000, 0x37BA8000, 0x37BB0000, 0x37BB8000, 0x37BC0000, 0x37BC8000, 0x37BD0000, 0x37BD8000, 0x37BE0000, 0x37BE8000, 0x37BF0000, 0x37BF8000,\n  0x37C00000, 0x37C08000, 0x37C10000, 0x37C18000, 0x37C20000, 0x37C28000, 0x37C30000, 0x37C38000, 0x37C40000, 0x37C48000, 0x37C50000, 0x37C58000, 0x37C60000, 0x37C68000, 0x37C70000, 0x37C78000,\n  0x37C80000, 0x37C88000, 0x37C90000, 0x37C98000, 0x37CA0000, 0x37CA8000, 0x37CB0000, 0x37CB8000, 0x37CC0000, 0x37CC8000, 0x37CD0000, 0x37CD8000, 0x37CE0000, 0x37CE8000, 0x37CF0000, 0x37CF8000,\n  0x37D00000, 0x37D08000, 0x37D10000, 0x37D18000, 0x37D20000, 0x37D28000, 0x37D30000, 0x37D38000, 0x37D40000, 0x37D48000, 0x37D50000, 0x37D58000, 0x37D60000, 0x37D68000, 0x37D70000, 0x37D78000,\n  0x37D80000, 0x37D88000, 0x37D90000, 0x37D98000, 0x37DA0000, 0x37DA8000, 0x37DB0000, 0x37DB8000, 0x37DC0000, 0x37DC8000, 0x37DD0000, 0x37DD8000, 0x37DE0000, 0x37DE8000, 0x37DF0000, 0x37DF8000,\n  0x37E00000, 0x37E08000, 0x37E10000, 0x37E18000, 0x37E20000, 0x37E28000, 0x37E30000, 0x37E38000, 0x37E40000, 0x37E48000, 0x37E50000, 0x37E58000, 0x37E60000, 0x37E68000, 0x37E70000, 0x37E78000,\n  0x37E80000, 0x37E88000, 0x37E90000, 0x37E98000, 0x37EA0000, 0x37EA8000, 0x37EB0000, 0x37EB8000, 0x37EC0000, 0x37EC8000, 0x37ED0000, 0x37ED8000, 0x37EE0000, 0x37EE8000, 0x37EF0000, 0x37EF8000,\n  0x37F00000, 0x37F08000, 0x37F10000, 0x37F18000, 0x37F20000, 0x", "37F28000, 0x37F30000, 0x37F38000, 0x37F40000, 0x37F48000, 0x37F50000, 0x37F58000, 0x37F60000, 0x37F68000, 0x37F70000, 0x37F78000,\n  0x37F80000, 0x37F88000, 0x37F90000, 0x37F98000, 0x37FA0000, 0x37FA8000, 0x37FB0000, 0x37FB8000, 0x37FC0000, 0x37FC8000, 0x37FD0000, 0x37FD8000, 0x37FE0000, 0x37FE8000, 0x37FF0000, 0x37FF8000,\n  0x38000000, 0x38004000, 0x38008000, 0x3800C000, 0x38010000, 0x38014000, 0x38018000, 0x3801C000, 0x38020000, 0x38024000, 0x38028000, 0x3802C000, 0x38030000, 0x38034000, 0x38038000, 0x3803C000,\n  0x38040000, 0x38044000, 0x38048000, 0x3804C000, 0x38050000, 0x38054000, 0x38058000, 0x3805C000, 0x38060000, 0x38064000, 0x38068000, 0x3806C000, 0x38070000, 0x38074000, 0x38078000, 0x3807C000,\n  0x38080000, 0x38084000, 0x38088000, 0x3808C000, 0x38090000, 0x38094000, 0x38098000, 0x3809C000, 0x380A0000, 0x380A4000, 0x380A8000, 0x380AC000, 0x380B0000, 0x380B4000, 0x380B8000, 0x380BC000,\n  0x380C0000, 0x380C4000, 0x380C8000, 0x380CC000, 0x380D0000, 0x380D4000, 0x380D8000, 0x380DC000, 0x380E0000, 0x380E4000, 0x380E8000, 0x380EC000, 0x380F0000, 0x380F4000, 0x380F8000, 0x380FC000,\n  0x38100000, 0x38104000, 0x38108000, 0x3810C000, 0x38110000, 0x38114000, 0x38118000, 0x3811C000, 0x38120000, 0x38124000, 0x38128000, 0x3812C000, 0x38130000, 0x38134000, 0x38138000, 0x3813C000,\n  0x38140000, 0x38144000, 0x38148000, 0x3814C000, 0x38150000, 0x38154000, 0x38158000, 0x3815C000, 0x38160000, 0x38164000, 0x38168000, 0x3816C000, 0x38170000, 0x38174000, 0x38178000, 0x3817C000,\n  0x38180000, 0x38184000, 0x38188000, 0x3818C000, 0x38190000, 0x38194000, 0x38198000, 0x3819C000, 0x381A0000, 0x381A4000, 0x381A8000, 0x381AC000, 0x381B0000, 0x381B4000, 0x381B8000, 0x381BC000,\n  0x381C0000, 0x381C4000, 0x381C8000, 0x381CC000, 0x381D0000, 0x381D4000, 0x381D8000, 0x381DC000, 0x381E0000, 0x381E4000, 0x381E8000, 0x381EC000, 0x381F0000, 0x381F4000, 0x381F8000, 0x381FC000,\n  0x38200000, 0x38204000, 0x38208000, 0x3820C000, 0x38210000, 0x38214000, 0x38218000, 0x3821C000, 0x38220000, 0x38224000, 0x",
                                    "38228000, 0x3822C000, 0x38230000, 0x38234000, 0x38238000, 0x3823C000,\n  0x38240000, 0x38244000, 0x38248000, 0x3824C000, 0x38250000, 0x38254000, 0x38258000, 0x3825C000, 0x38260000, 0x38264000, 0x38268000, 0x3826C000, 0x38270000, 0x38274000, 0x38278000, 0x3827C000,\n  0x38280000, 0x38284000, 0x38288000, 0x3828C000, 0x38290000, 0x38294000, 0x38298000, 0x3829C000, 0x382A0000, 0x382A4000, 0x382A8000, 0x382AC000, 0x382B0000, 0x382B4000, 0x382B8000, 0x382BC000,\n  0x382C0000, 0x382C4000, 0x382C8000, 0x382CC000, 0x382D0000, 0x382D4000, 0x382D8000, 0x382DC000, 0x382E0000, 0x382E4000, 0x382E8000, 0x382EC000, 0x382F0000, 0x382F4000, 0x382F8000, 0x382FC000,\n  0x38300000, 0x38304000, 0x38308000, 0x3830C000, 0x38310000, 0x38314000, 0x38318000, 0x3831C000, 0x38320000, 0x38324000, 0x38328000, 0x3832C000, 0x38330000, 0x38334000, 0x38338000, 0x3833C000,\n  0x38340000, 0x38344000, 0x38348000, 0x3834C000, 0x38350000, 0x38354000, 0x38358000, 0x3835C000, 0x38360000, 0x38364000, 0x38368000, 0x3836C000, 0x38370000, 0x38374000, 0x38378000, 0x3837C000,\n  0x38380000, 0x38384000, 0x38388000, 0x3838C000, 0x38390000, 0x38394000, 0x38398000, 0x3839C000, 0x383A0000, 0x383A4000, 0x383A8000, 0x383AC000, 0x383B0000, 0x383B4000, 0x383B8000, 0x383BC000,\n  0x383C0000, 0x383C4000, 0x383C8000, 0x383CC000, 0x383D0000, 0x383D4000, 0x383D8000, 0x383DC000, 0x383E0000, 0x383E4000, 0x383E8000, 0x383EC000, 0x383F0000, 0x383F4000, 0x383F8000, 0x383FC000,\n  0x38400000, 0x38404000, 0x38408000, 0x3840C000, 0x38410000, 0x38414000, 0x38418000, 0x3841C000, 0x38420000, 0x38424000, 0x38428000, 0x3842C000, 0x38430000, 0x38434000, 0x38438000, 0x3843C000,\n  0x38440000, 0x38444000, 0x38448000, 0x3844C000, 0x38450000, 0x38454000, 0x38458000, 0x3845C000, 0x38460000, 0x38464000, 0x38468000, 0x3846C000, 0x38470000, 0x38474000, 0x38478000, 0x3847C000,\n  0x38480000, 0x38484000, 0x38488000, 0x3848C000, 0x38490000, 0x38494000, 0x38498000, 0x3849C000, 0x384A0000, 0x384A4000, 0x384A8000, 0x384AC000, 0x384B0000, 0x384B4000, 0x384B8000, 0x", "384BC000,\n  0x384C0000, 0x384C4000, 0x384C8000, 0x384CC000, 0x384D0000, 0x384D4000, 0x384D8000, 0x384DC000, 0x384E0000, 0x384E4000, 0x384E8000, 0x384EC000, 0x384F0000, 0x384F4000, 0x384F8000, 0x384FC000,\n  0x38500000, 0x38504000, 0x38508000, 0x3850C000, 0x38510000, 0x38514000, 0x38518000, 0x3851C000, 0x38520000, 0x38524000, 0x38528000, 0x3852C000, 0x38530000, 0x38534000, 0x38538000, 0x3853C000,\n  0x38540000, 0x38544000, 0x38548000, 0x3854C000, 0x38550000, 0x38554000, 0x38558000, 0x3855C000, 0x38560000, 0x38564000, 0x38568000, 0x3856C000, 0x38570000, 0x38574000, 0x38578000, 0x3857C000,\n  0x38580000, 0x38584000, 0x38588000, 0x3858C000, 0x38590000, 0x38594000, 0x38598000, 0x3859C000, 0x385A0000, 0x385A4000, 0x385A8000, 0x385AC000, 0x385B0000, 0x385B4000, 0x385B8000, 0x385BC000,\n  0x385C0000, 0x385C4000, 0x385C8000, 0x385CC000, 0x385D0000, 0x385D4000, 0x385D8000, 0x385DC000, 0x385E0000, 0x385E4000, 0x385E8000, 0x385EC000, 0x385F0000, 0x385F4000, 0x385F8000, 0x385FC000,\n  0x38600000, 0x38604000, 0x38608000, 0x3860C000, 0x38610000, 0x38614000, 0x38618000, 0x3861C000, 0x38620000, 0x38624000, 0x38628000, 0x3862C000, 0x38630000, 0x38634000, 0x38638000, 0x3863C000,\n  0x38640000, 0x38644000, 0x38648000, 0x3864C000, 0x38650000, 0x38654000, 0x38658000, 0x3865C000, 0x38660000, 0x38664000, 0x38668000, 0x3866C000, 0x38670000, 0x38674000, 0x38678000, 0x3867C000,\n  0x38680000, 0x38684000, 0x38688000, 0x3868C000, 0x38690000, 0x38694000, 0x38698000, 0x3869C000, 0x386A0000, 0x386A4000, 0x386A8000, 0x386AC000, 0x386B0000, 0x386B4000, 0x386B8000, 0x386BC000,\n  0x386C0000, 0x386C4000, 0x386C8000, 0x386CC000, 0x386D0000, 0x386D4000, 0x386D8000, 0x386DC000, 0x386E0000, 0x386E4000, 0x386E8000, 0x386EC000, 0x386F0000, 0x386F4000, 0x386F8000, 0x386FC000,\n  0x38700000, 0x38704000, 0x38708000, 0x3870C000, 0x38710000, 0x38714000, 0x38718000, 0x3871C000, 0x38720000, 0x38724000, 0x38728000, 0x3872C000, 0x38730000, 0x38734000, 0x38738000, 0x3873C000,\n  0x38740000, 0x38744000, 0x38748000, 0x3874C000, ", "0x38750000, 0x38754000, 0x38758000, 0x3875C000, 0x38760000, 0x38764000, 0x38768000, 0x3876C000, 0x38770000, 0x38774000, 0x38778000, 0x3877C000,\n  0x38780000, 0x38784000, 0x38788000, 0x3878C000, 0x38790000, 0x38794000, 0x38798000, 0x3879C000, 0x387A0000, 0x387A4000, 0x387A8000, 0x387AC000, 0x387B0000, 0x387B4000, 0x387B8000, 0x387BC000,\n  0x387C0000, 0x387C4000, 0x387C8000, 0x387CC000, 0x387D0000, 0x387D4000, 0x387D8000, 0x387DC000, 0x387E0000, 0x387E4000, 0x387E8000, 0x387EC000, 0x387F0000, 0x387F4000, 0x387F8000, 0x387FC000,\n  0x38000000, 0x38002000, 0x38004000, 0x38006000, 0x38008000, 0x3800A000, 0x3800C000, 0x3800E000, 0x38010000, 0x38012000, 0x38014000, 0x38016000, 0x38018000, 0x3801A000, 0x3801C000, 0x3801E000,\n  0x38020000, 0x38022000, 0x38024000, 0x38026000, 0x38028000, 0x3802A000, 0x3802C000, 0x3802E000, 0x38030000, 0x38032000, 0x38034000, 0x38036000, 0x38038000, 0x3803A000, 0x3803C000, 0x3803E000,\n  0x38040000, 0x38042000, 0x38044000, 0x38046000, 0x38048000, 0x3804A000, 0x3804C000, 0x3804E000, 0x38050000, 0x38052000, 0x38054000, 0x38056000, 0x38058000, 0x3805A000, 0x3805C000, 0x3805E000,\n  0x38060000, 0x38062000, 0x38064000, 0x38066000, 0x38068000, 0x3806A000, 0x3806C000, 0x3806E000, 0x38070000, 0x38072000, 0x38074000, 0x38076000, 0x38078000, 0x3807A000, 0x3807C000, 0x3807E000,\n  0x38080000, 0x38082000, 0x38084000, 0x38086000, 0x38088000, 0x3808A000, 0x3808C000, 0x3808E000, 0x38090000, 0x38092000, 0x38094000, 0x38096000, 0x38098000, 0x3809A000, 0x3809C000, 0x3809E000,\n  0x380A0000, 0x380A2000, 0x380A4000, 0x380A6000, 0x380A8000, 0x380AA000, 0x380AC000, 0x380AE000, 0x380B0000, 0x380B2000, 0x380B4000, 0x380B6000, 0x380B8000, 0x380BA000, 0x380BC000, 0x380BE000,\n  0x380C0000, 0x380C2000, 0x380C4000, 0x380C6000, 0x380C8000, 0x380CA000, 0x380CC000, 0x380CE000, 0x380D0000, 0x380D2000, 0x380D4000, 0x380D6000, 0x380D8000, 0x380DA000, 0x380DC000, 0x380DE000,\n  0x380E0000, 0x380E2000, 0x380E4000, 0x380E6000, 0x380E8000, 0x380EA000, 0x380EC000, 0x380EE000, 0x380F0000, ",
                                    "0x380F2000, 0x380F4000, 0x380F6000, 0x380F8000, 0x380FA000, 0x380FC000, 0x380FE000,\n  0x38100000, 0x38102000, 0x38104000, 0x38106000, 0x38108000, 0x3810A000, 0x3810C000, 0x3810E000, 0x38110000, 0x38112000, 0x38114000, 0x38116000, 0x38118000, 0x3811A000, 0x3811C000, 0x3811E000,\n  0x38120000, 0x38122000, 0x38124000, 0x38126000, 0x38128000, 0x3812A000, 0x3812C000, 0x3812E000, 0x38130000, 0x38132000, 0x38134000, 0x38136000, 0x38138000, 0x3813A000, 0x3813C000, 0x3813E000,\n  0x38140000, 0x38142000, 0x38144000, 0x38146000, 0x38148000, 0x3814A000, 0x3814C000, 0x3814E000, 0x38150000, 0x38152000, 0x38154000, 0x38156000, 0x38158000, 0x3815A000, 0x3815C000, 0x3815E000,\n  0x38160000, 0x38162000, 0x38164000, 0x38166000, 0x38168000, 0x3816A000, 0x3816C000, 0x3816E000, 0x38170000, 0x38172000, 0x38174000, 0x38176000, 0x38178000, 0x3817A000, 0x3817C000, 0x3817E000,\n  0x38180000, 0x38182000, 0x38184000, 0x38186000, 0x38188000, 0x3818A000, 0x3818C000, 0x3818E000, 0x38190000, 0x38192000, 0x38194000, 0x38196000, 0x38198000, 0x3819A000, 0x3819C000, 0x3819E000,\n  0x381A0000, 0x381A2000, 0x381A4000, 0x381A6000, 0x381A8000, 0x381AA000, 0x381AC000, 0x381AE000, 0x381B0000, 0x381B2000, 0x381B4000, 0x381B6000, 0x381B8000, 0x381BA000, 0x381BC000, 0x381BE000,\n  0x381C0000, 0x381C2000, 0x381C4000, 0x381C6000, 0x381C8000, 0x381CA000, 0x381CC000, 0x381CE000, 0x381D0000, 0x381D2000, 0x381D4000, 0x381D6000, 0x381D8000, 0x381DA000, 0x381DC000, 0x381DE000,\n  0x381E0000, 0x381E2000, 0x381E4000, 0x381E6000, 0x381E8000, 0x381EA000, 0x381EC000, 0x381EE000, 0x381F0000, 0x381F2000, 0x381F4000, 0x381F6000, 0x381F8000, 0x381FA000, 0x381FC000, 0x381FE000,\n  0x38200000, 0x38202000, 0x38204000, 0x38206000, 0x38208000, 0x3820A000, 0x3820C000, 0x3820E000, 0x38210000, 0x38212000, 0x38214000, 0x38216000, 0x38218000, 0x3821A000, 0x3821C000, 0x3821E000,\n  0x38220000, 0x38222000, 0x38224000, 0x38226000, 0x38228000, 0x3822A000, 0x3822C000, 0x3822E000, 0x38230000, 0x38232000, 0x38234000, 0x38236000, 0x38238000, 0x3823A000, ", "0x3823C000, 0x3823E000,\n  0x38240000, 0x38242000, 0x38244000, 0x38246000, 0x38248000, 0x3824A000, 0x3824C000, 0x3824E000, 0x38250000, 0x38252000, 0x38254000, 0x38256000, 0x38258000, 0x3825A000, 0x3825C000, 0x3825E000,\n  0x38260000, 0x38262000, 0x38264000, 0x38266000, 0x38268000, 0x3826A000, 0x3826C000, 0x3826E000, 0x38270000, 0x38272000, 0x38274000, 0x38276000, 0x38278000, 0x3827A000, 0x3827C000, 0x3827E000,\n  0x38280000, 0x38282000, 0x38284000, 0x38286000, 0x38288000, 0x3828A000, 0x3828C000, 0x3828E000, 0x38290000, 0x38292000, 0x38294000, 0x38296000, 0x38298000, 0x3829A000, 0x3829C000, 0x3829E000,\n  0x382A0000, 0x382A2000, 0x382A4000, 0x382A6000, 0x382A8000, 0x382AA000, 0x382AC000, 0x382AE000, 0x382B0000, 0x382B2000, 0x382B4000, 0x382B6000, 0x382B8000, 0x382BA000, 0x382BC000, 0x382BE000,\n  0x382C0000, 0x382C2000, 0x382C4000, 0x382C6000, 0x382C8000, 0x382CA000, 0x382CC000, 0x382CE000, 0x382D0000, 0x382D2000, 0x382D4000, 0x382D6000, 0x382D8000, 0x382DA000, 0x382DC000, 0x382DE000,\n  0x382E0000, 0x382E2000, 0x382E4000, 0x382E6000, 0x382E8000, 0x382EA000, 0x382EC000, 0x382EE000, 0x382F0000, 0x382F2000, 0x382F4000, 0x382F6000, 0x382F8000, 0x382FA000, 0x382FC000, 0x382FE000,\n  0x38300000, 0x38302000, 0x38304000, 0x38306000, 0x38308000, 0x3830A000, 0x3830C000, 0x3830E000, 0x38310000, 0x38312000, 0x38314000, 0x38316000, 0x38318000, 0x3831A000, 0x3831C000, 0x3831E000,\n  0x38320000, 0x38322000, 0x38324000, 0x38326000, 0x38328000, 0x3832A000, 0x3832C000, 0x3832E000, 0x38330000, 0x38332000, 0x38334000, 0x38336000, 0x38338000, 0x3833A000, 0x3833C000, 0x3833E000,\n  0x38340000, 0x38342000, 0x38344000, 0x38346000, 0x38348000, 0x3834A000, 0x3834C000, 0x3834E000, 0x38350000, 0x38352000, 0x38354000, 0x38356000, 0x38358000, 0x3835A000, 0x3835C000, 0x3835E000,\n  0x38360000, 0x38362000, 0x38364000, 0x38366000, 0x38368000, 0x3836A000, 0x3836C000, 0x3836E000, 0x38370000, 0x38372000, 0x38374000, 0x38376000, 0x38378000, 0x3837A000, 0x3837C000, 0x3837E000,\n  0x38380000, 0x38382000, 0x38384000", ", 0x38386000, 0x38388000, 0x3838A000, 0x3838C000, 0x3838E000, 0x38390000, 0x38392000, 0x38394000, 0x38396000, 0x38398000, 0x3839A000, 0x3839C000, 0x3839E000,\n  0x383A0000, 0x383A2000, 0x383A4000, 0x383A6000, 0x383A8000, 0x383AA000, 0x383AC000, 0x383AE000, 0x383B0000, 0x383B2000, 0x383B4000, 0x383B6000, 0x383B8000, 0x383BA000, 0x383BC000, 0x383BE000,\n  0x383C0000, 0x383C2000, 0x383C4000, 0x383C6000, 0x383C8000, 0x383CA000, 0x383CC000, 0x383CE000, 0x383D0000, 0x383D2000, 0x383D4000, 0x383D6000, 0x383D8000, 0x383DA000, 0x383DC000, 0x383DE000,\n  0x383E0000, 0x383E2000, 0x383E4000, 0x383E6000, 0x383E8000, 0x383EA000, 0x383EC000, 0x383EE000, 0x383F0000, 0x383F2000, 0x383F4000, 0x383F6000, 0x383F8000, 0x383FA000, 0x383FC000, 0x383FE000,\n  0x38400000, 0x38402000, 0x38404000, 0x38406000, 0x38408000, 0x3840A000, 0x3840C000, 0x3840E000, 0x38410000, 0x38412000, 0x38414000, 0x38416000, 0x38418000, 0x3841A000, 0x3841C000, 0x3841E000,\n  0x38420000, 0x38422000, 0x38424000, 0x38426000, 0x38428000, 0x3842A000, 0x3842C000, 0x3842E000, 0x38430000, 0x38432000, 0x38434000, 0x38436000, 0x38438000, 0x3843A000, 0x3843C000, 0x3843E000,\n  0x38440000, 0x38442000, 0x38444000, 0x38446000, 0x38448000, 0x3844A000, 0x3844C000, 0x3844E000, 0x38450000, 0x38452000, 0x38454000, 0x38456000, 0x38458000, 0x3845A000, 0x3845C000, 0x3845E000,\n  0x38460000, 0x38462000, 0x38464000, 0x38466000, 0x38468000, 0x3846A000, 0x3846C000, 0x3846E000, 0x38470000, 0x38472000, 0x38474000, 0x38476000, 0x38478000, 0x3847A000, 0x3847C000, 0x3847E000,\n  0x38480000, 0x38482000, 0x38484000, 0x38486000, 0x38488000, 0x3848A000, 0x3848C000, 0x3848E000, 0x38490000, 0x38492000, 0x38494000, 0x38496000, 0x38498000, 0x3849A000, 0x3849C000, 0x3849E000,\n  0x384A0000, 0x384A2000, 0x384A4000, 0x384A6000, 0x384A8000, 0x384AA000, 0x384AC000, 0x384AE000, 0x384B0000, 0x384B2000, 0x384B4000, 0x384B6000, 0x384B8000, 0x384BA000, 0x384BC000, 0x384BE000,\n  0x384C0000, 0x384C2000, 0x384C4000, 0x384C6000, 0x384C8000, 0x384CA000, 0x384CC000, 0x384CE000",
                                    ", 0x384D0000, 0x384D2000, 0x384D4000, 0x384D6000, 0x384D8000, 0x384DA000, 0x384DC000, 0x384DE000,\n  0x384E0000, 0x384E2000, 0x384E4000, 0x384E6000, 0x384E8000, 0x384EA000, 0x384EC000, 0x384EE000, 0x384F0000, 0x384F2000, 0x384F4000, 0x384F6000, 0x384F8000, 0x384FA000, 0x384FC000, 0x384FE000,\n  0x38500000, 0x38502000, 0x38504000, 0x38506000, 0x38508000, 0x3850A000, 0x3850C000, 0x3850E000, 0x38510000, 0x38512000, 0x38514000, 0x38516000, 0x38518000, 0x3851A000, 0x3851C000, 0x3851E000,\n  0x38520000, 0x38522000, 0x38524000, 0x38526000, 0x38528000, 0x3852A000, 0x3852C000, 0x3852E000, 0x38530000, 0x38532000, 0x38534000, 0x38536000, 0x38538000, 0x3853A000, 0x3853C000, 0x3853E000,\n  0x38540000, 0x38542000, 0x38544000, 0x38546000, 0x38548000, 0x3854A000, 0x3854C000, 0x3854E000, 0x38550000, 0x38552000, 0x38554000, 0x38556000, 0x38558000, 0x3855A000, 0x3855C000, 0x3855E000,\n  0x38560000, 0x38562000, 0x38564000, 0x38566000, 0x38568000, 0x3856A000, 0x3856C000, 0x3856E000, 0x38570000, 0x38572000, 0x38574000, 0x38576000, 0x38578000, 0x3857A000, 0x3857C000, 0x3857E000,\n  0x38580000, 0x38582000, 0x38584000, 0x38586000, 0x38588000, 0x3858A000, 0x3858C000, 0x3858E000, 0x38590000, 0x38592000, 0x38594000, 0x38596000, 0x38598000, 0x3859A000, 0x3859C000, 0x3859E000,\n  0x385A0000, 0x385A2000, 0x385A4000, 0x385A6000, 0x385A8000, 0x385AA000, 0x385AC000, 0x385AE000, 0x385B0000, 0x385B2000, 0x385B4000, 0x385B6000, 0x385B8000, 0x385BA000, 0x385BC000, 0x385BE000,\n  0x385C0000, 0x385C2000, 0x385C4000, 0x385C6000, 0x385C8000, 0x385CA000, 0x385CC000, 0x385CE000, 0x385D0000, 0x385D2000, 0x385D4000, 0x385D6000, 0x385D8000, 0x385DA000, 0x385DC000, 0x385DE000,\n  0x385E0000, 0x385E2000, 0x385E4000, 0x385E6000, 0x385E8000, 0x385EA000, 0x385EC000, 0x385EE000, 0x385F0000, 0x385F2000, 0x385F4000, 0x385F6000, 0x385F8000, 0x385FA000, 0x385FC000, 0x385FE000,\n  0x38600000, 0x38602000, 0x38604000, 0x38606000, 0x38608000, 0x3860A000, 0x3860C000, 0x3860E000, 0x38610000, 0x38612000, 0x38614000, 0x38616000, 0x38618000", ", 0x3861A000, 0x3861C000, 0x3861E000,\n  0x38620000, 0x38622000, 0x38624000, 0x38626000, 0x38628000, 0x3862A000, 0x3862C000, 0x3862E000, 0x38630000, 0x38632000, 0x38634000, 0x38636000, 0x38638000, 0x3863A000, 0x3863C000, 0x3863E000,\n  0x38640000, 0x38642000, 0x38644000, 0x38646000, 0x38648000, 0x3864A000, 0x3864C000, 0x3864E000, 0x38650000, 0x38652000, 0x38654000, 0x38656000, 0x38658000, 0x3865A000, 0x3865C000, 0x3865E000,\n  0x38660000, 0x38662000, 0x38664000, 0x38666000, 0x38668000, 0x3866A000, 0x3866C000, 0x3866E000, 0x38670000, 0x38672000, 0x38674000, 0x38676000, 0x38678000, 0x3867A000, 0x3867C000, 0x3867E000,\n  0x38680000, 0x38682000, 0x38684000, 0x38686000, 0x38688000, 0x3868A000, 0x3868C000, 0x3868E000, 0x38690000, 0x38692000, 0x38694000, 0x38696000, 0x38698000, 0x3869A000, 0x3869C000, 0x3869E000,\n  0x386A0000, 0x386A2000, 0x386A4000, 0x386A6000, 0x386A8000, 0x386AA000, 0x386AC000, 0x386AE000, 0x386B0000, 0x386B2000, 0x386B4000, 0x386B6000, 0x386B8000, 0x386BA000, 0x386BC000, 0x386BE000,\n  0x386C0000, 0x386C2000, 0x386C4000, 0x386C6000, 0x386C8000, 0x386CA000, 0x386CC000, 0x386CE000, 0x386D0000, 0x386D2000, 0x386D4000, 0x386D6000, 0x386D8000, 0x386DA000, 0x386DC000, 0x386DE000,\n  0x386E0000, 0x386E2000, 0x386E4000, 0x386E6000, 0x386E8000, 0x386EA000, 0x386EC000, 0x386EE000, 0x386F0000, 0x386F2000, 0x386F4000, 0x386F6000, 0x386F8000, 0x386FA000, 0x386FC000, 0x386FE000,\n  0x38700000, 0x38702000, 0x38704000, 0x38706000, 0x38708000, 0x3870A000, 0x3870C000, 0x3870E000, 0x38710000, 0x38712000, 0x38714000, 0x38716000, 0x38718000, 0x3871A000, 0x3871C000, 0x3871E000,\n  0x38720000, 0x38722000, 0x38724000, 0x38726000, 0x38728000, 0x3872A000, 0x3872C000, 0x3872E000, 0x38730000, 0x38732000, 0x38734000, 0x38736000, 0x38738000, 0x3873A000, 0x3873C000, 0x3873E000,\n  0x38740000, 0x38742000, 0x38744000, 0x38746000, 0x38748000, 0x3874A000, 0x3874C000, 0x3874E000, 0x38750000, 0x38752000, 0x38754000, 0x38756000, 0x38758000, 0x3875A000, 0x3875C000, 0x3875E000,\n  0x38760000, 0x387620", "00, 0x38764000, 0x38766000, 0x38768000, 0x3876A000, 0x3876C000, 0x3876E000, 0x38770000, 0x38772000, 0x38774000, 0x38776000, 0x38778000, 0x3877A000, 0x3877C000, 0x3877E000,\n  0x38780000, 0x38782000, 0x38784000, 0x38786000, 0x38788000, 0x3878A000, 0x3878C000, 0x3878E000, 0x38790000, 0x38792000, 0x38794000, 0x38796000, 0x38798000, 0x3879A000, 0x3879C000, 0x3879E000,\n  0x387A0000, 0x387A2000, 0x387A4000, 0x387A6000, 0x387A8000, 0x387AA000, 0x387AC000, 0x387AE000, 0x387B0000, 0x387B2000, 0x387B4000, 0x387B6000, 0x387B8000, 0x387BA000, 0x387BC000, 0x387BE000,\n  0x387C0000, 0x387C2000, 0x387C4000, 0x387C6000, 0x387C8000, 0x387CA000, 0x387CC000, 0x387CE000, 0x387D0000, 0x387D2000, 0x387D4000, 0x387D6000, 0x387D8000, 0x387DA000, 0x387DC000, 0x387DE000,\n  0x387E0000, 0x387E2000, 0x387E4000, 0x387E6000, 0x387E8000, 0x387EA000, 0x387EC000, 0x387EE000, 0x387F0000, 0x387F2000, 0x387F4000, 0x387F6000, 0x387F8000, 0x387FA000, 0x387FC000, 0x387FE000 };\n__constant static const uint32_t exponent_table[64] = {\n  0x00000000, 0x00800000, 0x01000000, 0x01800000, 0x02000000, 0x02800000, 0x03000000, 0x03800000, 0x04000000, 0x04800000, 0x05000000, 0x05800000, 0x06000000, 0x06800000, 0x07000000, 0x07800000,\n  0x08000000, 0x08800000, 0x09000000, 0x09800000, 0x0A000000, 0x0A800000, 0x0B000000, 0x0B800000, 0x0C000000, 0x0C800000, 0x0D000000, 0x0D800000, 0x0E000000, 0x0E800000, 0x0F000000, 0x47800000,\n  0x80000000, 0x80800000, 0x81000000, 0x81800000, 0x82000000, 0x82800000, 0x83000000, 0x83800000, 0x84000000, 0x84800000, 0x85000000, 0x85800000, 0x86000000, 0x86800000, 0x87000000, 0x87800000,\n  0x88000000, 0x88800000, 0x89000000, 0x89800000, 0x8A000000, 0x8A800000, 0x8B000000, 0x8B800000, 0x8C000000, 0x8C800000, 0x8D000000, 0x8D800000, 0x8E000000, 0x8E800000, 0x8F000000, 0xC7800000 };\n__constant static const unsigned short offset_table[64] = {\n  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1",
                                    "024, 1024, 1024, 1024, 1024, 1024,\n  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024 };\n\nSCALAR_FUN_ATTR uint16_t float2halfbits(float value) {\n  union { float x; uint32_t y; } u;\n  u.x = value;\n  uint32_t bits = u.y;\n\n  uint16_t hbits = base_table[bits>>23] + (uint16_t)((bits&0x7FFFFF)>>shift_table[bits>>23]);;\n\n  return hbits;\n}\n\nSCALAR_FUN_ATTR float halfbits2float(uint16_t value) {\n  uint32_t bits = mantissa_table[offset_table[value>>10]+(value&0x3FF)] + exponent_table[value>>10];\n\n  union { uint32_t x; float y; } u;\n  u.x = bits;\n  return u.y;\n}\n\nSCALAR_FUN_ATTR uint16_t halfbitsnextafter(uint16_t from, uint16_t to) {\n  int fabs = from & 0x7FFF, tabs = to & 0x7FFF;\n  if(fabs > 0x7C00 || tabs > 0x7C00) {\n    return ((from&0x7FFF)>0x7C00) ? (from|0x200) : (to|0x200);\n  }\n  if(from == to || !(fabs|tabs)) {\n    return to;\n  }\n  if(!fabs) {\n    return (to&0x8000)+1;\n  }\n  unsigned int out =\n    from +\n    (((from>>15)^(unsigned int)((from^(0x8000|(0x8000-(from>>15))))<(to^(0x8000|(0x8000-(to>>15))))))<<1)\n    - 1;\n  return out;\n}\n\n// End of half.h.\n// Start of scalar.h.\n\n// Implementation of the primitive scalar operations.  Very\n// repetitive.  This code is inserted directly into both CUDA and\n// OpenCL programs, as well as the CPU code, so it has some #ifdefs to\n// work everywhere.  Some operations are defined as macros because\n// this allows us to use them as constant expressions in things like\n// array sizes and static initialisers.\n\n// Some of the #ifdefs are because OpenCL uses type-generic functions\n// for some operations (e.g. sqrt), while C and CUDA sensibly use\n// distinct functions for different precisions (e.g. sqrtf() and\n// sqrt()).  This is quite annoying.  Due to C's unfortunate casting\n// rules, it is also really easy to accidentally implement\n// floating-point functions in the wrong precision, so be careful.\n\n/", "/ Double-precision definitions are only included if the preprocessor\n// macro FUTHARK_F64_ENABLED is set.\n\nSCALAR_FUN_ATTR int32_t futrts_to_bits32(float x);\nSCALAR_FUN_ATTR float futrts_from_bits32(int32_t x);\n\nSCALAR_FUN_ATTR uint8_t add8(uint8_t x, uint8_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint16_t add16(uint16_t x, uint16_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint32_t add32(uint32_t x, uint32_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint64_t add64(uint64_t x, uint64_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint8_t sub8(uint8_t x, uint8_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint16_t sub16(uint16_t x, uint16_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint32_t sub32(uint32_t x, uint32_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint64_t sub64(uint64_t x, uint64_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint8_t mul8(uint8_t x, uint8_t y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR uint16_t mul16(uint16_t x, uint16_t y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR uint32_t mul32(uint32_t x, uint32_t y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR uint64_t mul64(uint64_t x, uint64_t y) {\n  return x * y;\n}\n\n#if ISPC\n\nSCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {\n  // This strange pattern is used to prevent the ISPC compiler from\n  // causing SIGFPEs and bogus results on divisions where inactive lanes\n  // have 0-valued divisors. It ensures that any inactive lane instead\n  // has a divisor of 1. https://github.com/ispc/ispc/issues/2292\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {\n  uint", "8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALA",
                                    "R_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int8_t q = x / ys;\n  int8_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int16_t q = x / ys;\n  int16_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  int32_t q = x / ys;\n  int32_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int64_t q = x / ys;\n  int64_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {\n  return sdiv8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {\n  return sdiv16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y)", " {\n  return sdiv32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {\n  return sdiv64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int8_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int16_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int32_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int64_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : sdiv8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : sdiv16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : sdiv32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : sdiv64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {\n  return sdiv_safe8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {\n  return sdiv_safe16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {\n  return sdiv_safe32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {\n  return sdiv_safe64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : smod8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : smod16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) ", "{\n  return y == 0 ? 0 : smod32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : smod64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  ",
                                    "foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\n#else\n\nSCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {\n  return", " y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {\n  int8_t q = x / y;\n  int8_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {\n  int16_t q = x / y;\n  int16_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {\n  int32_t q = x / y;\n  int32_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {\n  int64_t q = x / y;\n  int64_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {\n  return sdiv8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {\n  return sdiv16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {\n  return sdiv32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {\n  return sdiv64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {\n  int8_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {\n  int16_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {\n  int32_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {\n  int64_t r = ", "x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : sdiv8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : sdiv16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : sdiv32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : sdiv64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {\n  return sdiv_safe8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {\n  return sdiv_safe16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {\n  return sdiv_safe32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {\n  return sdiv_safe64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : smod8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : smod16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : smod32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : smod64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t ",
                                    "y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\n#endif\n\nSCALAR_FUN_ATTR int8_t smin8(int8_t x, int8_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int16_t smin16(int16_t x, int16_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int32_t smin32(int32_t x, int32_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int64_t smin64(int64_t x, int64_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint8_t umin8(uint8_t x, uint8_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint16_t umin16(uint16_t x, uint16_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint32_t umin32(uint32_t x, uint32_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint64_t umin64(uint64_t x, uint64_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int8_t smax8(int8_t x, int8_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR int16_t smax16(int16_t x, int16_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR int32_t smax32(int32_t x, int32_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR int64_t smax64(int64_t x, int64_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint8_t umax8(uint8_t x, uint8_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint16_t umax16(uint16_t x, uint16_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint32_t umax32(uint32_t x, uint32_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint64_t umax64(uint64_t x, uint64_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint8_t shl8(uint8_t x, uint8_t y) {\n  return (uint8_t)(x << y);\n}\n\nS", "CALAR_FUN_ATTR uint16_t shl16(uint16_t x, uint16_t y) {\n  return (uint16_t)(x << y);\n}\n\nSCALAR_FUN_ATTR uint32_t shl32(uint32_t x, uint32_t y) {\n  return x << y;\n}\n\nSCALAR_FUN_ATTR uint64_t shl64(uint64_t x, uint64_t y) {\n  return x << y;\n}\n\nSCALAR_FUN_ATTR uint8_t lshr8(uint8_t x, uint8_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint16_t lshr16(uint16_t x, uint16_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint32_t lshr32(uint32_t x, uint32_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint64_t lshr64(uint64_t x, uint64_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int8_t ashr8(int8_t x, int8_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int16_t ashr16(int16_t x, int16_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int32_t ashr32(int32_t x, int32_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int64_t ashr64(int64_t x, int64_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint8_t and8(uint8_t x, uint8_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint16_t and16(uint16_t x, uint16_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint32_t and32(uint32_t x, uint32_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint64_t and64(uint64_t x, uint64_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint8_t or8(uint8_t x, uint8_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint16_t or16(uint16_t x, uint16_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint32_t or32(uint32_t x, uint32_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint64_t or64(uint64_t x, uint64_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint8_t xor8(uint8_t x, uint8_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR uint16_t xor16(uint16_t x, uint16_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR uint32_t xor32(uint32_t x, uint32_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR uint64_t xor64(uint64_t x, uint64_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR bool ult8(uint8_t x, uint8_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ult16(uint16_t x, uint16_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ult32(uint32_t x, uint32_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ult64(uint64_t x, uint64", "_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ule8(uint8_t x, uint8_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool ule16(uint16_t x, uint16_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool ule32(uint32_t x, uint32_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool ule64(uint64_t x, uint64_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool slt8(int8_t x, int8_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool slt16(int16_t x, int16_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool slt32(int32_t x, int32_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool slt64(int64_t x, int64_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool sle8(int8_t x, int8_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool sle16(int16_t x, int16_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool sle32(int32_t x, int32_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool sle64(int64_t x, int64_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR uint8_t pow8(uint8_t x, uint8_t y) {\n  uint8_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uint16_t pow16(uint16_t x, uint16_t y) {\n  uint16_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uint32_t pow32(uint32_t x, uint32_t y) {\n  uint32_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uint64_t pow64(uint64_t x, uint64_t y) {\n  uint64_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR bool itob_i8_bool(int8_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR bool itob_i16_bool(int16_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR bool itob_i32_bool(int32_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR bool itob_i64_bool(int64_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR int8_t btoi_bool_i8(bool x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR int16_t btoi_bool_i16(bool x",
                                    ") {\n  return x;\n}\n\nSCALAR_FUN_ATTR int32_t btoi_bool_i32(bool x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR int64_t btoi_bool_i64(bool x) {\n  return x;\n}\n\n#define sext_i8_i8(x) ((int8_t) (int8_t) (x))\n#define sext_i8_i16(x) ((int16_t) (int8_t) (x))\n#define sext_i8_i32(x) ((int32_t) (int8_t) (x))\n#define sext_i8_i64(x) ((int64_t) (int8_t) (x))\n#define sext_i16_i8(x) ((int8_t) (int16_t) (x))\n#define sext_i16_i16(x) ((int16_t) (int16_t) (x))\n#define sext_i16_i32(x) ((int32_t) (int16_t) (x))\n#define sext_i16_i64(x) ((int64_t) (int16_t) (x))\n#define sext_i32_i8(x) ((int8_t) (int32_t) (x))\n#define sext_i32_i16(x) ((int16_t) (int32_t) (x))\n#define sext_i32_i32(x) ((int32_t) (int32_t) (x))\n#define sext_i32_i64(x) ((int64_t) (int32_t) (x))\n#define sext_i64_i8(x) ((int8_t) (int64_t) (x))\n#define sext_i64_i16(x) ((int16_t) (int64_t) (x))\n#define sext_i64_i32(x) ((int32_t) (int64_t) (x))\n#define sext_i64_i64(x) ((int64_t) (int64_t) (x))\n#define zext_i8_i8(x) ((int8_t) (uint8_t) (x))\n#define zext_i8_i16(x) ((int16_t) (uint8_t) (x))\n#define zext_i8_i32(x) ((int32_t) (uint8_t) (x))\n#define zext_i8_i64(x) ((int64_t) (uint8_t) (x))\n#define zext_i16_i8(x) ((int8_t) (uint16_t) (x))\n#define zext_i16_i16(x) ((int16_t) (uint16_t) (x))\n#define zext_i16_i32(x) ((int32_t) (uint16_t) (x))\n#define zext_i16_i64(x) ((int64_t) (uint16_t) (x))\n#define zext_i32_i8(x) ((int8_t) (uint32_t) (x))\n#define zext_i32_i16(x) ((int16_t) (uint32_t) (x))\n#define zext_i32_i32(x) ((int32_t) (uint32_t) (x))\n#define zext_i32_i64(x) ((int64_t) (uint32_t) (x))\n#define zext_i64_i8(x) ((int8_t) (uint64_t) (x))\n#define zext_i64_i16(x) ((int16_t) (uint64_t) (x))\n#define zext_i64_i32(x) ((int32_t) (uint64_t) (x))\n#define zext_i64_i64(x) ((int64_t) (uint64_t) (x))\n\nSCALAR_FUN_ATTR int8_t abs8(int8_t x) {\n  return (int8_t)abs(x);\n}\n\nSCALAR_FUN_ATTR int16_t abs16(int16_t x) {\n  return (int16_t)abs(x);\n}\n\nSCALAR_FUN_ATTR int32_t abs32(int32_t x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR int64_t abs64(int64_t x) {\n#if defined(__OPENCL_VER", "SION__) || defined(ISPC)\n  return abs(x);\n#else\n  return llabs(x);\n#endif\n}\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {\n  return popcount(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {\n  return popcount(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {\n  return popcount(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {\n  return popcount(x);\n}\n#elif defined(__CUDA_ARCH__)\n\nSCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {\n  return __popc(zext_i8_i32(x));\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {\n  return __popc(zext_i16_i32(x));\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {\n  return __popc(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {\n  return __popcll(x);\n}\n\n#else // Not OpenCL or CUDA, but plain C.\n\nSCALAR_FUN_ATTR int32_t futrts_popc8(uint8_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc16(uint16_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc32(uint32_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc64(uint64_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR uint8_t  futrts_umul_hi8 ( uint8_t a,  uint8_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint8_t  futrts_smul_hi8 ( int8_t a,  int8_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return m", "ul_hi(a, b); }\n#elif defined(__CUDA_ARCH__)\nSCALAR_FUN_ATTR  uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return __umulhi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return __umul64hi(a, b); }\nSCALAR_FUN_ATTR  uint8_t futrts_smul_hi8 ( int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return __mulhi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return __mul64hi(a, b); }\n#elif ISPC\nSCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) {\n  uint64_t ah = a >> 32;\n  uint64_t al = a & 0xffffffff;\n  uint64_t bh = b >> 32;\n  uint64_t bl = b & 0xffffffff;\n\n  uint64_t p1 = al * bl;\n  uint64_t p2 = al * bh;\n  uint64_t p3 = ah * bl;\n  uint64_t p4 = ah * bh;\n\n  uint64_t p1h = p1 >> 32;\n  uint64_t p2h = p2 >> 32;\n  uint64_t p3h = p3 >> 32;\n  uint64_t p2l = p2 & 0xffffffff;\n  uint64_t p3l = p3 & 0xffffffff;\n\n  uint64_t l = p1h + p2l + p3l;\n  uint64_t m = (p2 >> 32) + (p3 >> 32);\n  uint64_t h = (l >> 32) + m + p4;\n\n  return h;\n}\nSCALAR_FUN_ATTR  int8_t futrts_smul_hi8 ( int8_t a,  int8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR int",
                                    "32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nSCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) {\n  uint64_t ah = a >> 32;\n  uint64_t al = a & 0xffffffff;\n  uint64_t bh = b >> 32;\n  uint64_t bl = b & 0xffffffff;\n\n  uint64_t p1 =  al * bl;\n  int64_t  p2 = al * bh;\n  int64_t  p3 = ah * bl;\n  uint64_t p4 =  ah * bh;\n\n  uint64_t p1h = p1 >> 32;\n  uint64_t p2h = p2 >> 32;\n  uint64_t p3h = p3 >> 32;\n  uint64_t p2l = p2 & 0xffffffff;\n  uint64_t p3l = p3 & 0xffffffff;\n\n  uint64_t l = p1h + p2l + p3l;\n  uint64_t m = (p2 >> 32) + (p3 >> 32);\n  uint64_t h = (l >> 32) + m + p4;\n\n  return h;\n}\n\n#else // Not OpenCL, ISPC, or CUDA, but plain C.\nSCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return ((__uint128_t)a) * ((__uint128_t)b) >> 64; }\nSCALAR_FUN_ATTR int8_t futrts_smul_hi8(int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }\nSCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }\nSCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((int64_t)a) * ((int64_t)b) >> 32; }\nSCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) { return ((__int128_t)a) * ((__int128_t)b) >> 64; }\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR  uint8_t futrts_umad_hi8 ( uint8_t a,  uint8_t b,  uint8_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t ", "a, uint64_t b, uint64_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR  uint8_t futrts_smad_hi8( int8_t a,  int8_t b,   int8_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return mad_hi(a, b, c); }\n#else // Not OpenCL\n\nSCALAR_FUN_ATTR  uint8_t futrts_umad_hi8( uint8_t a,  uint8_t b,  uint8_t c) { return futrts_umul_hi8(a, b) + c; }\nSCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return futrts_umul_hi16(a, b) + c; }\nSCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return futrts_umul_hi32(a, b) + c; }\nSCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return futrts_umul_hi64(a, b) + c; }\nSCALAR_FUN_ATTR  uint8_t futrts_smad_hi8 ( int8_t a,  int8_t b,  int8_t c) { return futrts_smul_hi8(a, b) + c; }\nSCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return futrts_smul_hi16(a, b) + c; }\nSCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return futrts_smul_hi32(a, b) + c; }\nSCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return futrts_smul_hi64(a, b) + c; }\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  return clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return clz(x);\n}\n\n#elif defined(__CUDA_ARCH__)\n\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return __clz(zext_i8_i32(x)) - 24;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return __clz(zext_i16_i32(x)) - 16;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  retur", "n __clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return __clzll(x);\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return count_leading_zeros((int32_t)(uint8_t)x)-24;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return count_leading_zeros((int32_t)(uint16_t)x)-16;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  return count_leading_zeros(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return count_leading_zeros(x);\n}\n\n#else // Not OpenCL, ISPC or CUDA, but plain C.\n\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return x == 0 ? 8 : __builtin_clz((uint32_t)zext_i8_i32(x)) - 24;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return x == 0 ? 16 : __builtin_clz((uint32_t)zext_i16_i32(x)) - 16;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  return x == 0 ? 32 : __builtin_clz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return x == 0 ? 64 : __builtin_clzll((uint64_t)x);\n}\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  int i = 0;\n  for (; i < 8 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  int i = 0;\n  for (; i < 16 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  int i = 0;\n  for (; i < 32 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  int i = 0;\n  for (; i < 64 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\n#elif defined(__CUDA_ARCH__)\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 8 : y - 1;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 16 : y - 1;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 32 : y - 1;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  int y = __ffsll(x);\n  return y == 0 ? 64 : y - 1",
                                    ";\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  return x == 0 ? 8 : count_trailing_zeros((int32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  return x == 0 ? 16 : count_trailing_zeros((int32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  return count_trailing_zeros(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  return count_trailing_zeros(x);\n}\n\n#else // Not OpenCL or CUDA, but plain C.\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  return x == 0 ? 8 : __builtin_ctz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  return x == 0 ? 16 : __builtin_ctz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  return x == 0 ? 32 : __builtin_ctz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  return x == 0 ? 64 : __builtin_ctzll((uint64_t)x);\n}\n#endif\n\nSCALAR_FUN_ATTR float fdiv32(float x, float y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR float fadd32(float x, float y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR float fsub32(float x, float y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR float fmul32(float x, float y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt32(float x, float y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple32(float x, float y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR float sitofp_i8_f32(int8_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float sitofp_i16_f32(int16_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float sitofp_i32_f32(int32_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float sitofp_i64_f32(int64_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i8_f32(uint8_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i16_f32(uint16_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i32_f32(uint32_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i64_f32(uint64_t x) {\n  return (float) x;\n}\n\n#ifdef __OPENCL_VERSION__\nSCALAR_FUN_ATTR float fabs32(float x) {\n  return fabs(x);\n}\n\nSCALAR_FUN_ATTR float fmax32(float x, f", "loat y) {\n  return fmax(x, y);\n}\n\nSCALAR_FUN_ATTR float fmin32(float x, float y) {\n  return fmin(x, y);\n}\n\nSCALAR_FUN_ATTR float fpow32(float x, float y) {\n  return pow(x, y);\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR float fabs32(float x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR float fmax32(float x, float y) {\n  return isnan(x) ? y : isnan(y) ? x : max(x, y);\n}\n\nSCALAR_FUN_ATTR float fmin32(float x, float y) {\n  return isnan(x) ? y : isnan(y) ? x : min(x, y);\n}\n\nSCALAR_FUN_ATTR float fpow32(float a, float b) {\n  float ret;\n  foreach_active (i) {\n      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));\n      ret = insert(ret, i, r);\n  }\n  return ret;\n}\n\n#else // Not OpenCL, but CUDA or plain C.\n\nSCALAR_FUN_ATTR float fabs32(float x) {\n  return fabsf(x);\n}\n\nSCALAR_FUN_ATTR float fmax32(float x, float y) {\n  return fmaxf(x, y);\n}\n\nSCALAR_FUN_ATTR float fmin32(float x, float y) {\n  return fminf(x, y);\n}\n\nSCALAR_FUN_ATTR float fpow32(float x, float y) {\n  return powf(x, y);\n}\n#endif\n\nSCALAR_FUN_ATTR bool futrts_isnan32(float x) {\n  return isnan(x);\n}\n\n#if ISPC\n\nSCALAR_FUN_ATTR bool futrts_isinf32(float x) {\n  return !isnan(x) && isnan(x - x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isfinite32(float x) {\n  return !isnan(x) && !futrts_isinf32(x);\n}\n\n#else\n\nSCALAR_FUN_ATTR bool futrts_isinf32(float x) {\n  return isinf(x);\n}\n\n#endif\n\nSCALAR_FUN_ATTR int8_t fptosi_f32_i8(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f32_i16(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f32_i32(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f32_i64(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  };\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f32_i8(float x) {", "\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f32_i16(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f32_i32(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f32_i64(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR bool ftob_f32_bool(float x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR float btof_bool_f32(bool x) {\n  return x ? 1 : 0;\n}\n\n#ifdef __OPENCL_VERSION__\nSCALAR_FUN_ATTR float futrts_log32(float x) {\n  return log(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log2_32(float x) {\n  return log2(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log10_32(float x) {\n  return log10(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log1p_32(float x) {\n  return log1p(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sqrt32(float x) {\n  return sqrt(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cbrt32(float x) {\n  return cbrt(x);\n}\n\nSCALAR_FUN_ATTR float futrts_exp32(float x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cos32(float x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sin32(float x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tan32(float x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acos32(float x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asin32(float x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan32(float x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cosh32(float x) {\n  return cosh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sinh32(float x) {\n  return sinh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tanh32(float x) {\n  return tanh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acosh32(float x) {\n  return acosh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asinh32(float x) {\n  return asinh(x);\n}\n\nSC",
                                    "ALAR_FUN_ATTR float futrts_atanh32(float x) {\n  return atanh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {\n  return atan2(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {\n  return hypot(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_gamma32(float x) {\n  return tgamma(x);\n}\n\nSCALAR_FUN_ATTR float futrts_lgamma32(float x) {\n  return lgamma(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erf32(float x) {\n  return erf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erfc32(float x) {\n  return erfc(x);\n}\n\nSCALAR_FUN_ATTR float fmod32(float x, float y) {\n  return fmod(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_round32(float x) {\n  return rint(x);\n}\n\nSCALAR_FUN_ATTR float futrts_floor32(float x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR float futrts_ceil32(float x) {\n  return ceil(x);\n}\n\nSCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {\n  return nextafter(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {\n  return mix(v0, v1, t);\n}\n\nSCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {\n  return ldexp(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {\n  return copysign(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {\n  return mad(a, b, c);\n}\n\nSCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {\n  return fma(a, b, c);\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR float futrts_log32(float x) {\n  return futrts_isfinite32(x) || (futrts_isinf32(x) && x < 0)? log(x) : x;\n}\n\nSCALAR_FUN_ATTR float futrts_log2_32(float x) {\n  return futrts_log32(x) / log(2.0f);\n}\n\nSCALAR_FUN_ATTR float futrts_log10_32(float x) {\n  return futrts_log32(x) / log(10.0f);\n}\n\nSCALAR_FUN_ATTR float futrts_log1p_32(float x) {\n  if(x == -1.0f || (futrts_isinf32(x) && x > 0.0f)) return x / 0.0f;\n  float y = 1.0f + x;\n  float z = y - 1.0f;\n  return log(y) - (z-x)/y;\n}\n\nSCALAR_FUN_ATTR float futrts_sqrt32(float x) {\n  return sqrt(x);\n}\n\nextern \"C\" unmasked uniform float cbrtf(uniform float);\nSCALAR_FUN_ATTR float futrts_cbrt32(float", " x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = cbrtf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR float futrts_exp32(float x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cos32(float x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sin32(float x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tan32(float x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acos32(float x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asin32(float x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan32(float x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cosh32(float x) {\n  return (exp(x)+exp(-x)) / 2.0f;\n}\n\nSCALAR_FUN_ATTR float futrts_sinh32(float x) {\n  return (exp(x)-exp(-x)) / 2.0f;\n}\n\nSCALAR_FUN_ATTR float futrts_tanh32(float x) {\n  return futrts_sinh32(x)/futrts_cosh32(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acosh32(float x) {\n  float f = x+sqrt(x*x-1);\n  if(futrts_isfinite32(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR float futrts_asinh32(float x) {\n  float f = x+sqrt(x*x+1);\n  if(futrts_isfinite32(f)) return log(f);\n  return f;\n\n}\n\nSCALAR_FUN_ATTR float futrts_atanh32(float x) {\n  float f = (1+x)/(1-x);\n  if(futrts_isfinite32(f)) return log(f)/2.0f;\n  return f;\n\n}\n\nSCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {\n  return (x == 0.0f && y == 0.0f) ? 0.0f : atan2(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {\n  if (futrts_isfinite32(x) && futrts_isfinite32(y)) {\n    x = abs(x);\n    y = abs(y);\n    float a;\n    float b;\n    if (x >= y){\n        a = x;\n        b = y;\n    } else {\n        a = y;\n        b = x;\n    }\n    if(b == 0){\n      return a;\n    }\n\n    int e;\n    float an;\n    float bn;\n    an = frexp (a, &e);\n    bn = ldexp (b, - e);\n    float cn;\n    cn = sqrt (an * an + bn * bn);\n    return ldexp (cn, e);\n  } else {\n    if (futrts_isinf32(x) || futrts_isinf32(y)) return INFINITY;\n    else return x + y;\n  }\n\n}\n\nextern \"C\" unmasked uniform float tgammaf(", "uniform float x);\nSCALAR_FUN_ATTR float futrts_gamma32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = tgammaf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float lgammaf(uniform float x);\nSCALAR_FUN_ATTR float futrts_lgamma32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = lgammaf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float erff(uniform float x);\nSCALAR_FUN_ATTR float futrts_erf32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = erff(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float erfcf(uniform float x);\nSCALAR_FUN_ATTR float futrts_erfc32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = erfcf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR float fmod32(float x, float y) {\n  return x - y * trunc(x/y);\n}\n\nSCALAR_FUN_ATTR float futrts_round32(float x) {\n  return round(x);\n}\n\nSCALAR_FUN_ATTR float futrts_floor32(float x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR float futrts_ceil32(float x) {\n  return ceil(x);\n}\n\nextern \"C\" unmasked uniform float nextafterf(uniform float x, uniform float y);\nSCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {\n  float res;\n  foreach_active (i) {\n    uniform float r = nextafterf(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {\n  return x * pow((double)2.0, (double)y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {\n  int32_t xb = futrts_to_bits32(x);\n  int32_t yb = futrts_to_bits32(y);\n  return futrts_from_bits32((xb & ~(1<<31)) | (yb & (1<<31)));\n}\n\nSCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR float futr",
                                    "ts_fma32(float a, float b, float c) {\n  return a * b + c;\n}\n\n#else // Not OpenCL or ISPC, but CUDA or plain C.\n\nSCALAR_FUN_ATTR float futrts_log32(float x) {\n  return logf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log2_32(float x) {\n  return log2f(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log10_32(float x) {\n  return log10f(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log1p_32(float x) {\n  return log1pf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sqrt32(float x) {\n  return sqrtf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cbrt32(float x) {\n  return cbrtf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_exp32(float x) {\n  return expf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cos32(float x) {\n  return cosf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sin32(float x) {\n  return sinf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tan32(float x) {\n  return tanf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acos32(float x) {\n  return acosf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asin32(float x) {\n  return asinf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan32(float x) {\n  return atanf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cosh32(float x) {\n  return coshf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sinh32(float x) {\n  return sinhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tanh32(float x) {\n  return tanhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acosh32(float x) {\n  return acoshf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asinh32(float x) {\n  return asinhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atanh32(float x) {\n  return atanhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {\n  return atan2f(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {\n  return hypotf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_gamma32(float x) {\n  return tgammaf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_lgamma32(float x) {\n  return lgammaf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erf32(float x) {\n  return erff(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erfc32(float x) {\n  return erfcf(x);\n}\n\nSCALAR_FUN_ATTR float fmod32(float x, float y) {\n  return fmodf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_round32(float x) {\n  re", "turn rintf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_floor32(float x) {\n  return floorf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_ceil32(float x) {\n  return ceilf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {\n  return nextafterf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {\n  return ldexpf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {\n  return copysignf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {\n  return fmaf(a, b, c);\n}\n#endif\n\n#if ISPC\nSCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {\n  return intbits(x);\n}\n\nSCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {\n  return floatbits(x);\n}\n#else\nSCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {\n  union {\n    float f;\n    int32_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {\n  union {\n    int32_t f;\n    float t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n#endif\n\nSCALAR_FUN_ATTR float fsignum32(float x) {\n  return futrts_isnan32(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nSCALAR_FUN_ATTR double futrts_from_bits64(int64_t x);\nSCALAR_FUN_ATTR int64_t futrts_to_bits64(double x);\n\n#if ISPC\nSCALAR_FUN_ATTR bool futrts_isinf64(float x) {\n  return !isnan(x) && isnan(x - x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isfinite64(float x) {\n  return !isnan(x) && !futrts_isinf64(x);\n}\n\nSCALAR_FUN_ATTR double fdiv64(double x, double y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR double fadd64(double x, double y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR double fsub64(double x, double y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR double fmul64(double x, double y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt64(double x, double y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple64(double x, double y) {\n  return x <= y;\n}", "\n\nSCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double fabs64(double x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR double fmax64(double x, double y) {\n  return isnan(x) ? y : isnan(y) ? x : max(x, y);\n}\n\nSCALAR_FUN_ATTR double fmin64(double x, double y) {\n  return isnan(x) ? y : isnan(y) ? x : min(x, y);\n}\n\nSCALAR_FUN_ATTR double fpow64(double a, double b) {\n  float ret;\n  foreach_active (i) {\n      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));\n      ret = insert(ret, i, r);\n  }\n  return ret;\n}\n\nSCALAR_FUN_ATTR double futrts_log64(double x) {\n  return futrts_isfinite64(x) || (futrts_isinf64(x) && x < 0)? log(x) : x;\n}\n\nSCALAR_FUN_ATTR double futrts_log2_64(double x) {\n  return futrts_log64(x)/log(2.0d);\n}\n\nSCALAR_FUN_ATTR double futrts_log10_64(double x) {\n  return futrts_log64(x)/log(10.0d);\n}\n\nSCALAR_FUN_ATTR double futrts_log1p_64(double x) {\n  if(x == -1.0d || (futrts_isinf64(x) && x > 0.0d)) return x / 0.0d;\n  double y = 1.0d + x;\n  double z = y - 1.0d;\n  return log(y) - (z-x)/y;\n}\n\nSCALAR_FUN_ATTR double futrts_sqrt64(double x) {\n  return sqrt(x);\n}\n\nextern \"C\" unmasked uniform double cbrt(uniform double);\nSCALAR_FUN_ATTR double futrts_cbrt64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = cbrtf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_exp64(double x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cos64(dou",
                                    "ble x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sin64(double x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_tan64(double x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acos64(double x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_asin64(double x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atan64(double x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cosh64(double x) {\n  return (exp(x)+exp(-x)) / 2.0d;\n}\n\nSCALAR_FUN_ATTR double futrts_sinh64(double x) {\n  return (exp(x)-exp(-x)) / 2.0d;\n}\n\nSCALAR_FUN_ATTR double futrts_tanh64(double x) {\n  return futrts_sinh64(x)/futrts_cosh64(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acosh64(double x) {\n  double f = x+sqrt(x*x-1.0d);\n  if(futrts_isfinite64(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR double futrts_asinh64(double x) {\n  double f = x+sqrt(x*x+1.0d);\n  if(futrts_isfinite64(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR double futrts_atanh64(double x) {\n  double f = (1.0d+x)/(1.0d-x);\n  if(futrts_isfinite64(f)) return log(f)/2.0d;\n  return f;\n\n}\n\nSCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {\n  return atan2(x, y);\n}\n\nextern \"C\" unmasked uniform double hypot(uniform double x, uniform double y);\nSCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {\n  double res;\n  foreach_active (i) {\n    uniform double r = hypot(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double tgamma(uniform double x);\nSCALAR_FUN_ATTR double futrts_gamma64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = tgamma(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double lgamma(uniform double x);\nSCALAR_FUN_ATTR double futrts_lgamma64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = lgamma(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double erf(uniform double x);\nSCALAR_FUN_ATTR do", "uble futrts_erf64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = erf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double erfc(uniform double x);\nSCALAR_FUN_ATTR double futrts_erfc64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = erfc(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR double futrts_round64(double x) {\n  return round(x);\n}\n\nSCALAR_FUN_ATTR double futrts_ceil64(double x) {\n  return ceil(x);\n}\n\nextern \"C\" unmasked uniform double nextafter(uniform float x, uniform double y);\nSCALAR_FUN_ATTR float futrts_nextafter64(double x, double y) {\n  double res;\n  foreach_active (i) {\n    uniform double r = nextafter(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_floor64(double x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isnan64(double x) {\n  return isnan(x);\n}\n\nSCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int", "16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR bool ftob_f64_bool(double x) {\n  return x != 0.0;\n}\n\nSCALAR_FUN_ATTR double btof_bool_f64(bool x) {\n  return x ? 1.0 : 0.0;\n}\n\nSCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {\n  int64_t res;\n  foreach_active (i) {\n    uniform double tmp = extract(x, i);\n    uniform int64_t r = *((uniform int64_t* uniform)&tmp);\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {\n  double res;\n  foreach_active (i) {\n    uniform int64_t tmp = extract(x, i);\n    uniform double r = *((uniform double* uniform)&tmp);\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double fmod64(double x, double y) {\n  return x - y * trunc(x/y);\n}\n\nSCALAR_FUN_ATTR double fsignum64(double x) {\n  return futrts_isnan64(x) ? x : (x > 0 ? 1.0d : 0.0d) - (x < 0 ? 1.0d : 0.0d);\n}\n\nSCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {\n  return x * pow((double)2.0, (double)y);\n}\n\nSCALAR_FUN_ATTR double futrts_copysign64(double x, double y) {\n  int64_t xb = futrts_to_bits64(x);\n  int64_t yb = futrts_to_bits64(y);\n  return futrts_from_bits64((xb & ~(((int64_t)1)<<63)) | (yb & (((int64_t)1)<<63)));\n}\n\nSCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR float fpconv_f32_f32(float x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f32_f64(float x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR float fpconv_f64_f32(double x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f64_f64(double x) {\n  return (double) x;\n}\n\n#e",
                                    "lse\n\nSCALAR_FUN_ATTR double fdiv64(double x, double y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR double fadd64(double x, double y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR double fsub64(double x, double y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR double fmul64(double x, double y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt64(double x, double y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple64(double x, double y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double fabs64(double x) {\n  return fabs(x);\n}\n\nSCALAR_FUN_ATTR double fmax64(double x, double y) {\n  return fmax(x, y);\n}\n\nSCALAR_FUN_ATTR double fmin64(double x, double y) {\n  return fmin(x, y);\n}\n\nSCALAR_FUN_ATTR double fpow64(double x, double y) {\n  return pow(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_log64(double x) {\n  return log(x);\n}\n\nSCALAR_FUN_ATTR double futrts_log2_64(double x) {\n  return log2(x);\n}\n\nSCALAR_FUN_ATTR double futrts_log10_64(double x) {\n  return log10(x);\n}\n\nSCALAR_FUN_ATTR double futrts_log1p_64(double x) {\n  return log1p(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sqrt64(double x) {\n  return sqrt(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cbrt64(double x) {\n  return cbrt(x);\n}\n\nSCALAR_FUN_ATTR double futrts_exp64(double x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cos64(double x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sin64(double x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_tan64(double x) {\n  r", "eturn tan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acos64(double x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_asin64(double x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atan64(double x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cosh64(double x) {\n  return cosh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sinh64(double x) {\n  return sinh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_tanh64(double x) {\n  return tanh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acosh64(double x) {\n  return acosh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_asinh64(double x) {\n  return asinh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atanh64(double x) {\n  return atanh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {\n  return atan2(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {\n  return hypot(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_gamma64(double x) {\n  return tgamma(x);\n}\n\nSCALAR_FUN_ATTR double futrts_lgamma64(double x) {\n  return lgamma(x);\n}\n\nSCALAR_FUN_ATTR double futrts_erf64(double x) {\n  return erf(x);\n}\n\nSCALAR_FUN_ATTR double futrts_erfc64(double x) {\n  return erfc(x);\n}\n\nSCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {\n  return fma(a, b, c);\n}\n\nSCALAR_FUN_ATTR double futrts_round64(double x) {\n  return rint(x);\n}\n\nSCALAR_FUN_ATTR double futrts_ceil64(double x) {\n  return ceil(x);\n}\n\nSCALAR_FUN_ATTR float futrts_nextafter64(float x, float y) {\n  return nextafter(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_floor64(double x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isnan64(double x) {\n  return isnan(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isinf64(double x) {\n  return isinf(x);\n}\n\nSCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x", ") {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR bool ftob_f64_bool(double x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR double btof_bool_f64(bool x) {\n  return x ? 1 : 0;\n}\n\nSCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {\n  union {\n    double f;\n    int64_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {\n  union {\n    int64_t f;\n    double t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR double fmod64(double x, double y) {\n  return fmod(x, y);\n}\n\nSCALAR_FUN_ATTR double fsignum64(double x) {\n  return futrts_isnan64(x) ? x : (x > 0) - (x < 0);\n}\n\nSCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {\n#ifdef __OPENCL_VERSION__\n  return mix(v0, v1, t);\n#else\n  return v0 + (v1 - v0) * t;\n#endif\n}\n\nSCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {\n  return ldexp(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign64(double x, double y) {\n  return copysign(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {\n#ifdef __OPENCL_VERSION__\n  return mad(a, b, c);\n#else\n  return a * b + c;\n#endif\n}\n\nSCALAR",
                                    "_FUN_ATTR float fpconv_f32_f32(float x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f32_f64(float x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR float fpconv_f64_f32(double x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f64_f64(double x) {\n  return (double) x;\n}\n\n#endif\n\n#endif\n\n// End of scalar.h.\n// Start of scalar_f16.h.\n\n// Half-precision is emulated if needed (e.g. in straight C) with the\n// native type used if possible.  The emulation works by typedef'ing\n// 'float' to 'f16', and then implementing all operations on single\n// precision.  To cut down on duplication, we use the same code for\n// those Futhark functions that require just operators or casts.  The\n// in-memory representation for arrays will still be 16 bits even\n// under emulation, so the compiler will have to be careful when\n// generating reads or writes.\n\n#if !defined(cl_khr_fp16) && !(defined(__CUDA_ARCH__) && __CUDA_ARCH__ >= 600) && !(defined(ISPC))\n#define EMULATE_F16\n#endif\n\n#if !defined(EMULATE_F16) && defined(__OPENCL_VERSION__)\n#pragma OPENCL EXTENSION cl_khr_fp16 : enable\n#endif\n\n#ifdef EMULATE_F16\n\n// Note that the half-precision storage format is still 16 bits - the\n// compiler will have to be real careful!\ntypedef float f16;\n\n#elif ISPC\ntypedef float16 f16;\n\n#else\n\n#ifdef __CUDA_ARCH__\n#include <cuda_fp16.h>\n#endif\n\ntypedef half f16;\n\n#endif\n\n// Some of these functions convert to single precision because half\n// precision versions are not available.\n\nSCALAR_FUN_ATTR f16 fadd16(f16 x, f16 y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR f16 fsub16(f16 x, f16 y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR f16 fmul16(f16 x, f16 y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt16(f16 x, f16 y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple16(f16 x, f16 y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR f16 sitofp_i8_f16(int8_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 sitofp_i16_f16(int16_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 sitofp_i32_f16(int32_t x) {\n  return (f16) x;\n}\n\nSCALAR", "_FUN_ATTR f16 sitofp_i64_f16(int64_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i8_f16(uint8_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i16_f16(uint16_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i32_f16(uint32_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i64_f16(uint64_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR int8_t fptosi_f16_i8(f16 x) {\n  return (int8_t) (float) x;\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f16_i16(f16 x) {\n  return (int16_t) x;\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f16_i32(f16 x) {\n  return (int32_t) x;\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f16_i64(f16 x) {\n  return (int64_t) x;\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f16_i8(f16 x) {\n  return (uint8_t) (float) x;\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f16_i16(f16 x) {\n  return (uint16_t) x;\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f16_i32(f16 x) {\n  return (uint32_t) x;\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f16_i64(f16 x) {\n  return (uint64_t) x;\n}\n\nSCALAR_FUN_ATTR bool ftob_f16_bool(f16 x) {\n  return x != (f16)0;\n}\n\nSCALAR_FUN_ATTR f16 btof_bool_f16(bool x) {\n  return x ? 1 : 0;\n}\n\n#ifndef EMULATE_F16\nSCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {\n  return isnan((float)x);\n}\n\n#ifdef __OPENCL_VERSION__\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return fabs(x);\n}\n\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return fmax(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {\n  return fmin(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return pow(x, y);\n}\n\n#elif ISPC\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : max(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {\n  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : min(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return pow(x, y);\n}\n\n#else // Assuming CUDA.\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return fabsf(x);\n}\n\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return fmaxf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 ", "x, f16 y) {\n  return fminf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return powf(x, y);\n}\n#endif\n\n#if ISPC\nSCALAR_FUN_ATTR bool futrts_isinf16(float x) {\n  return !futrts_isnan16(x) && futrts_isnan16(x - x);\n}\nSCALAR_FUN_ATTR bool futrts_isfinite16(float x) {\n  return !futrts_isnan16(x) && !futrts_isinf16(x);\n}\n\n#else\n\nSCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {\n  return isinf((float)x);\n}\n#endif\n\n#ifdef __OPENCL_VERSION__\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return log(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return log2(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return log10(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  return log1p(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return sqrt(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  return cbrt(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  return cosh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return sinh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return tanh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  return acosh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  return asinh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  return atanh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return atan2(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return hypot(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {\n  return tgamma(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  return lgamma(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  return e",
                                    "rf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  return erfc(x);\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return fmod(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return rint(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return ceil(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {\n  return nextafter(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return mix(v0, v1, t);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return ldexp(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return copysign(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return mad(a, b, c);\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return fma(a, b, c);\n}\n#elif ISPC\n\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return futrts_isfinite16(x) || (futrts_isinf16(x) && x < 0) ? log(x) : x;\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return futrts_log16(x) / log(2.0f16);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return futrts_log16(x) / log(10.0f16);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  if(x == -1.0f16 || (futrts_isinf16(x) && x > 0.0f16)) return x / 0.0f16;\n  f16 y = 1.0f16 + x;\n  f16 z = y - 1.0f16;\n  return log(y) - (z-x)/y;\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return (float16)sqrt((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return (float16)cos((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return (float16)sin((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return (float16)tan((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return (float16)acos((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return (float16)asin((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return (float16)atan((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  retu", "rn (exp(x)+exp(-x)) / 2.0f16;\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return (exp(x)-exp(-x)) / 2.0f16;\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return futrts_sinh16(x)/futrts_cosh16(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  float16 f = x+(float16)sqrt((float)(x*x-1));\n  if(futrts_isfinite16(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  float16 f = x+(float16)sqrt((float)(x*x+1));\n  if(futrts_isfinite16(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  float16 f = (1+x)/(1-x);\n  if(futrts_isfinite16(f)) return log(f)/2.0f16;\n  return f;\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return (float16)atan2((float)x, (float)y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return (float16)futrts_hypot32((float)x, (float)y);\n}\n\nextern \"C\" unmasked uniform float tgammaf(uniform float x);\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {\n  f16 res;\n  foreach_active (i) {\n    uniform f16 r = (f16)tgammaf(extract((float)x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float lgammaf(uniform float x);\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  f16 res;\n  foreach_active (i) {\n    uniform f16 r = (f16)lgammaf(extract((float)x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  f16 res = (f16)futrts_cbrt32((float)x);\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  f16 res = (f16)futrts_erf32((float)x);\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  f16 res = (f16)futrts_erfc32((float)x);\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return x - y * (float16)trunc((float) (x/y));\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return (float16)round((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return (float16)floor((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return (float16)ceil((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrt", "s_nextafter16(f16 x, f16 y) {\n  return (float16)futrts_nextafter32((float)x, (float) y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return futrts_ldexp32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return futrts_copysign32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\n#else // Assume CUDA.\n\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return hlog(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return hlog2(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return hlog10(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  return (f16)log1pf((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return hsqrt(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  return cbrtf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return hexp(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return hcos(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return hsin(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return tanf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return acosf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return asinf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return atanf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  return coshf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return sinhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return tanhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  return acoshf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  return asinhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  return atanhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return atan2f(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return hypotf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_gamma16(f1",
                                    "6 x) {\n  return tgammaf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  return lgammaf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  return erff(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  return erfcf(x);\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return fmodf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return rintf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return hfloor(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return hceil(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {\n  return __ushort_as_half(halfbitsnextafter(__half_as_ushort(x), __half_as_ushort(y)));\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return futrts_ldexp32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return futrts_copysign32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return fmaf(a, b, c);\n}\n\n#endif\n\n// The CUDA __half type cannot be put in unions for some reason, so we\n// use bespoke conversion functions instead.\n#ifdef __CUDA_ARCH__\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  return __half_as_ushort(x);\n}\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  return __ushort_as_half(x);\n}\n#elif ISPC\n\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  varying int16_t y = *((varying int16_t * uniform)&x);\n  return y;\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  varying f16 y = *((varying f16 * uniform)&x);\n  return y;\n}\n#else\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  union {\n    f16 f;\n    int16_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  union {\n    int16_t f;\n    f16 t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n#endif\n\n#else // No native f16 - emulate.\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return fabs32(x);\n}\n\nSC", "ALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return fmax32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {\n  return fmin32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return fpow32(x, y);\n}\n\nSCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {\n  return futrts_isnan32(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {\n  return futrts_isinf32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return futrts_log32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return futrts_log2_32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return futrts_log10_32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  return futrts_log1p_32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return futrts_sqrt32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  return futrts_cbrt32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return futrts_exp32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return futrts_cos32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return futrts_sin32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return futrts_tan32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return futrts_acos32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return futrts_asin32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return futrts_atan32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  return futrts_cosh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return futrts_sinh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return futrts_tanh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  return futrts_acosh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  return futrts_asinh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  return futrts_atanh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return futrts_atan2_32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return futrts_hypot32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {\n  return futrts_gamma32(x);\n}\n\nSCA", "LAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  return futrts_lgamma32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  return futrts_erf32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  return futrts_erfc32(x);\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return fmod32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return futrts_round32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return futrts_floor32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return futrts_ceil32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {\n  return halfbits2float(halfbitsnextafter(float2halfbits(x), float2halfbits(y)));\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return futrts_lerp32(v0, v1, t);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return futrts_ldexp32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return futrts_copysign32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return futrts_mad32(a, b, c);\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return futrts_fma32(a, b, c);\n}\n\n// Even when we are using an OpenCL that does not support cl_khr_fp16,\n// it must still support vload_half for actually creating a\n// half-precision number, which can then be efficiently converted to a\n// float.  Similarly for vstore_half.\n#ifdef __OPENCL_VERSION__\n\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  int16_t y;\n  // Violating strict aliasing here.\n  vstore_half((float)x, 0, (half*)&y);\n  return y;\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  return (f16)vload_half(0, (half*)&x);\n}\n\n#else\n\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  return (int16_t)float2halfbits(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  return halfbits2float((uint16_t)x);\n}\n\nSCALAR_FUN_ATTR f16 fsignum16(f16 x) {\n  return futrts_isnan16(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);\n}\n\n#endif\n\n#endif\n\nSCALAR_FUN_ATTR float fpconv_f16_f16(f16 x) {\n  retu",
                                    "rn x;\n}\n\nSCALAR_FUN_ATTR float fpconv_f16_f32(f16 x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR f16 fpconv_f32_f16(float x) {\n  return (f16) x;\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nSCALAR_FUN_ATTR double fpconv_f16_f64(f16 x) {\n  return (double) x;\n}\n\n#if ISPC\nSCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {\n  return (f16) ((float)x);\n}\n#else\nSCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {\n  return (f16) x;\n}\n#endif\n#endif\n\n\n// End of scalar_f16.h.\n// Start of atomics.h\n\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_global(volatile __global int32_t *p,\n                                                         int32_t cmp, int32_t val);\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_shared(volatile __local int32_t *p,\n                                                        int32_t cmp, int32_t val);\nSCALAR_FUN_ATTR int32_t atomic_add_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_add_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR float atomic_fadd_f32_global(volatile __global float *p, float x);\nSCALAR_FUN_ATTR float atomic_fadd_f32_shared(volatile __local float *p, float x);\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_global(volatile __global uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_shared(volatile __local uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_global(volatile __global uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_shared(volatile __local uint32", "_t *p, uint32_t x);\nSCALAR_FUN_ATTR int32_t atomic_and_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_and_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_or_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_or_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_shared(volatile __local int32_t *p, int32_t x);\n\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_global(volatile __global int32_t *p,\n                                                         int32_t cmp, int32_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((int32_t*)p, cmp, val);\n#else\n  return atomic_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_shared(volatile __local int32_t *p,\n                                                        int32_t cmp, int32_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((int32_t*)p, cmp, val);\n#else\n  return atomic_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_add_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((int32_t*)p, x);\n#else\n  return atomic_add(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_add_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((int32_t*)p, x);\n#el", "se\n  return atomic_add(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR float atomic_fadd_f32_global(volatile __global float *p, float x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((float*)p, x);\n  // On OpenCL, use technique from\n  // https://pipinspace.github.io/blog/atomic-float-addition-in-opencl.html\n#elif defined(cl_nv_pragma_unroll)\n  // use hardware-supported atomic addition on Nvidia GPUs with inline\n  // PTX assembly\n  float ret;\n  asm volatile(\"atom.global.add.f32 %0,[%1],%2;\":\"=f\"(ret):\"l\"(p),\"f\"(x):\"memory\");\n  return ret;\n#elif defined(__opencl_c_ext_fp32_global_atomic_add)\n  // use hardware-supported atomic addition on some Intel GPUs\n  return atomic_fetch_add_explicit((volatile __global atomic_float*)p,\n                                   x,\n                                   memory_order_relaxed);\n#elif __has_builtin(__builtin_amdgcn_global_atomic_fadd_f32)\n  // use hardware-supported atomic addition on some AMD GPUs\n  return __builtin_amdgcn_global_atomic_fadd_f32(p, x);\n#else\n  // fallback emulation:\n  // https://forums.developer.nvidia.com/t/atomicadd-float-float-atomicmul-float-float/14639/5\n  float old = x;\n  float ret;\n  while ((old=atomic_xchg(p, ret=atomic_xchg(p, 0.0f)+old))!=0.0f);\n  return ret;\n#endif\n}\n\nSCALAR_FUN_ATTR float atomic_fadd_f32_shared(volatile __local float *p, float x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((float*)p, x);\n#else\n  union { int32_t i; float f; } old;\n  union { int32_t i; float f; } assumed;\n  old.f = *p;\n  do {\n    assumed.f = old.f;\n    old.f = old.f + x;\n    old.i = atomic_cmpxchg_i32_shared((volatile __local int32_t*)p, assumed.i, old.i);\n  } while (assumed.i != old.i);\n  return old.f;\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((int32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_shared(volatile",
                                    " __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((int32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((int32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((int32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_global(volatile __global uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_shared(volatile __local uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_global(volatile __global uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_shared(volatile __local uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_and_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((int32_t*)p, x);\n#else\n  return atomic_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_and_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((int32_t*)p, x);\n#else\n  return atomic_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_or_i32_global(volatile __global int32_t *p, ", "int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((int32_t*)p, x);\n#else\n  return atomic_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_or_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((int32_t*)p, x);\n#else\n  return atomic_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\n// Start of 64 bit atomics\n\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP) || defined(cl_khr_int64_base_atomics) && defined(cl_khr_int64_extended_atomics)\n\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_global(volatile __global int64_t *p,\n                                                         int64_t cmp, int64_t val);\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_shared(volatile __local int64_t *p,\n                                                        int64_t cmp, int64_t val);\nSCALAR_FUN_ATTR int64_t atomic_add_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_add_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR uint", "64_t atomic_umax_i64_global(volatile __global uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_shared(volatile __local uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_global(volatile __global uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_shared(volatile __local uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR int64_t atomic_and_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_and_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_or_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_or_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_shared(volatile __local int64_t *p, int64_t x);\n\n#ifdef FUTHARK_F64_ENABLED\nSCALAR_FUN_ATTR double atomic_fadd_f64_global(volatile __global double *p, double x);\nSCALAR_FUN_ATTR double atomic_fadd_f64_shared(volatile __local double *p, double x);\n#endif\n\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_global(volatile __global int64_t *p,\n                                                         int64_t cmp, int64_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((uint64_t*)p, cmp, val);\n#else\n  return atom_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_shared(volatile __local int64_t *p,\n                                                        int64_t cmp, int64_t val) {\n#if defined(F",
                                    "UTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((uint64_t*)p, cmp, val);\n#else\n  return atom_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_add_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((uint64_t*)p, x);\n#else\n  return atom_add(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_add_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((uint64_t*)p, x);\n#else\n  return atom_add(p, x);\n#endif\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nSCALAR_FUN_ATTR double atomic_fadd_f64_global(volatile __global double *p, double x) {\n#if defined(FUTHARK_CUDA) && __CUDA_ARCH__ >= 600 || defined(FUTHARK_HIP)\n  return atomicAdd((double*)p, x);\n  // On OpenCL, use technique from\n  // https://pipinspace.github.io/blog/atomic-float-addition-in-opencl.html\n#elif defined(cl_nv_pragma_unroll)\n  // use hardware-supported atomic addition on Nvidia GPUs with inline\n  // PTX assembly\n  double ret;\n  asm volatile(\"atom.global.add.f64 %0,[%1],%2;\":\"=d\"(ret):\"l\"(p),\"d\"(x):\"memory\");\n  return ret;\n#elif __has_builtin(__builtin_amdgcn_global_atomic_fadd_f64)\n  // use hardware-supported atomic addition on some AMD GPUs\n  return __builtin_amdgcn_global_atomic_fadd_f64(p, x);\n#else\n  // fallback emulation:\n  // https://forums.developer.nvidia.com/t/atomicadd-float-float-atomicmul-float-float/14639/5\n  union {int64_t i; double f;} old;\n  union {int64_t i; double f;} ret;\n  old.f = x;\n  while (1) {\n    ret.i = atom_xchg((volatile __global int64_t*)p, (int64_t)0);\n    ret.f += old.f;\n    old.i = atom_xchg((volatile __global int64_t*)p, ret.i);\n    if (old.i == 0) {\n      break;\n    }\n  }\n  return ret.f;\n#endif\n}\n\nSCALAR_FUN_ATTR double atomic_fadd_f64_shared(volatile __local double *p, double x) {\n#if defined(FUTHARK_CUDA) && __CUDA_ARCH__ >= 600 || defined(FUTHARK_HIP)\n  return atomicAdd((double*)p, x);\n#else\n  union { int64_t i; double f; } old;\n  u", "nion { int64_t i; double f; } assumed;\n  old.f = *p;\n  do {\n    assumed.f = old.f;\n    old.f = old.f + x;\n    old.i = atomic_cmpxchg_i64_shared((volatile __local int64_t*)p, assumed.i, old.i);\n  } while (assumed.i != old.i);\n  return old.f;\n#endif\n}\n\n#endif\n\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMax((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smax64(old, x);\n    old = atomic_cmpxchg_i64_global((volatile __global int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMax((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smax64(old, x);\n    old = atomic_cmpxchg_i64_shared((volatile __local int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMin((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smin64(old, x);\n    old = atomic_cmpxchg_i64_global((volatile __global int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMin((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do ", "{\n    assumed = old;\n    old = smin64(old, x);\n    old = atomic_cmpxchg_i64_shared((volatile __local int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_global(volatile __global uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint64_t*)p, x);\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_shared(volatile __local uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint64_t*)p, x);\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_global(volatile __global uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint64_t*)p, x);\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_shared(volatile __local uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint64_t*)p, x);\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_and_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((uint64_t*)p, x);\n#else\n  return atom_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_and_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((uint64_t*)p, x);\n#else\n  return atom_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_or_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((uint64_t*)p, x);\n#else\n  return atom_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_or_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((uint64_t*)p, x);\n#else\n  return atom_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_global(v",
                                    "olatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\n#endif // defined(FUTHARK_CUDA) || defined(FUTHARK_HIP) || defined(cl_khr_int64_base_atomics) && defined(cl_khr_int64_extended_atomics)\n\n// End of atomics.h\n// Start of transpose.cl\n\n#define GEN_TRANSPOSE_KERNELS(NAME, ELEM_TYPE)                          \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*2, TR_TILE_DIM/TR_ELEMS_PER_THREAD, 1)\\\nvoid map_transpose_##NAME(SHARED_MEM_PARAM                              \\\n                          __global ELEM_TYPE *dst_mem,                  \\\n                          int64_t dst_offset,                           \\\n                          __global ELEM_TYPE *src_mem,                  \\\n                          int64_t src_offset,                           \\\n                          int32_t num_arrays,                           \\\n                          int32_t x_elems,                              \\\n                          int32_t y_elems,                              \\\n                          int32_t mulx,                                 \\\n                          int32_t muly,                                 \\\n                          int32_t repeat_1,                             \\\n                          int32_t repeat_2) {                           \\\n  (void)mulx; (void)muly;                                               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_g", "lobal_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t x_index = global_id_0;                                    \\\n      int32_t y_index = tblock_id_1 * TR_TILE_DIM + get_local_id(1);    \\\n      if (x_index < x_elems) {                                          \\\n        for (int32_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int32_t index_i = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * x_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < y_elems) { \\\n            block[(get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * (TR_TILE_DIM+1) + \\\n                  get_local_id(0)] =                                    \\\n              src_mem[idata_offset + index_i];                          \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_TILE_DIM + get_local_id(0);            \\\n      y_index = tblock_id_0 * TR_TILE_DIM + get_local_id(1);            \\\n      if (x_index < y_elems) {                                          \\\n        for (int32_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int32_t index_out = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * y_elems + x_index; \\\n          if (y_in", "dex + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < x_elems) { \\\n            dst_mem[(odata_offset + index_out)] =                       \\\n              block[get_local_id(0) * (TR_TILE_DIM+1) +                 \\\n                    get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)]; \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM, TR_BLOCK_DIM, 1)                     \\\nvoid map_transpose_##NAME##_low_height(SHARED_MEM_PARAM                 \\\n                                                __global ELEM_TYPE *dst_mem, \\\n                                                int64_t dst_offset,     \\\n                                                __global ELEM_TYPE *src_mem, \\\n                                                int64_t src_offset,     \\\n                                                int32_t num_arrays,     \\\n                                                int32_t x_elems,        \\\n                                                int32_t y_elems,        \\\n                                                int32_t mulx,           \\\n                                                int32_t muly,           \\\n                                                int32_t repeat_1,       \\\n ",
                                    "                                               int32_t repeat_2) {     \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t x_index =                                                 \\\n        tblock_id_0 * TR_BLOCK_DIM * mulx +                             \\\n        get_local_id(0) +                                               \\\n        get_local_id(1)%mulx * TR_BLOCK_DIM;                            \\\n      int32_t y_index = tblock_id_1 * TR_BLOCK_DIM + get_local_id(1)/mulx; \\\n      int32_t index_in = y_index * x_elems + x_index;                   \\\n      if (x_index < x_elems && y_index < y_elems) {                     \\\n        block[get_local_id(1) * (TR_BLOCK_DIM+1) + get_local_id(0)] =   \\\n          src_mem[idata_offset + index_in];                             \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_BLOCK_DIM + get_local_id(0)/mulx;      \\\n      y_index =                                                         \\\n        tblock_id_0 * TR_BLOCK_DIM * mulx +                             \\\n", "        get_local_id(1) +                                               \\\n        (get_local_id(0)%mulx) * TR_BLOCK_DIM;                          \\\n      int32_t index_out = y_index * y_elems + x_index;                  \\\n      if (x_index < y_elems && y_index < x_elems) {                     \\\n        dst_mem[odata_offset + index_out] =                             \\\n          block[get_local_id(0) * (TR_BLOCK_DIM+1) + get_local_id(1)];  \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM, TR_BLOCK_DIM, 1)                     \\\nvoid map_transpose_##NAME##_low_width(SHARED_MEM_PARAM                  \\\n                                      __global ELEM_TYPE *dst_mem,      \\\n                                      int64_t dst_offset,               \\\n                                      __global ELEM_TYPE *src_mem,      \\\n                                      int64_t src_offset,               \\\n                                      int32_t num_arrays,               \\\n                                      int32_t x_elems,                  \\\n                                      int32_t y_elems,                  \\\n                                      int32_t mulx,                     \\\n                                      int32_t muly,                     \\\n                                      int32_t repeat_1,                 \\\n  ", "                                    int32_t repeat_2) {               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t x_index = tblock_id_0 * TR_BLOCK_DIM + get_local_id(0)/muly; \\\n      int32_t y_index =                                                 \\\n        tblock_id_1 * TR_BLOCK_DIM * muly +                             \\\n        get_local_id(1) + (get_local_id(0)%muly) * TR_BLOCK_DIM;        \\\n      int32_t index_in = y_index * x_elems + x_index;                   \\\n      if (x_index < x_elems && y_index < y_elems) {                     \\\n        block[get_local_id(1) * (TR_BLOCK_DIM+1) + get_local_id(0)] =   \\\n          src_mem[idata_offset + index_in];                             \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_BLOCK_DIM * muly +                     \\\n        get_local_id(0) + (get_local_id(1)%muly) * TR_BLOCK_DIM;        \\\n      y_index = tblock_id_0 * TR_BLOCK_DIM + get_local_id(1)/muly;      \\\n      int32_t index_out = y_index * y_elems + x_index;                  \\\n ",
                                    "     if (x_index < y_elems && y_index < x_elems) {                     \\\n        dst_mem[odata_offset + index_out] =                             \\\n          block[get_local_id(0) * (TR_BLOCK_DIM+1) + get_local_id(1)];  \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_num_tblocks(2) * get_local_size(2);            \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_num_tblocks(1) * get_local_size(1);              \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*TR_BLOCK_DIM, 1, 1)                   \\\nvoid map_transpose_##NAME##_small(SHARED_MEM_PARAM                       \\\n                                  __global ELEM_TYPE *dst_mem,          \\\n                                  int64_t dst_offset,                   \\\n                                  __global ELEM_TYPE *src_mem,          \\\n                                  int64_t src_offset,                   \\\n                                  int32_t num_arrays,                   \\\n                                  int32_t x_elems,                      \\\n                                  int32_t y_elems,                      \\\n                                  int32_t mulx,                         \\\n                                  int32_t muly,                         \\\n                                  int32_t repeat_1,                     \\\n                                  int32_t repeat_2) {                   \\\n  (void)mulx; (void)muly;                                               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  ", "int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = global_id_0/(y_elems * x_elems) * y_elems * x_elems; \\\n      int32_t x_index = (global_id_0 % (y_elems * x_elems))/y_elems;    \\\n      int32_t y_index = global_id_0%y_elems;                            \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t index_in = y_index * x_elems + x_index;                   \\\n      int32_t index_out = x_index * y_elems + y_index;                  \\\n      if (global_id_0 < x_elems * y_elems * num_arrays) {               \\\n        dst_mem[odata_offset + index_out] = src_mem[idata_offset + index_in]; \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*2, TR_TILE_DIM/TR_ELEMS_", "PER_THREAD, 1)\\\nvoid map_transpose_##NAME##_large(SHARED_MEM_PARAM                      \\\n                                  __global ELEM_TYPE *dst_mem,          \\\n                                  int64_t dst_offset,                   \\\n                                  __global ELEM_TYPE *src_mem,          \\\n                                  int64_t src_offset,                   \\\n                                  int64_t num_arrays,                   \\\n                                  int64_t x_elems,                      \\\n                                  int64_t y_elems,                      \\\n                                  int64_t mulx,                         \\\n                                  int64_t muly,                         \\\n                                  int32_t repeat_1,                     \\\n                                  int32_t repeat_2) {                   \\\n  (void)mulx; (void)muly;                                               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;             \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int64_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int64_t odata_offset = dst_offset + our_array_offset;             \\\n      int64_t idata_offset = src_offset + our_array_offset;             \\\n      int64_t x_index = global_id_0;                                    \\\n      int64_t y_index = tblock_id_1 * TR_TILE_DIM + get_loc",
                                    "al_id(1);    \\\n      if (x_index < x_elems) {                                          \\\n        for (int64_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int64_t index_i = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * x_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < y_elems) { \\\n            block[(get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * (TR_TILE_DIM+1) + \\\n                  get_local_id(0)] =                                    \\\n              src_mem[idata_offset + index_i];                          \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_TILE_DIM + get_local_id(0);            \\\n      y_index = tblock_id_0 * TR_TILE_DIM + get_local_id(1);            \\\n      if (x_index < y_elems) {                                          \\\n        for (int64_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int64_t index_out = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * y_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < x_elems) { \\\n            dst_mem[(odata_offset + index_out)] =                       \\\n              block[get_local_id(0) * (TR_TILE_DIM+1) +                 \\\n                    get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)]; \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                      ", "                             \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n\nGEN_TRANSPOSE_KERNELS(1b, uint8_t)\nGEN_TRANSPOSE_KERNELS(2b, uint16_t)\nGEN_TRANSPOSE_KERNELS(4b, uint32_t)\nGEN_TRANSPOSE_KERNELS(8b, uint64_t)\n\n// End of transpose.cl\n// Start of copy.cl\n\n#define GEN_COPY_KERNEL(NAME, ELEM_TYPE) \\\nFUTHARK_KERNEL void lmad_copy_##NAME(SHARED_MEM_PARAM                   \\\n                               __global ELEM_TYPE *dst_mem,             \\\n                               int64_t dst_offset,                      \\\n                               __global ELEM_TYPE *src_mem,             \\\n                               int64_t src_offset,                      \\\n                               int64_t n,                               \\\n                               int r,                                   \\\n                               int64_t shape0, int64_t dst_stride0, int64_t src_stride0, \\\n                               int64_t shape1, int64_t dst_stride1, int64_t src_stride1, \\\n                               int64_t shape2, int64_t dst_stride2, int64_t src_stride2, \\\n                               int64_t shape3, int64_t dst_stride3, int64_t src_stride3, \\\n                               int64_t shape4, int64_t dst_stride4, int64_t src_stride4, \\\n                               int64_t shape5, int64_t dst_stride5, int64_t src_stride5, \\\n                               int64_t shape6, int64_t dst_stride6, int64_t src_stride6, \\\n                               int64_t shape7, int64_t dst_stride7, int64_t src_stride7) { \\\n  int64_t gtid = get_global_id(0);                                      \\\n  int64_t remainder = gtid;                                             \\\n                                             ", "                           \\\n  if (gtid >= n) {                                                      \\\n    return;                                                             \\\n  }                                                                     \\\n                                                                        \\\n  if (r > 0) {                                                          \\\n    int64_t i = remainder % shape0;                                     \\\n    dst_offset += i * dst_stride0;                                      \\\n    src_offset += i * src_stride0;                                      \\\n    remainder /= shape0;                                                \\\n  }                                                                     \\\n  if (r > 1) {                                                          \\\n    int64_t i = remainder % shape1;                                     \\\n    dst_offset += i * dst_stride1;                                      \\\n    src_offset += i * src_stride1;                                      \\\n    remainder /= shape1;                                                \\\n  }                                                                     \\\n  if (r > 2) {                                                          \\\n    int64_t i = remainder % shape2;                                     \\\n    dst_offset += i * dst_stride2;                                      \\\n    src_offset += i * src_stride2;                                      \\\n    remainder /= shape2;                                                \\\n  }                                                                     \\\n  if (r > 3) {                                                          \\\n    int64_t i = remainder % shape3;                                     \\\n    dst_offset += i * dst_stride3;                                      \\\n    src_offset += i * src_stride3;                                      \\\n    remainder /= shape3;                       ",
                                    "                         \\\n  }                                                                     \\\n  if (r > 4) {                                                          \\\n    int64_t i = remainder % shape4;                                     \\\n    dst_offset += i * dst_stride4;                                      \\\n    src_offset += i * src_stride4;                                      \\\n    remainder /= shape4;                                                \\\n  }                                                                     \\\n  if (r > 5) {                                                          \\\n    int64_t i = remainder % shape5;                                     \\\n    dst_offset += i * dst_stride5;                                      \\\n    src_offset += i * src_stride5;                                      \\\n    remainder /= shape5;                                                \\\n  }                                                                     \\\n  if (r > 6) {                                                          \\\n    int64_t i = remainder % shape6;                                     \\\n    dst_offset += i * dst_stride6;                                      \\\n    src_offset += i * src_stride6;                                      \\\n    remainder /= shape6;                                                \\\n  }                                                                     \\\n  if (r > 7) {                                                          \\\n    int64_t i = remainder % shape7;                                     \\\n    dst_offset += i * dst_stride7;                                      \\\n    src_offset += i * src_stride7;                                      \\\n    remainder /= shape7;                                                \\\n  }                                                                     \\\n                                                                        \\\n  dst_mem[dst_offset] = src_mem[src_offset];     ", "                       \\\n}\n\nGEN_COPY_KERNEL(1b, uint8_t)\nGEN_COPY_KERNEL(2b, uint16_t)\nGEN_COPY_KERNEL(4b, uint32_t)\nGEN_COPY_KERNEL(8b, uint64_t)\n\n// End of copy.cl\n\n\n\nFUTHARK_KERNEL\nvoid builtinzhiota_i64ziiota_i64_27020(int64_t n_27016, int64_t x_27017, int64_t s_27018, int64_t virt_num_tblocks_27025, int64_t num_tblocks_27026, __global unsigned char *mem_27015)\n{\n    int32_t iota_ltid_27021;\n    int32_t tblock_sizze_27023;\n    int32_t iota_gid_27022;\n    int32_t iota_gtid_27020;\n    int32_t phys_tblock_id_27027;\n    int32_t iterations_27028;\n    \n    iota_ltid_27021 = get_local_id(0);\n    tblock_sizze_27023 = get_local_size(0);\n    iota_gid_27022 = get_tblock_id(0);\n    iota_gtid_27020 = iota_gid_27022 * tblock_sizze_27023 + iota_ltid_27021;\n    phys_tblock_id_27027 = get_tblock_id(0);\n    iterations_27028 = sdiv_up32(sext_i64_i32(virt_num_tblocks_27025) - phys_tblock_id_27027, sext_i64_i32(num_tblocks_27026));\n    for (int32_t i_27029 = 0; i_27029 < iterations_27028; i_27029++) {\n        int32_t virt_tblock_id_27030;\n        int64_t global_tid_27031;\n        \n        virt_tblock_id_27030 = phys_tblock_id_27027 + i_27029 * sext_i64_i32(num_tblocks_27026);\n        global_tid_27031 = sext_i32_i64(virt_tblock_id_27030) * sext_i32_i64(tblock_sizze_27023) + sext_i32_i64(iota_ltid_27021);\n        if (slt64(global_tid_27031, n_27016)) {\n            ((__global int64_t *) mem_27015)[global_tid_27031] = add64(mul64(global_tid_27031, s_27018), x_27017);\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_i32zireplicate_27049(int64_t num_elems_27045, int32_t val_27046, int64_t replicate_n_27048, int64_t virt_num_tblocks_27054, int64_t num_tblocks_27055, __global unsigned char *mem_27044)\n{\n    int32_t replicate_ltid_27050;\n    int32_t tblock_sizze_27052;\n    int32_t replicate_gid_27051;\n    int32_t replicate_gtid_27049;\n    int32_t phys_tblock_id_27056;\n    int32_t iterations_27057", ";\n    \n    replicate_ltid_27050 = get_local_id(0);\n    tblock_sizze_27052 = get_local_size(0);\n    replicate_gid_27051 = get_tblock_id(0);\n    replicate_gtid_27049 = replicate_gid_27051 * tblock_sizze_27052 + replicate_ltid_27050;\n    phys_tblock_id_27056 = get_tblock_id(0);\n    iterations_27057 = sdiv_up32(sext_i64_i32(virt_num_tblocks_27054) - phys_tblock_id_27056, sext_i64_i32(num_tblocks_27055));\n    for (int32_t i_27058 = 0; i_27058 < iterations_27057; i_27058++) {\n        int32_t virt_tblock_id_27059;\n        int64_t global_tid_27060;\n        int64_t slice_27062;\n        int64_t rep_i_27061;\n        int64_t remnant_27063;\n        \n        virt_tblock_id_27059 = phys_tblock_id_27056 + i_27058 * sext_i64_i32(num_tblocks_27055);\n        global_tid_27060 = sext_i32_i64(virt_tblock_id_27059) * sext_i32_i64(tblock_sizze_27052) + sext_i32_i64(replicate_ltid_27050);\n        slice_27062 = num_elems_27045;\n        rep_i_27061 = global_tid_27060;\n        remnant_27063 = global_tid_27060 - rep_i_27061;\n        if (slt64(global_tid_27060, replicate_n_27048)) {\n            ((__global int32_t *) mem_27044)[rep_i_27061] = val_27046;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_i64zireplicate_27023(int64_t num_elems_27019, int64_t val_27020, int64_t replicate_n_27022, int64_t virt_num_tblocks_27028, int64_t num_tblocks_27029, __global unsigned char *mem_27018)\n{\n    int32_t replicate_ltid_27024;\n    int32_t tblock_sizze_27026;\n    int32_t replicate_gid_27025;\n    int32_t replicate_gtid_27023;\n    int32_t phys_tblock_id_27030;\n    int32_t iterations_27031;\n    \n    replicate_ltid_27024 = get_local_id(0);\n    tblock_sizze_27026 = get_local_size(0);\n    replicate_gid_27025 = get_tblock_id(0);\n    replicate_gtid_27023 = replicate_gid_27025 * tblock_sizze_27026 + replicate_ltid_27024;\n    phys_tblock_id_27030 = get_tblock_id(0);\n    iterations_27031 = sdiv_up32(sext_i64_i32(virt_num",
                                    "_tblocks_27028) - phys_tblock_id_27030, sext_i64_i32(num_tblocks_27029));\n    for (int32_t i_27032 = 0; i_27032 < iterations_27031; i_27032++) {\n        int32_t virt_tblock_id_27033;\n        int64_t global_tid_27034;\n        int64_t slice_27036;\n        int64_t rep_i_27035;\n        int64_t remnant_27037;\n        \n        virt_tblock_id_27033 = phys_tblock_id_27030 + i_27032 * sext_i64_i32(num_tblocks_27029);\n        global_tid_27034 = sext_i32_i64(virt_tblock_id_27033) * sext_i32_i64(tblock_sizze_27026) + sext_i32_i64(replicate_ltid_27024);\n        slice_27036 = num_elems_27019;\n        rep_i_27035 = global_tid_27034;\n        remnant_27037 = global_tid_27034 - rep_i_27035;\n        if (slt64(global_tid_27034, replicate_n_27022)) {\n            ((__global int64_t *) mem_27018)[rep_i_27035] = val_27020;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_i8zireplicate_27405(int64_t num_elems_27401, int8_t val_27402, int64_t replicate_n_27404, int64_t virt_num_tblocks_27410, int64_t num_tblocks_27411, __global unsigned char *mem_27400)\n{\n    int32_t replicate_ltid_27406;\n    int32_t tblock_sizze_27408;\n    int32_t replicate_gid_27407;\n    int32_t replicate_gtid_27405;\n    int32_t phys_tblock_id_27412;\n    int32_t iterations_27413;\n    \n    replicate_ltid_27406 = get_local_id(0);\n    tblock_sizze_27408 = get_local_size(0);\n    replicate_gid_27407 = get_tblock_id(0);\n    replicate_gtid_27405 = replicate_gid_27407 * tblock_sizze_27408 + replicate_ltid_27406;\n    phys_tblock_id_27412 = get_tblock_id(0);\n    iterations_27413 = sdiv_up32(sext_i64_i32(virt_num_tblocks_27410) - phys_tblock_id_27412, sext_i64_i32(num_tblocks_27411));\n    for (int32_t i_27414 = 0; i_27414 < iterations_27413; i_27414++) {\n        int32_t virt_tblock_id_27415;\n        int64_t global_tid_27416;\n        int64_t slice_27418;\n        int64_t rep_i_27417;\n        int64_t remnant_27419;\n        \n        virt_tblo", "ck_id_27415 = phys_tblock_id_27412 + i_27414 * sext_i64_i32(num_tblocks_27411);\n        global_tid_27416 = sext_i32_i64(virt_tblock_id_27415) * sext_i32_i64(tblock_sizze_27408) + sext_i32_i64(replicate_ltid_27406);\n        slice_27418 = num_elems_27401;\n        rep_i_27417 = global_tid_27416;\n        remnant_27419 = global_tid_27416 - rep_i_27417;\n        if (slt64(global_tid_27416, replicate_n_27404)) {\n            ((__global int8_t *) mem_27400)[rep_i_27417] = val_27402;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzigpuseq_27038_dim1, 1, 1)\nvoid inner_SMJ_intzigpuseq_27038(__global int *global_failure, int64_t gt_rhs_21419, __global unsigned char *tR_mem_26243, __global unsigned char *mem_26251)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27040;\n    int32_t tblock_sizze_27043;\n    int32_t wave_sizze_27042;\n    int32_t block_id_27041;\n    int32_t global_tid_27039;\n    int64_t tid_27038;\n    int32_t x_26142;\n    \n    local_tid_27040 = get_local_id(0);\n    tblock_sizze_27043 = get_local_size(0);\n    wave_sizze_27042 = LOCKSTEP_WIDTH;\n    block_id_27041 = get_tblock_id(0);\n    global_tid_27039 = block_id_27041 * tblock_sizze_27043 + local_tid_27040;\n    tid_27038 = sext_i32_i64(global_tid_27039);\n    x_26142 = ((__global int32_t *) tR_mem_26243)[gt_rhs_21419];\n    ((__global int32_t *) mem_26251)[(int64_t) 0] = x_26142;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzigpuseq_27070_dim1, 1, 1)\nvoid inner_SMJ_intzigpuseq_27070(__global int *global_failure, int64_t tS_start_21436, __global unsigned char *tS_mem_26244, __global unsigned char *ext_mem_26252, __global unsigned char *mem_26259, __global unsigned char *mem_26260)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27072;\n    int32_t tblock_sizze_27075;\n    int32_t wave_sizze_27074;\n    int32_t block_id_27073;\n    int32_t global_tid_27071;\n    i", "nt64_t tid_27070;\n    int32_t gt_lhs_26146;\n    int32_t gt_rhs_26148;\n    bool defunc_0_gt_res_26150;\n    \n    local_tid_27072 = get_local_id(0);\n    tblock_sizze_27075 = get_local_size(0);\n    wave_sizze_27074 = LOCKSTEP_WIDTH;\n    block_id_27073 = get_tblock_id(0);\n    global_tid_27071 = block_id_27073 * tblock_sizze_27075 + local_tid_27072;\n    tid_27070 = sext_i32_i64(global_tid_27071);\n    gt_lhs_26146 = ((__global int32_t *) tS_mem_26244)[tS_start_21436];\n    gt_rhs_26148 = ((__global int32_t *) ext_mem_26252)[(int64_t) 0];\n    defunc_0_gt_res_26150 = slt32(gt_rhs_26148, gt_lhs_26146);\n    ((__global int32_t *) mem_26259)[(int64_t) 0] = gt_lhs_26146;\n    ((__global bool *) mem_26260)[(int64_t) 0] = defunc_0_gt_res_26150;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzigpuseq_27076_dim1, 1, 1)\nvoid inner_SMJ_intzigpuseq_27076(__global int *global_failure, int64_t i_p_m_t_s_21442, __global unsigned char *tS_mem_26244, __global unsigned char *mem_26526)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27078;\n    int32_t tblock_sizze_27081;\n    int32_t wave_sizze_27080;\n    int32_t block_id_27079;\n    int32_t global_tid_27077;\n    int64_t tid_27076;\n    int32_t x_26152;\n    \n    local_tid_27078 = get_local_id(0);\n    tblock_sizze_27081 = get_local_size(0);\n    wave_sizze_27080 = LOCKSTEP_WIDTH;\n    block_id_27079 = get_tblock_id(0);\n    global_tid_27077 = block_id_27079 * tblock_sizze_27081 + local_tid_27078;\n    tid_27076 = sext_i32_i64(global_tid_27077);\n    x_26152 = ((__global int32_t *) tS_mem_26244)[i_p_m_t_s_21442];\n    ((__global int32_t *) mem_26526)[(int64_t) 0] = x_26152;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzigpuseq_27092_dim1, 1, 1)\nvoid inner_SMJ_intzigpuseq_27092(__global int *global_failure, int64_t start_22996, int64_t i_p_m_t_s_23002, __global unsigned char *tR_mem_26243, __global unsigned char *mem_26534, __global unsigned char *mem_26535)\n{\n    if (*global_failure >= 0)\n    ",
                                    "    return;\n    \n    int32_t local_tid_27094;\n    int32_t tblock_sizze_27097;\n    int32_t wave_sizze_27096;\n    int32_t block_id_27095;\n    int32_t global_tid_27093;\n    int64_t tid_27092;\n    int32_t r_max_26156;\n    int32_t r_min_26159;\n    \n    local_tid_27094 = get_local_id(0);\n    tblock_sizze_27097 = get_local_size(0);\n    wave_sizze_27096 = LOCKSTEP_WIDTH;\n    block_id_27095 = get_tblock_id(0);\n    global_tid_27093 = block_id_27095 * tblock_sizze_27097 + local_tid_27094;\n    tid_27092 = sext_i32_i64(global_tid_27093);\n    r_max_26156 = ((__global int32_t *) tR_mem_26243)[i_p_m_t_s_23002];\n    r_min_26159 = ((__global int32_t *) tR_mem_26243)[start_22996];\n    ((__global int32_t *) mem_26534)[(int64_t) 0] = r_max_26156;\n    ((__global int32_t *) mem_26535)[(int64_t) 0] = r_min_26159;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzigpuseq_27098_dim1, 1, 1)\nvoid inner_SMJ_intzigpuseq_27098(__global int *global_failure, __global unsigned char *mem_26535, __global unsigned char *ext_mem_26536, __global unsigned char *mem_26538)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27100;\n    int32_t tblock_sizze_27103;\n    int32_t wave_sizze_27102;\n    int32_t block_id_27101;\n    int32_t global_tid_27099;\n    int64_t tid_27098;\n    int32_t s_max_26161;\n    int32_t r_min_26162;\n    bool defunc_0_gt_res_26163;\n    \n    local_tid_27100 = get_local_id(0);\n    tblock_sizze_27103 = get_local_size(0);\n    wave_sizze_27102 = LOCKSTEP_WIDTH;\n    block_id_27101 = get_tblock_id(0);\n    global_tid_27099 = block_id_27101 * tblock_sizze_27103 + local_tid_27100;\n    tid_27098 = sext_i32_i64(global_tid_27099);\n    s_max_26161 = ((__global int32_t *) ext_mem_26536)[(int64_t) 0];\n    r_min_26162 = ((__global int32_t *) mem_26535)[(int64_t) 0];\n    defunc_0_gt_res_26163 = slt32(s_max_26161, r_min_26162);\n    ((__global bool *) mem_26538)[(int64_t) 0] = defunc_0_gt_res_26163;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzigpus", "eq_27104_dim1, 1, 1)\nvoid inner_SMJ_intzigpuseq_27104(__global int *global_failure, __global unsigned char *mem_26534, __global unsigned char *ext_mem_26537, __global unsigned char *mem_26539)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27106;\n    int32_t tblock_sizze_27109;\n    int32_t wave_sizze_27108;\n    int32_t block_id_27107;\n    int32_t global_tid_27105;\n    int64_t tid_27104;\n    int32_t r_max_26166;\n    int32_t s_min_26167;\n    bool defunc_0_gt_res_26168;\n    \n    local_tid_27106 = get_local_id(0);\n    tblock_sizze_27109 = get_local_size(0);\n    wave_sizze_27108 = LOCKSTEP_WIDTH;\n    block_id_27107 = get_tblock_id(0);\n    global_tid_27105 = block_id_27107 * tblock_sizze_27109 + local_tid_27106;\n    tid_27104 = sext_i32_i64(global_tid_27105);\n    r_max_26166 = ((__global int32_t *) mem_26534)[(int64_t) 0];\n    s_min_26167 = ((__global int32_t *) ext_mem_26537)[(int64_t) 0];\n    defunc_0_gt_res_26168 = slt32(r_max_26166, s_min_26167);\n    ((__global bool *) mem_26539)[(int64_t) 0] = defunc_0_gt_res_26168;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzigpuseq_27163_dim1, 1, 1)\nvoid inner_SMJ_intzigpuseq_27163(__global int *global_failure, __global unsigned char *tR_mem_26243, __global unsigned char *mem_26266)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27165;\n    int32_t tblock_sizze_27168;\n    int32_t wave_sizze_27167;\n    int32_t block_id_27166;\n    int32_t global_tid_27164;\n    int64_t tid_27163;\n    int32_t x_26170;\n    \n    local_tid_27165 = get_local_id(0);\n    tblock_sizze_27168 = get_local_size(0);\n    wave_sizze_27167 = LOCKSTEP_WIDTH;\n    block_id_27166 = get_tblock_id(0);\n    global_tid_27164 = block_id_27166 * tblock_sizze_27168 + local_tid_27165;\n    tid_27163 = sext_i32_i64(global_tid_27164);\n    x_26170 = ((__global int32_t *) tR_mem_26243)[(int64_t) 0];\n    ((__global int32_t *) mem_26266)[(int64_t) 0] = x_26170;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(", "inner_SMJ_intzigpuseq_27169_dim1, 1, 1)\nvoid inner_SMJ_intzigpuseq_27169(__global int *global_failure, __global unsigned char *mem_26259, __global unsigned char *ext_mem_26267, __global unsigned char *mem_26268)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27171;\n    int32_t tblock_sizze_27174;\n    int32_t wave_sizze_27173;\n    int32_t block_id_27172;\n    int32_t global_tid_27170;\n    int64_t tid_27169;\n    int32_t leq_lhs_26174;\n    int32_t gt_lhs_26175;\n    bool defunc_0_leq_res_26176;\n    \n    local_tid_27171 = get_local_id(0);\n    tblock_sizze_27174 = get_local_size(0);\n    wave_sizze_27173 = LOCKSTEP_WIDTH;\n    block_id_27172 = get_tblock_id(0);\n    global_tid_27170 = block_id_27172 * tblock_sizze_27174 + local_tid_27171;\n    tid_27169 = sext_i32_i64(global_tid_27170);\n    leq_lhs_26174 = ((__global int32_t *) ext_mem_26267)[(int64_t) 0];\n    gt_lhs_26175 = ((__global int32_t *) mem_26259)[(int64_t) 0];\n    defunc_0_leq_res_26176 = sle32(leq_lhs_26174, gt_lhs_26175);\n    ((__global bool *) mem_26268)[(int64_t) 0] = defunc_0_leq_res_26176;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzigpuseq_27175_dim1, 1, 1)\nvoid inner_SMJ_intzigpuseq_27175(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t nR_17046, unsigned char y_21584_bits, __global unsigned char *tR_mem_26243, __global unsigned char *mem_26259, __global unsigned char *mem_26268, __global unsigned char *mem_26270)\n{\n    bool y_21584 = y_21584_bits;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27177;\n    int32_t tblock_sizze_27180;\n    int32_t wave_sizze_27179;\n    int32_t block_id_27178;\n    int32_t global_tid_27176;\n    int64_t tid_27175;\n    bool defunc_0_leq_res_26178;\n    int32_t x_26183;\n    \n    local_tid_27177 = get_local_id(0);\n    tblock_sizze_27180 = get_local_size(0);\n    wave_sizze_27179 = LOCKSTEP_WIDTH;\n    block_id_27178 = get_tblock_id(0);\n    global_tid_2717",
                                    "6 = block_id_27178 * tblock_sizze_27180 + local_tid_27177;\n    tid_27175 = sext_i32_i64(global_tid_27176);\n    defunc_0_leq_res_26178 = ((__global bool *) mem_26268)[(int64_t) 0];\n    if (defunc_0_leq_res_26178) {\n        bool index_certs_26179;\n        int32_t lowest_t_res_26180;\n        \n        if (!y_21584) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 0) == -1) {\n                    global_failure_args[0] = (int64_t) (int64_t) 0;\n                    global_failure_args[1] = (int64_t) nR_17046;\n                    ;\n                }\n                return;\n            }\n        }\n        lowest_t_res_26180 = ((__global int32_t *) tR_mem_26243)[(int64_t) 0];\n        x_26183 = lowest_t_res_26180;\n    } else {\n        int32_t gt_lhs_26182;\n        bool index_certs_26181;\n        \n        gt_lhs_26182 = ((__global int32_t *) mem_26259)[(int64_t) 0];\n        if (!y_21584) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 1) == -1) {\n                    global_failure_args[0] = (int64_t) (int64_t) 0;\n                    global_failure_args[1] = (int64_t) nR_17046;\n                    ;\n                }\n                return;\n            }\n        }\n        x_26183 = gt_lhs_26182;\n    }\n    ((__global int32_t *) mem_26270)[(int64_t) 0] = x_26183;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzigpuseq_27237_dim1, 1, 1)\nvoid inner_SMJ_intzigpuseq_27237(__global int *global_failure, int64_t slice_22507, __global unsigned char *tS_mem_26244, __global unsigned char *mem_26318)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27239;\n    int32_t tblock_sizze_27242;\n    int32_t wave_sizze_27241;\n    int32_t block_id_27240;\n    int32_t global_tid_27238;\n    int64_t tid_27237;\n    int32_t x_26188;\n    \n    local_tid_27239 = get_local_id(0);\n    tblock_sizze_27242 = get_local_size(0);\n    wave_sizze_27241 = LOCKSTEP_WIDTH;\n    block_id_27240 = get_tblock_id(0);\n    g", "lobal_tid_27238 = block_id_27240 * tblock_sizze_27242 + local_tid_27239;\n    tid_27237 = sext_i32_i64(global_tid_27238);\n    x_26188 = ((__global int32_t *) tS_mem_26244)[slice_22507];\n    ((__global int32_t *) mem_26318)[(int64_t) 0] = x_26188;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzigpuseq_27243_dim1, 1, 1)\nvoid inner_SMJ_intzigpuseq_27243(__global int *global_failure, int64_t slice_23305, __global unsigned char *tS_mem_26244, __global unsigned char *mem_26321)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27245;\n    int32_t tblock_sizze_27248;\n    int32_t wave_sizze_27247;\n    int32_t block_id_27246;\n    int32_t global_tid_27244;\n    int64_t tid_27243;\n    int32_t x_26192;\n    \n    local_tid_27245 = get_local_id(0);\n    tblock_sizze_27248 = get_local_size(0);\n    wave_sizze_27247 = LOCKSTEP_WIDTH;\n    block_id_27246 = get_tblock_id(0);\n    global_tid_27244 = block_id_27246 * tblock_sizze_27248 + local_tid_27245;\n    tid_27243 = sext_i32_i64(global_tid_27244);\n    x_26192 = ((__global int32_t *) tS_mem_26244)[slice_23305];\n    ((__global int32_t *) mem_26321)[(int64_t) 0] = x_26192;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzigpuseq_27259_dim1, 1, 1)\nvoid inner_SMJ_intzigpuseq_27259(__global int *global_failure, int64_t slice_22150, int64_t slice_22159, __global unsigned char *tR_mem_26243, __global unsigned char *mem_26329, __global unsigned char *mem_26330)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27261;\n    int32_t tblock_sizze_27264;\n    int32_t wave_sizze_27263;\n    int32_t block_id_27262;\n    int32_t global_tid_27260;\n    int64_t tid_27259;\n    int32_t r_max_26196;\n    int32_t r_min_26199;\n    \n    local_tid_27261 = get_local_id(0);\n    tblock_sizze_27264 = get_local_size(0);\n    wave_sizze_27263 = LOCKSTEP_WIDTH;\n    block_id_27262 = get_tblock_id(0);\n    global_tid_27260 = block_id_27262 * tblock_sizze_27264 + local_tid_27261;\n    tid_27259 = sext", "_i32_i64(global_tid_27260);\n    r_max_26196 = ((__global int32_t *) tR_mem_26243)[slice_22159];\n    r_min_26199 = ((__global int32_t *) tR_mem_26243)[slice_22150];\n    ((__global int32_t *) mem_26329)[(int64_t) 0] = r_max_26196;\n    ((__global int32_t *) mem_26330)[(int64_t) 0] = r_min_26199;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzigpuseq_27265_dim1, 1, 1)\nvoid inner_SMJ_intzigpuseq_27265(__global int *global_failure, __global unsigned char *mem_26330, __global unsigned char *ext_mem_26331, __global unsigned char *mem_26333)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27267;\n    int32_t tblock_sizze_27270;\n    int32_t wave_sizze_27269;\n    int32_t block_id_27268;\n    int32_t global_tid_27266;\n    int64_t tid_27265;\n    int32_t s_max_26201;\n    int32_t r_min_26202;\n    bool defunc_0_gt_res_26203;\n    \n    local_tid_27267 = get_local_id(0);\n    tblock_sizze_27270 = get_local_size(0);\n    wave_sizze_27269 = LOCKSTEP_WIDTH;\n    block_id_27268 = get_tblock_id(0);\n    global_tid_27266 = block_id_27268 * tblock_sizze_27270 + local_tid_27267;\n    tid_27265 = sext_i32_i64(global_tid_27266);\n    s_max_26201 = ((__global int32_t *) ext_mem_26331)[(int64_t) 0];\n    r_min_26202 = ((__global int32_t *) mem_26330)[(int64_t) 0];\n    defunc_0_gt_res_26203 = slt32(s_max_26201, r_min_26202);\n    ((__global bool *) mem_26333)[(int64_t) 0] = defunc_0_gt_res_26203;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzigpuseq_27271_dim1, 1, 1)\nvoid inner_SMJ_intzigpuseq_27271(__global int *global_failure, __global unsigned char *mem_26329, __global unsigned char *ext_mem_26332, __global unsigned char *mem_26334)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27273;\n    int32_t tblock_sizze_27276;\n    int32_t wave_sizze_27275;\n    int32_t block_id_27274;\n    int32_t global_tid_27272;\n    int64_t tid_27271;\n    int32_t r_max_26206;\n    int32_t s_min_26207;\n    bool defunc_0_gt_res_26208;\n    \n  ",
                                    "  local_tid_27273 = get_local_id(0);\n    tblock_sizze_27276 = get_local_size(0);\n    wave_sizze_27275 = LOCKSTEP_WIDTH;\n    block_id_27274 = get_tblock_id(0);\n    global_tid_27272 = block_id_27274 * tblock_sizze_27276 + local_tid_27273;\n    tid_27271 = sext_i32_i64(global_tid_27272);\n    r_max_26206 = ((__global int32_t *) mem_26329)[(int64_t) 0];\n    s_min_26207 = ((__global int32_t *) ext_mem_26332)[(int64_t) 0];\n    defunc_0_gt_res_26208 = slt32(r_max_26206, s_min_26207);\n    ((__global bool *) mem_26334)[(int64_t) 0] = defunc_0_gt_res_26208;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzigpuseq_27384_dim1, 1, 1)\nvoid inner_SMJ_intzigpuseq_27384(__global int *global_failure, int64_t gt_rhs_21419, int64_t i_p_m_t_s_21442, __global unsigned char *tR_mem_26243, __global unsigned char *tS_mem_26244, __global unsigned char *mem_26702)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27386;\n    int32_t tblock_sizze_27389;\n    int32_t wave_sizze_27388;\n    int32_t block_id_27387;\n    int32_t global_tid_27385;\n    int64_t tid_27384;\n    int32_t leq_lhs_26210;\n    int32_t leq_rhs_26212;\n    bool defunc_0_leq_res_26216;\n    \n    local_tid_27386 = get_local_id(0);\n    tblock_sizze_27389 = get_local_size(0);\n    wave_sizze_27388 = LOCKSTEP_WIDTH;\n    block_id_27387 = get_tblock_id(0);\n    global_tid_27385 = block_id_27387 * tblock_sizze_27389 + local_tid_27386;\n    tid_27384 = sext_i32_i64(global_tid_27385);\n    leq_lhs_26210 = ((__global int32_t *) tS_mem_26244)[i_p_m_t_s_21442];\n    leq_rhs_26212 = ((__global int32_t *) tR_mem_26243)[gt_rhs_21419];\n    defunc_0_leq_res_26216 = sle32(leq_lhs_26210, leq_rhs_26212);\n    ((__global bool *) mem_26702)[(int64_t) 0] = defunc_0_leq_res_26216;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzigpuseq_27689_dim1, 1, 1)\nvoid inner_SMJ_intzigpuseq_27689(__global int *global_failure, int64_t m_22292, __global unsigned char *mem_26738, __global unsigned char *mem_26740)\n{\n    i", "f (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27691;\n    int32_t tblock_sizze_27694;\n    int32_t wave_sizze_27693;\n    int32_t block_id_27692;\n    int32_t global_tid_27690;\n    int64_t tid_27689;\n    int64_t x_26218;\n    \n    local_tid_27691 = get_local_id(0);\n    tblock_sizze_27694 = get_local_size(0);\n    wave_sizze_27693 = LOCKSTEP_WIDTH;\n    block_id_27692 = get_tblock_id(0);\n    global_tid_27690 = block_id_27692 * tblock_sizze_27694 + local_tid_27691;\n    tid_27689 = sext_i32_i64(global_tid_27690);\n    x_26218 = ((__global int64_t *) mem_26738)[m_22292];\n    ((__global int64_t *) mem_26740)[(int64_t) 0] = x_26218;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzigpuseq_27695_dim1, 1, 1)\nvoid inner_SMJ_intzigpuseq_27695(__global int *global_failure, int64_t m_22292, __global unsigned char *mem_26721, __global unsigned char *mem_26743)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27697;\n    int32_t tblock_sizze_27700;\n    int32_t wave_sizze_27699;\n    int32_t block_id_27698;\n    int32_t global_tid_27696;\n    int64_t tid_27695;\n    int64_t x_26222;\n    \n    local_tid_27697 = get_local_id(0);\n    tblock_sizze_27700 = get_local_size(0);\n    wave_sizze_27699 = LOCKSTEP_WIDTH;\n    block_id_27698 = get_tblock_id(0);\n    global_tid_27696 = block_id_27698 * tblock_sizze_27700 + local_tid_27697;\n    tid_27695 = sext_i32_i64(global_tid_27696);\n    x_26222 = ((__global int64_t *) mem_26721)[m_22292];\n    ((__global int64_t *) mem_26743)[(int64_t) 0] = x_26222;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzigpuseq_27701_dim1, 1, 1)\nvoid inner_SMJ_intzigpuseq_27701(__global int *global_failure, __global unsigned char *ext_mem_26741, __global unsigned char *ext_mem_26744, __global unsigned char *mem_26750)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27703;\n    int32_t tblock_sizze_27706;\n    int32_t wave_sizze_27705;\n    int32_t block_id_27704;\n    int32_t glo", "bal_tid_27702;\n    int64_t tid_27701;\n    int64_t zp_lhs_26226;\n    int64_t n_pairs_t_res_26227;\n    int64_t n_pairs_t_res_26228;\n    \n    local_tid_27703 = get_local_id(0);\n    tblock_sizze_27706 = get_local_size(0);\n    wave_sizze_27705 = LOCKSTEP_WIDTH;\n    block_id_27704 = get_tblock_id(0);\n    global_tid_27702 = block_id_27704 * tblock_sizze_27706 + local_tid_27703;\n    tid_27701 = sext_i32_i64(global_tid_27702);\n    zp_lhs_26226 = ((__global int64_t *) ext_mem_26741)[(int64_t) 0];\n    n_pairs_t_res_26227 = ((__global int64_t *) ext_mem_26744)[(int64_t) 0];\n    n_pairs_t_res_26228 = add64(zp_lhs_26226, n_pairs_t_res_26227);\n    ((__global int64_t *) mem_26750)[(int64_t) 0] = n_pairs_t_res_26228;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzigpuseq_27748_dim1, 1, 1)\nvoid inner_SMJ_intzigpuseq_27748(__global int *global_failure, int64_t loopres_22466, __global unsigned char *mem_param_26784, __global unsigned char *mem_param_26787, __global unsigned char *mem_param_26790, __global unsigned char *mem_26797, __global unsigned char *mem_26798, __global unsigned char *mem_26799)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27750;\n    int32_t tblock_sizze_27753;\n    int32_t wave_sizze_27752;\n    int32_t block_id_27751;\n    int32_t global_tid_27749;\n    int64_t tid_27748;\n    int32_t loopres_26230;\n    int64_t loopres_26232;\n    int64_t loopres_26234;\n    \n    local_tid_27750 = get_local_id(0);\n    tblock_sizze_27753 = get_local_size(0);\n    wave_sizze_27752 = LOCKSTEP_WIDTH;\n    block_id_27751 = get_tblock_id(0);\n    global_tid_27749 = block_id_27751 * tblock_sizze_27753 + local_tid_27750;\n    tid_27748 = sext_i32_i64(global_tid_27749);\n    loopres_26230 = ((__global int32_t *) mem_param_26784)[loopres_22466];\n    loopres_26232 = ((__global int64_t *) mem_param_26787)[loopres_22466];\n    loopres_26234 = ((__global int64_t *) mem_param_26790)[loopres_22466];\n    ((__global int32_t *) mem_26797)[(int64_t) 0] = loopres_26",
                                    "230;\n    ((__global int64_t *) mem_26798)[(int64_t) 0] = loopres_26232;\n    ((__global int64_t *) mem_26799)[(int64_t) 0] = loopres_26234;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL\nvoid inner_SMJ_intzireplicate_27755(int64_t loopres_22467, int64_t replicate_n_27754, int64_t virt_num_tblocks_27760, int64_t num_tblocks_27761, __global unsigned char *mem_26797, __global unsigned char *mem_26801)\n{\n    int32_t replicate_ltid_27756;\n    int32_t tblock_sizze_27758;\n    int32_t replicate_gid_27757;\n    int32_t replicate_gtid_27755;\n    int32_t phys_tblock_id_27762;\n    int32_t iterations_27763;\n    \n    replicate_ltid_27756 = get_local_id(0);\n    tblock_sizze_27758 = get_local_size(0);\n    replicate_gid_27757 = get_tblock_id(0);\n    replicate_gtid_27755 = replicate_gid_27757 * tblock_sizze_27758 + replicate_ltid_27756;\n    phys_tblock_id_27762 = get_tblock_id(0);\n    iterations_27763 = sdiv_up32(sext_i64_i32(virt_num_tblocks_27760) - phys_tblock_id_27762, sext_i64_i32(num_tblocks_27761));\n    for (int32_t i_27764 = 0; i_27764 < iterations_27763; i_27764++) {\n        int32_t virt_tblock_id_27765;\n        int64_t global_tid_27766;\n        int64_t slice_27769;\n        int64_t slice_27770;\n        int64_t rep_i_27767;\n        int64_t remnant_27771;\n        int64_t rep_i_27768;\n        int64_t remnant_27772;\n        \n        virt_tblock_id_27765 = phys_tblock_id_27762 + i_27764 * sext_i64_i32(num_tblocks_27761);\n        global_tid_27766 = sext_i32_i64(virt_tblock_id_27765) * sext_i32_i64(tblock_sizze_27758) + sext_i32_i64(replicate_ltid_27756);\n        slice_27769 = (int64_t) 1;\n        slice_27770 = loopres_22467 * slice_27769;\n        rep_i_27767 = squot64(global_tid_27766, slice_27769);\n        remnant_27771 = global_tid_27766 - rep_i_27767 * slice_27769;\n        rep_i_27768 = remnant_27771;\n        remnant_27772 = remnant_27771 - rep_i_27768;\n        if (slt64(global_tid_27766, replicate_n_27754)) {\n            int32_t tmp_27773 = ((__global int32_t *) mem_26797)[rep_i_2", "7768];\n            \n            ((__global int32_t *) mem_26801)[rep_i_27767 + rep_i_27768] = tmp_27773;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid inner_SMJ_intzireplicate_27775(int64_t loopres_22467, int64_t replicate_n_27774, int64_t virt_num_tblocks_27780, int64_t num_tblocks_27781, __global unsigned char *mem_26798, __global unsigned char *mem_26803)\n{\n    int32_t replicate_ltid_27776;\n    int32_t tblock_sizze_27778;\n    int32_t replicate_gid_27777;\n    int32_t replicate_gtid_27775;\n    int32_t phys_tblock_id_27782;\n    int32_t iterations_27783;\n    \n    replicate_ltid_27776 = get_local_id(0);\n    tblock_sizze_27778 = get_local_size(0);\n    replicate_gid_27777 = get_tblock_id(0);\n    replicate_gtid_27775 = replicate_gid_27777 * tblock_sizze_27778 + replicate_ltid_27776;\n    phys_tblock_id_27782 = get_tblock_id(0);\n    iterations_27783 = sdiv_up32(sext_i64_i32(virt_num_tblocks_27780) - phys_tblock_id_27782, sext_i64_i32(num_tblocks_27781));\n    for (int32_t i_27784 = 0; i_27784 < iterations_27783; i_27784++) {\n        int32_t virt_tblock_id_27785;\n        int64_t global_tid_27786;\n        int64_t slice_27789;\n        int64_t slice_27790;\n        int64_t rep_i_27787;\n        int64_t remnant_27791;\n        int64_t rep_i_27788;\n        int64_t remnant_27792;\n        \n        virt_tblock_id_27785 = phys_tblock_id_27782 + i_27784 * sext_i64_i32(num_tblocks_27781);\n        global_tid_27786 = sext_i32_i64(virt_tblock_id_27785) * sext_i32_i64(tblock_sizze_27778) + sext_i32_i64(replicate_ltid_27776);\n        slice_27789 = (int64_t) 1;\n        slice_27790 = loopres_22467 * slice_27789;\n        rep_i_27787 = squot64(global_tid_27786, slice_27789);\n        remnant_27791 = global_tid_27786 - rep_i_27787 * slice_27789;\n        rep_i_27788 = remnant_27791;\n        remnant_27792 = remnant_27791 - rep_i_27788;\n        if (slt64(global_tid_27786, replicate_n_27774)) {\n            int64_t tmp_27793", " = ((__global int64_t *) mem_26798)[rep_i_27788];\n            \n            ((__global int64_t *) mem_26803)[rep_i_27787 + rep_i_27788] = tmp_27793;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzisegmap_23741_dim1, 1, 1)\nvoid inner_SMJ_intzisegmap_23741(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t nR_17046, int64_t tS_start_21436, int64_t dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578, int64_t max_res_21609, int64_t dzlz7bUZLzmZRz20UZLupToThreadZRz20UZLfirstThrZRz7dUzg_21610, int64_t zt_rhs_21615, __global unsigned char *tR_mem_26243, __global unsigned char *tS_mem_26244, __global unsigned char *ext_mem_26271, __global unsigned char *mem_26280, __global unsigned char *mem_26282)\n{\n    #define segmap_tblock_sizze_23736 (inner_SMJ_intzisegmap_23741zisegmap_tblock_sizze_23736)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27187;\n    int32_t tblock_sizze_27190;\n    int32_t wave_sizze_27189;\n    int32_t block_id_27188;\n    int32_t global_tid_27186;\n    int64_t phys_tid_23741;\n    int64_t global_tid_27191;\n    int64_t slice_27192;\n    int64_t gtid_23740;\n    int64_t remnant_27193;\n    \n    local_tid_27187 = get_local_id(0);\n    tblock_sizze_27190 = get_local_size(0);\n    wave_sizze_27189 = LOCKSTEP_WIDTH;\n    block_id_27188 = get_tblock_id(0);\n    global_tid_27186 = block_id_27188 * tblock_sizze_27190 + local_tid_27187;\n    phys_tid_23741 = sext_i32_i64(global_tid_27186);\n    global_tid_27191 = sext_i32_i64(block_id_27188) * segmap_tblock_sizze_23736 + sext_i32_i64(local_tid_27187);\n    slice_27192 = dzlz7bUZLzmZRz20UZLupToThreadZRz20UZLfirstThrZRz7dUzg_21610;\n    gtid_23740 = global_tid_27191;\n    remnant_27193 = global_tid_27191 - gtid_23740;\n    if (slt64(gtid_23740, dzlz7bUZLzmZRz20UZLupToThreadZRz20UZLfirstThrZRz7dUzg_21610)) {\n        int32_t lowest_26187;\n        int6",
                                    "4_t index_primexp_24673;\n        int64_t zs_lhs_23743;\n        int64_t index_23744;\n        bool cond_23745;\n        int64_t loop_over_23746;\n        int64_t loop_over_23747;\n        int64_t loop_over_23749;\n        bool defunc_0_f_res_23752;\n        int64_t defunc_0_f_res_23753;\n        int64_t defunc_0_f_res_23754;\n        int64_t defunc_0_f_res_23755;\n        bool loop_while_23756;\n        int64_t p_23757;\n        int64_t p_23758;\n        int64_t p_23759;\n        \n        lowest_26187 = ((__global int32_t *) ext_mem_26271)[(int64_t) 0];\n        index_primexp_24673 = add64(max_res_21609, gtid_23740);\n        zs_lhs_23743 = mul64(zt_rhs_21615, index_primexp_24673);\n        index_23744 = sdiv64(zs_lhs_23743, dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578);\n        cond_23745 = slt64(nR_17046, index_23744);\n        if (cond_23745) {\n            loop_over_23746 = nR_17046;\n        } else {\n            loop_over_23746 = index_23744;\n        }\n        if (cond_23745) {\n            int64_t loop_over_t_res_23748 = sub64(index_23744, nR_17046);\n            \n            loop_over_23747 = loop_over_t_res_23748;\n        } else {\n            loop_over_23747 = (int64_t) 0;\n        }\n        if (cond_23745) {\n            int64_t zm_lhs_23750;\n            int64_t loop_over_t_res_23751;\n            \n            zm_lhs_23750 = sub64(index_23744, nR_17046);\n            loop_over_t_res_23751 = sub64(zm_lhs_23750, (int64_t) 1);\n            loop_over_23749 = loop_over_t_res_23751;\n        } else {\n            loop_over_23749 = (int64_t) 0;\n        }\n        loop_while_23756 = 1;\n        p_23757 = loop_over_23749;\n        p_23758 = loop_over_23746;\n        p_23759 = loop_over_23747;\n        while (loop_while_23756) {\n            int64_t zs_lhs_23760;\n            int64_t offset_23761;\n            int64_t ai_23762;\n            int64_t max_arg1_23763;\n            int64_t max_res_23764;\n            bool cond_23765;\n            int32_t b_prev_23766;\n            bool cond", "_23774;\n            int64_t loopres_23775;\n            int64_t loopres_23776;\n            int64_t loopres_23777;\n            bool loopres_23778;\n            bool loop_while_tmp_27194;\n            int64_t p_tmp_27195;\n            int64_t p_tmp_27196;\n            int64_t p_tmp_27197;\n            \n            zs_lhs_23760 = sub64(p_23758, p_23757);\n            offset_23761 = sdiv64(zs_lhs_23760, (int64_t) 2);\n            ai_23762 = sub64(p_23758, offset_23761);\n            max_arg1_23763 = add64(p_23759, offset_23761);\n            max_res_23764 = smax64((int64_t) 0, max_arg1_23763);\n            cond_23765 = slt64((int64_t) 0, max_res_23764);\n            if (cond_23765) {\n                int64_t tmp_23767;\n                bool x_23768;\n                bool y_23769;\n                bool bounds_check_23770;\n                bool index_certs_23771;\n                int64_t slice_23772;\n                int32_t b_prev_t_res_23773;\n                \n                tmp_23767 = sub64(max_res_23764, (int64_t) 1);\n                x_23768 = sle64((int64_t) 0, tmp_23767);\n                y_23769 = slt64(tmp_23767, nR_17046);\n                bounds_check_23770 = x_23768 && y_23769;\n                if (!bounds_check_23770) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 2) == -1) {\n                            global_failure_args[0] = (int64_t) tmp_23767;\n                            global_failure_args[1] = (int64_t) nR_17046;\n                            ;\n                        }\n                        return;\n                    }\n                }\n                slice_23772 = tS_start_21436 + tmp_23767;\n                b_prev_t_res_23773 = ((__global int32_t *) tS_mem_26244)[slice_23772];\n                b_prev_23766 = b_prev_t_res_23773;\n            } else {\n                b_prev_23766 = lowest_26187;\n            }\n            cond_23774 = sle64(ai_23762, (int64_t) 0);\n            if (cond_23774) {\n                loopres_23775 =", " p_23757;\n                loopres_23776 = (int64_t) 0;\n                loopres_23777 = max_res_23764;\n                loopres_23778 = 0;\n            } else {\n                bool cond_23779;\n                int64_t loopres_f_res_23780;\n                int64_t loopres_f_res_23781;\n                int64_t loopres_f_res_23782;\n                bool loopres_f_res_23783;\n                \n                cond_23779 = sle64(nR_17046, max_res_23764);\n                if (cond_23779) {\n                    int64_t min_arg1_23784;\n                    int64_t min_res_23785;\n                    bool x_23786;\n                    bool y_23787;\n                    bool bounds_check_23788;\n                    bool index_certs_23789;\n                    bool x_23792;\n                    bool y_23793;\n                    bool bounds_check_23794;\n                    bool index_certs_23795;\n                    int64_t slice_23790;\n                    int32_t leq_lhs_23791;\n                    int32_t leq_rhs_23796;\n                    bool defunc_0_leq_res_23797;\n                    int64_t loopres_f_res_t_res_23798;\n                    bool x_23799;\n                    int64_t loopres_f_res_t_res_23800;\n                    \n                    min_arg1_23784 = sub64(nR_17046, (int64_t) 1);\n                    min_res_23785 = smin64(ai_23762, min_arg1_23784);\n                    x_23786 = sle64((int64_t) 0, min_arg1_23784);\n                    y_23787 = slt64(min_arg1_23784, nR_17046);\n                    bounds_check_23788 = x_23786 && y_23787;\n                    if (!bounds_check_23788) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 3) == -1) {\n                                global_failure_args[0] = (int64_t) min_arg1_23784;\n                                global_failure_args[1] = (int64_t) nR_17046;\n                                ;\n                            }\n                            return;\n                        }\n  ",
                                    "                  }\n                    x_23792 = sle64((int64_t) 0, min_res_23785);\n                    y_23793 = slt64(min_res_23785, nR_17046);\n                    bounds_check_23794 = x_23792 && y_23793;\n                    if (!bounds_check_23794) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 4) == -1) {\n                                global_failure_args[0] = (int64_t) min_res_23785;\n                                global_failure_args[1] = (int64_t) nR_17046;\n                                ;\n                            }\n                            return;\n                        }\n                    }\n                    slice_23790 = tS_start_21436 + min_arg1_23784;\n                    leq_lhs_23791 = ((__global int32_t *) tS_mem_26244)[slice_23790];\n                    leq_rhs_23796 = ((__global int32_t *) tR_mem_26243)[min_res_23785];\n                    defunc_0_leq_res_23797 = sle32(leq_lhs_23791, leq_rhs_23796);\n                    if (defunc_0_leq_res_23797) {\n                        loopres_f_res_t_res_23798 = ai_23762;\n                    } else {\n                        loopres_f_res_t_res_23798 = p_23758;\n                    }\n                    x_23799 = !defunc_0_leq_res_23797;\n                    if (defunc_0_leq_res_23797) {\n                        loopres_f_res_t_res_23800 = nR_17046;\n                    } else {\n                        int64_t tmp_23801 = sub64(min_arg1_23784, offset_23761);\n                        \n                        loopres_f_res_t_res_23800 = tmp_23801;\n                    }\n                    loopres_f_res_23780 = p_23757;\n                    loopres_f_res_23781 = loopres_f_res_t_res_23798;\n                    loopres_f_res_23782 = loopres_f_res_t_res_23800;\n                    loopres_f_res_23783 = x_23799;\n                } else {\n                    bool cond_23802;\n                    int64_t loopres_f_res_f_res_23803;\n                    int64_t loo", "pres_f_res_f_res_23804;\n                    int64_t loopres_f_res_f_res_23805;\n                    bool loopres_f_res_f_res_23806;\n                    \n                    cond_23802 = sle64(nR_17046, ai_23762);\n                    if (cond_23802) {\n                        int64_t min_arg1_23807;\n                        int64_t min_res_23808;\n                        bool x_23809;\n                        bool y_23810;\n                        bool bounds_check_23811;\n                        bool index_certs_23812;\n                        bool x_23814;\n                        bool y_23815;\n                        bool bounds_check_23816;\n                        bool index_certs_23817;\n                        int32_t leq_lhs_23813;\n                        int64_t slice_23818;\n                        int32_t leq_rhs_23819;\n                        bool defunc_0_leq_res_23820;\n                        int64_t loopres_f_res_f_res_t_res_23821;\n                        bool x_23822;\n                        int64_t loopres_f_res_f_res_t_res_23823;\n                        \n                        min_arg1_23807 = sub64(nR_17046, (int64_t) 1);\n                        min_res_23808 = smin64(max_res_23764, min_arg1_23807);\n                        x_23809 = sle64((int64_t) 0, min_arg1_23807);\n                        y_23810 = slt64(min_arg1_23807, nR_17046);\n                        bounds_check_23811 = x_23809 && y_23810;\n                        if (!bounds_check_23811) {\n                            {\n                                if (atomic_cmpxchg_i32_global(global_failure, -1, 5) == -1) {\n                                    global_failure_args[0] = (int64_t) min_arg1_23807;\n                                    global_failure_args[1] = (int64_t) nR_17046;\n                                    ;\n                                }\n                                return;\n                            }\n                        }\n                        x_23814 = sle64((int64_t) 0, min_res_", "23808);\n                        y_23815 = slt64(min_res_23808, nR_17046);\n                        bounds_check_23816 = x_23814 && y_23815;\n                        if (!bounds_check_23816) {\n                            {\n                                if (atomic_cmpxchg_i32_global(global_failure, -1, 6) == -1) {\n                                    global_failure_args[0] = (int64_t) min_res_23808;\n                                    global_failure_args[1] = (int64_t) nR_17046;\n                                    ;\n                                }\n                                return;\n                            }\n                        }\n                        leq_lhs_23813 = ((__global int32_t *) tR_mem_26243)[min_arg1_23807];\n                        slice_23818 = tS_start_21436 + min_res_23808;\n                        leq_rhs_23819 = ((__global int32_t *) tS_mem_26244)[slice_23818];\n                        defunc_0_leq_res_23820 = sle32(leq_lhs_23813, leq_rhs_23819);\n                        if (defunc_0_leq_res_23820) {\n                            loopres_f_res_f_res_t_res_23821 = max_res_23764;\n                        } else {\n                            loopres_f_res_f_res_t_res_23821 = p_23759;\n                        }\n                        x_23822 = !defunc_0_leq_res_23820;\n                        if (defunc_0_leq_res_23820) {\n                            loopres_f_res_f_res_t_res_23823 = nR_17046;\n                        } else {\n                            loopres_f_res_f_res_t_res_23823 = min_arg1_23807;\n                        }\n                        loopres_f_res_f_res_23803 = p_23757;\n                        loopres_f_res_f_res_23804 = loopres_f_res_f_res_t_res_23823;\n                        loopres_f_res_f_res_23805 = loopres_f_res_f_res_t_res_23821;\n                        loopres_f_res_f_res_23806 = x_23822;\n                    } else {\n                        bool cond_23824;\n                        int64_t loopres_f_res_f_res_f_res_23825;\n  ",
                                    "                      int64_t loopres_f_res_f_res_f_res_23826;\n                        int64_t loopres_f_res_f_res_f_res_23827;\n                        bool loopres_f_res_f_res_f_res_23828;\n                        \n                        cond_23824 = sle64(p_23758, p_23757);\n                        if (cond_23824) {\n                            bool cond_23829;\n                            int64_t ai_23830;\n                            bool x_23843;\n                            bool y_23844;\n                            bool bounds_check_23845;\n                            bool index_certs_23846;\n                            int32_t b_prev_23832;\n                            int32_t gt_lhs_23847;\n                            bool defunc_0_gt_res_23848;\n                            int64_t defunc_0_partFunc_sequential_search_res_23849;\n                            int64_t defunc_0_partFunc_sequential_search_res_23850;\n                            \n                            cond_23829 = slt64(ai_23762, nR_17046);\n                            if (cond_23829) {\n                                ai_23830 = ai_23762;\n                            } else {\n                                int64_t ai_f_res_23831 = sub64(nR_17046, (int64_t) 1);\n                                \n                                ai_23830 = ai_f_res_23831;\n                            }\n                            x_23843 = sle64((int64_t) 0, ai_23830);\n                            y_23844 = slt64(ai_23830, nR_17046);\n                            bounds_check_23845 = x_23843 && y_23844;\n                            if (!bounds_check_23845) {\n                                {\n                                    if (atomic_cmpxchg_i32_global(global_failure, -1, 7) == -1) {\n                                        global_failure_args[0] = (int64_t) ai_23830;\n                                        global_failure_args[1] = (int64_t) nR_17046;\n                                        ;\n                                    ", "}\n                                    return;\n                                }\n                            }\n                            if (cond_23765) {\n                                int64_t tmp_23833;\n                                bool x_23834;\n                                bool y_23835;\n                                bool bounds_check_23836;\n                                bool index_certs_23837;\n                                int64_t slice_23838;\n                                int32_t b_prev_t_res_23839;\n                                \n                                tmp_23833 = sub64(max_res_23764, (int64_t) 1);\n                                x_23834 = sle64((int64_t) 0, tmp_23833);\n                                y_23835 = slt64(tmp_23833, nR_17046);\n                                bounds_check_23836 = x_23834 && y_23835;\n                                if (!bounds_check_23836) {\n                                    {\n                                        if (atomic_cmpxchg_i32_global(global_failure, -1, 8) == -1) {\n                                            global_failure_args[0] = (int64_t) tmp_23833;\n                                            global_failure_args[1] = (int64_t) nR_17046;\n                                            ;\n                                        }\n                                        return;\n                                    }\n                                }\n                                slice_23838 = tS_start_21436 + tmp_23833;\n                                b_prev_t_res_23839 = ((__global int32_t *) tS_mem_26244)[slice_23838];\n                                b_prev_23832 = b_prev_t_res_23839;\n                            } else {\n                                bool y_23840;\n                                bool index_certs_23841;\n                                int32_t b_prev_f_res_23842;\n                                \n                                y_23840 = slt64((int64_t) 0, nR_17046);\n             ", "                   if (!y_23840) {\n                                    {\n                                        if (atomic_cmpxchg_i32_global(global_failure, -1, 9) == -1) {\n                                            global_failure_args[0] = (int64_t) (int64_t) 0;\n                                            global_failure_args[1] = (int64_t) nR_17046;\n                                            ;\n                                        }\n                                        return;\n                                    }\n                                }\n                                b_prev_f_res_23842 = ((__global int32_t *) tS_mem_26244)[tS_start_21436];\n                                b_prev_23832 = b_prev_f_res_23842;\n                            }\n                            gt_lhs_23847 = ((__global int32_t *) tR_mem_26243)[ai_23830];\n                            defunc_0_gt_res_23848 = slt32(b_prev_23832, gt_lhs_23847);\n                            if (defunc_0_gt_res_23848) {\n                                int64_t zl_rhs_23851;\n                                bool loop_cond_23852;\n                                bool defunc_0_partFunc_sequential_search_res_t_res_23853;\n                                int64_t defunc_0_partFunc_sequential_search_res_t_res_23854;\n                                int64_t defunc_0_partFunc_sequential_search_res_t_res_23855;\n                                int64_t defunc_0_partFunc_sequential_search_res_t_res_23856;\n                                bool loop_while_23857;\n                                int64_t p_23858;\n                                int64_t p_23859;\n                                int64_t p_23860;\n                                \n                                zl_rhs_23851 = sub64(nR_17046, max_res_23764);\n                                loop_cond_23852 = slt64((int64_t) 0, zl_rhs_23851);\n                                loop_while_23857 = loop_cond_23852;\n                                p_23858 = ai_23830;\n    ",
                                    "                            p_23859 = max_res_23764;\n                                p_23860 = (int64_t) 0;\n                                while (loop_while_23857) {\n                                    int64_t i_a_23861;\n                                    int64_t i_b_23862;\n                                    int64_t leq_lhs_23863;\n                                    bool x_23864;\n                                    bool y_23865;\n                                    bool bounds_check_23866;\n                                    bool index_certs_23867;\n                                    bool x_23869;\n                                    bool y_23870;\n                                    bool bounds_check_23871;\n                                    bool index_certs_23872;\n                                    int32_t leq_lhs_23868;\n                                    int64_t slice_23873;\n                                    int32_t leq_rhs_23874;\n                                    bool defunc_0_leq_res_23875;\n                                    int64_t loopres_23876;\n                                    int64_t loopres_23877;\n                                    int64_t loopres_23878;\n                                    bool loop_cond_23880;\n                                    bool loop_while_tmp_27198;\n                                    int64_t p_tmp_27199;\n                                    int64_t p_tmp_27200;\n                                    int64_t p_tmp_27201;\n                                    \n                                    i_a_23861 = sub64(ai_23830, p_23860);\n                                    i_b_23862 = add64(max_res_23764, p_23860);\n                                    leq_lhs_23863 = sub64(i_a_23861, (int64_t) 1);\n                                    x_23864 = sle64((int64_t) 0, leq_lhs_23863);\n                                    y_23865 = slt64(leq_lhs_23863, nR_17046);\n                                    bounds_check_23866 = x_23864 && y_23865;\n    ", "                                if (!bounds_check_23866) {\n                                        {\n                                            if (atomic_cmpxchg_i32_global(global_failure, -1, 10) == -1) {\n                                                global_failure_args[0] = (int64_t) leq_lhs_23863;\n                                                global_failure_args[1] = (int64_t) nR_17046;\n                                                ;\n                                            }\n                                            return;\n                                        }\n                                    }\n                                    x_23869 = sle64((int64_t) 0, i_b_23862);\n                                    y_23870 = slt64(i_b_23862, nR_17046);\n                                    bounds_check_23871 = x_23869 && y_23870;\n                                    if (!bounds_check_23871) {\n                                        {\n                                            if (atomic_cmpxchg_i32_global(global_failure, -1, 11) == -1) {\n                                                global_failure_args[0] = (int64_t) i_b_23862;\n                                                global_failure_args[1] = (int64_t) nR_17046;\n                                                ;\n                                            }\n                                            return;\n                                        }\n                                    }\n                                    leq_lhs_23868 = ((__global int32_t *) tR_mem_26243)[leq_lhs_23863];\n                                    slice_23873 = tS_start_21436 + i_b_23862;\n                                    leq_rhs_23874 = ((__global int32_t *) tS_mem_26244)[slice_23873];\n                                    defunc_0_leq_res_23875 = sle32(leq_lhs_23868, leq_rhs_23874);\n                                    if (defunc_0_leq_res_23875) {\n                                        loopres_23876 = i_a_23861;\n   ", "                                 } else {\n                                        loopres_23876 = ai_23830;\n                                    }\n                                    if (defunc_0_leq_res_23875) {\n                                        loopres_23877 = i_b_23862;\n                                    } else {\n                                        loopres_23877 = max_res_23764;\n                                    }\n                                    if (defunc_0_leq_res_23875) {\n                                        loopres_23878 = zl_rhs_23851;\n                                    } else {\n                                        int64_t tmp_23879 = add64((int64_t) 1, p_23860);\n                                        \n                                        loopres_23878 = tmp_23879;\n                                    }\n                                    loop_cond_23880 = slt64(loopres_23878, zl_rhs_23851);\n                                    loop_while_tmp_27198 = loop_cond_23880;\n                                    p_tmp_27199 = loopres_23876;\n                                    p_tmp_27200 = loopres_23877;\n                                    p_tmp_27201 = loopres_23878;\n                                    loop_while_23857 = loop_while_tmp_27198;\n                                    p_23858 = p_tmp_27199;\n                                    p_23859 = p_tmp_27200;\n                                    p_23860 = p_tmp_27201;\n                                }\n                                defunc_0_partFunc_sequential_search_res_t_res_23853 = loop_while_23857;\n                                defunc_0_partFunc_sequential_search_res_t_res_23854 = p_23858;\n                                defunc_0_partFunc_sequential_search_res_t_res_23855 = p_23859;\n                                defunc_0_partFunc_sequential_search_res_t_res_23856 = p_23860;\n                                defunc_0_partFunc_sequential_search_res_23849 = defunc_0_partFunc_sequential_sear",
                                    "ch_res_t_res_23854;\n                                defunc_0_partFunc_sequential_search_res_23850 = defunc_0_partFunc_sequential_search_res_t_res_23855;\n                            } else {\n                                int64_t zl_rhs_23881;\n                                bool loop_cond_23882;\n                                bool defunc_0_partFunc_sequential_search_res_f_res_23883;\n                                int64_t defunc_0_partFunc_sequential_search_res_f_res_23884;\n                                int64_t defunc_0_partFunc_sequential_search_res_f_res_23885;\n                                int64_t defunc_0_partFunc_sequential_search_res_f_res_23886;\n                                bool loop_while_23887;\n                                int64_t p_23888;\n                                int64_t p_23889;\n                                int64_t p_23890;\n                                \n                                zl_rhs_23881 = sub64(max_res_23764, (int64_t) 1);\n                                loop_cond_23882 = slt64((int64_t) 0, zl_rhs_23881);\n                                loop_while_23887 = loop_cond_23882;\n                                p_23888 = ai_23830;\n                                p_23889 = max_res_23764;\n                                p_23890 = (int64_t) 0;\n                                while (loop_while_23887) {\n                                    int64_t zp_lhs_23891;\n                                    int64_t hi_a_23892;\n                                    bool cond_23893;\n                                    int64_t i_a_23894;\n                                    int64_t zm_lhs_23896;\n                                    int64_t i_b_23897;\n                                    bool x_23898;\n                                    bool y_23899;\n                                    bool bounds_check_23900;\n                                    bool index_certs_23901;\n                                    bool x_23903;\n                                   ", " bool y_23904;\n                                    bool bounds_check_23905;\n                                    bool index_certs_23906;\n                                    int32_t gt_lhs_23902;\n                                    int64_t slice_23907;\n                                    int32_t gt_rhs_23908;\n                                    bool defunc_0_gt_res_23909;\n                                    int64_t loopres_23910;\n                                    int64_t loopres_23911;\n                                    int64_t loopres_23912;\n                                    bool loop_cond_23914;\n                                    bool loop_while_tmp_27202;\n                                    int64_t p_tmp_27203;\n                                    int64_t p_tmp_27204;\n                                    int64_t p_tmp_27205;\n                                    \n                                    zp_lhs_23891 = add64(ai_23830, p_23890);\n                                    hi_a_23892 = add64((int64_t) 1, zp_lhs_23891);\n                                    cond_23893 = slt64(hi_a_23892, nR_17046);\n                                    if (cond_23893) {\n                                        i_a_23894 = hi_a_23892;\n                                    } else {\n                                        int64_t i_a_f_res_23895 = sub64(nR_17046, (int64_t) 1);\n                                        \n                                        i_a_23894 = i_a_f_res_23895;\n                                    }\n                                    zm_lhs_23896 = sub64(max_res_23764, p_23890);\n                                    i_b_23897 = sub64(zm_lhs_23896, (int64_t) 1);\n                                    x_23898 = sle64((int64_t) 0, i_a_23894);\n                                    y_23899 = slt64(i_a_23894, nR_17046);\n                                    bounds_check_23900 = x_23898 && y_23899;\n                                    if (!bounds_check_23900) {\n                     ", "                   {\n                                            if (atomic_cmpxchg_i32_global(global_failure, -1, 12) == -1) {\n                                                global_failure_args[0] = (int64_t) i_a_23894;\n                                                global_failure_args[1] = (int64_t) nR_17046;\n                                                ;\n                                            }\n                                            return;\n                                        }\n                                    }\n                                    x_23903 = sle64((int64_t) 0, i_b_23897);\n                                    y_23904 = slt64(i_b_23897, nR_17046);\n                                    bounds_check_23905 = x_23903 && y_23904;\n                                    if (!bounds_check_23905) {\n                                        {\n                                            if (atomic_cmpxchg_i32_global(global_failure, -1, 13) == -1) {\n                                                global_failure_args[0] = (int64_t) i_b_23897;\n                                                global_failure_args[1] = (int64_t) nR_17046;\n                                                ;\n                                            }\n                                            return;\n                                        }\n                                    }\n                                    gt_lhs_23902 = ((__global int32_t *) tR_mem_26243)[i_a_23894];\n                                    slice_23907 = tS_start_21436 + i_b_23897;\n                                    gt_rhs_23908 = ((__global int32_t *) tS_mem_26244)[slice_23907];\n                                    defunc_0_gt_res_23909 = slt32(gt_rhs_23908, gt_lhs_23902);\n                                    if (defunc_0_gt_res_23909) {\n                                        loopres_23910 = i_a_23894;\n                                    } else {\n                                        loopres_2391",
                                    "0 = ai_23830;\n                                    }\n                                    if (defunc_0_gt_res_23909) {\n                                        loopres_23911 = zm_lhs_23896;\n                                    } else {\n                                        loopres_23911 = max_res_23764;\n                                    }\n                                    if (defunc_0_gt_res_23909) {\n                                        loopres_23912 = zl_rhs_23881;\n                                    } else {\n                                        int64_t tmp_23913 = add64((int64_t) 1, p_23890);\n                                        \n                                        loopres_23912 = tmp_23913;\n                                    }\n                                    loop_cond_23914 = slt64(loopres_23912, zl_rhs_23881);\n                                    loop_while_tmp_27202 = loop_cond_23914;\n                                    p_tmp_27203 = loopres_23910;\n                                    p_tmp_27204 = loopres_23911;\n                                    p_tmp_27205 = loopres_23912;\n                                    loop_while_23887 = loop_while_tmp_27202;\n                                    p_23888 = p_tmp_27203;\n                                    p_23889 = p_tmp_27204;\n                                    p_23890 = p_tmp_27205;\n                                }\n                                defunc_0_partFunc_sequential_search_res_f_res_23883 = loop_while_23887;\n                                defunc_0_partFunc_sequential_search_res_f_res_23884 = p_23888;\n                                defunc_0_partFunc_sequential_search_res_f_res_23885 = p_23889;\n                                defunc_0_partFunc_sequential_search_res_f_res_23886 = p_23890;\n                                defunc_0_partFunc_sequential_search_res_23849 = defunc_0_partFunc_sequential_search_res_f_res_23884;\n                                defunc_0_partFunc_sequential_search_res_2", "3850 = defunc_0_partFunc_sequential_search_res_f_res_23885;\n                            }\n                            loopres_f_res_f_res_f_res_23825 = p_23757;\n                            loopres_f_res_f_res_f_res_23826 = defunc_0_partFunc_sequential_search_res_23849;\n                            loopres_f_res_f_res_f_res_23827 = defunc_0_partFunc_sequential_search_res_23850;\n                            loopres_f_res_f_res_f_res_23828 = 0;\n                        } else {\n                            bool x_23915;\n                            bool y_23916;\n                            bool bounds_check_23917;\n                            bool index_certs_23918;\n                            int32_t gt_lhs_23919;\n                            bool defunc_0_gt_res_23920;\n                            int64_t loopres_f_res_f_res_f_res_f_res_23921;\n                            int64_t loopres_f_res_f_res_f_res_f_res_23922;\n                            int64_t loopres_f_res_f_res_f_res_f_res_23923;\n                            bool loopres_f_res_f_res_f_res_f_res_23924;\n                            \n                            x_23915 = sle64((int64_t) 0, ai_23762);\n                            y_23916 = slt64(ai_23762, nR_17046);\n                            bounds_check_23917 = x_23915 && y_23916;\n                            if (!bounds_check_23917) {\n                                {\n                                    if (atomic_cmpxchg_i32_global(global_failure, -1, 14) == -1) {\n                                        global_failure_args[0] = (int64_t) ai_23762;\n                                        global_failure_args[1] = (int64_t) nR_17046;\n                                        ;\n                                    }\n                                    return;\n                                }\n                            }\n                            gt_lhs_23919 = ((__global int32_t *) tR_mem_26243)[ai_23762];\n                            defunc_0_gt_res_23920 = slt32(b_prev", "_23766, gt_lhs_23919);\n                            if (defunc_0_gt_res_23920) {\n                                int64_t leq_lhs_23925;\n                                bool x_23926;\n                                bool y_23927;\n                                bool bounds_check_23928;\n                                bool index_certs_23929;\n                                bool x_23931;\n                                bool y_23932;\n                                bool bounds_check_23933;\n                                bool index_certs_23934;\n                                int32_t leq_lhs_23930;\n                                int64_t slice_23935;\n                                int32_t leq_rhs_23936;\n                                bool defunc_0_leq_res_23937;\n                                bool x_23938;\n                                int64_t loopres_f_res_f_res_f_res_f_res_t_res_23939;\n                                int64_t loopres_f_res_f_res_f_res_f_res_t_res_23940;\n                                \n                                leq_lhs_23925 = sub64(ai_23762, (int64_t) 1);\n                                x_23926 = sle64((int64_t) 0, leq_lhs_23925);\n                                y_23927 = slt64(leq_lhs_23925, nR_17046);\n                                bounds_check_23928 = x_23926 && y_23927;\n                                if (!bounds_check_23928) {\n                                    {\n                                        if (atomic_cmpxchg_i32_global(global_failure, -1, 15) == -1) {\n                                            global_failure_args[0] = (int64_t) leq_lhs_23925;\n                                            global_failure_args[1] = (int64_t) nR_17046;\n                                            ;\n                                        }\n                                        return;\n                                    }\n                                }\n                                x_23931 = sle64((int64_t) 0, max_res_23764);\n            ",
                                    "                    y_23932 = slt64(max_res_23764, nR_17046);\n                                bounds_check_23933 = x_23931 && y_23932;\n                                if (!bounds_check_23933) {\n                                    {\n                                        if (atomic_cmpxchg_i32_global(global_failure, -1, 16) == -1) {\n                                            global_failure_args[0] = (int64_t) max_res_23764;\n                                            global_failure_args[1] = (int64_t) nR_17046;\n                                            ;\n                                        }\n                                        return;\n                                    }\n                                }\n                                leq_lhs_23930 = ((__global int32_t *) tR_mem_26243)[leq_lhs_23925];\n                                slice_23935 = tS_start_21436 + max_res_23764;\n                                leq_rhs_23936 = ((__global int32_t *) tS_mem_26244)[slice_23935];\n                                defunc_0_leq_res_23937 = sle32(leq_lhs_23930, leq_rhs_23936);\n                                x_23938 = !defunc_0_leq_res_23937;\n                                if (defunc_0_leq_res_23937) {\n                                    loopres_f_res_f_res_f_res_f_res_t_res_23939 = ai_23762;\n                                } else {\n                                    loopres_f_res_f_res_f_res_f_res_t_res_23939 = leq_lhs_23925;\n                                }\n                                if (defunc_0_leq_res_23937) {\n                                    loopres_f_res_f_res_f_res_f_res_t_res_23940 = max_res_23764;\n                                } else {\n                                    int64_t tmp_23941 = add64((int64_t) 1, max_res_23764);\n                                    \n                                    loopres_f_res_f_res_f_res_f_res_t_res_23940 = tmp_23941;\n                                }\n                                loopres_f_res_f_res_f_re", "s_f_res_23921 = p_23757;\n                                loopres_f_res_f_res_f_res_f_res_23922 = loopres_f_res_f_res_f_res_f_res_t_res_23939;\n                                loopres_f_res_f_res_f_res_f_res_23923 = loopres_f_res_f_res_f_res_f_res_t_res_23940;\n                                loopres_f_res_f_res_f_res_f_res_23924 = x_23938;\n                            } else {\n                                int64_t tmp_23942 = add64((int64_t) 1, ai_23762);\n                                \n                                loopres_f_res_f_res_f_res_f_res_23921 = tmp_23942;\n                                loopres_f_res_f_res_f_res_f_res_23922 = p_23758;\n                                loopres_f_res_f_res_f_res_f_res_23923 = p_23759;\n                                loopres_f_res_f_res_f_res_f_res_23924 = 1;\n                            }\n                            loopres_f_res_f_res_f_res_23825 = loopres_f_res_f_res_f_res_f_res_23921;\n                            loopres_f_res_f_res_f_res_23826 = loopres_f_res_f_res_f_res_f_res_23922;\n                            loopres_f_res_f_res_f_res_23827 = loopres_f_res_f_res_f_res_f_res_23923;\n                            loopres_f_res_f_res_f_res_23828 = loopres_f_res_f_res_f_res_f_res_23924;\n                        }\n                        loopres_f_res_f_res_23803 = loopres_f_res_f_res_f_res_23825;\n                        loopres_f_res_f_res_23804 = loopres_f_res_f_res_f_res_23826;\n                        loopres_f_res_f_res_23805 = loopres_f_res_f_res_f_res_23827;\n                        loopres_f_res_f_res_23806 = loopres_f_res_f_res_f_res_23828;\n                    }\n                    loopres_f_res_23780 = loopres_f_res_f_res_23803;\n                    loopres_f_res_23781 = loopres_f_res_f_res_23804;\n                    loopres_f_res_23782 = loopres_f_res_f_res_23805;\n                    loopres_f_res_23783 = loopres_f_res_f_res_23806;\n                }\n                loopres_23775 = loopres_f_res_23780;\n                loo", "pres_23776 = loopres_f_res_23781;\n                loopres_23777 = loopres_f_res_23782;\n                loopres_23778 = loopres_f_res_23783;\n            }\n            loop_while_tmp_27194 = loopres_23778;\n            p_tmp_27195 = loopres_23775;\n            p_tmp_27196 = loopres_23776;\n            p_tmp_27197 = loopres_23777;\n            loop_while_23756 = loop_while_tmp_27194;\n            p_23757 = p_tmp_27195;\n            p_23758 = p_tmp_27196;\n            p_23759 = p_tmp_27197;\n        }\n        defunc_0_f_res_23752 = loop_while_23756;\n        defunc_0_f_res_23753 = p_23757;\n        defunc_0_f_res_23754 = p_23758;\n        defunc_0_f_res_23755 = p_23759;\n        ((__global int64_t *) mem_26280)[gtid_23740] = defunc_0_f_res_23754;\n        ((__global int64_t *) mem_26282)[gtid_23740] = defunc_0_f_res_23755;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_23736\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzisegmap_24115_dim1, 1, 1)\nvoid inner_SMJ_intzisegmap_24115(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t nR_17046, int64_t gt_rhs_21419, int64_t tS_start_21436, int64_t dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578, int64_t zeze_rhs_21852, __global unsigned char *tR_mem_26243, __global unsigned char *tS_mem_26244, __global unsigned char *mem_26262, __global unsigned char *mem_26264, __global unsigned char *mem_26298, __global unsigned char *mem_26300)\n{\n    #define segmap_tblock_sizze_24110 (inner_SMJ_intzisegmap_24115zisegmap_tblock_sizze_24110)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27210;\n    int32_t tblock_sizze_27213;\n    int32_t wave_sizze_27212;\n    int32_t block_id_27211;\n    int32_t global_tid_27209;\n    int64_t phys_tid_24115;\n    int64_t global_tid_27214;\n    int64_t slice_27215;\n    int64_t gtid_24114;\n    int64_t remnant_27216;\n    \n    local_tid_27210 = get_local_id(0);\n    tblock_sizze_27213 = get_local_size(0);\n    wave_sizze_27212",
                                    " = LOCKSTEP_WIDTH;\n    block_id_27211 = get_tblock_id(0);\n    global_tid_27209 = block_id_27211 * tblock_sizze_27213 + local_tid_27210;\n    phys_tid_24115 = sext_i32_i64(global_tid_27209);\n    global_tid_27214 = sext_i32_i64(block_id_27211) * segmap_tblock_sizze_24110 + sext_i32_i64(local_tid_27210);\n    slice_27215 = dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578;\n    gtid_24114 = global_tid_27214;\n    remnant_27216 = global_tid_27214 - gtid_24114;\n    if (slt64(gtid_24114, dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578)) {\n        int64_t eta_p_24117;\n        int64_t min_res_24118;\n        bool x_24119;\n        bool y_24120;\n        bool bounds_check_24121;\n        bool index_certs_24122;\n        bool cond_24124;\n        int64_t ri_next_24125;\n        int64_t max_arg1_24132;\n        int64_t max_res_24133;\n        bool x_24134;\n        bool y_24135;\n        bool bounds_check_24136;\n        bool index_certs_24137;\n        int32_t r_min_24123;\n        int32_t r_max_24138;\n        bool defunc_0_f_res_24139;\n        int64_t defunc_0_f_res_24140;\n        bool loop_while_24141;\n        int64_t fm_24142;\n        bool defunc_0_f_res_24208;\n        int64_t defunc_0_f_res_24209;\n        bool loop_while_24210;\n        int64_t lm_24211;\n        \n        eta_p_24117 = ((__global int64_t *) mem_26262)[gtid_24114];\n        min_res_24118 = smin64(gt_rhs_21419, eta_p_24117);\n        x_24119 = sle64((int64_t) 0, min_res_24118);\n        y_24120 = slt64(min_res_24118, nR_17046);\n        bounds_check_24121 = x_24119 && y_24120;\n        if (!bounds_check_24121) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 17) == -1) {\n                    global_failure_args[0] = (int64_t) min_res_24118;\n                    global_failure_args[1] = (int64_t) nR_17046;\n                    ;\n                }\n                return;\n            }\n        }\n        cond_24124 = gtid_24114 == zeze_rhs_21852;\n        if (cond_24124", ") {\n            ri_next_24125 = nR_17046;\n        } else {\n            int64_t tmp_24126;\n            bool x_24127;\n            bool y_24128;\n            bool bounds_check_24129;\n            bool index_certs_24130;\n            int64_t ri_next_f_res_24131;\n            \n            tmp_24126 = add64((int64_t) 1, gtid_24114);\n            x_24127 = sle64((int64_t) 0, tmp_24126);\n            y_24128 = slt64(tmp_24126, dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578);\n            bounds_check_24129 = x_24127 && y_24128;\n            if (!bounds_check_24129) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 18) == -1) {\n                        global_failure_args[0] = (int64_t) tmp_24126;\n                        global_failure_args[1] = (int64_t) dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578;\n                        ;\n                    }\n                    return;\n                }\n            }\n            ri_next_f_res_24131 = ((__global int64_t *) mem_26262)[tmp_24126];\n            ri_next_24125 = ri_next_f_res_24131;\n        }\n        max_arg1_24132 = sub64(ri_next_24125, (int64_t) 1);\n        max_res_24133 = smax64((int64_t) 0, max_arg1_24132);\n        x_24134 = sle64((int64_t) 0, max_res_24133);\n        y_24135 = slt64(max_res_24133, nR_17046);\n        bounds_check_24136 = x_24134 && y_24135;\n        if (!bounds_check_24136) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 19) == -1) {\n                    global_failure_args[0] = (int64_t) max_res_24133;\n                    global_failure_args[1] = (int64_t) nR_17046;\n                    ;\n                }\n                return;\n            }\n        }\n        r_min_24123 = ((__global int32_t *) tR_mem_26243)[min_res_24118];\n        r_max_24138 = ((__global int32_t *) tR_mem_26243)[max_res_24133];\n        loop_while_24141 = 1;\n        fm_24142 = gtid_24114;\n        while (loop_while_24141) {\n        ", "    bool x_24143;\n            bool y_24144;\n            bool bounds_check_24145;\n            bool index_certs_24146;\n            int64_t loopres_24147;\n            int64_t min_res_24148;\n            bool x_24149;\n            bool y_24150;\n            bool bounds_check_24151;\n            bool index_certs_24152;\n            bool cond_24155;\n            int64_t si_next_24156;\n            int64_t max_arg1_24163;\n            int64_t max_res_24164;\n            bool x_24165;\n            bool y_24166;\n            bool bounds_check_24167;\n            bool index_certs_24168;\n            int64_t min_res_24171;\n            bool x_24172;\n            bool y_24173;\n            bool bounds_check_24174;\n            bool index_certs_24175;\n            int64_t max_arg1_24178;\n            int64_t max_res_24179;\n            bool x_24180;\n            bool y_24181;\n            bool bounds_check_24182;\n            bool index_certs_24183;\n            int64_t slice_24153;\n            int32_t s_min_24154;\n            int64_t slice_24169;\n            int64_t slice_24176;\n            int64_t slice_24184;\n            bool defunc_0_gt_res_24186;\n            bool loopres_24187;\n            int64_t loopres_24188;\n            bool loop_while_tmp_27217;\n            int64_t fm_tmp_27218;\n            \n            x_24143 = sle64((int64_t) 0, fm_24142);\n            y_24144 = slt64(fm_24142, dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578);\n            bounds_check_24145 = x_24143 && y_24144;\n            if (!bounds_check_24145) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 20) == -1) {\n                        global_failure_args[0] = (int64_t) fm_24142;\n                        global_failure_args[1] = (int64_t) dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578;\n                        ;\n                    }\n                    return;\n                }\n            }\n            loopres_24147 = ((__global int64_t *) mem_26",
                                    "264)[fm_24142];\n            min_res_24148 = smin64(gt_rhs_21419, loopres_24147);\n            x_24149 = sle64((int64_t) 0, min_res_24148);\n            y_24150 = slt64(min_res_24148, nR_17046);\n            bounds_check_24151 = x_24149 && y_24150;\n            if (!bounds_check_24151) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 21) == -1) {\n                        global_failure_args[0] = (int64_t) min_res_24148;\n                        global_failure_args[1] = (int64_t) nR_17046;\n                        ;\n                    }\n                    return;\n                }\n            }\n            cond_24155 = sle64(zeze_rhs_21852, fm_24142);\n            if (cond_24155) {\n                si_next_24156 = nR_17046;\n            } else {\n                int64_t tmp_24157;\n                bool x_24158;\n                bool y_24159;\n                bool bounds_check_24160;\n                bool index_certs_24161;\n                int64_t si_next_f_res_24162;\n                \n                tmp_24157 = add64((int64_t) 1, fm_24142);\n                x_24158 = sle64((int64_t) 0, tmp_24157);\n                y_24159 = slt64(tmp_24157, dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578);\n                bounds_check_24160 = x_24158 && y_24159;\n                if (!bounds_check_24160) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 22) == -1) {\n                            global_failure_args[0] = (int64_t) tmp_24157;\n                            global_failure_args[1] = (int64_t) dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578;\n                            ;\n                        }\n                        return;\n                    }\n                }\n                si_next_f_res_24162 = ((__global int64_t *) mem_26264)[tmp_24157];\n                si_next_24156 = si_next_f_res_24162;\n            }\n            max_arg1_24163 = sub64(si_next_24156, (int", "64_t) 1);\n            max_res_24164 = smax64(min_res_24148, max_arg1_24163);\n            x_24165 = sle64((int64_t) 0, max_res_24164);\n            y_24166 = slt64(max_res_24164, nR_17046);\n            bounds_check_24167 = x_24165 && y_24166;\n            if (!bounds_check_24167) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 23) == -1) {\n                        global_failure_args[0] = (int64_t) max_res_24164;\n                        global_failure_args[1] = (int64_t) nR_17046;\n                        ;\n                    }\n                    return;\n                }\n            }\n            min_res_24171 = smin64(zeze_rhs_21852, si_next_24156);\n            x_24172 = sle64((int64_t) 0, min_res_24171);\n            y_24173 = slt64(min_res_24171, nR_17046);\n            bounds_check_24174 = x_24172 && y_24173;\n            if (!bounds_check_24174) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 24) == -1) {\n                        global_failure_args[0] = (int64_t) min_res_24171;\n                        global_failure_args[1] = (int64_t) nR_17046;\n                        ;\n                    }\n                    return;\n                }\n            }\n            max_arg1_24178 = sub64(min_res_24148, (int64_t) 1);\n            max_res_24179 = smax64((int64_t) 0, max_arg1_24178);\n            x_24180 = sle64((int64_t) 0, max_res_24179);\n            y_24181 = slt64(max_res_24179, nR_17046);\n            bounds_check_24182 = x_24180 && y_24181;\n            if (!bounds_check_24182) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 25) == -1) {\n                        global_failure_args[0] = (int64_t) max_res_24179;\n                        global_failure_args[1] = (int64_t) nR_17046;\n                        ;\n                    }\n                    return;\n                }\n            }\n            slice_24153 = tS_start_21436 + min_res_24148;\n    ", "        s_min_24154 = ((__global int32_t *) tS_mem_26244)[slice_24153];\n            slice_24169 = tS_start_21436 + max_res_24164;\n            slice_24176 = tS_start_21436 + min_res_24171;\n            slice_24184 = tS_start_21436 + max_res_24179;\n            defunc_0_gt_res_24186 = slt32(s_min_24154, r_min_24123);\n            if (defunc_0_gt_res_24186) {\n                int32_t s_max_24170;\n                bool defunc_0_leq_res_24189;\n                bool loopres_t_res_24190;\n                int64_t loopres_t_res_24191;\n                \n                s_max_24170 = ((__global int32_t *) tS_mem_26244)[slice_24169];\n                defunc_0_leq_res_24189 = sle32(r_min_24123, s_max_24170);\n                if (defunc_0_leq_res_24189) {\n                    loopres_t_res_24190 = 0;\n                    loopres_t_res_24191 = fm_24142;\n                } else {\n                    int32_t s_nextMin_24177;\n                    bool defunc_0_leq_res_24192;\n                    int64_t zgze_lhs_24193;\n                    bool tmp_f_res_24194;\n                    bool x_24195;\n                    bool y_24196;\n                    bool tmp_24197;\n                    bool loopres_t_res_f_res_24198;\n                    \n                    s_nextMin_24177 = ((__global int32_t *) tS_mem_26244)[slice_24176];\n                    defunc_0_leq_res_24192 = sle32(r_min_24123, s_nextMin_24177);\n                    zgze_lhs_24193 = add64((int64_t) 1, fm_24142);\n                    tmp_f_res_24194 = sle64(dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578, zgze_lhs_24193);\n                    x_24195 = !defunc_0_leq_res_24192;\n                    y_24196 = tmp_f_res_24194 && x_24195;\n                    tmp_24197 = defunc_0_leq_res_24192 || y_24196;\n                    loopres_t_res_f_res_24198 = !tmp_24197;\n                    loopres_t_res_24190 = loopres_t_res_f_res_24198;\n                    loopres_t_res_24191 = zgze_lhs_24193;\n                }\n                loopres_241",
                                    "87 = loopres_t_res_24190;\n                loopres_24188 = loopres_t_res_24191;\n            } else {\n                int32_t s_prevMax_24185;\n                bool defunc_0_leq_res_24199;\n                int64_t zlze_lhs_24200;\n                bool tmp_f_res_24201;\n                bool x_24202;\n                bool y_24203;\n                bool tmp_24204;\n                int64_t max_res_24205;\n                bool loopres_f_res_24206;\n                \n                s_prevMax_24185 = ((__global int32_t *) tS_mem_26244)[slice_24184];\n                defunc_0_leq_res_24199 = sle32(s_prevMax_24185, r_min_24123);\n                zlze_lhs_24200 = sub64(fm_24142, (int64_t) 1);\n                tmp_f_res_24201 = sle64(zlze_lhs_24200, (int64_t) 0);\n                x_24202 = !defunc_0_leq_res_24199;\n                y_24203 = tmp_f_res_24201 && x_24202;\n                tmp_24204 = defunc_0_leq_res_24199 || y_24203;\n                max_res_24205 = smax64((int64_t) 0, zlze_lhs_24200);\n                loopres_f_res_24206 = !tmp_24204;\n                loopres_24187 = loopres_f_res_24206;\n                loopres_24188 = max_res_24205;\n            }\n            loop_while_tmp_27217 = loopres_24187;\n            fm_tmp_27218 = loopres_24188;\n            loop_while_24141 = loop_while_tmp_27217;\n            fm_24142 = fm_tmp_27218;\n        }\n        defunc_0_f_res_24139 = loop_while_24141;\n        defunc_0_f_res_24140 = fm_24142;\n        loop_while_24210 = 1;\n        lm_24211 = gtid_24114;\n        while (loop_while_24210) {\n            bool x_24212;\n            bool y_24213;\n            bool bounds_check_24214;\n            bool index_certs_24215;\n            int64_t loopres_24216;\n            int64_t min_res_24217;\n            bool x_24218;\n            bool y_24219;\n            bool bounds_check_24220;\n            bool index_certs_24221;\n            bool cond_24224;\n            int64_t si_next_24225;\n            int64_t max_arg1_24232;\n            int64_t max_res_24233;\n            bool ", "x_24234;\n            bool y_24235;\n            bool bounds_check_24236;\n            bool index_certs_24237;\n            int64_t min_res_24240;\n            bool x_24241;\n            bool y_24242;\n            bool bounds_check_24243;\n            bool index_certs_24244;\n            int64_t max_arg1_24247;\n            int64_t max_res_24248;\n            bool x_24249;\n            bool y_24250;\n            bool bounds_check_24251;\n            bool index_certs_24252;\n            int64_t slice_24222;\n            int64_t slice_24238;\n            int32_t s_max_24239;\n            int64_t slice_24245;\n            int64_t slice_24253;\n            bool defunc_0_gt_res_24255;\n            bool loopres_24256;\n            int64_t loopres_24257;\n            bool loop_cond_t_res_24272;\n            bool x_24273;\n            bool loop_while_tmp_27219;\n            int64_t lm_tmp_27220;\n            \n            x_24212 = sle64((int64_t) 0, lm_24211);\n            y_24213 = slt64(lm_24211, dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578);\n            bounds_check_24214 = x_24212 && y_24213;\n            if (!bounds_check_24214) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 26) == -1) {\n                        global_failure_args[0] = (int64_t) lm_24211;\n                        global_failure_args[1] = (int64_t) dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578;\n                        ;\n                    }\n                    return;\n                }\n            }\n            loopres_24216 = ((__global int64_t *) mem_26264)[lm_24211];\n            min_res_24217 = smin64(gt_rhs_21419, loopres_24216);\n            x_24218 = sle64((int64_t) 0, min_res_24217);\n            y_24219 = slt64(min_res_24217, nR_17046);\n            bounds_check_24220 = x_24218 && y_24219;\n            if (!bounds_check_24220) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 27) == -1) {\n             ", "           global_failure_args[0] = (int64_t) min_res_24217;\n                        global_failure_args[1] = (int64_t) nR_17046;\n                        ;\n                    }\n                    return;\n                }\n            }\n            cond_24224 = sle64(zeze_rhs_21852, lm_24211);\n            if (cond_24224) {\n                si_next_24225 = nR_17046;\n            } else {\n                int64_t tmp_24226;\n                bool x_24227;\n                bool y_24228;\n                bool bounds_check_24229;\n                bool index_certs_24230;\n                int64_t si_next_f_res_24231;\n                \n                tmp_24226 = add64((int64_t) 1, lm_24211);\n                x_24227 = sle64((int64_t) 0, tmp_24226);\n                y_24228 = slt64(tmp_24226, dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578);\n                bounds_check_24229 = x_24227 && y_24228;\n                if (!bounds_check_24229) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 28) == -1) {\n                            global_failure_args[0] = (int64_t) tmp_24226;\n                            global_failure_args[1] = (int64_t) dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578;\n                            ;\n                        }\n                        return;\n                    }\n                }\n                si_next_f_res_24231 = ((__global int64_t *) mem_26264)[tmp_24226];\n                si_next_24225 = si_next_f_res_24231;\n            }\n            max_arg1_24232 = sub64(si_next_24225, (int64_t) 1);\n            max_res_24233 = smax64(min_res_24217, max_arg1_24232);\n            x_24234 = sle64((int64_t) 0, max_res_24233);\n            y_24235 = slt64(max_res_24233, nR_17046);\n            bounds_check_24236 = x_24234 && y_24235;\n            if (!bounds_check_24236) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 29) == -1) {\n                 ",
                                    "       global_failure_args[0] = (int64_t) max_res_24233;\n                        global_failure_args[1] = (int64_t) nR_17046;\n                        ;\n                    }\n                    return;\n                }\n            }\n            min_res_24240 = smin64(zeze_rhs_21852, si_next_24225);\n            x_24241 = sle64((int64_t) 0, min_res_24240);\n            y_24242 = slt64(min_res_24240, nR_17046);\n            bounds_check_24243 = x_24241 && y_24242;\n            if (!bounds_check_24243) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 30) == -1) {\n                        global_failure_args[0] = (int64_t) min_res_24240;\n                        global_failure_args[1] = (int64_t) nR_17046;\n                        ;\n                    }\n                    return;\n                }\n            }\n            max_arg1_24247 = sub64(min_res_24217, (int64_t) 1);\n            max_res_24248 = smax64((int64_t) 0, max_arg1_24247);\n            x_24249 = sle64((int64_t) 0, max_res_24248);\n            y_24250 = slt64(max_res_24248, nR_17046);\n            bounds_check_24251 = x_24249 && y_24250;\n            if (!bounds_check_24251) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 31) == -1) {\n                        global_failure_args[0] = (int64_t) max_res_24248;\n                        global_failure_args[1] = (int64_t) nR_17046;\n                        ;\n                    }\n                    return;\n                }\n            }\n            slice_24222 = tS_start_21436 + min_res_24217;\n            slice_24238 = tS_start_21436 + max_res_24233;\n            s_max_24239 = ((__global int32_t *) tS_mem_26244)[slice_24238];\n            slice_24245 = tS_start_21436 + min_res_24240;\n            slice_24253 = tS_start_21436 + max_res_24248;\n            defunc_0_gt_res_24255 = slt32(r_max_24138, s_max_24239);\n            if (defunc_0_gt_res_24255) {\n                int32_t s_min_24223;\n     ", "           bool defunc_0_leq_res_24258;\n                bool loopres_t_res_24259;\n                int64_t loopres_t_res_24260;\n                \n                s_min_24223 = ((__global int32_t *) tS_mem_26244)[slice_24222];\n                defunc_0_leq_res_24258 = sle32(s_min_24223, r_max_24138);\n                if (defunc_0_leq_res_24258) {\n                    loopres_t_res_24259 = 0;\n                    loopres_t_res_24260 = lm_24211;\n                } else {\n                    int32_t s_prevMax_24254;\n                    bool defunc_0_leq_res_24261;\n                    int64_t zlze_lhs_24262;\n                    bool tmp_f_res_24263;\n                    bool x_24264;\n                    bool y_24265;\n                    bool tmp_24266;\n                    int64_t max_res_24267;\n                    bool loopres_t_res_f_res_24268;\n                    \n                    s_prevMax_24254 = ((__global int32_t *) tS_mem_26244)[slice_24253];\n                    defunc_0_leq_res_24261 = sle32(s_prevMax_24254, r_max_24138);\n                    zlze_lhs_24262 = sub64(lm_24211, (int64_t) 1);\n                    tmp_f_res_24263 = sle64(zlze_lhs_24262, (int64_t) 0);\n                    x_24264 = !defunc_0_leq_res_24261;\n                    y_24265 = tmp_f_res_24263 && x_24264;\n                    tmp_24266 = defunc_0_leq_res_24261 || y_24265;\n                    max_res_24267 = smax64((int64_t) 0, zlze_lhs_24262);\n                    loopres_t_res_f_res_24268 = !tmp_24266;\n                    loopres_t_res_24259 = loopres_t_res_f_res_24268;\n                    loopres_t_res_24260 = max_res_24267;\n                }\n                loopres_24256 = loopres_t_res_24259;\n                loopres_24257 = loopres_t_res_24260;\n            } else {\n                int32_t s_nextMin_24246;\n                bool defunc_0_leq_res_24269;\n                int64_t tmp_24270;\n                bool loopres_f_res_24271;\n                \n                s_nextMin_24246 = ((__global int32_t *) tS_", "mem_26244)[slice_24245];\n                defunc_0_leq_res_24269 = sle32(r_max_24138, s_nextMin_24246);\n                tmp_24270 = add64((int64_t) 1, lm_24211);\n                loopres_f_res_24271 = !defunc_0_leq_res_24269;\n                loopres_24256 = loopres_f_res_24271;\n                loopres_24257 = tmp_24270;\n            }\n            loop_cond_t_res_24272 = slt64(loopres_24257, dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578);\n            x_24273 = loopres_24256 && loop_cond_t_res_24272;\n            loop_while_tmp_27219 = x_24273;\n            lm_tmp_27220 = loopres_24257;\n            loop_while_24210 = loop_while_tmp_27219;\n            lm_24211 = lm_tmp_27220;\n        }\n        defunc_0_f_res_24208 = loop_while_24210;\n        defunc_0_f_res_24209 = lm_24211;\n        ((__global int64_t *) mem_26298)[gtid_24114] = defunc_0_f_res_24140;\n        ((__global int64_t *) mem_26300)[gtid_24114] = defunc_0_f_res_24209;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_24110\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzisegmap_24467_dim1, 1, 1)\nvoid inner_SMJ_intzisegmap_24467(__global int *global_failure, int64_t dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046, int64_t ext_26479, int64_t ext_26480, __global unsigned char *mem_param_26316, __global unsigned char *ext_mem_26483, __global unsigned char *mem_26487)\n{\n    #define segmap_tblock_sizze_24463 (inner_SMJ_intzisegmap_24467zisegmap_tblock_sizze_24463)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27332;\n    int32_t tblock_sizze_27335;\n    int32_t wave_sizze_27334;\n    int32_t block_id_27333;\n    int32_t global_tid_27331;\n    int64_t phys_tid_24467;\n    int64_t global_tid_27336;\n    int64_t slice_27337;\n    int64_t gtid_24466;\n    int64_t remnant_27338;\n    \n    local_tid_27332 = get_local_id(0);\n    tblock_sizze_27335 = get_local_size(0);\n    wave_sizze_27334 = LOCKSTEP_WIDTH;\n    block_id_27333 = get_tblock_id(0);\n    global_tid_27331 = block_id_27333 * tbloc",
                                    "k_sizze_27335 + local_tid_27332;\n    phys_tid_24467 = sext_i32_i64(global_tid_27331);\n    global_tid_27336 = sext_i32_i64(block_id_27333) * segmap_tblock_sizze_24463 + sext_i32_i64(local_tid_27332);\n    slice_27337 = dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046;\n    gtid_24466 = global_tid_27336;\n    remnant_27338 = global_tid_27336 - gtid_24466;\n    if (slt64(gtid_24466, dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046)) {\n        int64_t eta_p_24468;\n        bool cond_24470;\n        int64_t lifted_lambda_res_24471;\n        \n        eta_p_24468 = ((__global int64_t *) mem_param_26316)[gtid_24466];\n        cond_24470 = slt64(eta_p_24468, (int64_t) 0);\n        if (cond_24470) {\n            int64_t eta_p_24469 = ((__global int64_t *) ext_mem_26483)[ext_26480 + gtid_24466 * ext_26479];\n            \n            lifted_lambda_res_24471 = eta_p_24469;\n        } else {\n            lifted_lambda_res_24471 = eta_p_24468;\n        }\n        ((__global int64_t *) mem_26487)[gtid_24466] = lifted_lambda_res_24471;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_24463\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzisegmap_24488_dim1, 1, 1)\nvoid inner_SMJ_intzisegmap_24488(__global int *global_failure, int64_t dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046, int64_t ext_26481, int64_t ext_26482, __global unsigned char *mem_param_26313, __global unsigned char *ext_mem_26484, __global unsigned char *mem_26490)\n{\n    #define segmap_tblock_sizze_24484 (inner_SMJ_intzisegmap_24488zisegmap_tblock_sizze_24484)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27341;\n    int32_t tblock_sizze_27344;\n    int32_t wave_sizze_27343;\n    int32_t block_id_27342;\n    int32_t global_tid_27340;\n    int64_t phys_tid_24488;\n    int64_t global_tid_27345;\n    int64_t slice_27346;\n    int64_t gtid_24487;\n    int64_t remnant_27347;\n    \n    local_tid_27341 = get_local_id(0);\n    tblock_sizze_27344 = get_local_size(0);\n    wave_sizze_27343 = LOCKSTEP_WIDTH;\n    block_id_27342 = ge", "t_tblock_id(0);\n    global_tid_27340 = block_id_27342 * tblock_sizze_27344 + local_tid_27341;\n    phys_tid_24488 = sext_i32_i64(global_tid_27340);\n    global_tid_27345 = sext_i32_i64(block_id_27342) * segmap_tblock_sizze_24484 + sext_i32_i64(local_tid_27341);\n    slice_27346 = dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046;\n    gtid_24487 = global_tid_27345;\n    remnant_27347 = global_tid_27345 - gtid_24487;\n    if (slt64(gtid_24487, dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046)) {\n        int64_t eta_p_24489;\n        int64_t eta_p_24490;\n        int64_t defunc_0_f_res_24491;\n        \n        eta_p_24489 = ((__global int64_t *) mem_param_26313)[gtid_24487];\n        eta_p_24490 = ((__global int64_t *) ext_mem_26484)[ext_26482 + gtid_24487 * ext_26481];\n        defunc_0_f_res_24491 = add64(eta_p_24489, eta_p_24490);\n        ((__global int64_t *) mem_26490)[gtid_24487] = defunc_0_f_res_24491;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_24484\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzisegmap_24509_dim1, 1, 1)\nvoid inner_SMJ_intzisegmap_24509(__global int *global_failure, int64_t loopres_f_res_f_res_22031, int64_t dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046, int64_t ctx_param_ext_26304, int64_t ctx_param_ext_26305, __global unsigned char *mem_param_26306, __global unsigned char *ext_mem_26495, __global unsigned char *mem_26499)\n{\n    #define segmap_tblock_sizze_24505 (inner_SMJ_intzisegmap_24509zisegmap_tblock_sizze_24505)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27350;\n    int32_t tblock_sizze_27353;\n    int32_t wave_sizze_27352;\n    int32_t block_id_27351;\n    int32_t global_tid_27349;\n    int64_t phys_tid_24509;\n    int64_t global_tid_27354;\n    int64_t slice_27355;\n    int64_t gtid_24508;\n    int64_t remnant_27356;\n    \n    local_tid_27350 = get_local_id(0);\n    tblock_sizze_27353 = get_local_size(0);\n    wave_sizze_27352 = LOCKSTEP_WIDTH;\n    block_id_27351 = get_tblock_id(0);\n    global_tid_27349 = block_id_27351 * ", "tblock_sizze_27353 + local_tid_27350;\n    phys_tid_24509 = sext_i32_i64(global_tid_27349);\n    global_tid_27354 = sext_i32_i64(block_id_27351) * segmap_tblock_sizze_24505 + sext_i32_i64(local_tid_27350);\n    slice_27355 = dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046;\n    gtid_24508 = global_tid_27354;\n    remnant_27356 = global_tid_27354 - gtid_24508;\n    if (slt64(gtid_24508, dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046)) {\n        int64_t slice_24667;\n        int64_t eta_p_24510;\n        bool cond_24512;\n        int64_t lifted_lambda_res_24513;\n        \n        slice_24667 = loopres_f_res_f_res_22031 + gtid_24508;\n        eta_p_24510 = ((__global int64_t *) mem_param_26306)[ctx_param_ext_26304 + slice_24667 * ctx_param_ext_26305];\n        cond_24512 = slt64(eta_p_24510, (int64_t) 0);\n        if (cond_24512) {\n            int64_t eta_p_24511 = ((__global int64_t *) ext_mem_26495)[gtid_24508];\n            \n            lifted_lambda_res_24513 = eta_p_24511;\n        } else {\n            lifted_lambda_res_24513 = eta_p_24510;\n        }\n        ((__global int64_t *) mem_26499)[gtid_24508] = lifted_lambda_res_24513;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_24505\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzisegmap_24530_dim1, 1, 1)\nvoid inner_SMJ_intzisegmap_24530(__global int *global_failure, int64_t loopres_f_res_f_res_22031, int64_t dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046, int64_t ctx_param_ext_26301, int64_t ctx_param_ext_26302, __global unsigned char *mem_param_26303, __global unsigned char *ext_mem_26496, __global unsigned char *mem_26502)\n{\n    #define segmap_tblock_sizze_24526 (inner_SMJ_intzisegmap_24530zisegmap_tblock_sizze_24526)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27359;\n    int32_t tblock_sizze_27362;\n    int32_t wave_sizze_27361;\n    int32_t block_id_27360;\n    int32_t global_tid_27358;\n    int64_t phys_tid_24530;\n    int64_t global_tid_27363;\n    int64_t slice_27364;\n    int64_t gtid_24529;\n    i",
                                    "nt64_t remnant_27365;\n    \n    local_tid_27359 = get_local_id(0);\n    tblock_sizze_27362 = get_local_size(0);\n    wave_sizze_27361 = LOCKSTEP_WIDTH;\n    block_id_27360 = get_tblock_id(0);\n    global_tid_27358 = block_id_27360 * tblock_sizze_27362 + local_tid_27359;\n    phys_tid_24530 = sext_i32_i64(global_tid_27358);\n    global_tid_27363 = sext_i32_i64(block_id_27360) * segmap_tblock_sizze_24526 + sext_i32_i64(local_tid_27359);\n    slice_27364 = dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046;\n    gtid_24529 = global_tid_27363;\n    remnant_27365 = global_tid_27363 - gtid_24529;\n    if (slt64(gtid_24529, dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046)) {\n        int64_t slice_24666;\n        int64_t eta_p_24531;\n        int64_t eta_p_24532;\n        int64_t defunc_0_f_res_24533;\n        \n        slice_24666 = loopres_f_res_f_res_22031 + gtid_24529;\n        eta_p_24531 = ((__global int64_t *) mem_param_26303)[ctx_param_ext_26301 + slice_24666 * ctx_param_ext_26302];\n        eta_p_24532 = ((__global int64_t *) ext_mem_26496)[gtid_24529];\n        defunc_0_f_res_24533 = add64(eta_p_24531, eta_p_24532);\n        ((__global int64_t *) mem_26502)[gtid_24529] = defunc_0_f_res_24533;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_24526\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzisegmap_24551_dim1, 1, 1)\nvoid inner_SMJ_intzisegmap_24551(__global int *global_failure, int64_t nR_17046, int64_t ext_26690, int64_t ext_26691, __global unsigned char *mem_param_26258, __global unsigned char *ext_mem_26692, __global unsigned char *mem_26698)\n{\n    #define segmap_tblock_sizze_24547 (inner_SMJ_intzisegmap_24551zisegmap_tblock_sizze_24547)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27368;\n    int32_t tblock_sizze_27371;\n    int32_t wave_sizze_27370;\n    int32_t block_id_27369;\n    int32_t global_tid_27367;\n    int64_t phys_tid_24551;\n    int64_t global_tid_27372;\n    int64_t slice_27373;\n    int64_t gtid_24550;\n    int64_t remnant_27374;\n    \n    local", "_tid_27368 = get_local_id(0);\n    tblock_sizze_27371 = get_local_size(0);\n    wave_sizze_27370 = LOCKSTEP_WIDTH;\n    block_id_27369 = get_tblock_id(0);\n    global_tid_27367 = block_id_27369 * tblock_sizze_27371 + local_tid_27368;\n    phys_tid_24551 = sext_i32_i64(global_tid_27367);\n    global_tid_27372 = sext_i32_i64(block_id_27369) * segmap_tblock_sizze_24547 + sext_i32_i64(local_tid_27368);\n    slice_27373 = nR_17046;\n    gtid_24550 = global_tid_27372;\n    remnant_27374 = global_tid_27372 - gtid_24550;\n    if (slt64(gtid_24550, nR_17046)) {\n        int64_t eta_p_24552;\n        bool cond_24554;\n        int64_t lifted_lambda_res_24555;\n        \n        eta_p_24552 = ((__global int64_t *) mem_param_26258)[gtid_24550];\n        cond_24554 = slt64(eta_p_24552, (int64_t) 0);\n        if (cond_24554) {\n            int64_t eta_p_24553 = ((__global int64_t *) ext_mem_26692)[ext_26691 + gtid_24550 * ext_26690];\n            \n            lifted_lambda_res_24555 = eta_p_24553;\n        } else {\n            lifted_lambda_res_24555 = eta_p_24552;\n        }\n        ((__global int64_t *) mem_26698)[gtid_24550] = lifted_lambda_res_24555;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_24547\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzisegmap_24572_dim1, 1, 1)\nvoid inner_SMJ_intzisegmap_24572(__global int *global_failure, int64_t nR_17046, int64_t ext_26693, int64_t ext_26694, __global unsigned char *mem_param_26255, __global unsigned char *ext_mem_26695, __global unsigned char *mem_26701)\n{\n    #define segmap_tblock_sizze_24568 (inner_SMJ_intzisegmap_24572zisegmap_tblock_sizze_24568)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27377;\n    int32_t tblock_sizze_27380;\n    int32_t wave_sizze_27379;\n    int32_t block_id_27378;\n    int32_t global_tid_27376;\n    int64_t phys_tid_24572;\n    int64_t global_tid_27381;\n    int64_t slice_27382;\n    int64_t gtid_24571;\n    int64_t remnant_27383;\n    \n    local_tid_27377 = get_local_id(0);\n    tblock_sizze_273", "80 = get_local_size(0);\n    wave_sizze_27379 = LOCKSTEP_WIDTH;\n    block_id_27378 = get_tblock_id(0);\n    global_tid_27376 = block_id_27378 * tblock_sizze_27380 + local_tid_27377;\n    phys_tid_24572 = sext_i32_i64(global_tid_27376);\n    global_tid_27381 = sext_i32_i64(block_id_27378) * segmap_tblock_sizze_24568 + sext_i32_i64(local_tid_27377);\n    slice_27382 = nR_17046;\n    gtid_24571 = global_tid_27381;\n    remnant_27383 = global_tid_27381 - gtid_24571;\n    if (slt64(gtid_24571, nR_17046)) {\n        int64_t eta_p_24573;\n        int64_t eta_p_24574;\n        int64_t defunc_0_f_res_24575;\n        \n        eta_p_24573 = ((__global int64_t *) mem_param_26255)[gtid_24571];\n        eta_p_24574 = ((__global int64_t *) ext_mem_26695)[ext_26694 + gtid_24571 * ext_26693];\n        defunc_0_f_res_24575 = add64(eta_p_24573, eta_p_24574);\n        ((__global int64_t *) mem_26701)[gtid_24571] = defunc_0_f_res_24575;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_24568\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzisegmap_24585_dim1, 1, 1)\nvoid inner_SMJ_intzisegmap_24585(__global int *global_failure, int64_t nR_17046, int64_t m_22282, int64_t num_tblocks_24590, int32_t virt_num_tblocks_27514, __global unsigned char *tR_mem_26243, __global unsigned char *ext_mem_26245, __global unsigned char *ext_mem_26713, __global unsigned char *ext_mem_26714, __global unsigned char *mem_26717, __global unsigned char *mem_26719, __global unsigned char *mem_26721, __global unsigned char *mem_26723, __global unsigned char *mem_26725, __global unsigned char *mem_26727)\n{\n    #define segmap_tblock_sizze_24588 (inner_SMJ_intzisegmap_24585zisegmap_tblock_sizze_24588)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27516;\n    int32_t tblock_sizze_27519;\n    int32_t wave_sizze_27518;\n    int32_t block_id_27517;\n    int32_t global_tid_27515;\n    int64_t phys_tid_24585;\n    int32_t phys_tblock_id_27520;\n    int32_t iterations_27521;\n    \n    local_tid_27516 = get_local_id(",
                                    "0);\n    tblock_sizze_27519 = get_local_size(0);\n    wave_sizze_27518 = LOCKSTEP_WIDTH;\n    block_id_27517 = get_tblock_id(0);\n    global_tid_27515 = block_id_27517 * tblock_sizze_27519 + local_tid_27516;\n    phys_tid_24585 = sext_i32_i64(global_tid_27515);\n    phys_tblock_id_27520 = get_tblock_id(0);\n    iterations_27521 = sdiv_up32(virt_num_tblocks_27514 - phys_tblock_id_27520, sext_i64_i32(num_tblocks_24590));\n    for (int32_t i_27522 = 0; i_27522 < iterations_27521; i_27522++) {\n        int32_t virt_tblock_id_27523;\n        int64_t global_tid_27524;\n        int64_t slice_27525;\n        int64_t write_i_24584;\n        int64_t remnant_27526;\n        \n        virt_tblock_id_27523 = phys_tblock_id_27520 + i_27522 * sext_i64_i32(num_tblocks_24590);\n        global_tid_27524 = sext_i32_i64(virt_tblock_id_27523) * segmap_tblock_sizze_24588 + sext_i32_i64(local_tid_27516);\n        slice_27525 = nR_17046;\n        write_i_24584 = global_tid_27524;\n        remnant_27526 = global_tid_27524 - write_i_24584;\n        if (slt64(write_i_24584, nR_17046)) {\n            int64_t eta_p_22547;\n            int32_t write_value_22549;\n            int64_t write_value_22550;\n            int64_t write_value_22551;\n            int64_t write_value_22552;\n            bool cond_22553;\n            int64_t lifted_lambda_res_22554;\n            \n            eta_p_22547 = ((__global int64_t *) mem_26719)[write_i_24584];\n            write_value_22549 = ((__global int32_t *) tR_mem_26243)[write_i_24584];\n            write_value_22550 = ((__global int64_t *) ext_mem_26245)[write_i_24584];\n            write_value_22551 = ((__global int64_t *) ext_mem_26713)[write_i_24584];\n            write_value_22552 = ((__global int64_t *) ext_mem_26714)[write_i_24584];\n            cond_22553 = eta_p_22547 == (int64_t) 1;\n            if (cond_22553) {\n                int64_t eta_p_22548;\n                int64_t lifted_lambda_res_t_res_23328;\n                \n                eta_p_22548 = ((__global int64_t *) mem_26717", ")[write_i_24584];\n                lifted_lambda_res_t_res_23328 = sub64(eta_p_22548, (int64_t) 1);\n                lifted_lambda_res_22554 = lifted_lambda_res_t_res_23328;\n            } else {\n                lifted_lambda_res_22554 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_22554) && slt64(lifted_lambda_res_22554, m_22282)) {\n                ((__global int32_t *) mem_26727)[lifted_lambda_res_22554] = write_value_22549;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_22554) && slt64(lifted_lambda_res_22554, m_22282)) {\n                ((__global int64_t *) mem_26725)[lifted_lambda_res_22554] = write_value_22550;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_22554) && slt64(lifted_lambda_res_22554, m_22282)) {\n                ((__global int64_t *) mem_26723)[lifted_lambda_res_22554] = write_value_22551;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_22554) && slt64(lifted_lambda_res_22554, m_22282)) {\n                ((__global int64_t *) mem_26721)[lifted_lambda_res_22554] = write_value_22552;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_24588\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzisegmap_24619_dim1, 1, 1)\nvoid inner_SMJ_intzisegmap_24619(__global int *global_failure, int64_t m_22282, __global unsigned char *mem_26731, __global unsigned char *mem_26738)\n{\n    #define segmap_tblock_sizze_24615 (inner_SMJ_intzisegmap_24619zisegmap_tblock_sizze_24615)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27682;\n    int32_t tblock_sizze_27685;\n    int32_t wave_sizze_27684;\n    int32_t block_id_27683;\n    int32_t global_tid_27681;\n    int64_t phys_tid_24619;\n    int64_t global_tid_27686;\n    int64_t slice_27687;\n    int64_t gtid_24618;\n    int64_t remnant_27688;\n    \n    local_tid_27682 = get_local_id(0);\n    tblock_sizze_27685 = get_local_size(0);\n   ", " wave_sizze_27684 = LOCKSTEP_WIDTH;\n    block_id_27683 = get_tblock_id(0);\n    global_tid_27681 = block_id_27683 * tblock_sizze_27685 + local_tid_27682;\n    phys_tid_24619 = sext_i32_i64(global_tid_27681);\n    global_tid_27686 = sext_i32_i64(block_id_27683) * segmap_tblock_sizze_24615 + sext_i32_i64(local_tid_27682);\n    slice_27687 = m_22282;\n    gtid_24618 = global_tid_27686;\n    remnant_27688 = global_tid_27686 - gtid_24618;\n    if (slt64(gtid_24618, m_22282)) {\n        int64_t zv_lhs_24621;\n        int64_t tmp_24622;\n        bool cond_24624;\n        int64_t lifted_lambda_res_24625;\n        \n        zv_lhs_24621 = add64((int64_t) -1, gtid_24618);\n        tmp_24622 = smod64(zv_lhs_24621, m_22282);\n        cond_24624 = gtid_24618 == (int64_t) 0;\n        if (cond_24624) {\n            lifted_lambda_res_24625 = (int64_t) 0;\n        } else {\n            int64_t lifted_lambda_res_24623 = ((__global int64_t *) mem_26731)[tmp_24622];\n            \n            lifted_lambda_res_24625 = lifted_lambda_res_24623;\n        }\n        ((__global int64_t *) mem_26738)[gtid_24618] = lifted_lambda_res_24625;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_24615\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzisegmap_24627_dim1, 1, 1)\nvoid inner_SMJ_intzisegmap_24627(__global int *global_failure, int64_t m_22282, int64_t lower_bound_22365, int64_t min_res_22367, int64_t j_m_i_22368, int64_t num_tblocks_24632, int32_t virt_num_tblocks_27727, __global unsigned char *mem_26723, __global unsigned char *mem_26725, __global unsigned char *mem_26727, __global unsigned char *mem_26738, __global unsigned char *mem_26767, __global unsigned char *mem_26769, __global unsigned char *mem_26771)\n{\n    #define segmap_tblock_sizze_24630 (inner_SMJ_intzisegmap_24627zisegmap_tblock_sizze_24630)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27729;\n    int32_t tblock_sizze_27732;\n    int32_t wave_sizze_27731;\n    int32_t block_id_27730;\n    int32_t global_tid_27728;\n    in",
                                    "t64_t phys_tid_24627;\n    int32_t phys_tblock_id_27733;\n    int32_t iterations_27734;\n    \n    local_tid_27729 = get_local_id(0);\n    tblock_sizze_27732 = get_local_size(0);\n    wave_sizze_27731 = LOCKSTEP_WIDTH;\n    block_id_27730 = get_tblock_id(0);\n    global_tid_27728 = block_id_27730 * tblock_sizze_27732 + local_tid_27729;\n    phys_tid_24627 = sext_i32_i64(global_tid_27728);\n    phys_tblock_id_27733 = get_tblock_id(0);\n    iterations_27734 = sdiv_up32(virt_num_tblocks_27727 - phys_tblock_id_27733, sext_i64_i32(num_tblocks_24632));\n    for (int32_t i_27735 = 0; i_27735 < iterations_27734; i_27735++) {\n        int32_t virt_tblock_id_27736;\n        int64_t global_tid_27737;\n        int64_t slice_27738;\n        int64_t write_i_24626;\n        int64_t remnant_27739;\n        \n        virt_tblock_id_27736 = phys_tblock_id_27733 + i_27735 * sext_i64_i32(num_tblocks_24632);\n        global_tid_27737 = sext_i32_i64(virt_tblock_id_27736) * segmap_tblock_sizze_24630 + sext_i32_i64(local_tid_27729);\n        slice_27738 = m_22282;\n        write_i_24626 = global_tid_27737;\n        remnant_27739 = global_tid_27737 - write_i_24626;\n        if (slt64(write_i_24626, m_22282)) {\n            int64_t eta_p_22940;\n            int32_t write_value_22941;\n            int64_t write_value_22942;\n            int64_t write_value_22943;\n            bool cond_22944;\n            bool cond_t_res_22945;\n            bool x_22946;\n            int64_t lifted_lambda_res_22947;\n            \n            eta_p_22940 = ((__global int64_t *) mem_26738)[write_i_24626];\n            write_value_22941 = ((__global int32_t *) mem_26727)[write_i_24626];\n            write_value_22942 = ((__global int64_t *) mem_26725)[write_i_24626];\n            write_value_22943 = ((__global int64_t *) mem_26723)[write_i_24626];\n            cond_22944 = sle64(lower_bound_22365, eta_p_22940);\n            cond_t_res_22945 = slt64(eta_p_22940, min_res_22367);\n            x_22946 = cond_22944 && cond_t_res_22945;\n            if (x_2", "2946) {\n                int64_t lifted_lambda_res_t_res_23331 = sub64(eta_p_22940, lower_bound_22365);\n                \n                lifted_lambda_res_22947 = lifted_lambda_res_t_res_23331;\n            } else {\n                lifted_lambda_res_22947 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_22947) && slt64(lifted_lambda_res_22947, j_m_i_22368)) {\n                ((__global int32_t *) mem_26767)[lifted_lambda_res_22947] = write_value_22941;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_22947) && slt64(lifted_lambda_res_22947, j_m_i_22368)) {\n                ((__global int64_t *) mem_26769)[lifted_lambda_res_22947] = write_value_22942;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_22947) && slt64(lifted_lambda_res_22947, j_m_i_22368)) {\n                ((__global int64_t *) mem_26771)[lifted_lambda_res_22947] = write_value_22943;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_24630\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzisegmap_24635_dim1, 1, 1)\nvoid inner_SMJ_intzisegmap_24635(__global int *global_failure, int64_t m_22282, int64_t m_22422, int64_t num_tblocks_24640, int32_t virt_num_tblocks_27709, __global unsigned char *mem_26721, __global unsigned char *mem_26733, __global unsigned char *mem_26735, __global unsigned char *mem_26738, __global unsigned char *mem_26746, __global unsigned char *mem_26748)\n{\n    #define segmap_tblock_sizze_24638 (inner_SMJ_intzisegmap_24635zisegmap_tblock_sizze_24638)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27711;\n    int32_t tblock_sizze_27714;\n    int32_t wave_sizze_27713;\n    int32_t block_id_27712;\n    int32_t global_tid_27710;\n    int64_t phys_tid_24635;\n    int32_t phys_tblock_id_27715;\n    int32_t iterations_27716;\n    \n    local_tid_27711 = get_local_id(0);\n    tblock_sizze_27714 = get_local_size(0);\n    wave_si", "zze_27713 = LOCKSTEP_WIDTH;\n    block_id_27712 = get_tblock_id(0);\n    global_tid_27710 = block_id_27712 * tblock_sizze_27714 + local_tid_27711;\n    phys_tid_24635 = sext_i32_i64(global_tid_27710);\n    phys_tblock_id_27715 = get_tblock_id(0);\n    iterations_27716 = sdiv_up32(virt_num_tblocks_27709 - phys_tblock_id_27715, sext_i64_i32(num_tblocks_24640));\n    for (int32_t i_27717 = 0; i_27717 < iterations_27716; i_27717++) {\n        int32_t virt_tblock_id_27718;\n        int64_t global_tid_27719;\n        int64_t slice_27720;\n        int64_t write_i_24634;\n        int64_t remnant_27721;\n        \n        virt_tblock_id_27718 = phys_tblock_id_27715 + i_27717 * sext_i64_i32(num_tblocks_24640);\n        global_tid_27719 = sext_i32_i64(virt_tblock_id_27718) * segmap_tblock_sizze_24638 + sext_i32_i64(local_tid_27711);\n        slice_27720 = m_22282;\n        write_i_24634 = global_tid_27719;\n        remnant_27721 = global_tid_27719 - write_i_24634;\n        if (slt64(write_i_24634, m_22282)) {\n            int64_t eta_p_22524;\n            int64_t write_value_22526;\n            int64_t write_value_22527;\n            bool cond_22528;\n            int64_t lifted_lambda_res_22529;\n            \n            eta_p_22524 = ((__global int64_t *) mem_26735)[write_i_24634];\n            write_value_22526 = ((__global int64_t *) mem_26738)[write_i_24634];\n            write_value_22527 = ((__global int64_t *) mem_26721)[write_i_24634];\n            cond_22528 = eta_p_22524 == (int64_t) 1;\n            if (cond_22528) {\n                int64_t eta_p_22525;\n                int64_t lifted_lambda_res_t_res_23336;\n                \n                eta_p_22525 = ((__global int64_t *) mem_26733)[write_i_24634];\n                lifted_lambda_res_t_res_23336 = sub64(eta_p_22525, (int64_t) 1);\n                lifted_lambda_res_22529 = lifted_lambda_res_t_res_23336;\n            } else {\n                lifted_lambda_res_22529 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_",
                                    "22529) && slt64(lifted_lambda_res_22529, m_22422)) {\n                ((__global int64_t *) mem_26748)[lifted_lambda_res_22529] = write_value_22526;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_22529) && slt64(lifted_lambda_res_22529, m_22422)) {\n                ((__global int64_t *) mem_26746)[lifted_lambda_res_22529] = write_value_22527;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_24638\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzisegmap_24657_dim1, 1, 1)\nvoid inner_SMJ_intzisegmap_24657(__global int *global_failure, int64_t loopres_22466, int64_t loopres_22467, __global unsigned char *mem_26796, __global unsigned char *mem_26799)\n{\n    #define segmap_tblock_sizze_24653 (inner_SMJ_intzisegmap_24657zisegmap_tblock_sizze_24653)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27796;\n    int32_t tblock_sizze_27799;\n    int32_t wave_sizze_27798;\n    int32_t block_id_27797;\n    int32_t global_tid_27795;\n    int64_t phys_tid_24657;\n    int64_t global_tid_27800;\n    int64_t slice_27801;\n    int64_t gtid_24656;\n    int64_t remnant_27802;\n    \n    local_tid_27796 = get_local_id(0);\n    tblock_sizze_27799 = get_local_size(0);\n    wave_sizze_27798 = LOCKSTEP_WIDTH;\n    block_id_27797 = get_tblock_id(0);\n    global_tid_27795 = block_id_27797 * tblock_sizze_27799 + local_tid_27796;\n    phys_tid_24657 = sext_i32_i64(global_tid_27795);\n    global_tid_27800 = sext_i32_i64(block_id_27797) * segmap_tblock_sizze_24653 + sext_i32_i64(local_tid_27796);\n    slice_27801 = loopres_22467;\n    gtid_24656 = global_tid_27800;\n    remnant_27802 = global_tid_27800 - gtid_24656;\n    if (slt64(gtid_24656, loopres_22467)) {\n        int64_t loopres_26238;\n        int64_t tmp_24659;\n        \n        loopres_26238 = ((__global int64_t *) mem_26799)[(int64_t) 0];\n        tmp_24659 = add64(gtid_24656, loopres_26238);\n        ((__global int64_t *) mem_26796)[lo", "opres_22466 + gtid_24656] = tmp_24659;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_24653\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzisegmap_intrablock_24675_dim1, 1, 1)\nvoid inner_SMJ_intzisegmap_intrablock_24675(__global int *global_failure, int64_t tS_start_21436, int64_t dzlz7bUZLzmZRz20UtS_endz20UtS_startz7dUzg_21439, int64_t start_22996, int64_t min_res_22998, int64_t ldim_24678, int64_t num_whole_tiles_24693, int64_t residual_input_24917, unsigned char cond_24918_bits, int64_t binop_x_24934, __global unsigned char *tR_mem_26243, __global unsigned char *tS_mem_26244, __global unsigned char *ext_mem_26543, __global unsigned char *mem_26663, __global unsigned char *mem_26665)\n{\n    bool cond_24918 = cond_24918_bits;\n    \n    #define tile_sizze_24677 (inner_SMJ_intzisegmap_intrablock_24675zitile_sizze_24677)\n    #define bytes_26625 (inner_SMJ_intzisegmap_intrablock_24675zibytes_26625)\n    #define bytes_26627 (inner_SMJ_intzisegmap_intrablock_24675zibytes_26627)\n    \n    volatile __local unsigned char *color_27004_backing_2 = &shared_mem[0];\n    const int64_t color_27004_backing_2_offset = 0 + (bytes_26625 + srem64((int64_t) 8 - srem64(bytes_26625, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_27003_backing_1 = &shared_mem[color_27004_backing_2_offset];\n    const int64_t color_27003_backing_1_offset = color_27004_backing_2_offset + (bytes_26627 + srem64((int64_t) 8 - srem64(bytes_26627, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_27002_backing_0 = &shared_mem[color_27003_backing_1_offset];\n    const int64_t color_27002_backing_0_offset = color_27003_backing_1_offset + (bytes_26625 + srem64((int64_t) 8 - srem64(bytes_26625, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27113;\n    int32_t tblock_sizze_27116;\n    int32_t wave_sizze_27115;\n    int32_t block_id_27114;\n    int32_t global_tid_27112;\n    int64_t gid_flat_24675;\n    int64_t slice_2", "7118;\n    int64_t ltid_pre_27117;\n    int64_t remnant_27119;\n    int64_t slice_27120;\n    int64_t gid_24674;\n    int64_t remnant_27121;\n    __local unsigned char *color_27002;\n    __local unsigned char *color_27003;\n    __local unsigned char *color_27004;\n    int64_t binop_x_24685;\n    int32_t mem_26609[1];\n    int64_t ltid_flat_24680;\n    int64_t ltid_24679;\n    int64_t gtid_24686;\n    bool cond_24687;\n    int32_t pre_24688;\n    int64_t mem_26613[1];\n    int32_t mem_26617[1];\n    int64_t mem_26621[1];\n    int64_t ltid_flat_24695;\n    int64_t ltid_24694;\n    int64_t gtid_24705;\n    bool cond_24706;\n    int64_t neutral_24707;\n    int32_t neutral_24708;\n    int64_t ext_mem_26645[1];\n    int32_t ext_mem_26644[1];\n    int64_t ext_mem_26643[1];\n    int64_t mem_param_26622[1];\n    int32_t mem_param_26623[1];\n    int64_t mem_param_26624[1];\n    int64_t mem_26655[1];\n    int64_t mem_26659[1];\n    int64_t ext_mem_26661[1];\n    int64_t ext_mem_26660[1];\n    \n    local_tid_27113 = get_local_id(0);\n    tblock_sizze_27116 = get_local_size(0);\n    wave_sizze_27115 = LOCKSTEP_WIDTH;\n    block_id_27114 = get_tblock_id(0);\n    global_tid_27112 = block_id_27114 * tblock_sizze_27116 + local_tid_27113;\n    gid_flat_24675 = sext_i32_i64(block_id_27114);\n    slice_27118 = tile_sizze_24677;\n    ltid_pre_27117 = sext_i32_i64(local_tid_27113);\n    remnant_27119 = sext_i32_i64(local_tid_27113) - ltid_pre_27117;\n    slice_27120 = ldim_24678;\n    gid_24674 = sext_i32_i64(block_id_27114);\n    remnant_27121 = sext_i32_i64(block_id_27114) - gid_24674;\n    color_27002 = (__local unsigned char *) color_27002_backing_0;\n    color_27003 = (__local unsigned char *) color_27003_backing_1;\n    color_27004 = (__local unsigned char *) color_27004_backing_2;\n    binop_x_24685 = gid_24674 * tile_sizze_24677;\n    ltid_flat_24680 = sext_i32_i64(local_tid_27113);\n    ltid_24679 = sext_i32_i64(sext_i64_i32(ltid_pre_27117));\n    gtid_24686 = ltid_24679 + binop_x_24685;\n    cond_24687 = slt64(gtid_24686, min_res_",
                                    "22998);\n    if (cond_24687) {\n        int64_t slice_24689;\n        int32_t eta_p_24690;\n        \n        slice_24689 = start_22996 + gtid_24686;\n        eta_p_24690 = ((__global int32_t *) tR_mem_26243)[slice_24689];\n        pre_24688 = eta_p_24690;\n    } else {\n        pre_24688 = 0;\n    }\n    mem_26609[(int64_t) 0] = pre_24688;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    ltid_flat_24695 = sext_i32_i64(local_tid_27113);\n    ltid_24694 = sext_i32_i64(sext_i64_i32(ltid_pre_27117));\n    gtid_24705 = binop_x_24685 + ltid_24694;\n    cond_24706 = slt64(gtid_24705, min_res_22998);\n    if (cond_24706) {\n        neutral_24707 = (int64_t) -1;\n    } else {\n        neutral_24707 = (int64_t) 0;\n    }\n    if (cond_24706) {\n        int32_t eta_p_24710 = mem_26609[(int64_t) 0];\n        \n        neutral_24708 = eta_p_24710;\n    } else {\n        neutral_24708 = 0;\n    }\n    mem_26613[(int64_t) 0] = neutral_24707;\n    mem_26617[(int64_t) 0] = neutral_24708;\n    mem_26621[(int64_t) 0] = (int64_t) 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    for (int32_t i_3 = 0; i_3 < 1; i_3++)\n        mem_param_26622[i_3] = mem_26613[i_3];\n    for (int32_t i_4 = 0; i_4 < 1; i_4++)\n        mem_param_26623[i_4] = mem_26617[i_4];\n    for (int32_t i_5 = 0; i_5 < 1; i_5++)\n        mem_param_26624[i_5] = mem_26621[i_5];\n    for (int64_t tile_id_24720 = 0; tile_id_24720 < num_whole_tiles_24693; tile_id_24720++) {\n        int64_t binop_x_24819;\n        int64_t ltid_flat_24818;\n        int64_t ltid_24817;\n        int64_t j_24820;\n        bool cond_24824;\n        int64_t pre1d_24827;\n        int64_t pre1d_24825;\n        int32_t pre1d_24826;\n        int64_t mem_26634[1];\n        int32_t mem_26638[1];\n        int64_t mem_26642[1];\n        int64_t ltid_flat_24838;\n        int64_t ltid_24837;\n        int64_t gtid_24840;\n        int64_t acc_24842;\n        int32_t acc_24843;\n        int64_t acc_24844;\n        bool cond_24845;\n        int64_t acc_24846;\n        int32_t acc_24847;\n        int64", "_t acc_24848;\n        int64_t mem_param_tmp_27122[1];\n        int32_t mem_param_tmp_27123[1];\n        int64_t mem_param_tmp_27124[1];\n        \n        binop_x_24819 = tile_sizze_24677 * tile_id_24720;\n        ltid_flat_24818 = sext_i32_i64(local_tid_27113);\n        ltid_24817 = sext_i32_i64(sext_i64_i32(ltid_pre_27117));\n        j_24820 = ltid_24817 + binop_x_24819;\n        cond_24824 = slt64(j_24820, dzlz7bUZLzmZRz20UtS_endz20UtS_startz7dUzg_21439);\n        pre1d_24827 = btoi_bool_i64(cond_24824);\n        if (cond_24824) {\n            int64_t tile_elem_24828;\n            int64_t slice_26097;\n            int32_t tile_elem_24829;\n            \n            tile_elem_24828 = ((__global int64_t *) ext_mem_26543)[j_24820];\n            slice_26097 = tS_start_21436 + j_24820;\n            tile_elem_24829 = ((__global int32_t *) tS_mem_26244)[slice_26097];\n            pre1d_24825 = tile_elem_24828;\n            pre1d_24826 = tile_elem_24829;\n        } else {\n            pre1d_24825 = (int64_t) 0;\n            pre1d_24826 = 0;\n        }\n        ((__local int64_t *) color_27004)[ltid_24817] = pre1d_24825;\n        ((__local int32_t *) color_27003)[ltid_24817] = pre1d_24826;\n        ((__local int64_t *) color_27002)[ltid_24817] = pre1d_24827;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_24838 = sext_i32_i64(local_tid_27113);\n        ltid_24837 = sext_i32_i64(sext_i64_i32(ltid_pre_27117));\n        gtid_24840 = binop_x_24685 + ltid_24837;\n        acc_24842 = mem_param_26622[(int64_t) 0];\n        acc_24843 = mem_param_26623[(int64_t) 0];\n        acc_24844 = mem_param_26624[(int64_t) 0];\n        cond_24845 = slt64(gtid_24840, min_res_22998);\n        if (cond_24845) {\n            int32_t eta_p_24841;\n            int64_t x_24849;\n            int32_t x_24850;\n            int64_t x_24851;\n            int64_t redout_26110;\n            int32_t redout_26111;\n            int64_t redout_26112;\n            \n            eta_p_24841 = mem_26609[(int64_t) 0];\n            redout_26110 = a", "cc_24842;\n            redout_26111 = acc_24843;\n            redout_26112 = acc_24844;\n            for (int64_t i_26113 = 0; i_26113 < tile_sizze_24677; i_26113++) {\n                int64_t x_24852;\n                int32_t x_24853;\n                bool defunc_0_neq_res_24861;\n                bool defunc_0_neq_res_24862;\n                bool cond_f_res_24863;\n                bool y_24864;\n                bool cond_24865;\n                bool defunc_0_neq_res_24866;\n                bool defunc_0_neq_res_24867;\n                bool cond_t_res_f_res_24868;\n                bool y_24869;\n                bool cond_t_res_24870;\n                bool x_24871;\n                int64_t defunc_0_op_res_24872;\n                int32_t defunc_0_op_res_24873;\n                int64_t defunc_0_op_res_24874;\n                int64_t redout_tmp_27128;\n                int32_t redout_tmp_27129;\n                int64_t redout_tmp_27130;\n                \n                x_24852 = ((__local int64_t *) color_27004)[i_26113];\n                x_24853 = ((__local int32_t *) color_27003)[i_26113];\n                defunc_0_neq_res_24861 = redout_26111 == eta_p_24841;\n                defunc_0_neq_res_24862 = !defunc_0_neq_res_24861;\n                cond_f_res_24863 = slt64(redout_26110, (int64_t) 0);\n                y_24864 = defunc_0_neq_res_24861 && cond_f_res_24863;\n                cond_24865 = defunc_0_neq_res_24862 || y_24864;\n                defunc_0_neq_res_24866 = x_24853 == eta_p_24841;\n                defunc_0_neq_res_24867 = !defunc_0_neq_res_24866;\n                cond_t_res_f_res_24868 = slt64(x_24852, (int64_t) 0);\n                y_24869 = defunc_0_neq_res_24866 && cond_t_res_f_res_24868;\n                cond_t_res_24870 = defunc_0_neq_res_24867 || y_24869;\n                x_24871 = cond_24865 && cond_t_res_24870;\n                if (x_24871) {\n                    defunc_0_op_res_24872 = (int64_t) -1;\n                    defunc_0_op_res_24873 = eta_p_24841;\n                    defunc_0_",
                                    "op_res_24874 = (int64_t) 0;\n                } else {\n                    int64_t x_24854;\n                    int64_t defunc_0_op_res_f_res_24875;\n                    int32_t defunc_0_op_res_f_res_24876;\n                    int64_t defunc_0_op_res_f_res_24877;\n                    \n                    x_24854 = ((__local int64_t *) color_27002)[i_26113];\n                    if (cond_24865) {\n                        defunc_0_op_res_f_res_24875 = x_24852;\n                        defunc_0_op_res_f_res_24876 = x_24853;\n                        defunc_0_op_res_f_res_24877 = x_24854;\n                    } else {\n                        int32_t defunc_0_op_res_f_res_f_res_24878;\n                        int64_t defunc_0_op_res_f_res_f_res_24879;\n                        int64_t defunc_0_op_res_f_res_f_res_24880;\n                        \n                        if (cond_t_res_24870) {\n                            defunc_0_op_res_f_res_f_res_24878 = redout_26111;\n                        } else {\n                            defunc_0_op_res_f_res_f_res_24878 = eta_p_24841;\n                        }\n                        if (cond_t_res_24870) {\n                            defunc_0_op_res_f_res_f_res_24879 = redout_26110;\n                            defunc_0_op_res_f_res_f_res_24880 = redout_26112;\n                        } else {\n                            int64_t min_res_24881;\n                            int64_t tmp_24882;\n                            \n                            min_res_24881 = smin64(x_24852, redout_26110);\n                            tmp_24882 = add64(x_24854, redout_26112);\n                            defunc_0_op_res_f_res_f_res_24879 = min_res_24881;\n                            defunc_0_op_res_f_res_f_res_24880 = tmp_24882;\n                        }\n                        defunc_0_op_res_f_res_24875 = defunc_0_op_res_f_res_f_res_24879;\n                        defunc_0_op_res_f_res_24876 = defunc_0_op_res_f_res_f_res_24878;\n                        defunc_0_", "op_res_f_res_24877 = defunc_0_op_res_f_res_f_res_24880;\n                    }\n                    defunc_0_op_res_24872 = defunc_0_op_res_f_res_24875;\n                    defunc_0_op_res_24873 = defunc_0_op_res_f_res_24876;\n                    defunc_0_op_res_24874 = defunc_0_op_res_f_res_24877;\n                }\n                redout_tmp_27128 = defunc_0_op_res_24872;\n                redout_tmp_27129 = defunc_0_op_res_24873;\n                redout_tmp_27130 = defunc_0_op_res_24874;\n                redout_26110 = redout_tmp_27128;\n                redout_26111 = redout_tmp_27129;\n                redout_26112 = redout_tmp_27130;\n            }\n            x_24849 = redout_26110;\n            x_24850 = redout_26111;\n            x_24851 = redout_26112;\n            acc_24846 = x_24849;\n            acc_24847 = x_24850;\n            acc_24848 = x_24851;\n        } else {\n            acc_24846 = acc_24842;\n            acc_24847 = acc_24843;\n            acc_24848 = acc_24844;\n        }\n        mem_26634[(int64_t) 0] = acc_24846;\n        mem_26638[(int64_t) 0] = acc_24847;\n        mem_26642[(int64_t) 0] = acc_24848;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_6 = 0; i_6 < 1; i_6++)\n            mem_param_tmp_27122[i_6] = mem_26634[i_6];\n        for (int32_t i_7 = 0; i_7 < 1; i_7++)\n            mem_param_tmp_27123[i_7] = mem_26638[i_7];\n        for (int32_t i_8 = 0; i_8 < 1; i_8++)\n            mem_param_tmp_27124[i_8] = mem_26642[i_8];\n        for (int32_t i_9 = 0; i_9 < 1; i_9++)\n            mem_param_26622[i_9] = mem_param_tmp_27122[i_9];\n        for (int32_t i_10 = 0; i_10 < 1; i_10++)\n            mem_param_26623[i_10] = mem_param_tmp_27123[i_10];\n        for (int32_t i_11 = 0; i_11 < 1; i_11++)\n            mem_param_26624[i_11] = mem_param_tmp_27124[i_11];\n    }\n    for (int32_t i_12 = 0; i_12 < 1; i_12++)\n        ext_mem_26645[i_12] = mem_param_26622[i_12];\n    for (int32_t i_13 = 0; i_13 < 1; i_13++)\n        ext_mem_26644[i_13] = mem_param_26623[i_13];\n    f", "or (int32_t i_14 = 0; i_14 < 1; i_14++)\n        ext_mem_26643[i_14] = mem_param_26624[i_14];\n    barrier(CLK_LOCAL_MEM_FENCE);\n    if (cond_24918) {\n        for (int32_t i_15 = 0; i_15 < 1; i_15++)\n            ext_mem_26661[i_15] = ext_mem_26645[i_15];\n        for (int32_t i_16 = 0; i_16 < 1; i_16++)\n            ext_mem_26660[i_16] = ext_mem_26643[i_16];\n    } else {\n        int64_t ltid_flat_24920;\n        int64_t ltid_24919;\n        int64_t j_24935;\n        bool cond_24939;\n        int64_t pre1d_24942;\n        int64_t pre1d_24940;\n        int32_t pre1d_24941;\n        int64_t ltid_flat_24956;\n        int64_t ltid_24955;\n        int64_t gtid_24969;\n        int64_t acc_24971;\n        int64_t acc_24973;\n        bool cond_24974;\n        int64_t acc_24975;\n        int64_t acc_24977;\n        \n        ltid_flat_24920 = sext_i32_i64(local_tid_27113);\n        ltid_24919 = sext_i32_i64(sext_i64_i32(ltid_pre_27117));\n        j_24935 = ltid_24919 + binop_x_24934;\n        cond_24939 = slt64(j_24935, dzlz7bUZLzmZRz20UtS_endz20UtS_startz7dUzg_21439);\n        pre1d_24942 = btoi_bool_i64(cond_24939);\n        if (cond_24939) {\n            int64_t tile_elem_24943;\n            int64_t slice_26096;\n            int32_t tile_elem_24944;\n            \n            tile_elem_24943 = ((__global int64_t *) ext_mem_26543)[j_24935];\n            slice_26096 = tS_start_21436 + j_24935;\n            tile_elem_24944 = ((__global int32_t *) tS_mem_26244)[slice_26096];\n            pre1d_24940 = tile_elem_24943;\n            pre1d_24941 = tile_elem_24944;\n        } else {\n            pre1d_24940 = (int64_t) 0;\n            pre1d_24941 = 0;\n        }\n        ((__local int64_t *) color_27004)[ltid_24919] = pre1d_24940;\n        ((__local int32_t *) color_27003)[ltid_24919] = pre1d_24941;\n        ((__local int64_t *) color_27002)[ltid_24919] = pre1d_24942;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_24956 = sext_i32_i64(local_tid_27113);\n        ltid_24955 = sext_i32_i64(sext_i64_i32(ltid_pre_2711",
                                    "7));\n        gtid_24969 = binop_x_24685 + ltid_24955;\n        acc_24971 = ext_mem_26645[(int64_t) 0];\n        acc_24973 = ext_mem_26643[(int64_t) 0];\n        cond_24974 = slt64(gtid_24969, min_res_22998);\n        if (cond_24974) {\n            int32_t eta_p_24970;\n            int32_t acc_24972;\n            int64_t x_24978;\n            int32_t x_24979;\n            int64_t x_24980;\n            int64_t redout_26114;\n            int32_t redout_26115;\n            int64_t redout_26116;\n            \n            eta_p_24970 = mem_26609[(int64_t) 0];\n            acc_24972 = ext_mem_26644[(int64_t) 0];\n            redout_26114 = acc_24971;\n            redout_26115 = acc_24972;\n            redout_26116 = acc_24973;\n            for (int64_t i_26117 = 0; i_26117 < residual_input_24917; i_26117++) {\n                int64_t x_24981;\n                int32_t x_24982;\n                bool defunc_0_neq_res_24990;\n                bool defunc_0_neq_res_24991;\n                bool cond_f_res_24992;\n                bool y_24993;\n                bool cond_24994;\n                bool defunc_0_neq_res_24995;\n                bool defunc_0_neq_res_24996;\n                bool cond_t_res_f_res_24997;\n                bool y_24998;\n                bool cond_t_res_24999;\n                bool x_25000;\n                int64_t defunc_0_op_res_25001;\n                int32_t defunc_0_op_res_25002;\n                int64_t defunc_0_op_res_25003;\n                int64_t redout_tmp_27131;\n                int32_t redout_tmp_27132;\n                int64_t redout_tmp_27133;\n                \n                x_24981 = ((__local int64_t *) color_27004)[i_26117];\n                x_24982 = ((__local int32_t *) color_27003)[i_26117];\n                defunc_0_neq_res_24990 = redout_26115 == eta_p_24970;\n                defunc_0_neq_res_24991 = !defunc_0_neq_res_24990;\n                cond_f_res_24992 = slt64(redout_26114, (int64_t) 0);\n                y_24993 = defunc_0_neq_res_24990 && cond_f_res_24992;\n             ", "   cond_24994 = defunc_0_neq_res_24991 || y_24993;\n                defunc_0_neq_res_24995 = x_24982 == eta_p_24970;\n                defunc_0_neq_res_24996 = !defunc_0_neq_res_24995;\n                cond_t_res_f_res_24997 = slt64(x_24981, (int64_t) 0);\n                y_24998 = defunc_0_neq_res_24995 && cond_t_res_f_res_24997;\n                cond_t_res_24999 = defunc_0_neq_res_24996 || y_24998;\n                x_25000 = cond_24994 && cond_t_res_24999;\n                if (x_25000) {\n                    defunc_0_op_res_25001 = (int64_t) -1;\n                    defunc_0_op_res_25002 = eta_p_24970;\n                    defunc_0_op_res_25003 = (int64_t) 0;\n                } else {\n                    int64_t x_24983;\n                    int64_t defunc_0_op_res_f_res_25004;\n                    int32_t defunc_0_op_res_f_res_25005;\n                    int64_t defunc_0_op_res_f_res_25006;\n                    \n                    x_24983 = ((__local int64_t *) color_27002)[i_26117];\n                    if (cond_24994) {\n                        defunc_0_op_res_f_res_25004 = x_24981;\n                        defunc_0_op_res_f_res_25005 = x_24982;\n                        defunc_0_op_res_f_res_25006 = x_24983;\n                    } else {\n                        int32_t defunc_0_op_res_f_res_f_res_25007;\n                        int64_t defunc_0_op_res_f_res_f_res_25008;\n                        int64_t defunc_0_op_res_f_res_f_res_25009;\n                        \n                        if (cond_t_res_24999) {\n                            defunc_0_op_res_f_res_f_res_25007 = redout_26115;\n                        } else {\n                            defunc_0_op_res_f_res_f_res_25007 = eta_p_24970;\n                        }\n                        if (cond_t_res_24999) {\n                            defunc_0_op_res_f_res_f_res_25008 = redout_26114;\n                            defunc_0_op_res_f_res_f_res_25009 = redout_26116;\n                        } else {\n                            int6", "4_t min_res_25010;\n                            int64_t tmp_25011;\n                            \n                            min_res_25010 = smin64(x_24981, redout_26114);\n                            tmp_25011 = add64(x_24983, redout_26116);\n                            defunc_0_op_res_f_res_f_res_25008 = min_res_25010;\n                            defunc_0_op_res_f_res_f_res_25009 = tmp_25011;\n                        }\n                        defunc_0_op_res_f_res_25004 = defunc_0_op_res_f_res_f_res_25008;\n                        defunc_0_op_res_f_res_25005 = defunc_0_op_res_f_res_f_res_25007;\n                        defunc_0_op_res_f_res_25006 = defunc_0_op_res_f_res_f_res_25009;\n                    }\n                    defunc_0_op_res_25001 = defunc_0_op_res_f_res_25004;\n                    defunc_0_op_res_25002 = defunc_0_op_res_f_res_25005;\n                    defunc_0_op_res_25003 = defunc_0_op_res_f_res_25006;\n                }\n                redout_tmp_27131 = defunc_0_op_res_25001;\n                redout_tmp_27132 = defunc_0_op_res_25002;\n                redout_tmp_27133 = defunc_0_op_res_25003;\n                redout_26114 = redout_tmp_27131;\n                redout_26115 = redout_tmp_27132;\n                redout_26116 = redout_tmp_27133;\n            }\n            x_24978 = redout_26114;\n            x_24979 = redout_26115;\n            x_24980 = redout_26116;\n            acc_24975 = x_24978;\n            acc_24977 = x_24980;\n        } else {\n            acc_24975 = acc_24971;\n            acc_24977 = acc_24973;\n        }\n        mem_26655[(int64_t) 0] = acc_24975;\n        mem_26659[(int64_t) 0] = acc_24977;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_17 = 0; i_17 < 1; i_17++)\n            ext_mem_26661[i_17] = mem_26655[i_17];\n        for (int32_t i_18 = 0; i_18 < 1; i_18++)\n            ext_mem_26660[i_18] = mem_26659[i_18];\n    }\n    if (slt64(sext_i32_i64(local_tid_27113) + tile_sizze_24677 * sext_i32_i64(block_id_27114), min_res_22998)) {\n   ",
                                    "     int64_t tmp_27134 = ext_mem_26661[(int64_t) 0];\n        \n        ((__global int64_t *) mem_26663)[sext_i32_i64(local_tid_27113) + tile_sizze_24677 * sext_i32_i64(block_id_27114)] = tmp_27134;\n    }\n    if (slt64(sext_i32_i64(local_tid_27113) + tile_sizze_24677 * sext_i32_i64(block_id_27114), min_res_22998)) {\n        int64_t tmp_27135 = ext_mem_26660[(int64_t) 0];\n        \n        ((__global int64_t *) mem_26665)[sext_i32_i64(local_tid_27113) + tile_sizze_24677 * sext_i32_i64(block_id_27114)] = tmp_27135;\n    }\n    \n  error_8:\n    return;\n    #undef tile_sizze_24677\n    #undef bytes_26625\n    #undef bytes_26627\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzisegmap_intrablock_25030_dim1, 1, 1)\nvoid inner_SMJ_intzisegmap_intrablock_25030(__global int *global_failure, int64_t tS_start_21436, int64_t dzlz7bUZLzmZRz20UtS_endz20UtS_startz7dUzg_21439, int64_t start_22996, int64_t min_res_22998, int64_t ldim_25033, int64_t num_whole_tiles_25048, int64_t residual_input_25272, unsigned char cond_25273_bits, int64_t binop_x_25289, __global unsigned char *tR_mem_26243, __global unsigned char *tS_mem_26244, __global unsigned char *ext_mem_26543, __global unsigned char *mem_26602, __global unsigned char *mem_26604)\n{\n    bool cond_25273 = cond_25273_bits;\n    \n    #define tile_sizze_25032 (inner_SMJ_intzisegmap_intrablock_25030zitile_sizze_25032)\n    #define bytes_26564 (inner_SMJ_intzisegmap_intrablock_25030zibytes_26564)\n    #define bytes_26566 (inner_SMJ_intzisegmap_intrablock_25030zibytes_26566)\n    \n    volatile __local unsigned char *color_27007_backing_2 = &shared_mem[0];\n    const int64_t color_27007_backing_2_offset = 0 + (bytes_26564 + srem64((int64_t) 8 - srem64(bytes_26564, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_27006_backing_1 = &shared_mem[color_27007_backing_2_offset];\n    const int64_t color_27006_backing_1_offset = color_27007_backing_2_offset + (bytes_26566 + srem64((int64_t) 8 - srem64(bytes_26566, (int64_t) 8), (int64_t) 8));\n    vo", "latile __local unsigned char *color_27005_backing_0 = &shared_mem[color_27006_backing_1_offset];\n    const int64_t color_27005_backing_0_offset = color_27006_backing_1_offset + (bytes_26564 + srem64((int64_t) 8 - srem64(bytes_26564, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27139;\n    int32_t tblock_sizze_27142;\n    int32_t wave_sizze_27141;\n    int32_t block_id_27140;\n    int32_t global_tid_27138;\n    int64_t gid_flat_25030;\n    int64_t slice_27144;\n    int64_t ltid_pre_27143;\n    int64_t remnant_27145;\n    int64_t slice_27146;\n    int64_t gid_25029;\n    int64_t remnant_27147;\n    __local unsigned char *color_27005;\n    __local unsigned char *color_27006;\n    __local unsigned char *color_27007;\n    int64_t binop_x_25040;\n    int32_t mem_26548[1];\n    int64_t ltid_flat_25035;\n    int64_t ltid_25034;\n    int64_t gtid_25041;\n    bool cond_25042;\n    int32_t pre_25043;\n    int64_t mem_26552[1];\n    int32_t mem_26556[1];\n    int64_t mem_26560[1];\n    int64_t ltid_flat_25050;\n    int64_t ltid_25049;\n    int64_t gtid_25060;\n    bool cond_25061;\n    int64_t neutral_25062;\n    int32_t neutral_25063;\n    int64_t ext_mem_26584[1];\n    int32_t ext_mem_26583[1];\n    int64_t ext_mem_26582[1];\n    int64_t mem_param_26561[1];\n    int32_t mem_param_26562[1];\n    int64_t mem_param_26563[1];\n    int64_t mem_26594[1];\n    int64_t mem_26598[1];\n    int64_t ext_mem_26600[1];\n    int64_t ext_mem_26599[1];\n    \n    local_tid_27139 = get_local_id(0);\n    tblock_sizze_27142 = get_local_size(0);\n    wave_sizze_27141 = LOCKSTEP_WIDTH;\n    block_id_27140 = get_tblock_id(0);\n    global_tid_27138 = block_id_27140 * tblock_sizze_27142 + local_tid_27139;\n    gid_flat_25030 = sext_i32_i64(block_id_27140);\n    slice_27144 = tile_sizze_25032;\n    ltid_pre_27143 = sext_i32_i64(local_tid_27139);\n    remnant_27145 = sext_i32_i64(local_tid_27139) - ltid_pre_27143;\n    slice_27146 = ldim_25033;\n    gid_25029 = sext_i32_i64(block_id_27140);\n ", "   remnant_27147 = sext_i32_i64(block_id_27140) - gid_25029;\n    color_27005 = (__local unsigned char *) color_27005_backing_0;\n    color_27006 = (__local unsigned char *) color_27006_backing_1;\n    color_27007 = (__local unsigned char *) color_27007_backing_2;\n    binop_x_25040 = gid_25029 * tile_sizze_25032;\n    ltid_flat_25035 = sext_i32_i64(local_tid_27139);\n    ltid_25034 = sext_i32_i64(sext_i64_i32(ltid_pre_27143));\n    gtid_25041 = ltid_25034 + binop_x_25040;\n    cond_25042 = slt64(gtid_25041, min_res_22998);\n    if (cond_25042) {\n        int64_t slice_25044;\n        int32_t eta_p_25045;\n        \n        slice_25044 = start_22996 + gtid_25041;\n        eta_p_25045 = ((__global int32_t *) tR_mem_26243)[slice_25044];\n        pre_25043 = eta_p_25045;\n    } else {\n        pre_25043 = 0;\n    }\n    mem_26548[(int64_t) 0] = pre_25043;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    ltid_flat_25050 = sext_i32_i64(local_tid_27139);\n    ltid_25049 = sext_i32_i64(sext_i64_i32(ltid_pre_27143));\n    gtid_25060 = binop_x_25040 + ltid_25049;\n    cond_25061 = slt64(gtid_25060, min_res_22998);\n    if (cond_25061) {\n        neutral_25062 = (int64_t) -1;\n    } else {\n        neutral_25062 = (int64_t) 0;\n    }\n    if (cond_25061) {\n        int32_t eta_p_25065 = mem_26548[(int64_t) 0];\n        \n        neutral_25063 = eta_p_25065;\n    } else {\n        neutral_25063 = 0;\n    }\n    mem_26552[(int64_t) 0] = neutral_25062;\n    mem_26556[(int64_t) 0] = neutral_25063;\n    mem_26560[(int64_t) 0] = (int64_t) 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    for (int32_t i_3 = 0; i_3 < 1; i_3++)\n        mem_param_26561[i_3] = mem_26552[i_3];\n    for (int32_t i_4 = 0; i_4 < 1; i_4++)\n        mem_param_26562[i_4] = mem_26556[i_4];\n    for (int32_t i_5 = 0; i_5 < 1; i_5++)\n        mem_param_26563[i_5] = mem_26560[i_5];\n    for (int64_t tile_id_25075 = 0; tile_id_25075 < num_whole_tiles_25048; tile_id_25075++) {\n        int64_t binop_x_25174;\n        int64_t ltid_flat_25173;\n   ",
                                    "     int64_t ltid_25172;\n        int64_t j_25175;\n        bool cond_25179;\n        int64_t pre1d_25182;\n        int64_t pre1d_25180;\n        int32_t pre1d_25181;\n        int64_t mem_26573[1];\n        int32_t mem_26577[1];\n        int64_t mem_26581[1];\n        int64_t ltid_flat_25193;\n        int64_t ltid_25192;\n        int64_t gtid_25195;\n        int64_t acc_25197;\n        int32_t acc_25198;\n        int64_t acc_25199;\n        bool cond_25200;\n        int64_t acc_25201;\n        int32_t acc_25202;\n        int64_t acc_25203;\n        int64_t mem_param_tmp_27148[1];\n        int32_t mem_param_tmp_27149[1];\n        int64_t mem_param_tmp_27150[1];\n        \n        binop_x_25174 = tile_sizze_25032 * tile_id_25075;\n        ltid_flat_25173 = sext_i32_i64(local_tid_27139);\n        ltid_25172 = sext_i32_i64(sext_i64_i32(ltid_pre_27143));\n        j_25175 = ltid_25172 + binop_x_25174;\n        cond_25179 = slt64(j_25175, dzlz7bUZLzmZRz20UtS_endz20UtS_startz7dUzg_21439);\n        pre1d_25182 = btoi_bool_i64(cond_25179);\n        if (cond_25179) {\n            int64_t tile_elem_25183;\n            int64_t slice_26101;\n            int32_t tile_elem_25184;\n            \n            tile_elem_25183 = ((__global int64_t *) ext_mem_26543)[j_25175];\n            slice_26101 = tS_start_21436 + j_25175;\n            tile_elem_25184 = ((__global int32_t *) tS_mem_26244)[slice_26101];\n            pre1d_25180 = tile_elem_25183;\n            pre1d_25181 = tile_elem_25184;\n        } else {\n            pre1d_25180 = (int64_t) 0;\n            pre1d_25181 = 0;\n        }\n        ((__local int64_t *) color_27007)[ltid_25172] = pre1d_25180;\n        ((__local int32_t *) color_27006)[ltid_25172] = pre1d_25181;\n        ((__local int64_t *) color_27005)[ltid_25172] = pre1d_25182;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_25193 = sext_i32_i64(local_tid_27139);\n        ltid_25192 = sext_i32_i64(sext_i64_i32(ltid_pre_27143));\n        gtid_25195 = binop_x_25040 + ltid_25192;\n        acc_25197 = mem_param_", "26561[(int64_t) 0];\n        acc_25198 = mem_param_26562[(int64_t) 0];\n        acc_25199 = mem_param_26563[(int64_t) 0];\n        cond_25200 = slt64(gtid_25195, min_res_22998);\n        if (cond_25200) {\n            int32_t eta_p_25196;\n            int64_t x_25204;\n            int32_t x_25205;\n            int64_t x_25206;\n            int64_t redout_26118;\n            int32_t redout_26119;\n            int64_t redout_26120;\n            \n            eta_p_25196 = mem_26548[(int64_t) 0];\n            redout_26118 = acc_25197;\n            redout_26119 = acc_25198;\n            redout_26120 = acc_25199;\n            for (int64_t i_26121 = 0; i_26121 < tile_sizze_25032; i_26121++) {\n                int64_t x_25207;\n                int32_t x_25208;\n                bool defunc_0_neq_res_25216;\n                bool defunc_0_neq_res_25217;\n                bool cond_f_res_25218;\n                bool y_25219;\n                bool cond_25220;\n                bool defunc_0_neq_res_25221;\n                bool defunc_0_neq_res_25222;\n                bool cond_t_res_f_res_25223;\n                bool y_25224;\n                bool cond_t_res_25225;\n                bool x_25226;\n                int64_t defunc_0_op_res_25227;\n                int32_t defunc_0_op_res_25228;\n                int64_t defunc_0_op_res_25229;\n                int64_t redout_tmp_27154;\n                int32_t redout_tmp_27155;\n                int64_t redout_tmp_27156;\n                \n                x_25207 = ((__local int64_t *) color_27007)[i_26121];\n                x_25208 = ((__local int32_t *) color_27006)[i_26121];\n                defunc_0_neq_res_25216 = redout_26119 == eta_p_25196;\n                defunc_0_neq_res_25217 = !defunc_0_neq_res_25216;\n                cond_f_res_25218 = slt64(redout_26118, (int64_t) 0);\n                y_25219 = defunc_0_neq_res_25216 && cond_f_res_25218;\n                cond_25220 = defunc_0_neq_res_25217 || y_25219;\n                defunc_0_neq_res_25221 = x_25208 == eta_p_25196;\n ", "               defunc_0_neq_res_25222 = !defunc_0_neq_res_25221;\n                cond_t_res_f_res_25223 = slt64(x_25207, (int64_t) 0);\n                y_25224 = defunc_0_neq_res_25221 && cond_t_res_f_res_25223;\n                cond_t_res_25225 = defunc_0_neq_res_25222 || y_25224;\n                x_25226 = cond_25220 && cond_t_res_25225;\n                if (x_25226) {\n                    defunc_0_op_res_25227 = (int64_t) -1;\n                    defunc_0_op_res_25228 = eta_p_25196;\n                    defunc_0_op_res_25229 = (int64_t) 0;\n                } else {\n                    int64_t x_25209;\n                    int64_t defunc_0_op_res_f_res_25230;\n                    int32_t defunc_0_op_res_f_res_25231;\n                    int64_t defunc_0_op_res_f_res_25232;\n                    \n                    x_25209 = ((__local int64_t *) color_27005)[i_26121];\n                    if (cond_25220) {\n                        defunc_0_op_res_f_res_25230 = x_25207;\n                        defunc_0_op_res_f_res_25231 = x_25208;\n                        defunc_0_op_res_f_res_25232 = x_25209;\n                    } else {\n                        int32_t defunc_0_op_res_f_res_f_res_25233;\n                        int64_t defunc_0_op_res_f_res_f_res_25234;\n                        int64_t defunc_0_op_res_f_res_f_res_25235;\n                        \n                        if (cond_t_res_25225) {\n                            defunc_0_op_res_f_res_f_res_25233 = redout_26119;\n                        } else {\n                            defunc_0_op_res_f_res_f_res_25233 = eta_p_25196;\n                        }\n                        if (cond_t_res_25225) {\n                            defunc_0_op_res_f_res_f_res_25234 = redout_26118;\n                            defunc_0_op_res_f_res_f_res_25235 = redout_26120;\n                        } else {\n                            int64_t min_res_25236;\n                            int64_t tmp_25237;\n                            \n                      ",
                                    "      min_res_25236 = smin64(x_25207, redout_26118);\n                            tmp_25237 = add64(x_25209, redout_26120);\n                            defunc_0_op_res_f_res_f_res_25234 = min_res_25236;\n                            defunc_0_op_res_f_res_f_res_25235 = tmp_25237;\n                        }\n                        defunc_0_op_res_f_res_25230 = defunc_0_op_res_f_res_f_res_25234;\n                        defunc_0_op_res_f_res_25231 = defunc_0_op_res_f_res_f_res_25233;\n                        defunc_0_op_res_f_res_25232 = defunc_0_op_res_f_res_f_res_25235;\n                    }\n                    defunc_0_op_res_25227 = defunc_0_op_res_f_res_25230;\n                    defunc_0_op_res_25228 = defunc_0_op_res_f_res_25231;\n                    defunc_0_op_res_25229 = defunc_0_op_res_f_res_25232;\n                }\n                redout_tmp_27154 = defunc_0_op_res_25227;\n                redout_tmp_27155 = defunc_0_op_res_25228;\n                redout_tmp_27156 = defunc_0_op_res_25229;\n                redout_26118 = redout_tmp_27154;\n                redout_26119 = redout_tmp_27155;\n                redout_26120 = redout_tmp_27156;\n            }\n            x_25204 = redout_26118;\n            x_25205 = redout_26119;\n            x_25206 = redout_26120;\n            acc_25201 = x_25204;\n            acc_25202 = x_25205;\n            acc_25203 = x_25206;\n        } else {\n            acc_25201 = acc_25197;\n            acc_25202 = acc_25198;\n            acc_25203 = acc_25199;\n        }\n        mem_26573[(int64_t) 0] = acc_25201;\n        mem_26577[(int64_t) 0] = acc_25202;\n        mem_26581[(int64_t) 0] = acc_25203;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_6 = 0; i_6 < 1; i_6++)\n            mem_param_tmp_27148[i_6] = mem_26573[i_6];\n        for (int32_t i_7 = 0; i_7 < 1; i_7++)\n            mem_param_tmp_27149[i_7] = mem_26577[i_7];\n        for (int32_t i_8 = 0; i_8 < 1; i_8++)\n            mem_param_tmp_27150[i_8] = mem_26581[i_8];\n        for (int32_t i_9", " = 0; i_9 < 1; i_9++)\n            mem_param_26561[i_9] = mem_param_tmp_27148[i_9];\n        for (int32_t i_10 = 0; i_10 < 1; i_10++)\n            mem_param_26562[i_10] = mem_param_tmp_27149[i_10];\n        for (int32_t i_11 = 0; i_11 < 1; i_11++)\n            mem_param_26563[i_11] = mem_param_tmp_27150[i_11];\n    }\n    for (int32_t i_12 = 0; i_12 < 1; i_12++)\n        ext_mem_26584[i_12] = mem_param_26561[i_12];\n    for (int32_t i_13 = 0; i_13 < 1; i_13++)\n        ext_mem_26583[i_13] = mem_param_26562[i_13];\n    for (int32_t i_14 = 0; i_14 < 1; i_14++)\n        ext_mem_26582[i_14] = mem_param_26563[i_14];\n    barrier(CLK_LOCAL_MEM_FENCE);\n    if (cond_25273) {\n        for (int32_t i_15 = 0; i_15 < 1; i_15++)\n            ext_mem_26600[i_15] = ext_mem_26584[i_15];\n        for (int32_t i_16 = 0; i_16 < 1; i_16++)\n            ext_mem_26599[i_16] = ext_mem_26582[i_16];\n    } else {\n        int64_t ltid_flat_25275;\n        int64_t ltid_25274;\n        int64_t j_25290;\n        bool cond_25294;\n        int64_t pre1d_25297;\n        int64_t pre1d_25295;\n        int32_t pre1d_25296;\n        int64_t ltid_flat_25311;\n        int64_t ltid_25310;\n        int64_t gtid_25324;\n        int64_t acc_25326;\n        int64_t acc_25328;\n        bool cond_25329;\n        int64_t acc_25330;\n        int64_t acc_25332;\n        \n        ltid_flat_25275 = sext_i32_i64(local_tid_27139);\n        ltid_25274 = sext_i32_i64(sext_i64_i32(ltid_pre_27143));\n        j_25290 = ltid_25274 + binop_x_25289;\n        cond_25294 = slt64(j_25290, dzlz7bUZLzmZRz20UtS_endz20UtS_startz7dUzg_21439);\n        pre1d_25297 = btoi_bool_i64(cond_25294);\n        if (cond_25294) {\n            int64_t tile_elem_25298;\n            int64_t slice_26100;\n            int32_t tile_elem_25299;\n            \n            tile_elem_25298 = ((__global int64_t *) ext_mem_26543)[j_25290];\n            slice_26100 = tS_start_21436 + j_25290;\n            tile_elem_25299 = ((__global int32_t *) tS_mem_26244)[slice_26100];\n            pre1d_25295 = til", "e_elem_25298;\n            pre1d_25296 = tile_elem_25299;\n        } else {\n            pre1d_25295 = (int64_t) 0;\n            pre1d_25296 = 0;\n        }\n        ((__local int64_t *) color_27007)[ltid_25274] = pre1d_25295;\n        ((__local int32_t *) color_27006)[ltid_25274] = pre1d_25296;\n        ((__local int64_t *) color_27005)[ltid_25274] = pre1d_25297;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_25311 = sext_i32_i64(local_tid_27139);\n        ltid_25310 = sext_i32_i64(sext_i64_i32(ltid_pre_27143));\n        gtid_25324 = binop_x_25040 + ltid_25310;\n        acc_25326 = ext_mem_26584[(int64_t) 0];\n        acc_25328 = ext_mem_26582[(int64_t) 0];\n        cond_25329 = slt64(gtid_25324, min_res_22998);\n        if (cond_25329) {\n            int32_t eta_p_25325;\n            int32_t acc_25327;\n            int64_t x_25333;\n            int32_t x_25334;\n            int64_t x_25335;\n            int64_t redout_26122;\n            int32_t redout_26123;\n            int64_t redout_26124;\n            \n            eta_p_25325 = mem_26548[(int64_t) 0];\n            acc_25327 = ext_mem_26583[(int64_t) 0];\n            redout_26122 = acc_25326;\n            redout_26123 = acc_25327;\n            redout_26124 = acc_25328;\n            for (int64_t i_26125 = 0; i_26125 < residual_input_25272; i_26125++) {\n                int64_t x_25336;\n                int32_t x_25337;\n                bool defunc_0_neq_res_25345;\n                bool defunc_0_neq_res_25346;\n                bool cond_f_res_25347;\n                bool y_25348;\n                bool cond_25349;\n                bool defunc_0_neq_res_25350;\n                bool defunc_0_neq_res_25351;\n                bool cond_t_res_f_res_25352;\n                bool y_25353;\n                bool cond_t_res_25354;\n                bool x_25355;\n                int64_t defunc_0_op_res_25356;\n                int32_t defunc_0_op_res_25357;\n                int64_t defunc_0_op_res_25358;\n                int64_t redout_tmp_27157;\n               ",
                                    " int32_t redout_tmp_27158;\n                int64_t redout_tmp_27159;\n                \n                x_25336 = ((__local int64_t *) color_27007)[i_26125];\n                x_25337 = ((__local int32_t *) color_27006)[i_26125];\n                defunc_0_neq_res_25345 = redout_26123 == eta_p_25325;\n                defunc_0_neq_res_25346 = !defunc_0_neq_res_25345;\n                cond_f_res_25347 = slt64(redout_26122, (int64_t) 0);\n                y_25348 = defunc_0_neq_res_25345 && cond_f_res_25347;\n                cond_25349 = defunc_0_neq_res_25346 || y_25348;\n                defunc_0_neq_res_25350 = x_25337 == eta_p_25325;\n                defunc_0_neq_res_25351 = !defunc_0_neq_res_25350;\n                cond_t_res_f_res_25352 = slt64(x_25336, (int64_t) 0);\n                y_25353 = defunc_0_neq_res_25350 && cond_t_res_f_res_25352;\n                cond_t_res_25354 = defunc_0_neq_res_25351 || y_25353;\n                x_25355 = cond_25349 && cond_t_res_25354;\n                if (x_25355) {\n                    defunc_0_op_res_25356 = (int64_t) -1;\n                    defunc_0_op_res_25357 = eta_p_25325;\n                    defunc_0_op_res_25358 = (int64_t) 0;\n                } else {\n                    int64_t x_25338;\n                    int64_t defunc_0_op_res_f_res_25359;\n                    int32_t defunc_0_op_res_f_res_25360;\n                    int64_t defunc_0_op_res_f_res_25361;\n                    \n                    x_25338 = ((__local int64_t *) color_27005)[i_26125];\n                    if (cond_25349) {\n                        defunc_0_op_res_f_res_25359 = x_25336;\n                        defunc_0_op_res_f_res_25360 = x_25337;\n                        defunc_0_op_res_f_res_25361 = x_25338;\n                    } else {\n                        int32_t defunc_0_op_res_f_res_f_res_25362;\n                        int64_t defunc_0_op_res_f_res_f_res_25363;\n                        int64_t defunc_0_op_res_f_res_f_res_25364;\n                        \n                 ", "       if (cond_t_res_25354) {\n                            defunc_0_op_res_f_res_f_res_25362 = redout_26123;\n                        } else {\n                            defunc_0_op_res_f_res_f_res_25362 = eta_p_25325;\n                        }\n                        if (cond_t_res_25354) {\n                            defunc_0_op_res_f_res_f_res_25363 = redout_26122;\n                            defunc_0_op_res_f_res_f_res_25364 = redout_26124;\n                        } else {\n                            int64_t min_res_25365;\n                            int64_t tmp_25366;\n                            \n                            min_res_25365 = smin64(x_25336, redout_26122);\n                            tmp_25366 = add64(x_25338, redout_26124);\n                            defunc_0_op_res_f_res_f_res_25363 = min_res_25365;\n                            defunc_0_op_res_f_res_f_res_25364 = tmp_25366;\n                        }\n                        defunc_0_op_res_f_res_25359 = defunc_0_op_res_f_res_f_res_25363;\n                        defunc_0_op_res_f_res_25360 = defunc_0_op_res_f_res_f_res_25362;\n                        defunc_0_op_res_f_res_25361 = defunc_0_op_res_f_res_f_res_25364;\n                    }\n                    defunc_0_op_res_25356 = defunc_0_op_res_f_res_25359;\n                    defunc_0_op_res_25357 = defunc_0_op_res_f_res_25360;\n                    defunc_0_op_res_25358 = defunc_0_op_res_f_res_25361;\n                }\n                redout_tmp_27157 = defunc_0_op_res_25356;\n                redout_tmp_27158 = defunc_0_op_res_25357;\n                redout_tmp_27159 = defunc_0_op_res_25358;\n                redout_26122 = redout_tmp_27157;\n                redout_26123 = redout_tmp_27158;\n                redout_26124 = redout_tmp_27159;\n            }\n            x_25333 = redout_26122;\n            x_25334 = redout_26123;\n            x_25335 = redout_26124;\n            acc_25330 = x_25333;\n            acc_25332 = x_25335;\n        } else {\n            ac", "c_25330 = acc_25326;\n            acc_25332 = acc_25328;\n        }\n        mem_26594[(int64_t) 0] = acc_25330;\n        mem_26598[(int64_t) 0] = acc_25332;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_17 = 0; i_17 < 1; i_17++)\n            ext_mem_26600[i_17] = mem_26594[i_17];\n        for (int32_t i_18 = 0; i_18 < 1; i_18++)\n            ext_mem_26599[i_18] = mem_26598[i_18];\n    }\n    if (slt64(sext_i32_i64(local_tid_27139) + tile_sizze_25032 * sext_i32_i64(block_id_27140), min_res_22998)) {\n        int64_t tmp_27160 = ext_mem_26600[(int64_t) 0];\n        \n        ((__global int64_t *) mem_26602)[sext_i32_i64(local_tid_27139) + tile_sizze_25032 * sext_i32_i64(block_id_27140)] = tmp_27160;\n    }\n    if (slt64(sext_i32_i64(local_tid_27139) + tile_sizze_25032 * sext_i32_i64(block_id_27140), min_res_22998)) {\n        int64_t tmp_27161 = ext_mem_26599[(int64_t) 0];\n        \n        ((__global int64_t *) mem_26604)[sext_i32_i64(local_tid_27139) + tile_sizze_25032 * sext_i32_i64(block_id_27140)] = tmp_27161;\n    }\n    \n  error_8:\n    return;\n    #undef tile_sizze_25032\n    #undef bytes_26564\n    #undef bytes_26566\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzisegmap_intrablock_25385_dim1, 1, 1)\nvoid inner_SMJ_intzisegmap_intrablock_25385(__global int *global_failure, int64_t j_m_i_22098, int64_t min_res_22136, int64_t slice_22150, int64_t slice_22507, int64_t ldim_25388, int64_t num_whole_tiles_25403, int64_t residual_input_25627, unsigned char cond_25628_bits, int64_t binop_x_25644, __global unsigned char *tR_mem_26243, __global unsigned char *tS_mem_26244, __global unsigned char *ext_mem_26338, __global unsigned char *mem_26458, __global unsigned char *mem_26460)\n{\n    bool cond_25628 = cond_25628_bits;\n    \n    #define tile_sizze_25387 (inner_SMJ_intzisegmap_intrablock_25385zitile_sizze_25387)\n    #define bytes_26420 (inner_SMJ_intzisegmap_intrablock_25385zibytes_26420)\n    #define bytes_26422 (inner_SMJ_intzisegmap_intrablock_25385zibytes_26422)\n    \n    volatile ",
                                    "__local unsigned char *color_27010_backing_2 = &shared_mem[0];\n    const int64_t color_27010_backing_2_offset = 0 + (bytes_26420 + srem64((int64_t) 8 - srem64(bytes_26420, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_27009_backing_1 = &shared_mem[color_27010_backing_2_offset];\n    const int64_t color_27009_backing_1_offset = color_27010_backing_2_offset + (bytes_26422 + srem64((int64_t) 8 - srem64(bytes_26422, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_27008_backing_0 = &shared_mem[color_27009_backing_1_offset];\n    const int64_t color_27008_backing_0_offset = color_27009_backing_1_offset + (bytes_26420 + srem64((int64_t) 8 - srem64(bytes_26420, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27280;\n    int32_t tblock_sizze_27283;\n    int32_t wave_sizze_27282;\n    int32_t block_id_27281;\n    int32_t global_tid_27279;\n    int64_t gid_flat_25385;\n    int64_t slice_27285;\n    int64_t ltid_pre_27284;\n    int64_t remnant_27286;\n    int64_t slice_27287;\n    int64_t gid_25384;\n    int64_t remnant_27288;\n    __local unsigned char *color_27008;\n    __local unsigned char *color_27009;\n    __local unsigned char *color_27010;\n    int64_t binop_x_25395;\n    int32_t mem_26404[1];\n    int64_t ltid_flat_25390;\n    int64_t ltid_25389;\n    int64_t gtid_25396;\n    bool cond_25397;\n    int32_t pre_25398;\n    int64_t mem_26408[1];\n    int32_t mem_26412[1];\n    int64_t mem_26416[1];\n    int64_t ltid_flat_25405;\n    int64_t ltid_25404;\n    int64_t gtid_25415;\n    bool cond_25416;\n    int64_t neutral_25417;\n    int32_t neutral_25418;\n    int64_t ext_mem_26440[1];\n    int32_t ext_mem_26439[1];\n    int64_t ext_mem_26438[1];\n    int64_t mem_param_26417[1];\n    int32_t mem_param_26418[1];\n    int64_t mem_param_26419[1];\n    int64_t mem_26450[1];\n    int64_t mem_26454[1];\n    int64_t ext_mem_26456[1];\n    int64_t ext_mem_26455[1];\n    \n    local_tid_27280 = get_local_id(0);\n    tbloc", "k_sizze_27283 = get_local_size(0);\n    wave_sizze_27282 = LOCKSTEP_WIDTH;\n    block_id_27281 = get_tblock_id(0);\n    global_tid_27279 = block_id_27281 * tblock_sizze_27283 + local_tid_27280;\n    gid_flat_25385 = sext_i32_i64(block_id_27281);\n    slice_27285 = tile_sizze_25387;\n    ltid_pre_27284 = sext_i32_i64(local_tid_27280);\n    remnant_27286 = sext_i32_i64(local_tid_27280) - ltid_pre_27284;\n    slice_27287 = ldim_25388;\n    gid_25384 = sext_i32_i64(block_id_27281);\n    remnant_27288 = sext_i32_i64(block_id_27281) - gid_25384;\n    color_27008 = (__local unsigned char *) color_27008_backing_0;\n    color_27009 = (__local unsigned char *) color_27009_backing_1;\n    color_27010 = (__local unsigned char *) color_27010_backing_2;\n    binop_x_25395 = gid_25384 * tile_sizze_25387;\n    ltid_flat_25390 = sext_i32_i64(local_tid_27280);\n    ltid_25389 = sext_i32_i64(sext_i64_i32(ltid_pre_27284));\n    gtid_25396 = ltid_25389 + binop_x_25395;\n    cond_25397 = slt64(gtid_25396, min_res_22136);\n    if (cond_25397) {\n        int64_t slice_25399;\n        int32_t eta_p_25400;\n        \n        slice_25399 = slice_22150 + gtid_25396;\n        eta_p_25400 = ((__global int32_t *) tR_mem_26243)[slice_25399];\n        pre_25398 = eta_p_25400;\n    } else {\n        pre_25398 = 0;\n    }\n    mem_26404[(int64_t) 0] = pre_25398;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    ltid_flat_25405 = sext_i32_i64(local_tid_27280);\n    ltid_25404 = sext_i32_i64(sext_i64_i32(ltid_pre_27284));\n    gtid_25415 = binop_x_25395 + ltid_25404;\n    cond_25416 = slt64(gtid_25415, min_res_22136);\n    if (cond_25416) {\n        neutral_25417 = (int64_t) -1;\n    } else {\n        neutral_25417 = (int64_t) 0;\n    }\n    if (cond_25416) {\n        int32_t eta_p_25420 = mem_26404[(int64_t) 0];\n        \n        neutral_25418 = eta_p_25420;\n    } else {\n        neutral_25418 = 0;\n    }\n    mem_26408[(int64_t) 0] = neutral_25417;\n    mem_26412[(int64_t) 0] = neutral_25418;\n    mem_26416[(int64_t) 0] = (int64_t) 0;\n    barrier(CLK_LOCAL", "_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    for (int32_t i_3 = 0; i_3 < 1; i_3++)\n        mem_param_26417[i_3] = mem_26408[i_3];\n    for (int32_t i_4 = 0; i_4 < 1; i_4++)\n        mem_param_26418[i_4] = mem_26412[i_4];\n    for (int32_t i_5 = 0; i_5 < 1; i_5++)\n        mem_param_26419[i_5] = mem_26416[i_5];\n    for (int64_t tile_id_25430 = 0; tile_id_25430 < num_whole_tiles_25403; tile_id_25430++) {\n        int64_t binop_x_25529;\n        int64_t ltid_flat_25528;\n        int64_t ltid_25527;\n        int64_t j_25530;\n        bool cond_25534;\n        int64_t pre1d_25537;\n        int64_t pre1d_25535;\n        int32_t pre1d_25536;\n        int64_t mem_26429[1];\n        int32_t mem_26433[1];\n        int64_t mem_26437[1];\n        int64_t ltid_flat_25548;\n        int64_t ltid_25547;\n        int64_t gtid_25550;\n        int64_t acc_25552;\n        int32_t acc_25553;\n        int64_t acc_25554;\n        bool cond_25555;\n        int64_t acc_25556;\n        int32_t acc_25557;\n        int64_t acc_25558;\n        int64_t mem_param_tmp_27289[1];\n        int32_t mem_param_tmp_27290[1];\n        int64_t mem_param_tmp_27291[1];\n        \n        binop_x_25529 = tile_sizze_25387 * tile_id_25430;\n        ltid_flat_25528 = sext_i32_i64(local_tid_27280);\n        ltid_25527 = sext_i32_i64(sext_i64_i32(ltid_pre_27284));\n        j_25530 = ltid_25527 + binop_x_25529;\n        cond_25534 = slt64(j_25530, j_m_i_22098);\n        pre1d_25537 = btoi_bool_i64(cond_25534);\n        if (cond_25534) {\n            int64_t tile_elem_25538;\n            int64_t slice_26105;\n            int32_t tile_elem_25539;\n            \n            tile_elem_25538 = ((__global int64_t *) ext_mem_26338)[j_25530];\n            slice_26105 = slice_22507 + j_25530;\n            tile_elem_25539 = ((__global int32_t *) tS_mem_26244)[slice_26105];\n            pre1d_25535 = tile_elem_25538;\n            pre1d_25536 = tile_elem_25539;\n        } else {\n            pre1d_25535 = (int64_t) 0;\n            pre1d_25536 = 0;\n        }\n        ((",
                                    "__local int64_t *) color_27010)[ltid_25527] = pre1d_25535;\n        ((__local int32_t *) color_27009)[ltid_25527] = pre1d_25536;\n        ((__local int64_t *) color_27008)[ltid_25527] = pre1d_25537;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_25548 = sext_i32_i64(local_tid_27280);\n        ltid_25547 = sext_i32_i64(sext_i64_i32(ltid_pre_27284));\n        gtid_25550 = binop_x_25395 + ltid_25547;\n        acc_25552 = mem_param_26417[(int64_t) 0];\n        acc_25553 = mem_param_26418[(int64_t) 0];\n        acc_25554 = mem_param_26419[(int64_t) 0];\n        cond_25555 = slt64(gtid_25550, min_res_22136);\n        if (cond_25555) {\n            int32_t eta_p_25551;\n            int64_t x_25559;\n            int32_t x_25560;\n            int64_t x_25561;\n            int64_t redout_26126;\n            int32_t redout_26127;\n            int64_t redout_26128;\n            \n            eta_p_25551 = mem_26404[(int64_t) 0];\n            redout_26126 = acc_25552;\n            redout_26127 = acc_25553;\n            redout_26128 = acc_25554;\n            for (int64_t i_26129 = 0; i_26129 < tile_sizze_25387; i_26129++) {\n                int64_t x_25562;\n                int32_t x_25563;\n                bool defunc_0_neq_res_25571;\n                bool defunc_0_neq_res_25572;\n                bool cond_f_res_25573;\n                bool y_25574;\n                bool cond_25575;\n                bool defunc_0_neq_res_25576;\n                bool defunc_0_neq_res_25577;\n                bool cond_t_res_f_res_25578;\n                bool y_25579;\n                bool cond_t_res_25580;\n                bool x_25581;\n                int64_t defunc_0_op_res_25582;\n                int32_t defunc_0_op_res_25583;\n                int64_t defunc_0_op_res_25584;\n                int64_t redout_tmp_27295;\n                int32_t redout_tmp_27296;\n                int64_t redout_tmp_27297;\n                \n                x_25562 = ((__local int64_t *) color_27010)[i_26129];\n                x_25563 = ((__local int", "32_t *) color_27009)[i_26129];\n                defunc_0_neq_res_25571 = redout_26127 == eta_p_25551;\n                defunc_0_neq_res_25572 = !defunc_0_neq_res_25571;\n                cond_f_res_25573 = slt64(redout_26126, (int64_t) 0);\n                y_25574 = defunc_0_neq_res_25571 && cond_f_res_25573;\n                cond_25575 = defunc_0_neq_res_25572 || y_25574;\n                defunc_0_neq_res_25576 = x_25563 == eta_p_25551;\n                defunc_0_neq_res_25577 = !defunc_0_neq_res_25576;\n                cond_t_res_f_res_25578 = slt64(x_25562, (int64_t) 0);\n                y_25579 = defunc_0_neq_res_25576 && cond_t_res_f_res_25578;\n                cond_t_res_25580 = defunc_0_neq_res_25577 || y_25579;\n                x_25581 = cond_25575 && cond_t_res_25580;\n                if (x_25581) {\n                    defunc_0_op_res_25582 = (int64_t) -1;\n                    defunc_0_op_res_25583 = eta_p_25551;\n                    defunc_0_op_res_25584 = (int64_t) 0;\n                } else {\n                    int64_t x_25564;\n                    int64_t defunc_0_op_res_f_res_25585;\n                    int32_t defunc_0_op_res_f_res_25586;\n                    int64_t defunc_0_op_res_f_res_25587;\n                    \n                    x_25564 = ((__local int64_t *) color_27008)[i_26129];\n                    if (cond_25575) {\n                        defunc_0_op_res_f_res_25585 = x_25562;\n                        defunc_0_op_res_f_res_25586 = x_25563;\n                        defunc_0_op_res_f_res_25587 = x_25564;\n                    } else {\n                        int32_t defunc_0_op_res_f_res_f_res_25588;\n                        int64_t defunc_0_op_res_f_res_f_res_25589;\n                        int64_t defunc_0_op_res_f_res_f_res_25590;\n                        \n                        if (cond_t_res_25580) {\n                            defunc_0_op_res_f_res_f_res_25588 = redout_26127;\n                        } else {\n                            defunc_0_op_res_f_res_f_r", "es_25588 = eta_p_25551;\n                        }\n                        if (cond_t_res_25580) {\n                            defunc_0_op_res_f_res_f_res_25589 = redout_26126;\n                            defunc_0_op_res_f_res_f_res_25590 = redout_26128;\n                        } else {\n                            int64_t min_res_25591;\n                            int64_t tmp_25592;\n                            \n                            min_res_25591 = smin64(x_25562, redout_26126);\n                            tmp_25592 = add64(x_25564, redout_26128);\n                            defunc_0_op_res_f_res_f_res_25589 = min_res_25591;\n                            defunc_0_op_res_f_res_f_res_25590 = tmp_25592;\n                        }\n                        defunc_0_op_res_f_res_25585 = defunc_0_op_res_f_res_f_res_25589;\n                        defunc_0_op_res_f_res_25586 = defunc_0_op_res_f_res_f_res_25588;\n                        defunc_0_op_res_f_res_25587 = defunc_0_op_res_f_res_f_res_25590;\n                    }\n                    defunc_0_op_res_25582 = defunc_0_op_res_f_res_25585;\n                    defunc_0_op_res_25583 = defunc_0_op_res_f_res_25586;\n                    defunc_0_op_res_25584 = defunc_0_op_res_f_res_25587;\n                }\n                redout_tmp_27295 = defunc_0_op_res_25582;\n                redout_tmp_27296 = defunc_0_op_res_25583;\n                redout_tmp_27297 = defunc_0_op_res_25584;\n                redout_26126 = redout_tmp_27295;\n                redout_26127 = redout_tmp_27296;\n                redout_26128 = redout_tmp_27297;\n            }\n            x_25559 = redout_26126;\n            x_25560 = redout_26127;\n            x_25561 = redout_26128;\n            acc_25556 = x_25559;\n            acc_25557 = x_25560;\n            acc_25558 = x_25561;\n        } else {\n            acc_25556 = acc_25552;\n            acc_25557 = acc_25553;\n            acc_25558 = acc_25554;\n        }\n        mem_26429[(int64_t) 0] = acc_25556;\n        mem_26433",
                                    "[(int64_t) 0] = acc_25557;\n        mem_26437[(int64_t) 0] = acc_25558;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_6 = 0; i_6 < 1; i_6++)\n            mem_param_tmp_27289[i_6] = mem_26429[i_6];\n        for (int32_t i_7 = 0; i_7 < 1; i_7++)\n            mem_param_tmp_27290[i_7] = mem_26433[i_7];\n        for (int32_t i_8 = 0; i_8 < 1; i_8++)\n            mem_param_tmp_27291[i_8] = mem_26437[i_8];\n        for (int32_t i_9 = 0; i_9 < 1; i_9++)\n            mem_param_26417[i_9] = mem_param_tmp_27289[i_9];\n        for (int32_t i_10 = 0; i_10 < 1; i_10++)\n            mem_param_26418[i_10] = mem_param_tmp_27290[i_10];\n        for (int32_t i_11 = 0; i_11 < 1; i_11++)\n            mem_param_26419[i_11] = mem_param_tmp_27291[i_11];\n    }\n    for (int32_t i_12 = 0; i_12 < 1; i_12++)\n        ext_mem_26440[i_12] = mem_param_26417[i_12];\n    for (int32_t i_13 = 0; i_13 < 1; i_13++)\n        ext_mem_26439[i_13] = mem_param_26418[i_13];\n    for (int32_t i_14 = 0; i_14 < 1; i_14++)\n        ext_mem_26438[i_14] = mem_param_26419[i_14];\n    barrier(CLK_LOCAL_MEM_FENCE);\n    if (cond_25628) {\n        for (int32_t i_15 = 0; i_15 < 1; i_15++)\n            ext_mem_26456[i_15] = ext_mem_26440[i_15];\n        for (int32_t i_16 = 0; i_16 < 1; i_16++)\n            ext_mem_26455[i_16] = ext_mem_26438[i_16];\n    } else {\n        int64_t ltid_flat_25630;\n        int64_t ltid_25629;\n        int64_t j_25645;\n        bool cond_25649;\n        int64_t pre1d_25652;\n        int64_t pre1d_25650;\n        int32_t pre1d_25651;\n        int64_t ltid_flat_25666;\n        int64_t ltid_25665;\n        int64_t gtid_25679;\n        int64_t acc_25681;\n        int64_t acc_25683;\n        bool cond_25684;\n        int64_t acc_25685;\n        int64_t acc_25687;\n        \n        ltid_flat_25630 = sext_i32_i64(local_tid_27280);\n        ltid_25629 = sext_i32_i64(sext_i64_i32(ltid_pre_27284));\n        j_25645 = ltid_25629 + binop_x_25644;\n        cond_25649 = slt64(j_25645, j_m_i_22098);\n        pre1d_25652 = btoi_bool_i", "64(cond_25649);\n        if (cond_25649) {\n            int64_t tile_elem_25653;\n            int64_t slice_26104;\n            int32_t tile_elem_25654;\n            \n            tile_elem_25653 = ((__global int64_t *) ext_mem_26338)[j_25645];\n            slice_26104 = slice_22507 + j_25645;\n            tile_elem_25654 = ((__global int32_t *) tS_mem_26244)[slice_26104];\n            pre1d_25650 = tile_elem_25653;\n            pre1d_25651 = tile_elem_25654;\n        } else {\n            pre1d_25650 = (int64_t) 0;\n            pre1d_25651 = 0;\n        }\n        ((__local int64_t *) color_27010)[ltid_25629] = pre1d_25650;\n        ((__local int32_t *) color_27009)[ltid_25629] = pre1d_25651;\n        ((__local int64_t *) color_27008)[ltid_25629] = pre1d_25652;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_25666 = sext_i32_i64(local_tid_27280);\n        ltid_25665 = sext_i32_i64(sext_i64_i32(ltid_pre_27284));\n        gtid_25679 = binop_x_25395 + ltid_25665;\n        acc_25681 = ext_mem_26440[(int64_t) 0];\n        acc_25683 = ext_mem_26438[(int64_t) 0];\n        cond_25684 = slt64(gtid_25679, min_res_22136);\n        if (cond_25684) {\n            int32_t eta_p_25680;\n            int32_t acc_25682;\n            int64_t x_25688;\n            int32_t x_25689;\n            int64_t x_25690;\n            int64_t redout_26130;\n            int32_t redout_26131;\n            int64_t redout_26132;\n            \n            eta_p_25680 = mem_26404[(int64_t) 0];\n            acc_25682 = ext_mem_26439[(int64_t) 0];\n            redout_26130 = acc_25681;\n            redout_26131 = acc_25682;\n            redout_26132 = acc_25683;\n            for (int64_t i_26133 = 0; i_26133 < residual_input_25627; i_26133++) {\n                int64_t x_25691;\n                int32_t x_25692;\n                bool defunc_0_neq_res_25700;\n                bool defunc_0_neq_res_25701;\n                bool cond_f_res_25702;\n                bool y_25703;\n                bool cond_25704;\n                bool defunc_0_neq_r", "es_25705;\n                bool defunc_0_neq_res_25706;\n                bool cond_t_res_f_res_25707;\n                bool y_25708;\n                bool cond_t_res_25709;\n                bool x_25710;\n                int64_t defunc_0_op_res_25711;\n                int32_t defunc_0_op_res_25712;\n                int64_t defunc_0_op_res_25713;\n                int64_t redout_tmp_27298;\n                int32_t redout_tmp_27299;\n                int64_t redout_tmp_27300;\n                \n                x_25691 = ((__local int64_t *) color_27010)[i_26133];\n                x_25692 = ((__local int32_t *) color_27009)[i_26133];\n                defunc_0_neq_res_25700 = redout_26131 == eta_p_25680;\n                defunc_0_neq_res_25701 = !defunc_0_neq_res_25700;\n                cond_f_res_25702 = slt64(redout_26130, (int64_t) 0);\n                y_25703 = defunc_0_neq_res_25700 && cond_f_res_25702;\n                cond_25704 = defunc_0_neq_res_25701 || y_25703;\n                defunc_0_neq_res_25705 = x_25692 == eta_p_25680;\n                defunc_0_neq_res_25706 = !defunc_0_neq_res_25705;\n                cond_t_res_f_res_25707 = slt64(x_25691, (int64_t) 0);\n                y_25708 = defunc_0_neq_res_25705 && cond_t_res_f_res_25707;\n                cond_t_res_25709 = defunc_0_neq_res_25706 || y_25708;\n                x_25710 = cond_25704 && cond_t_res_25709;\n                if (x_25710) {\n                    defunc_0_op_res_25711 = (int64_t) -1;\n                    defunc_0_op_res_25712 = eta_p_25680;\n                    defunc_0_op_res_25713 = (int64_t) 0;\n                } else {\n                    int64_t x_25693;\n                    int64_t defunc_0_op_res_f_res_25714;\n                    int32_t defunc_0_op_res_f_res_25715;\n                    int64_t defunc_0_op_res_f_res_25716;\n                    \n                    x_25693 = ((__local int64_t *) color_27008)[i_26133];\n                    if (cond_25704) {\n                        defunc_0_op_res_f_res_25714 = x_25691;\n ",
                                    "                       defunc_0_op_res_f_res_25715 = x_25692;\n                        defunc_0_op_res_f_res_25716 = x_25693;\n                    } else {\n                        int32_t defunc_0_op_res_f_res_f_res_25717;\n                        int64_t defunc_0_op_res_f_res_f_res_25718;\n                        int64_t defunc_0_op_res_f_res_f_res_25719;\n                        \n                        if (cond_t_res_25709) {\n                            defunc_0_op_res_f_res_f_res_25717 = redout_26131;\n                        } else {\n                            defunc_0_op_res_f_res_f_res_25717 = eta_p_25680;\n                        }\n                        if (cond_t_res_25709) {\n                            defunc_0_op_res_f_res_f_res_25718 = redout_26130;\n                            defunc_0_op_res_f_res_f_res_25719 = redout_26132;\n                        } else {\n                            int64_t min_res_25720;\n                            int64_t tmp_25721;\n                            \n                            min_res_25720 = smin64(x_25691, redout_26130);\n                            tmp_25721 = add64(x_25693, redout_26132);\n                            defunc_0_op_res_f_res_f_res_25718 = min_res_25720;\n                            defunc_0_op_res_f_res_f_res_25719 = tmp_25721;\n                        }\n                        defunc_0_op_res_f_res_25714 = defunc_0_op_res_f_res_f_res_25718;\n                        defunc_0_op_res_f_res_25715 = defunc_0_op_res_f_res_f_res_25717;\n                        defunc_0_op_res_f_res_25716 = defunc_0_op_res_f_res_f_res_25719;\n                    }\n                    defunc_0_op_res_25711 = defunc_0_op_res_f_res_25714;\n                    defunc_0_op_res_25712 = defunc_0_op_res_f_res_25715;\n                    defunc_0_op_res_25713 = defunc_0_op_res_f_res_25716;\n                }\n                redout_tmp_27298 = defunc_0_op_res_25711;\n                redout_tmp_27299 = defunc_0_op_res_25712;\n                redout_tmp_", "27300 = defunc_0_op_res_25713;\n                redout_26130 = redout_tmp_27298;\n                redout_26131 = redout_tmp_27299;\n                redout_26132 = redout_tmp_27300;\n            }\n            x_25688 = redout_26130;\n            x_25689 = redout_26131;\n            x_25690 = redout_26132;\n            acc_25685 = x_25688;\n            acc_25687 = x_25690;\n        } else {\n            acc_25685 = acc_25681;\n            acc_25687 = acc_25683;\n        }\n        mem_26450[(int64_t) 0] = acc_25685;\n        mem_26454[(int64_t) 0] = acc_25687;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_17 = 0; i_17 < 1; i_17++)\n            ext_mem_26456[i_17] = mem_26450[i_17];\n        for (int32_t i_18 = 0; i_18 < 1; i_18++)\n            ext_mem_26455[i_18] = mem_26454[i_18];\n    }\n    if (slt64(sext_i32_i64(local_tid_27280) + tile_sizze_25387 * sext_i32_i64(block_id_27281), min_res_22136)) {\n        int64_t tmp_27301 = ext_mem_26456[(int64_t) 0];\n        \n        ((__global int64_t *) mem_26458)[sext_i32_i64(local_tid_27280) + tile_sizze_25387 * sext_i32_i64(block_id_27281)] = tmp_27301;\n    }\n    if (slt64(sext_i32_i64(local_tid_27280) + tile_sizze_25387 * sext_i32_i64(block_id_27281), min_res_22136)) {\n        int64_t tmp_27302 = ext_mem_26455[(int64_t) 0];\n        \n        ((__global int64_t *) mem_26460)[sext_i32_i64(local_tid_27280) + tile_sizze_25387 * sext_i32_i64(block_id_27281)] = tmp_27302;\n    }\n    \n  error_8:\n    return;\n    #undef tile_sizze_25387\n    #undef bytes_26420\n    #undef bytes_26422\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzisegmap_intrablock_25740_dim1, 1, 1)\nvoid inner_SMJ_intzisegmap_intrablock_25740(__global int *global_failure, int64_t j_m_i_22098, int64_t min_res_22136, int64_t slice_22150, int64_t slice_22507, int64_t ldim_25743, int64_t num_whole_tiles_25758, int64_t residual_input_25982, unsigned char cond_25983_bits, int64_t binop_x_25999, __global unsigned char *tR_mem_26243, __global unsigned char *tS_mem_26244, __global unsigned ch", "ar *ext_mem_26338, __global unsigned char *mem_26397, __global unsigned char *mem_26399)\n{\n    bool cond_25983 = cond_25983_bits;\n    \n    #define tile_sizze_25742 (inner_SMJ_intzisegmap_intrablock_25740zitile_sizze_25742)\n    #define bytes_26359 (inner_SMJ_intzisegmap_intrablock_25740zibytes_26359)\n    #define bytes_26361 (inner_SMJ_intzisegmap_intrablock_25740zibytes_26361)\n    \n    volatile __local unsigned char *color_27013_backing_2 = &shared_mem[0];\n    const int64_t color_27013_backing_2_offset = 0 + (bytes_26359 + srem64((int64_t) 8 - srem64(bytes_26359, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_27012_backing_1 = &shared_mem[color_27013_backing_2_offset];\n    const int64_t color_27012_backing_1_offset = color_27013_backing_2_offset + (bytes_26361 + srem64((int64_t) 8 - srem64(bytes_26361, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_27011_backing_0 = &shared_mem[color_27012_backing_1_offset];\n    const int64_t color_27011_backing_0_offset = color_27012_backing_1_offset + (bytes_26359 + srem64((int64_t) 8 - srem64(bytes_26359, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27306;\n    int32_t tblock_sizze_27309;\n    int32_t wave_sizze_27308;\n    int32_t block_id_27307;\n    int32_t global_tid_27305;\n    int64_t gid_flat_25740;\n    int64_t slice_27311;\n    int64_t ltid_pre_27310;\n    int64_t remnant_27312;\n    int64_t slice_27313;\n    int64_t gid_25739;\n    int64_t remnant_27314;\n    __local unsigned char *color_27011;\n    __local unsigned char *color_27012;\n    __local unsigned char *color_27013;\n    int64_t binop_x_25750;\n    int32_t mem_26343[1];\n    int64_t ltid_flat_25745;\n    int64_t ltid_25744;\n    int64_t gtid_25751;\n    bool cond_25752;\n    int32_t pre_25753;\n    int64_t mem_26347[1];\n    int32_t mem_26351[1];\n    int64_t mem_26355[1];\n    int64_t ltid_flat_25760;\n    int64_t ltid_25759;\n    int64_t gtid_25770;\n    bool cond_25771;\n    int6",
                                    "4_t neutral_25772;\n    int32_t neutral_25773;\n    int64_t ext_mem_26379[1];\n    int32_t ext_mem_26378[1];\n    int64_t ext_mem_26377[1];\n    int64_t mem_param_26356[1];\n    int32_t mem_param_26357[1];\n    int64_t mem_param_26358[1];\n    int64_t mem_26389[1];\n    int64_t mem_26393[1];\n    int64_t ext_mem_26395[1];\n    int64_t ext_mem_26394[1];\n    \n    local_tid_27306 = get_local_id(0);\n    tblock_sizze_27309 = get_local_size(0);\n    wave_sizze_27308 = LOCKSTEP_WIDTH;\n    block_id_27307 = get_tblock_id(0);\n    global_tid_27305 = block_id_27307 * tblock_sizze_27309 + local_tid_27306;\n    gid_flat_25740 = sext_i32_i64(block_id_27307);\n    slice_27311 = tile_sizze_25742;\n    ltid_pre_27310 = sext_i32_i64(local_tid_27306);\n    remnant_27312 = sext_i32_i64(local_tid_27306) - ltid_pre_27310;\n    slice_27313 = ldim_25743;\n    gid_25739 = sext_i32_i64(block_id_27307);\n    remnant_27314 = sext_i32_i64(block_id_27307) - gid_25739;\n    color_27011 = (__local unsigned char *) color_27011_backing_0;\n    color_27012 = (__local unsigned char *) color_27012_backing_1;\n    color_27013 = (__local unsigned char *) color_27013_backing_2;\n    binop_x_25750 = gid_25739 * tile_sizze_25742;\n    ltid_flat_25745 = sext_i32_i64(local_tid_27306);\n    ltid_25744 = sext_i32_i64(sext_i64_i32(ltid_pre_27310));\n    gtid_25751 = ltid_25744 + binop_x_25750;\n    cond_25752 = slt64(gtid_25751, min_res_22136);\n    if (cond_25752) {\n        int64_t slice_25754;\n        int32_t eta_p_25755;\n        \n        slice_25754 = slice_22150 + gtid_25751;\n        eta_p_25755 = ((__global int32_t *) tR_mem_26243)[slice_25754];\n        pre_25753 = eta_p_25755;\n    } else {\n        pre_25753 = 0;\n    }\n    mem_26343[(int64_t) 0] = pre_25753;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    ltid_flat_25760 = sext_i32_i64(local_tid_27306);\n    ltid_25759 = sext_i32_i64(sext_i64_i32(ltid_pre_27310));\n    gtid_25770 = binop_x_25750 + ltid_25759;\n    cond_25771 = slt64(gtid_25770, min_res_22136);\n    if (cond_25771) {\n        neutral_", "25772 = (int64_t) -1;\n    } else {\n        neutral_25772 = (int64_t) 0;\n    }\n    if (cond_25771) {\n        int32_t eta_p_25775 = mem_26343[(int64_t) 0];\n        \n        neutral_25773 = eta_p_25775;\n    } else {\n        neutral_25773 = 0;\n    }\n    mem_26347[(int64_t) 0] = neutral_25772;\n    mem_26351[(int64_t) 0] = neutral_25773;\n    mem_26355[(int64_t) 0] = (int64_t) 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    for (int32_t i_3 = 0; i_3 < 1; i_3++)\n        mem_param_26356[i_3] = mem_26347[i_3];\n    for (int32_t i_4 = 0; i_4 < 1; i_4++)\n        mem_param_26357[i_4] = mem_26351[i_4];\n    for (int32_t i_5 = 0; i_5 < 1; i_5++)\n        mem_param_26358[i_5] = mem_26355[i_5];\n    for (int64_t tile_id_25785 = 0; tile_id_25785 < num_whole_tiles_25758; tile_id_25785++) {\n        int64_t binop_x_25884;\n        int64_t ltid_flat_25883;\n        int64_t ltid_25882;\n        int64_t j_25885;\n        bool cond_25889;\n        int64_t pre1d_25892;\n        int64_t pre1d_25890;\n        int32_t pre1d_25891;\n        int64_t mem_26368[1];\n        int32_t mem_26372[1];\n        int64_t mem_26376[1];\n        int64_t ltid_flat_25903;\n        int64_t ltid_25902;\n        int64_t gtid_25905;\n        int64_t acc_25907;\n        int32_t acc_25908;\n        int64_t acc_25909;\n        bool cond_25910;\n        int64_t acc_25911;\n        int32_t acc_25912;\n        int64_t acc_25913;\n        int64_t mem_param_tmp_27315[1];\n        int32_t mem_param_tmp_27316[1];\n        int64_t mem_param_tmp_27317[1];\n        \n        binop_x_25884 = tile_sizze_25742 * tile_id_25785;\n        ltid_flat_25883 = sext_i32_i64(local_tid_27306);\n        ltid_25882 = sext_i32_i64(sext_i64_i32(ltid_pre_27310));\n        j_25885 = ltid_25882 + binop_x_25884;\n        cond_25889 = slt64(j_25885, j_m_i_22098);\n        pre1d_25892 = btoi_bool_i64(cond_25889);\n        if (cond_25889) {\n            int64_t tile_elem_25893;\n            int64_t slice_26109;\n            int32_t tile_elem_25894;\n            \n", "            tile_elem_25893 = ((__global int64_t *) ext_mem_26338)[j_25885];\n            slice_26109 = slice_22507 + j_25885;\n            tile_elem_25894 = ((__global int32_t *) tS_mem_26244)[slice_26109];\n            pre1d_25890 = tile_elem_25893;\n            pre1d_25891 = tile_elem_25894;\n        } else {\n            pre1d_25890 = (int64_t) 0;\n            pre1d_25891 = 0;\n        }\n        ((__local int64_t *) color_27013)[ltid_25882] = pre1d_25890;\n        ((__local int32_t *) color_27012)[ltid_25882] = pre1d_25891;\n        ((__local int64_t *) color_27011)[ltid_25882] = pre1d_25892;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_25903 = sext_i32_i64(local_tid_27306);\n        ltid_25902 = sext_i32_i64(sext_i64_i32(ltid_pre_27310));\n        gtid_25905 = binop_x_25750 + ltid_25902;\n        acc_25907 = mem_param_26356[(int64_t) 0];\n        acc_25908 = mem_param_26357[(int64_t) 0];\n        acc_25909 = mem_param_26358[(int64_t) 0];\n        cond_25910 = slt64(gtid_25905, min_res_22136);\n        if (cond_25910) {\n            int32_t eta_p_25906;\n            int64_t x_25914;\n            int32_t x_25915;\n            int64_t x_25916;\n            int64_t redout_26134;\n            int32_t redout_26135;\n            int64_t redout_26136;\n            \n            eta_p_25906 = mem_26343[(int64_t) 0];\n            redout_26134 = acc_25907;\n            redout_26135 = acc_25908;\n            redout_26136 = acc_25909;\n            for (int64_t i_26137 = 0; i_26137 < tile_sizze_25742; i_26137++) {\n                int64_t x_25917;\n                int32_t x_25918;\n                bool defunc_0_neq_res_25926;\n                bool defunc_0_neq_res_25927;\n                bool cond_f_res_25928;\n                bool y_25929;\n                bool cond_25930;\n                bool defunc_0_neq_res_25931;\n                bool defunc_0_neq_res_25932;\n                bool cond_t_res_f_res_25933;\n                bool y_25934;\n                bool cond_t_res_25935;\n                bool x_259",
                                    "36;\n                int64_t defunc_0_op_res_25937;\n                int32_t defunc_0_op_res_25938;\n                int64_t defunc_0_op_res_25939;\n                int64_t redout_tmp_27321;\n                int32_t redout_tmp_27322;\n                int64_t redout_tmp_27323;\n                \n                x_25917 = ((__local int64_t *) color_27013)[i_26137];\n                x_25918 = ((__local int32_t *) color_27012)[i_26137];\n                defunc_0_neq_res_25926 = redout_26135 == eta_p_25906;\n                defunc_0_neq_res_25927 = !defunc_0_neq_res_25926;\n                cond_f_res_25928 = slt64(redout_26134, (int64_t) 0);\n                y_25929 = defunc_0_neq_res_25926 && cond_f_res_25928;\n                cond_25930 = defunc_0_neq_res_25927 || y_25929;\n                defunc_0_neq_res_25931 = x_25918 == eta_p_25906;\n                defunc_0_neq_res_25932 = !defunc_0_neq_res_25931;\n                cond_t_res_f_res_25933 = slt64(x_25917, (int64_t) 0);\n                y_25934 = defunc_0_neq_res_25931 && cond_t_res_f_res_25933;\n                cond_t_res_25935 = defunc_0_neq_res_25932 || y_25934;\n                x_25936 = cond_25930 && cond_t_res_25935;\n                if (x_25936) {\n                    defunc_0_op_res_25937 = (int64_t) -1;\n                    defunc_0_op_res_25938 = eta_p_25906;\n                    defunc_0_op_res_25939 = (int64_t) 0;\n                } else {\n                    int64_t x_25919;\n                    int64_t defunc_0_op_res_f_res_25940;\n                    int32_t defunc_0_op_res_f_res_25941;\n                    int64_t defunc_0_op_res_f_res_25942;\n                    \n                    x_25919 = ((__local int64_t *) color_27011)[i_26137];\n                    if (cond_25930) {\n                        defunc_0_op_res_f_res_25940 = x_25917;\n                        defunc_0_op_res_f_res_25941 = x_25918;\n                        defunc_0_op_res_f_res_25942 = x_25919;\n                    } else {\n                        int32_t defunc_0_", "op_res_f_res_f_res_25943;\n                        int64_t defunc_0_op_res_f_res_f_res_25944;\n                        int64_t defunc_0_op_res_f_res_f_res_25945;\n                        \n                        if (cond_t_res_25935) {\n                            defunc_0_op_res_f_res_f_res_25943 = redout_26135;\n                        } else {\n                            defunc_0_op_res_f_res_f_res_25943 = eta_p_25906;\n                        }\n                        if (cond_t_res_25935) {\n                            defunc_0_op_res_f_res_f_res_25944 = redout_26134;\n                            defunc_0_op_res_f_res_f_res_25945 = redout_26136;\n                        } else {\n                            int64_t min_res_25946;\n                            int64_t tmp_25947;\n                            \n                            min_res_25946 = smin64(x_25917, redout_26134);\n                            tmp_25947 = add64(x_25919, redout_26136);\n                            defunc_0_op_res_f_res_f_res_25944 = min_res_25946;\n                            defunc_0_op_res_f_res_f_res_25945 = tmp_25947;\n                        }\n                        defunc_0_op_res_f_res_25940 = defunc_0_op_res_f_res_f_res_25944;\n                        defunc_0_op_res_f_res_25941 = defunc_0_op_res_f_res_f_res_25943;\n                        defunc_0_op_res_f_res_25942 = defunc_0_op_res_f_res_f_res_25945;\n                    }\n                    defunc_0_op_res_25937 = defunc_0_op_res_f_res_25940;\n                    defunc_0_op_res_25938 = defunc_0_op_res_f_res_25941;\n                    defunc_0_op_res_25939 = defunc_0_op_res_f_res_25942;\n                }\n                redout_tmp_27321 = defunc_0_op_res_25937;\n                redout_tmp_27322 = defunc_0_op_res_25938;\n                redout_tmp_27323 = defunc_0_op_res_25939;\n                redout_26134 = redout_tmp_27321;\n                redout_26135 = redout_tmp_27322;\n                redout_26136 = redout_tmp_27323;\n            }\n   ", "         x_25914 = redout_26134;\n            x_25915 = redout_26135;\n            x_25916 = redout_26136;\n            acc_25911 = x_25914;\n            acc_25912 = x_25915;\n            acc_25913 = x_25916;\n        } else {\n            acc_25911 = acc_25907;\n            acc_25912 = acc_25908;\n            acc_25913 = acc_25909;\n        }\n        mem_26368[(int64_t) 0] = acc_25911;\n        mem_26372[(int64_t) 0] = acc_25912;\n        mem_26376[(int64_t) 0] = acc_25913;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_6 = 0; i_6 < 1; i_6++)\n            mem_param_tmp_27315[i_6] = mem_26368[i_6];\n        for (int32_t i_7 = 0; i_7 < 1; i_7++)\n            mem_param_tmp_27316[i_7] = mem_26372[i_7];\n        for (int32_t i_8 = 0; i_8 < 1; i_8++)\n            mem_param_tmp_27317[i_8] = mem_26376[i_8];\n        for (int32_t i_9 = 0; i_9 < 1; i_9++)\n            mem_param_26356[i_9] = mem_param_tmp_27315[i_9];\n        for (int32_t i_10 = 0; i_10 < 1; i_10++)\n            mem_param_26357[i_10] = mem_param_tmp_27316[i_10];\n        for (int32_t i_11 = 0; i_11 < 1; i_11++)\n            mem_param_26358[i_11] = mem_param_tmp_27317[i_11];\n    }\n    for (int32_t i_12 = 0; i_12 < 1; i_12++)\n        ext_mem_26379[i_12] = mem_param_26356[i_12];\n    for (int32_t i_13 = 0; i_13 < 1; i_13++)\n        ext_mem_26378[i_13] = mem_param_26357[i_13];\n    for (int32_t i_14 = 0; i_14 < 1; i_14++)\n        ext_mem_26377[i_14] = mem_param_26358[i_14];\n    barrier(CLK_LOCAL_MEM_FENCE);\n    if (cond_25983) {\n        for (int32_t i_15 = 0; i_15 < 1; i_15++)\n            ext_mem_26395[i_15] = ext_mem_26379[i_15];\n        for (int32_t i_16 = 0; i_16 < 1; i_16++)\n            ext_mem_26394[i_16] = ext_mem_26377[i_16];\n    } else {\n        int64_t ltid_flat_25985;\n        int64_t ltid_25984;\n        int64_t j_26000;\n        bool cond_26004;\n        int64_t pre1d_26007;\n        int64_t pre1d_26005;\n        int32_t pre1d_26006;\n        int64_t ltid_flat_26021;\n        int64_t ltid_26020;\n        int64_t gtid_260",
                                    "34;\n        int64_t acc_26036;\n        int64_t acc_26038;\n        bool cond_26039;\n        int64_t acc_26040;\n        int64_t acc_26042;\n        \n        ltid_flat_25985 = sext_i32_i64(local_tid_27306);\n        ltid_25984 = sext_i32_i64(sext_i64_i32(ltid_pre_27310));\n        j_26000 = ltid_25984 + binop_x_25999;\n        cond_26004 = slt64(j_26000, j_m_i_22098);\n        pre1d_26007 = btoi_bool_i64(cond_26004);\n        if (cond_26004) {\n            int64_t tile_elem_26008;\n            int64_t slice_26108;\n            int32_t tile_elem_26009;\n            \n            tile_elem_26008 = ((__global int64_t *) ext_mem_26338)[j_26000];\n            slice_26108 = slice_22507 + j_26000;\n            tile_elem_26009 = ((__global int32_t *) tS_mem_26244)[slice_26108];\n            pre1d_26005 = tile_elem_26008;\n            pre1d_26006 = tile_elem_26009;\n        } else {\n            pre1d_26005 = (int64_t) 0;\n            pre1d_26006 = 0;\n        }\n        ((__local int64_t *) color_27013)[ltid_25984] = pre1d_26005;\n        ((__local int32_t *) color_27012)[ltid_25984] = pre1d_26006;\n        ((__local int64_t *) color_27011)[ltid_25984] = pre1d_26007;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_26021 = sext_i32_i64(local_tid_27306);\n        ltid_26020 = sext_i32_i64(sext_i64_i32(ltid_pre_27310));\n        gtid_26034 = binop_x_25750 + ltid_26020;\n        acc_26036 = ext_mem_26379[(int64_t) 0];\n        acc_26038 = ext_mem_26377[(int64_t) 0];\n        cond_26039 = slt64(gtid_26034, min_res_22136);\n        if (cond_26039) {\n            int32_t eta_p_26035;\n            int32_t acc_26037;\n            int64_t x_26043;\n            int32_t x_26044;\n            int64_t x_26045;\n            int64_t redout_26138;\n            int32_t redout_26139;\n            int64_t redout_26140;\n            \n            eta_p_26035 = mem_26343[(int64_t) 0];\n            acc_26037 = ext_mem_26378[(int64_t) 0];\n            redout_26138 = acc_26036;\n            redout_26139 = acc_26037;\n            redou", "t_26140 = acc_26038;\n            for (int64_t i_26141 = 0; i_26141 < residual_input_25982; i_26141++) {\n                int64_t x_26046;\n                int32_t x_26047;\n                bool defunc_0_neq_res_26055;\n                bool defunc_0_neq_res_26056;\n                bool cond_f_res_26057;\n                bool y_26058;\n                bool cond_26059;\n                bool defunc_0_neq_res_26060;\n                bool defunc_0_neq_res_26061;\n                bool cond_t_res_f_res_26062;\n                bool y_26063;\n                bool cond_t_res_26064;\n                bool x_26065;\n                int64_t defunc_0_op_res_26066;\n                int32_t defunc_0_op_res_26067;\n                int64_t defunc_0_op_res_26068;\n                int64_t redout_tmp_27324;\n                int32_t redout_tmp_27325;\n                int64_t redout_tmp_27326;\n                \n                x_26046 = ((__local int64_t *) color_27013)[i_26141];\n                x_26047 = ((__local int32_t *) color_27012)[i_26141];\n                defunc_0_neq_res_26055 = redout_26139 == eta_p_26035;\n                defunc_0_neq_res_26056 = !defunc_0_neq_res_26055;\n                cond_f_res_26057 = slt64(redout_26138, (int64_t) 0);\n                y_26058 = defunc_0_neq_res_26055 && cond_f_res_26057;\n                cond_26059 = defunc_0_neq_res_26056 || y_26058;\n                defunc_0_neq_res_26060 = x_26047 == eta_p_26035;\n                defunc_0_neq_res_26061 = !defunc_0_neq_res_26060;\n                cond_t_res_f_res_26062 = slt64(x_26046, (int64_t) 0);\n                y_26063 = defunc_0_neq_res_26060 && cond_t_res_f_res_26062;\n                cond_t_res_26064 = defunc_0_neq_res_26061 || y_26063;\n                x_26065 = cond_26059 && cond_t_res_26064;\n                if (x_26065) {\n                    defunc_0_op_res_26066 = (int64_t) -1;\n                    defunc_0_op_res_26067 = eta_p_26035;\n                    defunc_0_op_res_26068 = (int64_t) 0;\n                } else {\n        ", "            int64_t x_26048;\n                    int64_t defunc_0_op_res_f_res_26069;\n                    int32_t defunc_0_op_res_f_res_26070;\n                    int64_t defunc_0_op_res_f_res_26071;\n                    \n                    x_26048 = ((__local int64_t *) color_27011)[i_26141];\n                    if (cond_26059) {\n                        defunc_0_op_res_f_res_26069 = x_26046;\n                        defunc_0_op_res_f_res_26070 = x_26047;\n                        defunc_0_op_res_f_res_26071 = x_26048;\n                    } else {\n                        int32_t defunc_0_op_res_f_res_f_res_26072;\n                        int64_t defunc_0_op_res_f_res_f_res_26073;\n                        int64_t defunc_0_op_res_f_res_f_res_26074;\n                        \n                        if (cond_t_res_26064) {\n                            defunc_0_op_res_f_res_f_res_26072 = redout_26139;\n                        } else {\n                            defunc_0_op_res_f_res_f_res_26072 = eta_p_26035;\n                        }\n                        if (cond_t_res_26064) {\n                            defunc_0_op_res_f_res_f_res_26073 = redout_26138;\n                            defunc_0_op_res_f_res_f_res_26074 = redout_26140;\n                        } else {\n                            int64_t min_res_26075;\n                            int64_t tmp_26076;\n                            \n                            min_res_26075 = smin64(x_26046, redout_26138);\n                            tmp_26076 = add64(x_26048, redout_26140);\n                            defunc_0_op_res_f_res_f_res_26073 = min_res_26075;\n                            defunc_0_op_res_f_res_f_res_26074 = tmp_26076;\n                        }\n                        defunc_0_op_res_f_res_26069 = defunc_0_op_res_f_res_f_res_26073;\n                        defunc_0_op_res_f_res_26070 = defunc_0_op_res_f_res_f_res_26072;\n                        defunc_0_op_res_f_res_26071 = defunc_0_op_res_f_res_f_res_26074;\n     ",
                                    "               }\n                    defunc_0_op_res_26066 = defunc_0_op_res_f_res_26069;\n                    defunc_0_op_res_26067 = defunc_0_op_res_f_res_26070;\n                    defunc_0_op_res_26068 = defunc_0_op_res_f_res_26071;\n                }\n                redout_tmp_27324 = defunc_0_op_res_26066;\n                redout_tmp_27325 = defunc_0_op_res_26067;\n                redout_tmp_27326 = defunc_0_op_res_26068;\n                redout_26138 = redout_tmp_27324;\n                redout_26139 = redout_tmp_27325;\n                redout_26140 = redout_tmp_27326;\n            }\n            x_26043 = redout_26138;\n            x_26044 = redout_26139;\n            x_26045 = redout_26140;\n            acc_26040 = x_26043;\n            acc_26042 = x_26045;\n        } else {\n            acc_26040 = acc_26036;\n            acc_26042 = acc_26038;\n        }\n        mem_26389[(int64_t) 0] = acc_26040;\n        mem_26393[(int64_t) 0] = acc_26042;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_17 = 0; i_17 < 1; i_17++)\n            ext_mem_26395[i_17] = mem_26389[i_17];\n        for (int32_t i_18 = 0; i_18 < 1; i_18++)\n            ext_mem_26394[i_18] = mem_26393[i_18];\n    }\n    if (slt64(sext_i32_i64(local_tid_27306) + tile_sizze_25742 * sext_i32_i64(block_id_27307), min_res_22136)) {\n        int64_t tmp_27327 = ext_mem_26395[(int64_t) 0];\n        \n        ((__global int64_t *) mem_26397)[sext_i32_i64(local_tid_27306) + tile_sizze_25742 * sext_i32_i64(block_id_27307)] = tmp_27327;\n    }\n    if (slt64(sext_i32_i64(local_tid_27306) + tile_sizze_25742 * sext_i32_i64(block_id_27307), min_res_22136)) {\n        int64_t tmp_27328 = ext_mem_26394[(int64_t) 0];\n        \n        ((__global int64_t *) mem_26399)[sext_i32_i64(local_tid_27306) + tile_sizze_25742 * sext_i32_i64(block_id_27307)] = tmp_27328;\n    }\n    \n  error_8:\n    return;\n    #undef tile_sizze_25742\n    #undef bytes_26359\n    #undef bytes_26361\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzisegscan_24583_dim1, 1, 1)\nvoid", " inner_SMJ_intzisegscan_24583(__global int *global_failure, int64_t nR_17046, int64_t num_tblocks_24580, int64_t num_virt_blocks_27396, int64_t num_virt_threads_27397, __global unsigned char *ext_mem_26714, __global unsigned char *mem_26717, __global unsigned char *mem_26719, __global unsigned char *status_flags_mem_27398, __global unsigned char *aggregates_mem_27420, __global unsigned char *incprefixes_mem_27422, __global unsigned char *global_dynid_mem_27424)\n{\n    #define segscan_tblock_sizze_24578 (inner_SMJ_intzisegscan_24583zisegscan_tblock_sizze_24578)\n    #define chunk_sizze_27395 (inner_SMJ_intzisegscan_24583zichunk_sizze_27395)\n    \n    volatile __local unsigned char *local_mem_27434_backing_0 = &shared_mem[0];\n    const int64_t local_mem_27434_backing_0_offset = 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_24578), chunk_sizze_27395 * segscan_tblock_sizze_24578 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_24578), chunk_sizze_27395 * segscan_tblock_sizze_24578 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27427;\n    int32_t tblock_sizze_27430;\n    int32_t wave_sizze_27429;\n    int32_t block_id_27428;\n    int32_t global_tid_27426;\n    int64_t phys_tid_24583;\n    int32_t chunk_sizze_32b_27431;\n    int64_t byte_offsets_27432;\n    int64_t warp_byte_offset_27433;\n    __local unsigned char *local_mem_27434;\n    int64_t trans_arr_len_27435;\n    int64_t phys_block_id_27441;\n    int64_t virtloop_bound_27442;\n    \n    local_tid_27427 = get_local_id(0);\n    tblock_sizze_27430 = get_local_size(0);\n    wave_sizze_27429 = LOCKSTEP_WIDTH;\n    block_id_27428 = get_tblock_id(0);\n    global_tid_27426 = block_id_27428 * tblock_sizze_27430 + local_tid_27427;\n    phys_tid_24583 = sext_i32_i64(global_tid_27426);\n    chunk_sizze_32b_27431 = sext_i64_i32(chunk_sizze_27395);\n    byte_offsets_27432 = segscan_tblock_sizze", "_24578 * (int64_t) 8;\n    warp_byte_offset_27433 = (int64_t) 288;\n    // Allocate reusable shared memory\n    { }\n    local_mem_27434 = (__local unsigned char *) local_mem_27434_backing_0;\n    trans_arr_len_27435 = chunk_sizze_27395 * segscan_tblock_sizze_24578;\n    phys_block_id_27441 = get_tblock_id(0);\n    virtloop_bound_27442 = sdiv_up64(num_virt_blocks_27396 - phys_block_id_27441, num_tblocks_24580);\n    for (int64_t virtloop_i_27443 = 0; virtloop_i_27443 < virtloop_bound_27442; virtloop_i_27443++) {\n        int64_t dynamic_id_27444;\n        int64_t block_offset_27445;\n        int64_t sgm_idx_27446;\n        int32_t boundary_27447;\n        int32_t segsizze_compact_27448;\n        int64_t private_mem_27449[chunk_sizze_27395];\n        int64_t thd_offset_27451;\n        int64_t acc_27467;\n        int64_t prefix_27477;\n        bool block_new_sgm_27478;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_27427 == 0) {\n                dynamic_id_27444 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_27424)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_27434)[(int64_t) 0] = dynamic_id_27444;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_27444 == num_virt_blocks_27396 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_27424)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_27444 = ((__local int32_t *) local_mem_27434)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_27445 = dynamic_id_27444 * chunk_sizze_27395 * segscan_tblock_sizze_24578;\n        sgm_idx_27446 = smod64(block_offset_27445, nR_17046);\n        boundary_27447 = sext_i64_i32(smin64(chunk_sizze_2",
                                    "7395 * segscan_tblock_sizze_24578, nR_17046 - sgm_idx_27446));\n        segsizze_compact_27448 = sext_i64_i32(smin64(chunk_sizze_27395 * segscan_tblock_sizze_24578, nR_17046));\n        thd_offset_27451 = block_offset_27445 + sext_i32_i64(local_tid_27427);\n        // Load and map\n        {\n            for (int64_t i_27452 = 0; i_27452 < chunk_sizze_27395; i_27452++) {\n                int64_t virt_tid_27453 = thd_offset_27451 + i_27452 * segscan_tblock_sizze_24578;\n                int64_t slice_27454 = nR_17046;\n                int64_t gtid_24582 = virt_tid_27453;\n                int64_t remnant_27455 = virt_tid_27453 - gtid_24582;\n                \n                if (slt64(virt_tid_27453, nR_17046)) {\n                    int64_t eta_p_22558 = ((__global int64_t *) ext_mem_26714)[gtid_24582];\n                    bool lifted_lambda_res_22559 = slt64((int64_t) 0, eta_p_22558);\n                    int64_t defunc_0_f_res_22560 = btoi_bool_i64(lifted_lambda_res_22559);\n                    \n                    ((__global int64_t *) mem_26719)[gtid_24582] = defunc_0_f_res_22560;\n                    private_mem_27449[i_27452] = defunc_0_f_res_22560;\n                } else {\n                    private_mem_27449[i_27452] = (int64_t) 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_27456 = 0; i_27456 < chunk_sizze_27395; i_27456++) {\n                int64_t sharedIdx_27457 = sext_i32_i64(local_tid_27427) + i_27456 * segscan_tblock_sizze_24578;\n                int64_t tmp_27458 = private_mem_27449[i_27456];\n                \n                ((__local int64_t *) local_mem_27434)[sharedIdx_27457] = tmp_27458;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_27459 = 0; i_27459 < chunk_sizze_27395; i_27459++) {\n                int64_t sharedIdx_27460 = sext_i32_i64(local_tid_27427) * chunk_sizze_27395 + i_27459;\n                int64_t tmp_27461 = (", "(__local int64_t *) local_mem_27434)[sharedIdx_27460];\n                \n                private_mem_27449[i_27459] = tmp_27461;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_27462 = 0; i_27462 < chunk_sizze_27395 - (int64_t) 1; i_27462++) {\n                int64_t eta_p_22269;\n                int64_t eta_p_22270;\n                \n                eta_p_22269 = private_mem_27449[i_27462];\n                eta_p_22270 = private_mem_27449[i_27462 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_22271 = add64(eta_p_22269, eta_p_22270);\n                \n                private_mem_27449[i_27462 + (int64_t) 1] = defunc_0_op_res_22271;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_27463 = private_mem_27449[chunk_sizze_27395 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_27434)[sext_i32_i64(local_tid_27427)] = tmp_27463;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_27464;\n            int64_t eta_p_27465;\n            int64_t eta_p_27468;\n            int64_t eta_p_27469;\n            bool ltid_in_bounds_27471 = slt64(sext_i32_i64(local_tid_27427), num_virt_threads_27397);\n            int32_t skip_threads_27472;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_27471) {\n                    eta_p_27465 = ((volatile __local int64_t *) local_mem_27434)[sext_i32_i64(local_tid_27427)];\n                    if ((local_tid_27427 - squot32(local_tid_27427, 32) * 32) == 0) {\n                        eta_p_27464 = eta_p_27465;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_27472 = 1;\n                while (slt32(skip_threads_27472, 32)) {\n                    bo", "ol thread_active_27473 = sle32(skip_threads_27472, local_tid_27427 - squot32(local_tid_27427, 32) * 32) && ltid_in_bounds_27471;\n                    \n                    if (thread_active_27473) {\n                        // read operands\n                        {\n                            eta_p_27464 = ((volatile __local int64_t *) local_mem_27434)[sext_i32_i64(local_tid_27427) - sext_i32_i64(skip_threads_27472)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_27473) {\n                            int64_t defunc_0_op_res_27466 = add64(eta_p_27464, eta_p_27465);\n                            \n                            eta_p_27464 = defunc_0_op_res_27466;\n                        }\n                    }\n                    if (sle32(wave_sizze_27429, skip_threads_27472)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_27473) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_27434)[sext_i32_i64(local_tid_27427)] = eta_p_27464;\n                            eta_p_27465 = eta_p_27464;\n                        }\n                    }\n                    if (sle32(wave_sizze_27429, skip_threads_27472)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_27472 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_27427 - squot32(local_tid_27427, 32) * 32) == 31 && ltid_in_bounds_27471) {\n                    ((volatile __local int64_t *) local_mem_27434)[sext_i32_i64(squot32(local_tid_27427, 32))] = eta_p_27464;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, aft",
                                    "er which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_27474;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_27427, 32) == 0 && ltid_in_bounds_27471) {\n                        eta_p_27469 = ((volatile __local int64_t *) local_mem_27434)[sext_i32_i64(local_tid_27427)];\n                        if ((local_tid_27427 - squot32(local_tid_27427, 32) * 32) == 0) {\n                            eta_p_27468 = eta_p_27469;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_27474 = 1;\n                    while (slt32(skip_threads_27474, 32)) {\n                        bool thread_active_27475 = sle32(skip_threads_27474, local_tid_27427 - squot32(local_tid_27427, 32) * 32) && (squot32(local_tid_27427, 32) == 0 && ltid_in_bounds_27471);\n                        \n                        if (thread_active_27475) {\n                            // read operands\n                            {\n                                eta_p_27468 = ((volatile __local int64_t *) local_mem_27434)[sext_i32_i64(local_tid_27427) - sext_i32_i64(skip_threads_27474)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_27475) {\n                                int64_t defunc_0_op_res_27470 = add64(eta_p_27468, eta_p_27469);\n                                \n                                eta_p_27468 = defunc_0_op_res_27470;\n                            }\n                        }\n                        if (sle32(wave_sizze_27429, skip_threads_27474)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_27475) {\n                            // write result\n          ", "                  {\n                                ((volatile __local int64_t *) local_mem_27434)[sext_i32_i64(local_tid_27427)] = eta_p_27468;\n                                eta_p_27469 = eta_p_27468;\n                            }\n                        }\n                        if (sle32(wave_sizze_27429, skip_threads_27474)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_27474 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_27476 = squot32(local_tid_27427, 32) == 0 || !ltid_in_bounds_27471;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_27476) {\n                        eta_p_27465 = eta_p_27464;\n                        eta_p_27464 = ((__local int64_t *) local_mem_27434)[sext_i32_i64(squot32(local_tid_27427, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_27476) {\n                        int64_t defunc_0_op_res_27466 = add64(eta_p_27464, eta_p_27465);\n                        \n                        eta_p_27464 = defunc_0_op_res_27466;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_27476) {\n                        ((__local int64_t *) local_mem_27434)[sext_i32_i64(local_tid_27427)] = eta_p_27464;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_27427, 32) == 0 && ltid_in_bounds_27471) {\n                    ((__local int64_t *) local_mem_27434)[sext_i32_i64(local_tid_27427)] = eta_p_27465;\n                }\n            }\n            ", "barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_27427 == 0) {\n                acc_27467 = ((__local int64_t *) local_mem_27434)[segscan_tblock_sizze_24578 - (int64_t) 1];\n            } else {\n                acc_27467 = ((__local int64_t *) local_mem_27434)[sext_i32_i64(local_tid_27427) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_27477 = (int64_t) 0;\n        block_new_sgm_27478 = sgm_idx_27446 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_27478 && local_tid_27427 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_27422)[dynamic_id_27444] = acc_27467;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_27398)[dynamic_id_27444] = (int8_t) 2;\n                acc_27467 = (int64_t) 0;\n            }\n            if (!block_new_sgm_27478 && slt32(local_tid_27427, wave_sizze_27429)) {\n                if (local_tid_27427 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_27420)[dynamic_id_27444] = acc_27467;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_27398)[dynamic_id_27444] = (int8_t) 1;\n                    \n                    int8_t tmp_27479 = ((volatile __global int8_t *) status_flags_mem_27398)[dynamic_id_27444 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_27434)[(int64_t) 0] = tmp_27479;\n                }\n                mem_fence_local();\n                \n                int8_t status_27480 = ((__local int8_t *) local_mem_27434)[(int64_t) 0];\n                \n                if (status_27480 == (int8_t) 2) {\n                    if (local_tid_27427 == 0) {\n                        prefix_27477 = ((volatile __global int64_t *) incprefixes_mem_27422)[dynamic_id_27444 - (int64_t) 1];\n                    }\n                } else {\n    ",
                                    "                int32_t readOffset_27481 = sext_i64_i32(dynamic_id_27444 - sext_i32_i64(wave_sizze_27429));\n                    \n                    while (slt32(wave_sizze_27429 * -1, readOffset_27481)) {\n                        int32_t read_i_27482 = readOffset_27481 + local_tid_27427;\n                        int64_t aggr_27483 = (int64_t) 0;\n                        int8_t flag_27484 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_27482)) {\n                            flag_27484 = ((volatile __global int8_t *) status_flags_mem_27398)[sext_i32_i64(read_i_27482)];\n                            if (flag_27484 == (int8_t) 2) {\n                                aggr_27483 = ((volatile __global int64_t *) incprefixes_mem_27422)[sext_i32_i64(read_i_27482)];\n                            } else if (flag_27484 == (int8_t) 1) {\n                                aggr_27483 = ((volatile __global int64_t *) aggregates_mem_27420)[sext_i32_i64(read_i_27482)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_27434)[(int64_t) 4 + sext_i32_i64(local_tid_27427)] = aggr_27483;\n                        ((__local int8_t *) local_mem_27434)[sext_i32_i64(local_tid_27427)] = flag_27484;\n                        flag_27484 = ((__local int8_t *) local_mem_27434)[sext_i32_i64(wave_sizze_27429) - (int64_t) 1];\n                        if (slt8(flag_27484, (int8_t) 2)) {\n                            int8_t flg_x_27488;\n                            int8_t flg_y_27489;\n                            int64_t eta_p_27485;\n                            int64_t eta_p_27486;\n                            int32_t skip_threads_27490;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_27489 = ((volatile __local int8_t *) local_mem_27434)[sext_i32_i64(local_tid_27427)];\n                                eta_p_27486 = ((volatil", "e __local int64_t *) local_mem_27434)[(int64_t) 4 + sext_i32_i64(local_tid_27427)];\n                                if ((local_tid_27427 - squot32(local_tid_27427, 32) * 32) == 0) {\n                                    eta_p_27485 = eta_p_27486;\n                                    flg_x_27488 = flg_y_27489;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_27490 = 1;\n                                while (slt32(skip_threads_27490, 32)) {\n                                    if (sle32(skip_threads_27490, local_tid_27427 - squot32(local_tid_27427, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_27488 = ((volatile __local int8_t *) local_mem_27434)[sext_i32_i64(local_tid_27427) - sext_i32_i64(skip_threads_27490)];\n                                            eta_p_27485 = ((volatile __local int64_t *) local_mem_27434)[(int64_t) 4 + (sext_i32_i64(local_tid_27427) - sext_i32_i64(skip_threads_27490))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_27489 == (int8_t) 2 || flg_y_27489 == (int8_t) 0) {\n                                                flg_x_27488 = flg_y_27489;\n                                                eta_p_27485 = eta_p_27486;\n                                            } else {\n                                                int64_t defunc_0_op_res_27487 = add64(eta_p_27485, eta_p_27486);\n                                                \n                                                eta_p_27485 = defunc_0_op_res_27487;\n                                            }\n                                        }\n                         ", "               // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_27434)[sext_i32_i64(local_tid_27427)] = flg_x_27488;\n                                            flg_y_27489 = flg_x_27488;\n                                            ((volatile __local int64_t *) local_mem_27434)[(int64_t) 4 + sext_i32_i64(local_tid_27427)] = eta_p_27485;\n                                            eta_p_27486 = eta_p_27485;\n                                        }\n                                    }\n                                    skip_threads_27490 *= 2;\n                                }\n                            }\n                        }\n                        flag_27484 = ((__local int8_t *) local_mem_27434)[sext_i32_i64(wave_sizze_27429) - (int64_t) 1];\n                        aggr_27483 = ((__local int64_t *) local_mem_27434)[(int64_t) 4 + (sext_i32_i64(wave_sizze_27429) - (int64_t) 1)];\n                        if (flag_27484 == (int8_t) 2) {\n                            readOffset_27481 = wave_sizze_27429 * -1;\n                        } else if (flag_27484 == (int8_t) 1) {\n                            readOffset_27481 -= wave_sizze_27429;\n                        }\n                        if (slt8((int8_t) 0, flag_27484)) {\n                            int64_t eta_p_27491 = aggr_27483;\n                            int64_t eta_p_27492 = prefix_27477;\n                            int64_t defunc_0_op_res_27493 = add64(eta_p_27491, eta_p_27492);\n                            \n                            prefix_27477 = defunc_0_op_res_27493;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_27427 == 0) {\n                    if (boundary_27447 == sext_i64_i32(segscan_tblock_sizze_24578 * chunk_sizze_27395)) {\n                        int64_t eta_p_27494 = prefix_27477;\n                        int64_t et",
                                    "a_p_27495 = acc_27467;\n                        int64_t defunc_0_op_res_27496 = add64(eta_p_27494, eta_p_27495);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_27422)[dynamic_id_27444] = defunc_0_op_res_27496;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_27398)[dynamic_id_27444] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_27434)[(int64_t) 4] = prefix_27477;\n                    acc_27467 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_27444 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_27477 = ((__local int64_t *) local_mem_27434)[(int64_t) 4];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_27497;\n            int64_t eta_p_27498;\n            int64_t eta_p_27500 = prefix_27477;\n            int64_t eta_p_27501 = acc_27467;\n            \n            if (slt32(local_tid_27427 * chunk_sizze_32b_27431, boundary_27447) && !block_new_sgm_27478) {\n                int64_t defunc_0_op_res_27502 = add64(eta_p_27500, eta_p_27501);\n                \n                eta_p_27497 = defunc_0_op_res_27502;\n            } else {\n                eta_p_27497 = acc_27467;\n            }\n            \n            int32_t stopping_point_27503 = segsizze_compact_27448 - srem32(local_tid_27427 * chunk_sizze_32b_27431 - 1 + segsizze_compact_27448 - boundary_27447, segsizze_compact_27448);\n            \n            for (int64_t i_27504 = 0; i_27504 < chunk_sizze_27395; i_27504++) {\n                if (slt32(sext_i64_i32(i_27504), stopping_point_27503 - 1)) {\n                    eta_p_27498 = private_mem_27449[i_27504];\n                    \n                    int64_t defunc_0_op_res_27499 = add64(eta_p_27497, eta_p_27498);\n                    \n                    private_mem_27449[i_2750", "4] = defunc_0_op_res_27499;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_27505 = 0; i_27505 < chunk_sizze_27395; i_27505++) {\n                int64_t sharedIdx_27506 = sext_i32_i64(local_tid_27427) * chunk_sizze_27395 + i_27505;\n                int64_t tmp_27507 = private_mem_27449[i_27505];\n                \n                ((__local int64_t *) local_mem_27434)[sharedIdx_27506] = tmp_27507;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_27508 = 0; i_27508 < chunk_sizze_27395; i_27508++) {\n                int64_t flat_idx_27509 = thd_offset_27451 + i_27508 * segscan_tblock_sizze_24578;\n                int64_t slice_27510 = nR_17046;\n                int64_t gtid_24582 = flat_idx_27509;\n                int64_t remnant_27511 = flat_idx_27509 - gtid_24582;\n                \n                if (slt64(flat_idx_27509, nR_17046)) {\n                    int64_t tmp_27512 = ((__local int64_t *) local_mem_27434)[flat_idx_27509 - block_offset_27445];\n                    \n                    ((__global int64_t *) mem_26717)[gtid_24582] = tmp_27512;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_24578\n    #undef chunk_sizze_27395\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzisegscan_24599_dim1, 1, 1)\nvoid inner_SMJ_intzisegscan_24599(__global int *global_failure, int64_t m_22282, int64_t num_tblocks_24596, int64_t num_virt_blocks_27533, int64_t num_virt_threads_27534, __global unsigned char *mem_26721, __global unsigned char *mem_26731, __global unsigned char *mem_26733, __global unsigned char *mem_26735, __global unsigned char *status_flags_mem_27535, __global unsigned char *aggregates_mem_27537, __global unsigned char *incprefixes_mem_27539, __global unsigned char *aggregates_mem_27541, __global unsigned char *incprefixes_mem_27543, __g", "lobal unsigned char *global_dynid_mem_27545)\n{\n    #define segscan_tblock_sizze_24594 (inner_SMJ_intzisegscan_24599zisegscan_tblock_sizze_24594)\n    #define chunk_sizze_27532 (inner_SMJ_intzisegscan_24599zichunk_sizze_27532)\n    \n    volatile __local unsigned char *local_mem_27557_backing_0 = &shared_mem[0];\n    const int64_t local_mem_27557_backing_0_offset = 0 + (smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_24594, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_24594), smax64(chunk_sizze_27532 * segscan_tblock_sizze_24594 * (int64_t) 8, chunk_sizze_27532 * segscan_tblock_sizze_24594 * (int64_t) 8)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_24594, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_24594), smax64(chunk_sizze_27532 * segscan_tblock_sizze_24594 * (int64_t) 8, chunk_sizze_27532 * segscan_tblock_sizze_24594 * (int64_t) 8)), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_27548;\n    int32_t tblock_sizze_27551;\n    int32_t wave_sizze_27550;\n    int32_t block_id_27549;\n    int32_t global_tid_27547;\n    int64_t phys_tid_24599;\n    int32_t chunk_sizze_32b_27552;\n    int64_t byte_offsets_27553;\n    int64_t byte_offsets_27554;\n    int64_t warp_byte_offset_27555;\n    int64_t warp_byte_offset_27556;\n    __local unsigned char *local_mem_27557;\n    int64_t trans_arr_len_27558;\n    int64_t phys_block_id_27567;\n    int64_t virtloop_bound_27568;\n    \n    local_tid_27548 = get_local_id(0);\n    tblock_sizze_27551 = get_local_size(0);\n    wave_sizze_27550 = LOCKSTEP_WIDTH;\n    block_id_27549 = get_tblock_id(0);\n    global_tid_27547 = block_id_27549 * tblock_sizze_27551 + local_tid_27548;\n    phys_tid_24599 = sext_i32_i64(global_tid_27547);\n    chunk_sizze_32b_27552 = sext_i64_i32(chunk_sizze_27532);\n    byte_offsets_27553 = segscan_tblock_sizze_24594 * (int64_t) 8;\n    byte_offsets_27554 = sdiv",
                                    "_up64(byte_offsets_27553, (int64_t) 8) * (int64_t) 8 + segscan_tblock_sizze_24594 * (int64_t) 8;\n    warp_byte_offset_27555 = (int64_t) 288;\n    warp_byte_offset_27556 = sdiv_up64(warp_byte_offset_27555, (int64_t) 8) * (int64_t) 8 + (int64_t) 256;\n    // Allocate reusable shared memory\n    { }\n    local_mem_27557 = (__local unsigned char *) local_mem_27557_backing_0;\n    trans_arr_len_27558 = chunk_sizze_27532 * segscan_tblock_sizze_24594;\n    phys_block_id_27567 = get_tblock_id(0);\n    virtloop_bound_27568 = sdiv_up64(num_virt_blocks_27533 - phys_block_id_27567, num_tblocks_24596);\n    for (int64_t virtloop_i_27569 = 0; virtloop_i_27569 < virtloop_bound_27568; virtloop_i_27569++) {\n        int64_t dynamic_id_27570;\n        int64_t block_offset_27571;\n        int64_t sgm_idx_27572;\n        int32_t boundary_27573;\n        int32_t segsizze_compact_27574;\n        int64_t private_mem_27575[chunk_sizze_27532];\n        int64_t private_mem_27577[chunk_sizze_27532];\n        int64_t thd_offset_27579;\n        int64_t acc_27605;\n        int64_t acc_27606;\n        int64_t prefix_27619;\n        int64_t prefix_27620;\n        bool block_new_sgm_27621;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_27548 == 0) {\n                dynamic_id_27570 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_27545)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_27557)[(int64_t) 0] = dynamic_id_27570;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_27570 == num_virt_blocks_27533 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_27545)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_27570 = ((__local int", "32_t *) local_mem_27557)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_27571 = dynamic_id_27570 * chunk_sizze_27532 * segscan_tblock_sizze_24594;\n        sgm_idx_27572 = smod64(block_offset_27571, m_22282);\n        boundary_27573 = sext_i64_i32(smin64(chunk_sizze_27532 * segscan_tblock_sizze_24594, m_22282 - sgm_idx_27572));\n        segsizze_compact_27574 = sext_i64_i32(smin64(chunk_sizze_27532 * segscan_tblock_sizze_24594, m_22282));\n        thd_offset_27579 = block_offset_27571 + sext_i32_i64(local_tid_27548);\n        // Load and map\n        {\n            for (int64_t i_27580 = 0; i_27580 < chunk_sizze_27532; i_27580++) {\n                int64_t virt_tid_27581 = thd_offset_27579 + i_27580 * segscan_tblock_sizze_24594;\n                int64_t slice_27582 = m_22282;\n                int64_t gtid_24598 = virt_tid_27581;\n                int64_t remnant_27583 = virt_tid_27581 - gtid_24598;\n                \n                if (slt64(virt_tid_27581, m_22282)) {\n                    int64_t x_22563 = ((__global int64_t *) mem_26721)[gtid_24598];\n                    bool lifted_lambda_res_22565 = slt64((int64_t) 1, x_22563);\n                    int64_t defunc_0_f_res_22566 = btoi_bool_i64(lifted_lambda_res_22565);\n                    \n                    ((__global int64_t *) mem_26735)[gtid_24598] = defunc_0_f_res_22566;\n                    private_mem_27575[i_27580] = x_22563;\n                    private_mem_27577[i_27580] = defunc_0_f_res_22566;\n                } else {\n                    private_mem_27575[i_27580] = (int64_t) 0;\n                    private_mem_27577[i_27580] = (int64_t) 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_27584 = 0; i_27584 < chunk_sizze_27532; i_27584++) {\n                int64_t sharedIdx_27585 = sext_i32_i64(local_tid_27548) + i_27584 * segscan_tblock_sizze_24594;\n                int64_t tmp_27586 = private_m", "em_27575[i_27584];\n                \n                ((__local int64_t *) local_mem_27557)[sharedIdx_27585] = tmp_27586;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_27587 = 0; i_27587 < chunk_sizze_27532; i_27587++) {\n                int64_t sharedIdx_27588 = sext_i32_i64(local_tid_27548) * chunk_sizze_27532 + i_27587;\n                int64_t tmp_27589 = ((__local int64_t *) local_mem_27557)[sharedIdx_27588];\n                \n                private_mem_27575[i_27587] = tmp_27589;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_27590 = 0; i_27590 < chunk_sizze_27532; i_27590++) {\n                int64_t sharedIdx_27591 = sext_i32_i64(local_tid_27548) + i_27590 * segscan_tblock_sizze_24594;\n                int64_t tmp_27592 = private_mem_27577[i_27590];\n                \n                ((__local int64_t *) local_mem_27557)[sharedIdx_27591] = tmp_27592;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_27593 = 0; i_27593 < chunk_sizze_27532; i_27593++) {\n                int64_t sharedIdx_27594 = sext_i32_i64(local_tid_27548) * chunk_sizze_27532 + i_27593;\n                int64_t tmp_27595 = ((__local int64_t *) local_mem_27557)[sharedIdx_27594];\n                \n                private_mem_27577[i_27593] = tmp_27595;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_27596 = 0; i_27596 < chunk_sizze_27532 - (int64_t) 1; i_27596++) {\n                int64_t eta_p_22319;\n                int64_t eta_p_22320;\n                \n                eta_p_22319 = private_mem_27575[i_27596];\n                eta_p_22320 = private_mem_27575[i_27596 + (int64_t) 1];\n                \n                int64_t eta_p_22412;\n                int64_t eta_p_22413;\n                \n                eta_p_22412 = private_mem_27577[i_27596];\n                eta_p_22413 = private_mem_27577[i_27596 + (int64_t) 1];\n   ",
                                    "             \n                int64_t lifted_lambda_res_22321 = add64(eta_p_22319, eta_p_22320);\n                int64_t defunc_0_op_res_22414 = add64(eta_p_22412, eta_p_22413);\n                \n                private_mem_27575[i_27596 + (int64_t) 1] = lifted_lambda_res_22321;\n                private_mem_27577[i_27596 + (int64_t) 1] = defunc_0_op_res_22414;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_27597 = private_mem_27575[chunk_sizze_27532 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_27557)[sext_i32_i64(local_tid_27548)] = tmp_27597;\n            \n            int64_t tmp_27598 = private_mem_27577[chunk_sizze_27532 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_27557)[squot64(byte_offsets_27553, (int64_t) 8) + sext_i32_i64(local_tid_27548)] = tmp_27598;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_27599;\n            int64_t eta_p_27600;\n            int64_t eta_p_27601;\n            int64_t eta_p_27602;\n            int64_t eta_p_27607;\n            int64_t eta_p_27608;\n            int64_t eta_p_27609;\n            int64_t eta_p_27610;\n            bool ltid_in_bounds_27613 = slt64(sext_i32_i64(local_tid_27548), num_virt_threads_27534);\n            int32_t skip_threads_27614;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_27613) {\n                    eta_p_27601 = ((volatile __local int64_t *) local_mem_27557)[sext_i32_i64(local_tid_27548)];\n                    eta_p_27602 = ((volatile __local int64_t *) local_mem_27557)[squot64(byte_offsets_27553, (int64_t) 8) + sext_i32_i64(local_tid_27548)];\n                    if ((local_tid_27548 - squot32(local_tid_27548, 32) * 32) == 0) {\n                        eta_p_27599 = eta_p_27601;\n                        eta_p_27600 = eta_p_27602;\n                    }\n                }\n  ", "          }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_27614 = 1;\n                while (slt32(skip_threads_27614, 32)) {\n                    bool thread_active_27615 = sle32(skip_threads_27614, local_tid_27548 - squot32(local_tid_27548, 32) * 32) && ltid_in_bounds_27613;\n                    \n                    if (thread_active_27615) {\n                        // read operands\n                        {\n                            eta_p_27599 = ((volatile __local int64_t *) local_mem_27557)[sext_i32_i64(local_tid_27548) - sext_i32_i64(skip_threads_27614)];\n                            eta_p_27600 = ((volatile __local int64_t *) local_mem_27557)[squot64(byte_offsets_27553, (int64_t) 8) + (sext_i32_i64(local_tid_27548) - sext_i32_i64(skip_threads_27614))];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_27615) {\n                            int64_t lifted_lambda_res_27603 = add64(eta_p_27599, eta_p_27601);\n                            int64_t defunc_0_op_res_27604 = add64(eta_p_27600, eta_p_27602);\n                            \n                            eta_p_27599 = lifted_lambda_res_27603;\n                            eta_p_27600 = defunc_0_op_res_27604;\n                        }\n                    }\n                    if (sle32(wave_sizze_27550, skip_threads_27614)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_27615) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_27557)[sext_i32_i64(local_tid_27548)] = eta_p_27599;\n                            eta_p_27601 = eta_p_27599;\n                            ((volatile __local int64_t *) local_mem_27557)[squot64(byte_offsets_27553, (int64_t) 8) + sext_i32_i64(local_tid_27548)] = eta_p_27600;\n                ", "            eta_p_27602 = eta_p_27600;\n                        }\n                    }\n                    if (sle32(wave_sizze_27550, skip_threads_27614)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_27614 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_27548 - squot32(local_tid_27548, 32) * 32) == 31 && ltid_in_bounds_27613) {\n                    ((volatile __local int64_t *) local_mem_27557)[sext_i32_i64(squot32(local_tid_27548, 32))] = eta_p_27599;\n                    ((volatile __local int64_t *) local_mem_27557)[squot64(byte_offsets_27553, (int64_t) 8) + sext_i32_i64(squot32(local_tid_27548, 32))] = eta_p_27600;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_27616;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_27548, 32) == 0 && ltid_in_bounds_27613) {\n                        eta_p_27609 = ((volatile __local int64_t *) local_mem_27557)[sext_i32_i64(local_tid_27548)];\n                        eta_p_27610 = ((volatile __local int64_t *) local_mem_27557)[squot64(byte_offsets_27553, (int64_t) 8) + sext_i32_i64(local_tid_27548)];\n                        if ((local_tid_27548 - squot32(local_tid_27548, 32) * 32) == 0) {\n                            eta_p_27607 = eta_p_27609;\n                            eta_p_27608 = eta_p_27610;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_27616 = 1;\n                    while (slt32(skip_threads_27616, 32)) {\n                        bool thread_",
                                    "active_27617 = sle32(skip_threads_27616, local_tid_27548 - squot32(local_tid_27548, 32) * 32) && (squot32(local_tid_27548, 32) == 0 && ltid_in_bounds_27613);\n                        \n                        if (thread_active_27617) {\n                            // read operands\n                            {\n                                eta_p_27607 = ((volatile __local int64_t *) local_mem_27557)[sext_i32_i64(local_tid_27548) - sext_i32_i64(skip_threads_27616)];\n                                eta_p_27608 = ((volatile __local int64_t *) local_mem_27557)[squot64(byte_offsets_27553, (int64_t) 8) + (sext_i32_i64(local_tid_27548) - sext_i32_i64(skip_threads_27616))];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_27617) {\n                                int64_t lifted_lambda_res_27611 = add64(eta_p_27607, eta_p_27609);\n                                int64_t defunc_0_op_res_27612 = add64(eta_p_27608, eta_p_27610);\n                                \n                                eta_p_27607 = lifted_lambda_res_27611;\n                                eta_p_27608 = defunc_0_op_res_27612;\n                            }\n                        }\n                        if (sle32(wave_sizze_27550, skip_threads_27616)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_27617) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_27557)[sext_i32_i64(local_tid_27548)] = eta_p_27607;\n                                eta_p_27609 = eta_p_27607;\n                                ((volatile __local int64_t *) local_mem_27557)[squot64(byte_offsets_27553, (int64_t) 8) + sext_i32_i64(local_tid_27548)] = eta_p_27608;\n                                eta_p_27610 = eta_p_27608;\n                        ", "    }\n                        }\n                        if (sle32(wave_sizze_27550, skip_threads_27616)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_27616 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_27618 = squot32(local_tid_27548, 32) == 0 || !ltid_in_bounds_27613;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_27618) {\n                        eta_p_27601 = eta_p_27599;\n                        eta_p_27602 = eta_p_27600;\n                        eta_p_27599 = ((__local int64_t *) local_mem_27557)[sext_i32_i64(squot32(local_tid_27548, 32)) - (int64_t) 1];\n                        eta_p_27600 = ((__local int64_t *) local_mem_27557)[squot64(byte_offsets_27553, (int64_t) 8) + (sext_i32_i64(squot32(local_tid_27548, 32)) - (int64_t) 1)];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_27618) {\n                        int64_t lifted_lambda_res_27603 = add64(eta_p_27599, eta_p_27601);\n                        int64_t defunc_0_op_res_27604 = add64(eta_p_27600, eta_p_27602);\n                        \n                        eta_p_27599 = lifted_lambda_res_27603;\n                        eta_p_27600 = defunc_0_op_res_27604;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_27618) {\n                        ((__local int64_t *) local_mem_27557)[sext_i32_i64(local_tid_27548)] = eta_p_27599;\n                        ((__local int64_t *) local_mem_27557)[squot64(byte_offsets_27553, (int64_t) 8) + sext_i32_i64(local_tid_27548)] = eta_p_27600;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_M", "EM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_27548, 32) == 0 && ltid_in_bounds_27613) {\n                    ((__local int64_t *) local_mem_27557)[sext_i32_i64(local_tid_27548)] = eta_p_27601;\n                    ((__local int64_t *) local_mem_27557)[squot64(byte_offsets_27553, (int64_t) 8) + sext_i32_i64(local_tid_27548)] = eta_p_27602;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_27548 == 0) {\n                acc_27605 = ((__local int64_t *) local_mem_27557)[segscan_tblock_sizze_24594 - (int64_t) 1];\n                acc_27606 = ((__local int64_t *) local_mem_27557)[squot64(byte_offsets_27553, (int64_t) 8) + (segscan_tblock_sizze_24594 - (int64_t) 1)];\n            } else {\n                acc_27605 = ((__local int64_t *) local_mem_27557)[sext_i32_i64(local_tid_27548) - (int64_t) 1];\n                acc_27606 = ((__local int64_t *) local_mem_27557)[squot64(byte_offsets_27553, (int64_t) 8) + (sext_i32_i64(local_tid_27548) - (int64_t) 1)];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_27619 = (int64_t) 0;\n        prefix_27620 = (int64_t) 0;\n        block_new_sgm_27621 = sgm_idx_27572 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_27621 && local_tid_27548 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_27539)[dynamic_id_27570] = acc_27605;\n                ((volatile __global int64_t *) incprefixes_mem_27543)[dynamic_id_27570] = acc_27606;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_27535)[dynamic_id_27570] = (int8_t) 2;\n                acc_27605 = (int64_t) 0;\n                acc_27606 = (int64_t) 0;\n            }\n            if (!block_new_sgm_27621 && slt32(local_tid_27548, wave_sizze_27550)) {\n                if (local_tid_27548 == 0) {\n                 ",
                                    "   ((volatile __global int64_t *) aggregates_mem_27537)[dynamic_id_27570] = acc_27605;\n                    ((volatile __global int64_t *) aggregates_mem_27541)[dynamic_id_27570] = acc_27606;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_27535)[dynamic_id_27570] = (int8_t) 1;\n                    \n                    int8_t tmp_27622 = ((volatile __global int8_t *) status_flags_mem_27535)[dynamic_id_27570 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_27557)[(int64_t) 0] = tmp_27622;\n                }\n                mem_fence_local();\n                \n                int8_t status_27623 = ((__local int8_t *) local_mem_27557)[(int64_t) 0];\n                \n                if (status_27623 == (int8_t) 2) {\n                    if (local_tid_27548 == 0) {\n                        prefix_27619 = ((volatile __global int64_t *) incprefixes_mem_27539)[dynamic_id_27570 - (int64_t) 1];\n                        prefix_27620 = ((volatile __global int64_t *) incprefixes_mem_27543)[dynamic_id_27570 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_27624 = sext_i64_i32(dynamic_id_27570 - sext_i32_i64(wave_sizze_27550));\n                    \n                    while (slt32(wave_sizze_27550 * -1, readOffset_27624)) {\n                        int32_t read_i_27625 = readOffset_27624 + local_tid_27548;\n                        int64_t aggr_27626 = (int64_t) 0;\n                        int64_t aggr_27627 = (int64_t) 0;\n                        int8_t flag_27628 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_27625)) {\n                            flag_27628 = ((volatile __global int8_t *) status_flags_mem_27535)[sext_i32_i64(read_i_27625)];\n                            if (flag_27628 == (int8_t) 2) {\n                                aggr_27626 = ((volatile __global int64_t *) incprefixes_mem_27539)[sex", "t_i32_i64(read_i_27625)];\n                                aggr_27627 = ((volatile __global int64_t *) incprefixes_mem_27543)[sext_i32_i64(read_i_27625)];\n                            } else if (flag_27628 == (int8_t) 1) {\n                                aggr_27626 = ((volatile __global int64_t *) aggregates_mem_27537)[sext_i32_i64(read_i_27625)];\n                                aggr_27627 = ((volatile __global int64_t *) aggregates_mem_27541)[sext_i32_i64(read_i_27625)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_27557)[(int64_t) 4 + sext_i32_i64(local_tid_27548)] = aggr_27626;\n                        ((__local int64_t *) local_mem_27557)[squot64(warp_byte_offset_27555, (int64_t) 8) + sext_i32_i64(local_tid_27548)] = aggr_27627;\n                        ((__local int8_t *) local_mem_27557)[sext_i32_i64(local_tid_27548)] = flag_27628;\n                        flag_27628 = ((__local int8_t *) local_mem_27557)[sext_i32_i64(wave_sizze_27550) - (int64_t) 1];\n                        if (slt8(flag_27628, (int8_t) 2)) {\n                            int8_t flg_x_27635;\n                            int8_t flg_y_27636;\n                            int64_t eta_p_27629;\n                            int64_t eta_p_27630;\n                            int64_t eta_p_27631;\n                            int64_t eta_p_27632;\n                            int32_t skip_threads_27637;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_27636 = ((volatile __local int8_t *) local_mem_27557)[sext_i32_i64(local_tid_27548)];\n                                eta_p_27631 = ((volatile __local int64_t *) local_mem_27557)[(int64_t) 4 + sext_i32_i64(local_tid_27548)];\n                                eta_p_27632 = ((volatile __local int64_t *) local_mem_27557)[squot64(warp_byte_offset_27555, (int64_t) 8) + sext_i32_i64(local_tid_27548)];\n     ", "                           if ((local_tid_27548 - squot32(local_tid_27548, 32) * 32) == 0) {\n                                    eta_p_27629 = eta_p_27631;\n                                    eta_p_27630 = eta_p_27632;\n                                    flg_x_27635 = flg_y_27636;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_27637 = 1;\n                                while (slt32(skip_threads_27637, 32)) {\n                                    if (sle32(skip_threads_27637, local_tid_27548 - squot32(local_tid_27548, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_27635 = ((volatile __local int8_t *) local_mem_27557)[sext_i32_i64(local_tid_27548) - sext_i32_i64(skip_threads_27637)];\n                                            eta_p_27629 = ((volatile __local int64_t *) local_mem_27557)[(int64_t) 4 + (sext_i32_i64(local_tid_27548) - sext_i32_i64(skip_threads_27637))];\n                                            eta_p_27630 = ((volatile __local int64_t *) local_mem_27557)[squot64(warp_byte_offset_27555, (int64_t) 8) + (sext_i32_i64(local_tid_27548) - sext_i32_i64(skip_threads_27637))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_27636 == (int8_t) 2 || flg_y_27636 == (int8_t) 0) {\n                                                flg_x_27635 = flg_y_27636;\n                                                eta_p_27629 = eta_p_27631;\n                                                eta_p_27630 = eta_p_27632;\n                                            } else {\n                                                int64_t lifted_lambda_res_27633 = add64(et",
                                    "a_p_27629, eta_p_27631);\n                                                int64_t defunc_0_op_res_27634 = add64(eta_p_27630, eta_p_27632);\n                                                \n                                                eta_p_27629 = lifted_lambda_res_27633;\n                                                eta_p_27630 = defunc_0_op_res_27634;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_27557)[sext_i32_i64(local_tid_27548)] = flg_x_27635;\n                                            flg_y_27636 = flg_x_27635;\n                                            ((volatile __local int64_t *) local_mem_27557)[(int64_t) 4 + sext_i32_i64(local_tid_27548)] = eta_p_27629;\n                                            eta_p_27631 = eta_p_27629;\n                                            ((volatile __local int64_t *) local_mem_27557)[squot64(warp_byte_offset_27555, (int64_t) 8) + sext_i32_i64(local_tid_27548)] = eta_p_27630;\n                                            eta_p_27632 = eta_p_27630;\n                                        }\n                                    }\n                                    skip_threads_27637 *= 2;\n                                }\n                            }\n                        }\n                        flag_27628 = ((__local int8_t *) local_mem_27557)[sext_i32_i64(wave_sizze_27550) - (int64_t) 1];\n                        aggr_27626 = ((__local int64_t *) local_mem_27557)[(int64_t) 4 + (sext_i32_i64(wave_sizze_27550) - (int64_t) 1)];\n                        aggr_27627 = ((__local int64_t *) local_mem_27557)[squot64(warp_byte_offset_27555, (int64_t) 8) + (sext_i32_i64(wave_sizze_27550) - (int64_t) 1)];\n                        if (flag_27628 == (int8_t) 2) {\n                            readOffset_27624 = wave_si", "zze_27550 * -1;\n                        } else if (flag_27628 == (int8_t) 1) {\n                            readOffset_27624 -= wave_sizze_27550;\n                        }\n                        if (slt8((int8_t) 0, flag_27628)) {\n                            int64_t eta_p_27638 = aggr_27626;\n                            int64_t eta_p_27639 = aggr_27627;\n                            int64_t eta_p_27640 = prefix_27619;\n                            int64_t eta_p_27641 = prefix_27620;\n                            int64_t lifted_lambda_res_27642 = add64(eta_p_27638, eta_p_27640);\n                            int64_t defunc_0_op_res_27643 = add64(eta_p_27639, eta_p_27641);\n                            \n                            prefix_27619 = lifted_lambda_res_27642;\n                            prefix_27620 = defunc_0_op_res_27643;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_27548 == 0) {\n                    if (boundary_27573 == sext_i64_i32(segscan_tblock_sizze_24594 * chunk_sizze_27532)) {\n                        int64_t eta_p_27644 = prefix_27619;\n                        int64_t eta_p_27645 = prefix_27620;\n                        int64_t eta_p_27646 = acc_27605;\n                        int64_t eta_p_27647 = acc_27606;\n                        int64_t lifted_lambda_res_27648 = add64(eta_p_27644, eta_p_27646);\n                        int64_t defunc_0_op_res_27649 = add64(eta_p_27645, eta_p_27647);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_27539)[dynamic_id_27570] = lifted_lambda_res_27648;\n                        ((volatile __global int64_t *) incprefixes_mem_27543)[dynamic_id_27570] = defunc_0_op_res_27649;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_27535)[dynamic_id_27570] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_m", "em_27557)[(int64_t) 4] = prefix_27619;\n                    ((__local int64_t *) local_mem_27557)[squot64(warp_byte_offset_27555, (int64_t) 8)] = prefix_27620;\n                    acc_27605 = (int64_t) 0;\n                    acc_27606 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_27570 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_27619 = ((__local int64_t *) local_mem_27557)[(int64_t) 4];\n                prefix_27620 = ((__local int64_t *) local_mem_27557)[squot64(warp_byte_offset_27555, (int64_t) 8)];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_27650;\n            int64_t eta_p_27652;\n            int64_t eta_p_27656 = prefix_27619;\n            int64_t eta_p_27658 = acc_27605;\n            int64_t eta_p_27651;\n            int64_t eta_p_27653;\n            int64_t eta_p_27657 = prefix_27620;\n            int64_t eta_p_27659 = acc_27606;\n            \n            if (slt32(local_tid_27548 * chunk_sizze_32b_27552, boundary_27573) && !block_new_sgm_27621) {\n                int64_t lifted_lambda_res_27660 = add64(eta_p_27656, eta_p_27658);\n                int64_t defunc_0_op_res_27661 = add64(eta_p_27657, eta_p_27659);\n                \n                eta_p_27650 = lifted_lambda_res_27660;\n                eta_p_27651 = defunc_0_op_res_27661;\n            } else {\n                eta_p_27650 = acc_27605;\n                eta_p_27651 = acc_27606;\n            }\n            \n            int32_t stopping_point_27662 = segsizze_compact_27574 - srem32(local_tid_27548 * chunk_sizze_32b_27552 - 1 + segsizze_compact_27574 - boundary_27573, segsizze_compact_27574);\n            \n            for (int64_t i_27663 = 0; i_27663 < chunk_sizze_27532; i_27663++) {\n                if (slt32(sext_i64_i32(i_27663), stopping_point_27662 - 1)) {\n                    eta_p_27652 = private_mem_27575[i_27663];\n                    eta_p_27653 = ",
                                    "private_mem_27577[i_27663];\n                    \n                    int64_t lifted_lambda_res_27654 = add64(eta_p_27650, eta_p_27652);\n                    int64_t defunc_0_op_res_27655 = add64(eta_p_27651, eta_p_27653);\n                    \n                    private_mem_27575[i_27663] = lifted_lambda_res_27654;\n                    private_mem_27577[i_27663] = defunc_0_op_res_27655;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_27664 = 0; i_27664 < chunk_sizze_27532; i_27664++) {\n                int64_t sharedIdx_27665 = sext_i32_i64(local_tid_27548) * chunk_sizze_27532 + i_27664;\n                int64_t tmp_27666 = private_mem_27575[i_27664];\n                \n                ((__local int64_t *) local_mem_27557)[sharedIdx_27665] = tmp_27666;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_27667 = 0; i_27667 < chunk_sizze_27532; i_27667++) {\n                int64_t flat_idx_27668 = thd_offset_27579 + i_27667 * segscan_tblock_sizze_24594;\n                int64_t slice_27669 = m_22282;\n                int64_t gtid_24598 = flat_idx_27668;\n                int64_t remnant_27670 = flat_idx_27668 - gtid_24598;\n                \n                if (slt64(flat_idx_27668, m_22282)) {\n                    int64_t tmp_27671 = ((__local int64_t *) local_mem_27557)[flat_idx_27668 - block_offset_27571];\n                    \n                    ((__global int64_t *) mem_26731)[gtid_24598] = tmp_27671;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_27672 = 0; i_27672 < chunk_sizze_27532; i_27672++) {\n                int64_t sharedIdx_27673 = sext_i32_i64(local_tid_27548) * chunk_sizze_27532 + i_27672;\n                int64_t tmp_27674 = private_mem_27577[i_27672];\n                \n                ((__local int64_t *) local_mem_27557)[sharedIdx_27673] = tmp_27674;\n            }\n   ", "         barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_27675 = 0; i_27675 < chunk_sizze_27532; i_27675++) {\n                int64_t flat_idx_27676 = thd_offset_27579 + i_27675 * segscan_tblock_sizze_24594;\n                int64_t slice_27677 = m_22282;\n                int64_t gtid_24598 = flat_idx_27676;\n                int64_t remnant_27678 = flat_idx_27676 - gtid_24598;\n                \n                if (slt64(flat_idx_27676, m_22282)) {\n                    int64_t tmp_27679 = ((__local int64_t *) local_mem_27557)[flat_idx_27676 - block_offset_27571];\n                    \n                    ((__global int64_t *) mem_26733)[gtid_24598] = tmp_27679;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_24594\n    #undef chunk_sizze_27532\n}\n", NULL};
// Start of gpu_prototypes.h

// Constants used for transpositions.  In principle these should be configurable.
#define TR_BLOCK_DIM 16
#define TR_TILE_DIM (TR_BLOCK_DIM*2)
#define TR_ELEMS_PER_THREAD 8

// Config stuff included in every GPU backend.
struct gpu_config {
  size_t default_block_size;
  size_t default_grid_size;
  size_t default_tile_size;
  size_t default_reg_tile_size;
  size_t default_cache;
  size_t default_shared_memory;
  size_t default_registers;
  size_t default_threshold;

  int default_block_size_changed;
  int default_grid_size_changed;
  int default_tile_size_changed;
};

// The following are dummy sizes that mean the concrete defaults
// will be set during initialisation via hardware-inspection-based
// heuristics.
struct gpu_config gpu_config_initial = {
  0
};

// Must be defined by the user.
static int gpu_macros(struct futhark_context *ctx, char*** names, int64_t** values);

static void gpu_init_log(struct futhark_context *ctx);
struct builtin_kernels* init_builtin_kernels(struct futhark_context* ctx);
void free_builtin_kernels(struct futhark_context* ctx, struct builtin_kernels* kernels);
static int gpu_free_all(struct futhark_context *ctx);

// End of gpu_prototypes.h

// Start of backends/cuda.h.

// Forward declarations.
// Invoked by setup_opencl() after the platform and device has been
// found, but before the program is loaded.  Its intended use is to
// tune constants based on the selected platform and device.
static void set_tuning_params(struct futhark_context* ctx);
static char* get_failure_msg(int failure_idx, int64_t args[]);

#define CUDA_SUCCEED_FATAL(x) cuda_api_succeed_fatal(x, #x, __FILE__, __LINE__)
#define CUDA_SUCCEED_NONFATAL(x) cuda_api_succeed_nonfatal(x, #x, __FILE__, __LINE__)
#define NVRTC_SUCCEED_FATAL(x) nvrtc_api_succeed_fatal(x, #x, __FILE__, __LINE__)
#define NVRTC_SUCCEED_NONFATAL(x) nvrtc_api_succeed_nonfatal(x, #x, __FILE__, __LINE__)
// Take care not to override an existing error.
#define CUDA_SUCCEED_OR_RETURN(e) {             \
    char *serror = CUDA_SUCCEED_NONFATAL(e);    \
    if (serror) {                               \
      if (!ctx->error) {                        \
        ctx->error = serror;                    \
      } else {                                  \
        free(serror);                           \
      }                                         \
      return bad;                               \
    }                                           \
  }

// CUDA_SUCCEED_OR_RETURN returns the value of the variable 'bad' in
// scope.  By default, it will be this one.  Create a local variable
// of some other type if needed.  This is a bit of a hack, but it
// saves effort in the code generator.
static const int bad = 1;

static inline void cuda_api_succeed_fatal(CUresult res, const char *call,
                                          const char *file, int line) {
  if (res != CUDA_SUCCESS) {
    const char *err_str;
    cuGetErrorString(res, &err_str);
    if (err_str == NULL) { err_str = "Unknown"; }
    futhark_panic(-1, "%s:%d: CUDA call\n  %s\nfailed with error code %d (%s)\n",
                  file, line, call, res, err_str);
  }
}

static char* cuda_api_succeed_nonfatal(CUresult res, const char *call,
                                       const char *file, int line) {
  if (res != CUDA_SUCCESS) {
    const char *err_str;
    cuGetErrorString(res, &err_str);
    if (err_str == NULL) { err_str = "Unknown"; }
    return msgprintf("%s:%d: CUDA call\n  %s\nfailed with error code %d (%s)\n",
                     file, line, call, res, err_str);
  } else {
    return NULL;
  }
}

static inline void nvrtc_api_succeed_fatal(nvrtcResult res, const char *call,
                                           const char *file, int line) {
  if (res != NVRTC_SUCCESS) {
    const char *err_str = nvrtcGetErrorString(res);
    futhark_panic(-1, "%s:%d: NVRTC call\n  %s\nfailed with error code %d (%s)\n",
                  file, line, call, res, err_str);
  }
}

static char* nvrtc_api_succeed_nonfatal(nvrtcResult res, const char *call,
                                        const char *file, int line) {
  if (res != NVRTC_SUCCESS) {
    const char *err_str = nvrtcGetErrorString(res);
    return msgprintf("%s:%d: NVRTC call\n  %s\nfailed with error code %d (%s)\n",
                     file, line, call, res, err_str);
  } else {
    return NULL;
  }
}

struct futhark_context_config {
  int in_use;
  int debugging;
  int profiling;
  int logging;
  char* cache_fname;
  int num_tuning_params;
  int64_t *tuning_params;
  const char** tuning_param_names;
  const char** tuning_param_vars;
  const char** tuning_param_classes;
  // Uniform fields above.

  char* program;
  int num_nvrtc_opts;
  char* *nvrtc_opts;

  char* preferred_device;
  int preferred_device_num;

  int unified_memory;

  char* dump_ptx_to;
  char* load_ptx_from;

  struct gpu_config gpu;
};

static void backend_context_config_setup(struct futhark_context_config *cfg) {
  cfg->num_nvrtc_opts = 0;
  cfg->nvrtc_opts = (char**) malloc(sizeof(char*));
  cfg->nvrtc_opts[0] = NULL;

  cfg->program = strconcat(gpu_program);

  cfg->preferred_device_num = 0;
  cfg->preferred_device = strdup("");

  cfg->dump_ptx_to = NULL;
  cfg->load_ptx_from = NULL;

  cfg->unified_memory = 2;

  cfg->gpu = gpu_config_initial;
  cfg->gpu.default_block_size = 256;
  cfg->gpu.default_tile_size = 32;
  cfg->gpu.default_reg_tile_size = 2;
  cfg->gpu.default_threshold = 32*1024;
}

static void backend_context_config_teardown(struct futhark_context_config* cfg) {
  for (int i = 0; i < cfg->num_nvrtc_opts; i++) {
    free(cfg->nvrtc_opts[i]);
  }
  free(cfg->nvrtc_opts);
  free(cfg->dump_ptx_to);
  free(cfg->load_ptx_from);
  free(cfg->preferred_device);
  free(cfg->program);
}

void futhark_context_config_add_nvrtc_option(struct futhark_context_config *cfg, const char *opt) {
  cfg->nvrtc_opts[cfg->num_nvrtc_opts] = strdup(opt);
  cfg->num_nvrtc_opts++;
  cfg->nvrtc_opts = (char **) realloc(cfg->nvrtc_opts, (cfg->num_nvrtc_opts + 1) * sizeof(char *));
  cfg->nvrtc_opts[cfg->num_nvrtc_opts] = NULL;
}

void futhark_context_config_set_device(struct futhark_context_config *cfg, const char *s) {
  int x = 0;
  if (*s == '#') {
    s++;
    while (isdigit(*s)) {
      x = x * 10 + (*s++)-'0';
    }
    // Skip trailing spaces.
    while (isspace(*s)) {
      s++;
    }
  }
  free(cfg->preferred_device);
  cfg->preferred_device = strdup(s);
  cfg->preferred_device_num = x;
}

const char* futhark_context_config_get_program(struct futhark_context_config *cfg) {
  return cfg->program;
}

void futhark_context_config_set_program(struct futhark_context_config *cfg, const char *s) {
  free(cfg->program);
  cfg->program = strdup(s);
}

void futhark_context_config_dump_ptx_to(struct futhark_context_config *cfg, const char *path) {
  free(cfg->dump_ptx_to);
  cfg->dump_ptx_to = strdup(path);
}

void futhark_context_config_load_ptx_from(struct futhark_context_config *cfg, const char *path) {
  free(cfg->load_ptx_from);
  cfg->load_ptx_from = strdup(path);
}

void futhark_context_config_set_unified_memory(struct futhark_context_config* cfg, int flag) {
  cfg->unified_memory = flag;
}

// A record of something that happened.
struct profiling_record {
  cudaEvent_t *events; // Points to two events.
  const char *name;
};

struct futhark_context {
  struct futhark_context_config* cfg;
  int detail_memory;
  int debugging;
  int profiling;
  int profiling_paused;
  int logging;
  lock_t lock;
  char *error;
  lock_t error_lock;
  FILE *log;
  struct constants *constants;
  struct free_list free_list;
  struct event_list event_list;
  int64_t peak_mem_usage_default;
  int64_t cur_mem_usage_default;
  struct program* program;
  bool program_initialised;
  // Uniform fields above.

  CUdeviceptr global_failure;
  CUdeviceptr global_failure_args;
  struct tuning_params tuning_params;
  // True if a potentially failing kernel has been enqueued.
  int32_t failure_is_an_option;
  int total_runs;
  long int total_runtime;
  int64_t peak_mem_usage_device;
  int64_t cur_mem_usage_device;

  CUdevice dev;
  CUcontext cu_ctx;
  CUmodule module;
  CUstream stream;

  struct free_list gpu_free_list;

  size_t max_thread_block_size;
  size_t max_grid_size;
  size_t max_tile_size;
  size_t max_threshold;
  size_t max_shared_memory;
  size_t max_bespoke;
  size_t max_registers;
  size_t max_cache;

  size_t lockstep_width;

  struct builtin_kernels* kernels;
};

#define CU_DEV_ATTR(x) (CU_DEVICE_ATTRIBUTE_##x)
#define device_query(dev,attrib) _device_query(dev, CU_DEV_ATTR(attrib))
static int _device_query(CUdevice dev, CUdevice_attribute attrib) {
  int val;
  CUDA_SUCCEED_FATAL(cuDeviceGetAttribute(&val, attrib, dev));
  return val;
}

#define CU_FUN_ATTR(x) (CU_FUNC_ATTRIBUTE_##x)
#define function_query(fn,attrib) _function_query(dev, CU_FUN_ATTR(attrib))
static int _function_query(CUfunction dev, CUfunction_attribute attrib) {
  int val;
  CUDA_SUCCEED_FATAL(cuFuncGetAttribute(&val, attrib, dev));
  return val;
}

static int cuda_device_setup(struct futhark_context *ctx) {
  struct futhark_context_config *cfg = ctx->cfg;
  char name[256];
  int count, chosen = -1, best_cc = -1;
  int cc_major_best = 0, cc_minor_best = 0;
  int cc_major = 0, cc_minor = 0;
  CUdevice dev;

  CUDA_SUCCEED_FATAL(cuDeviceGetCount(&count));
  if (count == 0) { return 1; }

  int num_device_matches = 0;

  // XXX: Current device selection policy is to choose the device with the
  // highest compute capability (if no preferred device is set).
  // This should maybe be changed, since greater compute capability is not
  // necessarily an indicator of better performance.
  for (int i = 0; i < count; i++) {
    CUDA_SUCCEED_FATAL(cuDeviceGet(&dev, i));

    cc_major = device_query(dev, COMPUTE_CAPABILITY_MAJOR);
    cc_minor = device_query(dev, COMPUTE_CAPABILITY_MINOR);

    CUDA_SUCCEED_FATAL(cuDeviceGetName(name, sizeof(name) - 1, dev));
    name[sizeof(name) - 1] = 0;

    if (cfg->logging) {
      fprintf(ctx->log, "Device #%d: name=\"%s\", compute capability=%d.%d\n",
              i, name, cc_major, cc_minor);
    }

    if (device_query(dev, COMPUTE_MODE) == CU_COMPUTEMODE_PROHIBITED) {
      if (cfg->logging) {
        fprintf(ctx->log, "Device #%d is compute-prohibited, ignoring\n", i);
      }
      continue;
    }

    if (best_cc == -1 || cc_major > cc_major_best ||
        (cc_major == cc_major_best && cc_minor > cc_minor_best)) {
      best_cc = i;
      cc_major_best = cc_major;
      cc_minor_best = cc_minor;
    }

    if (strstr(name, cfg->preferred_device) != NULL &&
        num_device_matches++ == cfg->preferred_device_num) {
      chosen = i;
      break;
    }
  }

  if (chosen == -1) { chosen = best_cc; }
  if (chosen == -1) { return 1; }

  if (cfg->logging) {
    fprintf(ctx->log, "Using device #%d\n", chosen);
  }

  CUDA_SUCCEED_FATAL(cuDeviceGet(&ctx->dev, chosen));
  return 0;
}

static const char *cuda_nvrtc_get_arch(CUdevice dev) {
  static struct {
    int major;
    int minor;
    const char *arch_str;
  } const x[] = {
    { 3, 0, "compute_30" },
    { 3, 2, "compute_32" },
    { 3, 5, "compute_35" },
    { 3, 7, "compute_37" },
    { 5, 0, "compute_50" },
    { 5, 2, "compute_52" },
    { 5, 3, "compute_53" },
    { 6, 0, "compute_60" },
    { 6, 1, "compute_61" },
    { 6, 2, "compute_62" },
    { 7, 0, "compute_70" },
    { 7, 2, "compute_72" },
    { 7, 5, "compute_75" },
    { 8, 0, "compute_80" },
    { 8, 6, "compute_80" },
    { 8, 7, "compute_80" }
  };

  int major = device_query(dev, COMPUTE_CAPABILITY_MAJOR);
  int minor = device_query(dev, COMPUTE_CAPABILITY_MINOR);

  int chosen = -1;
  int num_archs = sizeof(x)/sizeof(x[0]);
  for (int i = 0; i < num_archs; i++) {
    if (x[i].major < major || (x[i].major == major && x[i].minor <= minor)) {
      chosen = i;
    } else {
      break;
    }
  }

  if (chosen == -1) {
    futhark_panic(-1, "Unsupported compute capability %d.%d\n", major, minor);
  }

  if (x[chosen].major != major || x[chosen].minor != minor) {
    fprintf(stderr,
            "Warning: device compute capability is %d.%d, but newest supported by Futhark is %d.%d.\n",
            major, minor, x[chosen].major, x[chosen].minor);
  }

  return x[chosen].arch_str;
}

static void cuda_nvrtc_mk_build_options(struct futhark_context *ctx, const char *extra_opts[],
                                        char*** opts_out, size_t *n_opts) {
  int arch_set = 0, num_extra_opts;
  struct futhark_context_config *cfg = ctx->cfg;

  char** macro_names;
  int64_t* macro_vals;
  int num_macros = gpu_macros(ctx, &macro_names, &macro_vals);

  // nvrtc cannot handle multiple -arch options.  Hence, if one of the
  // extra_opts is -arch, we have to be careful not to do our usual
  // automatic generation.
  for (num_extra_opts = 0; extra_opts[num_extra_opts] != NULL; num_extra_opts++) {
    if (strstr(extra_opts[num_extra_opts], "-arch")
        == extra_opts[num_extra_opts] ||
        strstr(extra_opts[num_extra_opts], "--gpu-architecture")
        == extra_opts[num_extra_opts]) {
      arch_set = 1;
    }
  }

  size_t i = 0, n_opts_alloc = 20 + num_macros + num_extra_opts + cfg->num_tuning_params;
  char **opts = (char**) malloc(n_opts_alloc * sizeof(char *));
  if (!arch_set) {
    opts[i++] = strdup("-arch");
    opts[i++] = strdup(cuda_nvrtc_get_arch(ctx->dev));
  }
  opts[i++] = strdup("-default-device");
  if (cfg->debugging) {
    opts[i++] = strdup("-G");
    opts[i++] = strdup("-lineinfo");
  } else {
    opts[i++] = strdup("--disable-warnings");
  }
  opts[i++] = msgprintf("-D%s=%d",
                        "max_thread_block_size",
                        (int)ctx->max_thread_block_size);
  opts[i++] = msgprintf("-D%s=%d",
                        "max_shared_memory",
                        (int)ctx->max_shared_memory);
  opts[i++] = msgprintf("-D%s=%d",
                        "max_registers",
                        (int)ctx->max_registers);

  for (int j = 0; j < num_macros; j++) {
    opts[i++] = msgprintf("-D%s=%zu", macro_names[j], macro_vals[j]);
  }

  for (int j = 0; j < cfg->num_tuning_params; j++) {
    opts[i++] = msgprintf("-D%s=%zu", cfg->tuning_param_vars[j],
                          cfg->tuning_params[j]);
  }
  opts[i++] = msgprintf("-DLOCKSTEP_WIDTH=%zu", ctx->lockstep_width);
  opts[i++] = msgprintf("-DMAX_THREADS_PER_BLOCK=%zu", ctx->max_thread_block_size);

  // Time for the best lines of the code in the entire compiler.
  if (getenv("CUDA_HOME") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_HOME"));
  }
  if (getenv("CUDA_ROOT") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_ROOT"));
  }
  if (getenv("CUDA_PATH") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_PATH"));
  }
  opts[i++] = msgprintf("-I/usr/local/cuda/include");
  opts[i++] = msgprintf("-I/usr/include");

  for (int j = 0; extra_opts[j] != NULL; j++) {
    opts[i++] = strdup(extra_opts[j]);
  }

  opts[i++] = msgprintf("-DTR_BLOCK_DIM=%d", TR_BLOCK_DIM);
  opts[i++] = msgprintf("-DTR_TILE_DIM=%d", TR_TILE_DIM);
  opts[i++] = msgprintf("-DTR_ELEMS_PER_THREAD=%d", TR_ELEMS_PER_THREAD);

  free(macro_names);
  free(macro_vals);

  *n_opts = i;
  *opts_out = opts;
}

static char* cuda_nvrtc_build(const char *src, const char *opts[], size_t n_opts,
                              char **ptx) {
  nvrtcProgram prog;
  char *problem = NULL;

  problem = NVRTC_SUCCEED_NONFATAL(nvrtcCreateProgram(&prog, src, "futhark-cuda", 0, NULL, NULL));

  if (problem) {
    return problem;
  }

  nvrtcResult res = nvrtcCompileProgram(prog, n_opts, opts);
  if (res != NVRTC_SUCCESS) {
    size_t log_size;
    if (nvrtcGetProgramLogSize(prog, &log_size) == NVRTC_SUCCESS) {
      char *log = (char*) malloc(log_size);
      if (nvrtcGetProgramLog(prog, log) == NVRTC_SUCCESS) {
        problem = msgprintf("NVRTC compilation failed.\n\n%s\n", log);
      } else {
        problem = msgprintf("Could not retrieve compilation log\n");
      }
      free(log);
    }
    return problem;
  }

  size_t ptx_size;
  NVRTC_SUCCEED_FATAL(nvrtcGetPTXSize(prog, &ptx_size));
  *ptx = (char*) malloc(ptx_size);
  NVRTC_SUCCEED_FATAL(nvrtcGetPTX(prog, *ptx));

  NVRTC_SUCCEED_FATAL(nvrtcDestroyProgram(&prog));

  return NULL;
}

static void cuda_load_ptx_from_cache(struct futhark_context_config *cfg,
                                     const char *src,
                                     const char *opts[], size_t n_opts,
                                     struct cache_hash *h, const char *cache_fname,
                                     char **ptx) {
  if (cfg->logging) {
    fprintf(stderr, "Restoring cache from from %s...\n", cache_fname);
  }
  cache_hash_init(h);
  for (size_t i = 0; i < n_opts; i++) {
    cache_hash(h, opts[i], strlen(opts[i]));
  }
  cache_hash(h, src, strlen(src));
  size_t ptxsize;
  errno = 0;
  if (cache_restore(cache_fname, h, (unsigned char**)ptx, &ptxsize) != 0) {
    if (cfg->logging) {
      fprintf(stderr, "Failed to restore cache (errno: %s)\n", strerror(errno));
    }
  }
}

static void cuda_size_setup(struct futhark_context *ctx)
{
  struct futhark_context_config *cfg = ctx->cfg;
  if (cfg->gpu.default_block_size > ctx->max_thread_block_size) {
    if (cfg->gpu.default_block_size_changed) {
      fprintf(stderr,
              "Note: Device limits default block size to %zu (down from %zu).\n",
              ctx->max_thread_block_size, cfg->gpu.default_block_size);
    }
    cfg->gpu.default_block_size = ctx->max_thread_block_size;
  }
  if (cfg->gpu.default_grid_size > ctx->max_grid_size) {
    if (cfg->gpu.default_grid_size_changed) {
      fprintf(stderr,
              "Note: Device limits default grid size to %zu (down from %zu).\n",
              ctx->max_grid_size, cfg->gpu.default_grid_size);
    }
    cfg->gpu.default_grid_size = ctx->max_grid_size;
  }
  if (cfg->gpu.default_tile_size > ctx->max_tile_size) {
    if (cfg->gpu.default_tile_size_changed) {
      fprintf(stderr,
              "Note: Device limits default tile size to %zu (down from %zu).\n",
              ctx->max_tile_size, cfg->gpu.default_tile_size);
    }
    cfg->gpu.default_tile_size = ctx->max_tile_size;
  }

  if (!cfg->gpu.default_grid_size_changed) {
    cfg->gpu.default_grid_size =
      (device_query(ctx->dev, MULTIPROCESSOR_COUNT) *
       device_query(ctx->dev, MAX_THREADS_PER_MULTIPROCESSOR))
      / cfg->gpu.default_block_size;
  }

  for (int i = 0; i < cfg->num_tuning_params; i++) {
    const char *size_class = cfg->tuning_param_classes[i];
    int64_t *size_value = &cfg->tuning_params[i];
    const char* size_name = cfg->tuning_param_names[i];
    int64_t max_value = 0, default_value = 0;

    if (strstr(size_class, "thread_block_size") == size_class) {
      max_value = ctx->max_thread_block_size;
      default_value = cfg->gpu.default_block_size;
    } else if (strstr(size_class, "grid_size") == size_class) {
      max_value = ctx->max_grid_size;
      default_value = cfg->gpu.default_grid_size;
      // XXX: as a quick and dirty hack, use twice as many threads for
      // histograms by default.  We really should just be smarter
      // about sizes somehow.
      if (strstr(size_name, ".seghist_") != NULL) {
        default_value *= 2;
      }
    } else if (strstr(size_class, "tile_size") == size_class) {
      max_value = ctx->max_tile_size;
      default_value = cfg->gpu.default_tile_size;
    } else if (strstr(size_class, "reg_tile_size") == size_class) {
      max_value = 0; // No limit.
      default_value = cfg->gpu.default_reg_tile_size;
    } else if (strstr(size_class, "shared_memory") == size_class) {
      max_value = ctx->max_shared_memory;
      default_value = ctx->max_shared_memory;
    } else if (strstr(size_class, "cache") == size_class) {
      max_value = ctx->max_cache;
      default_value = ctx->max_cache;
    } else if (strstr(size_class, "threshold") == size_class) {
      // Threshold can be as large as it takes.
      default_value = cfg->gpu.default_threshold;
    } else {
      // Bespoke sizes have no limit or default.
    }

    if (*size_value == 0) {
      *size_value = default_value;
    } else if (max_value > 0 && *size_value > max_value) {
      fprintf(stderr, "Note: Device limits %s to %zu (down from %zu)\n",
              size_name, max_value, *size_value);
      *size_value = max_value;
    }
  }
}

static char* cuda_module_setup(struct futhark_context *ctx,
                               const char *src,
                               const char *extra_opts[],
                               const char* cache_fname) {
  char *ptx = NULL;
  struct futhark_context_config *cfg = ctx->cfg;

  if (cfg->load_ptx_from) {
    ptx = slurp_file(cfg->load_ptx_from, NULL);
  }

  char **opts;
  size_t n_opts;
  cuda_nvrtc_mk_build_options(ctx, extra_opts, &opts, &n_opts);

  if (cfg->logging) {
    fprintf(stderr, "NVRTC compile options:\n");
    for (size_t j = 0; j < n_opts; j++) {
      fprintf(stderr, "\t%s\n", opts[j]);
    }
    fprintf(stderr, "\n");
  }

  struct cache_hash h;
  int loaded_ptx_from_cache = 0;
  if (cache_fname != NULL) {
    cuda_load_ptx_from_cache(cfg, src, (const char**)opts, n_opts, &h, cache_fname, &ptx);

    if (ptx != NULL) {
      if (cfg->logging) {
        fprintf(stderr, "Restored PTX from cache; now loading module...\n");
      }
      if (cuModuleLoadData(&ctx->module, ptx) == CUDA_SUCCESS) {
        if (cfg->logging) {
          fprintf(stderr, "Success!\n");
        }
        loaded_ptx_from_cache = 1;
      } else {
        if (cfg->logging) {
          fprintf(stderr, "Failed!\n");
        }
        free(ptx);
        ptx = NULL;
      }
    }
  }

  if (ptx == NULL) {
    char* problem = cuda_nvrtc_build(src, (const char**)opts, n_opts, &ptx);
    if (problem != NULL) {
      return problem;
    }
  }

  if (cfg->dump_ptx_to != NULL) {
    dump_file(cfg->dump_ptx_to, ptx, strlen(ptx));
  }

  if (!loaded_ptx_from_cache) {
    CUDA_SUCCEED_FATAL(cuModuleLoadData(&ctx->module, ptx));
  }

  if (cache_fname != NULL && !loaded_ptx_from_cache) {
    if (cfg->logging) {
      fprintf(stderr, "Caching PTX in %s...\n", cache_fname);
    }
    errno = 0;
    if (cache_store(cache_fname, &h, (const unsigned char*)ptx, strlen(ptx)) != 0) {
      fprintf(stderr, "Failed to cache PTX: %s\n", strerror(errno));
    }
  }

  for (size_t i = 0; i < n_opts; i++) {
    free((char *)opts[i]);
  }
  free(opts);
  free(ptx);

  return NULL;
}

struct cuda_event {
  cudaEvent_t start;
  cudaEvent_t end;
};

static struct cuda_event* cuda_event_new(struct futhark_context* ctx) {
  if (ctx->profiling && !ctx->profiling_paused) {
    struct cuda_event* e = malloc(sizeof(struct cuda_event));
    cudaEventCreate(&e->start);
    cudaEventCreate(&e->end);
    return e;
  } else {
    return NULL;
  }
}

static int cuda_event_report(struct str_builder* sb, struct cuda_event* e) {
  float ms;
  CUresult err;
  if ((err = cuEventElapsedTime(&ms, e->start, e->end)) != CUDA_SUCCESS) {
    return err;
  }

  // CUDA provides milisecond resolution, but we want microseconds.
  str_builder(sb, ",\"duration\":%f", ms*1000);

  if ((err = cuEventDestroy(e->start)) != CUDA_SUCCESS) {
    return 1;
  }

  if ((err = cuEventDestroy(e->end)) != CUDA_SUCCESS) {
    return 1;
  }

  free(e);

  return 0;
}

int futhark_context_sync(struct futhark_context* ctx) {
  CUDA_SUCCEED_OR_RETURN(cuCtxPushCurrent(ctx->cu_ctx));
  CUDA_SUCCEED_OR_RETURN(cuCtxSynchronize());
  if (ctx->failure_is_an_option) {
    // Check for any delayed error.
    int32_t failure_idx;
    CUDA_SUCCEED_OR_RETURN(
                           cuMemcpyDtoH(&failure_idx,
                                        ctx->global_failure,
                                        sizeof(int32_t)));
    ctx->failure_is_an_option = 0;

    if (failure_idx >= 0) {
      // We have to clear global_failure so that the next entry point
      // is not considered a failure from the start.
      int32_t no_failure = -1;
      CUDA_SUCCEED_OR_RETURN(
                             cuMemcpyHtoD(ctx->global_failure,
                                          &no_failure,
                                          sizeof(int32_t)));

      int64_t args[max_failure_args+1];
      CUDA_SUCCEED_OR_RETURN(
                             cuMemcpyDtoH(&args,
                                          ctx->global_failure_args,
                                          sizeof(args)));

      ctx->error = get_failure_msg(failure_idx, args);

      return FUTHARK_PROGRAM_ERROR;
    }
  }

  CUDA_SUCCEED_OR_RETURN(cuCtxPopCurrent(&ctx->cu_ctx));
  return 0;
}

struct builtin_kernels* init_builtin_kernels(struct futhark_context* ctx);
void free_builtin_kernels(struct futhark_context* ctx, struct builtin_kernels* kernels);

int backend_context_setup(struct futhark_context* ctx) {
  ctx->failure_is_an_option = 0;
  ctx->total_runs = 0;
  ctx->total_runtime = 0;
  ctx->peak_mem_usage_device = 0;
  ctx->cur_mem_usage_device = 0;
  ctx->kernels = NULL;

  CUDA_SUCCEED_FATAL(cuInit(0));
  if (cuda_device_setup(ctx) != 0) {
    futhark_panic(-1, "No suitable CUDA device found.\n");
  }
  CUDA_SUCCEED_FATAL(cuCtxCreate(&ctx->cu_ctx, 0, ctx->dev));

  free_list_init(&ctx->gpu_free_list);

  if (ctx->cfg->unified_memory == 2) {
    ctx->cfg->unified_memory = device_query(ctx->dev, MANAGED_MEMORY);
  }

  if (ctx->cfg->logging) {
    if (ctx->cfg->unified_memory) {
      fprintf(ctx->log, "Using managed memory\n");
    } else {
      fprintf(ctx->log, "Using unmanaged memory\n");
    }
  }

  ctx->max_thread_block_size = device_query(ctx->dev, MAX_THREADS_PER_BLOCK);
  ctx->max_grid_size = device_query(ctx->dev, MAX_GRID_DIM_X);
  ctx->max_tile_size = sqrt(ctx->max_thread_block_size);
  ctx->max_threshold = 1U<<31; // No limit.
  ctx->max_bespoke = 1U<<31; // No limit.

  if (ctx->cfg->gpu.default_registers != 0) {
    ctx->max_registers = ctx->cfg->gpu.default_registers;
  } else {
    ctx->max_registers = device_query(ctx->dev, MAX_REGISTERS_PER_BLOCK);
  }

  if (ctx->cfg->gpu.default_shared_memory != 0) {
    ctx->max_shared_memory = ctx->cfg->gpu.default_shared_memory;
  } else {
    // MAX_SHARED_MEMORY_PER_BLOCK gives bogus numbers (48KiB); probably
    // for backwards compatibility.  Add _OPTIN and you seem to get the
    // right number.
    ctx->max_shared_memory = device_query(ctx->dev, MAX_SHARED_MEMORY_PER_BLOCK_OPTIN);
#if CUDART_VERSION >= 12000
    ctx->max_shared_memory -= device_query(ctx->dev, RESERVED_SHARED_MEMORY_PER_BLOCK);
#endif
  }

  if (ctx->cfg->gpu.default_cache != 0) {
    ctx->max_cache = ctx->cfg->gpu.default_cache;
  } else {
    ctx->max_cache = device_query(ctx->dev, L2_CACHE_SIZE);
  }

  ctx->lockstep_width = device_query(ctx->dev, WARP_SIZE);
  CUDA_SUCCEED_FATAL(cuStreamCreate(&ctx->stream, CU_STREAM_DEFAULT));
  cuda_size_setup(ctx);

  gpu_init_log(ctx);

  ctx->error = cuda_module_setup(ctx,
                                 ctx->cfg->program,
                                 (const char**)ctx->cfg->nvrtc_opts,
                                 ctx->cfg->cache_fname);

  if (ctx->error != NULL) {
    futhark_panic(1, "During CUDA initialisation:\n%s\n", ctx->error);
  }

  int32_t no_error = -1;
  CUDA_SUCCEED_FATAL(cuMemAlloc(&ctx->global_failure, sizeof(no_error)));
  CUDA_SUCCEED_FATAL(cuMemcpyHtoD(ctx->global_failure, &no_error, sizeof(no_error)));
  // The +1 is to avoid zero-byte allocations.
  CUDA_SUCCEED_FATAL(cuMemAlloc(&ctx->global_failure_args, sizeof(int64_t)*(max_failure_args+1)));

  if ((ctx->kernels = init_builtin_kernels(ctx)) == NULL) {
    return 1;
  }

  return 0;
}

void backend_context_teardown(struct futhark_context* ctx) {
  if (ctx->kernels != NULL) {
    free_builtin_kernels(ctx, ctx->kernels);
    cuMemFree(ctx->global_failure);
    cuMemFree(ctx->global_failure_args);
    CUDA_SUCCEED_FATAL(gpu_free_all(ctx));
    CUDA_SUCCEED_FATAL(cuStreamDestroy(ctx->stream));
    CUDA_SUCCEED_FATAL(cuModuleUnload(ctx->module));
    CUDA_SUCCEED_FATAL(cuCtxDestroy(ctx->cu_ctx));
  }
  free_list_destroy(&ctx->gpu_free_list);
}

// GPU ABSTRACTION LAYER

// Types.

typedef CUfunction gpu_kernel;
typedef CUdeviceptr gpu_mem;

static void gpu_create_kernel(struct futhark_context *ctx,
                              gpu_kernel* kernel,
                              const char* name) {
  if (ctx->debugging) {
    fprintf(ctx->log, "Creating kernel %s.\n", name);
  }
  CUDA_SUCCEED_FATAL(cuModuleGetFunction(kernel, ctx->module, name));
  // Unless the below is set, the kernel is limited to 48KiB of memory.
  CUDA_SUCCEED_FATAL(cuFuncSetAttribute(*kernel,
                                        cudaFuncAttributeMaxDynamicSharedMemorySize,
                                        ctx->max_shared_memory));
}

static void gpu_free_kernel(struct futhark_context *ctx,
                            gpu_kernel kernel) {
  (void)ctx;
  (void)kernel;
}

static int gpu_scalar_to_device(struct futhark_context* ctx,
                                gpu_mem dst, size_t offset, size_t size,
                                void *src) {
  struct cuda_event *event = cuda_event_new(ctx);
  if (event != NULL) {
    add_event(ctx,
              "copy_scalar_to_dev",
              strdup(""),
              event,
              (event_report_fn)cuda_event_report);
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
  }
  CUDA_SUCCEED_OR_RETURN(cuMemcpyHtoD(dst + offset, src, size));
  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }
  return FUTHARK_SUCCESS;
}

static int gpu_scalar_from_device(struct futhark_context* ctx,
                                  void *dst,
                                  gpu_mem src, size_t offset, size_t size) {
  struct cuda_event *event = cuda_event_new(ctx);
  if (event != NULL) {
    add_event(ctx,
              "copy_scalar_from_dev",
              strdup(""),
              event,
              (event_report_fn)cuda_event_report);
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
  }
  CUDA_SUCCEED_OR_RETURN(cuMemcpyDtoH(dst, src + offset, size));
  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }
  return FUTHARK_SUCCESS;
}

static int gpu_memcpy(struct futhark_context* ctx,
                      gpu_mem dst, int64_t dst_offset,
                      gpu_mem src, int64_t src_offset,
                      int64_t nbytes) {
  struct cuda_event *event = cuda_event_new(ctx);
  if (event != NULL) {
    add_event(ctx,
              "copy_dev_to_dev",
              strdup(""),
              event,
              (event_report_fn)cuda_event_report);
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
  }
  CUDA_SUCCEED_OR_RETURN(cuMemcpyAsync(dst+dst_offset, src+src_offset, nbytes, ctx->stream));
  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }
  return FUTHARK_SUCCESS;
}

static int memcpy_host2gpu(struct futhark_context* ctx, bool sync,
                           gpu_mem dst, int64_t dst_offset,
                           const unsigned char* src, int64_t src_offset,
                           int64_t nbytes) {
  if (nbytes > 0) {
    struct cuda_event *event = cuda_event_new(ctx);
    if (event != NULL) {
      add_event(ctx,
                "copy_host_to_dev",
                strdup(""),
                event,
                (event_report_fn)cuda_event_report);
      CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
    }
    if (sync) {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyHtoD(dst + dst_offset, src + src_offset, nbytes));
    } else {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyHtoDAsync(dst + dst_offset, src + src_offset, nbytes, ctx->stream));
    }
    if (event != NULL) {
      CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
    }
  }
  return FUTHARK_SUCCESS;
}

static int memcpy_gpu2host(struct futhark_context* ctx, bool sync,
                           unsigned char* dst, int64_t dst_offset,
                           gpu_mem src, int64_t src_offset,
                           int64_t nbytes) {
  if (nbytes > 0) {
    struct cuda_event *event = cuda_event_new(ctx);
    if (event != NULL) {
      add_event(ctx,
                "copy_dev_to_host",
                strdup(""),
                event,
                (event_report_fn)cuda_event_report);
      CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
    }
    if (sync) {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyDtoH(dst + dst_offset, src + src_offset, nbytes));
    } else {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyDtoHAsync(dst + dst_offset, src + src_offset, nbytes, ctx->stream));
    }
    if (event != NULL) {
      CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
    }
    if (sync &&
        ctx->failure_is_an_option &&
        futhark_context_sync(ctx) != 0) {
      return 1;
    }
  }
  return FUTHARK_SUCCESS;
}

static int gpu_launch_kernel(struct futhark_context* ctx,
                             gpu_kernel kernel, const char *name,
                             const int32_t grid[3],
                             const int32_t block[3],
                             unsigned int shared_mem_bytes,
                             int num_args,
                             void* args[num_args],
                             size_t args_sizes[num_args]) {
  (void) args_sizes;

  if (shared_mem_bytes > ctx->max_shared_memory) {
    set_error(ctx, msgprintf("Kernel %s with %d bytes of memory exceeds device limit of %d\n",
                             name, shared_mem_bytes, (int)ctx->max_shared_memory));
    return 1;
  }

  int64_t time_start = 0, time_end = 0;
  if (ctx->debugging) {
    time_start = get_wall_time();
  }

  struct cuda_event *event = cuda_event_new(ctx);

  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
    add_event(ctx,
              name,
              msgprintf("Kernel %s with\n"
                        "  grid=(%d,%d,%d)\n"
                        "  block=(%d,%d,%d)\n"
                        "  shared memory=%d",
                        name,
                        grid[0], grid[1], grid[2],
                        block[0], block[1], block[2],
                        shared_mem_bytes),
              event,
              (event_report_fn)cuda_event_report);
  }

  CUDA_SUCCEED_OR_RETURN
    (cuLaunchKernel(kernel,
                    grid[0], grid[1], grid[2],
                    block[0], block[1], block[2],
                    shared_mem_bytes, ctx->stream,
                    args, NULL));

  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }

  if (ctx->debugging) {
    CUDA_SUCCEED_FATAL(cuCtxSynchronize());
    time_end = get_wall_time();
    long int time_diff = time_end - time_start;
    fprintf(ctx->log, "  runtime: %ldus\n", time_diff);
  }
  if (ctx->logging) {
    fprintf(ctx->log, "\n");
  }

  return FUTHARK_SUCCESS;
}

static int gpu_alloc_actual(struct futhark_context *ctx, size_t size, gpu_mem *mem_out) {
  CUresult res;
  if (ctx->cfg->unified_memory) {
    res = cuMemAllocManaged(mem_out, size, CU_MEM_ATTACH_GLOBAL);
  } else {
    res = cuMemAlloc(mem_out, size);
  }

  if (res == CUDA_ERROR_OUT_OF_MEMORY) {
    return FUTHARK_OUT_OF_MEMORY;
  }

  CUDA_SUCCEED_OR_RETURN(res);
  return FUTHARK_SUCCESS;
}

static int gpu_free_actual(struct futhark_context *ctx, gpu_mem mem) {
  (void)ctx;
  CUDA_SUCCEED_OR_RETURN(cuMemFree(mem));
  return FUTHARK_SUCCESS;
}

// End of backends/cuda.h.

// Start of gpu.h

// Generic functions that use our tiny GPU abstraction layer.  The
// entire context must be defined before this header is included.  In
// particular we expect the following functions to be available:

static int gpu_free_actual(struct futhark_context *ctx, gpu_mem mem);
static int gpu_alloc_actual(struct futhark_context *ctx, size_t size, gpu_mem *mem_out);
int gpu_launch_kernel(struct futhark_context* ctx,
                      gpu_kernel kernel, const char *name,
                      const int32_t grid[3],
                      const int32_t block[3],
                      unsigned int shared_mem_bytes,
                      int num_args,
                      void* args[num_args],
                      size_t args_sizes[num_args]);
int gpu_memcpy(struct futhark_context* ctx,
               gpu_mem dst, int64_t dst_offset,
               gpu_mem src, int64_t src_offset,
               int64_t nbytes);
int gpu_scalar_from_device(struct futhark_context* ctx,
                           void *dst,
                           gpu_mem src, size_t offset, size_t size);
int gpu_scalar_to_device(struct futhark_context* ctx,
                         gpu_mem dst, size_t offset, size_t size,
                         void *src);
void gpu_create_kernel(struct futhark_context *ctx,
                       gpu_kernel* kernel,
                       const char* name);

static void gpu_init_log(struct futhark_context *ctx) {
  if (ctx->cfg->logging) {
    fprintf(ctx->log, "Default block size: %ld\n", (long)ctx->cfg->gpu.default_block_size);
    fprintf(ctx->log, "Default grid size: %ld\n", (long)ctx->cfg->gpu.default_grid_size);
    fprintf(ctx->log, "Default tile size: %ld\n", (long)ctx->cfg->gpu.default_tile_size);
    fprintf(ctx->log, "Default register tile size: %ld\n", (long)ctx->cfg->gpu.default_reg_tile_size);
    fprintf(ctx->log, "Default cache: %ld\n", (long)ctx->cfg->gpu.default_cache);
    fprintf(ctx->log, "Default registers: %ld\n", (long)ctx->cfg->gpu.default_registers);
    fprintf(ctx->log, "Default threshold: %ld\n", (long)ctx->cfg->gpu.default_threshold);
    fprintf(ctx->log, "Max thread block size: %ld\n", (long)ctx->max_thread_block_size);
    fprintf(ctx->log, "Max grid size: %ld\n", (long)ctx->max_grid_size);
    fprintf(ctx->log, "Max tile size: %ld\n", (long)ctx->max_tile_size);
    fprintf(ctx->log, "Max threshold: %ld\n", (long)ctx->max_threshold);
    fprintf(ctx->log, "Max shared memory: %ld\n", (long)ctx->max_shared_memory);
    fprintf(ctx->log, "Max registers: %ld\n", (long)ctx->max_registers);
    fprintf(ctx->log, "Max cache: %ld\n", (long)ctx->max_cache);
    fprintf(ctx->log, "Lockstep width: %ld\n", (long)ctx->lockstep_width);
  }
}

// Generic GPU command line options.

void futhark_context_config_set_default_thread_block_size(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_block_size = size;
  cfg->gpu.default_block_size_changed = 1;
}

void futhark_context_config_set_default_group_size(struct futhark_context_config *cfg, int size) {
  futhark_context_config_set_default_thread_block_size(cfg, size);
}

void futhark_context_config_set_default_grid_size(struct futhark_context_config *cfg, int num) {
  cfg->gpu.default_grid_size = num;
  cfg->gpu.default_grid_size_changed = 1;
}

void futhark_context_config_set_default_num_groups(struct futhark_context_config *cfg, int num) {
  futhark_context_config_set_default_grid_size(cfg, num);
}

void futhark_context_config_set_default_tile_size(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_tile_size = size;
  cfg->gpu.default_tile_size_changed = 1;
}

void futhark_context_config_set_default_reg_tile_size(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_reg_tile_size = size;
}

void futhark_context_config_set_default_cache(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_cache = size;
}

void futhark_context_config_set_default_registers(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_registers = size;
}

void futhark_context_config_set_default_threshold(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_threshold = size;
}

int futhark_context_config_set_tuning_param(struct futhark_context_config *cfg,
                                            const char *param_name,
                                            size_t new_value) {
  for (int i = 0; i < cfg->num_tuning_params; i++) {
    if (strcmp(param_name, cfg->tuning_param_names[i]) == 0) {
      cfg->tuning_params[i] = new_value;
      return 0;
    }
  }
  if (strcmp(param_name, "default_thread_block_size") == 0 ||
      strcmp(param_name, "default_group_size") == 0) {
    cfg->gpu.default_block_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_grid_size") == 0 ||
      strcmp(param_name, "default_num_groups") == 0) {
    cfg->gpu.default_grid_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_threshold") == 0) {
    cfg->gpu.default_threshold = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_tile_size") == 0) {
    cfg->gpu.default_tile_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_reg_tile_size") == 0) {
    cfg->gpu.default_reg_tile_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_cache") == 0) {
    cfg->gpu.default_cache = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_shared_memory") == 0) {
    cfg->gpu.default_shared_memory = new_value;
    return 0;
  }

  return 1;
}

// End of GPU command line optiopns.

// Max number of thead blocks we allow along the second or third
// dimension for transpositions.
#define MAX_TR_THREAD_BLOCKS 65535

struct builtin_kernels {
  // We have a lot of ways to transpose arrays.
  gpu_kernel map_transpose_1b;
  gpu_kernel map_transpose_1b_low_height;
  gpu_kernel map_transpose_1b_low_width;
  gpu_kernel map_transpose_1b_small;
  gpu_kernel map_transpose_1b_large;
  gpu_kernel map_transpose_2b;
  gpu_kernel map_transpose_2b_low_height;
  gpu_kernel map_transpose_2b_low_width;
  gpu_kernel map_transpose_2b_small;
  gpu_kernel map_transpose_2b_large;
  gpu_kernel map_transpose_4b;
  gpu_kernel map_transpose_4b_low_height;
  gpu_kernel map_transpose_4b_low_width;
  gpu_kernel map_transpose_4b_small;
  gpu_kernel map_transpose_4b_large;
  gpu_kernel map_transpose_8b;
  gpu_kernel map_transpose_8b_low_height;
  gpu_kernel map_transpose_8b_low_width;
  gpu_kernel map_transpose_8b_small;
  gpu_kernel map_transpose_8b_large;

  // And a few ways of copying.
  gpu_kernel lmad_copy_1b;
  gpu_kernel lmad_copy_2b;
  gpu_kernel lmad_copy_4b;
  gpu_kernel lmad_copy_8b;
};

struct builtin_kernels* init_builtin_kernels(struct futhark_context* ctx) {
  struct builtin_kernels *kernels = malloc(sizeof(struct builtin_kernels));
  gpu_create_kernel(ctx, &kernels->map_transpose_1b, "map_transpose_1b");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_large, "map_transpose_1b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_low_height, "map_transpose_1b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_low_width, "map_transpose_1b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_small, "map_transpose_1b_small");

  gpu_create_kernel(ctx, &kernels->map_transpose_2b, "map_transpose_2b");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_large, "map_transpose_2b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_low_height, "map_transpose_2b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_low_width, "map_transpose_2b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_small, "map_transpose_2b_small");

  gpu_create_kernel(ctx, &kernels->map_transpose_4b, "map_transpose_4b");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_large, "map_transpose_4b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_low_height, "map_transpose_4b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_low_width, "map_transpose_4b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_small, "map_transpose_4b_small");

  gpu_create_kernel(ctx, &kernels->map_transpose_8b, "map_transpose_8b");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_large, "map_transpose_8b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_low_height, "map_transpose_8b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_low_width, "map_transpose_8b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_small, "map_transpose_8b_small");

  gpu_create_kernel(ctx, &kernels->lmad_copy_1b, "lmad_copy_1b");
  gpu_create_kernel(ctx, &kernels->lmad_copy_2b, "lmad_copy_2b");
  gpu_create_kernel(ctx, &kernels->lmad_copy_4b, "lmad_copy_4b");
  gpu_create_kernel(ctx, &kernels->lmad_copy_8b, "lmad_copy_8b");

  return kernels;
}

void free_builtin_kernels(struct futhark_context* ctx, struct builtin_kernels* kernels) {
  gpu_free_kernel(ctx, kernels->map_transpose_1b);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_small);

  gpu_free_kernel(ctx, kernels->map_transpose_2b);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_small);

  gpu_free_kernel(ctx, kernels->map_transpose_4b);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_small);

  gpu_free_kernel(ctx, kernels->map_transpose_8b);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_small);

  gpu_free_kernel(ctx, kernels->lmad_copy_1b);
  gpu_free_kernel(ctx, kernels->lmad_copy_2b);
  gpu_free_kernel(ctx, kernels->lmad_copy_4b);
  gpu_free_kernel(ctx, kernels->lmad_copy_8b);

  free(kernels);
}

static int gpu_alloc(struct futhark_context *ctx, FILE *log,
                     size_t min_size, const char *tag,
                     gpu_mem *mem_out, size_t *size_out) {
  if (min_size < sizeof(int)) {
    min_size = sizeof(int);
  }

  gpu_mem* memptr;
  if (free_list_find(&ctx->gpu_free_list, min_size, tag, size_out, (fl_mem*)&memptr) == 0) {
    // Successfully found a free block.  Is it big enough?
    if (*size_out >= min_size) {
      if (ctx->cfg->debugging) {
        fprintf(log, "No need to allocate: Found a block in the free list.\n");
      }
      *mem_out = *memptr;
      free(memptr);
      return FUTHARK_SUCCESS;
    } else {
      if (ctx->cfg->debugging) {
        fprintf(log, "Found a free block, but it was too small.\n");
      }
      int error = gpu_free_actual(ctx, *memptr);
      free(memptr);
      if (error != FUTHARK_SUCCESS) {
        return error;
      }
    }
  }

  *size_out = min_size;

  // We have to allocate a new block from the driver.  If the
  // allocation does not succeed, then we might be in an out-of-memory
  // situation.  We now start freeing things from the free list until
  // we think we have freed enough that the allocation will succeed.
  // Since we don't know how far the allocation is from fitting, we
  // have to check after every deallocation.  This might be pretty
  // expensive.  Let's hope that this case is hit rarely.

  if (ctx->cfg->debugging) {
    fprintf(log, "Actually allocating the desired block.\n");
  }

  int error = gpu_alloc_actual(ctx, min_size, mem_out);

  while (error == FUTHARK_OUT_OF_MEMORY) {
    if (ctx->cfg->debugging) {
      fprintf(log, "Out of GPU memory: releasing entry from the free list...\n");
    }
    gpu_mem* memptr;
    if (free_list_first(&ctx->gpu_free_list, (fl_mem*)&memptr) == 0) {
      gpu_mem mem = *memptr;
      free(memptr);
      error = gpu_free_actual(ctx, mem);
      if (error != FUTHARK_SUCCESS) {
        return error;
      }
    } else {
      break;
    }
    error = gpu_alloc_actual(ctx, min_size, mem_out);
  }

  return error;
}

static int gpu_free(struct futhark_context *ctx,
                    gpu_mem mem, size_t size, const char *tag) {
  gpu_mem* memptr = malloc(sizeof(gpu_mem));
  *memptr = mem;
  free_list_insert(&ctx->gpu_free_list, size, (fl_mem)memptr, tag);
  return FUTHARK_SUCCESS;
}

static int gpu_free_all(struct futhark_context *ctx) {
  free_list_pack(&ctx->gpu_free_list);
  gpu_mem* memptr;
  while (free_list_first(&ctx->gpu_free_list, (fl_mem*)&memptr) == 0) {
    gpu_mem mem = *memptr;
    free(memptr);
    int error = gpu_free_actual(ctx, mem);
    if (error != FUTHARK_SUCCESS) {
      return error;
    }
  }

  return FUTHARK_SUCCESS;
}

static int gpu_map_transpose(struct futhark_context* ctx,
                             gpu_kernel kernel_default,
                             gpu_kernel kernel_low_height,
                             gpu_kernel kernel_low_width,
                             gpu_kernel kernel_small,
                             gpu_kernel kernel_large,
                             const char *name, size_t elem_size,
                             gpu_mem dst, int64_t dst_offset,
                             gpu_mem src, int64_t src_offset,
                             int64_t k, int64_t n, int64_t m) {
  int64_t mulx = TR_BLOCK_DIM / n;
  int64_t muly = TR_BLOCK_DIM / m;
  int32_t mulx32 = mulx;
  int32_t muly32 = muly;
  int32_t k32 = k;
  int32_t n32 = n;
  int32_t m32 = m;

  gpu_kernel kernel = kernel_default;
  int32_t grid[3];
  int32_t block[3];

  void* args[11];
  size_t args_sizes[11] = {
    sizeof(gpu_mem), sizeof(int64_t),
    sizeof(gpu_mem), sizeof(int64_t),
    sizeof(int32_t),
    sizeof(int32_t),
    sizeof(int32_t),
    sizeof(int32_t),
    sizeof(int32_t)
  };

  args[0] = &dst;
  args[1] = &dst_offset;
  args[2] = &src;
  args[3] = &src_offset;
  args[7] = &mulx;
  args[8] = &muly;

  if (dst_offset + k * n * m <= 2147483647L &&
      src_offset + k * n * m <= 2147483647L) {
    if (m <= TR_BLOCK_DIM/2 && n <= TR_BLOCK_DIM/2) {
      if (ctx->logging) { fprintf(ctx->log, "Using small kernel\n"); }
      kernel = kernel_small;
      grid[0] = ((k * n * m) + (TR_BLOCK_DIM*TR_BLOCK_DIM) - 1) / (TR_BLOCK_DIM*TR_BLOCK_DIM);
      grid[1] = 1;
      grid[2] = 1;
      block[0] = TR_BLOCK_DIM*TR_BLOCK_DIM;
      block[1] = 1;
      block[2] = 1;
    } else if (m <= TR_BLOCK_DIM/2 && TR_BLOCK_DIM < n) {
      if (ctx->logging) { fprintf(ctx->log, "Using low-width kernel\n"); }
      kernel = kernel_low_width;
      int64_t x_elems = m;
      int64_t y_elems = (n + muly - 1) / muly;
      grid[0] = (x_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[1] = (y_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[2] = k;
      block[0] = TR_BLOCK_DIM;
      block[1] = TR_BLOCK_DIM;
      block[2] = 1;
    } else if (n <= TR_BLOCK_DIM/2 && TR_BLOCK_DIM < m) {
      if (ctx->logging) { fprintf(ctx->log, "Using low-height kernel\n"); }
      kernel = kernel_low_height;
      int64_t x_elems = (m + mulx - 1) / mulx;
      int64_t y_elems = n;
      grid[0] = (x_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[1] = (y_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[2] = k;
      block[0] = TR_BLOCK_DIM;
      block[1] = TR_BLOCK_DIM;
      block[2] = 1;
    } else {
      if (ctx->logging) { fprintf(ctx->log, "Using default kernel\n"); }
      kernel = kernel_default;
      grid[0] = (m+TR_TILE_DIM-1)/TR_TILE_DIM;
      grid[1] = (n+TR_TILE_DIM-1)/TR_TILE_DIM;
      grid[2] = k;
      block[0] = TR_TILE_DIM;
      block[1] = TR_TILE_DIM/TR_ELEMS_PER_THREAD;
      block[2] = 1;
    }
    args[4] = &k32;
    args[5] = &m32;
    args[6] = &n32;
    args[7] = &mulx32;
    args[8] = &muly32;
  } else {
    if (ctx->logging) { fprintf(ctx->log, "Using large kernel\n"); }
    kernel = kernel_large;
    grid[0] = (m+TR_TILE_DIM-1)/TR_TILE_DIM;
    grid[1] = (n+TR_TILE_DIM-1)/TR_TILE_DIM;
    grid[2] = k;
    block[0] = TR_TILE_DIM;
    block[1] = TR_TILE_DIM/TR_ELEMS_PER_THREAD;
    block[2] = 1;
    args[4] = &k;
    args[5] = &m;
    args[6] = &n;
    args[7] = &mulx;
    args[8] = &muly;
    args_sizes[4] = sizeof(int64_t);
    args_sizes[5] = sizeof(int64_t);
    args_sizes[6] = sizeof(int64_t);
    args_sizes[7] = sizeof(int64_t);
    args_sizes[8] = sizeof(int64_t);
  }

  // Cap the number of thead blocks we launch and figure out how many
  // repeats we need alongside each dimension.
  int32_t repeat_1 = grid[1] / MAX_TR_THREAD_BLOCKS;
  int32_t repeat_2 = grid[2] / MAX_TR_THREAD_BLOCKS;
  grid[1] = repeat_1 > 0 ? MAX_TR_THREAD_BLOCKS : grid[1];
  grid[2] = repeat_2 > 0 ? MAX_TR_THREAD_BLOCKS : grid[2];
  args[9] = &repeat_1;
  args[10] = &repeat_2;
  args_sizes[9] = sizeof(repeat_1);
  args_sizes[10] = sizeof(repeat_2);

  if (ctx->logging) {
    fprintf(ctx->log, "\n");
  }

  return gpu_launch_kernel(ctx, kernel, name, grid, block,
                           TR_TILE_DIM*(TR_TILE_DIM+1)*elem_size,
                           sizeof(args)/sizeof(args[0]), args, args_sizes);
}

#define GEN_MAP_TRANSPOSE_GPU2GPU(NAME, ELEM_TYPE)                      \
  static int map_transpose_gpu2gpu_##NAME                               \
  (struct futhark_context* ctx,                                         \
   gpu_mem dst, int64_t dst_offset,                                     \
   gpu_mem src, int64_t src_offset,                                     \
   int64_t k, int64_t m, int64_t n)                                     \
  {                                                                     \
    return                                                              \
      gpu_map_transpose                                                 \
      (ctx,                                                             \
       ctx->kernels->map_transpose_##NAME,                              \
       ctx->kernels->map_transpose_##NAME##_low_height,                 \
       ctx->kernels->map_transpose_##NAME##_low_width,                  \
       ctx->kernels->map_transpose_##NAME##_small,                      \
       ctx->kernels->map_transpose_##NAME##_large,                      \
       "map_transpose_" #NAME, sizeof(ELEM_TYPE),                       \
       dst, dst_offset, src, src_offset,                                \
       k, n, m);                                                        \
  }

static int gpu_lmad_copy(struct futhark_context* ctx,
                         gpu_kernel kernel, int r,
                         gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],
                         gpu_mem src, int64_t src_offset, int64_t src_strides[r],
                         int64_t shape[r]) {
  if (r > 8) {
    set_error(ctx, strdup("Futhark runtime limitation:\nCannot copy array of greater than rank 8.\n"));
    return 1;
  }

  int64_t n = 1;
  for (int i = 0; i < r; i++) { n *= shape[i]; }

  void* args[6+(8*3)];
  size_t args_sizes[6+(8*3)];

  args[0] = &dst;
  args_sizes[0] = sizeof(gpu_mem);
  args[1] = &dst_offset;
  args_sizes[1] = sizeof(dst_offset);
  args[2] = &src;
  args_sizes[2] = sizeof(gpu_mem);
  args[3] = &src_offset;
  args_sizes[3] = sizeof(src_offset);
  args[4] = &n;
  args_sizes[4] = sizeof(n);
  args[5] = &r;
  args_sizes[5] = sizeof(r);

  int64_t zero = 0;

  for (int i = 0; i < 8; i++) {
    args_sizes[6+i*3] = sizeof(int64_t);
    args_sizes[6+i*3+1] = sizeof(int64_t);
    args_sizes[6+i*3+2] = sizeof(int64_t);
    if (i < r) {
      args[6+i*3] = &shape[i];
      args[6+i*3+1] = &dst_strides[i];
      args[6+i*3+2] = &src_strides[i];
    } else {
      args[6+i*3] = &zero;
      args[6+i*3+1] = &zero;
      args[6+i*3+2] = &zero;
    }
  }
  const size_t w = 256; // XXX: hardcoded thread block size.

  return gpu_launch_kernel(ctx, kernel, "copy_lmad_dev_to_dev",
                           (const int32_t[3]) {(n+w-1)/w,1,1},
                           (const int32_t[3]) {w,1,1},
                           0, 6+(8*3), args, args_sizes);
}

#define GEN_LMAD_COPY_ELEMENTS_GPU2GPU(NAME, ELEM_TYPE)                 \
  static int lmad_copy_elements_gpu2gpu_##NAME                          \
  (struct futhark_context* ctx,                                         \
   int r,                                                               \
   gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],             \
   gpu_mem src, int64_t src_offset, int64_t src_strides[r],             \
   int64_t shape[r]) {                                                  \
    return gpu_lmad_copy(ctx, ctx->kernels->lmad_copy_##NAME, r,        \
                         dst, dst_offset, dst_strides,                  \
                         src, src_offset, src_strides,                  \
                         shape);                                        \
  }                                                                     \

#define GEN_LMAD_COPY_GPU2GPU(NAME, ELEM_TYPE)                          \
  static int lmad_copy_gpu2gpu_##NAME                                   \
  (struct futhark_context* ctx,                                         \
   int r,                                                               \
   gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],             \
   gpu_mem src, int64_t src_offset, int64_t src_strides[r],             \
   int64_t shape[r]) {                                                  \
    log_copy(ctx, "GPU to GPU", r, dst_offset, dst_strides,             \
             src_offset, src_strides, shape);                           \
    int64_t size = 1;                                                   \
    for (int i = 0; i < r; i++) { size *= shape[i]; }                   \
    if (size == 0) { return FUTHARK_SUCCESS; }                          \
    int64_t k, n, m;                                                    \
    if (lmad_map_tr(&k, &n, &m,                                         \
                       r, dst_strides, src_strides, shape)) {           \
      log_transpose(ctx, k, n, m);                                      \
      return map_transpose_gpu2gpu_##NAME                               \
        (ctx, dst, dst_offset, src, src_offset, k, n, m);               \
    } else if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {   \
      if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}        \
      return gpu_memcpy(ctx,                                            \
                        dst, dst_offset*sizeof(ELEM_TYPE),              \
                        src, src_offset*sizeof(ELEM_TYPE),              \
                        size * sizeof(ELEM_TYPE));                      \
    } else {                                                            \
      if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}     \
      return lmad_copy_elements_gpu2gpu_##NAME                          \
        (ctx, r,                                                        \
         dst, dst_offset, dst_strides,                                  \
         src, src_offset, src_strides,                                  \
         shape);                                                        \
    }                                                                   \
  }

static int
lmad_copy_elements_host2gpu(struct futhark_context *ctx, size_t elem_size,
                            int r,
                            gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],
                            unsigned char* src, int64_t src_offset, int64_t src_strides[r],
                            int64_t shape[r]) {
  (void)ctx; (void)elem_size; (void)r;
  (void)dst; (void)dst_offset; (void)dst_strides;
  (void)src; (void)src_offset; (void)src_strides;
  (void)shape;
  set_error(ctx, strdup("Futhark runtime limitation:\nCannot copy unstructured array from host to GPU.\n"));
  return 1;
}

static int
lmad_copy_elements_gpu2host (struct futhark_context *ctx, size_t elem_size,
                             int r,
                             unsigned char* dst, int64_t dst_offset, int64_t dst_strides[r],
                             gpu_mem src, int64_t src_offset, int64_t src_strides[r],
                             int64_t shape[r]) {
  (void)ctx; (void)elem_size; (void)r;
  (void)dst; (void)dst_offset; (void)dst_strides;
  (void)src; (void)src_offset; (void)src_strides;
  (void)shape;
  set_error(ctx, strdup("Futhark runtime limitation:\nCannot copy unstructured array from GPU to host.\n"));
  return 1;
}

#define GEN_LMAD_COPY_ELEMENTS_HOSTGPU(NAME, ELEM_TYPE)                 \
  static int lmad_copy_elements_gpu2gpu_##NAME                          \
  (struct futhark_context* ctx,                                         \
   int r,                                                               \
   gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],             \
   gpu_mem src, int64_t src_offset, int64_t src_strides[r],             \
   int64_t shape[r]) {                                                  \
    return (ctx, ctx->kernels->lmad_copy_##NAME, r,                     \
                         dst, dst_offset, dst_strides,                  \
                         src, src_offset, src_strides,                  \
                         shape);                                        \
  }                                                                     \


static int lmad_copy_host2gpu(struct futhark_context* ctx, size_t elem_size, bool sync,
                              int r,
                              gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],
                              unsigned char* src, int64_t src_offset, int64_t src_strides[r],
                              int64_t shape[r]) {
  log_copy(ctx, "Host to GPU", r, dst_offset, dst_strides,
           src_offset, src_strides, shape);
  int64_t size = elem_size;
  for (int i = 0; i < r; i++) { size *= shape[i]; }
  if (size == 0) { return FUTHARK_SUCCESS; }
  int64_t k, n, m;
  if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {
    if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}
    return memcpy_host2gpu(ctx, sync,
                           dst, dst_offset*elem_size,
                           src, src_offset*elem_size,
                           size);
  } else {
    if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}
    int error;
    error = lmad_copy_elements_host2gpu
      (ctx, elem_size, r,
       dst, dst_offset, dst_strides,
       src, src_offset, src_strides,
       shape);
    if (error == 0 && sync) {
      error = futhark_context_sync(ctx);
    }
    return error;
  }
}

static int lmad_copy_gpu2host(struct futhark_context* ctx, size_t elem_size, bool sync,
                              int r,
                              unsigned char* dst, int64_t dst_offset, int64_t dst_strides[r],
                              gpu_mem src, int64_t src_offset, int64_t src_strides[r],
                              int64_t shape[r]) {
  log_copy(ctx, "Host to GPU", r, dst_offset, dst_strides,
           src_offset, src_strides, shape);
  int64_t size = elem_size;
  for (int i = 0; i < r; i++) { size *= shape[i]; }
  if (size == 0) { return FUTHARK_SUCCESS; }
  int64_t k, n, m;
  if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {
    if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}
    return memcpy_gpu2host(ctx, sync,
                           dst, dst_offset*elem_size,
                           src, src_offset*elem_size,
                           size);
  } else {
    if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}
    int error;
    error = lmad_copy_elements_gpu2host
      (ctx, elem_size, r,
       dst, dst_offset, dst_strides,
       src, src_offset, src_strides,
       shape);
    if (error == 0 && sync) {
      error = futhark_context_sync(ctx);
    }
    return error;
  }
}

GEN_MAP_TRANSPOSE_GPU2GPU(1b, uint8_t)
GEN_MAP_TRANSPOSE_GPU2GPU(2b, uint16_t)
GEN_MAP_TRANSPOSE_GPU2GPU(4b, uint32_t)
GEN_MAP_TRANSPOSE_GPU2GPU(8b, uint64_t)

GEN_LMAD_COPY_ELEMENTS_GPU2GPU(1b, uint8_t)
GEN_LMAD_COPY_ELEMENTS_GPU2GPU(2b, uint16_t)
GEN_LMAD_COPY_ELEMENTS_GPU2GPU(4b, uint32_t)
GEN_LMAD_COPY_ELEMENTS_GPU2GPU(8b, uint64_t)

GEN_LMAD_COPY_GPU2GPU(1b, uint8_t)
GEN_LMAD_COPY_GPU2GPU(2b, uint16_t)
GEN_LMAD_COPY_GPU2GPU(4b, uint32_t)
GEN_LMAD_COPY_GPU2GPU(8b, uint64_t)

// End of gpu.h

static int gpu_macros(struct futhark_context *ctx, char ***names_out, int64_t **values_out)
{
    int num_macros = 67;
    char **names = malloc(num_macros * sizeof(char *));
    int64_t *values = malloc(num_macros * sizeof(int64_t));
    
    {
        names[0] = "inner_SMJ_intzisegmap_24657_dim1";
        values[0] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24645;
    }
    {
        names[1] = "inner_SMJ_intzisegmap_24657zisegmap_tblock_sizze_24653";
        values[1] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24645;
    }
    {
        names[2] = "inner_SMJ_intzigpuseq_27748_dim1";
        values[2] = (int64_t) 1;
    }
    {
        names[3] = "inner_SMJ_intzisegmap_24627_dim1";
        values[3] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24629;
    }
    {
        names[4] = "inner_SMJ_intzisegmap_24627zisegmap_tblock_sizze_24630";
        values[4] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24629;
    }
    {
        names[5] = "inner_SMJ_intzisegmap_24635_dim1";
        values[5] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24637;
    }
    {
        names[6] = "inner_SMJ_intzisegmap_24635zisegmap_tblock_sizze_24638";
        values[6] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24637;
    }
    {
        names[7] = "inner_SMJ_intzigpuseq_27701_dim1";
        values[7] = (int64_t) 1;
    }
    {
        names[8] = "inner_SMJ_intzigpuseq_27695_dim1";
        values[8] = (int64_t) 1;
    }
    {
        names[9] = "inner_SMJ_intzigpuseq_27689_dim1";
        values[9] = (int64_t) 1;
    }
    {
        names[10] = "inner_SMJ_intzisegmap_24619_dim1";
        values[10] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24603;
    }
    {
        names[11] = "inner_SMJ_intzisegmap_24619zisegmap_tblock_sizze_24615";
        values[11] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24603;
    }
    {
        names[12] = "inner_SMJ_intzisegscan_24599_dim1";
        values[12] = *ctx->tuning_params.inner_SMJ_intzisegscan_tblock_sizze_24593;
    }
    {
        names[13] = "inner_SMJ_intzisegscan_24599zisegscan_tblock_sizze_24594";
        values[13] = *ctx->tuning_params.inner_SMJ_intzisegscan_tblock_sizze_24593;
    }
    {
        names[14] = "inner_SMJ_intzisegscan_24599zichunk_sizze_27532";
        values[14] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[15] = "inner_SMJ_intzisegmap_24585_dim1";
        values[15] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24587;
    }
    {
        names[16] = "inner_SMJ_intzisegmap_24585zisegmap_tblock_sizze_24588";
        values[16] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24587;
    }
    {
        names[17] = "inner_SMJ_intzisegscan_24583_dim1";
        values[17] = *ctx->tuning_params.inner_SMJ_intzisegscan_tblock_sizze_24577;
    }
    {
        names[18] = "inner_SMJ_intzisegscan_24583zisegscan_tblock_sizze_24578";
        values[18] = *ctx->tuning_params.inner_SMJ_intzisegscan_tblock_sizze_24577;
    }
    {
        names[19] = "inner_SMJ_intzisegscan_24583zichunk_sizze_27395";
        values[19] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[20] = "inner_SMJ_intzigpuseq_27384_dim1";
        values[20] = (int64_t) 1;
    }
    {
        names[21] = "inner_SMJ_intzisegmap_24572_dim1";
        values[21] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24559;
    }
    {
        names[22] = "inner_SMJ_intzisegmap_24572zisegmap_tblock_sizze_24568";
        values[22] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24559;
    }
    {
        names[23] = "inner_SMJ_intzisegmap_24551_dim1";
        values[23] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24537;
    }
    {
        names[24] = "inner_SMJ_intzisegmap_24551zisegmap_tblock_sizze_24547";
        values[24] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24537;
    }
    {
        names[25] = "inner_SMJ_intzisegmap_24530_dim1";
        values[25] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24517;
    }
    {
        names[26] = "inner_SMJ_intzisegmap_24530zisegmap_tblock_sizze_24526";
        values[26] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24517;
    }
    {
        names[27] = "inner_SMJ_intzisegmap_24509_dim1";
        values[27] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24495;
    }
    {
        names[28] = "inner_SMJ_intzisegmap_24509zisegmap_tblock_sizze_24505";
        values[28] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24495;
    }
    {
        names[29] = "inner_SMJ_intzisegmap_24488_dim1";
        values[29] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24475;
    }
    {
        names[30] = "inner_SMJ_intzisegmap_24488zisegmap_tblock_sizze_24484";
        values[30] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24475;
    }
    {
        names[31] = "inner_SMJ_intzisegmap_24467_dim1";
        values[31] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24453;
    }
    {
        names[32] = "inner_SMJ_intzisegmap_24467zisegmap_tblock_sizze_24463";
        values[32] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24453;
    }
    {
        names[33] = "inner_SMJ_intzisegmap_intrablock_25740_dim1";
        values[33] = *ctx->tuning_params.inner_SMJ_intzitile_sizze_25741;
    }
    {
        names[34] = "inner_SMJ_intzisegmap_intrablock_25740zitile_sizze_25742";
        values[34] = *ctx->tuning_params.inner_SMJ_intzitile_sizze_25741;
    }
    {
        names[35] = "inner_SMJ_intzisegmap_intrablock_25740zibytes_26359";
        values[35] = (int64_t) 8 * *ctx->tuning_params.inner_SMJ_intzitile_sizze_25741;
    }
    {
        names[36] = "inner_SMJ_intzisegmap_intrablock_25740zibytes_26361";
        values[36] = (int64_t) 4 * *ctx->tuning_params.inner_SMJ_intzitile_sizze_25741;
    }
    {
        names[37] = "inner_SMJ_intzisegmap_intrablock_25385_dim1";
        values[37] = *ctx->tuning_params.inner_SMJ_intzitile_sizze_25386;
    }
    {
        names[38] = "inner_SMJ_intzisegmap_intrablock_25385zitile_sizze_25387";
        values[38] = *ctx->tuning_params.inner_SMJ_intzitile_sizze_25386;
    }
    {
        names[39] = "inner_SMJ_intzisegmap_intrablock_25385zibytes_26420";
        values[39] = (int64_t) 8 * *ctx->tuning_params.inner_SMJ_intzitile_sizze_25386;
    }
    {
        names[40] = "inner_SMJ_intzisegmap_intrablock_25385zibytes_26422";
        values[40] = (int64_t) 4 * *ctx->tuning_params.inner_SMJ_intzitile_sizze_25386;
    }
    {
        names[41] = "inner_SMJ_intzigpuseq_27271_dim1";
        values[41] = (int64_t) 1;
    }
    {
        names[42] = "inner_SMJ_intzigpuseq_27265_dim1";
        values[42] = (int64_t) 1;
    }
    {
        names[43] = "inner_SMJ_intzigpuseq_27259_dim1";
        values[43] = (int64_t) 1;
    }
    {
        names[44] = "inner_SMJ_intzigpuseq_27243_dim1";
        values[44] = (int64_t) 1;
    }
    {
        names[45] = "inner_SMJ_intzigpuseq_27237_dim1";
        values[45] = (int64_t) 1;
    }
    {
        names[46] = "inner_SMJ_intzisegmap_24115_dim1";
        values[46] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_23946;
    }
    {
        names[47] = "inner_SMJ_intzisegmap_24115zisegmap_tblock_sizze_24110";
        values[47] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_23946;
    }
    {
        names[48] = "inner_SMJ_intzisegmap_23741_dim1";
        values[48] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_23529;
    }
    {
        names[49] = "inner_SMJ_intzisegmap_23741zisegmap_tblock_sizze_23736";
        values[49] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_23529;
    }
    {
        names[50] = "inner_SMJ_intzigpuseq_27175_dim1";
        values[50] = (int64_t) 1;
    }
    {
        names[51] = "inner_SMJ_intzigpuseq_27169_dim1";
        values[51] = (int64_t) 1;
    }
    {
        names[52] = "inner_SMJ_intzigpuseq_27163_dim1";
        values[52] = (int64_t) 1;
    }
    {
        names[53] = "inner_SMJ_intzisegmap_intrablock_25030_dim1";
        values[53] = *ctx->tuning_params.inner_SMJ_intzitile_sizze_25031;
    }
    {
        names[54] = "inner_SMJ_intzisegmap_intrablock_25030zitile_sizze_25032";
        values[54] = *ctx->tuning_params.inner_SMJ_intzitile_sizze_25031;
    }
    {
        names[55] = "inner_SMJ_intzisegmap_intrablock_25030zibytes_26564";
        values[55] = (int64_t) 8 * *ctx->tuning_params.inner_SMJ_intzitile_sizze_25031;
    }
    {
        names[56] = "inner_SMJ_intzisegmap_intrablock_25030zibytes_26566";
        values[56] = (int64_t) 4 * *ctx->tuning_params.inner_SMJ_intzitile_sizze_25031;
    }
    {
        names[57] = "inner_SMJ_intzisegmap_intrablock_24675_dim1";
        values[57] = *ctx->tuning_params.inner_SMJ_intzitile_sizze_24676;
    }
    {
        names[58] = "inner_SMJ_intzisegmap_intrablock_24675zitile_sizze_24677";
        values[58] = *ctx->tuning_params.inner_SMJ_intzitile_sizze_24676;
    }
    {
        names[59] = "inner_SMJ_intzisegmap_intrablock_24675zibytes_26625";
        values[59] = (int64_t) 8 * *ctx->tuning_params.inner_SMJ_intzitile_sizze_24676;
    }
    {
        names[60] = "inner_SMJ_intzisegmap_intrablock_24675zibytes_26627";
        values[60] = (int64_t) 4 * *ctx->tuning_params.inner_SMJ_intzitile_sizze_24676;
    }
    {
        names[61] = "inner_SMJ_intzigpuseq_27104_dim1";
        values[61] = (int64_t) 1;
    }
    {
        names[62] = "inner_SMJ_intzigpuseq_27098_dim1";
        values[62] = (int64_t) 1;
    }
    {
        names[63] = "inner_SMJ_intzigpuseq_27092_dim1";
        values[63] = (int64_t) 1;
    }
    {
        names[64] = "inner_SMJ_intzigpuseq_27076_dim1";
        values[64] = (int64_t) 1;
    }
    {
        names[65] = "inner_SMJ_intzigpuseq_27070_dim1";
        values[65] = (int64_t) 1;
    }
    {
        names[66] = "inner_SMJ_intzigpuseq_27038_dim1";
        values[66] = (int64_t) 1;
    }
    *names_out = names;
    *values_out = values;
    return num_macros;
}
static char *get_failure_msg(int failure_idx, int64_t args[])
{
    (void) args;
    switch (failure_idx) {
        
      case 0:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:150:44-49\n   #1  ftSMJerr.fut:315:124-127\n   #2  ftSMJerr.fut:304:1-315:127\n", args[0], args[1]);
            break;
        }
        
      case 1:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:150:55-60\n   #1  ftSMJerr.fut:315:124-127\n   #2  ftSMJerr.fut:304:1-315:127\n", args[0], args[1]);
            break;
        }
        
      case 2:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:168:37-45\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftbasics.fut:155:8-215:8\n   #3  ftSMJerr.fut:315:124-127\n   #4  ftSMJerr.fut:304:1-315:127\n", args[0], args[1]);
            break;
        }
        
      case 3:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:179:25-32\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftbasics.fut:155:8-215:8\n   #3  ftSMJerr.fut:315:124-127\n   #4  ftSMJerr.fut:304:1-315:127\n", args[0], args[1]);
            break;
        }
        
      case 4:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:179:39-48\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftbasics.fut:155:8-215:8\n   #3  ftSMJerr.fut:315:124-127\n   #4  ftSMJerr.fut:304:1-315:127\n", args[0], args[1]);
            break;
        }
        
      case 5:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:186:25-32\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftbasics.fut:155:8-215:8\n   #3  ftSMJerr.fut:315:124-127\n   #4  ftSMJerr.fut:304:1-315:127\n", args[0], args[1]);
            break;
        }
        
      case 6:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:186:39-48\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftbasics.fut:155:8-215:8\n   #3  ftSMJerr.fut:315:124-127\n   #4  ftSMJerr.fut:304:1-315:127\n", args[0], args[1]);
            break;
        }
        
      case 7:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:120:8-14\n   #1  ftbasics.fut:190:80-82\n   #2  /prelude/functional.fut:9:44-45\n   #3  ftbasics.fut:155:8-215:8\n   #4  ftSMJerr.fut:315:124-127\n   #5  ftSMJerr.fut:304:1-315:127\n", args[0], args[1]);
            break;
        }
        
      case 8:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:118:31-39\n   #1  ftbasics.fut:190:80-82\n   #2  /prelude/functional.fut:9:44-45\n   #3  ftbasics.fut:155:8-215:8\n   #4  ftSMJerr.fut:315:124-127\n   #5  ftSMJerr.fut:304:1-315:127\n", args[0], args[1]);
            break;
        }
        
      case 9:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:118:45-50\n   #1  ftbasics.fut:190:80-82\n   #2  /prelude/functional.fut:9:44-45\n   #3  ftbasics.fut:155:8-215:8\n   #4  ftSMJerr.fut:315:124-127\n   #5  ftSMJerr.fut:304:1-315:127\n", args[0], args[1]);
            break;
        }
        
      case 10:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:126:15-24\n   #1  ftbasics.fut:190:80-82\n   #2  /prelude/functional.fut:9:44-45\n   #3  ftbasics.fut:155:8-215:8\n   #4  ftSMJerr.fut:315:124-127\n   #5  ftSMJerr.fut:304:1-315:127\n", args[0], args[1]);
            break;
        }
        
      case 11:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:126:31-38\n   #1  ftbasics.fut:190:80-82\n   #2  /prelude/functional.fut:9:44-45\n   #3  ftbasics.fut:155:8-215:8\n   #4  ftSMJerr.fut:315:124-127\n   #5  ftSMJerr.fut:304:1-315:127\n", args[0], args[1]);
            break;
        }
        
      case 12:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:136:15-22\n   #1  ftbasics.fut:190:80-82\n   #2  /prelude/functional.fut:9:44-45\n   #3  ftbasics.fut:155:8-215:8\n   #4  ftSMJerr.fut:315:124-127\n   #5  ftSMJerr.fut:304:1-315:127\n", args[0], args[1]);
            break;
        }
        
      case 13:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:136:28-35\n   #1  ftbasics.fut:190:80-82\n   #2  /prelude/functional.fut:9:44-45\n   #3  ftbasics.fut:155:8-215:8\n   #4  ftSMJerr.fut:315:124-127\n   #5  ftSMJerr.fut:304:1-315:127\n", args[0], args[1]);
            break;
        }
        
      case 14:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:194:17-23\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftbasics.fut:155:8-215:8\n   #3  ftSMJerr.fut:315:124-127\n   #4  ftSMJerr.fut:304:1-315:127\n", args[0], args[1]);
            break;
        }
        
      case 15:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:195:19-27\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftbasics.fut:155:8-215:8\n   #3  ftSMJerr.fut:315:124-127\n   #4  ftSMJerr.fut:304:1-315:127\n", args[0], args[1]);
            break;
        }
        
      case 16:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:195:34-40\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftbasics.fut:155:8-215:8\n   #3  ftSMJerr.fut:315:124-127\n   #4  ftSMJerr.fut:304:1-315:127\n", args[0], args[1]);
            break;
        }
        
      case 17:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftSMJerr.fut:103:19-41\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJerr.fut:102:8-140:6\n   #3  ftSMJerr.fut:315:124-127\n   #4  ftSMJerr.fut:304:1-315:127\n", args[0], args[1]);
            break;
        }
        
      case 18:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftSMJerr.fut:104:44-63\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJerr.fut:102:8-140:6\n   #3  ftSMJerr.fut:315:124-127\n   #4  ftSMJerr.fut:304:1-315:127\n", args[0], args[1]);
            break;
        }
        
      case 19:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftSMJerr.fut:105:19-46\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJerr.fut:102:8-140:6\n   #3  ftSMJerr.fut:315:124-127\n   #4  ftSMJerr.fut:304:1-315:127\n", args[0], args[1]);
            break;
        }
        
      case 20:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftSMJerr.fut:110:36-61\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJerr.fut:102:8-140:6\n   #3  ftSMJerr.fut:315:124-127\n   #4  ftSMJerr.fut:304:1-315:127\n", args[0], args[1]);
            break;
        }
        
      case 21:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftSMJerr.fut:111:23-29\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJerr.fut:102:8-140:6\n   #3  ftSMJerr.fut:315:124-127\n   #4  ftSMJerr.fut:304:1-315:127\n", args[0], args[1]);
            break;
        }
        
      case 22:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftSMJerr.fut:112:56-83\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJerr.fut:102:8-140:6\n   #3  ftSMJerr.fut:315:124-127\n   #4  ftSMJerr.fut:304:1-315:127\n", args[0], args[1]);
            break;
        }
        
      case 23:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftSMJerr.fut:113:23-51\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJerr.fut:102:8-140:6\n   #3  ftSMJerr.fut:315:124-127\n   #4  ftSMJerr.fut:304:1-315:127\n", args[0], args[1]);
            break;
        }
        
      case 24:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftSMJerr.fut:114:27-55\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJerr.fut:102:8-140:6\n   #3  ftSMJerr.fut:315:124-127\n   #4  ftSMJerr.fut:304:1-315:127\n", args[0], args[1]);
            break;
        }
        
      case 25:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftSMJerr.fut:115:27-49\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJerr.fut:102:8-140:6\n   #3  ftSMJerr.fut:315:124-127\n   #4  ftSMJerr.fut:304:1-315:127\n", args[0], args[1]);
            break;
        }
        
      case 26:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftSMJerr.fut:126:36-61\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJerr.fut:102:8-140:6\n   #3  ftSMJerr.fut:315:124-127\n   #4  ftSMJerr.fut:304:1-315:127\n", args[0], args[1]);
            break;
        }
        
      case 27:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftSMJerr.fut:127:23-29\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJerr.fut:102:8-140:6\n   #3  ftSMJerr.fut:315:124-127\n   #4  ftSMJerr.fut:304:1-315:127\n", args[0], args[1]);
            break;
        }
        
      case 28:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftSMJerr.fut:128:56-83\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJerr.fut:102:8-140:6\n   #3  ftSMJerr.fut:315:124-127\n   #4  ftSMJerr.fut:304:1-315:127\n", args[0], args[1]);
            break;
        }
        
      case 29:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftSMJerr.fut:129:23-51\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJerr.fut:102:8-140:6\n   #3  ftSMJerr.fut:315:124-127\n   #4  ftSMJerr.fut:304:1-315:127\n", args[0], args[1]);
            break;
        }
        
      case 30:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftSMJerr.fut:130:27-55\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJerr.fut:102:8-140:6\n   #3  ftSMJerr.fut:315:124-127\n   #4  ftSMJerr.fut:304:1-315:127\n", args[0], args[1]);
            break;
        }
        
      case 31:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftSMJerr.fut:131:27-49\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJerr.fut:102:8-140:6\n   #3  ftSMJerr.fut:315:124-127\n   #4  ftSMJerr.fut:304:1-315:127\n", args[0], args[1]);
            break;
        }
    }
    return strdup("Unknown error.  This is a compiler bug.");
}
struct program {
    int dummy;
    gpu_kernel builtinzhiota_i64ziiota_i64_27020;
    gpu_kernel builtinzhreplicate_i32zireplicate_27049;
    gpu_kernel builtinzhreplicate_i64zireplicate_27023;
    gpu_kernel builtinzhreplicate_i8zireplicate_27405;
    gpu_kernel inner_SMJ_intzigpuseq_27038;
    gpu_kernel inner_SMJ_intzigpuseq_27070;
    gpu_kernel inner_SMJ_intzigpuseq_27076;
    gpu_kernel inner_SMJ_intzigpuseq_27092;
    gpu_kernel inner_SMJ_intzigpuseq_27098;
    gpu_kernel inner_SMJ_intzigpuseq_27104;
    gpu_kernel inner_SMJ_intzigpuseq_27163;
    gpu_kernel inner_SMJ_intzigpuseq_27169;
    gpu_kernel inner_SMJ_intzigpuseq_27175;
    gpu_kernel inner_SMJ_intzigpuseq_27237;
    gpu_kernel inner_SMJ_intzigpuseq_27243;
    gpu_kernel inner_SMJ_intzigpuseq_27259;
    gpu_kernel inner_SMJ_intzigpuseq_27265;
    gpu_kernel inner_SMJ_intzigpuseq_27271;
    gpu_kernel inner_SMJ_intzigpuseq_27384;
    gpu_kernel inner_SMJ_intzigpuseq_27689;
    gpu_kernel inner_SMJ_intzigpuseq_27695;
    gpu_kernel inner_SMJ_intzigpuseq_27701;
    gpu_kernel inner_SMJ_intzigpuseq_27748;
    gpu_kernel inner_SMJ_intzireplicate_27755;
    gpu_kernel inner_SMJ_intzireplicate_27775;
    gpu_kernel inner_SMJ_intzisegmap_23741;
    gpu_kernel inner_SMJ_intzisegmap_24115;
    gpu_kernel inner_SMJ_intzisegmap_24467;
    gpu_kernel inner_SMJ_intzisegmap_24488;
    gpu_kernel inner_SMJ_intzisegmap_24509;
    gpu_kernel inner_SMJ_intzisegmap_24530;
    gpu_kernel inner_SMJ_intzisegmap_24551;
    gpu_kernel inner_SMJ_intzisegmap_24572;
    gpu_kernel inner_SMJ_intzisegmap_24585;
    gpu_kernel inner_SMJ_intzisegmap_24619;
    gpu_kernel inner_SMJ_intzisegmap_24627;
    gpu_kernel inner_SMJ_intzisegmap_24635;
    gpu_kernel inner_SMJ_intzisegmap_24657;
    gpu_kernel inner_SMJ_intzisegmap_intrablock_24675;
    gpu_kernel inner_SMJ_intzisegmap_intrablock_25030;
    gpu_kernel inner_SMJ_intzisegmap_intrablock_25385;
    gpu_kernel inner_SMJ_intzisegmap_intrablock_25740;
    gpu_kernel inner_SMJ_intzisegscan_24583;
    gpu_kernel inner_SMJ_intzisegscan_24599;
};
static void setup_program(struct futhark_context *ctx)
{
    (void) ctx;
    
    int error = 0;
    
    (void) error;
    ctx->program = malloc(sizeof(struct program));
    gpu_create_kernel(ctx, &ctx->program->builtinzhiota_i64ziiota_i64_27020, "builtinzhiota_i64ziiota_i64_27020");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_i32zireplicate_27049, "builtinzhreplicate_i32zireplicate_27049");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_i64zireplicate_27023, "builtinzhreplicate_i64zireplicate_27023");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_i8zireplicate_27405, "builtinzhreplicate_i8zireplicate_27405");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzigpuseq_27038, "inner_SMJ_intzigpuseq_27038");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzigpuseq_27070, "inner_SMJ_intzigpuseq_27070");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzigpuseq_27076, "inner_SMJ_intzigpuseq_27076");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzigpuseq_27092, "inner_SMJ_intzigpuseq_27092");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzigpuseq_27098, "inner_SMJ_intzigpuseq_27098");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzigpuseq_27104, "inner_SMJ_intzigpuseq_27104");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzigpuseq_27163, "inner_SMJ_intzigpuseq_27163");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzigpuseq_27169, "inner_SMJ_intzigpuseq_27169");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzigpuseq_27175, "inner_SMJ_intzigpuseq_27175");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzigpuseq_27237, "inner_SMJ_intzigpuseq_27237");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzigpuseq_27243, "inner_SMJ_intzigpuseq_27243");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzigpuseq_27259, "inner_SMJ_intzigpuseq_27259");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzigpuseq_27265, "inner_SMJ_intzigpuseq_27265");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzigpuseq_27271, "inner_SMJ_intzigpuseq_27271");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzigpuseq_27384, "inner_SMJ_intzigpuseq_27384");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzigpuseq_27689, "inner_SMJ_intzigpuseq_27689");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzigpuseq_27695, "inner_SMJ_intzigpuseq_27695");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzigpuseq_27701, "inner_SMJ_intzigpuseq_27701");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzigpuseq_27748, "inner_SMJ_intzigpuseq_27748");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzireplicate_27755, "inner_SMJ_intzireplicate_27755");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzireplicate_27775, "inner_SMJ_intzireplicate_27775");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzisegmap_23741, "inner_SMJ_intzisegmap_23741");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzisegmap_24115, "inner_SMJ_intzisegmap_24115");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzisegmap_24467, "inner_SMJ_intzisegmap_24467");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzisegmap_24488, "inner_SMJ_intzisegmap_24488");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzisegmap_24509, "inner_SMJ_intzisegmap_24509");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzisegmap_24530, "inner_SMJ_intzisegmap_24530");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzisegmap_24551, "inner_SMJ_intzisegmap_24551");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzisegmap_24572, "inner_SMJ_intzisegmap_24572");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzisegmap_24585, "inner_SMJ_intzisegmap_24585");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzisegmap_24619, "inner_SMJ_intzisegmap_24619");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzisegmap_24627, "inner_SMJ_intzisegmap_24627");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzisegmap_24635, "inner_SMJ_intzisegmap_24635");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzisegmap_24657, "inner_SMJ_intzisegmap_24657");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzisegmap_intrablock_24675, "inner_SMJ_intzisegmap_intrablock_24675");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzisegmap_intrablock_25030, "inner_SMJ_intzisegmap_intrablock_25030");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzisegmap_intrablock_25385, "inner_SMJ_intzisegmap_intrablock_25385");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzisegmap_intrablock_25740, "inner_SMJ_intzisegmap_intrablock_25740");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzisegscan_24583, "inner_SMJ_intzisegscan_24583");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzisegscan_24599, "inner_SMJ_intzisegscan_24599");
}
static void teardown_program(struct futhark_context *ctx)
{
    (void) ctx;
    
    int error = 0;
    
    (void) error;
    gpu_free_kernel(ctx, ctx->program->builtinzhiota_i64ziiota_i64_27020);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_i32zireplicate_27049);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_i64zireplicate_27023);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_i8zireplicate_27405);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27038);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27070);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27076);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27092);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27098);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27104);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27163);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27169);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27175);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27237);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27243);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27259);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27265);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27271);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27384);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27689);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27695);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27701);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27748);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzireplicate_27755);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzireplicate_27775);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_23741);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_24115);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_24467);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_24488);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_24509);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_24530);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_24551);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_24572);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_24585);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_24619);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_24627);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_24635);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_24657);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_intrablock_24675);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_intrablock_25030);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_intrablock_25385);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_intrablock_25740);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzisegscan_24583);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzisegscan_24599);
    free(ctx->program);
}
static void set_tuning_params(struct futhark_context *ctx)
{
    (void) ctx;
    ctx->tuning_params.builtinzhiota_i64zitblock_sizze_27024 = &ctx->cfg->tuning_params[0];
    ctx->tuning_params.builtinzhreplicate_i32zitblock_sizze_27053 = &ctx->cfg->tuning_params[1];
    ctx->tuning_params.builtinzhreplicate_i64zitblock_sizze_27027 = &ctx->cfg->tuning_params[2];
    ctx->tuning_params.builtinzhreplicate_i8zitblock_sizze_27409 = &ctx->cfg->tuning_params[3];
    ctx->tuning_params.inner_SMJ_intzisegmap_num_tblocks_24589 = &ctx->cfg->tuning_params[4];
    ctx->tuning_params.inner_SMJ_intzisegmap_num_tblocks_24631 = &ctx->cfg->tuning_params[5];
    ctx->tuning_params.inner_SMJ_intzisegmap_num_tblocks_24639 = &ctx->cfg->tuning_params[6];
    ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_23529 = &ctx->cfg->tuning_params[7];
    ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_23946 = &ctx->cfg->tuning_params[8];
    ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24453 = &ctx->cfg->tuning_params[9];
    ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24475 = &ctx->cfg->tuning_params[10];
    ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24495 = &ctx->cfg->tuning_params[11];
    ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24517 = &ctx->cfg->tuning_params[12];
    ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24537 = &ctx->cfg->tuning_params[13];
    ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24559 = &ctx->cfg->tuning_params[14];
    ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24587 = &ctx->cfg->tuning_params[15];
    ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24603 = &ctx->cfg->tuning_params[16];
    ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24629 = &ctx->cfg->tuning_params[17];
    ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24637 = &ctx->cfg->tuning_params[18];
    ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24645 = &ctx->cfg->tuning_params[19];
    ctx->tuning_params.inner_SMJ_intzisegscan_num_tblocks_24579 = &ctx->cfg->tuning_params[20];
    ctx->tuning_params.inner_SMJ_intzisegscan_num_tblocks_24595 = &ctx->cfg->tuning_params[21];
    ctx->tuning_params.inner_SMJ_intzisegscan_tblock_sizze_24577 = &ctx->cfg->tuning_params[22];
    ctx->tuning_params.inner_SMJ_intzisegscan_tblock_sizze_24593 = &ctx->cfg->tuning_params[23];
    ctx->tuning_params.inner_SMJ_intzisuff_outer_par_0 = &ctx->cfg->tuning_params[24];
    ctx->tuning_params.inner_SMJ_intzisuff_outer_par_1 = &ctx->cfg->tuning_params[25];
    ctx->tuning_params.inner_SMJ_intzitblock_sizze_27759 = &ctx->cfg->tuning_params[26];
    ctx->tuning_params.inner_SMJ_intzitblock_sizze_27779 = &ctx->cfg->tuning_params[27];
    ctx->tuning_params.inner_SMJ_intzitile_sizze_24676 = &ctx->cfg->tuning_params[28];
    ctx->tuning_params.inner_SMJ_intzitile_sizze_25031 = &ctx->cfg->tuning_params[29];
    ctx->tuning_params.inner_SMJ_intzitile_sizze_25386 = &ctx->cfg->tuning_params[30];
    ctx->tuning_params.inner_SMJ_intzitile_sizze_25741 = &ctx->cfg->tuning_params[31];
}
int memblock_unref_device(struct futhark_context *ctx, struct memblock_device *block, const char *desc)
{
    if (block->references != NULL) {
        *block->references -= 1;
        if (ctx->detail_memory)
            fprintf(ctx->log, "Unreferencing block %s (allocated as %s) in %s: %d references remaining.\n", desc, block->desc, "space 'device'", *block->references);
        if (*block->references == 0) {
            ctx->cur_mem_usage_device -= block->size;
            (void) gpu_free(ctx, block->mem, block->size, desc);
            free(block->references);
            if (ctx->detail_memory)
                fprintf(ctx->log, "%lld bytes freed (now allocated: %lld bytes)\n", (long long) block->size, (long long) ctx->cur_mem_usage_device);
        }
        block->references = NULL;
    }
    return 0;
}
int memblock_alloc_device(struct futhark_context *ctx, struct memblock_device *block, int64_t size, const char *desc)
{
    if (size < 0)
        futhark_panic(1, "Negative allocation of %lld bytes attempted for %s in %s.\n", (long long) size, desc, "space 'device'", ctx->cur_mem_usage_device);
    
    int ret = memblock_unref_device(ctx, block, desc);
    
    if (ret != FUTHARK_SUCCESS)
        return ret;
    if (ctx->detail_memory)
        fprintf(ctx->log, "Allocating %lld bytes for %s in %s (currently allocated: %lld bytes).\n", (long long) size, desc, "space 'device'", (long long) ctx->cur_mem_usage_device);
    (void) gpu_alloc(ctx, ctx->log, (size_t) size, desc, &block->mem, (size_t *) &size);
    if (ctx->error == NULL) {
        block->references = (int *) malloc(sizeof(int));
        *block->references = 1;
        block->size = size;
        block->desc = desc;
        
        long long new_usage = ctx->cur_mem_usage_device + size;
        
        if (ctx->detail_memory)
            fprintf(ctx->log, "Received block of %lld bytes; now allocated: %lld bytes", (long long) block->size, new_usage);
        ctx->cur_mem_usage_device = new_usage;
        if (new_usage > ctx->peak_mem_usage_device) {
            ctx->peak_mem_usage_device = new_usage;
            if (ctx->detail_memory)
                fprintf(ctx->log, " (new peak).\n");
        } else if (ctx->detail_memory)
            fprintf(ctx->log, ".\n");
        return FUTHARK_SUCCESS;
    } else {
        // We are naively assuming that any memory allocation error is due to OOM.
        lock_lock(&ctx->error_lock);
        
        char *old_error = ctx->error;
        
        ctx->error = msgprintf("Failed to allocate memory in %s.\nAttempted allocation: %12lld bytes\nCurrently allocated:  %12lld bytes\n%s", "space 'device'", (long long) size, (long long) ctx->cur_mem_usage_device, old_error);
        free(old_error);
        lock_unlock(&ctx->error_lock);
        return FUTHARK_OUT_OF_MEMORY;
    }
}
int memblock_set_device(struct futhark_context *ctx, struct memblock_device *lhs, struct memblock_device *rhs, const char *lhs_desc)
{
    int ret = memblock_unref_device(ctx, lhs, lhs_desc);
    
    if (rhs->references != NULL)
        (*rhs->references)++;
    *lhs = *rhs;
    return ret;
}
int memblock_unref(struct futhark_context *ctx, struct memblock *block, const char *desc)
{
    if (block->references != NULL) {
        *block->references -= 1;
        if (ctx->detail_memory)
            fprintf(ctx->log, "Unreferencing block %s (allocated as %s) in %s: %d references remaining.\n", desc, block->desc, "default space", *block->references);
        if (*block->references == 0) {
            ctx->cur_mem_usage_default -= block->size;
            host_free(ctx, (size_t) block->size, desc, (void *) block->mem);
            free(block->references);
            if (ctx->detail_memory)
                fprintf(ctx->log, "%lld bytes freed (now allocated: %lld bytes)\n", (long long) block->size, (long long) ctx->cur_mem_usage_default);
        }
        block->references = NULL;
    }
    return 0;
}
int memblock_alloc(struct futhark_context *ctx, struct memblock *block, int64_t size, const char *desc)
{
    if (size < 0)
        futhark_panic(1, "Negative allocation of %lld bytes attempted for %s in %s.\n", (long long) size, desc, "default space", ctx->cur_mem_usage_default);
    
    int ret = memblock_unref(ctx, block, desc);
    
    if (ret != FUTHARK_SUCCESS)
        return ret;
    if (ctx->detail_memory)
        fprintf(ctx->log, "Allocating %lld bytes for %s in %s (currently allocated: %lld bytes).\n", (long long) size, desc, "default space", (long long) ctx->cur_mem_usage_default);
    host_alloc(ctx, (size_t) size, desc, (size_t *) &size, (void *) &block->mem);
    if (ctx->error == NULL) {
        block->references = (int *) malloc(sizeof(int));
        *block->references = 1;
        block->size = size;
        block->desc = desc;
        
        long long new_usage = ctx->cur_mem_usage_default + size;
        
        if (ctx->detail_memory)
            fprintf(ctx->log, "Received block of %lld bytes; now allocated: %lld bytes", (long long) block->size, new_usage);
        ctx->cur_mem_usage_default = new_usage;
        if (new_usage > ctx->peak_mem_usage_default) {
            ctx->peak_mem_usage_default = new_usage;
            if (ctx->detail_memory)
                fprintf(ctx->log, " (new peak).\n");
        } else if (ctx->detail_memory)
            fprintf(ctx->log, ".\n");
        return FUTHARK_SUCCESS;
    } else {
        // We are naively assuming that any memory allocation error is due to OOM.
        lock_lock(&ctx->error_lock);
        
        char *old_error = ctx->error;
        
        ctx->error = msgprintf("Failed to allocate memory in %s.\nAttempted allocation: %12lld bytes\nCurrently allocated:  %12lld bytes\n%s", "default space", (long long) size, (long long) ctx->cur_mem_usage_default, old_error);
        free(old_error);
        lock_unlock(&ctx->error_lock);
        return FUTHARK_OUT_OF_MEMORY;
    }
}
int memblock_set(struct futhark_context *ctx, struct memblock *lhs, struct memblock *rhs, const char *lhs_desc)
{
    int ret = memblock_unref(ctx, lhs, lhs_desc);
    
    if (rhs->references != NULL)
        (*rhs->references)++;
    *lhs = *rhs;
    return ret;
}
char *futhark_context_report(struct futhark_context *ctx)
{
    if (futhark_context_sync(ctx) != 0)
        return NULL;
    
    struct str_builder builder;
    
    str_builder_init(&builder);
    str_builder_char(&builder, '{');
    str_builder_str(&builder, "\"memory\":{");
    str_builder(&builder, "\"space 'device'\": %lld", (long long) ctx->peak_mem_usage_device);
    str_builder_char(&builder, ',');
    str_builder(&builder, "\"default space\": %lld", (long long) ctx->peak_mem_usage_default);
    str_builder_str(&builder, "},\"events\":[");
    if (report_events_in_list(&ctx->event_list, &builder) != 0) {
        free(builder.str);
        return NULL;
    } else {
        str_builder_str(&builder, "]}");
        return builder.str;
    }
}
int futhark_context_clear_caches(struct futhark_context *ctx)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    ctx->peak_mem_usage_device = 0;
    ctx->peak_mem_usage_default = 0;
    if (ctx->error == NULL)
        gpu_free_all(ctx);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ctx->error != NULL;
}

// Start of context.h

// Internal functions.

static void set_error(struct futhark_context* ctx, char *error) {
  lock_lock(&ctx->error_lock);
  if (ctx->error == NULL) {
    ctx->error = error;
  } else {
    free(error);
  }
  lock_unlock(&ctx->error_lock);
}

// XXX: should be static, but used in ispc_util.h
void lexical_realloc_error(struct futhark_context* ctx, size_t new_size) {
  set_error(ctx,
            msgprintf("Failed to allocate memory.\nAttempted allocation: %12lld bytes\n",
                      (long long) new_size));
}

static int lexical_realloc(struct futhark_context *ctx,
                           unsigned char **ptr,
                           int64_t *old_size,
                           int64_t new_size) {
  unsigned char *new = realloc(*ptr, (size_t)new_size);
  if (new == NULL) {
    lexical_realloc_error(ctx, new_size);
    return FUTHARK_OUT_OF_MEMORY;
  } else {
    *ptr = new;
    *old_size = new_size;
    return FUTHARK_SUCCESS;
  }
}

static void free_all_in_free_list(struct futhark_context* ctx) {
  fl_mem mem;
  free_list_pack(&ctx->free_list);
  while (free_list_first(&ctx->free_list, (fl_mem*)&mem) == 0) {
    free((void*)mem);
  }
}

static int is_small_alloc(size_t size) {
  return size < 1024*1024;
}

static void host_alloc(struct futhark_context* ctx,
                       size_t size, const char* tag, size_t* size_out, void** mem_out) {
  if (is_small_alloc(size) || free_list_find(&ctx->free_list, size, tag, size_out, (fl_mem*)mem_out) != 0) {
    *size_out = size;
    *mem_out = malloc(size);
  }
}

static void host_free(struct futhark_context* ctx,
                      size_t size, const char* tag, void* mem) {
  // Small allocations are handled by malloc()s own free list.  The
  // threshold here is kind of arbitrary, but seems to work OK.
  // Larger allocations are mmap()ed/munmapped() every time, which is
  // very slow, and Futhark programs tend to use a few very large
  // allocations.
  if (is_small_alloc(size)) {
    free(mem);
  } else {
    free_list_insert(&ctx->free_list, size, (fl_mem)mem, tag);
  }
}

static void add_event(struct futhark_context* ctx,
                      const char* name,
                      char* description,
                      void* data,
                      event_report_fn f) {
  if (ctx->logging) {
    fprintf(ctx->log, "Event: %s\n%s\n", name, description);
  }
  add_event_to_list(&ctx->event_list, name, description, data, f);
}

char *futhark_context_get_error(struct futhark_context *ctx) {
  char *error = ctx->error;
  ctx->error = NULL;
  return error;
}

void futhark_context_config_set_debugging(struct futhark_context_config *cfg, int flag) {
    cfg->profiling = cfg->logging = cfg->debugging = flag;
}

void futhark_context_config_set_profiling(struct futhark_context_config *cfg, int flag) {
    cfg->profiling = flag;
}

void futhark_context_config_set_logging(struct futhark_context_config *cfg, int flag) {
    cfg->logging = flag;
}

void futhark_context_config_set_cache_file(struct futhark_context_config *cfg, const char *f) {
  cfg->cache_fname = strdup(f);
}

int futhark_get_tuning_param_count(void) {
  return num_tuning_params;
}

const char *futhark_get_tuning_param_name(int i) {
  return tuning_param_names[i];
}

const char *futhark_get_tuning_param_class(int i) {
    return tuning_param_classes[i];
}

void futhark_context_set_logging_file(struct futhark_context *ctx, FILE *f){
  ctx->log = f;
}

void futhark_context_pause_profiling(struct futhark_context *ctx) {
  ctx->profiling_paused = 1;
}

void futhark_context_unpause_profiling(struct futhark_context *ctx) {
  ctx->profiling_paused = 0;
}

struct futhark_context_config* futhark_context_config_new(void) {
  struct futhark_context_config* cfg = malloc(sizeof(struct futhark_context_config));
  if (cfg == NULL) {
    return NULL;
  }
  cfg->in_use = 0;
  cfg->debugging = 0;
  cfg->profiling = 0;
  cfg->logging = 0;
  cfg->cache_fname = NULL;
  cfg->num_tuning_params = num_tuning_params;
  cfg->tuning_params = malloc(cfg->num_tuning_params * sizeof(int64_t));
  memcpy(cfg->tuning_params, tuning_param_defaults,
         cfg->num_tuning_params * sizeof(int64_t));
  cfg->tuning_param_names = tuning_param_names;
  cfg->tuning_param_vars = tuning_param_vars;
  cfg->tuning_param_classes = tuning_param_classes;
  backend_context_config_setup(cfg);
  return cfg;
}

void futhark_context_config_free(struct futhark_context_config* cfg) {
  assert(!cfg->in_use);
  backend_context_config_teardown(cfg);
  free(cfg->cache_fname);
  free(cfg->tuning_params);
  free(cfg);
}

struct futhark_context* futhark_context_new(struct futhark_context_config* cfg) {
  struct futhark_context* ctx = malloc(sizeof(struct futhark_context));
  if (ctx == NULL) {
    return NULL;
  }
  assert(!cfg->in_use);
  ctx->cfg = cfg;
  ctx->cfg->in_use = 1;
  ctx->program_initialised = false;
  create_lock(&ctx->error_lock);
  create_lock(&ctx->lock);
  free_list_init(&ctx->free_list);
  event_list_init(&ctx->event_list);
  ctx->peak_mem_usage_default = 0;
  ctx->cur_mem_usage_default = 0;
  ctx->constants = malloc(sizeof(struct constants));
  ctx->debugging = cfg->debugging;
  ctx->logging = cfg->logging;
  ctx->detail_memory = cfg->logging;
  ctx->profiling = cfg->profiling;
  ctx->profiling_paused = 0;
  ctx->error = NULL;
  ctx->log = stderr;
  set_tuning_params(ctx);
  if (backend_context_setup(ctx) == 0) {
    setup_program(ctx);
    init_constants(ctx);
    ctx->program_initialised = true;
    (void)futhark_context_clear_caches(ctx);
    (void)futhark_context_sync(ctx);
  }
  return ctx;
}

void futhark_context_free(struct futhark_context* ctx) {
  if (ctx->program_initialised) {
    free_constants(ctx);
    teardown_program(ctx);
  }
  backend_context_teardown(ctx);
  free_all_in_free_list(ctx);
  free_list_destroy(&ctx->free_list);
  event_list_free(&ctx->event_list);
  free(ctx->constants);
  free(ctx->error);
  free_lock(&ctx->lock);
  free_lock(&ctx->error_lock);
  ctx->cfg->in_use = 0;
  free(ctx);
}

// End of context.h

// Start of copy.h

// Cache-oblivious map-transpose function.
#define GEN_MAP_TRANSPOSE(NAME, ELEM_TYPE)                              \
  static void map_transpose_##NAME                                      \
  (ELEM_TYPE* dst, ELEM_TYPE* src,                                      \
   int64_t k, int64_t m, int64_t n,                                     \
   int64_t cb, int64_t ce, int64_t rb, int64_t re)                      \
  {                                                                     \
  int32_t r = re - rb;                                                  \
  int32_t c = ce - cb;                                                  \
  if (k == 1) {                                                         \
    if (r <= 64 && c <= 64) {                                           \
      for (int64_t j = 0; j < c; j++) {                                 \
        for (int64_t i = 0; i < r; i++) {                               \
          dst[(j + cb) * n + (i + rb)] = src[(i + rb) * m + (j + cb)];  \
        }                                                               \
      }                                                                 \
    } else if (c <= r) {                                                \
      map_transpose_##NAME(dst, src, k, m, n, cb, ce, rb, rb + r/2);    \
      map_transpose_##NAME(dst, src, k, m, n, cb, ce, rb + r/2, re);    \
    } else {                                                            \
      map_transpose_##NAME(dst, src, k, m, n, cb, cb + c/2, rb, re);    \
      map_transpose_##NAME(dst, src, k, m, n, cb + c/2, ce, rb, re);    \
    }                                                                   \
  } else {                                                              \
  for (int64_t i = 0; i < k; i++) {                                     \
    map_transpose_##NAME(dst + i * m * n, src + i * m * n, 1, m, n, cb, ce, rb, re); \
  }\
} \
}

// Straightforward LMAD copy function.
#define GEN_LMAD_COPY_ELEMENTS(NAME, ELEM_TYPE)                         \
  static void lmad_copy_elements_##NAME(int r,                          \
                                        ELEM_TYPE* dst, int64_t dst_strides[r], \
                                        ELEM_TYPE *src, int64_t src_strides[r], \
                                        int64_t shape[r]) {             \
    if (r == 1) {                                                       \
      for (int i = 0; i < shape[0]; i++) {                              \
        dst[i*dst_strides[0]] = src[i*src_strides[0]];                  \
      }                                                                 \
    } else if (r > 1) {                                                 \
      for (int i = 0; i < shape[0]; i++) {                              \
        lmad_copy_elements_##NAME(r-1,                                  \
                                  dst+i*dst_strides[0], dst_strides+1,  \
                                  src+i*src_strides[0], src_strides+1,  \
                                  shape+1);                             \
      }                                                                 \
    }                                                                   \
  }                                                                     \

// Check whether this LMAD can be seen as a transposed 2D array.  This
// is done by checking every possible splitting point.
static bool lmad_is_tr(int64_t *n_out, int64_t *m_out,
                       int r,
                       const int64_t strides[r],
                       const int64_t shape[r]) {
  for (int i = 1; i < r; i++) {
    int n = 1, m = 1;
    bool ok = true;
    int64_t expected = 1;
    // Check strides before 'i'.
    for (int j = i-1; j >= 0; j--) {
      ok = ok && strides[j] == expected;
      expected *= shape[j];
      n *= shape[j];
    }
    // Check strides after 'i'.
    for (int j = r-1; j >= i; j--) {
      ok = ok && strides[j] == expected;
      expected *= shape[j];
      m *= shape[j];
    }
    if (ok) {
      *n_out = n;
      *m_out = m;
      return true;
    }
  }
  return false;
}

// This function determines whether the a 'dst' LMAD is row-major and
// 'src' LMAD is column-major.  Both LMADs are for arrays of the same
// shape.  Both LMADs are allowed to have additional dimensions "on
// top".  Essentially, this function determines whether a copy from
// 'src' to 'dst' is a "map(transpose)" that we know how to implement
// efficiently.  The LMADs can have arbitrary rank, and the main
// challenge here is checking whether the src LMAD actually
// corresponds to a 2D column-major layout by morally collapsing
// dimensions.  There is a lot of looping here, but the actual trip
// count is going to be very low in practice.
//
// Returns true if this is indeed a map(transpose), and writes the
// number of arrays, and moral array size to appropriate output
// parameters.
static bool lmad_map_tr(int64_t *num_arrays_out, int64_t *n_out, int64_t *m_out,
                        int r,
                        const int64_t dst_strides[r],
                        const int64_t src_strides[r],
                        const int64_t shape[r]) {
  int64_t rowmajor_strides[r];
  rowmajor_strides[r-1] = 1;

  for (int i = r-2; i >= 0; i--) {
    rowmajor_strides[i] = rowmajor_strides[i+1] * shape[i+1];
  }

  // map_r will be the number of mapped dimensions on top.
  int map_r = 0;
  int64_t num_arrays = 1;
  for (int i = 0; i < r; i++) {
    if (dst_strides[i] != rowmajor_strides[i] ||
        src_strides[i] != rowmajor_strides[i]) {
      break;
    } else {
      num_arrays *= shape[i];
      map_r++;
    }
  }

  *num_arrays_out = num_arrays;

  if (r==map_r) {
    return false;
  }

  if (memcmp(&rowmajor_strides[map_r],
             &dst_strides[map_r],
             sizeof(int64_t)*(r-map_r)) == 0) {
    return lmad_is_tr(n_out, m_out, r-map_r, src_strides+map_r, shape+map_r);
  } else if (memcmp(&rowmajor_strides[map_r],
                    &src_strides[map_r],
                    sizeof(int64_t)*(r-map_r)) == 0) {
    return lmad_is_tr(m_out, n_out, r-map_r, dst_strides+map_r, shape+map_r);
  }
  return false;
}

// Check if the strides correspond to row-major strides of *any*
// permutation of the shape.  This is done by recursive search with
// backtracking.  This is worst-case exponential, but hopefully the
// arrays we encounter do not have that many dimensions.
static bool lmad_contiguous_search(int checked, int64_t expected,
                                   int r,
                                   int64_t strides[r], int64_t shape[r], bool used[r]) {
  for (int i = 0; i < r; i++) {
    for (int j = 0; j < r; j++) {
      if (!used[j] && strides[j] == expected && strides[j] >= 0) {
        used[j] = true;
        if (checked+1 == r ||
            lmad_contiguous_search(checked+1, expected * shape[j], r, strides, shape, used)) {
          return true;
        }
        used[j] = false;
      }
    }
  }
  return false;
}

// Does this LMAD correspond to an array with positive strides and no
// holes?
static bool lmad_contiguous(int r, int64_t strides[r], int64_t shape[r]) {
  bool used[r];
  for (int i = 0; i < r; i++) {
    used[i] = false;
  }
  return lmad_contiguous_search(0, 1, r, strides, shape, used);
}

// Does this copy correspond to something that could be done with a
// memcpy()-like operation?  I.e. do the LMADs actually represent the
// same in-memory layout and are they contiguous?
static bool lmad_memcpyable(int r,
                            int64_t dst_strides[r], int64_t src_strides[r], int64_t shape[r]) {
  if (!lmad_contiguous(r, dst_strides, shape)) {
    return false;
  }
  for (int i = 0; i < r; i++) {
    if (dst_strides[i] != src_strides[i] && shape[i] != 1) {
      return false;
    }
  }
  return true;
}


static void log_copy(struct futhark_context* ctx,
                     const char *kind, int r,
                     int64_t dst_offset, int64_t dst_strides[r],
                     int64_t src_offset, int64_t src_strides[r],
                     int64_t shape[r]) {
  if (ctx->logging) {
    fprintf(ctx->log, "\n# Copy %s\n", kind);
    fprintf(ctx->log, "Shape: ");
    for (int i = 0; i < r; i++) { fprintf(ctx->log, "[%ld]", (long int)shape[i]); }
    fprintf(ctx->log, "\n");
    fprintf(ctx->log, "Dst offset: %ld\n", (long int)dst_offset);
    fprintf(ctx->log, "Dst strides:");
    for (int i = 0; i < r; i++) { fprintf(ctx->log, " %ld", (long int)dst_strides[i]); }
    fprintf(ctx->log, "\n");
    fprintf(ctx->log, "Src offset: %ld\n", (long int)src_offset);
    fprintf(ctx->log, "Src strides:");
    for (int i = 0; i < r; i++) { fprintf(ctx->log, " %ld", (long int)src_strides[i]); }
    fprintf(ctx->log, "\n");
  }
}

static void log_transpose(struct futhark_context* ctx,
                          int64_t k, int64_t n, int64_t m) {
  if (ctx->logging) {
    fprintf(ctx->log, "## Transpose\n");
    fprintf(ctx->log, "Arrays     : %ld\n", (long int)k);
    fprintf(ctx->log, "X elements : %ld\n", (long int)m);
    fprintf(ctx->log, "Y elements : %ld\n", (long int)n);
    fprintf(ctx->log, "\n");
  }
}

#define GEN_LMAD_COPY(NAME, ELEM_TYPE)                                  \
  static void lmad_copy_##NAME                                          \
  (struct futhark_context *ctx, int r,                                  \
   ELEM_TYPE* dst, int64_t dst_offset, int64_t dst_strides[r],          \
   ELEM_TYPE *src, int64_t src_offset, int64_t src_strides[r],          \
   int64_t shape[r]) {                                                  \
    log_copy(ctx, "CPU to CPU", r, dst_offset, dst_strides,             \
             src_offset, src_strides, shape);                           \
    int64_t size = 1;                                                   \
    for (int i = 0; i < r; i++) { size *= shape[i]; }                   \
    if (size == 0) { return; }                                          \
    int64_t k, n, m;                                                    \
    if (lmad_map_tr(&k, &n, &m,                                         \
                    r, dst_strides, src_strides, shape)) {              \
      log_transpose(ctx, k, n, m);                                      \
      map_transpose_##NAME                                              \
        (dst+dst_offset, src+src_offset, k, n, m, 0, n, 0, m);          \
    } else if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {   \
      if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}          \
      memcpy(dst+dst_offset, src+src_offset, size*sizeof(*dst));        \
    } else {                                                            \
      if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}       \
      lmad_copy_elements_##NAME                                         \
        (r,                                                             \
         dst+dst_offset, dst_strides,                                   \
         src+src_offset, src_strides, shape);                           \
    }                                                                   \
  }

GEN_MAP_TRANSPOSE(1b, uint8_t)
GEN_MAP_TRANSPOSE(2b, uint16_t)
GEN_MAP_TRANSPOSE(4b, uint32_t)
GEN_MAP_TRANSPOSE(8b, uint64_t)

GEN_LMAD_COPY_ELEMENTS(1b, uint8_t)
GEN_LMAD_COPY_ELEMENTS(2b, uint16_t)
GEN_LMAD_COPY_ELEMENTS(4b, uint32_t)
GEN_LMAD_COPY_ELEMENTS(8b, uint64_t)

GEN_LMAD_COPY(1b, uint8_t)
GEN_LMAD_COPY(2b, uint16_t)
GEN_LMAD_COPY(4b, uint32_t)
GEN_LMAD_COPY(8b, uint64_t)

// End of copy.h

#define FUTHARK_FUN_ATTR static

FUTHARK_FUN_ATTR int futrts_builtinzhiota_i64(struct futhark_context *ctx, struct memblock_device mem_27015, int64_t n_27016, int64_t x_27017, int64_t s_27018);
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i32(struct futhark_context *ctx, struct memblock_device mem_27044, int64_t num_elems_27045, int32_t val_27046);
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i64(struct futhark_context *ctx, struct memblock_device mem_27018, int64_t num_elems_27019, int64_t val_27020);
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i8(struct futhark_context *ctx, struct memblock_device mem_27400, int64_t num_elems_27401, int8_t val_27402);
FUTHARK_FUN_ATTR int futrts_entry_inner_SMJ_int(struct futhark_context *ctx, struct memblock_device *mem_out_p_27803, struct memblock_device *mem_out_p_27804, struct memblock_device *mem_out_p_27805, int64_t *out_prim_out_27806, struct memblock_device tR_mem_26243, struct memblock_device tS_mem_26244, int64_t nR_17046, int64_t nS_17047, int64_t offset_R_17050, int64_t offset_S_17051, int64_t partitionsPerWindow_17052, int64_t numberOfWindows_17053, int64_t extParallelism_17054, int64_t scatter_psizze_17055);
FUTHARK_FUN_ATTR int futrts_indicesWithIncrement_7095(struct futhark_context *ctx, struct memblock_device *mem_out_p_27824, struct memblock_device xs_mem_26243, int64_t n_11719, int64_t incr_11720);

static int init_constants(struct futhark_context *ctx)
{
    (void) ctx;
    
    int err = 0;
    
    #define global_dynid_mem_27424 (ctx->constants->global_dynid_mem_27424)
    #define global_dynid_mem_27545 (ctx->constants->global_dynid_mem_27545)
    global_dynid_mem_27424.references = NULL;
    global_dynid_mem_27545.references = NULL;
    if (memblock_alloc_device(ctx, &global_dynid_mem_27424, (int64_t) 4, "global_dynid_mem_27424")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_27424, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_27545, (int64_t) 4, "global_dynid_mem_27545")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_27545, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    #undef global_dynid_mem_27424
    #undef global_dynid_mem_27545
    
  cleanup:
    return err;
}
static int free_constants(struct futhark_context *ctx)
{
    (void) ctx;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_27424, "ctx->constants->global_dynid_mem_27424") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_27545, "ctx->constants->global_dynid_mem_27545") != 0)
        return 1;
    return 0;
}
static int gpu_kernel_builtinzhiota_i64ziiota_i64_27020(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhiota_i64ziiota_i64_27020, "builtin#iota_i64.iota_i64_27020", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_builtinzhreplicate_i32zireplicate_27049(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int32_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_i32zireplicate_27049, "builtin#replicate_i32.replicate_27049", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_builtinzhreplicate_i64zireplicate_27023(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_i64zireplicate_27023, "builtin#replicate_i64.replicate_27023", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_builtinzhreplicate_i8zireplicate_27405(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int8_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_i8zireplicate_27405, "builtin#replicate_i8.replicate_27405", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzigpuseq_27038(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27038, "inner_SMJ_int.gpuseq_27038", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzigpuseq_27070(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4};
        size_t args_sizes[6] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27070, "inner_SMJ_int.gpuseq_27070", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzigpuseq_27076(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27076, "inner_SMJ_int.gpuseq_27076", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzigpuseq_27092(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4};
        size_t args_sizes[6] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27092, "inner_SMJ_int.gpuseq_27092", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzigpuseq_27098(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, gpu_mem arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27098, "inner_SMJ_int.gpuseq_27098", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzigpuseq_27104(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, gpu_mem arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27104, "inner_SMJ_int.gpuseq_27104", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzisegmap_intrablock_24675(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, bool arg7, int64_t arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[15] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13};
        size_t args_sizes[15] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_intrablock_24675, "inner_SMJ_int.segmap_intrablock_24675", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 15, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzisegmap_intrablock_25030(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, bool arg7, int64_t arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[15] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13};
        size_t args_sizes[15] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_intrablock_25030, "inner_SMJ_int.segmap_intrablock_25030", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 15, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzigpuseq_27163(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, gpu_mem arg0, gpu_mem arg1)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[3] = {&ctx->global_failure, &arg0, &arg1};
        size_t args_sizes[3] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27163, "inner_SMJ_int.gpuseq_27163", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 3, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzigpuseq_27169(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, gpu_mem arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27169, "inner_SMJ_int.gpuseq_27169", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzigpuseq_27175(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, bool arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27175, "inner_SMJ_int.gpuseq_27175", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzisegmap_23741(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_23741, "inner_SMJ_int.segmap_23741", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzisegmap_24115(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_24115, "inner_SMJ_int.segmap_24115", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzigpuseq_27237(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27237, "inner_SMJ_int.gpuseq_27237", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzigpuseq_27243(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27243, "inner_SMJ_int.gpuseq_27243", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzigpuseq_27259(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4};
        size_t args_sizes[6] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27259, "inner_SMJ_int.gpuseq_27259", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzigpuseq_27265(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, gpu_mem arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27265, "inner_SMJ_int.gpuseq_27265", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzigpuseq_27271(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, gpu_mem arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27271, "inner_SMJ_int.gpuseq_27271", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzisegmap_intrablock_25385(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, bool arg7, int64_t arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[15] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13};
        size_t args_sizes[15] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_intrablock_25385, "inner_SMJ_int.segmap_intrablock_25385", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 15, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzisegmap_intrablock_25740(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, bool arg7, int64_t arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[15] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13};
        size_t args_sizes[15] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_intrablock_25740, "inner_SMJ_int.segmap_intrablock_25740", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 15, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzisegmap_24467(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_24467, "inner_SMJ_int.segmap_24467", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzisegmap_24488(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_24488, "inner_SMJ_int.segmap_24488", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzisegmap_24509(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_24509, "inner_SMJ_int.segmap_24509", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzisegmap_24530(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_24530, "inner_SMJ_int.segmap_24530", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzisegmap_24551(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_24551, "inner_SMJ_int.segmap_24551", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzisegmap_24572(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_24572, "inner_SMJ_int.segmap_24572", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzigpuseq_27384(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4};
        size_t args_sizes[6] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27384, "inner_SMJ_int.gpuseq_27384", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzisegscan_24583(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzisegscan_24583, "inner_SMJ_int.segscan_24583", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzisegmap_24585(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[15] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13};
        size_t args_sizes[15] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_24585, "inner_SMJ_int.segmap_24585", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 15, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzisegscan_24599(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[15] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13};
        size_t args_sizes[15] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzisegscan_24599, "inner_SMJ_int.segscan_24599", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 15, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzisegmap_24619(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_24619, "inner_SMJ_int.segmap_24619", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzigpuseq_27689(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27689, "inner_SMJ_int.gpuseq_27689", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzigpuseq_27695(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27695, "inner_SMJ_int.gpuseq_27695", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzigpuseq_27701(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, gpu_mem arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27701, "inner_SMJ_int.gpuseq_27701", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzisegmap_24635(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_24635, "inner_SMJ_int.segmap_24635", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzisegmap_24627(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int32_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_24627, "inner_SMJ_int.segmap_24627", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzigpuseq_27748(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_27748, "inner_SMJ_int.gpuseq_27748", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzireplicate_27755(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzireplicate_27755, "inner_SMJ_int.replicate_27755", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzireplicate_27775(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzireplicate_27775, "inner_SMJ_int.replicate_27775", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzisegmap_24657(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_24657, "inner_SMJ_int.segmap_24657", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
struct futhark_i32_1d {
    struct memblock_device mem;
    int64_t shape[1];
};
struct futhark_i32_1d *futhark_new_i32_1d(struct futhark_context *ctx, const int32_t *data, int64_t dim0)
{
    int err = 0;
    struct futhark_i32_1d *bad = NULL;
    struct futhark_i32_1d *arr = (struct futhark_i32_1d *) malloc(sizeof(struct futhark_i32_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * 4, "arr->mem"))
        err = 1;
    arr->shape[0] = dim0;
    err = memcpy_host2gpu(ctx, false, arr->mem.mem, 0, (const unsigned char *) data, 0, (size_t) dim0 * 4);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    if (err != 0) {
        free(arr);
        return bad;
    }
    return arr;
}
struct futhark_i32_1d *futhark_new_raw_i32_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0)
{
    int err = 0;
    struct futhark_i32_1d *bad = NULL;
    struct futhark_i32_1d *arr = (struct futhark_i32_1d *) malloc(sizeof(struct futhark_i32_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    arr->mem.mem = data;
    arr->shape[0] = dim0;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr, int32_t *data)
{
    int err = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    err = memcpy_gpu2host(ctx, false, (unsigned char *) data, 0, arr->mem.mem, 0, (size_t) arr->shape[0] * 4);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return err;
}
int futhark_index_i32_1d(struct futhark_context *ctx, int32_t *out, struct futhark_i32_1d *arr, int64_t i0)
{
    int err = 0;
    
    if (i0 >= 0 && i0 < arr->shape[0]) {
        lock_lock(&ctx->lock);
        CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
        err = memcpy_gpu2host(ctx, false, (unsigned char *) out, 0, arr->mem.mem, 4 * (i0 * 1), 4);
        CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
        lock_unlock(&ctx->lock);
    } else {
        err = 1;
        set_error(ctx, strdup("Index out of bounds."));
    }
    return err;
}
CUdeviceptr futhark_values_raw_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr)
{
    (void) ctx;
    return arr->shape;
}
struct futhark_i64_1d {
    struct memblock_device mem;
    int64_t shape[1];
};
struct futhark_i64_1d *futhark_new_i64_1d(struct futhark_context *ctx, const int64_t *data, int64_t dim0)
{
    int err = 0;
    struct futhark_i64_1d *bad = NULL;
    struct futhark_i64_1d *arr = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * 8, "arr->mem"))
        err = 1;
    arr->shape[0] = dim0;
    err = memcpy_host2gpu(ctx, false, arr->mem.mem, 0, (const unsigned char *) data, 0, (size_t) dim0 * 8);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    if (err != 0) {
        free(arr);
        return bad;
    }
    return arr;
}
struct futhark_i64_1d *futhark_new_raw_i64_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0)
{
    int err = 0;
    struct futhark_i64_1d *bad = NULL;
    struct futhark_i64_1d *arr = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    arr->mem.mem = data;
    arr->shape[0] = dim0;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr, int64_t *data)
{
    int err = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    err = memcpy_gpu2host(ctx, false, (unsigned char *) data, 0, arr->mem.mem, 0, (size_t) arr->shape[0] * 8);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return err;
}
int futhark_index_i64_1d(struct futhark_context *ctx, int64_t *out, struct futhark_i64_1d *arr, int64_t i0)
{
    int err = 0;
    
    if (i0 >= 0 && i0 < arr->shape[0]) {
        lock_lock(&ctx->lock);
        CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
        err = memcpy_gpu2host(ctx, false, (unsigned char *) out, 0, arr->mem.mem, 8 * (i0 * 1), 8);
        CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
        lock_unlock(&ctx->lock);
    } else {
        err = 1;
        set_error(ctx, strdup("Index out of bounds."));
    }
    return err;
}
CUdeviceptr futhark_values_raw_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr)
{
    (void) ctx;
    return arr->shape;
}
struct futhark_opaque_joinPairs_int {
    struct futhark_i64_1d *v0;
    struct futhark_i64_1d *v1;
    struct futhark_i32_1d *v2;
};
int futhark_project_opaque_joinPairs_int_ix(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_int *obj)
{
    (void) ctx;
    
    struct futhark_i64_1d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_i64_1d));
    memcpy(v, obj->v0, sizeof(struct futhark_i64_1d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_project_opaque_joinPairs_int_iy(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_int *obj)
{
    (void) ctx;
    
    struct futhark_i64_1d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_i64_1d));
    memcpy(v, obj->v1, sizeof(struct futhark_i64_1d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_project_opaque_joinPairs_int_vs(struct futhark_context *ctx, struct futhark_i32_1d **out, const struct futhark_opaque_joinPairs_int *obj)
{
    (void) ctx;
    
    struct futhark_i32_1d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_i32_1d));
    memcpy(v, obj->v2, sizeof(struct futhark_i32_1d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_new_opaque_joinPairs_int(struct futhark_context *ctx, struct futhark_opaque_joinPairs_int **out, const struct futhark_i64_1d *f_ix, const struct futhark_i64_1d *f_iy, const struct futhark_i32_1d *f_vs)
{
    struct futhark_opaque_joinPairs_int *v = malloc(sizeof(struct futhark_opaque_joinPairs_int));
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    {
        v->v0 = malloc(sizeof(struct futhark_i64_1d));
        *v->v0 = *f_ix;
        (void) (*v->v0->mem.references)++;
    }
    {
        v->v1 = malloc(sizeof(struct futhark_i64_1d));
        *v->v1 = *f_iy;
        (void) (*v->v1->mem.references)++;
    }
    {
        v->v2 = malloc(sizeof(struct futhark_i32_1d));
        *v->v2 = *f_vs;
        (void) (*v->v2->mem.references)++;
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return FUTHARK_SUCCESS;
}
int futhark_free_opaque_joinPairs_int(struct futhark_context *ctx, struct futhark_opaque_joinPairs_int *obj)
{
    (void) ctx;
    
    int ret = 0, tmp;
    
    if (obj->v0 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v0)) != 0)
        ret = tmp;
    if (obj->v1 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v1)) != 0)
        ret = tmp;
    if (obj->v2 != NULL && (tmp = futhark_free_i32_1d(ctx, obj->v2)) != 0)
        ret = tmp;
    free(obj);
    return ret;
}
int futhark_store_opaque_joinPairs_int(struct futhark_context *ctx, const struct futhark_opaque_joinPairs_int *obj, void **p, size_t *n)
{
    (void) ctx;
    
    int ret = 0;
    int64_t size_0 = 7 + 1 * sizeof(int64_t) + futhark_shape_i64_1d(ctx, obj->v0)[0] * sizeof(int64_t);
    int64_t size_1 = 7 + 1 * sizeof(int64_t) + futhark_shape_i64_1d(ctx, obj->v1)[0] * sizeof(int64_t);
    int64_t size_2 = 7 + 1 * sizeof(int64_t) + futhark_shape_i32_1d(ctx, obj->v2)[0] * sizeof(int32_t);
    
    *n = size_0 + size_1 + size_2;
    if (p != NULL && *p == NULL)
        *p = malloc(*n);
    if (p != NULL) {
        unsigned char *out = *p;
        
        *out++ = 'b';
        *out++ = 2;
        *out++ = 1;
        memcpy(out, " i64", 4);
        out += 4;
        memcpy(out, futhark_shape_i64_1d(ctx, obj->v0), 1 * sizeof(int64_t));
        out += 1 * sizeof(int64_t);
        ret |= futhark_values_i64_1d(ctx, obj->v0, (void *) out);
        out += futhark_shape_i64_1d(ctx, obj->v0)[0] * sizeof(int64_t);
        *out++ = 'b';
        *out++ = 2;
        *out++ = 1;
        memcpy(out, " i64", 4);
        out += 4;
        memcpy(out, futhark_shape_i64_1d(ctx, obj->v1), 1 * sizeof(int64_t));
        out += 1 * sizeof(int64_t);
        ret |= futhark_values_i64_1d(ctx, obj->v1, (void *) out);
        out += futhark_shape_i64_1d(ctx, obj->v1)[0] * sizeof(int64_t);
        *out++ = 'b';
        *out++ = 2;
        *out++ = 1;
        memcpy(out, " i32", 4);
        out += 4;
        memcpy(out, futhark_shape_i32_1d(ctx, obj->v2), 1 * sizeof(int64_t));
        out += 1 * sizeof(int64_t);
        ret |= futhark_values_i32_1d(ctx, obj->v2, (void *) out);
        out += futhark_shape_i32_1d(ctx, obj->v2)[0] * sizeof(int32_t);
    }
    return ret;
}
struct futhark_opaque_joinPairs_int *futhark_restore_opaque_joinPairs_int(struct futhark_context *ctx, const void *p)
{
    (void) ctx;
    
    int err = 0;
    const unsigned char *src = p;
    struct futhark_opaque_joinPairs_int *obj = malloc(sizeof(struct futhark_opaque_joinPairs_int));
    int64_t shape_0[1] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 1;
    err |= memcmp(src, " i64", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_0, src, 1 * sizeof(int64_t));
        src += 1 * sizeof(int64_t);
    }
    
    const void *data_0 = src;
    
    obj->v0 = NULL;
    src += shape_0[0] * sizeof(int64_t);
    
    int64_t shape_1[1] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 1;
    err |= memcmp(src, " i64", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_1, src, 1 * sizeof(int64_t));
        src += 1 * sizeof(int64_t);
    }
    
    const void *data_1 = src;
    
    obj->v1 = NULL;
    src += shape_1[0] * sizeof(int64_t);
    
    int64_t shape_2[1] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 1;
    err |= memcmp(src, " i32", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_2, src, 1 * sizeof(int64_t));
        src += 1 * sizeof(int64_t);
    }
    
    const void *data_2 = src;
    
    obj->v2 = NULL;
    src += shape_2[0] * sizeof(int32_t);
    if (err == 0) {
        obj->v0 = futhark_new_i64_1d(ctx, data_0, shape_0[0]);
        if (obj->v0 == NULL)
            err = 1;
        obj->v1 = futhark_new_i64_1d(ctx, data_1, shape_1[0]);
        if (obj->v1 == NULL)
            err = 1;
        obj->v2 = futhark_new_i32_1d(ctx, data_2, shape_2[0]);
        if (obj->v2 == NULL)
            err = 1;
    }
    if (err != 0) {
        int ret = 0, tmp;
        
        if (obj->v0 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v0)) != 0)
            ret = tmp;
        if (obj->v1 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v1)) != 0)
            ret = tmp;
        if (obj->v2 != NULL && (tmp = futhark_free_i32_1d(ctx, obj->v2)) != 0)
            ret = tmp;
        free(obj);
        obj = NULL;
    }
    return obj;
}

FUTHARK_FUN_ATTR int futrts_builtinzhiota_i64(struct futhark_context *ctx, struct memblock_device mem_27015, int64_t n_27016, int64_t x_27017, int64_t s_27018)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device global_dynid_mem_27424 = ctx->constants->global_dynid_mem_27424;
    struct memblock_device global_dynid_mem_27545 = ctx->constants->global_dynid_mem_27545;
    int64_t tblock_sizze_27024;
    
    tblock_sizze_27024 = *ctx->tuning_params.builtinzhiota_i64zitblock_sizze_27024;
    
    int64_t virt_num_tblocks_27025 = sdiv_up64(n_27016, tblock_sizze_27024);
    int64_t num_tblocks_27026 = smin64(virt_num_tblocks_27025, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhiota_i64ziiota_i64_27020(ctx, num_tblocks_27026, 1, 1, tblock_sizze_27024, 1, 1, (int64_t) 0, n_27016, x_27017, s_27018, virt_num_tblocks_27025, num_tblocks_27026, mem_27015.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i32(struct futhark_context *ctx, struct memblock_device mem_27044, int64_t num_elems_27045, int32_t val_27046)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device global_dynid_mem_27424 = ctx->constants->global_dynid_mem_27424;
    struct memblock_device global_dynid_mem_27545 = ctx->constants->global_dynid_mem_27545;
    int64_t replicate_n_27048 = num_elems_27045;
    int64_t tblock_sizze_27053;
    
    tblock_sizze_27053 = *ctx->tuning_params.builtinzhreplicate_i32zitblock_sizze_27053;
    
    int64_t virt_num_tblocks_27054 = sdiv_up64(replicate_n_27048, tblock_sizze_27053);
    int64_t num_tblocks_27055 = smin64(virt_num_tblocks_27054, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_i32zireplicate_27049(ctx, num_tblocks_27055, 1, 1, tblock_sizze_27053, 1, 1, (int64_t) 0, num_elems_27045, val_27046, replicate_n_27048, virt_num_tblocks_27054, num_tblocks_27055, mem_27044.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i64(struct futhark_context *ctx, struct memblock_device mem_27018, int64_t num_elems_27019, int64_t val_27020)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device global_dynid_mem_27424 = ctx->constants->global_dynid_mem_27424;
    struct memblock_device global_dynid_mem_27545 = ctx->constants->global_dynid_mem_27545;
    int64_t replicate_n_27022 = num_elems_27019;
    int64_t tblock_sizze_27027;
    
    tblock_sizze_27027 = *ctx->tuning_params.builtinzhreplicate_i64zitblock_sizze_27027;
    
    int64_t virt_num_tblocks_27028 = sdiv_up64(replicate_n_27022, tblock_sizze_27027);
    int64_t num_tblocks_27029 = smin64(virt_num_tblocks_27028, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_i64zireplicate_27023(ctx, num_tblocks_27029, 1, 1, tblock_sizze_27027, 1, 1, (int64_t) 0, num_elems_27019, val_27020, replicate_n_27022, virt_num_tblocks_27028, num_tblocks_27029, mem_27018.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i8(struct futhark_context *ctx, struct memblock_device mem_27400, int64_t num_elems_27401, int8_t val_27402)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device global_dynid_mem_27424 = ctx->constants->global_dynid_mem_27424;
    struct memblock_device global_dynid_mem_27545 = ctx->constants->global_dynid_mem_27545;
    int64_t replicate_n_27404 = num_elems_27401;
    int64_t tblock_sizze_27409;
    
    tblock_sizze_27409 = *ctx->tuning_params.builtinzhreplicate_i8zitblock_sizze_27409;
    
    int64_t virt_num_tblocks_27410 = sdiv_up64(replicate_n_27404, tblock_sizze_27409);
    int64_t num_tblocks_27411 = smin64(virt_num_tblocks_27410, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_i8zireplicate_27405(ctx, num_tblocks_27411, 1, 1, tblock_sizze_27409, 1, 1, (int64_t) 0, num_elems_27401, val_27402, replicate_n_27404, virt_num_tblocks_27410, num_tblocks_27411, mem_27400.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_inner_SMJ_int(struct futhark_context *ctx, struct memblock_device *mem_out_p_27803, struct memblock_device *mem_out_p_27804, struct memblock_device *mem_out_p_27805, int64_t *out_prim_out_27806, struct memblock_device tR_mem_26243, struct memblock_device tS_mem_26244, int64_t nR_17046, int64_t nS_17047, int64_t offset_R_17050, int64_t offset_S_17051, int64_t partitionsPerWindow_17052, int64_t numberOfWindows_17053, int64_t extParallelism_17054, int64_t scatter_psizze_17055)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_26821;
    
    mem_26821.references = NULL;
    
    struct memblock_device mem_26819;
    
    mem_26819.references = NULL;
    
    struct memblock_device mem_26817;
    
    mem_26817.references = NULL;
    
    struct memblock_device mem_param_tmp_27742;
    
    mem_param_tmp_27742.references = NULL;
    
    struct memblock_device mem_param_tmp_27741;
    
    mem_param_tmp_27741.references = NULL;
    
    struct memblock_device mem_param_tmp_27740;
    
    mem_param_tmp_27740.references = NULL;
    
    struct memblock_device mem_26803;
    
    mem_26803.references = NULL;
    
    struct memblock_device mem_26801;
    
    mem_26801.references = NULL;
    
    struct memblock_device mem_26796;
    
    mem_26796.references = NULL;
    
    struct memblock_device mem_26794;
    
    mem_26794.references = NULL;
    
    struct memblock_device mem_26792;
    
    mem_26792.references = NULL;
    
    struct memblock_device mem_param_26790;
    
    mem_param_26790.references = NULL;
    
    struct memblock_device mem_param_26787;
    
    mem_param_26787.references = NULL;
    
    struct memblock_device mem_param_26784;
    
    mem_param_26784.references = NULL;
    
    struct memblock_device ext_mem_26813;
    
    ext_mem_26813.references = NULL;
    
    struct memblock_device ext_mem_26814;
    
    ext_mem_26814.references = NULL;
    
    struct memblock_device ext_mem_26815;
    
    ext_mem_26815.references = NULL;
    
    struct memblock_device mem_26799;
    
    mem_26799.references = NULL;
    
    struct memblock_device mem_26798;
    
    mem_26798.references = NULL;
    
    struct memblock_device mem_26797;
    
    mem_26797.references = NULL;
    
    struct memblock_device mem_26771;
    
    mem_26771.references = NULL;
    
    struct memblock_device mem_26769;
    
    mem_26769.references = NULL;
    
    struct memblock_device mem_26767;
    
    mem_26767.references = NULL;
    
    struct memblock_device mem_26756;
    
    mem_26756.references = NULL;
    
    struct memblock_device mem_26754;
    
    mem_26754.references = NULL;
    
    struct memblock_device mem_26752;
    
    mem_26752.references = NULL;
    
    struct memblock_device mem_26748;
    
    mem_26748.references = NULL;
    
    struct memblock_device mem_26746;
    
    mem_26746.references = NULL;
    
    struct memblock_device mem_26750;
    
    mem_26750.references = NULL;
    
    struct memblock_device mem_26742;
    
    mem_26742.references = NULL;
    
    struct memblock_device mem_26743;
    
    mem_26743.references = NULL;
    
    struct memblock_device ext_mem_26744;
    
    ext_mem_26744.references = NULL;
    
    struct memblock_device mem_26739;
    
    mem_26739.references = NULL;
    
    struct memblock_device mem_26740;
    
    mem_26740.references = NULL;
    
    struct memblock_device ext_mem_26741;
    
    ext_mem_26741.references = NULL;
    
    struct memblock_device mem_26738;
    
    mem_26738.references = NULL;
    
    struct memblock_device incprefixes_mem_27543;
    
    incprefixes_mem_27543.references = NULL;
    
    struct memblock_device aggregates_mem_27541;
    
    aggregates_mem_27541.references = NULL;
    
    struct memblock_device incprefixes_mem_27539;
    
    incprefixes_mem_27539.references = NULL;
    
    struct memblock_device aggregates_mem_27537;
    
    aggregates_mem_27537.references = NULL;
    
    struct memblock_device status_flags_mem_27535;
    
    status_flags_mem_27535.references = NULL;
    
    struct memblock_device mem_26735;
    
    mem_26735.references = NULL;
    
    struct memblock_device mem_26733;
    
    mem_26733.references = NULL;
    
    struct memblock_device mem_26731;
    
    mem_26731.references = NULL;
    
    struct memblock_device mem_26727;
    
    mem_26727.references = NULL;
    
    struct memblock_device mem_26725;
    
    mem_26725.references = NULL;
    
    struct memblock_device mem_26723;
    
    mem_26723.references = NULL;
    
    struct memblock_device mem_26721;
    
    mem_26721.references = NULL;
    
    struct memblock_device incprefixes_mem_27422;
    
    incprefixes_mem_27422.references = NULL;
    
    struct memblock_device aggregates_mem_27420;
    
    aggregates_mem_27420.references = NULL;
    
    struct memblock_device status_flags_mem_27398;
    
    status_flags_mem_27398.references = NULL;
    
    struct memblock_device mem_26719;
    
    mem_26719.references = NULL;
    
    struct memblock_device mem_26717;
    
    mem_26717.references = NULL;
    
    struct memblock_device mem_param_tmp_27065;
    
    mem_param_tmp_27065.references = NULL;
    
    struct memblock_device mem_param_tmp_27064;
    
    mem_param_tmp_27064.references = NULL;
    
    struct memblock_device mem_26702;
    
    mem_26702.references = NULL;
    
    struct memblock_device mem_26701;
    
    mem_26701.references = NULL;
    
    struct memblock_device mem_26698;
    
    mem_26698.references = NULL;
    
    struct memblock_device mem_param_tmp_27222;
    
    mem_param_tmp_27222.references = NULL;
    
    struct memblock_device mem_param_tmp_27221;
    
    mem_param_tmp_27221.references = NULL;
    
    struct memblock_device mem_26506;
    
    mem_26506.references = NULL;
    
    struct memblock_device mem_26504;
    
    mem_26504.references = NULL;
    
    struct memblock_device mem_26502;
    
    mem_26502.references = NULL;
    
    struct memblock_device mem_26499;
    
    mem_26499.references = NULL;
    
    struct memblock_device mem_param_tmp_27232;
    
    mem_param_tmp_27232.references = NULL;
    
    struct memblock_device mem_param_tmp_27231;
    
    mem_param_tmp_27231.references = NULL;
    
    struct memblock_device mem_26490;
    
    mem_26490.references = NULL;
    
    struct memblock_device mem_26487;
    
    mem_26487.references = NULL;
    
    struct memblock_device mem_param_tmp_27250;
    
    mem_param_tmp_27250.references = NULL;
    
    struct memblock_device mem_param_tmp_27249;
    
    mem_param_tmp_27249.references = NULL;
    
    struct memblock_device mem_26466;
    
    mem_26466.references = NULL;
    
    struct memblock_device mem_26464;
    
    mem_26464.references = NULL;
    
    struct memblock_device mem_26399;
    
    mem_26399.references = NULL;
    
    struct memblock_device mem_26397;
    
    mem_26397.references = NULL;
    
    struct memblock_device mem_26460;
    
    mem_26460.references = NULL;
    
    struct memblock_device mem_26458;
    
    mem_26458.references = NULL;
    
    struct memblock_device ext_mem_26461;
    
    ext_mem_26461.references = NULL;
    
    struct memblock_device ext_mem_26462;
    
    ext_mem_26462.references = NULL;
    
    struct memblock_device ext_mem_26338;
    
    ext_mem_26338.references = NULL;
    
    struct memblock_device mem_26336;
    
    mem_26336.references = NULL;
    
    struct memblock_device ext_mem_26469;
    
    ext_mem_26469.references = NULL;
    
    struct memblock_device ext_mem_26472;
    
    ext_mem_26472.references = NULL;
    
    struct memblock_device mem_26334;
    
    mem_26334.references = NULL;
    
    struct memblock_device ext_mem_26475;
    
    ext_mem_26475.references = NULL;
    
    struct memblock_device ext_mem_26478;
    
    ext_mem_26478.references = NULL;
    
    struct memblock_device ext_mem_26332;
    
    ext_mem_26332.references = NULL;
    
    struct memblock_device ext_mem_26331;
    
    ext_mem_26331.references = NULL;
    
    struct memblock_device mem_param_26328;
    
    mem_param_26328.references = NULL;
    
    struct memblock_device mem_param_26325;
    
    mem_param_26325.references = NULL;
    
    struct memblock_device ext_mem_26483;
    
    ext_mem_26483.references = NULL;
    
    struct memblock_device ext_mem_26484;
    
    ext_mem_26484.references = NULL;
    
    struct memblock_device mem_26320;
    
    mem_26320.references = NULL;
    
    struct memblock_device mem_26321;
    
    mem_26321.references = NULL;
    
    struct memblock_device ext_mem_26322;
    
    ext_mem_26322.references = NULL;
    
    struct memblock_device mem_26317;
    
    mem_26317.references = NULL;
    
    struct memblock_device mem_26318;
    
    mem_26318.references = NULL;
    
    struct memblock_device ext_mem_26319;
    
    ext_mem_26319.references = NULL;
    
    struct memblock_device mem_param_26316;
    
    mem_param_26316.references = NULL;
    
    struct memblock_device mem_param_26313;
    
    mem_param_26313.references = NULL;
    
    struct memblock_device ext_mem_26495;
    
    ext_mem_26495.references = NULL;
    
    struct memblock_device ext_mem_26496;
    
    ext_mem_26496.references = NULL;
    
    struct memblock_device mem_26333;
    
    mem_26333.references = NULL;
    
    struct memblock_device mem_26330;
    
    mem_26330.references = NULL;
    
    struct memblock_device mem_26329;
    
    mem_26329.references = NULL;
    
    struct memblock_device mem_26310;
    
    mem_26310.references = NULL;
    
    struct memblock_device mem_26308;
    
    mem_26308.references = NULL;
    
    struct memblock_device ext_mem_26509;
    
    ext_mem_26509.references = NULL;
    
    struct memblock_device ext_mem_26512;
    
    ext_mem_26512.references = NULL;
    
    struct memblock_device ext_mem_26515;
    
    ext_mem_26515.references = NULL;
    
    struct memblock_device ext_mem_26518;
    
    ext_mem_26518.references = NULL;
    
    struct memblock_device mem_param_26306;
    
    mem_param_26306.references = NULL;
    
    struct memblock_device mem_param_26303;
    
    mem_param_26303.references = NULL;
    
    struct memblock_device ext_mem_26523;
    
    ext_mem_26523.references = NULL;
    
    struct memblock_device ext_mem_26524;
    
    ext_mem_26524.references = NULL;
    
    struct memblock_device mem_26300;
    
    mem_26300.references = NULL;
    
    struct memblock_device mem_26298;
    
    mem_26298.references = NULL;
    
    struct memblock_device mem_26285;
    
    mem_26285.references = NULL;
    
    struct memblock_device mem_26287;
    
    mem_26287.references = NULL;
    
    struct memblock_device ext_mem_26288;
    
    ext_mem_26288.references = NULL;
    
    struct memblock_device ext_mem_26289;
    
    ext_mem_26289.references = NULL;
    
    struct memblock_device mem_26282;
    
    mem_26282.references = NULL;
    
    struct memblock_device mem_26280;
    
    mem_26280.references = NULL;
    
    struct memblock_device mem_26269;
    
    mem_26269.references = NULL;
    
    struct memblock_device mem_26270;
    
    mem_26270.references = NULL;
    
    struct memblock_device ext_mem_26271;
    
    ext_mem_26271.references = NULL;
    
    struct memblock_device mem_26268;
    
    mem_26268.references = NULL;
    
    struct memblock_device mem_26265;
    
    mem_26265.references = NULL;
    
    struct memblock_device mem_26266;
    
    mem_26266.references = NULL;
    
    struct memblock_device ext_mem_26267;
    
    ext_mem_26267.references = NULL;
    
    struct memblock_device mem_26264;
    
    mem_26264.references = NULL;
    
    struct memblock_device mem_26262;
    
    mem_26262.references = NULL;
    
    struct memblock_device mem_param_tmp_27083;
    
    mem_param_tmp_27083.references = NULL;
    
    struct memblock_device mem_param_tmp_27082;
    
    mem_param_tmp_27082.references = NULL;
    
    struct memblock_device mem_26671;
    
    mem_26671.references = NULL;
    
    struct memblock_device mem_26669;
    
    mem_26669.references = NULL;
    
    struct memblock_device mem_26604;
    
    mem_26604.references = NULL;
    
    struct memblock_device mem_26602;
    
    mem_26602.references = NULL;
    
    struct memblock_device mem_26665;
    
    mem_26665.references = NULL;
    
    struct memblock_device mem_26663;
    
    mem_26663.references = NULL;
    
    struct memblock_device ext_mem_26666;
    
    ext_mem_26666.references = NULL;
    
    struct memblock_device ext_mem_26667;
    
    ext_mem_26667.references = NULL;
    
    struct memblock_device ext_mem_26543;
    
    ext_mem_26543.references = NULL;
    
    struct memblock_device mem_26541;
    
    mem_26541.references = NULL;
    
    struct memblock_device ext_mem_26674;
    
    ext_mem_26674.references = NULL;
    
    struct memblock_device ext_mem_26677;
    
    ext_mem_26677.references = NULL;
    
    struct memblock_device mem_26539;
    
    mem_26539.references = NULL;
    
    struct memblock_device ext_mem_26680;
    
    ext_mem_26680.references = NULL;
    
    struct memblock_device ext_mem_26683;
    
    ext_mem_26683.references = NULL;
    
    struct memblock_device ext_mem_26537;
    
    ext_mem_26537.references = NULL;
    
    struct memblock_device ext_mem_26536;
    
    ext_mem_26536.references = NULL;
    
    struct memblock_device mem_param_26533;
    
    mem_param_26533.references = NULL;
    
    struct memblock_device mem_param_26530;
    
    mem_param_26530.references = NULL;
    
    struct memblock_device ext_mem_26688;
    
    ext_mem_26688.references = NULL;
    
    struct memblock_device ext_mem_26689;
    
    ext_mem_26689.references = NULL;
    
    struct memblock_device mem_26538;
    
    mem_26538.references = NULL;
    
    struct memblock_device mem_26535;
    
    mem_26535.references = NULL;
    
    struct memblock_device mem_26534;
    
    mem_26534.references = NULL;
    
    struct memblock_device mem_26525;
    
    mem_26525.references = NULL;
    
    struct memblock_device mem_26526;
    
    mem_26526.references = NULL;
    
    struct memblock_device ext_mem_26527;
    
    ext_mem_26527.references = NULL;
    
    struct memblock_device ext_mem_26692;
    
    ext_mem_26692.references = NULL;
    
    struct memblock_device ext_mem_26695;
    
    ext_mem_26695.references = NULL;
    
    struct memblock_device ext_mem_26705;
    
    ext_mem_26705.references = NULL;
    
    struct memblock_device ext_mem_26708;
    
    ext_mem_26708.references = NULL;
    
    struct memblock_device mem_param_26258;
    
    mem_param_26258.references = NULL;
    
    struct memblock_device mem_param_26255;
    
    mem_param_26255.references = NULL;
    
    struct memblock_device ext_mem_26713;
    
    ext_mem_26713.references = NULL;
    
    struct memblock_device ext_mem_26714;
    
    ext_mem_26714.references = NULL;
    
    struct memblock_device mem_26260;
    
    mem_26260.references = NULL;
    
    struct memblock_device mem_26259;
    
    mem_26259.references = NULL;
    
    struct memblock_device mem_26250;
    
    mem_26250.references = NULL;
    
    struct memblock_device mem_26251;
    
    mem_26251.references = NULL;
    
    struct memblock_device ext_mem_26252;
    
    ext_mem_26252.references = NULL;
    
    struct memblock_device mem_26249;
    
    mem_26249.references = NULL;
    
    struct memblock_device mem_26247;
    
    mem_26247.references = NULL;
    
    struct memblock_device ext_mem_26245;
    
    ext_mem_26245.references = NULL;
    
    struct memblock_device mem_out_27016;
    
    mem_out_27016.references = NULL;
    
    struct memblock_device mem_out_27015;
    
    mem_out_27015.references = NULL;
    
    struct memblock_device mem_out_27014;
    
    mem_out_27014.references = NULL;
    
    struct memblock_device global_dynid_mem_27424 = ctx->constants->global_dynid_mem_27424;
    struct memblock_device global_dynid_mem_27545 = ctx->constants->global_dynid_mem_27545;
    int64_t prim_out_27017;
    int64_t zm_lhs_21408 = add64(nR_17046, nS_17047);
    int64_t zs_lhs_21409 = sub64(zm_lhs_21408, (int64_t) 1);
    bool zzero_21410 = nR_17046 == (int64_t) 0;
    bool nonzzero_21411 = !zzero_21410;
    bool nonzzero_cert_21412;
    
    if (!nonzzero_21411) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftSMJerr.fut:208:26-29\n   #1  ftSMJerr.fut:315:124-127\n   #2  ftSMJerr.fut:304:1-315:127\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t numIter_21413 = sdiv64(zs_lhs_21409, nR_17046);
    
    if (futrts_indicesWithIncrement_7095(ctx, &ext_mem_26245, tR_mem_26243, nR_17046, offset_R_17050) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t bytes_26246 = (int64_t) 8 * nR_17046;
    
    if (memblock_alloc_device(ctx, &mem_26247, bytes_26246, "mem_26247")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_26247, nR_17046, (int64_t) -1) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_26249, bytes_26246, "mem_26249")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_26249, nR_17046, (int64_t) 0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    bool loop_cond_21418 = slt64((int64_t) 0, numIter_21413);
    int64_t gt_rhs_21419 = sub64(nR_17046, (int64_t) 1);
    bool x_21420 = sle64((int64_t) 0, gt_rhs_21419);
    bool y_21421 = slt64(gt_rhs_21419, nR_17046);
    bool bounds_check_21422 = x_21420 && y_21421;
    bool loop_not_taken_21423 = !loop_cond_21418;
    bool protect_assert_disj_21424 = bounds_check_21422 || loop_not_taken_21423;
    bool index_certs_21425;
    
    if (!protect_assert_disj_21424) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) gt_rhs_21419, "] out of bounds for array of shape [", (long long) nR_17046, "].", "-> #0  ftSMJerr.fut:215:25-33\n   #1  ftSMJerr.fut:315:124-127\n   #2  ftSMJerr.fut:304:1-315:127\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    if (loop_cond_21418) {
        if (memblock_alloc_device(ctx, &mem_26251, (int64_t) 4, "mem_26251")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_intzigpuseq_27038(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, gt_rhs_21419, tR_mem_26243.mem, mem_26251.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_26252, &mem_26251, "mem_26251") != 0)
            return 1;
    } else {
        if (memblock_alloc_device(ctx, &mem_26250, (int64_t) 4, "mem_26250")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i32(ctx, mem_26250, (int64_t) 1, 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_26252, &mem_26250, "mem_26250") != 0)
            return 1;
    }
    if (memblock_alloc_device(ctx, &mem_26259, (int64_t) 4, "mem_26259")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_26260, (int64_t) 1, "mem_26260")) {
        err = 1;
        goto cleanup;
    }
    
    bool defunc_0_mergeJoin_res_21428;
    int64_t defunc_0_mergeJoin_res_21429;
    bool loop_while_21432;
    int64_t p_21433;
    
    if (memblock_set_device(ctx, &mem_param_26255, &mem_26249, "mem_26249") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_26258, &mem_26247, "mem_26247") != 0)
        return 1;
    loop_while_21432 = loop_cond_21418;
    p_21433 = (int64_t) 0;
    while (loop_while_21432) {
        int64_t tS_start_21436 = mul64(nR_17046, p_21433);
        int64_t min_arg1_21437 = add64(nR_17046, tS_start_21436);
        int64_t min_res_21438 = smin64(nS_17047, min_arg1_21437);
        int64_t dzlz7bUZLzmZRz20UtS_endz20UtS_startz7dUzg_21439 = sub64(min_res_21438, tS_start_21436);
        bool empty_slice_21440 = dzlz7bUZLzmZRz20UtS_endz20UtS_startz7dUzg_21439 == (int64_t) 0;
        int64_t m_21441 = sub64(dzlz7bUZLzmZRz20UtS_endz20UtS_startz7dUzg_21439, (int64_t) 1);
        int64_t i_p_m_t_s_21442 = add64(tS_start_21436, m_21441);
        bool zzero_leq_i_p_m_t_s_21443 = sle64((int64_t) 0, i_p_m_t_s_21442);
        bool i_p_m_t_s_leq_w_21444 = slt64(i_p_m_t_s_21442, nS_17047);
        bool zzero_lte_i_21445 = sle64((int64_t) 0, tS_start_21436);
        bool i_lte_j_21446 = sle64(tS_start_21436, min_res_21438);
        bool y_21447 = i_p_m_t_s_leq_w_21444 && zzero_lte_i_21445;
        bool y_21448 = zzero_leq_i_p_m_t_s_21443 && y_21447;
        bool forwards_ok_21449 = i_lte_j_21446 && y_21448;
        bool ok_or_empty_21450 = empty_slice_21440 || forwards_ok_21449;
        bool index_certs_21451;
        
        if (!ok_or_empty_21450) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) tS_start_21436, ":", (long long) min_res_21438, "] out of bounds for array of shape [", (long long) nS_17047, "].", "-> #0  ftSMJerr.fut:214:16-35\n   #1  ftSMJerr.fut:315:124-127\n   #2  ftSMJerr.fut:304:1-315:127\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        bool y_21453 = slt64((int64_t) 0, dzlz7bUZLzmZRz20UtS_endz20UtS_startz7dUzg_21439);
        bool index_certs_21454;
        
        if (!y_21453) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) (int64_t) 0, "] out of bounds for array of shape [", (long long) dzlz7bUZLzmZRz20UtS_endz20UtS_startz7dUzg_21439, "].", "-> #0  ftSMJerr.fut:215:12-19\n   #1  ftSMJerr.fut:315:124-127\n   #2  ftSMJerr.fut:304:1-315:127\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_intzigpuseq_27070(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, tS_start_21436, tS_mem_26244.mem, ext_mem_26252.mem, mem_26259.mem, mem_26260.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        
        bool read_res_27807;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_27807, mem_26260.mem, (int64_t) 0 * sizeof(bool), sizeof(bool))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        bool defunc_0_gt_res_21456 = read_res_27807;
        int64_t loopres_21457;
        
        if (defunc_0_gt_res_21456) {
            if (memblock_set_device(ctx, &ext_mem_26708, &mem_param_26255, "mem_param_26255") != 0)
                return 1;
            if (memblock_set_device(ctx, &ext_mem_26705, &mem_param_26258, "mem_param_26258") != 0)
                return 1;
            loopres_21457 = numIter_21413;
        } else {
            bool cond_21460 = slt64(dzlz7bUZLzmZRz20UtS_endz20UtS_startz7dUzg_21439, nR_17046);
            bool dim_match_21574 = nR_17046 == dzlz7bUZLzmZRz20UtS_endz20UtS_startz7dUzg_21439;
            bool protect_assert_disj_26923 = cond_21460 || dim_match_21574;
            bool empty_or_match_cert_21575;
            
            if (!protect_assert_disj_26923) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Value of (desugared) shape [", (long long) dzlz7bUZLzmZRz20UtS_endz20UtS_startz7dUzg_21439, "] cannot match shape of type `[", (long long) nR_17046, "]i32`.", "-> #0  ftSMJerr.fut:223:18-31\n   #1  ftSMJerr.fut:315:124-127\n   #2  ftSMJerr.fut:304:1-315:127\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            
            bool loop_cond_21581 = slt64((int64_t) 0, numberOfWindows_17053);
            bool y_21584 = slt64((int64_t) 0, nR_17046);
            bool loop_not_taken_21585 = !loop_cond_21581;
            bool protect_assert_disj_21586 = y_21584 || loop_not_taken_21585;
            bool protect_assert_disj_26925 = cond_21460 || protect_assert_disj_21586;
            bool index_certs_21587;
            
            if (!protect_assert_disj_26925) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) (int64_t) 0, "] out of bounds for array of shape [", (long long) nR_17046, "].", "-> #0  ftbasics.fut:150:20-25\n   #1  ftSMJerr.fut:315:124-127\n   #2  ftSMJerr.fut:304:1-315:127\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            
            int64_t zm_lhs_22970 = add64(nR_17046, extParallelism_17054);
            int64_t zs_lhs_22971 = sub64(zm_lhs_22970, (int64_t) 1);
            bool zzero_22972 = extParallelism_17054 == (int64_t) 0;
            bool nonzzero_22973 = !zzero_22972;
            bool loop_not_taken_26866 = !cond_21460;
            bool protect_assert_disj_26867 = nonzzero_22973 || loop_not_taken_26866;
            bool nonzzero_cert_22974;
            
            if (!protect_assert_disj_26867) {
                set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftSMJerr.fut:25:39-55\n   #1  ftSMJerr.fut:315:124-127\n   #2  ftSMJerr.fut:304:1-315:127\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            
            int64_t numIter_22975 = sdiv_safe64(zs_lhs_22971, extParallelism_17054);
            bool loop_cond_22976 = slt64((int64_t) 0, numIter_22975);
            bool loop_not_taken_22977 = !y_21453;
            bool loop_not_taken_22978 = !loop_cond_22976;
            bool x_22979 = sle64((int64_t) 0, m_21441);
            bool y_22980 = slt64(m_21441, dzlz7bUZLzmZRz20UtS_endz20UtS_startz7dUzg_21439);
            bool bounds_check_22982 = x_22979 && y_22980;
            bool protect_assert_disj_22983 = loop_not_taken_22977 || bounds_check_22982;
            bool protect_assert_disj_22984 = loop_not_taken_22978 || protect_assert_disj_22983;
            bool protect_assert_disj_26869 = protect_assert_disj_22984 || loop_not_taken_26866;
            bool index_certs_22985;
            
            if (!protect_assert_disj_26869) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) m_21441, "] out of bounds for array of shape [", (long long) dzlz7bUZLzmZRz20UtS_endz20UtS_startz7dUzg_21439, "].", "-> #0  ftSMJerr.fut:37:34-42\n   #1  ftSMJerr.fut:315:124-127\n   #2  ftSMJerr.fut:304:1-315:127\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            
            bool index_certs_22255;
            
            if (!bounds_check_22982) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) m_21441, "] out of bounds for array of shape [", (long long) dzlz7bUZLzmZRz20UtS_endz20UtS_startz7dUzg_21439, "].", "-> #0  ftSMJerr.fut:234:23-44\n   #1  ftSMJerr.fut:315:124-127\n   #2  ftSMJerr.fut:304:1-315:127\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            
            bool index_certs_22257;
            
            if (!bounds_check_21422) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) gt_rhs_21419, "] out of bounds for array of shape [", (long long) nR_17046, "].", "-> #0  ftSMJerr.fut:234:51-59\n   #1  ftSMJerr.fut:315:124-127\n   #2  ftSMJerr.fut:304:1-315:127\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            
            int64_t dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578 = mul64(partitionsPerWindow_17052, numberOfWindows_17053);
            int64_t join_chunks_arg3_21577 = add64(offset_S_17051, tS_start_21436);
            int64_t bytes_26261 = (int64_t) 8 * dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578;
            bool empty_slice_21582 = partitionsPerWindow_17052 == (int64_t) 0;
            int64_t m_21583 = sub64(partitionsPerWindow_17052, (int64_t) 1);
            int64_t segmap_tblock_sizze_23736;
            
            segmap_tblock_sizze_23736 = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_23529;
            
            int64_t zeze_rhs_21852 = sub64(dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578, (int64_t) 1);
            int64_t segmap_tblock_sizze_24110;
            
            segmap_tblock_sizze_24110 = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_23946;
            
            int64_t segmap_usable_groups_24111 = sdiv_up_safe64(dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578, segmap_tblock_sizze_24110);
            bool loop_cond_22007 = slt64((int64_t) 0, dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578);
            bool protect_cond_conj_22981 = y_21453 && loop_cond_22976;
            int64_t bytes_26540 = (int64_t) 4 * dzlz7bUZLzmZRz20UtS_endz20UtS_startz7dUzg_21439;
            int64_t ext_26694;
            int64_t ext_26693;
            int64_t ext_26691;
            int64_t ext_26690;
            
            if (cond_21460) {
                if (protect_cond_conj_22981) {
                    if (memblock_alloc_device(ctx, &mem_26526, (int64_t) 4, "mem_26526")) {
                        err = 1;
                        goto cleanup;
                    }
                    {
                        err = gpu_kernel_inner_SMJ_intzigpuseq_27076(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, i_p_m_t_s_21442, tS_mem_26244.mem, mem_26526.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (memblock_set_device(ctx, &ext_mem_26527, &mem_26526, "mem_26526") != 0)
                        return 1;
                } else {
                    if (memblock_alloc_device(ctx, &mem_26525, (int64_t) 4, "mem_26525")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (futrts_builtinzhreplicate_i32(ctx, mem_26525, (int64_t) 1, 0) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_set_device(ctx, &ext_mem_26527, &mem_26525, "mem_26525") != 0)
                        return 1;
                }
                if (memblock_alloc_device(ctx, &mem_26534, (int64_t) 4, "mem_26534")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &mem_26535, (int64_t) 4, "mem_26535")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &mem_26538, (int64_t) 1, "mem_26538")) {
                    err = 1;
                    goto cleanup;
                }
                
                int64_t ext_26687;
                int64_t ext_26686;
                int64_t ext_26685;
                int64_t ext_26684;
                bool defunc_0_find_joinTuples_res_22988;
                int64_t defunc_0_find_joinTuples_res_22989;
                bool loop_while_22992;
                int64_t p_22993;
                int64_t ctx_param_ext_26528;
                int64_t ctx_param_ext_26529;
                int64_t ctx_param_ext_26531;
                int64_t ctx_param_ext_26532;
                
                if (memblock_set_device(ctx, &mem_param_26530, &mem_26249, "mem_26249") != 0)
                    return 1;
                if (memblock_set_device(ctx, &mem_param_26533, &mem_26247, "mem_26247") != 0)
                    return 1;
                ctx_param_ext_26528 = (int64_t) 0;
                ctx_param_ext_26529 = (int64_t) 1;
                ctx_param_ext_26531 = (int64_t) 0;
                ctx_param_ext_26532 = (int64_t) 1;
                loop_while_22992 = loop_cond_22976;
                p_22993 = (int64_t) 0;
                while (loop_while_22992) {
                    int64_t start_22996 = mul64(extParallelism_17054, p_22993);
                    int64_t min_arg1_22997 = sub64(nR_17046, start_22996);
                    int64_t min_res_22998 = smin64(extParallelism_17054, min_arg1_22997);
                    int64_t iter_R_22999 = add64(start_22996, min_res_22998);
                    bool empty_slice_23000 = min_res_22998 == (int64_t) 0;
                    int64_t m_23001 = sub64(min_res_22998, (int64_t) 1);
                    int64_t i_p_m_t_s_23002 = add64(start_22996, m_23001);
                    bool zzero_leq_i_p_m_t_s_23003 = sle64((int64_t) 0, i_p_m_t_s_23002);
                    bool i_p_m_t_s_leq_w_23004 = slt64(i_p_m_t_s_23002, nR_17046);
                    bool zzero_lte_i_23005 = sle64((int64_t) 0, start_22996);
                    bool i_lte_j_23006 = sle64(start_22996, iter_R_22999);
                    bool y_23007 = i_p_m_t_s_leq_w_23004 && zzero_lte_i_23005;
                    bool y_23008 = zzero_leq_i_p_m_t_s_23003 && y_23007;
                    bool forwards_ok_23009 = i_lte_j_23006 && y_23008;
                    bool ok_or_empty_23010 = empty_slice_23000 || forwards_ok_23009;
                    bool index_certs_23011;
                    
                    if (!ok_or_empty_23010) {
                        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) start_22996, ":", (long long) iter_R_22999, "] out of bounds for array of shape [", (long long) nR_17046, "].", "-> #0  ftSMJerr.fut:32:20-49\n   #1  ftSMJerr.fut:315:124-127\n   #2  ftSMJerr.fut:304:1-315:127\n"));
                        err = FUTHARK_PROGRAM_ERROR;
                        goto cleanup;
                    }
                    
                    bool y_23012 = slt64(m_23001, min_res_22998);
                    bool x_23013 = sle64((int64_t) 0, m_23001);
                    bool bounds_check_23014 = y_23012 && x_23013;
                    bool index_certs_23015;
                    
                    if (!bounds_check_23014) {
                        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) m_23001, "] out of bounds for array of shape [", (long long) min_res_22998, "].", "-> #0  ftSMJerr.fut:35:21-40\n   #1  ftSMJerr.fut:315:124-127\n   #2  ftSMJerr.fut:304:1-315:127\n"));
                        err = FUTHARK_PROGRAM_ERROR;
                        goto cleanup;
                    }
                    
                    bool y_23018 = slt64((int64_t) 0, min_res_22998);
                    bool index_certs_23019;
                    
                    if (!y_23018) {
                        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) (int64_t) 0, "] out of bounds for array of shape [", (long long) min_res_22998, "].", "-> #0  ftSMJerr.fut:34:21-30\n   #1  ftSMJerr.fut:315:124-127\n   #2  ftSMJerr.fut:304:1-315:127\n"));
                        err = FUTHARK_PROGRAM_ERROR;
                        goto cleanup;
                    }
                    {
                        err = gpu_kernel_inner_SMJ_intzigpuseq_27092(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, start_22996, i_p_m_t_s_23002, tR_mem_26243.mem, mem_26534.mem, mem_26535.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (y_21453) {
                        if (memblock_set_device(ctx, &ext_mem_26536, &ext_mem_26527, "ext_mem_26527") != 0)
                            return 1;
                    } else if (memblock_set_device(ctx, &ext_mem_26536, &mem_26534, "mem_26534") != 0)
                        return 1;
                    if (y_21453) {
                        if (memblock_set_device(ctx, &ext_mem_26537, &mem_26259, "mem_26259") != 0)
                            return 1;
                    } else if (memblock_set_device(ctx, &ext_mem_26537, &mem_26535, "mem_26535") != 0)
                        return 1;
                    {
                        err = gpu_kernel_inner_SMJ_intzigpuseq_27098(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, mem_26535.mem, ext_mem_26536.mem, mem_26538.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (memblock_unref_device(ctx, &ext_mem_26536, "ext_mem_26536") != 0)
                        return 1;
                    
                    bool read_res_27808;
                    
                    if ((err = gpu_scalar_from_device(ctx, &read_res_27808, mem_26538.mem, (int64_t) 0 * sizeof(bool), sizeof(bool))) != 0)
                        goto cleanup;
                    if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    
                    bool defunc_0_gt_res_23021 = read_res_27808;
                    int64_t ext_26682;
                    int64_t ext_26681;
                    int64_t ext_26679;
                    int64_t ext_26678;
                    int64_t loopres_23023;
                    
                    if (defunc_0_gt_res_23021) {
                        if (memblock_set_device(ctx, &ext_mem_26683, &mem_param_26530, "mem_param_26530") != 0)
                            return 1;
                        ext_26682 = ctx_param_ext_26528;
                        ext_26681 = ctx_param_ext_26529;
                        if (memblock_set_device(ctx, &ext_mem_26680, &mem_param_26533, "mem_param_26533") != 0)
                            return 1;
                        ext_26679 = ctx_param_ext_26531;
                        ext_26678 = ctx_param_ext_26532;
                        loopres_23023 = numIter_22975;
                    } else {
                        if (memblock_alloc_device(ctx, &mem_26539, (int64_t) 1, "mem_26539")) {
                            err = 1;
                            goto cleanup;
                        }
                        {
                            err = gpu_kernel_inner_SMJ_intzigpuseq_27104(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, mem_26534.mem, ext_mem_26537.mem, mem_26539.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                        
                        bool read_res_27809;
                        
                        if ((err = gpu_scalar_from_device(ctx, &read_res_27809, mem_26539.mem, (int64_t) 0 * sizeof(bool), sizeof(bool))) != 0)
                            goto cleanup;
                        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                            err = 1;
                            goto cleanup;
                        }
                        
                        bool defunc_0_gt_res_23027 = read_res_27809;
                        
                        if (memblock_unref_device(ctx, &mem_26539, "mem_26539") != 0)
                            return 1;
                        
                        int64_t ext_26676;
                        
                        if (defunc_0_gt_res_23027) {
                            ext_26676 = ctx_param_ext_26528;
                        } else {
                            ext_26676 = (int64_t) 0;
                        }
                        
                        int64_t ext_26675;
                        
                        if (defunc_0_gt_res_23027) {
                            ext_26675 = ctx_param_ext_26529;
                        } else {
                            ext_26675 = (int64_t) 1;
                        }
                        
                        int64_t ext_26673;
                        
                        if (defunc_0_gt_res_23027) {
                            ext_26673 = ctx_param_ext_26531;
                        } else {
                            ext_26673 = (int64_t) 0;
                        }
                        
                        int64_t ext_26672;
                        
                        if (defunc_0_gt_res_23027) {
                            ext_26672 = ctx_param_ext_26532;
                        } else {
                            ext_26672 = (int64_t) 1;
                        }
                        
                        int64_t loopres_f_res_23028;
                        
                        if (defunc_0_gt_res_23027) {
                            int64_t tmp_23032 = add64((int64_t) 1, p_22993);
                            
                            if (memblock_set_device(ctx, &ext_mem_26677, &mem_param_26530, "mem_param_26530") != 0)
                                return 1;
                            if (memblock_set_device(ctx, &ext_mem_26674, &mem_param_26533, "mem_param_26533") != 0)
                                return 1;
                            loopres_f_res_23028 = tmp_23032;
                        } else {
                            if (memblock_alloc_device(ctx, &mem_26541, bytes_26540, "mem_26541")) {
                                err = 1;
                                goto cleanup;
                            }
                            if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_26541.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, tS_mem_26244.mem, tS_start_21436, (int64_t []) {(int64_t) 1}, (int64_t []) {dzlz7bUZLzmZRz20UtS_endz20UtS_startz7dUzg_21439})) != 0)
                                goto cleanup;
                            if (futrts_indicesWithIncrement_7095(ctx, &ext_mem_26543, mem_26541, dzlz7bUZLzmZRz20UtS_endz20UtS_startz7dUzg_21439, join_chunks_arg3_21577) != 0) {
                                err = 1;
                                goto cleanup;
                            }
                            if (memblock_unref_device(ctx, &mem_26541, "mem_26541") != 0)
                                return 1;
                            
                            bool suff_outer_par_23351;
                            
                            suff_outer_par_23351 = *ctx->tuning_params.inner_SMJ_intzisuff_outer_par_0 <= min_res_22998;
                            if (ctx->logging)
                                fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "inner_SMJ_int.suff_outer_par_0", (long) min_res_22998, suff_outer_par_23351 ? "true" : "false");
                            
                            int64_t tile_sizze_25032;
                            
                            tile_sizze_25032 = *ctx->tuning_params.inner_SMJ_intzitile_sizze_25031;
                            
                            int64_t tile_sizze_24677;
                            
                            tile_sizze_24677 = *ctx->tuning_params.inner_SMJ_intzitile_sizze_24676;
                            
                            int64_t num_whole_tiles_25048 = squot_safe64(dzlz7bUZLzmZRz20UtS_endz20UtS_startz7dUzg_21439, tile_sizze_25032);
                            int64_t residual_input_25272 = srem_safe64(dzlz7bUZLzmZRz20UtS_endz20UtS_startz7dUzg_21439, tile_sizze_25032);
                            bool cond_25273 = residual_input_25272 == (int64_t) 0;
                            int64_t binop_x_25289 = tile_sizze_25032 * num_whole_tiles_25048;
                            int64_t bytes_26601 = (int64_t) 8 * min_res_22998;
                            int64_t bytes_26564 = (int64_t) 8 * tile_sizze_25032;
                            int64_t bytes_26566 = (int64_t) 4 * tile_sizze_25032;
                            int64_t num_whole_tiles_24693 = squot_safe64(dzlz7bUZLzmZRz20UtS_endz20UtS_startz7dUzg_21439, tile_sizze_24677);
                            int64_t residual_input_24917 = srem_safe64(dzlz7bUZLzmZRz20UtS_endz20UtS_startz7dUzg_21439, tile_sizze_24677);
                            bool cond_24918 = residual_input_24917 == (int64_t) 0;
                            int64_t binop_x_24934 = tile_sizze_24677 * num_whole_tiles_24693;
                            int64_t bytes_26625 = (int64_t) 8 * tile_sizze_24677;
                            int64_t bytes_26627 = (int64_t) 4 * tile_sizze_24677;
                            int64_t shared_memory_capacity_27162;
                            
                            shared_memory_capacity_27162 = ctx->max_shared_memory;
                            if (suff_outer_par_23351 && sle64(sdiv_up64(bytes_26625, (int64_t) 8) * (int64_t) 8 + sdiv_up64(bytes_26627, (int64_t) 8) * (int64_t) 8 + sdiv_up64(bytes_26625, (int64_t) 8) * (int64_t) 8, shared_memory_capacity_27162)) {
                                int64_t ldim_24678 = sdiv_up64(min_res_22998, tile_sizze_24677);
                                
                                if (memblock_alloc_device(ctx, &mem_26663, bytes_26601, "mem_26663")) {
                                    err = 1;
                                    goto cleanup;
                                }
                                if (memblock_alloc_device(ctx, &mem_26665, bytes_26601, "mem_26665")) {
                                    err = 1;
                                    goto cleanup;
                                }
                                if (ctx->debugging)
                                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                                
                                int32_t num_chunks_27110 = sext_i64_i32(sdiv_up64(tile_sizze_24677, tile_sizze_24677));
                                int32_t virt_num_tblocks_27111 = sext_i64_i32(ldim_24678);
                                
                                {
                                    err = gpu_kernel_inner_SMJ_intzisegmap_intrablock_24675(ctx, ldim_24678, 1, 1, *ctx->tuning_params.inner_SMJ_intzitile_sizze_24676, 1, 1, bytes_26625 + srem64((int64_t) 8 - srem64(bytes_26625, (int64_t) 8), (int64_t) 8) + (bytes_26627 + srem64((int64_t) 8 - srem64(bytes_26627, (int64_t) 8), (int64_t) 8)) + (bytes_26625 + srem64((int64_t) 8 - srem64(bytes_26625, (int64_t) 8), (int64_t) 8)), tS_start_21436, dzlz7bUZLzmZRz20UtS_endz20UtS_startz7dUzg_21439, start_22996, min_res_22998, ldim_24678, num_whole_tiles_24693, residual_input_24917, cond_24918, binop_x_24934, tR_mem_26243.mem, tS_mem_26244.mem, ext_mem_26543.mem, mem_26663.mem, mem_26665.mem);
                                    if (err != FUTHARK_SUCCESS)
                                        goto cleanup;
                                }
                                if (ctx->debugging)
                                    fprintf(ctx->log, "%s\n", "");
                                if (memblock_set_device(ctx, &ext_mem_26667, &mem_26663, "mem_26663") != 0)
                                    return 1;
                                if (memblock_set_device(ctx, &ext_mem_26666, &mem_26665, "mem_26665") != 0)
                                    return 1;
                            } else {
                                int64_t ldim_25033 = sdiv_up64(min_res_22998, tile_sizze_25032);
                                
                                if (memblock_alloc_device(ctx, &mem_26602, bytes_26601, "mem_26602")) {
                                    err = 1;
                                    goto cleanup;
                                }
                                if (memblock_alloc_device(ctx, &mem_26604, bytes_26601, "mem_26604")) {
                                    err = 1;
                                    goto cleanup;
                                }
                                if (ctx->debugging)
                                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                                
                                int32_t num_chunks_27136 = sext_i64_i32(sdiv_up64(tile_sizze_25032, tile_sizze_25032));
                                int32_t virt_num_tblocks_27137 = sext_i64_i32(ldim_25033);
                                
                                {
                                    err = gpu_kernel_inner_SMJ_intzisegmap_intrablock_25030(ctx, ldim_25033, 1, 1, *ctx->tuning_params.inner_SMJ_intzitile_sizze_25031, 1, 1, bytes_26564 + srem64((int64_t) 8 - srem64(bytes_26564, (int64_t) 8), (int64_t) 8) + (bytes_26566 + srem64((int64_t) 8 - srem64(bytes_26566, (int64_t) 8), (int64_t) 8)) + (bytes_26564 + srem64((int64_t) 8 - srem64(bytes_26564, (int64_t) 8), (int64_t) 8)), tS_start_21436, dzlz7bUZLzmZRz20UtS_endz20UtS_startz7dUzg_21439, start_22996, min_res_22998, ldim_25033, num_whole_tiles_25048, residual_input_25272, cond_25273, binop_x_25289, tR_mem_26243.mem, tS_mem_26244.mem, ext_mem_26543.mem, mem_26602.mem, mem_26604.mem);
                                    if (err != FUTHARK_SUCCESS)
                                        goto cleanup;
                                }
                                if (ctx->debugging)
                                    fprintf(ctx->log, "%s\n", "");
                                if (memblock_set_device(ctx, &ext_mem_26667, &mem_26602, "mem_26602") != 0)
                                    return 1;
                                if (memblock_set_device(ctx, &ext_mem_26666, &mem_26604, "mem_26604") != 0)
                                    return 1;
                            }
                            if (memblock_unref_device(ctx, &ext_mem_26543, "ext_mem_26543") != 0)
                                return 1;
                            if (memblock_alloc_device(ctx, &mem_26669, bytes_26246, "mem_26669")) {
                                err = 1;
                                goto cleanup;
                            }
                            if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_26669.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_26533.mem, ctx_param_ext_26531, (int64_t []) {ctx_param_ext_26532}, (int64_t []) {nR_17046})) != 0)
                                goto cleanup;
                            if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_26669.mem, start_22996, (int64_t []) {(int64_t) 1}, ext_mem_26667.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {min_res_22998})) != 0)
                                goto cleanup;
                            if (memblock_unref_device(ctx, &ext_mem_26667, "ext_mem_26667") != 0)
                                return 1;
                            if (memblock_alloc_device(ctx, &mem_26671, bytes_26246, "mem_26671")) {
                                err = 1;
                                goto cleanup;
                            }
                            if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_26671.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_26530.mem, ctx_param_ext_26528, (int64_t []) {ctx_param_ext_26529}, (int64_t []) {nR_17046})) != 0)
                                goto cleanup;
                            if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_26671.mem, start_22996, (int64_t []) {(int64_t) 1}, ext_mem_26666.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {min_res_22998})) != 0)
                                goto cleanup;
                            if (memblock_unref_device(ctx, &ext_mem_26666, "ext_mem_26666") != 0)
                                return 1;
                            
                            int64_t tmp_23084 = add64((int64_t) 1, p_22993);
                            
                            if (memblock_set_device(ctx, &ext_mem_26677, &mem_26671, "mem_26671") != 0)
                                return 1;
                            if (memblock_set_device(ctx, &ext_mem_26674, &mem_26669, "mem_26669") != 0)
                                return 1;
                            loopres_f_res_23028 = tmp_23084;
                        }
                        if (memblock_set_device(ctx, &ext_mem_26683, &ext_mem_26677, "ext_mem_26677") != 0)
                            return 1;
                        ext_26682 = ext_26676;
                        ext_26681 = ext_26675;
                        if (memblock_set_device(ctx, &ext_mem_26680, &ext_mem_26674, "ext_mem_26674") != 0)
                            return 1;
                        ext_26679 = ext_26673;
                        ext_26678 = ext_26672;
                        loopres_23023 = loopres_f_res_23028;
                    }
                    if (memblock_unref_device(ctx, &ext_mem_26537, "ext_mem_26537") != 0)
                        return 1;
                    
                    bool loop_cond_23085 = slt64(loopres_23023, numIter_22975);
                    
                    if (memblock_set_device(ctx, &mem_param_tmp_27082, &ext_mem_26683, "ext_mem_26683") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &mem_param_tmp_27083, &ext_mem_26680, "ext_mem_26680") != 0)
                        return 1;
                    
                    int64_t ctx_param_ext_tmp_27084 = ext_26682;
                    int64_t ctx_param_ext_tmp_27085 = ext_26681;
                    int64_t ctx_param_ext_tmp_27086 = ext_26679;
                    int64_t ctx_param_ext_tmp_27087 = ext_26678;
                    bool loop_while_tmp_27088 = loop_cond_23085;
                    int64_t p_tmp_27089 = loopres_23023;
                    
                    if (memblock_set_device(ctx, &mem_param_26530, &mem_param_tmp_27082, "mem_param_tmp_27082") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &mem_param_26533, &mem_param_tmp_27083, "mem_param_tmp_27083") != 0)
                        return 1;
                    ctx_param_ext_26528 = ctx_param_ext_tmp_27084;
                    ctx_param_ext_26529 = ctx_param_ext_tmp_27085;
                    ctx_param_ext_26531 = ctx_param_ext_tmp_27086;
                    ctx_param_ext_26532 = ctx_param_ext_tmp_27087;
                    loop_while_22992 = loop_while_tmp_27088;
                    p_22993 = p_tmp_27089;
                }
                if (memblock_set_device(ctx, &ext_mem_26689, &mem_param_26530, "mem_param_26530") != 0)
                    return 1;
                if (memblock_set_device(ctx, &ext_mem_26688, &mem_param_26533, "mem_param_26533") != 0)
                    return 1;
                ext_26687 = ctx_param_ext_26528;
                ext_26686 = ctx_param_ext_26529;
                ext_26685 = ctx_param_ext_26531;
                ext_26684 = ctx_param_ext_26532;
                defunc_0_find_joinTuples_res_22988 = loop_while_22992;
                defunc_0_find_joinTuples_res_22989 = p_22993;
                if (memblock_unref_device(ctx, &ext_mem_26527, "ext_mem_26527") != 0)
                    return 1;
                if (memblock_unref_device(ctx, &mem_26534, "mem_26534") != 0)
                    return 1;
                if (memblock_unref_device(ctx, &mem_26535, "mem_26535") != 0)
                    return 1;
                if (memblock_unref_device(ctx, &mem_26538, "mem_26538") != 0)
                    return 1;
                if (memblock_set_device(ctx, &ext_mem_26695, &ext_mem_26689, "ext_mem_26689") != 0)
                    return 1;
                ext_26694 = ext_26687;
                ext_26693 = ext_26686;
                if (memblock_set_device(ctx, &ext_mem_26692, &ext_mem_26688, "ext_mem_26688") != 0)
                    return 1;
                ext_26691 = ext_26685;
                ext_26690 = ext_26684;
            } else {
                if (memblock_alloc_device(ctx, &mem_26262, bytes_26261, "mem_26262")) {
                    err = 1;
                    goto cleanup;
                }
                if (futrts_builtinzhreplicate_i64(ctx, mem_26262, dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578, nR_17046) != 0) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &mem_26264, bytes_26261, "mem_26264")) {
                    err = 1;
                    goto cleanup;
                }
                if (futrts_builtinzhreplicate_i64(ctx, mem_26264, dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578, nR_17046) != 0) {
                    err = 1;
                    goto cleanup;
                }
                if (loop_cond_21581) {
                    if (memblock_alloc_device(ctx, &mem_26266, (int64_t) 4, "mem_26266")) {
                        err = 1;
                        goto cleanup;
                    }
                    {
                        err = gpu_kernel_inner_SMJ_intzigpuseq_27163(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, tR_mem_26243.mem, mem_26266.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (memblock_set_device(ctx, &ext_mem_26267, &mem_26266, "mem_26266") != 0)
                        return 1;
                } else {
                    if (memblock_alloc_device(ctx, &mem_26265, (int64_t) 4, "mem_26265")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (futrts_builtinzhreplicate_i32(ctx, mem_26265, (int64_t) 1, 0) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_set_device(ctx, &ext_mem_26267, &mem_26265, "mem_26265") != 0)
                        return 1;
                }
                if (memblock_alloc_device(ctx, &mem_26268, (int64_t) 1, "mem_26268")) {
                    err = 1;
                    goto cleanup;
                }
                {
                    err = gpu_kernel_inner_SMJ_intzigpuseq_27169(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, mem_26259.mem, ext_mem_26267.mem, mem_26268.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (memblock_unref_device(ctx, &ext_mem_26267, "ext_mem_26267") != 0)
                    return 1;
                if (loop_cond_21581) {
                    if (memblock_alloc_device(ctx, &mem_26270, (int64_t) 4, "mem_26270")) {
                        err = 1;
                        goto cleanup;
                    }
                    {
                        err = gpu_kernel_inner_SMJ_intzigpuseq_27175(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, nR_17046, y_21584, tR_mem_26243.mem, mem_26259.mem, mem_26268.mem, mem_26270.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    ctx->failure_is_an_option = 1;
                    if (memblock_set_device(ctx, &ext_mem_26271, &mem_26270, "mem_26270") != 0)
                        return 1;
                } else {
                    if (memblock_alloc_device(ctx, &mem_26269, (int64_t) 4, "mem_26269")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (futrts_builtinzhreplicate_i32(ctx, mem_26269, (int64_t) 1, 0) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_set_device(ctx, &ext_mem_26271, &mem_26269, "mem_26269") != 0)
                        return 1;
                }
                if (memblock_unref_device(ctx, &mem_26268, "mem_26268") != 0)
                    return 1;
                
                bool defunc_0_windowed_partitionFunc_res_21599;
                int64_t defunc_0_windowed_partitionFunc_res_21600;
                bool loop_while_21603;
                int64_t p_21604;
                
                loop_while_21603 = loop_cond_21581;
                p_21604 = (int64_t) 0;
                while (loop_while_21603) {
                    int64_t start_21607 = mul64(partitionsPerWindow_17052, p_21604);
                    int64_t end_21608 = add64(partitionsPerWindow_17052, start_21607);
                    int64_t max_res_21609 = smax64((int64_t) 1, start_21607);
                    int64_t dzlz7bUZLzmZRz20UZLupToThreadZRz20UZLfirstThrZRz7dUzg_21610 = sub64(end_21608, max_res_21609);
                    bool bounds_invalid_upwards_21611 = slt64(end_21608, max_res_21609);
                    bool valid_21612 = !bounds_invalid_upwards_21611;
                    bool range_valid_c_21613;
                    
                    if (!valid_21612) {
                        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) max_res_21609, "..<", (long long) end_21608, " is invalid.", "-> #0  ftbasics.fut:153:43-68\n   #1  ftSMJerr.fut:315:124-127\n   #2  ftSMJerr.fut:304:1-315:127\n"));
                        err = FUTHARK_PROGRAM_ERROR;
                        goto cleanup;
                    }
                    
                    bool zzero_21616 = dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578 == (int64_t) 0;
                    bool nonzzero_21617 = !zzero_21616;
                    bool nonzzero_cert_21618;
                    
                    if (!nonzzero_21617) {
                        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftbasics.fut:156:36-47\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftbasics.fut:155:8-215:8\n   #3  ftSMJerr.fut:315:124-127\n   #4  ftSMJerr.fut:304:1-315:127\n"));
                        err = FUTHARK_PROGRAM_ERROR;
                        goto cleanup;
                    }
                    
                    int64_t bytes_26279 = (int64_t) 8 * dzlz7bUZLzmZRz20UZLupToThreadZRz20UZLfirstThrZRz7dUzg_21610;
                    bool cond_21819 = slt64((int64_t) 0, start_21607);
                    int64_t conc_tmp_21820 = (int64_t) 1 + dzlz7bUZLzmZRz20UZLupToThreadZRz20UZLfirstThrZRz7dUzg_21610;
                    int64_t ret_21821;
                    
                    if (cond_21819) {
                        ret_21821 = dzlz7bUZLzmZRz20UZLupToThreadZRz20UZLfirstThrZRz7dUzg_21610;
                    } else {
                        ret_21821 = conc_tmp_21820;
                    }
                    
                    bool eq_x_y_21829 = partitionsPerWindow_17052 == dzlz7bUZLzmZRz20UZLupToThreadZRz20UZLfirstThrZRz7dUzg_21610;
                    bool eq_x_zz_21830 = partitionsPerWindow_17052 == conc_tmp_21820;
                    bool p_and_eq_x_y_21831 = cond_21819 && eq_x_y_21829;
                    bool not_p_21832 = !cond_21819;
                    bool p_and_eq_x_y_21833 = eq_x_zz_21830 && not_p_21832;
                    bool dim_match_21834 = p_and_eq_x_y_21831 || p_and_eq_x_y_21833;
                    bool empty_or_match_cert_21835;
                    
                    if (!dim_match_21834) {
                        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Value of (desugared) shape [", (long long) ret_21821, "] cannot match shape of type `[", (long long) partitionsPerWindow_17052, "](i64, i64)`.", "-> #0  ftbasics.fut:217:5-222:49\n   #1  ftSMJerr.fut:315:124-127\n   #2  ftSMJerr.fut:304:1-315:127\n"));
                        err = FUTHARK_PROGRAM_ERROR;
                        goto cleanup;
                    }
                    
                    int64_t i_p_m_t_s_21837 = add64(m_21583, start_21607);
                    bool zzero_leq_i_p_m_t_s_21838 = sle64((int64_t) 0, i_p_m_t_s_21837);
                    bool i_p_m_t_s_leq_w_21839 = slt64(i_p_m_t_s_21837, dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578);
                    bool zzero_lte_i_21840 = sle64((int64_t) 0, start_21607);
                    bool i_lte_j_21841 = sle64(start_21607, end_21608);
                    bool y_21842 = i_p_m_t_s_leq_w_21839 && zzero_lte_i_21840;
                    bool y_21843 = zzero_leq_i_p_m_t_s_21838 && y_21842;
                    bool forwards_ok_21844 = i_lte_j_21841 && y_21843;
                    bool ok_or_empty_21845 = empty_slice_21582 || forwards_ok_21844;
                    bool index_certs_21846;
                    
                    if (!ok_or_empty_21845) {
                        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) start_21607, ":", (long long) end_21608, "] out of bounds for array of shape [", (long long) dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578, "].", "-> #0  ftSMJerr.fut:85:37-74\n   #1  ftSMJerr.fut:315:124-127\n   #2  ftSMJerr.fut:304:1-315:127\n"));
                        err = FUTHARK_PROGRAM_ERROR;
                        goto cleanup;
                    }
                    
                    int64_t zt_rhs_21615 = add64(nR_17046, nR_17046);
                    int64_t segmap_usable_groups_23737 = sdiv_up64(dzlz7bUZLzmZRz20UZLupToThreadZRz20UZLfirstThrZRz7dUzg_21610, segmap_tblock_sizze_23736);
                    
                    if (memblock_alloc_device(ctx, &mem_26280, bytes_26279, "mem_26280")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &mem_26282, bytes_26279, "mem_26282")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t virt_num_tblocks_27185 = sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20UZLupToThreadZRz20UZLfirstThrZRz7dUzg_21610, segmap_tblock_sizze_23736));
                    
                    {
                        err = gpu_kernel_inner_SMJ_intzisegmap_23741(ctx, segmap_usable_groups_23737, 1, 1, *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_23529, 1, 1, (int64_t) 0, nR_17046, tS_start_21436, dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578, max_res_21609, dzlz7bUZLzmZRz20UZLupToThreadZRz20UZLfirstThrZRz7dUzg_21610, zt_rhs_21615, tR_mem_26243.mem, tS_mem_26244.mem, ext_mem_26271.mem, mem_26280.mem, mem_26282.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    ctx->failure_is_an_option = 1;
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    
                    int64_t bytes_26284 = (int64_t) 8 * ret_21821;
                    
                    if (cond_21819) {
                        if (memblock_set_device(ctx, &ext_mem_26289, &mem_26280, "mem_26280") != 0)
                            return 1;
                        if (memblock_set_device(ctx, &ext_mem_26288, &mem_26282, "mem_26282") != 0)
                            return 1;
                    } else {
                        if (memblock_alloc_device(ctx, &mem_26287, bytes_26284, "mem_26287")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (futrts_builtinzhreplicate_i64(ctx, mem_26287, (int64_t) 1, (int64_t) 0) != 0) {
                            err = 1;
                            goto cleanup;
                        }
                        if (memblock_alloc_device(ctx, &mem_26285, bytes_26284, "mem_26285")) {
                            err = 1;
                            goto cleanup;
                        }
                        
                        int64_t tmp_offs_27206 = (int64_t) 0;
                        
                        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_26285.mem, tmp_offs_27206, (int64_t []) {(int64_t) 1}, mem_26287.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {(int64_t) 1})) != 0)
                            goto cleanup;
                        tmp_offs_27206 += (int64_t) 1;
                        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_26285.mem, tmp_offs_27206, (int64_t []) {(int64_t) 1}, mem_26280.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {dzlz7bUZLzmZRz20UZLupToThreadZRz20UZLfirstThrZRz7dUzg_21610})) != 0)
                            goto cleanup;
                        tmp_offs_27206 += dzlz7bUZLzmZRz20UZLupToThreadZRz20UZLfirstThrZRz7dUzg_21610;
                        
                        int64_t tmp_offs_27207 = (int64_t) 0;
                        
                        if (!(tmp_offs_27207 == (int64_t) 0)) {
                            if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_26287.mem, tmp_offs_27207, (int64_t []) {(int64_t) 1}, mem_26287.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {(int64_t) 1})) != 0)
                                goto cleanup;
                        }
                        tmp_offs_27207 += (int64_t) 1;
                        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_26287.mem, tmp_offs_27207, (int64_t []) {(int64_t) 1}, mem_26282.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {dzlz7bUZLzmZRz20UZLupToThreadZRz20UZLfirstThrZRz7dUzg_21610})) != 0)
                            goto cleanup;
                        tmp_offs_27207 += dzlz7bUZLzmZRz20UZLupToThreadZRz20UZLfirstThrZRz7dUzg_21610;
                        if (memblock_set_device(ctx, &ext_mem_26289, &mem_26285, "mem_26285") != 0)
                            return 1;
                        if (memblock_set_device(ctx, &ext_mem_26288, &mem_26287, "mem_26287") != 0)
                            return 1;
                    }
                    if (memblock_unref_device(ctx, &mem_26280, "mem_26280") != 0)
                        return 1;
                    if (memblock_unref_device(ctx, &mem_26282, "mem_26282") != 0)
                        return 1;
                    
                    int64_t tmp_21836 = add64((int64_t) 1, p_21604);
                    
                    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_26262.mem, start_21607, (int64_t []) {(int64_t) 1}, ext_mem_26289.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {ret_21821})) != 0)
                        goto cleanup;
                    if (memblock_unref_device(ctx, &ext_mem_26289, "ext_mem_26289") != 0)
                        return 1;
                    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_26264.mem, start_21607, (int64_t []) {(int64_t) 1}, ext_mem_26288.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {ret_21821})) != 0)
                        goto cleanup;
                    if (memblock_unref_device(ctx, &ext_mem_26288, "ext_mem_26288") != 0)
                        return 1;
                    
                    bool loop_cond_21849 = slt64(tmp_21836, numberOfWindows_17053);
                    bool loop_while_tmp_27181 = loop_cond_21849;
                    int64_t p_tmp_27182 = tmp_21836;
                    
                    loop_while_21603 = loop_while_tmp_27181;
                    p_21604 = p_tmp_27182;
                }
                defunc_0_windowed_partitionFunc_res_21599 = loop_while_21603;
                defunc_0_windowed_partitionFunc_res_21600 = p_21604;
                if (memblock_unref_device(ctx, &ext_mem_26271, "ext_mem_26271") != 0)
                    return 1;
                if (memblock_alloc_device(ctx, &mem_26298, bytes_26261, "mem_26298")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &mem_26300, bytes_26261, "mem_26300")) {
                    err = 1;
                    goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_27208 = sext_i64_i32(sdiv_up64(dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578, segmap_tblock_sizze_24110));
                
                {
                    err = gpu_kernel_inner_SMJ_intzisegmap_24115(ctx, segmap_usable_groups_24111, 1, 1, *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_23946, 1, 1, (int64_t) 0, nR_17046, gt_rhs_21419, tS_start_21436, dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578, zeze_rhs_21852, tR_mem_26243.mem, tS_mem_26244.mem, mem_26262.mem, mem_26264.mem, mem_26298.mem, mem_26300.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                ctx->failure_is_an_option = 1;
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                
                int64_t ext_26522;
                int64_t ext_26521;
                int64_t ext_26520;
                int64_t ext_26519;
                bool defunc_0_join_chunks_res_22008;
                int64_t defunc_0_join_chunks_res_22009;
                bool loop_while_22012;
                int64_t p_22013;
                int64_t ctx_param_ext_26301;
                int64_t ctx_param_ext_26302;
                int64_t ctx_param_ext_26304;
                int64_t ctx_param_ext_26305;
                
                if (memblock_set_device(ctx, &mem_param_26303, &mem_26249, "mem_26249") != 0)
                    return 1;
                if (memblock_set_device(ctx, &mem_param_26306, &mem_26247, "mem_26247") != 0)
                    return 1;
                ctx_param_ext_26301 = (int64_t) 0;
                ctx_param_ext_26302 = (int64_t) 1;
                ctx_param_ext_26304 = (int64_t) 0;
                ctx_param_ext_26305 = (int64_t) 1;
                loop_while_22012 = loop_cond_22007;
                p_22013 = (int64_t) 0;
                while (loop_while_22012) {
                    bool x_22016 = sle64((int64_t) 0, p_22013);
                    bool y_22017 = slt64(p_22013, dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578);
                    bool bounds_check_22018 = x_22016 && y_22017;
                    bool index_certs_22019;
                    
                    if (!bounds_check_22018) {
                        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) p_22013, "] out of bounds for array of shape [", (long long) dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578, "].", "-> #0  ftSMJerr.fut:163:22-34\n   #1  ftSMJerr.fut:315:124-127\n   #2  ftSMJerr.fut:304:1-315:127\n"));
                        err = FUTHARK_PROGRAM_ERROR;
                        goto cleanup;
                    }
                    
                    int64_t read_res_27810;
                    
                    if ((err = gpu_scalar_from_device(ctx, &read_res_27810, mem_26298.mem, p_22013 * sizeof(int64_t), sizeof(int64_t))) != 0)
                        goto cleanup;
                    if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    
                    int64_t loopres_22020 = read_res_27810;
                    int64_t read_res_27811;
                    
                    if ((err = gpu_scalar_from_device(ctx, &read_res_27811, mem_26300.mem, p_22013 * sizeof(int64_t), sizeof(int64_t))) != 0)
                        goto cleanup;
                    if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    
                    int64_t loopres_22021 = read_res_27811;
                    int64_t min_res_22022 = smin64(zeze_rhs_21852, loopres_22021);
                    bool cond_22023 = sle64(dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578, loopres_22020);
                    bool cond_22027 = slt64(min_res_22022, (int64_t) 0);
                    bool protect_assert_disj_22029 = bounds_check_22018 || cond_22027;
                    bool protect_assert_disj_26915 = cond_22023 || protect_assert_disj_22029;
                    bool index_certs_22030;
                    
                    if (!protect_assert_disj_26915) {
                        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) p_22013, "] out of bounds for array of shape [", (long long) dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578, "].", "-> #0  ftSMJerr.fut:167:19-32\n   #1  ftSMJerr.fut:315:124-127\n   #2  ftSMJerr.fut:304:1-315:127\n"));
                        err = FUTHARK_PROGRAM_ERROR;
                        goto cleanup;
                    }
                    
                    int64_t zeze_lhs_22033 = add64((int64_t) 1, p_22013);
                    bool cond_22034 = zeze_lhs_22033 == dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578;
                    bool x_22036 = sle64((int64_t) 0, zeze_lhs_22033);
                    bool y_22037 = slt64(zeze_lhs_22033, dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578);
                    bool bounds_check_22038 = x_22036 && y_22037;
                    bool protect_assert_disj_22039 = cond_22034 || bounds_check_22038;
                    bool protect_assert_disj_22040 = cond_22027 || protect_assert_disj_22039;
                    bool protect_assert_disj_26918 = cond_22023 || protect_assert_disj_22040;
                    bool index_certs_22041;
                    
                    if (!protect_assert_disj_26918) {
                        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) zeze_lhs_22033, "] out of bounds for array of shape [", (long long) dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578, "].", "-> #0  ftSMJerr.fut:168:49-64\n   #1  ftSMJerr.fut:315:124-127\n   #2  ftSMJerr.fut:304:1-315:127\n"));
                        err = FUTHARK_PROGRAM_ERROR;
                        goto cleanup;
                    }
                    
                    bool x_26912 = !cond_22023;
                    bool x_22028 = !cond_22027;
                    bool protect_cond_conj_26916 = x_22028 && x_26912;
                    int64_t loopres_f_res_f_res_22031;
                    
                    if (protect_cond_conj_26916) {
                        int64_t read_res_27812;
                        
                        if ((err = gpu_scalar_from_device(ctx, &read_res_27812, mem_26262.mem, p_22013 * sizeof(int64_t), sizeof(int64_t))) != 0)
                            goto cleanup;
                        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                            err = 1;
                            goto cleanup;
                        }
                        
                        int64_t x_23301 = read_res_27812;
                        
                        loopres_f_res_f_res_22031 = x_23301;
                    } else {
                        loopres_f_res_f_res_22031 = (int64_t) 0;
                    }
                    
                    bool x_22035 = !cond_22034;
                    bool protect_cond_conj_22042 = x_22028 && x_22035;
                    bool protect_cond_conj_26919 = protect_cond_conj_22042 && x_26912;
                    int64_t r_end_f_res_22043;
                    
                    if (protect_cond_conj_26919) {
                        int64_t read_res_27813;
                        
                        if ((err = gpu_scalar_from_device(ctx, &read_res_27813, mem_26262.mem, zeze_lhs_22033 * sizeof(int64_t), sizeof(int64_t))) != 0)
                            goto cleanup;
                        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                            err = 1;
                            goto cleanup;
                        }
                        
                        int64_t x_23302 = read_res_27813;
                        
                        r_end_f_res_22043 = x_23302;
                    } else {
                        r_end_f_res_22043 = (int64_t) 0;
                    }
                    
                    int64_t r_end_22045;
                    
                    if (cond_22034) {
                        r_end_22045 = nR_17046;
                    } else {
                        r_end_22045 = r_end_f_res_22043;
                    }
                    
                    int64_t dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046 = sub64(r_end_22045, loopres_f_res_f_res_22031);
                    int64_t ext_26511;
                    
                    if (cond_22027) {
                        ext_26511 = ctx_param_ext_26301;
                    } else {
                        ext_26511 = (int64_t) 0;
                    }
                    
                    int64_t ext_26510;
                    
                    if (cond_22027) {
                        ext_26510 = ctx_param_ext_26302;
                    } else {
                        ext_26510 = (int64_t) 1;
                    }
                    
                    int64_t ext_26508;
                    
                    if (cond_22027) {
                        ext_26508 = ctx_param_ext_26304;
                    } else {
                        ext_26508 = (int64_t) 0;
                    }
                    
                    int64_t ext_26507;
                    
                    if (cond_22027) {
                        ext_26507 = ctx_param_ext_26305;
                    } else {
                        ext_26507 = (int64_t) 1;
                    }
                    
                    int64_t bytes_26307 = (int64_t) 8 * dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046;
                    int64_t ext_26517;
                    
                    if (cond_22023) {
                        ext_26517 = ctx_param_ext_26301;
                    } else {
                        ext_26517 = ext_26511;
                    }
                    
                    int64_t ext_26516;
                    
                    if (cond_22023) {
                        ext_26516 = ctx_param_ext_26302;
                    } else {
                        ext_26516 = ext_26510;
                    }
                    
                    int64_t ext_26514;
                    
                    if (cond_22023) {
                        ext_26514 = ctx_param_ext_26304;
                    } else {
                        ext_26514 = ext_26508;
                    }
                    
                    int64_t ext_26513;
                    
                    if (cond_22023) {
                        ext_26513 = ctx_param_ext_26305;
                    } else {
                        ext_26513 = ext_26507;
                    }
                    
                    int64_t loopres_22024;
                    
                    if (cond_22023) {
                        loopres_22024 = dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578;
                    } else {
                        loopres_22024 = zeze_lhs_22033;
                    }
                    if (cond_22023) {
                        if (memblock_set_device(ctx, &ext_mem_26518, &mem_param_26303, "mem_param_26303") != 0)
                            return 1;
                        if (memblock_set_device(ctx, &ext_mem_26515, &mem_param_26306, "mem_param_26306") != 0)
                            return 1;
                    } else {
                        if (cond_22027) {
                            if (memblock_set_device(ctx, &ext_mem_26512, &mem_param_26303, "mem_param_26303") != 0)
                                return 1;
                            if (memblock_set_device(ctx, &ext_mem_26509, &mem_param_26306, "mem_param_26306") != 0)
                                return 1;
                        } else {
                            bool empty_slice_22049 = dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046 == (int64_t) 0;
                            int64_t m_22050 = sub64(dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046, (int64_t) 1);
                            int64_t i_p_m_t_s_22051 = add64(loopres_f_res_f_res_22031, m_22050);
                            bool zzero_leq_i_p_m_t_s_22052 = sle64((int64_t) 0, i_p_m_t_s_22051);
                            bool i_p_m_t_s_leq_w_22053 = slt64(i_p_m_t_s_22051, nR_17046);
                            bool zzero_lte_i_22054 = sle64((int64_t) 0, loopres_f_res_f_res_22031);
                            bool i_lte_j_22055 = sle64(loopres_f_res_f_res_22031, r_end_22045);
                            bool y_22056 = i_p_m_t_s_leq_w_22053 && zzero_lte_i_22054;
                            bool y_22057 = zzero_leq_i_p_m_t_s_22052 && y_22056;
                            bool forwards_ok_22058 = i_lte_j_22055 && y_22057;
                            bool ok_or_empty_22059 = empty_slice_22049 || forwards_ok_22058;
                            bool index_certs_22060;
                            
                            if (!ok_or_empty_22059) {
                                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) loopres_f_res_f_res_22031, ":", (long long) r_end_22045, "] out of bounds for array of shape [", (long long) nR_17046, "].", "-> #0  ftSMJerr.fut:169:16-33\n   #1  ftSMJerr.fut:315:124-127\n   #2  ftSMJerr.fut:304:1-315:127\n"));
                                err = FUTHARK_PROGRAM_ERROR;
                                goto cleanup;
                            }
                            
                            bool loop_cond_22063 = sle64(loopres_22020, min_res_22022);
                            bool loop_not_taken_22068 = !loop_cond_22063;
                            bool protect_assert_disj_22069 = loop_not_taken_22068 || nonzzero_22973;
                            bool nonzzero_cert_22070;
                            
                            if (!protect_assert_disj_22069) {
                                set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftSMJerr.fut:25:39-55\n   #1  ftSMJerr.fut:315:124-127\n   #2  ftSMJerr.fut:304:1-315:127\n"));
                                err = FUTHARK_PROGRAM_ERROR;
                                goto cleanup;
                            }
                            if (memblock_alloc_device(ctx, &mem_26308, bytes_26307, "mem_26308")) {
                                err = 1;
                                goto cleanup;
                            }
                            if (futrts_builtinzhreplicate_i64(ctx, mem_26308, dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046, (int64_t) -1) != 0) {
                                err = 1;
                                goto cleanup;
                            }
                            if (memblock_alloc_device(ctx, &mem_26310, bytes_26307, "mem_26310")) {
                                err = 1;
                                goto cleanup;
                            }
                            if (futrts_builtinzhreplicate_i64(ctx, mem_26310, dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046, (int64_t) 0) != 0) {
                                err = 1;
                                goto cleanup;
                            }
                            
                            int64_t zm_lhs_22064 = add64(extParallelism_17054, dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046);
                            int64_t zs_lhs_22065 = sub64(zm_lhs_22064, (int64_t) 1);
                            int64_t numIter_22071 = sdiv_safe64(zs_lhs_22065, extParallelism_17054);
                            bool loop_cond_22072 = slt64((int64_t) 0, numIter_22071);
                            bool loop_not_taken_22073 = !loop_cond_22072;
                            int64_t segmap_tblock_sizze_24463;
                            
                            segmap_tblock_sizze_24463 = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24453;
                            
                            int64_t segmap_usable_groups_24464 = sdiv_up_safe64(dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046, segmap_tblock_sizze_24463);
                            int64_t segmap_tblock_sizze_24484;
                            
                            segmap_tblock_sizze_24484 = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24475;
                            
                            int64_t segmap_usable_groups_24485 = sdiv_up_safe64(dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046, segmap_tblock_sizze_24484);
                            
                            if (memblock_alloc_device(ctx, &mem_26329, (int64_t) 4, "mem_26329")) {
                                err = 1;
                                goto cleanup;
                            }
                            if (memblock_alloc_device(ctx, &mem_26330, (int64_t) 4, "mem_26330")) {
                                err = 1;
                                goto cleanup;
                            }
                            if (memblock_alloc_device(ctx, &mem_26333, (int64_t) 1, "mem_26333")) {
                                err = 1;
                                goto cleanup;
                            }
                            
                            bool loopres_f_res_f_res_22074;
                            int64_t loopres_f_res_f_res_22075;
                            bool loop_while_22078;
                            int64_t dp_22079;
                            
                            if (memblock_set_device(ctx, &mem_param_26313, &mem_26310, "mem_26310") != 0)
                                return 1;
                            if (memblock_set_device(ctx, &mem_param_26316, &mem_26308, "mem_26308") != 0)
                                return 1;
                            loop_while_22078 = loop_cond_22063;
                            dp_22079 = loopres_22020;
                            while (loop_while_22078) {
                                bool x_22082 = sle64((int64_t) 0, dp_22079);
                                bool y_22083 = slt64(dp_22079, dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578);
                                bool bounds_check_22084 = x_22082 && y_22083;
                                bool index_certs_22085;
                                
                                if (!bounds_check_22084) {
                                    set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) dp_22079, "] out of bounds for array of shape [", (long long) dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578, "].", "-> #0  ftSMJerr.fut:173:21-38\n   #1  ftSMJerr.fut:315:124-127\n   #2  ftSMJerr.fut:304:1-315:127\n"));
                                    err = FUTHARK_PROGRAM_ERROR;
                                    goto cleanup;
                                }
                                
                                int64_t read_res_27814;
                                
                                if ((err = gpu_scalar_from_device(ctx, &read_res_27814, mem_26264.mem, dp_22079 * sizeof(int64_t), sizeof(int64_t))) != 0)
                                    goto cleanup;
                                if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                                    err = 1;
                                    goto cleanup;
                                }
                                
                                int64_t loopres_22086 = read_res_27814;
                                int64_t zeze_lhs_22087 = add64((int64_t) 1, dp_22079);
                                bool cond_22088 = zeze_lhs_22087 == dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578;
                                bool x_22089 = !cond_22088;
                                bool x_22090 = sle64((int64_t) 0, zeze_lhs_22087);
                                bool y_22091 = slt64(zeze_lhs_22087, dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578);
                                bool bounds_check_22092 = x_22090 && y_22091;
                                bool protect_assert_disj_22093 = cond_22088 || bounds_check_22092;
                                bool index_certs_22094;
                                
                                if (!protect_assert_disj_22093) {
                                    set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) zeze_lhs_22087, "] out of bounds for array of shape [", (long long) dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578, "].", "-> #0  ftSMJerr.fut:174:55-74\n   #1  ftSMJerr.fut:315:124-127\n   #2  ftSMJerr.fut:304:1-315:127\n"));
                                    err = FUTHARK_PROGRAM_ERROR;
                                    goto cleanup;
                                }
                                
                                int64_t s_end_f_res_22095;
                                
                                if (x_22089) {
                                    int64_t read_res_27815;
                                    
                                    if ((err = gpu_scalar_from_device(ctx, &read_res_27815, mem_26264.mem, zeze_lhs_22087 * sizeof(int64_t), sizeof(int64_t))) != 0)
                                        goto cleanup;
                                    if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                                        err = 1;
                                        goto cleanup;
                                    }
                                    
                                    int64_t x_23303 = read_res_27815;
                                    
                                    s_end_f_res_22095 = x_23303;
                                } else {
                                    s_end_f_res_22095 = (int64_t) 0;
                                }
                                
                                int64_t s_end_22097;
                                
                                if (cond_22088) {
                                    s_end_22097 = nR_17046;
                                } else {
                                    s_end_22097 = s_end_f_res_22095;
                                }
                                
                                int64_t j_m_i_22098 = sub64(s_end_22097, loopres_22086);
                                bool empty_slice_22099 = j_m_i_22098 == (int64_t) 0;
                                int64_t m_22100 = sub64(j_m_i_22098, (int64_t) 1);
                                int64_t i_p_m_t_s_22101 = add64(loopres_22086, m_22100);
                                bool zzero_leq_i_p_m_t_s_22102 = sle64((int64_t) 0, i_p_m_t_s_22101);
                                bool i_p_m_t_s_leq_w_22103 = slt64(i_p_m_t_s_22101, nR_17046);
                                bool zzero_lte_i_22104 = sle64((int64_t) 0, loopres_22086);
                                bool i_lte_j_22105 = sle64(loopres_22086, s_end_22097);
                                bool y_22106 = i_p_m_t_s_leq_w_22103 && zzero_lte_i_22104;
                                bool y_22107 = zzero_leq_i_p_m_t_s_22102 && y_22106;
                                bool forwards_ok_22108 = i_lte_j_22105 && y_22107;
                                bool ok_or_empty_22109 = empty_slice_22099 || forwards_ok_22108;
                                bool index_certs_22110;
                                
                                if (!ok_or_empty_22109) {
                                    set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) loopres_22086, ":", (long long) s_end_22097, "] out of bounds for array of shape [", (long long) nR_17046, "].", "-> #0  ftSMJerr.fut:175:18-35\n   #1  ftSMJerr.fut:315:124-127\n   #2  ftSMJerr.fut:304:1-315:127\n"));
                                    err = FUTHARK_PROGRAM_ERROR;
                                    goto cleanup;
                                }
                                
                                bool cond_22113 = slt64((int64_t) 0, j_m_i_22098);
                                bool loop_not_taken_22114 = !cond_22113;
                                bool x_22115 = sle64((int64_t) 0, m_22100);
                                bool y_22116 = slt64(m_22100, j_m_i_22098);
                                bool bounds_check_22120 = x_22115 && y_22116;
                                bool protect_assert_disj_22121 = loop_not_taken_22114 || bounds_check_22120;
                                bool protect_assert_disj_22122 = loop_not_taken_22073 || protect_assert_disj_22121;
                                bool index_certs_22123;
                                
                                if (!protect_assert_disj_22122) {
                                    set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) m_22100, "] out of bounds for array of shape [", (long long) j_m_i_22098, "].", "-> #0  ftSMJerr.fut:37:34-42\n   #1  ftSMJerr.fut:315:124-127\n   #2  ftSMJerr.fut:304:1-315:127\n"));
                                    err = FUTHARK_PROGRAM_ERROR;
                                    goto cleanup;
                                }
                                
                                int64_t slice_22507 = tS_start_21436 + loopres_22086;
                                int64_t find_joinTuples_arg3_22112 = add64(join_chunks_arg3_21577, loopres_22086);
                                bool protect_cond_conj_22117 = loop_cond_22072 && cond_22113;
                                
                                if (protect_cond_conj_22117) {
                                    if (memblock_alloc_device(ctx, &mem_26318, (int64_t) 4, "mem_26318")) {
                                        err = 1;
                                        goto cleanup;
                                    }
                                    {
                                        err = gpu_kernel_inner_SMJ_intzigpuseq_27237(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, slice_22507, tS_mem_26244.mem, mem_26318.mem);
                                        if (err != FUTHARK_SUCCESS)
                                            goto cleanup;
                                    }
                                    if (memblock_set_device(ctx, &ext_mem_26319, &mem_26318, "mem_26318") != 0)
                                        return 1;
                                } else {
                                    if (memblock_alloc_device(ctx, &mem_26317, (int64_t) 4, "mem_26317")) {
                                        err = 1;
                                        goto cleanup;
                                    }
                                    if (futrts_builtinzhreplicate_i32(ctx, mem_26317, (int64_t) 1, 0) != 0) {
                                        err = 1;
                                        goto cleanup;
                                    }
                                    if (memblock_set_device(ctx, &ext_mem_26319, &mem_26317, "mem_26317") != 0)
                                        return 1;
                                }
                                if (protect_cond_conj_22117) {
                                    int64_t slice_23305 = tS_start_21436 + i_p_m_t_s_22101;
                                    
                                    if (memblock_alloc_device(ctx, &mem_26321, (int64_t) 4, "mem_26321")) {
                                        err = 1;
                                        goto cleanup;
                                    }
                                    {
                                        err = gpu_kernel_inner_SMJ_intzigpuseq_27243(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, slice_23305, tS_mem_26244.mem, mem_26321.mem);
                                        if (err != FUTHARK_SUCCESS)
                                            goto cleanup;
                                    }
                                    if (memblock_set_device(ctx, &ext_mem_26322, &mem_26321, "mem_26321") != 0)
                                        return 1;
                                } else {
                                    if (memblock_alloc_device(ctx, &mem_26320, (int64_t) 4, "mem_26320")) {
                                        err = 1;
                                        goto cleanup;
                                    }
                                    if (futrts_builtinzhreplicate_i32(ctx, mem_26320, (int64_t) 1, 0) != 0) {
                                        err = 1;
                                        goto cleanup;
                                    }
                                    if (memblock_set_device(ctx, &ext_mem_26322, &mem_26320, "mem_26320") != 0)
                                        return 1;
                                }
                                
                                int64_t bytes_26335 = (int64_t) 4 * j_m_i_22098;
                                int64_t ext_26482;
                                int64_t ext_26481;
                                int64_t ext_26480;
                                int64_t ext_26479;
                                bool defunc_0_find_joinTuples_res_22126;
                                int64_t defunc_0_find_joinTuples_res_22127;
                                bool loop_while_22130;
                                int64_t p_22131;
                                int64_t ctx_param_ext_26323;
                                int64_t ctx_param_ext_26324;
                                int64_t ctx_param_ext_26326;
                                int64_t ctx_param_ext_26327;
                                
                                if (memblock_set_device(ctx, &mem_param_26325, &mem_26310, "mem_26310") != 0)
                                    return 1;
                                if (memblock_set_device(ctx, &mem_param_26328, &mem_26308, "mem_26308") != 0)
                                    return 1;
                                ctx_param_ext_26323 = (int64_t) 0;
                                ctx_param_ext_26324 = (int64_t) 1;
                                ctx_param_ext_26326 = (int64_t) 0;
                                ctx_param_ext_26327 = (int64_t) 1;
                                loop_while_22130 = loop_cond_22072;
                                p_22131 = (int64_t) 0;
                                while (loop_while_22130) {
                                    int64_t start_22134 = mul64(extParallelism_17054, p_22131);
                                    int64_t min_arg1_22135 = sub64(dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046, start_22134);
                                    int64_t min_res_22136 = smin64(extParallelism_17054, min_arg1_22135);
                                    int64_t iter_R_22137 = add64(start_22134, min_res_22136);
                                    bool empty_slice_22138 = min_res_22136 == (int64_t) 0;
                                    int64_t m_22139 = sub64(min_res_22136, (int64_t) 1);
                                    int64_t i_p_m_t_s_22140 = add64(start_22134, m_22139);
                                    bool zzero_leq_i_p_m_t_s_22141 = sle64((int64_t) 0, i_p_m_t_s_22140);
                                    bool i_p_m_t_s_leq_w_22142 = slt64(i_p_m_t_s_22140, dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046);
                                    bool zzero_lte_i_22143 = sle64((int64_t) 0, start_22134);
                                    bool i_lte_j_22144 = sle64(start_22134, iter_R_22137);
                                    bool y_22145 = i_p_m_t_s_leq_w_22142 && zzero_lte_i_22143;
                                    bool y_22146 = zzero_leq_i_p_m_t_s_22141 && y_22145;
                                    bool forwards_ok_22147 = i_lte_j_22144 && y_22146;
                                    bool ok_or_empty_22148 = empty_slice_22138 || forwards_ok_22147;
                                    bool index_certs_22149;
                                    
                                    if (!ok_or_empty_22148) {
                                        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) start_22134, ":", (long long) iter_R_22137, "] out of bounds for array of shape [", (long long) dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046, "].", "-> #0  ftSMJerr.fut:32:20-49\n   #1  ftSMJerr.fut:315:124-127\n   #2  ftSMJerr.fut:304:1-315:127\n"));
                                        err = FUTHARK_PROGRAM_ERROR;
                                        goto cleanup;
                                    }
                                    
                                    bool y_22156 = slt64(m_22139, min_res_22136);
                                    bool x_22155 = sle64((int64_t) 0, m_22139);
                                    bool bounds_check_22157 = x_22155 && y_22156;
                                    bool index_certs_22158;
                                    
                                    if (!bounds_check_22157) {
                                        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) m_22139, "] out of bounds for array of shape [", (long long) min_res_22136, "].", "-> #0  ftSMJerr.fut:35:21-40\n   #1  ftSMJerr.fut:315:124-127\n   #2  ftSMJerr.fut:304:1-315:127\n"));
                                        err = FUTHARK_PROGRAM_ERROR;
                                        goto cleanup;
                                    }
                                    
                                    bool y_22152 = slt64((int64_t) 0, min_res_22136);
                                    bool index_certs_22153;
                                    
                                    if (!y_22152) {
                                        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) (int64_t) 0, "] out of bounds for array of shape [", (long long) min_res_22136, "].", "-> #0  ftSMJerr.fut:34:21-30\n   #1  ftSMJerr.fut:315:124-127\n   #2  ftSMJerr.fut:304:1-315:127\n"));
                                        err = FUTHARK_PROGRAM_ERROR;
                                        goto cleanup;
                                    }
                                    
                                    int64_t slice_22150 = loopres_f_res_f_res_22031 + start_22134;
                                    int64_t slice_22159 = loopres_f_res_f_res_22031 + i_p_m_t_s_22140;
                                    
                                    {
                                        err = gpu_kernel_inner_SMJ_intzigpuseq_27259(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, slice_22150, slice_22159, tR_mem_26243.mem, mem_26329.mem, mem_26330.mem);
                                        if (err != FUTHARK_SUCCESS)
                                            goto cleanup;
                                    }
                                    if (cond_22113) {
                                        if (memblock_set_device(ctx, &ext_mem_26331, &ext_mem_26322, "ext_mem_26322") != 0)
                                            return 1;
                                    } else if (memblock_set_device(ctx, &ext_mem_26331, &mem_26329, "mem_26329") != 0)
                                        return 1;
                                    if (cond_22113) {
                                        if (memblock_set_device(ctx, &ext_mem_26332, &ext_mem_26319, "ext_mem_26319") != 0)
                                            return 1;
                                    } else if (memblock_set_device(ctx, &ext_mem_26332, &mem_26330, "mem_26330") != 0)
                                        return 1;
                                    {
                                        err = gpu_kernel_inner_SMJ_intzigpuseq_27265(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, mem_26330.mem, ext_mem_26331.mem, mem_26333.mem);
                                        if (err != FUTHARK_SUCCESS)
                                            goto cleanup;
                                    }
                                    if (memblock_unref_device(ctx, &ext_mem_26331, "ext_mem_26331") != 0)
                                        return 1;
                                    
                                    bool read_res_27816;
                                    
                                    if ((err = gpu_scalar_from_device(ctx, &read_res_27816, mem_26333.mem, (int64_t) 0 * sizeof(bool), sizeof(bool))) != 0)
                                        goto cleanup;
                                    if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                                        err = 1;
                                        goto cleanup;
                                    }
                                    
                                    bool defunc_0_gt_res_22163 = read_res_27816;
                                    int64_t ext_26477;
                                    int64_t ext_26476;
                                    int64_t ext_26474;
                                    int64_t ext_26473;
                                    int64_t loopres_22164;
                                    
                                    if (defunc_0_gt_res_22163) {
                                        if (memblock_set_device(ctx, &ext_mem_26478, &mem_param_26325, "mem_param_26325") != 0)
                                            return 1;
                                        ext_26477 = ctx_param_ext_26323;
                                        ext_26476 = ctx_param_ext_26324;
                                        if (memblock_set_device(ctx, &ext_mem_26475, &mem_param_26328, "mem_param_26328") != 0)
                                            return 1;
                                        ext_26474 = ctx_param_ext_26326;
                                        ext_26473 = ctx_param_ext_26327;
                                        loopres_22164 = numIter_22071;
                                    } else {
                                        if (memblock_alloc_device(ctx, &mem_26334, (int64_t) 1, "mem_26334")) {
                                            err = 1;
                                            goto cleanup;
                                        }
                                        {
                                            err = gpu_kernel_inner_SMJ_intzigpuseq_27271(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, mem_26329.mem, ext_mem_26332.mem, mem_26334.mem);
                                            if (err != FUTHARK_SUCCESS)
                                                goto cleanup;
                                        }
                                        
                                        bool read_res_27817;
                                        
                                        if ((err = gpu_scalar_from_device(ctx, &read_res_27817, mem_26334.mem, (int64_t) 0 * sizeof(bool), sizeof(bool))) != 0)
                                            goto cleanup;
                                        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                                            err = 1;
                                            goto cleanup;
                                        }
                                        
                                        bool defunc_0_gt_res_22167 = read_res_27817;
                                        
                                        if (memblock_unref_device(ctx, &mem_26334, "mem_26334") != 0)
                                            return 1;
                                        
                                        int64_t ext_26471;
                                        
                                        if (defunc_0_gt_res_22167) {
                                            ext_26471 = ctx_param_ext_26323;
                                        } else {
                                            ext_26471 = (int64_t) 0;
                                        }
                                        
                                        int64_t ext_26470;
                                        
                                        if (defunc_0_gt_res_22167) {
                                            ext_26470 = ctx_param_ext_26324;
                                        } else {
                                            ext_26470 = (int64_t) 1;
                                        }
                                        
                                        int64_t ext_26468;
                                        
                                        if (defunc_0_gt_res_22167) {
                                            ext_26468 = ctx_param_ext_26326;
                                        } else {
                                            ext_26468 = (int64_t) 0;
                                        }
                                        
                                        int64_t ext_26467;
                                        
                                        if (defunc_0_gt_res_22167) {
                                            ext_26467 = ctx_param_ext_26327;
                                        } else {
                                            ext_26467 = (int64_t) 1;
                                        }
                                        
                                        int64_t loopres_f_res_22168;
                                        
                                        if (defunc_0_gt_res_22167) {
                                            int64_t tmp_23309 = add64((int64_t) 1, p_22131);
                                            
                                            if (memblock_set_device(ctx, &ext_mem_26472, &mem_param_26325, "mem_param_26325") != 0)
                                                return 1;
                                            if (memblock_set_device(ctx, &ext_mem_26469, &mem_param_26328, "mem_param_26328") != 0)
                                                return 1;
                                            loopres_f_res_22168 = tmp_23309;
                                        } else {
                                            if (memblock_alloc_device(ctx, &mem_26336, bytes_26335, "mem_26336")) {
                                                err = 1;
                                                goto cleanup;
                                            }
                                            if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_26336.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, tS_mem_26244.mem, slice_22507, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_22098})) != 0)
                                                goto cleanup;
                                            if (futrts_indicesWithIncrement_7095(ctx, &ext_mem_26338, mem_26336, j_m_i_22098, find_joinTuples_arg3_22112) != 0) {
                                                err = 1;
                                                goto cleanup;
                                            }
                                            if (memblock_unref_device(ctx, &mem_26336, "mem_26336") != 0)
                                                return 1;
                                            
                                            bool suff_outer_par_24275;
                                            
                                            suff_outer_par_24275 = *ctx->tuning_params.inner_SMJ_intzisuff_outer_par_1 <= min_res_22136;
                                            if (ctx->logging)
                                                fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "inner_SMJ_int.suff_outer_par_1", (long) min_res_22136, suff_outer_par_24275 ? "true" : "false");
                                            
                                            int64_t tile_sizze_25742;
                                            
                                            tile_sizze_25742 = *ctx->tuning_params.inner_SMJ_intzitile_sizze_25741;
                                            
                                            int64_t tile_sizze_25387;
                                            
                                            tile_sizze_25387 = *ctx->tuning_params.inner_SMJ_intzitile_sizze_25386;
                                            
                                            int64_t num_whole_tiles_25758 = squot_safe64(j_m_i_22098, tile_sizze_25742);
                                            int64_t residual_input_25982 = srem_safe64(j_m_i_22098, tile_sizze_25742);
                                            bool cond_25983 = residual_input_25982 == (int64_t) 0;
                                            int64_t binop_x_25999 = tile_sizze_25742 * num_whole_tiles_25758;
                                            int64_t bytes_26396 = (int64_t) 8 * min_res_22136;
                                            int64_t bytes_26359 = (int64_t) 8 * tile_sizze_25742;
                                            int64_t bytes_26361 = (int64_t) 4 * tile_sizze_25742;
                                            int64_t num_whole_tiles_25403 = squot_safe64(j_m_i_22098, tile_sizze_25387);
                                            int64_t residual_input_25627 = srem_safe64(j_m_i_22098, tile_sizze_25387);
                                            bool cond_25628 = residual_input_25627 == (int64_t) 0;
                                            int64_t binop_x_25644 = tile_sizze_25387 * num_whole_tiles_25403;
                                            int64_t bytes_26420 = (int64_t) 8 * tile_sizze_25387;
                                            int64_t bytes_26422 = (int64_t) 4 * tile_sizze_25387;
                                            int64_t shared_memory_capacity_27329;
                                            
                                            shared_memory_capacity_27329 = ctx->max_shared_memory;
                                            if (suff_outer_par_24275 && sle64(sdiv_up64(bytes_26420, (int64_t) 8) * (int64_t) 8 + sdiv_up64(bytes_26422, (int64_t) 8) * (int64_t) 8 + sdiv_up64(bytes_26420, (int64_t) 8) * (int64_t) 8, shared_memory_capacity_27329)) {
                                                int64_t ldim_25388 = sdiv_up64(min_res_22136, tile_sizze_25387);
                                                
                                                if (memblock_alloc_device(ctx, &mem_26458, bytes_26396, "mem_26458")) {
                                                    err = 1;
                                                    goto cleanup;
                                                }
                                                if (memblock_alloc_device(ctx, &mem_26460, bytes_26396, "mem_26460")) {
                                                    err = 1;
                                                    goto cleanup;
                                                }
                                                if (ctx->debugging)
                                                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                                                
                                                int32_t num_chunks_27277 = sext_i64_i32(sdiv_up64(tile_sizze_25387, tile_sizze_25387));
                                                int32_t virt_num_tblocks_27278 = sext_i64_i32(ldim_25388);
                                                
                                                {
                                                    err = gpu_kernel_inner_SMJ_intzisegmap_intrablock_25385(ctx, ldim_25388, 1, 1, *ctx->tuning_params.inner_SMJ_intzitile_sizze_25386, 1, 1, bytes_26420 + srem64((int64_t) 8 - srem64(bytes_26420, (int64_t) 8), (int64_t) 8) + (bytes_26422 + srem64((int64_t) 8 - srem64(bytes_26422, (int64_t) 8), (int64_t) 8)) + (bytes_26420 + srem64((int64_t) 8 - srem64(bytes_26420, (int64_t) 8), (int64_t) 8)), j_m_i_22098, min_res_22136, slice_22150, slice_22507, ldim_25388, num_whole_tiles_25403, residual_input_25627, cond_25628, binop_x_25644, tR_mem_26243.mem, tS_mem_26244.mem, ext_mem_26338.mem, mem_26458.mem, mem_26460.mem);
                                                    if (err != FUTHARK_SUCCESS)
                                                        goto cleanup;
                                                }
                                                if (ctx->debugging)
                                                    fprintf(ctx->log, "%s\n", "");
                                                if (memblock_set_device(ctx, &ext_mem_26462, &mem_26458, "mem_26458") != 0)
                                                    return 1;
                                                if (memblock_set_device(ctx, &ext_mem_26461, &mem_26460, "mem_26460") != 0)
                                                    return 1;
                                            } else {
                                                int64_t ldim_25743 = sdiv_up64(min_res_22136, tile_sizze_25742);
                                                
                                                if (memblock_alloc_device(ctx, &mem_26397, bytes_26396, "mem_26397")) {
                                                    err = 1;
                                                    goto cleanup;
                                                }
                                                if (memblock_alloc_device(ctx, &mem_26399, bytes_26396, "mem_26399")) {
                                                    err = 1;
                                                    goto cleanup;
                                                }
                                                if (ctx->debugging)
                                                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                                                
                                                int32_t num_chunks_27303 = sext_i64_i32(sdiv_up64(tile_sizze_25742, tile_sizze_25742));
                                                int32_t virt_num_tblocks_27304 = sext_i64_i32(ldim_25743);
                                                
                                                {
                                                    err = gpu_kernel_inner_SMJ_intzisegmap_intrablock_25740(ctx, ldim_25743, 1, 1, *ctx->tuning_params.inner_SMJ_intzitile_sizze_25741, 1, 1, bytes_26359 + srem64((int64_t) 8 - srem64(bytes_26359, (int64_t) 8), (int64_t) 8) + (bytes_26361 + srem64((int64_t) 8 - srem64(bytes_26361, (int64_t) 8), (int64_t) 8)) + (bytes_26359 + srem64((int64_t) 8 - srem64(bytes_26359, (int64_t) 8), (int64_t) 8)), j_m_i_22098, min_res_22136, slice_22150, slice_22507, ldim_25743, num_whole_tiles_25758, residual_input_25982, cond_25983, binop_x_25999, tR_mem_26243.mem, tS_mem_26244.mem, ext_mem_26338.mem, mem_26397.mem, mem_26399.mem);
                                                    if (err != FUTHARK_SUCCESS)
                                                        goto cleanup;
                                                }
                                                if (ctx->debugging)
                                                    fprintf(ctx->log, "%s\n", "");
                                                if (memblock_set_device(ctx, &ext_mem_26462, &mem_26397, "mem_26397") != 0)
                                                    return 1;
                                                if (memblock_set_device(ctx, &ext_mem_26461, &mem_26399, "mem_26399") != 0)
                                                    return 1;
                                            }
                                            if (memblock_unref_device(ctx, &ext_mem_26338, "ext_mem_26338") != 0)
                                                return 1;
                                            if (memblock_alloc_device(ctx, &mem_26464, bytes_26307, "mem_26464")) {
                                                err = 1;
                                                goto cleanup;
                                            }
                                            if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_26464.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_26328.mem, ctx_param_ext_26326, (int64_t []) {ctx_param_ext_26327}, (int64_t []) {dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046})) != 0)
                                                goto cleanup;
                                            if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_26464.mem, start_22134, (int64_t []) {(int64_t) 1}, ext_mem_26462.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {min_res_22136})) != 0)
                                                goto cleanup;
                                            if (memblock_unref_device(ctx, &ext_mem_26462, "ext_mem_26462") != 0)
                                                return 1;
                                            if (memblock_alloc_device(ctx, &mem_26466, bytes_26307, "mem_26466")) {
                                                err = 1;
                                                goto cleanup;
                                            }
                                            if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_26466.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_26325.mem, ctx_param_ext_26323, (int64_t []) {ctx_param_ext_26324}, (int64_t []) {dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046})) != 0)
                                                goto cleanup;
                                            if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_26466.mem, start_22134, (int64_t []) {(int64_t) 1}, ext_mem_26461.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {min_res_22136})) != 0)
                                                goto cleanup;
                                            if (memblock_unref_device(ctx, &ext_mem_26461, "ext_mem_26461") != 0)
                                                return 1;
                                            
                                            int64_t tmp_22215 = add64((int64_t) 1, p_22131);
                                            
                                            if (memblock_set_device(ctx, &ext_mem_26472, &mem_26466, "mem_26466") != 0)
                                                return 1;
                                            if (memblock_set_device(ctx, &ext_mem_26469, &mem_26464, "mem_26464") != 0)
                                                return 1;
                                            loopres_f_res_22168 = tmp_22215;
                                        }
                                        if (memblock_set_device(ctx, &ext_mem_26478, &ext_mem_26472, "ext_mem_26472") != 0)
                                            return 1;
                                        ext_26477 = ext_26471;
                                        ext_26476 = ext_26470;
                                        if (memblock_set_device(ctx, &ext_mem_26475, &ext_mem_26469, "ext_mem_26469") != 0)
                                            return 1;
                                        ext_26474 = ext_26468;
                                        ext_26473 = ext_26467;
                                        loopres_22164 = loopres_f_res_22168;
                                    }
                                    if (memblock_unref_device(ctx, &ext_mem_26332, "ext_mem_26332") != 0)
                                        return 1;
                                    
                                    bool loop_cond_22216 = slt64(loopres_22164, numIter_22071);
                                    
                                    if (memblock_set_device(ctx, &mem_param_tmp_27249, &ext_mem_26478, "ext_mem_26478") != 0)
                                        return 1;
                                    if (memblock_set_device(ctx, &mem_param_tmp_27250, &ext_mem_26475, "ext_mem_26475") != 0)
                                        return 1;
                                    
                                    int64_t ctx_param_ext_tmp_27251 = ext_26477;
                                    int64_t ctx_param_ext_tmp_27252 = ext_26476;
                                    int64_t ctx_param_ext_tmp_27253 = ext_26474;
                                    int64_t ctx_param_ext_tmp_27254 = ext_26473;
                                    bool loop_while_tmp_27255 = loop_cond_22216;
                                    int64_t p_tmp_27256 = loopres_22164;
                                    
                                    if (memblock_set_device(ctx, &mem_param_26325, &mem_param_tmp_27249, "mem_param_tmp_27249") != 0)
                                        return 1;
                                    if (memblock_set_device(ctx, &mem_param_26328, &mem_param_tmp_27250, "mem_param_tmp_27250") != 0)
                                        return 1;
                                    ctx_param_ext_26323 = ctx_param_ext_tmp_27251;
                                    ctx_param_ext_26324 = ctx_param_ext_tmp_27252;
                                    ctx_param_ext_26326 = ctx_param_ext_tmp_27253;
                                    ctx_param_ext_26327 = ctx_param_ext_tmp_27254;
                                    loop_while_22130 = loop_while_tmp_27255;
                                    p_22131 = p_tmp_27256;
                                }
                                if (memblock_set_device(ctx, &ext_mem_26484, &mem_param_26325, "mem_param_26325") != 0)
                                    return 1;
                                if (memblock_set_device(ctx, &ext_mem_26483, &mem_param_26328, "mem_param_26328") != 0)
                                    return 1;
                                ext_26482 = ctx_param_ext_26323;
                                ext_26481 = ctx_param_ext_26324;
                                ext_26480 = ctx_param_ext_26326;
                                ext_26479 = ctx_param_ext_26327;
                                defunc_0_find_joinTuples_res_22126 = loop_while_22130;
                                defunc_0_find_joinTuples_res_22127 = p_22131;
                                if (memblock_unref_device(ctx, &ext_mem_26319, "ext_mem_26319") != 0)
                                    return 1;
                                if (memblock_unref_device(ctx, &ext_mem_26322, "ext_mem_26322") != 0)
                                    return 1;
                                if (memblock_alloc_device(ctx, &mem_26487, bytes_26307, "mem_26487")) {
                                    err = 1;
                                    goto cleanup;
                                }
                                if (ctx->debugging)
                                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                                
                                int32_t virt_num_tblocks_27330 = sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046, segmap_tblock_sizze_24463));
                                
                                {
                                    err = gpu_kernel_inner_SMJ_intzisegmap_24467(ctx, segmap_usable_groups_24464, 1, 1, *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24453, 1, 1, (int64_t) 0, dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046, ext_26479, ext_26480, mem_param_26316.mem, ext_mem_26483.mem, mem_26487.mem);
                                    if (err != FUTHARK_SUCCESS)
                                        goto cleanup;
                                }
                                if (ctx->debugging)
                                    fprintf(ctx->log, "%s\n", "");
                                if (memblock_unref_device(ctx, &ext_mem_26483, "ext_mem_26483") != 0)
                                    return 1;
                                if (memblock_alloc_device(ctx, &mem_26490, bytes_26307, "mem_26490")) {
                                    err = 1;
                                    goto cleanup;
                                }
                                if (ctx->debugging)
                                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                                
                                int32_t virt_num_tblocks_27339 = sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046, segmap_tblock_sizze_24484));
                                
                                {
                                    err = gpu_kernel_inner_SMJ_intzisegmap_24488(ctx, segmap_usable_groups_24485, 1, 1, *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24475, 1, 1, (int64_t) 0, dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046, ext_26481, ext_26482, mem_param_26313.mem, ext_mem_26484.mem, mem_26490.mem);
                                    if (err != FUTHARK_SUCCESS)
                                        goto cleanup;
                                }
                                if (ctx->debugging)
                                    fprintf(ctx->log, "%s\n", "");
                                if (memblock_unref_device(ctx, &ext_mem_26484, "ext_mem_26484") != 0)
                                    return 1;
                                
                                bool loop_cond_22226 = sle64(zeze_lhs_22087, min_res_22022);
                                
                                if (memblock_set_device(ctx, &mem_param_tmp_27231, &mem_26490, "mem_26490") != 0)
                                    return 1;
                                if (memblock_set_device(ctx, &mem_param_tmp_27232, &mem_26487, "mem_26487") != 0)
                                    return 1;
                                
                                bool loop_while_tmp_27233 = loop_cond_22226;
                                int64_t dp_tmp_27234 = zeze_lhs_22087;
                                
                                if (memblock_set_device(ctx, &mem_param_26313, &mem_param_tmp_27231, "mem_param_tmp_27231") != 0)
                                    return 1;
                                if (memblock_set_device(ctx, &mem_param_26316, &mem_param_tmp_27232, "mem_param_tmp_27232") != 0)
                                    return 1;
                                loop_while_22078 = loop_while_tmp_27233;
                                dp_22079 = dp_tmp_27234;
                            }
                            if (memblock_set_device(ctx, &ext_mem_26496, &mem_param_26313, "mem_param_26313") != 0)
                                return 1;
                            if (memblock_set_device(ctx, &ext_mem_26495, &mem_param_26316, "mem_param_26316") != 0)
                                return 1;
                            loopres_f_res_f_res_22074 = loop_while_22078;
                            loopres_f_res_f_res_22075 = dp_22079;
                            if (memblock_unref_device(ctx, &mem_26308, "mem_26308") != 0)
                                return 1;
                            if (memblock_unref_device(ctx, &mem_26310, "mem_26310") != 0)
                                return 1;
                            if (memblock_unref_device(ctx, &mem_26329, "mem_26329") != 0)
                                return 1;
                            if (memblock_unref_device(ctx, &mem_26330, "mem_26330") != 0)
                                return 1;
                            if (memblock_unref_device(ctx, &mem_26333, "mem_26333") != 0)
                                return 1;
                            
                            int64_t segmap_tblock_sizze_24505;
                            
                            segmap_tblock_sizze_24505 = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24495;
                            
                            int64_t segmap_usable_groups_24506 = sdiv_up64(dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046, segmap_tblock_sizze_24505);
                            
                            if (memblock_alloc_device(ctx, &mem_26499, bytes_26307, "mem_26499")) {
                                err = 1;
                                goto cleanup;
                            }
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s\n", "\n# SegMap");
                            
                            int32_t virt_num_tblocks_27348 = sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046, segmap_tblock_sizze_24505));
                            
                            {
                                err = gpu_kernel_inner_SMJ_intzisegmap_24509(ctx, segmap_usable_groups_24506, 1, 1, *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24495, 1, 1, (int64_t) 0, loopres_f_res_f_res_22031, dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046, ctx_param_ext_26304, ctx_param_ext_26305, mem_param_26306.mem, ext_mem_26495.mem, mem_26499.mem);
                                if (err != FUTHARK_SUCCESS)
                                    goto cleanup;
                            }
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s\n", "");
                            if (memblock_unref_device(ctx, &ext_mem_26495, "ext_mem_26495") != 0)
                                return 1;
                            
                            int64_t segmap_tblock_sizze_24526;
                            
                            segmap_tblock_sizze_24526 = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24517;
                            
                            int64_t segmap_usable_groups_24527 = sdiv_up64(dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046, segmap_tblock_sizze_24526);
                            
                            if (memblock_alloc_device(ctx, &mem_26502, bytes_26307, "mem_26502")) {
                                err = 1;
                                goto cleanup;
                            }
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s\n", "\n# SegMap");
                            
                            int32_t virt_num_tblocks_27357 = sext_i64_i32(sdiv_up64(dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046, segmap_tblock_sizze_24526));
                            
                            {
                                err = gpu_kernel_inner_SMJ_intzisegmap_24530(ctx, segmap_usable_groups_24527, 1, 1, *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24517, 1, 1, (int64_t) 0, loopres_f_res_f_res_22031, dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046, ctx_param_ext_26301, ctx_param_ext_26302, mem_param_26303.mem, ext_mem_26496.mem, mem_26502.mem);
                                if (err != FUTHARK_SUCCESS)
                                    goto cleanup;
                            }
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s\n", "");
                            if (memblock_unref_device(ctx, &ext_mem_26496, "ext_mem_26496") != 0)
                                return 1;
                            if (memblock_alloc_device(ctx, &mem_26504, bytes_26246, "mem_26504")) {
                                err = 1;
                                goto cleanup;
                            }
                            if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_26504.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_26306.mem, ctx_param_ext_26304, (int64_t []) {ctx_param_ext_26305}, (int64_t []) {nR_17046})) != 0)
                                goto cleanup;
                            if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_26504.mem, loopres_f_res_f_res_22031, (int64_t []) {(int64_t) 1}, mem_26499.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046})) != 0)
                                goto cleanup;
                            if (memblock_unref_device(ctx, &mem_26499, "mem_26499") != 0)
                                return 1;
                            if (memblock_alloc_device(ctx, &mem_26506, bytes_26246, "mem_26506")) {
                                err = 1;
                                goto cleanup;
                            }
                            if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_26506.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_26303.mem, ctx_param_ext_26301, (int64_t []) {ctx_param_ext_26302}, (int64_t []) {nR_17046})) != 0)
                                goto cleanup;
                            if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_26506.mem, loopres_f_res_f_res_22031, (int64_t []) {(int64_t) 1}, mem_26502.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {dzlz7bUZLzmZRz20Ur_endz20Ur_startz7dUzg_22046})) != 0)
                                goto cleanup;
                            if (memblock_unref_device(ctx, &mem_26502, "mem_26502") != 0)
                                return 1;
                            if (memblock_set_device(ctx, &ext_mem_26512, &mem_26506, "mem_26506") != 0)
                                return 1;
                            if (memblock_set_device(ctx, &ext_mem_26509, &mem_26504, "mem_26504") != 0)
                                return 1;
                        }
                        if (memblock_set_device(ctx, &ext_mem_26518, &ext_mem_26512, "ext_mem_26512") != 0)
                            return 1;
                        if (memblock_set_device(ctx, &ext_mem_26515, &ext_mem_26509, "ext_mem_26509") != 0)
                            return 1;
                    }
                    
                    bool loop_cond_22242 = slt64(loopres_22024, dzlz7bUZLztZRz20UpartitionsPerWindowz20UnumberOfWindowsz7dUzg_21578);
                    
                    if (memblock_set_device(ctx, &mem_param_tmp_27221, &ext_mem_26518, "ext_mem_26518") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &mem_param_tmp_27222, &ext_mem_26515, "ext_mem_26515") != 0)
                        return 1;
                    
                    int64_t ctx_param_ext_tmp_27223 = ext_26517;
                    int64_t ctx_param_ext_tmp_27224 = ext_26516;
                    int64_t ctx_param_ext_tmp_27225 = ext_26514;
                    int64_t ctx_param_ext_tmp_27226 = ext_26513;
                    bool loop_while_tmp_27227 = loop_cond_22242;
                    int64_t p_tmp_27228 = loopres_22024;
                    
                    if (memblock_set_device(ctx, &mem_param_26303, &mem_param_tmp_27221, "mem_param_tmp_27221") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &mem_param_26306, &mem_param_tmp_27222, "mem_param_tmp_27222") != 0)
                        return 1;
                    ctx_param_ext_26301 = ctx_param_ext_tmp_27223;
                    ctx_param_ext_26302 = ctx_param_ext_tmp_27224;
                    ctx_param_ext_26304 = ctx_param_ext_tmp_27225;
                    ctx_param_ext_26305 = ctx_param_ext_tmp_27226;
                    loop_while_22012 = loop_while_tmp_27227;
                    p_22013 = p_tmp_27228;
                }
                if (memblock_set_device(ctx, &ext_mem_26524, &mem_param_26303, "mem_param_26303") != 0)
                    return 1;
                if (memblock_set_device(ctx, &ext_mem_26523, &mem_param_26306, "mem_param_26306") != 0)
                    return 1;
                ext_26522 = ctx_param_ext_26301;
                ext_26521 = ctx_param_ext_26302;
                ext_26520 = ctx_param_ext_26304;
                ext_26519 = ctx_param_ext_26305;
                defunc_0_join_chunks_res_22008 = loop_while_22012;
                defunc_0_join_chunks_res_22009 = p_22013;
                if (memblock_unref_device(ctx, &mem_26262, "mem_26262") != 0)
                    return 1;
                if (memblock_unref_device(ctx, &mem_26264, "mem_26264") != 0)
                    return 1;
                if (memblock_unref_device(ctx, &mem_26298, "mem_26298") != 0)
                    return 1;
                if (memblock_unref_device(ctx, &mem_26300, "mem_26300") != 0)
                    return 1;
                if (memblock_set_device(ctx, &ext_mem_26695, &ext_mem_26524, "ext_mem_26524") != 0)
                    return 1;
                ext_26694 = ext_26522;
                ext_26693 = ext_26521;
                if (memblock_set_device(ctx, &ext_mem_26692, &ext_mem_26523, "ext_mem_26523") != 0)
                    return 1;
                ext_26691 = ext_26520;
                ext_26690 = ext_26519;
            }
            
            int64_t segmap_tblock_sizze_24547;
            
            segmap_tblock_sizze_24547 = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24537;
            
            int64_t segmap_usable_groups_24548 = sdiv_up64(nR_17046, segmap_tblock_sizze_24547);
            
            if (memblock_alloc_device(ctx, &mem_26698, bytes_26246, "mem_26698")) {
                err = 1;
                goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegMap");
            
            int32_t virt_num_tblocks_27366 = sext_i64_i32(sdiv_up64(nR_17046, segmap_tblock_sizze_24547));
            
            {
                err = gpu_kernel_inner_SMJ_intzisegmap_24551(ctx, segmap_usable_groups_24548, 1, 1, *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24537, 1, 1, (int64_t) 0, nR_17046, ext_26690, ext_26691, mem_param_26258.mem, ext_mem_26692.mem, mem_26698.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
            if (memblock_unref_device(ctx, &ext_mem_26692, "ext_mem_26692") != 0)
                return 1;
            
            int64_t segmap_tblock_sizze_24568;
            
            segmap_tblock_sizze_24568 = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24559;
            
            int64_t segmap_usable_groups_24569 = sdiv_up64(nR_17046, segmap_tblock_sizze_24568);
            
            if (memblock_alloc_device(ctx, &mem_26701, bytes_26246, "mem_26701")) {
                err = 1;
                goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegMap");
            
            int32_t virt_num_tblocks_27375 = sext_i64_i32(sdiv_up64(nR_17046, segmap_tblock_sizze_24568));
            
            {
                err = gpu_kernel_inner_SMJ_intzisegmap_24572(ctx, segmap_usable_groups_24569, 1, 1, *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24559, 1, 1, (int64_t) 0, nR_17046, ext_26693, ext_26694, mem_param_26255.mem, ext_mem_26695.mem, mem_26701.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
            if (memblock_unref_device(ctx, &ext_mem_26695, "ext_mem_26695") != 0)
                return 1;
            if (memblock_alloc_device(ctx, &mem_26702, (int64_t) 1, "mem_26702")) {
                err = 1;
                goto cleanup;
            }
            {
                err = gpu_kernel_inner_SMJ_intzigpuseq_27384(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, gt_rhs_21419, i_p_m_t_s_21442, tR_mem_26243.mem, tS_mem_26244.mem, mem_26702.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            
            bool read_res_27818;
            
            if ((err = gpu_scalar_from_device(ctx, &read_res_27818, mem_26702.mem, (int64_t) 0 * sizeof(bool), sizeof(bool))) != 0)
                goto cleanup;
            if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                err = 1;
                goto cleanup;
            }
            
            bool defunc_0_leq_res_22259 = read_res_27818;
            
            if (memblock_unref_device(ctx, &mem_26702, "mem_26702") != 0)
                return 1;
            
            int64_t nextIter_22260;
            
            if (defunc_0_leq_res_22259) {
                int64_t nextIter_t_res_23324 = add64((int64_t) 1, p_21433);
                
                nextIter_22260 = nextIter_t_res_23324;
            } else {
                nextIter_22260 = numIter_21413;
            }
            if (memblock_set_device(ctx, &ext_mem_26708, &mem_26701, "mem_26701") != 0)
                return 1;
            if (memblock_set_device(ctx, &ext_mem_26705, &mem_26698, "mem_26698") != 0)
                return 1;
            loopres_21457 = nextIter_22260;
        }
        
        bool loop_cond_22262 = slt64(loopres_21457, numIter_21413);
        
        if (memblock_set_device(ctx, &mem_param_tmp_27064, &ext_mem_26708, "ext_mem_26708") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_27065, &ext_mem_26705, "ext_mem_26705") != 0)
            return 1;
        
        bool loop_while_tmp_27066 = loop_cond_22262;
        int64_t p_tmp_27067 = loopres_21457;
        
        if (memblock_set_device(ctx, &mem_param_26255, &mem_param_tmp_27064, "mem_param_tmp_27064") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_26258, &mem_param_tmp_27065, "mem_param_tmp_27065") != 0)
            return 1;
        loop_while_21432 = loop_while_tmp_27066;
        p_21433 = p_tmp_27067;
    }
    if (memblock_set_device(ctx, &ext_mem_26714, &mem_param_26255, "mem_param_26255") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_26713, &mem_param_26258, "mem_param_26258") != 0)
        return 1;
    defunc_0_mergeJoin_res_21428 = loop_while_21432;
    defunc_0_mergeJoin_res_21429 = p_21433;
    if (memblock_unref_device(ctx, &mem_26247, "mem_26247") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_26249, "mem_26249") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_26252, "ext_mem_26252") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_26259, "mem_26259") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_26260, "mem_26260") != 0)
        return 1;
    
    int64_t segscan_tblock_sizze_24578;
    
    segscan_tblock_sizze_24578 = *ctx->tuning_params.inner_SMJ_intzisegscan_tblock_sizze_24577;
    
    int64_t num_tblocks_24580;
    int64_t max_num_tblocks_27390;
    
    max_num_tblocks_27390 = *ctx->tuning_params.inner_SMJ_intzisegscan_num_tblocks_24579;
    num_tblocks_24580 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nR_17046, segscan_tblock_sizze_24578), max_num_tblocks_27390)));
    if (memblock_alloc_device(ctx, &mem_26717, bytes_26246, "mem_26717")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_26719, bytes_26246, "mem_26719")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, nR_17046)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_27391;
        
        shared_memory_27391 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_27392;
        
        thread_block_sizze_27392 = ctx->max_thread_block_size;
        
        int64_t registers_27393;
        
        registers_27393 = ctx->max_registers;
        
        int64_t thread_block_sizze_27394;
        
        thread_block_sizze_27394 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_27395 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_27391, thread_block_sizze_27392), (int64_t) 8), squot64(squot64(registers_27393, thread_block_sizze_27394) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
        int64_t num_virt_blocks_27396 = sdiv_up64(nR_17046, segscan_tblock_sizze_24578 * chunk_sizze_27395);
        int64_t num_virt_threads_27397 = num_virt_blocks_27396 * segscan_tblock_sizze_24578;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_27395, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_27398, num_virt_blocks_27396, "status_flags_mem_27398")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_27398, num_virt_blocks_27396, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_27420, (int64_t) 8 * num_virt_blocks_27396, "aggregates_mem_27420")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_27422, (int64_t) 8 * num_virt_blocks_27396, "incprefixes_mem_27422")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_intzisegscan_24583(ctx, num_tblocks_24580, 1, 1, *ctx->tuning_params.inner_SMJ_intzisegscan_tblock_sizze_24577, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_24578), chunk_sizze_27395 * segscan_tblock_sizze_24578 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_24578), chunk_sizze_27395 * segscan_tblock_sizze_24578 * (int64_t) 8), (int64_t) 8), (int64_t) 8), nR_17046, num_tblocks_24580, num_virt_blocks_27396, num_virt_threads_27397, ext_mem_26714.mem, mem_26717.mem, mem_26719.mem, status_flags_mem_27398.mem, aggregates_mem_27420.mem, incprefixes_mem_27422.mem, global_dynid_mem_27424.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    
    bool protect_assert_disj_22278 = zzero_21410 || bounds_check_21422;
    bool index_certs_22279;
    
    if (!protect_assert_disj_22278) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) gt_rhs_21419, "] out of bounds for array of shape [", (long long) nR_17046, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJerr.fut:299:13-300:79\n   #3  ftSMJerr.fut:315:124-127\n   #4  ftSMJerr.fut:304:1-315:127\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t m_f_res_22280;
    
    if (nonzzero_21411) {
        int64_t read_res_27819;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_27819, mem_26717.mem, gt_rhs_21419 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_23327 = read_res_27819;
        
        m_f_res_22280 = x_23327;
    } else {
        m_f_res_22280 = (int64_t) 0;
    }
    
    int64_t m_22282;
    
    if (zzero_21410) {
        m_22282 = (int64_t) 0;
    } else {
        m_22282 = m_f_res_22280;
    }
    
    int64_t m_22292 = sub64(m_22282, (int64_t) 1);
    bool i_p_m_t_s_leq_w_22294 = slt64(m_22292, nR_17046);
    bool zzero_leq_i_p_m_t_s_22293 = sle64((int64_t) 0, m_22292);
    bool y_22296 = zzero_leq_i_p_m_t_s_22293 && i_p_m_t_s_leq_w_22294;
    bool i_lte_j_22295 = sle64((int64_t) 0, m_22282);
    bool forwards_ok_22297 = i_lte_j_22295 && y_22296;
    bool eq_x_zz_22289 = (int64_t) 0 == m_f_res_22280;
    bool p_and_eq_x_y_22290 = nonzzero_21411 && eq_x_zz_22289;
    bool empty_slice_22291 = zzero_21410 || p_and_eq_x_y_22290;
    bool ok_or_empty_22298 = empty_slice_22291 || forwards_ok_22297;
    bool index_certs_22299;
    
    if (!ok_or_empty_22298) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_22282, "] out of bounds for array of shape [", (long long) nR_17046, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJerr.fut:299:13-300:79\n   #3  ftSMJerr.fut:315:124-127\n   #4  ftSMJerr.fut:304:1-315:127\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_26720 = (int64_t) 8 * m_22282;
    
    if (memblock_alloc_device(ctx, &mem_26721, bytes_26720, "mem_26721")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_26721.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_26714.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_22282})) != 0)
        goto cleanup;
    if (memblock_alloc_device(ctx, &mem_26723, bytes_26720, "mem_26723")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_26723.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_26713.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_22282})) != 0)
        goto cleanup;
    if (memblock_alloc_device(ctx, &mem_26725, bytes_26720, "mem_26725")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_26725.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_26245.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_22282})) != 0)
        goto cleanup;
    
    int64_t bytes_26726 = (int64_t) 4 * m_22282;
    
    if (memblock_alloc_device(ctx, &mem_26727, bytes_26726, "mem_26727")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_26727.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, tR_mem_26243.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_22282})) != 0)
        goto cleanup;
    
    int64_t segmap_tblock_sizze_24588;
    
    segmap_tblock_sizze_24588 = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24587;
    
    int64_t num_tblocks_24590;
    int64_t max_num_tblocks_27513;
    
    max_num_tblocks_27513 = *ctx->tuning_params.inner_SMJ_intzisegmap_num_tblocks_24589;
    num_tblocks_24590 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nR_17046, segmap_tblock_sizze_24588), max_num_tblocks_27513)));
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_27514 = sext_i64_i32(sdiv_up64(nR_17046, segmap_tblock_sizze_24588));
    
    {
        err = gpu_kernel_inner_SMJ_intzisegmap_24585(ctx, num_tblocks_24590, 1, 1, *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24587, 1, 1, (int64_t) 0, nR_17046, m_22282, num_tblocks_24590, virt_num_tblocks_27514, tR_mem_26243.mem, ext_mem_26245.mem, ext_mem_26713.mem, ext_mem_26714.mem, mem_26717.mem, mem_26719.mem, mem_26721.mem, mem_26723.mem, mem_26725.mem, mem_26727.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &ext_mem_26245, "ext_mem_26245") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_26713, "ext_mem_26713") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_26714, "ext_mem_26714") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_26717, "mem_26717") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_26719, "mem_26719") != 0)
        return 1;
    
    int64_t segscan_tblock_sizze_24594;
    
    segscan_tblock_sizze_24594 = *ctx->tuning_params.inner_SMJ_intzisegscan_tblock_sizze_24593;
    
    int64_t num_tblocks_24596;
    int64_t max_num_tblocks_27527;
    
    max_num_tblocks_27527 = *ctx->tuning_params.inner_SMJ_intzisegscan_num_tblocks_24595;
    num_tblocks_24596 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_22282, segscan_tblock_sizze_24594), max_num_tblocks_27527)));
    if (memblock_alloc_device(ctx, &mem_26731, bytes_26720, "mem_26731")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_26733, bytes_26720, "mem_26733")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_26735, bytes_26720, "mem_26735")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, m_22282)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_27528;
        
        shared_memory_27528 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_27529;
        
        thread_block_sizze_27529 = ctx->max_thread_block_size;
        
        int64_t registers_27530;
        
        registers_27530 = ctx->max_registers;
        
        int64_t thread_block_sizze_27531;
        
        thread_block_sizze_27531 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_27532 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_27528, thread_block_sizze_27529), (int64_t) 8), squot64(squot64(registers_27530, thread_block_sizze_27531) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
        int64_t num_virt_blocks_27533 = sdiv_up64(m_22282, segscan_tblock_sizze_24594 * chunk_sizze_27532);
        int64_t num_virt_threads_27534 = num_virt_blocks_27533 * segscan_tblock_sizze_24594;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_27532, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_27535, num_virt_blocks_27533, "status_flags_mem_27535")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_27535, num_virt_blocks_27533, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_27537, (int64_t) 8 * num_virt_blocks_27533, "aggregates_mem_27537")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_27539, (int64_t) 8 * num_virt_blocks_27533, "incprefixes_mem_27539")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_27541, (int64_t) 8 * num_virt_blocks_27533, "aggregates_mem_27541")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_27543, (int64_t) 8 * num_virt_blocks_27533, "incprefixes_mem_27543")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_intzisegscan_24599(ctx, num_tblocks_24596, 1, 1, *ctx->tuning_params.inner_SMJ_intzisegscan_tblock_sizze_24593, 1, 1, smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_24594, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_24594), smax64(chunk_sizze_27532 * segscan_tblock_sizze_24594 * (int64_t) 8, chunk_sizze_27532 * segscan_tblock_sizze_24594 * (int64_t) 8)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_24594, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_24594), smax64(chunk_sizze_27532 * segscan_tblock_sizze_24594 * (int64_t) 8, chunk_sizze_27532 * segscan_tblock_sizze_24594 * (int64_t) 8)), (int64_t) 8), (int64_t) 8), m_22282, num_tblocks_24596, num_virt_blocks_27533, num_virt_threads_27534, mem_26721.mem, mem_26731.mem, mem_26733.mem, mem_26735.mem, status_flags_mem_27535.mem, aggregates_mem_27537.mem, incprefixes_mem_27539.mem, aggregates_mem_27541.mem, incprefixes_mem_27543.mem, global_dynid_mem_27545.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    
    int64_t segmap_tblock_sizze_24615;
    
    segmap_tblock_sizze_24615 = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24603;
    
    int64_t segmap_usable_groups_24616 = sdiv_up64(m_22282, segmap_tblock_sizze_24615);
    
    if (memblock_alloc_device(ctx, &mem_26738, bytes_26720, "mem_26738")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_27680 = sext_i64_i32(sdiv_up64(m_22282, segmap_tblock_sizze_24615));
    
    {
        err = gpu_kernel_inner_SMJ_intzisegmap_24619(ctx, segmap_usable_groups_24616, 1, 1, *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24603, 1, 1, (int64_t) 0, m_22282, mem_26731.mem, mem_26738.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_26731, "mem_26731") != 0)
        return 1;
    
    bool cond_22333 = slt64((int64_t) 0, m_22282);
    bool y_22334 = slt64(m_22292, m_22282);
    bool bounds_check_22335 = zzero_leq_i_p_m_t_s_22293 && y_22334;
    bool loop_not_taken_22336 = !cond_22333;
    bool protect_assert_disj_22337 = bounds_check_22335 || loop_not_taken_22336;
    bool index_certs_22338;
    
    if (!protect_assert_disj_22337) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) m_22292, "] out of bounds for array of shape [", (long long) m_22282, "].", "-> #0  ftSMJerr.fut:256:10-41\n   #1  ftSMJerr.fut:299:13-300:79\n   #2  ftSMJerr.fut:315:124-127\n   #3  ftSMJerr.fut:304:1-315:127\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    if (cond_22333) {
        if (memblock_alloc_device(ctx, &mem_26740, (int64_t) 8, "mem_26740")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_intzigpuseq_27689(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, m_22292, mem_26738.mem, mem_26740.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_26741, &mem_26740, "mem_26740") != 0)
            return 1;
    } else {
        if (memblock_alloc_device(ctx, &mem_26739, (int64_t) 8, "mem_26739")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i64(ctx, mem_26739, (int64_t) 1, (int64_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_26741, &mem_26739, "mem_26739") != 0)
            return 1;
    }
    if (cond_22333) {
        if (memblock_alloc_device(ctx, &mem_26743, (int64_t) 8, "mem_26743")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_intzigpuseq_27695(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, m_22292, mem_26721.mem, mem_26743.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_26744, &mem_26743, "mem_26743") != 0)
            return 1;
    } else {
        if (memblock_alloc_device(ctx, &mem_26742, (int64_t) 8, "mem_26742")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i64(ctx, mem_26742, (int64_t) 1, (int64_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_26744, &mem_26742, "mem_26742") != 0)
            return 1;
    }
    
    bool zzero_22350 = scatter_psizze_17055 == (int64_t) 0;
    bool nonzzero_22351 = !zzero_22350;
    bool nonzzero_cert_22352;
    
    if (!nonzzero_22351) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftbasics.fut:66:23-29\n   #1  ftSMJerr.fut:299:13-300:79\n   #2  ftSMJerr.fut:315:124-127\n   #3  ftSMJerr.fut:304:1-315:127\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    bool x_22417 = !empty_slice_22291;
    bool protect_assert_disj_22418 = empty_slice_22291 || bounds_check_22335;
    bool index_certs_22419;
    
    if (!protect_assert_disj_22418) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) m_22292, "] out of bounds for array of shape [", (long long) m_22282, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJerr.fut:299:13-300:79\n   #3  ftSMJerr.fut:315:124-127\n   #4  ftSMJerr.fut:304:1-315:127\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t m_f_res_22420;
    
    if (x_22417) {
        int64_t read_res_27820;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_27820, mem_26733.mem, m_22292 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_23335 = read_res_27820;
        
        m_f_res_22420 = x_23335;
    } else {
        m_f_res_22420 = (int64_t) 0;
    }
    
    int64_t m_22422;
    
    if (empty_slice_22291) {
        m_22422 = (int64_t) 0;
    } else {
        m_22422 = m_f_res_22420;
    }
    
    int64_t m_22432 = sub64(m_22422, (int64_t) 1);
    bool i_p_m_t_s_leq_w_22434 = slt64(m_22432, m_22282);
    bool zzero_leq_i_p_m_t_s_22433 = sle64((int64_t) 0, m_22432);
    bool y_22436 = zzero_leq_i_p_m_t_s_22433 && i_p_m_t_s_leq_w_22434;
    bool i_lte_j_22435 = sle64((int64_t) 0, m_22422);
    bool forwards_ok_22437 = i_lte_j_22435 && y_22436;
    bool eq_x_zz_22429 = (int64_t) 0 == m_f_res_22420;
    bool p_and_eq_x_y_22430 = x_22417 && eq_x_zz_22429;
    bool empty_slice_22431 = empty_slice_22291 || p_and_eq_x_y_22430;
    bool ok_or_empty_22438 = empty_slice_22431 || forwards_ok_22437;
    bool index_certs_22439;
    
    if (!ok_or_empty_22438) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_22422, "] out of bounds for array of shape [", (long long) m_22282, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJerr.fut:299:13-300:79\n   #3  ftSMJerr.fut:315:124-127\n   #4  ftSMJerr.fut:304:1-315:127\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_26745 = (int64_t) 8 * m_22422;
    
    if (memblock_alloc_device(ctx, &mem_26750, (int64_t) 8, "mem_26750")) {
        err = 1;
        goto cleanup;
    }
    {
        err = gpu_kernel_inner_SMJ_intzigpuseq_27701(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, ext_mem_26741.mem, ext_mem_26744.mem, mem_26750.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (memblock_unref_device(ctx, &ext_mem_26741, "ext_mem_26741") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_26744, "ext_mem_26744") != 0)
        return 1;
    
    int64_t n_pairs_t_res_22343;
    
    if (cond_22333) {
        int64_t read_res_27821;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_27821, mem_26750.mem, (int64_t) 0 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_26241 = read_res_27821;
        
        n_pairs_t_res_22343 = x_26241;
    } else {
        n_pairs_t_res_22343 = (int64_t) 0;
    }
    if (memblock_unref_device(ctx, &mem_26750, "mem_26750") != 0)
        return 1;
    
    int64_t n_pairs_22344;
    
    if (cond_22333) {
        n_pairs_22344 = n_pairs_t_res_22343;
    } else {
        n_pairs_22344 = (int64_t) 0;
    }
    
    int64_t bytes_26751 = (int64_t) 4 * n_pairs_22344;
    int64_t bytes_26753 = (int64_t) 8 * n_pairs_22344;
    int64_t segmap_tblock_sizze_24630;
    
    segmap_tblock_sizze_24630 = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24629;
    
    int64_t num_tblocks_24632;
    int64_t max_num_tblocks_27707;
    
    max_num_tblocks_27707 = *ctx->tuning_params.inner_SMJ_intzisegmap_num_tblocks_24631;
    num_tblocks_24632 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_22282, segmap_tblock_sizze_24630), max_num_tblocks_27707)));
    if (memblock_alloc_device(ctx, &mem_26746, bytes_26745, "mem_26746")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_26746.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_26721.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_22422})) != 0)
        goto cleanup;
    if (memblock_alloc_device(ctx, &mem_26748, bytes_26745, "mem_26748")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_26748.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_26738.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_22422})) != 0)
        goto cleanup;
    
    int64_t segmap_tblock_sizze_24638;
    
    segmap_tblock_sizze_24638 = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24637;
    
    int64_t num_tblocks_24640;
    int64_t max_num_tblocks_27708;
    
    max_num_tblocks_27708 = *ctx->tuning_params.inner_SMJ_intzisegmap_num_tblocks_24639;
    num_tblocks_24640 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_22282, segmap_tblock_sizze_24638), max_num_tblocks_27708)));
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_27709 = sext_i64_i32(sdiv_up64(m_22282, segmap_tblock_sizze_24638));
    
    {
        err = gpu_kernel_inner_SMJ_intzisegmap_24635(ctx, num_tblocks_24640, 1, 1, *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24637, 1, 1, (int64_t) 0, m_22282, m_22422, num_tblocks_24640, virt_num_tblocks_27709, mem_26721.mem, mem_26733.mem, mem_26735.mem, mem_26738.mem, mem_26746.mem, mem_26748.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_26721, "mem_26721") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_26733, "mem_26733") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_26735, "mem_26735") != 0)
        return 1;
    
    bool cond_22449 = slt64((int64_t) 0, m_22422);
    int64_t segmap_tblock_sizze_24653;
    
    segmap_tblock_sizze_24653 = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24645;
    if (memblock_alloc_device(ctx, &mem_26752, bytes_26751, "mem_26752")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, mem_26752, n_pairs_22344, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_26754, bytes_26753, "mem_26754")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_26754, n_pairs_22344, (int64_t) -1) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_26756, bytes_26753, "mem_26756")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_26756, n_pairs_22344, (int64_t) -1) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t zm_lhs_22348 = add64(scatter_psizze_17055, n_pairs_22344);
    int64_t zs_lhs_22349 = sub64(zm_lhs_22348, (int64_t) 1);
    int64_t m_22353 = sdiv64(zs_lhs_22349, scatter_psizze_17055);
    bool loop_cond_22354 = slt64((int64_t) 0, m_22353);
    bool partitioned_scatter_res_22355;
    int64_t partitioned_scatter_res_22359;
    bool loop_while_22360;
    int64_t p_22364;
    
    loop_while_22360 = loop_cond_22354;
    p_22364 = (int64_t) 0;
    while (loop_while_22360) {
        int64_t lower_bound_22365 = mul64(scatter_psizze_17055, p_22364);
        int64_t min_arg1_22366 = add64(scatter_psizze_17055, lower_bound_22365);
        int64_t min_res_22367 = smin64(n_pairs_22344, min_arg1_22366);
        int64_t j_m_i_22368 = sub64(min_res_22367, lower_bound_22365);
        bool empty_slice_22369 = j_m_i_22368 == (int64_t) 0;
        int64_t m_22370 = sub64(j_m_i_22368, (int64_t) 1);
        int64_t i_p_m_t_s_22371 = add64(lower_bound_22365, m_22370);
        bool zzero_leq_i_p_m_t_s_22372 = sle64((int64_t) 0, i_p_m_t_s_22371);
        bool i_p_m_t_s_leq_w_22373 = slt64(i_p_m_t_s_22371, n_pairs_22344);
        bool zzero_lte_i_22374 = sle64((int64_t) 0, lower_bound_22365);
        bool i_lte_j_22375 = sle64(lower_bound_22365, min_res_22367);
        bool y_22376 = i_p_m_t_s_leq_w_22373 && zzero_lte_i_22374;
        bool y_22377 = zzero_leq_i_p_m_t_s_22372 && y_22376;
        bool forwards_ok_22378 = i_lte_j_22375 && y_22377;
        bool ok_or_empty_22379 = empty_slice_22369 || forwards_ok_22378;
        bool index_certs_22380;
        
        if (!ok_or_empty_22379) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) lower_bound_22365, ":", (long long) min_res_22367, "] out of bounds for array of shape [", (long long) n_pairs_22344, "].", "-> #0  ftbasics.fut:72:25-56\n   #1  ftSMJerr.fut:299:13-300:79\n   #2  ftSMJerr.fut:315:124-127\n   #3  ftSMJerr.fut:304:1-315:127\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t bytes_26766 = (int64_t) 4 * j_m_i_22368;
        int64_t bytes_26768 = (int64_t) 8 * j_m_i_22368;
        
        if (memblock_alloc_device(ctx, &mem_26767, bytes_26766, "mem_26767")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_26767.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_26752.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_22365, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_22368})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_26769, bytes_26768, "mem_26769")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_26769.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_26754.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_22365, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_22368})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_26771, bytes_26768, "mem_26771")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_26771.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_26756.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_22365, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_22368})) != 0)
            goto cleanup;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_27727 = sext_i64_i32(sdiv_up64(m_22282, segmap_tblock_sizze_24630));
        
        {
            err = gpu_kernel_inner_SMJ_intzisegmap_24627(ctx, num_tblocks_24632, 1, 1, *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24629, 1, 1, (int64_t) 0, m_22282, lower_bound_22365, min_res_22367, j_m_i_22368, num_tblocks_24632, virt_num_tblocks_27727, mem_26723.mem, mem_26725.mem, mem_26727.mem, mem_26738.mem, mem_26767.mem, mem_26769.mem, mem_26771.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t tmp_22394 = add64((int64_t) 1, p_22364);
        
        if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_26752.mem, lower_bound_22365, (int64_t []) {(int64_t) 1}, mem_26767.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_22368})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_26767, "mem_26767") != 0)
            return 1;
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_26754.mem, lower_bound_22365, (int64_t []) {(int64_t) 1}, mem_26769.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_22368})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_26769, "mem_26769") != 0)
            return 1;
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_26756.mem, lower_bound_22365, (int64_t []) {(int64_t) 1}, mem_26771.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_22368})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_26771, "mem_26771") != 0)
            return 1;
        
        bool loop_cond_22405 = slt64(tmp_22394, m_22353);
        bool loop_while_tmp_27722 = loop_cond_22405;
        int64_t p_tmp_27726 = tmp_22394;
        
        loop_while_22360 = loop_while_tmp_27722;
        p_22364 = p_tmp_27726;
    }
    partitioned_scatter_res_22355 = loop_while_22360;
    partitioned_scatter_res_22359 = p_22364;
    if (memblock_unref_device(ctx, &mem_26723, "mem_26723") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_26725, "mem_26725") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_26727, "mem_26727") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_26738, "mem_26738") != 0)
        return 1;
    
    bool loop_cond_t_res_22450 = slt64(m_22282, n_pairs_22344);
    bool x_22451 = cond_22449 && loop_cond_t_res_22450;
    
    if (memblock_alloc_device(ctx, &mem_26797, (int64_t) 4, "mem_26797")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_26798, (int64_t) 8, "mem_26798")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_26799, (int64_t) 8, "mem_26799")) {
        err = 1;
        goto cleanup;
    }
    
    bool joinTups_to_joinPairs_InnerJoin_res_22452;
    int64_t joinTups_to_joinPairs_InnerJoin_res_22456;
    bool loop_while_22457;
    int64_t p_22461;
    
    if (memblock_set_device(ctx, &mem_param_26784, &mem_26752, "mem_26752") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_26787, &mem_26754, "mem_26754") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_26790, &mem_26756, "mem_26756") != 0)
        return 1;
    loop_while_22457 = x_22451;
    p_22461 = (int64_t) 0;
    while (loop_while_22457) {
        bool x_22462 = sle64((int64_t) 0, p_22461);
        bool y_22463 = slt64(p_22461, m_22422);
        bool bounds_check_22464 = x_22462 && y_22463;
        bool index_certs_22465;
        
        if (!bounds_check_22464) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) p_22461, "] out of bounds for array of shape [", (long long) m_22422, "].", "-> #0  ftSMJerr.fut:271:13-42\n   #1  ftSMJerr.fut:299:13-300:79\n   #2  ftSMJerr.fut:315:124-127\n   #3  ftSMJerr.fut:304:1-315:127\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t read_res_27822;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_27822, mem_26748.mem, p_22461 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t loopres_22466 = read_res_27822;
        int64_t read_res_27823;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_27823, mem_26746.mem, p_22461 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t loopres_22467 = read_res_27823;
        bool x_22468 = sle64((int64_t) 0, loopres_22466);
        bool y_22469 = slt64(loopres_22466, n_pairs_22344);
        bool bounds_check_22470 = x_22468 && y_22469;
        bool index_certs_22471;
        
        if (!bounds_check_22470) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) loopres_22466, "] out of bounds for array of shape [", (long long) n_pairs_22344, "].", "-> #0  ftSMJerr.fut:273:52-61\n   #1  ftSMJerr.fut:299:13-300:79\n   #2  ftSMJerr.fut:315:124-127\n   #3  ftSMJerr.fut:304:1-315:127\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t tmp_22482 = add64(loopres_22466, loopres_22467);
        bool empty_slice_22486 = loopres_22467 == (int64_t) 0;
        int64_t m_22487 = sub64(loopres_22467, (int64_t) 1);
        int64_t i_p_m_t_s_22488 = add64(loopres_22466, m_22487);
        bool zzero_leq_i_p_m_t_s_22489 = sle64((int64_t) 0, i_p_m_t_s_22488);
        bool i_p_m_t_s_leq_w_22490 = slt64(i_p_m_t_s_22488, n_pairs_22344);
        bool i_lte_j_22491 = sle64(loopres_22466, tmp_22482);
        bool y_22492 = x_22468 && i_p_m_t_s_leq_w_22490;
        bool y_22493 = zzero_leq_i_p_m_t_s_22489 && y_22492;
        bool forwards_ok_22494 = i_lte_j_22491 && y_22493;
        bool ok_or_empty_22495 = empty_slice_22486 || forwards_ok_22494;
        bool index_certs_22496;
        
        if (!ok_or_empty_22495) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) loopres_22466, ":", (long long) tmp_22482, "] out of bounds for array of shape [", (long long) n_pairs_22344, "].", "-> #0  ftSMJerr.fut:277:14-55\n   #1  ftSMJerr.fut:299:13-300:79\n   #2  ftSMJerr.fut:315:124-127\n   #3  ftSMJerr.fut:304:1-315:127\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t bytes_26800 = (int64_t) 4 * loopres_22467;
        int64_t bytes_26802 = (int64_t) 8 * loopres_22467;
        int64_t segmap_usable_groups_24654 = sdiv_up64(loopres_22467, segmap_tblock_sizze_24653);
        int64_t tmp_22481 = add64((int64_t) 1, p_22461);
        
        if (memblock_alloc_device(ctx, &mem_26792, bytes_26751, "mem_26792")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_26792.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_26784.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_22344})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_26794, bytes_26753, "mem_26794")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_26794.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_26787.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_22344})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_26796, bytes_26753, "mem_26796")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_26796.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_26790.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_22344})) != 0)
            goto cleanup;
        
        bool cond_22500 = slt64(tmp_22481, m_22422);
        bool x_22501 = loop_cond_t_res_22450 && cond_22500;
        
        {
            err = gpu_kernel_inner_SMJ_intzigpuseq_27748(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, loopres_22466, mem_param_26784.mem, mem_param_26787.mem, mem_param_26790.mem, mem_26797.mem, mem_26798.mem, mem_26799.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_26801, bytes_26800, "mem_26801")) {
            err = 1;
            goto cleanup;
        }
        
        int64_t replicate_n_27754 = loopres_22467;
        int64_t tblock_sizze_27759;
        
        tblock_sizze_27759 = *ctx->tuning_params.inner_SMJ_intzitblock_sizze_27759;
        
        int64_t virt_num_tblocks_27760 = sdiv_up64(replicate_n_27754, tblock_sizze_27759);
        int64_t num_tblocks_27761 = smin64(virt_num_tblocks_27760, (int64_t) 1048576);
        
        {
            err = gpu_kernel_inner_SMJ_intzireplicate_27755(ctx, num_tblocks_27761, 1, 1, tblock_sizze_27759, 1, 1, (int64_t) 0, loopres_22467, replicate_n_27754, virt_num_tblocks_27760, num_tblocks_27761, mem_26797.mem, mem_26801.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_26803, bytes_26802, "mem_26803")) {
            err = 1;
            goto cleanup;
        }
        
        int64_t replicate_n_27774 = loopres_22467;
        int64_t tblock_sizze_27779;
        
        tblock_sizze_27779 = *ctx->tuning_params.inner_SMJ_intzitblock_sizze_27779;
        
        int64_t virt_num_tblocks_27780 = sdiv_up64(replicate_n_27774, tblock_sizze_27779);
        int64_t num_tblocks_27781 = smin64(virt_num_tblocks_27780, (int64_t) 1048576);
        
        {
            err = gpu_kernel_inner_SMJ_intzireplicate_27775(ctx, num_tblocks_27781, 1, 1, tblock_sizze_27779, 1, 1, (int64_t) 0, loopres_22467, replicate_n_27774, virt_num_tblocks_27780, num_tblocks_27781, mem_26798.mem, mem_26803.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_27794 = sext_i64_i32(sdiv_up64(loopres_22467, segmap_tblock_sizze_24653));
        
        {
            err = gpu_kernel_inner_SMJ_intzisegmap_24657(ctx, segmap_usable_groups_24654, 1, 1, *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_24645, 1, 1, (int64_t) 0, loopres_22466, loopres_22467, mem_26796.mem, mem_26799.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_26792.mem, loopres_22466, (int64_t []) {(int64_t) 1}, mem_26801.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {loopres_22467})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_26801, "mem_26801") != 0)
            return 1;
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_26794.mem, loopres_22466, (int64_t []) {(int64_t) 1}, mem_26803.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {loopres_22467})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_26803, "mem_26803") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_27740, &mem_26792, "mem_26792") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_27741, &mem_26794, "mem_26794") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_27742, &mem_26796, "mem_26796") != 0)
            return 1;
        
        bool loop_while_tmp_27743 = x_22501;
        int64_t p_tmp_27747 = tmp_22481;
        
        if (memblock_set_device(ctx, &mem_param_26784, &mem_param_tmp_27740, "mem_param_tmp_27740") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_26787, &mem_param_tmp_27741, "mem_param_tmp_27741") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_26790, &mem_param_tmp_27742, "mem_param_tmp_27742") != 0)
            return 1;
        loop_while_22457 = loop_while_tmp_27743;
        p_22461 = p_tmp_27747;
    }
    if (memblock_set_device(ctx, &ext_mem_26815, &mem_param_26784, "mem_param_26784") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_26814, &mem_param_26787, "mem_param_26787") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_26813, &mem_param_26790, "mem_param_26790") != 0)
        return 1;
    joinTups_to_joinPairs_InnerJoin_res_22452 = loop_while_22457;
    joinTups_to_joinPairs_InnerJoin_res_22456 = p_22461;
    if (memblock_unref_device(ctx, &mem_26746, "mem_26746") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_26748, "mem_26748") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_26752, "mem_26752") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_26754, "mem_26754") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_26756, "mem_26756") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_26797, "mem_26797") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_26798, "mem_26798") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_26799, "mem_26799") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_26817, bytes_26751, "mem_26817")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_26817.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_26815.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_22344})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_26815, "ext_mem_26815") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_26819, bytes_26753, "mem_26819")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_26819.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_26814.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_22344})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_26814, "ext_mem_26814") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_26821, bytes_26753, "mem_26821")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_26821.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_26813.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_22344})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_26813, "ext_mem_26813") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_27014, &mem_26819, "mem_26819") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_27015, &mem_26821, "mem_26821") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_27016, &mem_26817, "mem_26817") != 0)
        return 1;
    prim_out_27017 = n_pairs_22344;
    if (memblock_set_device(ctx, &*mem_out_p_27803, &mem_out_27014, "mem_out_27014") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_27804, &mem_out_27015, "mem_out_27015") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_27805, &mem_out_27016, "mem_out_27016") != 0)
        return 1;
    *out_prim_out_27806 = prim_out_27017;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_26821, "mem_26821") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26819, "mem_26819") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26817, "mem_26817") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_27742, "mem_param_tmp_27742") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_27741, "mem_param_tmp_27741") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_27740, "mem_param_tmp_27740") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26803, "mem_26803") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26801, "mem_26801") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26796, "mem_26796") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26794, "mem_26794") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26792, "mem_26792") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_26790, "mem_param_26790") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_26787, "mem_param_26787") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_26784, "mem_param_26784") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26813, "ext_mem_26813") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26814, "ext_mem_26814") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26815, "ext_mem_26815") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26799, "mem_26799") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26798, "mem_26798") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26797, "mem_26797") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26771, "mem_26771") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26769, "mem_26769") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26767, "mem_26767") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26756, "mem_26756") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26754, "mem_26754") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26752, "mem_26752") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26748, "mem_26748") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26746, "mem_26746") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26750, "mem_26750") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26742, "mem_26742") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26743, "mem_26743") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26744, "ext_mem_26744") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26739, "mem_26739") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26740, "mem_26740") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26741, "ext_mem_26741") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26738, "mem_26738") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_27543, "incprefixes_mem_27543") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_27541, "aggregates_mem_27541") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_27539, "incprefixes_mem_27539") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_27537, "aggregates_mem_27537") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_27535, "status_flags_mem_27535") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26735, "mem_26735") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26733, "mem_26733") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26731, "mem_26731") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26727, "mem_26727") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26725, "mem_26725") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26723, "mem_26723") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26721, "mem_26721") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_27422, "incprefixes_mem_27422") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_27420, "aggregates_mem_27420") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_27398, "status_flags_mem_27398") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26719, "mem_26719") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26717, "mem_26717") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_27065, "mem_param_tmp_27065") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_27064, "mem_param_tmp_27064") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26702, "mem_26702") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26701, "mem_26701") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26698, "mem_26698") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_27222, "mem_param_tmp_27222") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_27221, "mem_param_tmp_27221") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26506, "mem_26506") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26504, "mem_26504") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26502, "mem_26502") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26499, "mem_26499") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_27232, "mem_param_tmp_27232") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_27231, "mem_param_tmp_27231") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26490, "mem_26490") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26487, "mem_26487") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_27250, "mem_param_tmp_27250") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_27249, "mem_param_tmp_27249") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26466, "mem_26466") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26464, "mem_26464") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26399, "mem_26399") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26397, "mem_26397") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26460, "mem_26460") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26458, "mem_26458") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26461, "ext_mem_26461") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26462, "ext_mem_26462") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26338, "ext_mem_26338") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26336, "mem_26336") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26469, "ext_mem_26469") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26472, "ext_mem_26472") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26334, "mem_26334") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26475, "ext_mem_26475") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26478, "ext_mem_26478") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26332, "ext_mem_26332") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26331, "ext_mem_26331") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_26328, "mem_param_26328") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_26325, "mem_param_26325") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26483, "ext_mem_26483") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26484, "ext_mem_26484") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26320, "mem_26320") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26321, "mem_26321") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26322, "ext_mem_26322") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26317, "mem_26317") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26318, "mem_26318") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26319, "ext_mem_26319") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_26316, "mem_param_26316") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_26313, "mem_param_26313") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26495, "ext_mem_26495") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26496, "ext_mem_26496") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26333, "mem_26333") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26330, "mem_26330") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26329, "mem_26329") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26310, "mem_26310") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26308, "mem_26308") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26509, "ext_mem_26509") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26512, "ext_mem_26512") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26515, "ext_mem_26515") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26518, "ext_mem_26518") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_26306, "mem_param_26306") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_26303, "mem_param_26303") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26523, "ext_mem_26523") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26524, "ext_mem_26524") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26300, "mem_26300") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26298, "mem_26298") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26285, "mem_26285") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26287, "mem_26287") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26288, "ext_mem_26288") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26289, "ext_mem_26289") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26282, "mem_26282") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26280, "mem_26280") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26269, "mem_26269") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26270, "mem_26270") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26271, "ext_mem_26271") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26268, "mem_26268") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26265, "mem_26265") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26266, "mem_26266") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26267, "ext_mem_26267") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26264, "mem_26264") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26262, "mem_26262") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_27083, "mem_param_tmp_27083") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_27082, "mem_param_tmp_27082") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26671, "mem_26671") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26669, "mem_26669") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26604, "mem_26604") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26602, "mem_26602") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26665, "mem_26665") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26663, "mem_26663") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26666, "ext_mem_26666") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26667, "ext_mem_26667") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26543, "ext_mem_26543") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26541, "mem_26541") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26674, "ext_mem_26674") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26677, "ext_mem_26677") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26539, "mem_26539") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26680, "ext_mem_26680") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26683, "ext_mem_26683") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26537, "ext_mem_26537") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26536, "ext_mem_26536") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_26533, "mem_param_26533") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_26530, "mem_param_26530") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26688, "ext_mem_26688") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26689, "ext_mem_26689") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26538, "mem_26538") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26535, "mem_26535") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26534, "mem_26534") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26525, "mem_26525") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26526, "mem_26526") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26527, "ext_mem_26527") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26692, "ext_mem_26692") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26695, "ext_mem_26695") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26705, "ext_mem_26705") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26708, "ext_mem_26708") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_26258, "mem_param_26258") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_26255, "mem_param_26255") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26713, "ext_mem_26713") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26714, "ext_mem_26714") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26260, "mem_26260") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26259, "mem_26259") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26250, "mem_26250") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26251, "mem_26251") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26252, "ext_mem_26252") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26249, "mem_26249") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_26247, "mem_26247") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_26245, "ext_mem_26245") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_27016, "mem_out_27016") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_27015, "mem_out_27015") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_27014, "mem_out_27014") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_indicesWithIncrement_7095(struct futhark_context *ctx, struct memblock_device *mem_out_p_27824, struct memblock_device xs_mem_26243, int64_t n_11719, int64_t incr_11720)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_26245;
    
    mem_26245.references = NULL;
    
    struct memblock_device mem_out_27014;
    
    mem_out_27014.references = NULL;
    
    struct memblock_device global_dynid_mem_27424 = ctx->constants->global_dynid_mem_27424;
    struct memblock_device global_dynid_mem_27545 = ctx->constants->global_dynid_mem_27545;
    int64_t rng_11725 = add64(n_11719, incr_11720);
    bool bounds_invalid_upwards_11729 = slt64(rng_11725, incr_11720);
    bool valid_11734 = !bounds_invalid_upwards_11729;
    bool range_valid_c_11735;
    
    if (!valid_11734) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) incr_11720, "..<", (long long) rng_11725, " is invalid.", "-> #0  ftbasics.fut:11:25-40\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_26244 = (int64_t) 8 * n_11719;
    
    if (memblock_alloc_device(ctx, &mem_26245, bytes_26244, "mem_26245")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhiota_i64(ctx, mem_26245, n_11719, incr_11720, (int64_t) 1) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_set_device(ctx, &mem_out_27014, &mem_26245, "mem_26245") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_27824, &mem_out_27014, "mem_out_27014") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_26245, "mem_26245") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_27014, "mem_out_27014") != 0)
            return 1;
    }
    return err;
}

int futhark_entry_inner_SMJ_int(struct futhark_context *ctx, struct futhark_opaque_joinPairs_int **out0, const struct futhark_i32_1d *in0, const struct futhark_i32_1d *in1, const int64_t in2, const int64_t in3, const int64_t in4, const int64_t in5, const int64_t in6, const int64_t in7)
{
    int64_t nR_17046 = (int64_t) 0;
    int64_t nS_17047 = (int64_t) 0;
    int64_t offset_R_17050 = (int64_t) 0;
    int64_t offset_S_17051 = (int64_t) 0;
    int64_t partitionsPerWindow_17052 = (int64_t) 0;
    int64_t numberOfWindows_17053 = (int64_t) 0;
    int64_t extParallelism_17054 = (int64_t) 0;
    int64_t scatter_psizze_17055 = (int64_t) 0;
    int64_t prim_out_27017 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_27016;
    
    mem_out_27016.references = NULL;
    
    struct memblock_device mem_out_27015;
    
    mem_out_27015.references = NULL;
    
    struct memblock_device mem_out_27014;
    
    mem_out_27014.references = NULL;
    
    struct memblock_device tS_mem_26244;
    
    tS_mem_26244.references = NULL;
    
    struct memblock_device tR_mem_26243;
    
    tR_mem_26243.references = NULL;
    tR_mem_26243 = in0->mem;
    nR_17046 = in0->shape[0];
    tS_mem_26244 = in1->mem;
    nS_17047 = in1->shape[0];
    offset_R_17050 = in2;
    offset_S_17051 = in3;
    partitionsPerWindow_17052 = in4;
    numberOfWindows_17053 = in5;
    extParallelism_17054 = in6;
    scatter_psizze_17055 = in7;
    if (!(nR_17046 == in0->shape[0] && nS_17047 == in1->shape[0])) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_inner_SMJ_int(ctx, &mem_out_27014, &mem_out_27015, &mem_out_27016, &prim_out_27017, tR_mem_26243, tS_mem_26244, nR_17046, nS_17047, offset_R_17050, offset_S_17051, partitionsPerWindow_17052, numberOfWindows_17053, extParallelism_17054, scatter_psizze_17055);
        if (ret == 0) {
            struct memblock_device global_dynid_mem_27424 = ctx->constants->global_dynid_mem_27424;
            struct memblock_device global_dynid_mem_27545 = ctx->constants->global_dynid_mem_27545;
            
            assert((*out0 = (struct futhark_opaque_joinPairs_int *) malloc(sizeof(struct futhark_opaque_joinPairs_int))) != NULL);
            assert(((*out0)->v0 = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d))) != NULL);
            (*out0)->v0->mem = mem_out_27014;
            (*out0)->v0->shape[0] = prim_out_27017;
            assert(((*out0)->v1 = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d))) != NULL);
            (*out0)->v1->mem = mem_out_27015;
            (*out0)->v1->shape[0] = prim_out_27017;
            assert(((*out0)->v2 = (struct futhark_i32_1d *) malloc(sizeof(struct futhark_i32_1d))) != NULL);
            (*out0)->v2->mem = mem_out_27016;
            (*out0)->v2->shape[0] = prim_out_27017;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
  
