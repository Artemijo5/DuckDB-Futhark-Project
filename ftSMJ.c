// Generated by Futhark 0.26.0 (prerelease - include info below when reporting bugs).
// git: 1de4f0c (Fri Jan 24 11:10:52 2025 +0100)
// Compiled with GHC 9.4.8.

// We need to define _GNU_SOURCE before
// _any_ headers files are imported to get
// the usage statistics of a thread (i.e. have RUSAGE_THREAD) on GNU/Linux
// https://manpages.courier-mta.org/htmlman2/getrusage.2.html
#ifndef _GNU_SOURCE // Avoid possible double-definition warning.
#define _GNU_SOURCE
#endif

#ifdef __clang__
#pragma clang diagnostic ignored "-Wunused-function"
#pragma clang diagnostic ignored "-Wunused-variable"
#pragma clang diagnostic ignored "-Wunused-const-variable"
#pragma clang diagnostic ignored "-Wparentheses"
#pragma clang diagnostic ignored "-Wunused-label"
#pragma clang diagnostic ignored "-Wunused-but-set-variable"
#elif __GNUC__
#pragma GCC diagnostic ignored "-Wunused-function"
#pragma GCC diagnostic ignored "-Wunused-variable"
#pragma GCC diagnostic ignored "-Wunused-const-variable"
#pragma GCC diagnostic ignored "-Wparentheses"
#pragma GCC diagnostic ignored "-Wunused-label"
#pragma GCC diagnostic ignored "-Wunused-but-set-variable"
#endif

// Headers
#include <stdint.h>
#include <stddef.h>
#include <stdbool.h>
#include <stdio.h>
#include <float.h>

#include <cuda.h>
#include <cuda_runtime.h>
#include <nvrtc.h>

#ifdef __cplusplus
extern "C" {
#endif

// Initialisation
struct futhark_context_config;
struct futhark_context_config *futhark_context_config_new(void);
void futhark_context_config_free(struct futhark_context_config *cfg);
int futhark_context_config_set_tuning_param(struct futhark_context_config *cfg, const char *param_name, size_t new_value);
struct futhark_context;
struct futhark_context *futhark_context_new(struct futhark_context_config *cfg);
void futhark_context_free(struct futhark_context *cfg);
void futhark_context_config_set_default_thread_block_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_grid_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_group_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_num_groups(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_tile_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_reg_tile_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_registers(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_cache(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_threshold(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_unified_memory(struct futhark_context_config *cfg, int flag);
void futhark_context_config_add_nvrtc_option(struct futhark_context_config *cfg, const char *opt);
void futhark_context_config_set_device(struct futhark_context_config *cfg, const char *s);
const char *futhark_context_config_get_program(struct futhark_context_config *cfg);
void futhark_context_config_set_program(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_dump_ptx_to(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_load_ptx_from(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_set_debugging(struct futhark_context_config *cfg, int flag);
void futhark_context_config_set_profiling(struct futhark_context_config *cfg, int flag);
void futhark_context_config_set_logging(struct futhark_context_config *cfg, int flag);
int futhark_get_tuning_param_count(void);
const char *futhark_get_tuning_param_name(int);
const char *futhark_get_tuning_param_class(int);

// Arrays
struct futhark_f32_1d;
struct futhark_f32_1d *futhark_new_f32_1d(struct futhark_context *ctx, const float *data, int64_t dim0);
struct futhark_f32_1d *futhark_new_raw_f32_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0);
int futhark_free_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr);
int futhark_values_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr, float *data);
int futhark_index_f32_1d(struct futhark_context *ctx, float *out, struct futhark_f32_1d *arr, int64_t i0);
CUdeviceptr futhark_values_raw_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr);
const int64_t *futhark_shape_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr);
struct futhark_f64_1d;
struct futhark_f64_1d *futhark_new_f64_1d(struct futhark_context *ctx, const double *data, int64_t dim0);
struct futhark_f64_1d *futhark_new_raw_f64_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0);
int futhark_free_f64_1d(struct futhark_context *ctx, struct futhark_f64_1d *arr);
int futhark_values_f64_1d(struct futhark_context *ctx, struct futhark_f64_1d *arr, double *data);
int futhark_index_f64_1d(struct futhark_context *ctx, double *out, struct futhark_f64_1d *arr, int64_t i0);
CUdeviceptr futhark_values_raw_f64_1d(struct futhark_context *ctx, struct futhark_f64_1d *arr);
const int64_t *futhark_shape_f64_1d(struct futhark_context *ctx, struct futhark_f64_1d *arr);
struct futhark_i16_1d;
struct futhark_i16_1d *futhark_new_i16_1d(struct futhark_context *ctx, const int16_t *data, int64_t dim0);
struct futhark_i16_1d *futhark_new_raw_i16_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0);
int futhark_free_i16_1d(struct futhark_context *ctx, struct futhark_i16_1d *arr);
int futhark_values_i16_1d(struct futhark_context *ctx, struct futhark_i16_1d *arr, int16_t *data);
int futhark_index_i16_1d(struct futhark_context *ctx, int16_t *out, struct futhark_i16_1d *arr, int64_t i0);
CUdeviceptr futhark_values_raw_i16_1d(struct futhark_context *ctx, struct futhark_i16_1d *arr);
const int64_t *futhark_shape_i16_1d(struct futhark_context *ctx, struct futhark_i16_1d *arr);
struct futhark_i32_1d;
struct futhark_i32_1d *futhark_new_i32_1d(struct futhark_context *ctx, const int32_t *data, int64_t dim0);
struct futhark_i32_1d *futhark_new_raw_i32_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0);
int futhark_free_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr);
int futhark_values_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr, int32_t *data);
int futhark_index_i32_1d(struct futhark_context *ctx, int32_t *out, struct futhark_i32_1d *arr, int64_t i0);
CUdeviceptr futhark_values_raw_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr);
const int64_t *futhark_shape_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr);
struct futhark_i64_1d;
struct futhark_i64_1d *futhark_new_i64_1d(struct futhark_context *ctx, const int64_t *data, int64_t dim0);
struct futhark_i64_1d *futhark_new_raw_i64_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0);
int futhark_free_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr);
int futhark_values_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr, int64_t *data);
int futhark_index_i64_1d(struct futhark_context *ctx, int64_t *out, struct futhark_i64_1d *arr, int64_t i0);
CUdeviceptr futhark_values_raw_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr);
const int64_t *futhark_shape_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr);

// Opaque values
struct futhark_opaque_joinPairs_double;
struct futhark_opaque_joinPairs_float;
struct futhark_opaque_joinPairs_int;
struct futhark_opaque_joinPairs_long;
struct futhark_opaque_joinPairs_short;
int futhark_free_opaque_joinPairs_double(struct futhark_context *ctx, struct futhark_opaque_joinPairs_double *obj);
int futhark_store_opaque_joinPairs_double(struct futhark_context *ctx, const struct futhark_opaque_joinPairs_double *obj, void **p, size_t *n);
struct futhark_opaque_joinPairs_double *futhark_restore_opaque_joinPairs_double(struct futhark_context *ctx, const void *p);
int futhark_project_opaque_joinPairs_double_ix(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_double *obj);
int futhark_project_opaque_joinPairs_double_iy(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_double *obj);
int futhark_project_opaque_joinPairs_double_vs(struct futhark_context *ctx, struct futhark_f64_1d **out, const struct futhark_opaque_joinPairs_double *obj);
int futhark_new_opaque_joinPairs_double(struct futhark_context *ctx, struct futhark_opaque_joinPairs_double **out, const struct futhark_i64_1d *f_ix, const struct futhark_i64_1d *f_iy, const struct futhark_f64_1d *f_vs);
int futhark_free_opaque_joinPairs_float(struct futhark_context *ctx, struct futhark_opaque_joinPairs_float *obj);
int futhark_store_opaque_joinPairs_float(struct futhark_context *ctx, const struct futhark_opaque_joinPairs_float *obj, void **p, size_t *n);
struct futhark_opaque_joinPairs_float *futhark_restore_opaque_joinPairs_float(struct futhark_context *ctx, const void *p);
int futhark_project_opaque_joinPairs_float_ix(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_float *obj);
int futhark_project_opaque_joinPairs_float_iy(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_float *obj);
int futhark_project_opaque_joinPairs_float_vs(struct futhark_context *ctx, struct futhark_f32_1d **out, const struct futhark_opaque_joinPairs_float *obj);
int futhark_new_opaque_joinPairs_float(struct futhark_context *ctx, struct futhark_opaque_joinPairs_float **out, const struct futhark_i64_1d *f_ix, const struct futhark_i64_1d *f_iy, const struct futhark_f32_1d *f_vs);
int futhark_free_opaque_joinPairs_int(struct futhark_context *ctx, struct futhark_opaque_joinPairs_int *obj);
int futhark_store_opaque_joinPairs_int(struct futhark_context *ctx, const struct futhark_opaque_joinPairs_int *obj, void **p, size_t *n);
struct futhark_opaque_joinPairs_int *futhark_restore_opaque_joinPairs_int(struct futhark_context *ctx, const void *p);
int futhark_project_opaque_joinPairs_int_ix(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_int *obj);
int futhark_project_opaque_joinPairs_int_iy(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_int *obj);
int futhark_project_opaque_joinPairs_int_vs(struct futhark_context *ctx, struct futhark_i32_1d **out, const struct futhark_opaque_joinPairs_int *obj);
int futhark_new_opaque_joinPairs_int(struct futhark_context *ctx, struct futhark_opaque_joinPairs_int **out, const struct futhark_i64_1d *f_ix, const struct futhark_i64_1d *f_iy, const struct futhark_i32_1d *f_vs);
int futhark_free_opaque_joinPairs_long(struct futhark_context *ctx, struct futhark_opaque_joinPairs_long *obj);
int futhark_store_opaque_joinPairs_long(struct futhark_context *ctx, const struct futhark_opaque_joinPairs_long *obj, void **p, size_t *n);
struct futhark_opaque_joinPairs_long *futhark_restore_opaque_joinPairs_long(struct futhark_context *ctx, const void *p);
int futhark_project_opaque_joinPairs_long_ix(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_long *obj);
int futhark_project_opaque_joinPairs_long_iy(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_long *obj);
int futhark_project_opaque_joinPairs_long_vs(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_long *obj);
int futhark_new_opaque_joinPairs_long(struct futhark_context *ctx, struct futhark_opaque_joinPairs_long **out, const struct futhark_i64_1d *f_ix, const struct futhark_i64_1d *f_iy, const struct futhark_i64_1d *f_vs);
int futhark_free_opaque_joinPairs_short(struct futhark_context *ctx, struct futhark_opaque_joinPairs_short *obj);
int futhark_store_opaque_joinPairs_short(struct futhark_context *ctx, const struct futhark_opaque_joinPairs_short *obj, void **p, size_t *n);
struct futhark_opaque_joinPairs_short *futhark_restore_opaque_joinPairs_short(struct futhark_context *ctx, const void *p);
int futhark_project_opaque_joinPairs_short_ix(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_short *obj);
int futhark_project_opaque_joinPairs_short_iy(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_short *obj);
int futhark_project_opaque_joinPairs_short_vs(struct futhark_context *ctx, struct futhark_i16_1d **out, const struct futhark_opaque_joinPairs_short *obj);
int futhark_new_opaque_joinPairs_short(struct futhark_context *ctx, struct futhark_opaque_joinPairs_short **out, const struct futhark_i64_1d *f_ix, const struct futhark_i64_1d *f_iy, const struct futhark_i16_1d *f_vs);

// Entry points
int futhark_entry_gather_payloads_double(struct futhark_context *ctx, struct futhark_f64_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_i64_1d *in2, const struct futhark_f64_1d *in3);
int futhark_entry_gather_payloads_double_GFUR(struct futhark_context *ctx, struct futhark_f64_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_f64_1d *in2, const struct futhark_i64_1d *in3, const struct futhark_f64_1d *in4);
int futhark_entry_gather_payloads_float(struct futhark_context *ctx, struct futhark_f32_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_i64_1d *in2, const struct futhark_f32_1d *in3);
int futhark_entry_gather_payloads_float_GFUR(struct futhark_context *ctx, struct futhark_f32_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_f32_1d *in2, const struct futhark_i64_1d *in3, const struct futhark_f32_1d *in4);
int futhark_entry_gather_payloads_int(struct futhark_context *ctx, struct futhark_i32_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_i64_1d *in2, const struct futhark_i32_1d *in3);
int futhark_entry_gather_payloads_int_GFUR(struct futhark_context *ctx, struct futhark_i32_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_i32_1d *in2, const struct futhark_i64_1d *in3, const struct futhark_i32_1d *in4);
int futhark_entry_gather_payloads_long(struct futhark_context *ctx, struct futhark_i64_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_i64_1d *in2, const struct futhark_i64_1d *in3);
int futhark_entry_gather_payloads_long_GFUR(struct futhark_context *ctx, struct futhark_i64_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_i64_1d *in2, const struct futhark_i64_1d *in3, const struct futhark_i64_1d *in4);
int futhark_entry_gather_payloads_short(struct futhark_context *ctx, struct futhark_i16_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_i64_1d *in2, const struct futhark_i16_1d *in3);
int futhark_entry_gather_payloads_short_GFUR(struct futhark_context *ctx, struct futhark_i16_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_i16_1d *in2, const struct futhark_i64_1d *in3, const struct futhark_i16_1d *in4);
int futhark_entry_inner_SMJ_double(struct futhark_context *ctx, struct futhark_opaque_joinPairs_double **out0, const struct futhark_f64_1d *in0, const struct futhark_f64_1d *in1, const int64_t in2, const int64_t in3, const int64_t in4, const int64_t in5, const int64_t in6, const int64_t in7);
int futhark_entry_inner_SMJ_float(struct futhark_context *ctx, struct futhark_opaque_joinPairs_float **out0, const struct futhark_f32_1d *in0, const struct futhark_f32_1d *in1, const int64_t in2, const int64_t in3, const int64_t in4, const int64_t in5, const int64_t in6, const int64_t in7);
int futhark_entry_inner_SMJ_int(struct futhark_context *ctx, struct futhark_opaque_joinPairs_int **out0, const struct futhark_i32_1d *in0, const struct futhark_i32_1d *in1, const int64_t in2, const int64_t in3, const int64_t in4, const int64_t in5, const int64_t in6, const int64_t in7);
int futhark_entry_inner_SMJ_long(struct futhark_context *ctx, struct futhark_opaque_joinPairs_long **out0, const struct futhark_i64_1d *in0, const struct futhark_i64_1d *in1, const int64_t in2, const int64_t in3, const int64_t in4, const int64_t in5, const int64_t in6, const int64_t in7);
int futhark_entry_inner_SMJ_short(struct futhark_context *ctx, struct futhark_opaque_joinPairs_short **out0, const struct futhark_i16_1d *in0, const struct futhark_i16_1d *in1, const int64_t in2, const int64_t in3, const int64_t in4, const int64_t in5, const int64_t in6, const int64_t in7);
int futhark_entry_max_idx(struct futhark_context *ctx, int64_t *out0, const struct futhark_i64_1d *in0);
int futhark_entry_min_idx(struct futhark_context *ctx, int64_t *out0, const struct futhark_i64_1d *in0);

// Miscellaneous
int futhark_context_sync(struct futhark_context *ctx);
void futhark_context_config_set_cache_file(struct futhark_context_config *cfg, const char *f);
char *futhark_context_get_error(struct futhark_context *ctx);
void futhark_context_set_logging_file(struct futhark_context *ctx, FILE *f);
void futhark_context_pause_profiling(struct futhark_context *ctx);
void futhark_context_unpause_profiling(struct futhark_context *ctx);
char *futhark_context_report(struct futhark_context *ctx);
int futhark_context_clear_caches(struct futhark_context *ctx);
#define FUTHARK_BACKEND_cuda
#define FUTHARK_SUCCESS 0
#define FUTHARK_PROGRAM_ERROR 2
#define FUTHARK_OUT_OF_MEMORY 3

#ifdef __cplusplus
}
#endif

#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <math.h>
#include <stdint.h>
// If NDEBUG is set, the assert() macro will do nothing. Since Futhark
// (unfortunately) makes use of assert() for error detection (and even some
// side effects), we want to avoid that.
#undef NDEBUG
#include <assert.h>
#include <stdarg.h>
#define SCALAR_FUN_ATTR static inline
// Start of util.h.
//
// Various helper functions that are useful in all generated C code.

#include <errno.h>
#include <string.h>

static const char *fut_progname = "(embedded Futhark)";

static void futhark_panic(int eval, const char *fmt, ...) __attribute__((noreturn));
static char* msgprintf(const char *s, ...);
static void* slurp_file(const char *filename, size_t *size);
static int dump_file(const char *file, const void *buf, size_t n);
struct str_builder;
static void str_builder_init(struct str_builder *b);
static void str_builder(struct str_builder *b, const char *s, ...);
static char *strclone(const char *str);

static void futhark_panic(int eval, const char *fmt, ...) {
  va_list ap;
  va_start(ap, fmt);
  fprintf(stderr, "%s: ", fut_progname);
  vfprintf(stderr, fmt, ap);
  va_end(ap);
  exit(eval);
}

// For generating arbitrary-sized error messages.  It is the callers
// responsibility to free the buffer at some point.
static char* msgprintf(const char *s, ...) {
  va_list vl;
  va_start(vl, s);
  size_t needed = 1 + (size_t)vsnprintf(NULL, 0, s, vl);
  char *buffer = (char*) malloc(needed);
  va_start(vl, s); // Must re-init.
  vsnprintf(buffer, needed, s, vl);
  return buffer;
}

static inline void check_err(int errval, int sets_errno, const char *fun, int line,
                             const char *msg, ...) {
  if (errval) {
    char errnum[10];

    va_list vl;
    va_start(vl, msg);

    fprintf(stderr, "ERROR: ");
    vfprintf(stderr, msg, vl);
    fprintf(stderr, " in %s() at line %d with error code %s\n",
            fun, line,
            sets_errno ? strerror(errno) : errnum);
    exit(errval);
  }
}

#define CHECK_ERR(err, ...) check_err(err, 0, __func__, __LINE__, __VA_ARGS__)
#define CHECK_ERRNO(err, ...) check_err(err, 1, __func__, __LINE__, __VA_ARGS__)

// Read the rest of an open file into a NUL-terminated string; returns
// NULL on error.
static void* fslurp_file(FILE *f, size_t *size) {
  long start = ftell(f);
  fseek(f, 0, SEEK_END);
  long src_size = ftell(f)-start;
  fseek(f, start, SEEK_SET);
  unsigned char *s = (unsigned char*) malloc((size_t)src_size + 1);
  if (fread(s, 1, (size_t)src_size, f) != (size_t)src_size) {
    free(s);
    s = NULL;
  } else {
    s[src_size] = '\0';
  }

  if (size) {
    *size = (size_t)src_size;
  }

  return s;
}

// Read a file into a NUL-terminated string; returns NULL on error.
static void* slurp_file(const char *filename, size_t *size) {
  FILE *f = fopen(filename, "rb"); // To avoid Windows messing with linebreaks.
  if (f == NULL) return NULL;
  unsigned char *s = fslurp_file(f, size);
  fclose(f);
  return s;
}

// Dump 'n' bytes from 'buf' into the file at the designated location.
// Returns 0 on success.
static int dump_file(const char *file, const void *buf, size_t n) {
  FILE *f = fopen(file, "w");

  if (f == NULL) {
    return 1;
  }

  if (fwrite(buf, sizeof(char), n, f) != n) {
    return 1;
  }

  if (fclose(f) != 0) {
    return 1;
  }

  return 0;
}

struct str_builder {
  char *str;
  size_t capacity; // Size of buffer.
  size_t used; // Bytes used, *not* including final zero.
};

static void str_builder_init(struct str_builder *b) {
  b->capacity = 10;
  b->used = 0;
  b->str = malloc(b->capacity);
  b->str[0] = 0;
}

static void str_builder(struct str_builder *b, const char *s, ...) {
  va_list vl;
  va_start(vl, s);
  size_t needed = (size_t)vsnprintf(NULL, 0, s, vl);

  while (b->capacity < b->used + needed + 1) {
    b->capacity *= 2;
    b->str = realloc(b->str, b->capacity);
  }

  va_start(vl, s); // Must re-init.
  vsnprintf(b->str+b->used, b->capacity-b->used, s, vl);
  b->used += needed;
}

static void str_builder_str(struct str_builder *b, const char *s) {
  size_t needed = strlen(s);
  if (b->capacity < b->used + needed + 1) {
    b->capacity *= 2;
    b->str = realloc(b->str, b->capacity);
  }
  strcpy(b->str+b->used, s);
  b->used += needed;
}

static void str_builder_char(struct str_builder *b, char c) {
  size_t needed = 1;
  if (b->capacity < b->used + needed + 1) {
    b->capacity *= 2;
    b->str = realloc(b->str, b->capacity);
  }
  b->str[b->used] = c;
  b->str[b->used+1] = 0;
  b->used += needed;
}

static void str_builder_json_str(struct str_builder* sb, const char* s) {
  str_builder_char(sb, '"');
  for (int j = 0; s[j]; j++) {
    char c = s[j];
    switch (c) {
    case '\n':
      str_builder_str(sb, "\\n");
      break;
    case '"':
      str_builder_str(sb, "\\\"");
      break;
    default:
      str_builder_char(sb, c);
    }
  }
  str_builder_char(sb, '"');
}

static char *strclone(const char *str) {
  size_t size = strlen(str) + 1;
  char *copy = (char*) malloc(size);
  if (copy == NULL) {
    return NULL;
  }

  memcpy(copy, str, size);
  return copy;
}

// Assumes NULL-terminated.
static char *strconcat(const char *src_fragments[]) {
  size_t src_len = 0;
  const char **p;

  for (p = src_fragments; *p; p++) {
    src_len += strlen(*p);
  }

  char *src = (char*) malloc(src_len + 1);
  size_t n = 0;
  for (p = src_fragments; *p; p++) {
    strcpy(src + n, *p);
    n += strlen(*p);
  }

  return src;
}

// End of util.h.
// Start of cache.h

#define CACHE_HASH_SIZE 8 // In 32-bit words.

struct cache_hash {
  uint32_t hash[CACHE_HASH_SIZE];
};

// Initialise a blank cache.
static void cache_hash_init(struct cache_hash *c);

// Hash some bytes and add them to the accumulated hash.
static void cache_hash(struct cache_hash *out, const char *in, size_t n);

// Try to restore cache contents from a file with the given name.
// Assumes the cache is invalid if it contains the given hash.
// Allocates memory and reads the cache conents, which is returned in
// *buf with size *buflen.  If the cache is successfully loaded, this
// function returns 0.  Otherwise it returns nonzero.  Errno is set if
// the failure to load the cache is due to anything except invalid
// cache conents.  Note that failing to restore the cache is not
// necessarily a problem: it might just be invalid or not created yet.
static int cache_restore(const char *fname, const struct cache_hash *hash,
                         unsigned char **buf, size_t *buflen);

// Store cache contents in the given file, with the given hash.
static int cache_store(const char *fname, const struct cache_hash *hash,
                       const unsigned char *buf, size_t buflen);

// Now for the implementation.

static void cache_hash_init(struct cache_hash *c) {
  memset(c->hash, 0, CACHE_HASH_SIZE * sizeof(uint32_t));
}

static void cache_hash(struct cache_hash *out, const char *in, size_t n) {
  // Adaptation of djb2 for larger output size by storing intermediate
  // states.
  uint32_t hash = 5381;
  for (size_t i = 0; i < n; i++) {
    hash = ((hash << 5) + hash) + in[i];
    out->hash[i % CACHE_HASH_SIZE] ^= hash;
  }
}

#define CACHE_HEADER_SIZE 8
static const char cache_header[CACHE_HEADER_SIZE] = "FUTHARK\0";

static int cache_restore(const char *fname, const struct cache_hash *hash,
                         unsigned char **buf, size_t *buflen) {
  FILE *f = fopen(fname, "rb");

  if (f == NULL) {
    return 1;
  }

  char f_header[CACHE_HEADER_SIZE];

  if (fread(f_header, sizeof(char), CACHE_HEADER_SIZE, f) != CACHE_HEADER_SIZE) {
    goto error;
  }

  if (memcmp(f_header, cache_header, CACHE_HEADER_SIZE) != 0) {
    goto error;
  }

  if (fseek(f, 0, SEEK_END) != 0) {
    goto error;
  }
  int64_t f_size = (int64_t)ftell(f);
  if (fseek(f, CACHE_HEADER_SIZE, SEEK_SET) != 0) {
    goto error;
  }

  int64_t expected_size;

  if (fread(&expected_size, sizeof(int64_t), 1, f) != 1) {
    goto error;
  }

  if (f_size != expected_size) {
    errno = 0;
    goto error;
  }

  int32_t f_hash[CACHE_HASH_SIZE];

  if (fread(f_hash, sizeof(int32_t), CACHE_HASH_SIZE, f) != CACHE_HASH_SIZE) {
    goto error;
  }

  if (memcmp(f_hash, hash->hash, CACHE_HASH_SIZE) != 0) {
    errno = 0;
    goto error;
  }

  *buflen = f_size - CACHE_HEADER_SIZE - sizeof(int64_t) - CACHE_HASH_SIZE*sizeof(int32_t);
  *buf = malloc(*buflen);
  if (fread(*buf, sizeof(char), *buflen, f) != *buflen) {
    free(*buf);
    goto error;
  }

  fclose(f);

  return 0;

 error:
  fclose(f);
  return 1;
}

static int cache_store(const char *fname, const struct cache_hash *hash,
                       const unsigned char *buf, size_t buflen) {
  FILE *f = fopen(fname, "wb");

  if (f == NULL) {
    return 1;
  }

  if (fwrite(cache_header, CACHE_HEADER_SIZE, 1, f) != 1) {
    goto error;
  }

  int64_t size = CACHE_HEADER_SIZE + sizeof(int64_t) + CACHE_HASH_SIZE*sizeof(int32_t) + buflen;

  if (fwrite(&size, sizeof(size), 1, f) != 1) {
    goto error;
  }

  if (fwrite(hash->hash, sizeof(int32_t), CACHE_HASH_SIZE, f) != CACHE_HASH_SIZE) {
    goto error;
  }

  if (fwrite(buf, sizeof(unsigned char), buflen, f) != buflen) {
    goto error;
  }

  fclose(f);

  return 0;

 error:
  fclose(f);
  return 1;
}

// End of cache.h
// Start of half.h.

// Conversion functions are from http://half.sourceforge.net/, but
// translated to C.
//
// Copyright (c) 2012-2021 Christian Rau
//
// Permission is hereby granted, free of charge, to any person obtaining a copy
// of this software and associated documentation files (the "Software"), to deal
// in the Software without restriction, including without limitation the rights
// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
// copies of the Software, and to permit persons to whom the Software is
// furnished to do so, subject to the following conditions:
//
// The above copyright notice and this permission notice shall be included in
// all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
// THE SOFTWARE.

#ifndef __OPENCL_VERSION__
#define __constant
#endif

__constant static const uint16_t base_table[512] = {
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0001, 0x0002, 0x0004, 0x0008, 0x0010, 0x0020, 0x0040, 0x0080, 0x0100,
  0x0200, 0x0400, 0x0800, 0x0C00, 0x1000, 0x1400, 0x1800, 0x1C00, 0x2000, 0x2400, 0x2800, 0x2C00, 0x3000, 0x3400, 0x3800, 0x3C00,
  0x4000, 0x4400, 0x4800, 0x4C00, 0x5000, 0x5400, 0x5800, 0x5C00, 0x6000, 0x6400, 0x6800, 0x6C00, 0x7000, 0x7400, 0x7800, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8001, 0x8002, 0x8004, 0x8008, 0x8010, 0x8020, 0x8040, 0x8080, 0x8100,
  0x8200, 0x8400, 0x8800, 0x8C00, 0x9000, 0x9400, 0x9800, 0x9C00, 0xA000, 0xA400, 0xA800, 0xAC00, 0xB000, 0xB400, 0xB800, 0xBC00,
  0xC000, 0xC400, 0xC800, 0xCC00, 0xD000, 0xD400, 0xD800, 0xDC00, 0xE000, 0xE400, 0xE800, 0xEC00, 0xF000, 0xF400, 0xF800, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00 };

__constant static const unsigned char shift_table[512] = {
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13 };

__constant static const uint32_t mantissa_table[2048] = {
  0x00000000, 0x33800000, 0x34000000, 0x34400000, 0x34800000, 0x34A00000, 0x34C00000, 0x34E00000, 0x35000000, 0x35100000, 0x35200000, 0x35300000, 0x35400000, 0x35500000, 0x35600000, 0x35700000,
  0x35800000, 0x35880000, 0x35900000, 0x35980000, 0x35A00000, 0x35A80000, 0x35B00000, 0x35B80000, 0x35C00000, 0x35C80000, 0x35D00000, 0x35D80000, 0x35E00000, 0x35E80000, 0x35F00000, 0x35F80000,
  0x36000000, 0x36040000, 0x36080000, 0x360C0000, 0x36100000, 0x36140000, 0x36180000, 0x361C0000, 0x36200000, 0x36240000, 0x36280000, 0x362C0000, 0x36300000, 0x36340000, 0x36380000, 0x363C0000,
  0x36400000, 0x36440000, 0x36480000, 0x364C0000, 0x36500000, 0x36540000, 0x36580000, 0x365C0000, 0x36600000, 0x36640000, 0x36680000, 0x366C0000, 0x36700000, 0x36740000, 0x36780000, 0x367C0000,
  0x36800000, 0x36820000, 0x36840000, 0x36860000, 0x36880000, 0x368A0000, 0x368C0000, 0x368E0000, 0x36900000, 0x36920000, 0x36940000, 0x36960000, 0x36980000, 0x369A0000, 0x369C0000, 0x369E0000,
  0x36A00000, 0x36A20000, 0x36A40000, 0x36A60000, 0x36A80000, 0x36AA0000, 0x36AC0000, 0x36AE0000, 0x36B00000, 0x36B20000, 0x36B40000, 0x36B60000, 0x36B80000, 0x36BA0000, 0x36BC0000, 0x36BE0000,
  0x36C00000, 0x36C20000, 0x36C40000, 0x36C60000, 0x36C80000, 0x36CA0000, 0x36CC0000, 0x36CE0000, 0x36D00000, 0x36D20000, 0x36D40000, 0x36D60000, 0x36D80000, 0x36DA0000, 0x36DC0000, 0x36DE0000,
  0x36E00000, 0x36E20000, 0x36E40000, 0x36E60000, 0x36E80000, 0x36EA0000, 0x36EC0000, 0x36EE0000, 0x36F00000, 0x36F20000, 0x36F40000, 0x36F60000, 0x36F80000, 0x36FA0000, 0x36FC0000, 0x36FE0000,
  0x37000000, 0x37010000, 0x37020000, 0x37030000, 0x37040000, 0x37050000, 0x37060000, 0x37070000, 0x37080000, 0x37090000, 0x370A0000, 0x370B0000, 0x370C0000, 0x370D0000, 0x370E0000, 0x370F0000,
  0x37100000, 0x37110000, 0x37120000, 0x37130000, 0x37140000, 0x37150000, 0x37160000, 0x37170000, 0x37180000, 0x37190000, 0x371A0000, 0x371B0000, 0x371C0000, 0x371D0000, 0x371E0000, 0x371F0000,
  0x37200000, 0x37210000, 0x37220000, 0x37230000, 0x37240000, 0x37250000, 0x37260000, 0x37270000, 0x37280000, 0x37290000, 0x372A0000, 0x372B0000, 0x372C0000, 0x372D0000, 0x372E0000, 0x372F0000,
  0x37300000, 0x37310000, 0x37320000, 0x37330000, 0x37340000, 0x37350000, 0x37360000, 0x37370000, 0x37380000, 0x37390000, 0x373A0000, 0x373B0000, 0x373C0000, 0x373D0000, 0x373E0000, 0x373F0000,
  0x37400000, 0x37410000, 0x37420000, 0x37430000, 0x37440000, 0x37450000, 0x37460000, 0x37470000, 0x37480000, 0x37490000, 0x374A0000, 0x374B0000, 0x374C0000, 0x374D0000, 0x374E0000, 0x374F0000,
  0x37500000, 0x37510000, 0x37520000, 0x37530000, 0x37540000, 0x37550000, 0x37560000, 0x37570000, 0x37580000, 0x37590000, 0x375A0000, 0x375B0000, 0x375C0000, 0x375D0000, 0x375E0000, 0x375F0000,
  0x37600000, 0x37610000, 0x37620000, 0x37630000, 0x37640000, 0x37650000, 0x37660000, 0x37670000, 0x37680000, 0x37690000, 0x376A0000, 0x376B0000, 0x376C0000, 0x376D0000, 0x376E0000, 0x376F0000,
  0x37700000, 0x37710000, 0x37720000, 0x37730000, 0x37740000, 0x37750000, 0x37760000, 0x37770000, 0x37780000, 0x37790000, 0x377A0000, 0x377B0000, 0x377C0000, 0x377D0000, 0x377E0000, 0x377F0000,
  0x37800000, 0x37808000, 0x37810000, 0x37818000, 0x37820000, 0x37828000, 0x37830000, 0x37838000, 0x37840000, 0x37848000, 0x37850000, 0x37858000, 0x37860000, 0x37868000, 0x37870000, 0x37878000,
  0x37880000, 0x37888000, 0x37890000, 0x37898000, 0x378A0000, 0x378A8000, 0x378B0000, 0x378B8000, 0x378C0000, 0x378C8000, 0x378D0000, 0x378D8000, 0x378E0000, 0x378E8000, 0x378F0000, 0x378F8000,
  0x37900000, 0x37908000, 0x37910000, 0x37918000, 0x37920000, 0x37928000, 0x37930000, 0x37938000, 0x37940000, 0x37948000, 0x37950000, 0x37958000, 0x37960000, 0x37968000, 0x37970000, 0x37978000,
  0x37980000, 0x37988000, 0x37990000, 0x37998000, 0x379A0000, 0x379A8000, 0x379B0000, 0x379B8000, 0x379C0000, 0x379C8000, 0x379D0000, 0x379D8000, 0x379E0000, 0x379E8000, 0x379F0000, 0x379F8000,
  0x37A00000, 0x37A08000, 0x37A10000, 0x37A18000, 0x37A20000, 0x37A28000, 0x37A30000, 0x37A38000, 0x37A40000, 0x37A48000, 0x37A50000, 0x37A58000, 0x37A60000, 0x37A68000, 0x37A70000, 0x37A78000,
  0x37A80000, 0x37A88000, 0x37A90000, 0x37A98000, 0x37AA0000, 0x37AA8000, 0x37AB0000, 0x37AB8000, 0x37AC0000, 0x37AC8000, 0x37AD0000, 0x37AD8000, 0x37AE0000, 0x37AE8000, 0x37AF0000, 0x37AF8000,
  0x37B00000, 0x37B08000, 0x37B10000, 0x37B18000, 0x37B20000, 0x37B28000, 0x37B30000, 0x37B38000, 0x37B40000, 0x37B48000, 0x37B50000, 0x37B58000, 0x37B60000, 0x37B68000, 0x37B70000, 0x37B78000,
  0x37B80000, 0x37B88000, 0x37B90000, 0x37B98000, 0x37BA0000, 0x37BA8000, 0x37BB0000, 0x37BB8000, 0x37BC0000, 0x37BC8000, 0x37BD0000, 0x37BD8000, 0x37BE0000, 0x37BE8000, 0x37BF0000, 0x37BF8000,
  0x37C00000, 0x37C08000, 0x37C10000, 0x37C18000, 0x37C20000, 0x37C28000, 0x37C30000, 0x37C38000, 0x37C40000, 0x37C48000, 0x37C50000, 0x37C58000, 0x37C60000, 0x37C68000, 0x37C70000, 0x37C78000,
  0x37C80000, 0x37C88000, 0x37C90000, 0x37C98000, 0x37CA0000, 0x37CA8000, 0x37CB0000, 0x37CB8000, 0x37CC0000, 0x37CC8000, 0x37CD0000, 0x37CD8000, 0x37CE0000, 0x37CE8000, 0x37CF0000, 0x37CF8000,
  0x37D00000, 0x37D08000, 0x37D10000, 0x37D18000, 0x37D20000, 0x37D28000, 0x37D30000, 0x37D38000, 0x37D40000, 0x37D48000, 0x37D50000, 0x37D58000, 0x37D60000, 0x37D68000, 0x37D70000, 0x37D78000,
  0x37D80000, 0x37D88000, 0x37D90000, 0x37D98000, 0x37DA0000, 0x37DA8000, 0x37DB0000, 0x37DB8000, 0x37DC0000, 0x37DC8000, 0x37DD0000, 0x37DD8000, 0x37DE0000, 0x37DE8000, 0x37DF0000, 0x37DF8000,
  0x37E00000, 0x37E08000, 0x37E10000, 0x37E18000, 0x37E20000, 0x37E28000, 0x37E30000, 0x37E38000, 0x37E40000, 0x37E48000, 0x37E50000, 0x37E58000, 0x37E60000, 0x37E68000, 0x37E70000, 0x37E78000,
  0x37E80000, 0x37E88000, 0x37E90000, 0x37E98000, 0x37EA0000, 0x37EA8000, 0x37EB0000, 0x37EB8000, 0x37EC0000, 0x37EC8000, 0x37ED0000, 0x37ED8000, 0x37EE0000, 0x37EE8000, 0x37EF0000, 0x37EF8000,
  0x37F00000, 0x37F08000, 0x37F10000, 0x37F18000, 0x37F20000, 0x37F28000, 0x37F30000, 0x37F38000, 0x37F40000, 0x37F48000, 0x37F50000, 0x37F58000, 0x37F60000, 0x37F68000, 0x37F70000, 0x37F78000,
  0x37F80000, 0x37F88000, 0x37F90000, 0x37F98000, 0x37FA0000, 0x37FA8000, 0x37FB0000, 0x37FB8000, 0x37FC0000, 0x37FC8000, 0x37FD0000, 0x37FD8000, 0x37FE0000, 0x37FE8000, 0x37FF0000, 0x37FF8000,
  0x38000000, 0x38004000, 0x38008000, 0x3800C000, 0x38010000, 0x38014000, 0x38018000, 0x3801C000, 0x38020000, 0x38024000, 0x38028000, 0x3802C000, 0x38030000, 0x38034000, 0x38038000, 0x3803C000,
  0x38040000, 0x38044000, 0x38048000, 0x3804C000, 0x38050000, 0x38054000, 0x38058000, 0x3805C000, 0x38060000, 0x38064000, 0x38068000, 0x3806C000, 0x38070000, 0x38074000, 0x38078000, 0x3807C000,
  0x38080000, 0x38084000, 0x38088000, 0x3808C000, 0x38090000, 0x38094000, 0x38098000, 0x3809C000, 0x380A0000, 0x380A4000, 0x380A8000, 0x380AC000, 0x380B0000, 0x380B4000, 0x380B8000, 0x380BC000,
  0x380C0000, 0x380C4000, 0x380C8000, 0x380CC000, 0x380D0000, 0x380D4000, 0x380D8000, 0x380DC000, 0x380E0000, 0x380E4000, 0x380E8000, 0x380EC000, 0x380F0000, 0x380F4000, 0x380F8000, 0x380FC000,
  0x38100000, 0x38104000, 0x38108000, 0x3810C000, 0x38110000, 0x38114000, 0x38118000, 0x3811C000, 0x38120000, 0x38124000, 0x38128000, 0x3812C000, 0x38130000, 0x38134000, 0x38138000, 0x3813C000,
  0x38140000, 0x38144000, 0x38148000, 0x3814C000, 0x38150000, 0x38154000, 0x38158000, 0x3815C000, 0x38160000, 0x38164000, 0x38168000, 0x3816C000, 0x38170000, 0x38174000, 0x38178000, 0x3817C000,
  0x38180000, 0x38184000, 0x38188000, 0x3818C000, 0x38190000, 0x38194000, 0x38198000, 0x3819C000, 0x381A0000, 0x381A4000, 0x381A8000, 0x381AC000, 0x381B0000, 0x381B4000, 0x381B8000, 0x381BC000,
  0x381C0000, 0x381C4000, 0x381C8000, 0x381CC000, 0x381D0000, 0x381D4000, 0x381D8000, 0x381DC000, 0x381E0000, 0x381E4000, 0x381E8000, 0x381EC000, 0x381F0000, 0x381F4000, 0x381F8000, 0x381FC000,
  0x38200000, 0x38204000, 0x38208000, 0x3820C000, 0x38210000, 0x38214000, 0x38218000, 0x3821C000, 0x38220000, 0x38224000, 0x38228000, 0x3822C000, 0x38230000, 0x38234000, 0x38238000, 0x3823C000,
  0x38240000, 0x38244000, 0x38248000, 0x3824C000, 0x38250000, 0x38254000, 0x38258000, 0x3825C000, 0x38260000, 0x38264000, 0x38268000, 0x3826C000, 0x38270000, 0x38274000, 0x38278000, 0x3827C000,
  0x38280000, 0x38284000, 0x38288000, 0x3828C000, 0x38290000, 0x38294000, 0x38298000, 0x3829C000, 0x382A0000, 0x382A4000, 0x382A8000, 0x382AC000, 0x382B0000, 0x382B4000, 0x382B8000, 0x382BC000,
  0x382C0000, 0x382C4000, 0x382C8000, 0x382CC000, 0x382D0000, 0x382D4000, 0x382D8000, 0x382DC000, 0x382E0000, 0x382E4000, 0x382E8000, 0x382EC000, 0x382F0000, 0x382F4000, 0x382F8000, 0x382FC000,
  0x38300000, 0x38304000, 0x38308000, 0x3830C000, 0x38310000, 0x38314000, 0x38318000, 0x3831C000, 0x38320000, 0x38324000, 0x38328000, 0x3832C000, 0x38330000, 0x38334000, 0x38338000, 0x3833C000,
  0x38340000, 0x38344000, 0x38348000, 0x3834C000, 0x38350000, 0x38354000, 0x38358000, 0x3835C000, 0x38360000, 0x38364000, 0x38368000, 0x3836C000, 0x38370000, 0x38374000, 0x38378000, 0x3837C000,
  0x38380000, 0x38384000, 0x38388000, 0x3838C000, 0x38390000, 0x38394000, 0x38398000, 0x3839C000, 0x383A0000, 0x383A4000, 0x383A8000, 0x383AC000, 0x383B0000, 0x383B4000, 0x383B8000, 0x383BC000,
  0x383C0000, 0x383C4000, 0x383C8000, 0x383CC000, 0x383D0000, 0x383D4000, 0x383D8000, 0x383DC000, 0x383E0000, 0x383E4000, 0x383E8000, 0x383EC000, 0x383F0000, 0x383F4000, 0x383F8000, 0x383FC000,
  0x38400000, 0x38404000, 0x38408000, 0x3840C000, 0x38410000, 0x38414000, 0x38418000, 0x3841C000, 0x38420000, 0x38424000, 0x38428000, 0x3842C000, 0x38430000, 0x38434000, 0x38438000, 0x3843C000,
  0x38440000, 0x38444000, 0x38448000, 0x3844C000, 0x38450000, 0x38454000, 0x38458000, 0x3845C000, 0x38460000, 0x38464000, 0x38468000, 0x3846C000, 0x38470000, 0x38474000, 0x38478000, 0x3847C000,
  0x38480000, 0x38484000, 0x38488000, 0x3848C000, 0x38490000, 0x38494000, 0x38498000, 0x3849C000, 0x384A0000, 0x384A4000, 0x384A8000, 0x384AC000, 0x384B0000, 0x384B4000, 0x384B8000, 0x384BC000,
  0x384C0000, 0x384C4000, 0x384C8000, 0x384CC000, 0x384D0000, 0x384D4000, 0x384D8000, 0x384DC000, 0x384E0000, 0x384E4000, 0x384E8000, 0x384EC000, 0x384F0000, 0x384F4000, 0x384F8000, 0x384FC000,
  0x38500000, 0x38504000, 0x38508000, 0x3850C000, 0x38510000, 0x38514000, 0x38518000, 0x3851C000, 0x38520000, 0x38524000, 0x38528000, 0x3852C000, 0x38530000, 0x38534000, 0x38538000, 0x3853C000,
  0x38540000, 0x38544000, 0x38548000, 0x3854C000, 0x38550000, 0x38554000, 0x38558000, 0x3855C000, 0x38560000, 0x38564000, 0x38568000, 0x3856C000, 0x38570000, 0x38574000, 0x38578000, 0x3857C000,
  0x38580000, 0x38584000, 0x38588000, 0x3858C000, 0x38590000, 0x38594000, 0x38598000, 0x3859C000, 0x385A0000, 0x385A4000, 0x385A8000, 0x385AC000, 0x385B0000, 0x385B4000, 0x385B8000, 0x385BC000,
  0x385C0000, 0x385C4000, 0x385C8000, 0x385CC000, 0x385D0000, 0x385D4000, 0x385D8000, 0x385DC000, 0x385E0000, 0x385E4000, 0x385E8000, 0x385EC000, 0x385F0000, 0x385F4000, 0x385F8000, 0x385FC000,
  0x38600000, 0x38604000, 0x38608000, 0x3860C000, 0x38610000, 0x38614000, 0x38618000, 0x3861C000, 0x38620000, 0x38624000, 0x38628000, 0x3862C000, 0x38630000, 0x38634000, 0x38638000, 0x3863C000,
  0x38640000, 0x38644000, 0x38648000, 0x3864C000, 0x38650000, 0x38654000, 0x38658000, 0x3865C000, 0x38660000, 0x38664000, 0x38668000, 0x3866C000, 0x38670000, 0x38674000, 0x38678000, 0x3867C000,
  0x38680000, 0x38684000, 0x38688000, 0x3868C000, 0x38690000, 0x38694000, 0x38698000, 0x3869C000, 0x386A0000, 0x386A4000, 0x386A8000, 0x386AC000, 0x386B0000, 0x386B4000, 0x386B8000, 0x386BC000,
  0x386C0000, 0x386C4000, 0x386C8000, 0x386CC000, 0x386D0000, 0x386D4000, 0x386D8000, 0x386DC000, 0x386E0000, 0x386E4000, 0x386E8000, 0x386EC000, 0x386F0000, 0x386F4000, 0x386F8000, 0x386FC000,
  0x38700000, 0x38704000, 0x38708000, 0x3870C000, 0x38710000, 0x38714000, 0x38718000, 0x3871C000, 0x38720000, 0x38724000, 0x38728000, 0x3872C000, 0x38730000, 0x38734000, 0x38738000, 0x3873C000,
  0x38740000, 0x38744000, 0x38748000, 0x3874C000, 0x38750000, 0x38754000, 0x38758000, 0x3875C000, 0x38760000, 0x38764000, 0x38768000, 0x3876C000, 0x38770000, 0x38774000, 0x38778000, 0x3877C000,
  0x38780000, 0x38784000, 0x38788000, 0x3878C000, 0x38790000, 0x38794000, 0x38798000, 0x3879C000, 0x387A0000, 0x387A4000, 0x387A8000, 0x387AC000, 0x387B0000, 0x387B4000, 0x387B8000, 0x387BC000,
  0x387C0000, 0x387C4000, 0x387C8000, 0x387CC000, 0x387D0000, 0x387D4000, 0x387D8000, 0x387DC000, 0x387E0000, 0x387E4000, 0x387E8000, 0x387EC000, 0x387F0000, 0x387F4000, 0x387F8000, 0x387FC000,
  0x38000000, 0x38002000, 0x38004000, 0x38006000, 0x38008000, 0x3800A000, 0x3800C000, 0x3800E000, 0x38010000, 0x38012000, 0x38014000, 0x38016000, 0x38018000, 0x3801A000, 0x3801C000, 0x3801E000,
  0x38020000, 0x38022000, 0x38024000, 0x38026000, 0x38028000, 0x3802A000, 0x3802C000, 0x3802E000, 0x38030000, 0x38032000, 0x38034000, 0x38036000, 0x38038000, 0x3803A000, 0x3803C000, 0x3803E000,
  0x38040000, 0x38042000, 0x38044000, 0x38046000, 0x38048000, 0x3804A000, 0x3804C000, 0x3804E000, 0x38050000, 0x38052000, 0x38054000, 0x38056000, 0x38058000, 0x3805A000, 0x3805C000, 0x3805E000,
  0x38060000, 0x38062000, 0x38064000, 0x38066000, 0x38068000, 0x3806A000, 0x3806C000, 0x3806E000, 0x38070000, 0x38072000, 0x38074000, 0x38076000, 0x38078000, 0x3807A000, 0x3807C000, 0x3807E000,
  0x38080000, 0x38082000, 0x38084000, 0x38086000, 0x38088000, 0x3808A000, 0x3808C000, 0x3808E000, 0x38090000, 0x38092000, 0x38094000, 0x38096000, 0x38098000, 0x3809A000, 0x3809C000, 0x3809E000,
  0x380A0000, 0x380A2000, 0x380A4000, 0x380A6000, 0x380A8000, 0x380AA000, 0x380AC000, 0x380AE000, 0x380B0000, 0x380B2000, 0x380B4000, 0x380B6000, 0x380B8000, 0x380BA000, 0x380BC000, 0x380BE000,
  0x380C0000, 0x380C2000, 0x380C4000, 0x380C6000, 0x380C8000, 0x380CA000, 0x380CC000, 0x380CE000, 0x380D0000, 0x380D2000, 0x380D4000, 0x380D6000, 0x380D8000, 0x380DA000, 0x380DC000, 0x380DE000,
  0x380E0000, 0x380E2000, 0x380E4000, 0x380E6000, 0x380E8000, 0x380EA000, 0x380EC000, 0x380EE000, 0x380F0000, 0x380F2000, 0x380F4000, 0x380F6000, 0x380F8000, 0x380FA000, 0x380FC000, 0x380FE000,
  0x38100000, 0x38102000, 0x38104000, 0x38106000, 0x38108000, 0x3810A000, 0x3810C000, 0x3810E000, 0x38110000, 0x38112000, 0x38114000, 0x38116000, 0x38118000, 0x3811A000, 0x3811C000, 0x3811E000,
  0x38120000, 0x38122000, 0x38124000, 0x38126000, 0x38128000, 0x3812A000, 0x3812C000, 0x3812E000, 0x38130000, 0x38132000, 0x38134000, 0x38136000, 0x38138000, 0x3813A000, 0x3813C000, 0x3813E000,
  0x38140000, 0x38142000, 0x38144000, 0x38146000, 0x38148000, 0x3814A000, 0x3814C000, 0x3814E000, 0x38150000, 0x38152000, 0x38154000, 0x38156000, 0x38158000, 0x3815A000, 0x3815C000, 0x3815E000,
  0x38160000, 0x38162000, 0x38164000, 0x38166000, 0x38168000, 0x3816A000, 0x3816C000, 0x3816E000, 0x38170000, 0x38172000, 0x38174000, 0x38176000, 0x38178000, 0x3817A000, 0x3817C000, 0x3817E000,
  0x38180000, 0x38182000, 0x38184000, 0x38186000, 0x38188000, 0x3818A000, 0x3818C000, 0x3818E000, 0x38190000, 0x38192000, 0x38194000, 0x38196000, 0x38198000, 0x3819A000, 0x3819C000, 0x3819E000,
  0x381A0000, 0x381A2000, 0x381A4000, 0x381A6000, 0x381A8000, 0x381AA000, 0x381AC000, 0x381AE000, 0x381B0000, 0x381B2000, 0x381B4000, 0x381B6000, 0x381B8000, 0x381BA000, 0x381BC000, 0x381BE000,
  0x381C0000, 0x381C2000, 0x381C4000, 0x381C6000, 0x381C8000, 0x381CA000, 0x381CC000, 0x381CE000, 0x381D0000, 0x381D2000, 0x381D4000, 0x381D6000, 0x381D8000, 0x381DA000, 0x381DC000, 0x381DE000,
  0x381E0000, 0x381E2000, 0x381E4000, 0x381E6000, 0x381E8000, 0x381EA000, 0x381EC000, 0x381EE000, 0x381F0000, 0x381F2000, 0x381F4000, 0x381F6000, 0x381F8000, 0x381FA000, 0x381FC000, 0x381FE000,
  0x38200000, 0x38202000, 0x38204000, 0x38206000, 0x38208000, 0x3820A000, 0x3820C000, 0x3820E000, 0x38210000, 0x38212000, 0x38214000, 0x38216000, 0x38218000, 0x3821A000, 0x3821C000, 0x3821E000,
  0x38220000, 0x38222000, 0x38224000, 0x38226000, 0x38228000, 0x3822A000, 0x3822C000, 0x3822E000, 0x38230000, 0x38232000, 0x38234000, 0x38236000, 0x38238000, 0x3823A000, 0x3823C000, 0x3823E000,
  0x38240000, 0x38242000, 0x38244000, 0x38246000, 0x38248000, 0x3824A000, 0x3824C000, 0x3824E000, 0x38250000, 0x38252000, 0x38254000, 0x38256000, 0x38258000, 0x3825A000, 0x3825C000, 0x3825E000,
  0x38260000, 0x38262000, 0x38264000, 0x38266000, 0x38268000, 0x3826A000, 0x3826C000, 0x3826E000, 0x38270000, 0x38272000, 0x38274000, 0x38276000, 0x38278000, 0x3827A000, 0x3827C000, 0x3827E000,
  0x38280000, 0x38282000, 0x38284000, 0x38286000, 0x38288000, 0x3828A000, 0x3828C000, 0x3828E000, 0x38290000, 0x38292000, 0x38294000, 0x38296000, 0x38298000, 0x3829A000, 0x3829C000, 0x3829E000,
  0x382A0000, 0x382A2000, 0x382A4000, 0x382A6000, 0x382A8000, 0x382AA000, 0x382AC000, 0x382AE000, 0x382B0000, 0x382B2000, 0x382B4000, 0x382B6000, 0x382B8000, 0x382BA000, 0x382BC000, 0x382BE000,
  0x382C0000, 0x382C2000, 0x382C4000, 0x382C6000, 0x382C8000, 0x382CA000, 0x382CC000, 0x382CE000, 0x382D0000, 0x382D2000, 0x382D4000, 0x382D6000, 0x382D8000, 0x382DA000, 0x382DC000, 0x382DE000,
  0x382E0000, 0x382E2000, 0x382E4000, 0x382E6000, 0x382E8000, 0x382EA000, 0x382EC000, 0x382EE000, 0x382F0000, 0x382F2000, 0x382F4000, 0x382F6000, 0x382F8000, 0x382FA000, 0x382FC000, 0x382FE000,
  0x38300000, 0x38302000, 0x38304000, 0x38306000, 0x38308000, 0x3830A000, 0x3830C000, 0x3830E000, 0x38310000, 0x38312000, 0x38314000, 0x38316000, 0x38318000, 0x3831A000, 0x3831C000, 0x3831E000,
  0x38320000, 0x38322000, 0x38324000, 0x38326000, 0x38328000, 0x3832A000, 0x3832C000, 0x3832E000, 0x38330000, 0x38332000, 0x38334000, 0x38336000, 0x38338000, 0x3833A000, 0x3833C000, 0x3833E000,
  0x38340000, 0x38342000, 0x38344000, 0x38346000, 0x38348000, 0x3834A000, 0x3834C000, 0x3834E000, 0x38350000, 0x38352000, 0x38354000, 0x38356000, 0x38358000, 0x3835A000, 0x3835C000, 0x3835E000,
  0x38360000, 0x38362000, 0x38364000, 0x38366000, 0x38368000, 0x3836A000, 0x3836C000, 0x3836E000, 0x38370000, 0x38372000, 0x38374000, 0x38376000, 0x38378000, 0x3837A000, 0x3837C000, 0x3837E000,
  0x38380000, 0x38382000, 0x38384000, 0x38386000, 0x38388000, 0x3838A000, 0x3838C000, 0x3838E000, 0x38390000, 0x38392000, 0x38394000, 0x38396000, 0x38398000, 0x3839A000, 0x3839C000, 0x3839E000,
  0x383A0000, 0x383A2000, 0x383A4000, 0x383A6000, 0x383A8000, 0x383AA000, 0x383AC000, 0x383AE000, 0x383B0000, 0x383B2000, 0x383B4000, 0x383B6000, 0x383B8000, 0x383BA000, 0x383BC000, 0x383BE000,
  0x383C0000, 0x383C2000, 0x383C4000, 0x383C6000, 0x383C8000, 0x383CA000, 0x383CC000, 0x383CE000, 0x383D0000, 0x383D2000, 0x383D4000, 0x383D6000, 0x383D8000, 0x383DA000, 0x383DC000, 0x383DE000,
  0x383E0000, 0x383E2000, 0x383E4000, 0x383E6000, 0x383E8000, 0x383EA000, 0x383EC000, 0x383EE000, 0x383F0000, 0x383F2000, 0x383F4000, 0x383F6000, 0x383F8000, 0x383FA000, 0x383FC000, 0x383FE000,
  0x38400000, 0x38402000, 0x38404000, 0x38406000, 0x38408000, 0x3840A000, 0x3840C000, 0x3840E000, 0x38410000, 0x38412000, 0x38414000, 0x38416000, 0x38418000, 0x3841A000, 0x3841C000, 0x3841E000,
  0x38420000, 0x38422000, 0x38424000, 0x38426000, 0x38428000, 0x3842A000, 0x3842C000, 0x3842E000, 0x38430000, 0x38432000, 0x38434000, 0x38436000, 0x38438000, 0x3843A000, 0x3843C000, 0x3843E000,
  0x38440000, 0x38442000, 0x38444000, 0x38446000, 0x38448000, 0x3844A000, 0x3844C000, 0x3844E000, 0x38450000, 0x38452000, 0x38454000, 0x38456000, 0x38458000, 0x3845A000, 0x3845C000, 0x3845E000,
  0x38460000, 0x38462000, 0x38464000, 0x38466000, 0x38468000, 0x3846A000, 0x3846C000, 0x3846E000, 0x38470000, 0x38472000, 0x38474000, 0x38476000, 0x38478000, 0x3847A000, 0x3847C000, 0x3847E000,
  0x38480000, 0x38482000, 0x38484000, 0x38486000, 0x38488000, 0x3848A000, 0x3848C000, 0x3848E000, 0x38490000, 0x38492000, 0x38494000, 0x38496000, 0x38498000, 0x3849A000, 0x3849C000, 0x3849E000,
  0x384A0000, 0x384A2000, 0x384A4000, 0x384A6000, 0x384A8000, 0x384AA000, 0x384AC000, 0x384AE000, 0x384B0000, 0x384B2000, 0x384B4000, 0x384B6000, 0x384B8000, 0x384BA000, 0x384BC000, 0x384BE000,
  0x384C0000, 0x384C2000, 0x384C4000, 0x384C6000, 0x384C8000, 0x384CA000, 0x384CC000, 0x384CE000, 0x384D0000, 0x384D2000, 0x384D4000, 0x384D6000, 0x384D8000, 0x384DA000, 0x384DC000, 0x384DE000,
  0x384E0000, 0x384E2000, 0x384E4000, 0x384E6000, 0x384E8000, 0x384EA000, 0x384EC000, 0x384EE000, 0x384F0000, 0x384F2000, 0x384F4000, 0x384F6000, 0x384F8000, 0x384FA000, 0x384FC000, 0x384FE000,
  0x38500000, 0x38502000, 0x38504000, 0x38506000, 0x38508000, 0x3850A000, 0x3850C000, 0x3850E000, 0x38510000, 0x38512000, 0x38514000, 0x38516000, 0x38518000, 0x3851A000, 0x3851C000, 0x3851E000,
  0x38520000, 0x38522000, 0x38524000, 0x38526000, 0x38528000, 0x3852A000, 0x3852C000, 0x3852E000, 0x38530000, 0x38532000, 0x38534000, 0x38536000, 0x38538000, 0x3853A000, 0x3853C000, 0x3853E000,
  0x38540000, 0x38542000, 0x38544000, 0x38546000, 0x38548000, 0x3854A000, 0x3854C000, 0x3854E000, 0x38550000, 0x38552000, 0x38554000, 0x38556000, 0x38558000, 0x3855A000, 0x3855C000, 0x3855E000,
  0x38560000, 0x38562000, 0x38564000, 0x38566000, 0x38568000, 0x3856A000, 0x3856C000, 0x3856E000, 0x38570000, 0x38572000, 0x38574000, 0x38576000, 0x38578000, 0x3857A000, 0x3857C000, 0x3857E000,
  0x38580000, 0x38582000, 0x38584000, 0x38586000, 0x38588000, 0x3858A000, 0x3858C000, 0x3858E000, 0x38590000, 0x38592000, 0x38594000, 0x38596000, 0x38598000, 0x3859A000, 0x3859C000, 0x3859E000,
  0x385A0000, 0x385A2000, 0x385A4000, 0x385A6000, 0x385A8000, 0x385AA000, 0x385AC000, 0x385AE000, 0x385B0000, 0x385B2000, 0x385B4000, 0x385B6000, 0x385B8000, 0x385BA000, 0x385BC000, 0x385BE000,
  0x385C0000, 0x385C2000, 0x385C4000, 0x385C6000, 0x385C8000, 0x385CA000, 0x385CC000, 0x385CE000, 0x385D0000, 0x385D2000, 0x385D4000, 0x385D6000, 0x385D8000, 0x385DA000, 0x385DC000, 0x385DE000,
  0x385E0000, 0x385E2000, 0x385E4000, 0x385E6000, 0x385E8000, 0x385EA000, 0x385EC000, 0x385EE000, 0x385F0000, 0x385F2000, 0x385F4000, 0x385F6000, 0x385F8000, 0x385FA000, 0x385FC000, 0x385FE000,
  0x38600000, 0x38602000, 0x38604000, 0x38606000, 0x38608000, 0x3860A000, 0x3860C000, 0x3860E000, 0x38610000, 0x38612000, 0x38614000, 0x38616000, 0x38618000, 0x3861A000, 0x3861C000, 0x3861E000,
  0x38620000, 0x38622000, 0x38624000, 0x38626000, 0x38628000, 0x3862A000, 0x3862C000, 0x3862E000, 0x38630000, 0x38632000, 0x38634000, 0x38636000, 0x38638000, 0x3863A000, 0x3863C000, 0x3863E000,
  0x38640000, 0x38642000, 0x38644000, 0x38646000, 0x38648000, 0x3864A000, 0x3864C000, 0x3864E000, 0x38650000, 0x38652000, 0x38654000, 0x38656000, 0x38658000, 0x3865A000, 0x3865C000, 0x3865E000,
  0x38660000, 0x38662000, 0x38664000, 0x38666000, 0x38668000, 0x3866A000, 0x3866C000, 0x3866E000, 0x38670000, 0x38672000, 0x38674000, 0x38676000, 0x38678000, 0x3867A000, 0x3867C000, 0x3867E000,
  0x38680000, 0x38682000, 0x38684000, 0x38686000, 0x38688000, 0x3868A000, 0x3868C000, 0x3868E000, 0x38690000, 0x38692000, 0x38694000, 0x38696000, 0x38698000, 0x3869A000, 0x3869C000, 0x3869E000,
  0x386A0000, 0x386A2000, 0x386A4000, 0x386A6000, 0x386A8000, 0x386AA000, 0x386AC000, 0x386AE000, 0x386B0000, 0x386B2000, 0x386B4000, 0x386B6000, 0x386B8000, 0x386BA000, 0x386BC000, 0x386BE000,
  0x386C0000, 0x386C2000, 0x386C4000, 0x386C6000, 0x386C8000, 0x386CA000, 0x386CC000, 0x386CE000, 0x386D0000, 0x386D2000, 0x386D4000, 0x386D6000, 0x386D8000, 0x386DA000, 0x386DC000, 0x386DE000,
  0x386E0000, 0x386E2000, 0x386E4000, 0x386E6000, 0x386E8000, 0x386EA000, 0x386EC000, 0x386EE000, 0x386F0000, 0x386F2000, 0x386F4000, 0x386F6000, 0x386F8000, 0x386FA000, 0x386FC000, 0x386FE000,
  0x38700000, 0x38702000, 0x38704000, 0x38706000, 0x38708000, 0x3870A000, 0x3870C000, 0x3870E000, 0x38710000, 0x38712000, 0x38714000, 0x38716000, 0x38718000, 0x3871A000, 0x3871C000, 0x3871E000,
  0x38720000, 0x38722000, 0x38724000, 0x38726000, 0x38728000, 0x3872A000, 0x3872C000, 0x3872E000, 0x38730000, 0x38732000, 0x38734000, 0x38736000, 0x38738000, 0x3873A000, 0x3873C000, 0x3873E000,
  0x38740000, 0x38742000, 0x38744000, 0x38746000, 0x38748000, 0x3874A000, 0x3874C000, 0x3874E000, 0x38750000, 0x38752000, 0x38754000, 0x38756000, 0x38758000, 0x3875A000, 0x3875C000, 0x3875E000,
  0x38760000, 0x38762000, 0x38764000, 0x38766000, 0x38768000, 0x3876A000, 0x3876C000, 0x3876E000, 0x38770000, 0x38772000, 0x38774000, 0x38776000, 0x38778000, 0x3877A000, 0x3877C000, 0x3877E000,
  0x38780000, 0x38782000, 0x38784000, 0x38786000, 0x38788000, 0x3878A000, 0x3878C000, 0x3878E000, 0x38790000, 0x38792000, 0x38794000, 0x38796000, 0x38798000, 0x3879A000, 0x3879C000, 0x3879E000,
  0x387A0000, 0x387A2000, 0x387A4000, 0x387A6000, 0x387A8000, 0x387AA000, 0x387AC000, 0x387AE000, 0x387B0000, 0x387B2000, 0x387B4000, 0x387B6000, 0x387B8000, 0x387BA000, 0x387BC000, 0x387BE000,
  0x387C0000, 0x387C2000, 0x387C4000, 0x387C6000, 0x387C8000, 0x387CA000, 0x387CC000, 0x387CE000, 0x387D0000, 0x387D2000, 0x387D4000, 0x387D6000, 0x387D8000, 0x387DA000, 0x387DC000, 0x387DE000,
  0x387E0000, 0x387E2000, 0x387E4000, 0x387E6000, 0x387E8000, 0x387EA000, 0x387EC000, 0x387EE000, 0x387F0000, 0x387F2000, 0x387F4000, 0x387F6000, 0x387F8000, 0x387FA000, 0x387FC000, 0x387FE000 };
__constant static const uint32_t exponent_table[64] = {
  0x00000000, 0x00800000, 0x01000000, 0x01800000, 0x02000000, 0x02800000, 0x03000000, 0x03800000, 0x04000000, 0x04800000, 0x05000000, 0x05800000, 0x06000000, 0x06800000, 0x07000000, 0x07800000,
  0x08000000, 0x08800000, 0x09000000, 0x09800000, 0x0A000000, 0x0A800000, 0x0B000000, 0x0B800000, 0x0C000000, 0x0C800000, 0x0D000000, 0x0D800000, 0x0E000000, 0x0E800000, 0x0F000000, 0x47800000,
  0x80000000, 0x80800000, 0x81000000, 0x81800000, 0x82000000, 0x82800000, 0x83000000, 0x83800000, 0x84000000, 0x84800000, 0x85000000, 0x85800000, 0x86000000, 0x86800000, 0x87000000, 0x87800000,
  0x88000000, 0x88800000, 0x89000000, 0x89800000, 0x8A000000, 0x8A800000, 0x8B000000, 0x8B800000, 0x8C000000, 0x8C800000, 0x8D000000, 0x8D800000, 0x8E000000, 0x8E800000, 0x8F000000, 0xC7800000 };
__constant static const unsigned short offset_table[64] = {
  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024,
  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024 };

SCALAR_FUN_ATTR uint16_t float2halfbits(float value) {
  union { float x; uint32_t y; } u;
  u.x = value;
  uint32_t bits = u.y;

  uint16_t hbits = base_table[bits>>23] + (uint16_t)((bits&0x7FFFFF)>>shift_table[bits>>23]);;

  return hbits;
}

SCALAR_FUN_ATTR float halfbits2float(uint16_t value) {
  uint32_t bits = mantissa_table[offset_table[value>>10]+(value&0x3FF)] + exponent_table[value>>10];

  union { uint32_t x; float y; } u;
  u.x = bits;
  return u.y;
}

SCALAR_FUN_ATTR uint16_t halfbitsnextafter(uint16_t from, uint16_t to) {
  int fabs = from & 0x7FFF, tabs = to & 0x7FFF;
  if(fabs > 0x7C00 || tabs > 0x7C00) {
    return ((from&0x7FFF)>0x7C00) ? (from|0x200) : (to|0x200);
  }
  if(from == to || !(fabs|tabs)) {
    return to;
  }
  if(!fabs) {
    return (to&0x8000)+1;
  }
  unsigned int out =
    from +
    (((from>>15)^(unsigned int)((from^(0x8000|(0x8000-(from>>15))))<(to^(0x8000|(0x8000-(to>>15))))))<<1)
    - 1;
  return out;
}

// End of half.h.
// Start of timing.h.

// The function get_wall_time() returns the wall time in microseconds
// (with an unspecified offset).

#ifdef _WIN32

#include <windows.h>

static int64_t get_wall_time(void) {
  LARGE_INTEGER time,freq;
  assert(QueryPerformanceFrequency(&freq));
  assert(QueryPerformanceCounter(&time));
  return ((double)time.QuadPart / freq.QuadPart) * 1000000;
}

static int64_t get_wall_time_ns(void) {
  return get_wall_time() * 1000;
}

#else
// Assuming POSIX

#include <time.h>
#include <sys/time.h>

static int64_t get_wall_time(void) {
  struct timeval time;
  assert(gettimeofday(&time,NULL) == 0);
  return time.tv_sec * 1000000 + time.tv_usec;
}

static int64_t get_wall_time_ns(void) {
  struct timespec time;
  assert(clock_gettime(CLOCK_REALTIME, &time) == 0);
  return time.tv_sec * 1000000000 + time.tv_nsec;
}

#endif

// End of timing.h.
// Start of lock.h.

// A very simple cross-platform implementation of locks.  Uses
// pthreads on Unix and some Windows thing there.  Futhark's
// host-level code is not multithreaded, but user code may be, so we
// need some mechanism for ensuring atomic access to API functions.
// This is that mechanism.  It is not exposed to user code at all, so
// we do not have to worry about name collisions.

#ifdef _WIN32

typedef HANDLE lock_t;

static void create_lock(lock_t *lock) {
  *lock = CreateMutex(NULL,  // Default security attributes.
                      FALSE, // Initially unlocked.
                      NULL); // Unnamed.
}

static void lock_lock(lock_t *lock) {
  assert(WaitForSingleObject(*lock, INFINITE) == WAIT_OBJECT_0);
}

static void lock_unlock(lock_t *lock) {
  assert(ReleaseMutex(*lock));
}

static void free_lock(lock_t *lock) {
  CloseHandle(*lock);
}

#else
// Assuming POSIX

#include <pthread.h>

typedef pthread_mutex_t lock_t;

static void create_lock(lock_t *lock) {
  int r = pthread_mutex_init(lock, NULL);
  assert(r == 0);
}

static void lock_lock(lock_t *lock) {
  int r = pthread_mutex_lock(lock);
  assert(r == 0);
}

static void lock_unlock(lock_t *lock) {
  int r = pthread_mutex_unlock(lock);
  assert(r == 0);
}

static void free_lock(lock_t *lock) {
  // Nothing to do for pthreads.
  (void)lock;
}

#endif

// End of lock.h.
// Start of free_list.h.

typedef uintptr_t fl_mem;

// An entry in the free list.  May be invalid, to avoid having to
// deallocate entries as soon as they are removed.  There is also a
// tag, to help with memory reuse.
struct free_list_entry {
  size_t size;
  fl_mem mem;
  const char *tag;
  unsigned char valid;
};

struct free_list {
  struct free_list_entry *entries; // Pointer to entries.
  int capacity;                    // Number of entries.
  int used;                        // Number of valid entries.
  lock_t lock;                     // Thread safety.
};

static void free_list_init(struct free_list *l) {
  l->capacity = 30; // Picked arbitrarily.
  l->used = 0;
  l->entries = (struct free_list_entry*) malloc(sizeof(struct free_list_entry) * l->capacity);
  for (int i = 0; i < l->capacity; i++) {
    l->entries[i].valid = 0;
  }
  create_lock(&l->lock);
}

// Remove invalid entries from the free list.
static void free_list_pack(struct free_list *l) {
  lock_lock(&l->lock);
  int p = 0;
  for (int i = 0; i < l->capacity; i++) {
    if (l->entries[i].valid) {
      l->entries[p] = l->entries[i];
      if (i > p) {
        l->entries[i].valid = 0;
      }
      p++;
    }
  }

  // Now p is the number of used elements.  We don't want it to go
  // less than the default capacity (although in practice it's OK as
  // long as it doesn't become 1).
  if (p < 30) {
    p = 30;
  }
  l->entries = realloc(l->entries, p * sizeof(struct free_list_entry));
  l->capacity = p;
  lock_unlock(&l->lock);
}

static void free_list_destroy(struct free_list *l) {
  assert(l->used == 0);
  free(l->entries);
  free_lock(&l->lock);
}

// Not part of the interface, so no locking.
static int free_list_find_invalid(struct free_list *l) {
  int i;
  for (i = 0; i < l->capacity; i++) {
    if (!l->entries[i].valid) {
      break;
    }
  }
  return i;
}

static void free_list_insert(struct free_list *l, size_t size, fl_mem mem, const char *tag) {
  lock_lock(&l->lock);
  int i = free_list_find_invalid(l);

  if (i == l->capacity) {
    // List is full; so we have to grow it.
    int new_capacity = l->capacity * 2 * sizeof(struct free_list_entry);
    l->entries = realloc(l->entries, new_capacity);
    for (int j = 0; j < l->capacity; j++) {
      l->entries[j+l->capacity].valid = 0;
    }
    l->capacity *= 2;
  }

  // Now 'i' points to the first invalid entry.
  l->entries[i].valid = 1;
  l->entries[i].size = size;
  l->entries[i].mem = mem;
  l->entries[i].tag = tag;

  l->used++;
  lock_unlock(&l->lock);
}

// Determine whether this entry in the free list is acceptable for
// satisfying the request.  Not public, so no locking.
static bool free_list_acceptable(size_t size, const char* tag, struct free_list_entry *entry) {
  // We check not just the hard requirement (is the entry acceptable
  // and big enough?) but also put a cap on how much wasted space
  // (internal fragmentation) we allow.  This is necessarily a
  // heuristic, and a crude one.

  if (!entry->valid) {
    return false;
  }

  if (size > entry->size) {
    return false;
  }

  // We know the block fits.  Now the question is whether it is too
  // big.  Our policy is as follows:
  //
  // 1) We don't care about wasted space below 4096 bytes (to avoid
  // churn in tiny allocations).
  //
  // 2) If the tag matches, we allow _any_ amount of wasted space.
  //
  // 3) Otherwise we allow up to 50% wasted space.

  if (entry->size < 4096) {
    return true;
  }

  if (entry->tag == tag) {
    return true;
  }

  if (entry->size < size * 2) {
    return true;
  }

  return false;
}

// Find and remove a memory block of the indicated tag, or if that
// does not exist, another memory block with exactly the desired size.
// Returns 0 on success.
static int free_list_find(struct free_list *l, size_t size, const char *tag,
                          size_t *size_out, fl_mem *mem_out) {
  lock_lock(&l->lock);
  int size_match = -1;
  int i;
  int ret = 1;
  for (i = 0; i < l->capacity; i++) {
    if (free_list_acceptable(size, tag, &l->entries[i]) &&
        (size_match < 0 || l->entries[i].size < l->entries[size_match].size)) {
      // If this entry is valid, has sufficient size, and is smaller than the
      // best entry found so far, use this entry.
      size_match = i;
    }
  }

  if (size_match >= 0) {
    l->entries[size_match].valid = 0;
    *size_out = l->entries[size_match].size;
    *mem_out = l->entries[size_match].mem;
    l->used--;
    ret = 0;
  }
  lock_unlock(&l->lock);
  return ret;
}

// Remove the first block in the free list.  Returns 0 if a block was
// removed, and nonzero if the free list was already empty.
static int free_list_first(struct free_list *l, fl_mem *mem_out) {
  lock_lock(&l->lock);
  int ret = 1;
  for (int i = 0; i < l->capacity; i++) {
    if (l->entries[i].valid) {
      l->entries[i].valid = 0;
      *mem_out = l->entries[i].mem;
      l->used--;
      ret = 0;
      break;
    }
  }
  lock_unlock(&l->lock);
  return ret;
}

// End of free_list.h.
// Start of event_list.h

typedef int (*event_report_fn)(struct str_builder*, void*);

struct event {
  void* data;
  event_report_fn f;
  const char* name;
  char *description;
};

struct event_list {
  struct event *events;
  int num_events;
  int capacity;
};

static void event_list_init(struct event_list *l) {
  l->capacity = 100;
  l->num_events = 0;
  l->events = calloc(l->capacity, sizeof(struct event));
}

static void event_list_free(struct event_list *l) {
  free(l->events);
}

static void add_event_to_list(struct event_list *l,
                              const char* name,
                              char* description,
                              void* data,
                              event_report_fn f) {
  if (l->num_events == l->capacity) {
    l->capacity *= 2;
    l->events = realloc(l->events, l->capacity * sizeof(struct event));
  }
  l->events[l->num_events].name = name;
  l->events[l->num_events].description = description;
  l->events[l->num_events].data = data;
  l->events[l->num_events].f = f;
  l->num_events++;
}

static int report_events_in_list(struct event_list *l,
                                 struct str_builder* sb) {
  int ret = 0;
  for (int i = 0; i < l->num_events; i++) {
    if (i != 0) {
      str_builder_str(sb, ",");
    }
    str_builder_str(sb, "{\"name\":");
    str_builder_json_str(sb, l->events[i].name);
    str_builder_str(sb, ",\"description\":");
    str_builder_json_str(sb, l->events[i].description);
    free(l->events[i].description);
    if (l->events[i].f(sb, l->events[i].data) != 0) {
      ret = 1;
      break;
    }
    str_builder(sb, "}");
  }
  event_list_free(l);
  event_list_init(l);
  return ret;
}

// End of event_list.h

#ifdef _MSC_VER
#define inline __inline
#endif
#include <string.h>
#include <string.h>
#include <errno.h>
#include <assert.h>
#include <ctype.h>


#include <cuda.h>
#include <cuda_runtime.h>
#include <nvrtc.h>


#define FUTHARK_F64_ENABLED

// Start of scalar.h.

// Implementation of the primitive scalar operations.  Very
// repetitive.  This code is inserted directly into both CUDA and
// OpenCL programs, as well as the CPU code, so it has some #ifdefs to
// work everywhere.  Some operations are defined as macros because
// this allows us to use them as constant expressions in things like
// array sizes and static initialisers.

// Some of the #ifdefs are because OpenCL uses type-generic functions
// for some operations (e.g. sqrt), while C and CUDA sensibly use
// distinct functions for different precisions (e.g. sqrtf() and
// sqrt()).  This is quite annoying.  Due to C's unfortunate casting
// rules, it is also really easy to accidentally implement
// floating-point functions in the wrong precision, so be careful.

// Double-precision definitions are only included if the preprocessor
// macro FUTHARK_F64_ENABLED is set.

SCALAR_FUN_ATTR int32_t futrts_to_bits32(float x);
SCALAR_FUN_ATTR float futrts_from_bits32(int32_t x);

SCALAR_FUN_ATTR uint8_t add8(uint8_t x, uint8_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint16_t add16(uint16_t x, uint16_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint32_t add32(uint32_t x, uint32_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint64_t add64(uint64_t x, uint64_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint8_t sub8(uint8_t x, uint8_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint16_t sub16(uint16_t x, uint16_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint32_t sub32(uint32_t x, uint32_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint64_t sub64(uint64_t x, uint64_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint8_t mul8(uint8_t x, uint8_t y) {
  return x * y;
}

SCALAR_FUN_ATTR uint16_t mul16(uint16_t x, uint16_t y) {
  return x * y;
}

SCALAR_FUN_ATTR uint32_t mul32(uint32_t x, uint32_t y) {
  return x * y;
}

SCALAR_FUN_ATTR uint64_t mul64(uint64_t x, uint64_t y) {
  return x * y;
}

#if ISPC

SCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {
  // This strange pattern is used to prevent the ISPC compiler from
  // causing SIGFPEs and bogus results on divisions where inactive lanes
  // have 0-valued divisors. It ensures that any inactive lane instead
  // has a divisor of 1. https://github.com/ispc/ispc/issues/2292
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return x / ys;
}

SCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return x / ys;
}

SCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return x % ys;
}

SCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int8_t q = x / ys;
  int8_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int16_t q = x / ys;
  int16_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  int32_t q = x / ys;
  int32_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int64_t q = x / ys;
  int64_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {
  return sdiv8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {
  return sdiv16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {
  return sdiv32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {
  return sdiv64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int8_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int16_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int32_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int64_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : sdiv8(x, y);
}

SCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : sdiv16(x, y);
}

SCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : sdiv32(x, y);
}

SCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : sdiv64(x, y);
}

SCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {
  return sdiv_safe8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {
  return sdiv_safe16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {
  return sdiv_safe32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {
  return sdiv_safe64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : smod8(x, y);
}

SCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : smod16(x, y);
}

SCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : smod32(x, y);
}

SCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : smod64(x, y);
}

SCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

#else

SCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {
  int8_t q = x / y;
  int8_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {
  int16_t q = x / y;
  int16_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {
  int32_t q = x / y;
  int32_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {
  int64_t q = x / y;
  int64_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {
  return sdiv8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {
  return sdiv16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {
  return sdiv32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {
  return sdiv64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {
  int8_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {
  int16_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {
  int32_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {
  int64_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : sdiv8(x, y);
}

SCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : sdiv16(x, y);
}

SCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : sdiv32(x, y);
}

SCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : sdiv64(x, y);
}

SCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {
  return sdiv_safe8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {
  return sdiv_safe16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {
  return sdiv_safe32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {
  return sdiv_safe64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : smod8(x, y);
}

SCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : smod16(x, y);
}

SCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : smod32(x, y);
}

SCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : smod64(x, y);
}

SCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : x % y;
}

#endif

SCALAR_FUN_ATTR int8_t smin8(int8_t x, int8_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int16_t smin16(int16_t x, int16_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int32_t smin32(int32_t x, int32_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int64_t smin64(int64_t x, int64_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint8_t umin8(uint8_t x, uint8_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint16_t umin16(uint16_t x, uint16_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint32_t umin32(uint32_t x, uint32_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint64_t umin64(uint64_t x, uint64_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int8_t smax8(int8_t x, int8_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR int16_t smax16(int16_t x, int16_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR int32_t smax32(int32_t x, int32_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR int64_t smax64(int64_t x, int64_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint8_t umax8(uint8_t x, uint8_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint16_t umax16(uint16_t x, uint16_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint32_t umax32(uint32_t x, uint32_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint64_t umax64(uint64_t x, uint64_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint8_t shl8(uint8_t x, uint8_t y) {
  return (uint8_t)(x << y);
}

SCALAR_FUN_ATTR uint16_t shl16(uint16_t x, uint16_t y) {
  return (uint16_t)(x << y);
}

SCALAR_FUN_ATTR uint32_t shl32(uint32_t x, uint32_t y) {
  return x << y;
}

SCALAR_FUN_ATTR uint64_t shl64(uint64_t x, uint64_t y) {
  return x << y;
}

SCALAR_FUN_ATTR uint8_t lshr8(uint8_t x, uint8_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint16_t lshr16(uint16_t x, uint16_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint32_t lshr32(uint32_t x, uint32_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint64_t lshr64(uint64_t x, uint64_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int8_t ashr8(int8_t x, int8_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int16_t ashr16(int16_t x, int16_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int32_t ashr32(int32_t x, int32_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int64_t ashr64(int64_t x, int64_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint8_t and8(uint8_t x, uint8_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint16_t and16(uint16_t x, uint16_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint32_t and32(uint32_t x, uint32_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint64_t and64(uint64_t x, uint64_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint8_t or8(uint8_t x, uint8_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint16_t or16(uint16_t x, uint16_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint32_t or32(uint32_t x, uint32_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint64_t or64(uint64_t x, uint64_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint8_t xor8(uint8_t x, uint8_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR uint16_t xor16(uint16_t x, uint16_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR uint32_t xor32(uint32_t x, uint32_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR uint64_t xor64(uint64_t x, uint64_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR bool ult8(uint8_t x, uint8_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ult16(uint16_t x, uint16_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ult32(uint32_t x, uint32_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ult64(uint64_t x, uint64_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ule8(uint8_t x, uint8_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool ule16(uint16_t x, uint16_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool ule32(uint32_t x, uint32_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool ule64(uint64_t x, uint64_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool slt8(int8_t x, int8_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool slt16(int16_t x, int16_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool slt32(int32_t x, int32_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool slt64(int64_t x, int64_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool sle8(int8_t x, int8_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool sle16(int16_t x, int16_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool sle32(int32_t x, int32_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool sle64(int64_t x, int64_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR uint8_t pow8(uint8_t x, uint8_t y) {
  uint8_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint16_t pow16(uint16_t x, uint16_t y) {
  uint16_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint32_t pow32(uint32_t x, uint32_t y) {
  uint32_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint64_t pow64(uint64_t x, uint64_t y) {
  uint64_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR bool itob_i8_bool(int8_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR bool itob_i16_bool(int16_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR bool itob_i32_bool(int32_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR bool itob_i64_bool(int64_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR int8_t btoi_bool_i8(bool x) {
  return x;
}

SCALAR_FUN_ATTR int16_t btoi_bool_i16(bool x) {
  return x;
}

SCALAR_FUN_ATTR int32_t btoi_bool_i32(bool x) {
  return x;
}

SCALAR_FUN_ATTR int64_t btoi_bool_i64(bool x) {
  return x;
}

#define sext_i8_i8(x) ((int8_t) (int8_t) (x))
#define sext_i8_i16(x) ((int16_t) (int8_t) (x))
#define sext_i8_i32(x) ((int32_t) (int8_t) (x))
#define sext_i8_i64(x) ((int64_t) (int8_t) (x))
#define sext_i16_i8(x) ((int8_t) (int16_t) (x))
#define sext_i16_i16(x) ((int16_t) (int16_t) (x))
#define sext_i16_i32(x) ((int32_t) (int16_t) (x))
#define sext_i16_i64(x) ((int64_t) (int16_t) (x))
#define sext_i32_i8(x) ((int8_t) (int32_t) (x))
#define sext_i32_i16(x) ((int16_t) (int32_t) (x))
#define sext_i32_i32(x) ((int32_t) (int32_t) (x))
#define sext_i32_i64(x) ((int64_t) (int32_t) (x))
#define sext_i64_i8(x) ((int8_t) (int64_t) (x))
#define sext_i64_i16(x) ((int16_t) (int64_t) (x))
#define sext_i64_i32(x) ((int32_t) (int64_t) (x))
#define sext_i64_i64(x) ((int64_t) (int64_t) (x))
#define zext_i8_i8(x) ((int8_t) (uint8_t) (x))
#define zext_i8_i16(x) ((int16_t) (uint8_t) (x))
#define zext_i8_i32(x) ((int32_t) (uint8_t) (x))
#define zext_i8_i64(x) ((int64_t) (uint8_t) (x))
#define zext_i16_i8(x) ((int8_t) (uint16_t) (x))
#define zext_i16_i16(x) ((int16_t) (uint16_t) (x))
#define zext_i16_i32(x) ((int32_t) (uint16_t) (x))
#define zext_i16_i64(x) ((int64_t) (uint16_t) (x))
#define zext_i32_i8(x) ((int8_t) (uint32_t) (x))
#define zext_i32_i16(x) ((int16_t) (uint32_t) (x))
#define zext_i32_i32(x) ((int32_t) (uint32_t) (x))
#define zext_i32_i64(x) ((int64_t) (uint32_t) (x))
#define zext_i64_i8(x) ((int8_t) (uint64_t) (x))
#define zext_i64_i16(x) ((int16_t) (uint64_t) (x))
#define zext_i64_i32(x) ((int32_t) (uint64_t) (x))
#define zext_i64_i64(x) ((int64_t) (uint64_t) (x))

SCALAR_FUN_ATTR int8_t abs8(int8_t x) {
  return (int8_t)abs(x);
}

SCALAR_FUN_ATTR int16_t abs16(int16_t x) {
  return (int16_t)abs(x);
}

SCALAR_FUN_ATTR int32_t abs32(int32_t x) {
  return abs(x);
}

SCALAR_FUN_ATTR int64_t abs64(int64_t x) {
#if defined(__OPENCL_VERSION__) || defined(ISPC)
  return abs(x);
#else
  return llabs(x);
#endif
}

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {
  return popcount(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {
  return popcount(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {
  return popcount(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {
  return popcount(x);
}
#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {
  return __popc(zext_i8_i32(x));
}

SCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {
  return __popc(zext_i16_i32(x));
}

SCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {
  return __popc(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {
  return __popcll(x);
}

#else // Not OpenCL or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_popc8(uint8_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc16(uint16_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc32(uint32_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc64(uint64_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR uint8_t  futrts_umul_hi8 ( uint8_t a,  uint8_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint8_t  futrts_smul_hi8 ( int8_t a,  int8_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return mul_hi(a, b); }
#elif defined(__CUDA_ARCH__)
SCALAR_FUN_ATTR  uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return __umulhi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return __umul64hi(a, b); }
SCALAR_FUN_ATTR  uint8_t futrts_smul_hi8 ( int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return __mulhi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return __mul64hi(a, b); }
#elif ISPC
SCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) {
  uint64_t ah = a >> 32;
  uint64_t al = a & 0xffffffff;
  uint64_t bh = b >> 32;
  uint64_t bl = b & 0xffffffff;

  uint64_t p1 = al * bl;
  uint64_t p2 = al * bh;
  uint64_t p3 = ah * bl;
  uint64_t p4 = ah * bh;

  uint64_t p1h = p1 >> 32;
  uint64_t p2h = p2 >> 32;
  uint64_t p3h = p3 >> 32;
  uint64_t p2l = p2 & 0xffffffff;
  uint64_t p3l = p3 & 0xffffffff;

  uint64_t l = p1h + p2l + p3l;
  uint64_t m = (p2 >> 32) + (p3 >> 32);
  uint64_t h = (l >> 32) + m + p4;

  return h;
}
SCALAR_FUN_ATTR  int8_t futrts_smul_hi8 ( int8_t a,  int8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) {
  uint64_t ah = a >> 32;
  uint64_t al = a & 0xffffffff;
  uint64_t bh = b >> 32;
  uint64_t bl = b & 0xffffffff;

  uint64_t p1 =  al * bl;
  int64_t  p2 = al * bh;
  int64_t  p3 = ah * bl;
  uint64_t p4 =  ah * bh;

  uint64_t p1h = p1 >> 32;
  uint64_t p2h = p2 >> 32;
  uint64_t p3h = p3 >> 32;
  uint64_t p2l = p2 & 0xffffffff;
  uint64_t p3l = p3 & 0xffffffff;

  uint64_t l = p1h + p2l + p3l;
  uint64_t m = (p2 >> 32) + (p3 >> 32);
  uint64_t h = (l >> 32) + m + p4;

  return h;
}

#else // Not OpenCL, ISPC, or CUDA, but plain C.
SCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return ((__uint128_t)a) * ((__uint128_t)b) >> 64; }
SCALAR_FUN_ATTR int8_t futrts_smul_hi8(int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }
SCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }
SCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((int64_t)a) * ((int64_t)b) >> 32; }
SCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) { return ((__int128_t)a) * ((__int128_t)b) >> 64; }
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR  uint8_t futrts_umad_hi8 ( uint8_t a,  uint8_t b,  uint8_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR  uint8_t futrts_smad_hi8( int8_t a,  int8_t b,   int8_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return mad_hi(a, b, c); }
#else // Not OpenCL

SCALAR_FUN_ATTR  uint8_t futrts_umad_hi8( uint8_t a,  uint8_t b,  uint8_t c) { return futrts_umul_hi8(a, b) + c; }
SCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return futrts_umul_hi16(a, b) + c; }
SCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return futrts_umul_hi32(a, b) + c; }
SCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return futrts_umul_hi64(a, b) + c; }
SCALAR_FUN_ATTR  uint8_t futrts_smad_hi8 ( int8_t a,  int8_t b,  int8_t c) { return futrts_smul_hi8(a, b) + c; }
SCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return futrts_smul_hi16(a, b) + c; }
SCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return futrts_smul_hi32(a, b) + c; }
SCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return futrts_smul_hi64(a, b) + c; }
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return clz(x);
}

#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return __clz(zext_i8_i32(x)) - 24;
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return __clz(zext_i16_i32(x)) - 16;
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return __clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return __clzll(x);
}

#elif ISPC

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return count_leading_zeros((int32_t)(uint8_t)x)-24;
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return count_leading_zeros((int32_t)(uint16_t)x)-16;
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return count_leading_zeros(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return count_leading_zeros(x);
}

#else // Not OpenCL, ISPC or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return x == 0 ? 8 : __builtin_clz((uint32_t)zext_i8_i32(x)) - 24;
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return x == 0 ? 16 : __builtin_clz((uint32_t)zext_i16_i32(x)) - 16;
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return x == 0 ? 32 : __builtin_clz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return x == 0 ? 64 : __builtin_clzll((uint64_t)x);
}
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  int i = 0;
  for (; i < 8 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  int i = 0;
  for (; i < 16 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  int i = 0;
  for (; i < 32 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  int i = 0;
  for (; i < 64 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  int y = __ffs(x);
  return y == 0 ? 8 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  int y = __ffs(x);
  return y == 0 ? 16 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  int y = __ffs(x);
  return y == 0 ? 32 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  int y = __ffsll(x);
  return y == 0 ? 64 : y - 1;
}

#elif ISPC

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  return x == 0 ? 8 : count_trailing_zeros((int32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  return x == 0 ? 16 : count_trailing_zeros((int32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  return count_trailing_zeros(x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  return count_trailing_zeros(x);
}

#else // Not OpenCL or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  return x == 0 ? 8 : __builtin_ctz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  return x == 0 ? 16 : __builtin_ctz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  return x == 0 ? 32 : __builtin_ctz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  return x == 0 ? 64 : __builtin_ctzll((uint64_t)x);
}
#endif

SCALAR_FUN_ATTR float fdiv32(float x, float y) {
  return x / y;
}

SCALAR_FUN_ATTR float fadd32(float x, float y) {
  return x + y;
}

SCALAR_FUN_ATTR float fsub32(float x, float y) {
  return x - y;
}

SCALAR_FUN_ATTR float fmul32(float x, float y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt32(float x, float y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple32(float x, float y) {
  return x <= y;
}

SCALAR_FUN_ATTR float sitofp_i8_f32(int8_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float sitofp_i16_f32(int16_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float sitofp_i32_f32(int32_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float sitofp_i64_f32(int64_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i8_f32(uint8_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i16_f32(uint16_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i32_f32(uint32_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i64_f32(uint64_t x) {
  return (float) x;
}

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR float fabs32(float x) {
  return fabs(x);
}

SCALAR_FUN_ATTR float fmax32(float x, float y) {
  return fmax(x, y);
}

SCALAR_FUN_ATTR float fmin32(float x, float y) {
  return fmin(x, y);
}

SCALAR_FUN_ATTR float fpow32(float x, float y) {
  return pow(x, y);
}

#elif ISPC

SCALAR_FUN_ATTR float fabs32(float x) {
  return abs(x);
}

SCALAR_FUN_ATTR float fmax32(float x, float y) {
  return isnan(x) ? y : isnan(y) ? x : max(x, y);
}

SCALAR_FUN_ATTR float fmin32(float x, float y) {
  return isnan(x) ? y : isnan(y) ? x : min(x, y);
}

SCALAR_FUN_ATTR float fpow32(float a, float b) {
  float ret;
  foreach_active (i) {
      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));
      ret = insert(ret, i, r);
  }
  return ret;
}

#else // Not OpenCL, but CUDA or plain C.

SCALAR_FUN_ATTR float fabs32(float x) {
  return fabsf(x);
}

SCALAR_FUN_ATTR float fmax32(float x, float y) {
  return fmaxf(x, y);
}

SCALAR_FUN_ATTR float fmin32(float x, float y) {
  return fminf(x, y);
}

SCALAR_FUN_ATTR float fpow32(float x, float y) {
  return powf(x, y);
}
#endif

SCALAR_FUN_ATTR bool futrts_isnan32(float x) {
  return isnan(x);
}

#if ISPC

SCALAR_FUN_ATTR bool futrts_isinf32(float x) {
  return !isnan(x) && isnan(x - x);
}

SCALAR_FUN_ATTR bool futrts_isfinite32(float x) {
  return !isnan(x) && !futrts_isinf32(x);
}

#else

SCALAR_FUN_ATTR bool futrts_isinf32(float x) {
  return isinf(x);
}

#endif

SCALAR_FUN_ATTR int8_t fptosi_f32_i8(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f32_i16(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f32_i32(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f32_i64(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int64_t) x;
  };
}

SCALAR_FUN_ATTR uint8_t fptoui_f32_i8(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f32_i16(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f32_i32(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f32_i64(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f32_bool(float x) {
  return x != 0;
}

SCALAR_FUN_ATTR float btof_bool_f32(bool x) {
  return x ? 1 : 0;
}

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR float futrts_log32(float x) {
  return log(x);
}

SCALAR_FUN_ATTR float futrts_log2_32(float x) {
  return log2(x);
}

SCALAR_FUN_ATTR float futrts_log10_32(float x) {
  return log10(x);
}

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  return log1p(x);
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) {
  return sqrt(x);
}

SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  return cbrt(x);
}

SCALAR_FUN_ATTR float futrts_exp32(float x) {
  return exp(x);
}

SCALAR_FUN_ATTR float futrts_cos32(float x) {
  return cos(x);
}

SCALAR_FUN_ATTR float futrts_sin32(float x) {
  return sin(x);
}

SCALAR_FUN_ATTR float futrts_tan32(float x) {
  return tan(x);
}

SCALAR_FUN_ATTR float futrts_acos32(float x) {
  return acos(x);
}

SCALAR_FUN_ATTR float futrts_asin32(float x) {
  return asin(x);
}

SCALAR_FUN_ATTR float futrts_atan32(float x) {
  return atan(x);
}

SCALAR_FUN_ATTR float futrts_cosh32(float x) {
  return cosh(x);
}

SCALAR_FUN_ATTR float futrts_sinh32(float x) {
  return sinh(x);
}

SCALAR_FUN_ATTR float futrts_tanh32(float x) {
  return tanh(x);
}

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  return acosh(x);
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  return asinh(x);
}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  return atanh(x);
}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {
  return atan2(x, y);
}

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  return hypot(x, y);
}

SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  return tgamma(x);
}

SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  return lgamma(x);
}

SCALAR_FUN_ATTR float futrts_erf32(float x) {
  return erf(x);
}

SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  return erfc(x);
}

SCALAR_FUN_ATTR float fmod32(float x, float y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR float futrts_round32(float x) {
  return rint(x);
}

SCALAR_FUN_ATTR float futrts_floor32(float x) {
  return floor(x);
}

SCALAR_FUN_ATTR float futrts_ceil32(float x) {
  return ceil(x);
}

SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  return nextafter(x, y);
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return mix(v0, v1, t);
}

SCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {
  return ldexp(x, y);
}

SCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {
  return copysign(x, y);
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return mad(a, b, c);
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return fma(a, b, c);
}

#elif ISPC

SCALAR_FUN_ATTR float futrts_log32(float x) {
  return futrts_isfinite32(x) || (futrts_isinf32(x) && x < 0)? log(x) : x;
}

SCALAR_FUN_ATTR float futrts_log2_32(float x) {
  return futrts_log32(x) / log(2.0f);
}

SCALAR_FUN_ATTR float futrts_log10_32(float x) {
  return futrts_log32(x) / log(10.0f);
}

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  if(x == -1.0f || (futrts_isinf32(x) && x > 0.0f)) return x / 0.0f;
  float y = 1.0f + x;
  float z = y - 1.0f;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) {
  return sqrt(x);
}

extern "C" unmasked uniform float cbrtf(uniform float);
SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = cbrtf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float futrts_exp32(float x) {
  return exp(x);
}

SCALAR_FUN_ATTR float futrts_cos32(float x) {
  return cos(x);
}

SCALAR_FUN_ATTR float futrts_sin32(float x) {
  return sin(x);
}

SCALAR_FUN_ATTR float futrts_tan32(float x) {
  return tan(x);
}

SCALAR_FUN_ATTR float futrts_acos32(float x) {
  return acos(x);
}

SCALAR_FUN_ATTR float futrts_asin32(float x) {
  return asin(x);
}

SCALAR_FUN_ATTR float futrts_atan32(float x) {
  return atan(x);
}

SCALAR_FUN_ATTR float futrts_cosh32(float x) {
  return (exp(x)+exp(-x)) / 2.0f;
}

SCALAR_FUN_ATTR float futrts_sinh32(float x) {
  return (exp(x)-exp(-x)) / 2.0f;
}

SCALAR_FUN_ATTR float futrts_tanh32(float x) {
  return futrts_sinh32(x)/futrts_cosh32(x);
}

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  float f = x+sqrt(x*x-1);
  if(futrts_isfinite32(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  float f = x+sqrt(x*x+1);
  if(futrts_isfinite32(f)) return log(f);
  return f;

}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  float f = (1+x)/(1-x);
  if(futrts_isfinite32(f)) return log(f)/2.0f;
  return f;

}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {
  return (x == 0.0f && y == 0.0f) ? 0.0f : atan2(x, y);
}

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  if (futrts_isfinite32(x) && futrts_isfinite32(y)) {
    x = abs(x);
    y = abs(y);
    float a;
    float b;
    if (x >= y){
        a = x;
        b = y;
    } else {
        a = y;
        b = x;
    }
    if(b == 0){
      return a;
    }

    int e;
    float an;
    float bn;
    an = frexp (a, &e);
    bn = ldexp (b, - e);
    float cn;
    cn = sqrt (an * an + bn * bn);
    return ldexp (cn, e);
  } else {
    if (futrts_isinf32(x) || futrts_isinf32(y)) return INFINITY;
    else return x + y;
  }

}

extern "C" unmasked uniform float tgammaf(uniform float x);
SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = tgammaf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float lgammaf(uniform float x);
SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = lgammaf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float erff(uniform float x);
SCALAR_FUN_ATTR float futrts_erf32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = erff(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float erfcf(uniform float x);
SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = erfcf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float fmod32(float x, float y) {
  return x - y * trunc(x/y);
}

SCALAR_FUN_ATTR float futrts_round32(float x) {
  return round(x);
}

SCALAR_FUN_ATTR float futrts_floor32(float x) {
  return floor(x);
}

SCALAR_FUN_ATTR float futrts_ceil32(float x) {
  return ceil(x);
}

extern "C" unmasked uniform float nextafterf(uniform float x, uniform float y);
SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  float res;
  foreach_active (i) {
    uniform float r = nextafterf(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {
  return x * pow((double)2.0, (double)y);
}

SCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {
  int32_t xb = futrts_to_bits32(x);
  int32_t yb = futrts_to_bits32(y);
  return futrts_from_bits32((xb & ~(1<<31)) | (yb & (1<<31)));
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return a * b + c;
}

#else // Not OpenCL or ISPC, but CUDA or plain C.

SCALAR_FUN_ATTR float futrts_log32(float x) {
  return logf(x);
}

SCALAR_FUN_ATTR float futrts_log2_32(float x) {
  return log2f(x);
}

SCALAR_FUN_ATTR float futrts_log10_32(float x) {
  return log10f(x);
}

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  return log1pf(x);
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) {
  return sqrtf(x);
}

SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  return cbrtf(x);
}

SCALAR_FUN_ATTR float futrts_exp32(float x) {
  return expf(x);
}

SCALAR_FUN_ATTR float futrts_cos32(float x) {
  return cosf(x);
}

SCALAR_FUN_ATTR float futrts_sin32(float x) {
  return sinf(x);
}

SCALAR_FUN_ATTR float futrts_tan32(float x) {
  return tanf(x);
}

SCALAR_FUN_ATTR float futrts_acos32(float x) {
  return acosf(x);
}

SCALAR_FUN_ATTR float futrts_asin32(float x) {
  return asinf(x);
}

SCALAR_FUN_ATTR float futrts_atan32(float x) {
  return atanf(x);
}

SCALAR_FUN_ATTR float futrts_cosh32(float x) {
  return coshf(x);
}

SCALAR_FUN_ATTR float futrts_sinh32(float x) {
  return sinhf(x);
}

SCALAR_FUN_ATTR float futrts_tanh32(float x) {
  return tanhf(x);
}

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  return acoshf(x);
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  return asinhf(x);
}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  return atanhf(x);
}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {
  return atan2f(x, y);
}

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  return hypotf(x, y);
}

SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  return tgammaf(x);
}

SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  return lgammaf(x);
}

SCALAR_FUN_ATTR float futrts_erf32(float x) {
  return erff(x);
}

SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  return erfcf(x);
}

SCALAR_FUN_ATTR float fmod32(float x, float y) {
  return fmodf(x, y);
}

SCALAR_FUN_ATTR float futrts_round32(float x) {
  return rintf(x);
}

SCALAR_FUN_ATTR float futrts_floor32(float x) {
  return floorf(x);
}

SCALAR_FUN_ATTR float futrts_ceil32(float x) {
  return ceilf(x);
}

SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  return nextafterf(x, y);
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {
  return ldexpf(x, y);
}

SCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {
  return copysignf(x, y);
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return fmaf(a, b, c);
}
#endif

#if ISPC
SCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {
  return intbits(x);
}

SCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {
  return floatbits(x);
}
#else
SCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {
  union {
    float f;
    int32_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {
  union {
    int32_t f;
    float t;
  } p;

  p.f = x;
  return p.t;
}
#endif

SCALAR_FUN_ATTR float fsignum32(float x) {
  return futrts_isnan32(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);
}

#ifdef FUTHARK_F64_ENABLED

SCALAR_FUN_ATTR double futrts_from_bits64(int64_t x);
SCALAR_FUN_ATTR int64_t futrts_to_bits64(double x);

#if ISPC
SCALAR_FUN_ATTR bool futrts_isinf64(float x) {
  return !isnan(x) && isnan(x - x);
}

SCALAR_FUN_ATTR bool futrts_isfinite64(float x) {
  return !isnan(x) && !futrts_isinf64(x);
}

SCALAR_FUN_ATTR double fdiv64(double x, double y) {
  return x / y;
}

SCALAR_FUN_ATTR double fadd64(double x, double y) {
  return x + y;
}

SCALAR_FUN_ATTR double fsub64(double x, double y) {
  return x - y;
}

SCALAR_FUN_ATTR double fmul64(double x, double y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt64(double x, double y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple64(double x, double y) {
  return x <= y;
}

SCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double fabs64(double x) {
  return abs(x);
}

SCALAR_FUN_ATTR double fmax64(double x, double y) {
  return isnan(x) ? y : isnan(y) ? x : max(x, y);
}

SCALAR_FUN_ATTR double fmin64(double x, double y) {
  return isnan(x) ? y : isnan(y) ? x : min(x, y);
}

SCALAR_FUN_ATTR double fpow64(double a, double b) {
  float ret;
  foreach_active (i) {
      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));
      ret = insert(ret, i, r);
  }
  return ret;
}

SCALAR_FUN_ATTR double futrts_log64(double x) {
  return futrts_isfinite64(x) || (futrts_isinf64(x) && x < 0)? log(x) : x;
}

SCALAR_FUN_ATTR double futrts_log2_64(double x) {
  return futrts_log64(x)/log(2.0d);
}

SCALAR_FUN_ATTR double futrts_log10_64(double x) {
  return futrts_log64(x)/log(10.0d);
}

SCALAR_FUN_ATTR double futrts_log1p_64(double x) {
  if(x == -1.0d || (futrts_isinf64(x) && x > 0.0d)) return x / 0.0d;
  double y = 1.0d + x;
  double z = y - 1.0d;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR double futrts_sqrt64(double x) {
  return sqrt(x);
}

extern "C" unmasked uniform double cbrt(uniform double);
SCALAR_FUN_ATTR double futrts_cbrt64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = cbrtf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_exp64(double x) {
  return exp(x);
}

SCALAR_FUN_ATTR double futrts_cos64(double x) {
  return cos(x);
}

SCALAR_FUN_ATTR double futrts_sin64(double x) {
  return sin(x);
}

SCALAR_FUN_ATTR double futrts_tan64(double x) {
  return tan(x);
}

SCALAR_FUN_ATTR double futrts_acos64(double x) {
  return acos(x);
}

SCALAR_FUN_ATTR double futrts_asin64(double x) {
  return asin(x);
}

SCALAR_FUN_ATTR double futrts_atan64(double x) {
  return atan(x);
}

SCALAR_FUN_ATTR double futrts_cosh64(double x) {
  return (exp(x)+exp(-x)) / 2.0d;
}

SCALAR_FUN_ATTR double futrts_sinh64(double x) {
  return (exp(x)-exp(-x)) / 2.0d;
}

SCALAR_FUN_ATTR double futrts_tanh64(double x) {
  return futrts_sinh64(x)/futrts_cosh64(x);
}

SCALAR_FUN_ATTR double futrts_acosh64(double x) {
  double f = x+sqrt(x*x-1.0d);
  if(futrts_isfinite64(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR double futrts_asinh64(double x) {
  double f = x+sqrt(x*x+1.0d);
  if(futrts_isfinite64(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR double futrts_atanh64(double x) {
  double f = (1.0d+x)/(1.0d-x);
  if(futrts_isfinite64(f)) return log(f)/2.0d;
  return f;

}

SCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {
  return atan2(x, y);
}

extern "C" unmasked uniform double hypot(uniform double x, uniform double y);
SCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {
  double res;
  foreach_active (i) {
    uniform double r = hypot(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double tgamma(uniform double x);
SCALAR_FUN_ATTR double futrts_gamma64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = tgamma(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double lgamma(uniform double x);
SCALAR_FUN_ATTR double futrts_lgamma64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = lgamma(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double erf(uniform double x);
SCALAR_FUN_ATTR double futrts_erf64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = erf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double erfc(uniform double x);
SCALAR_FUN_ATTR double futrts_erfc64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = erfc(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {
  return a * b + c;
}

SCALAR_FUN_ATTR double futrts_round64(double x) {
  return round(x);
}

SCALAR_FUN_ATTR double futrts_ceil64(double x) {
  return ceil(x);
}

extern "C" unmasked uniform double nextafter(uniform float x, uniform double y);
SCALAR_FUN_ATTR float futrts_nextafter64(double x, double y) {
  double res;
  foreach_active (i) {
    uniform double r = nextafter(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_floor64(double x) {
  return floor(x);
}

SCALAR_FUN_ATTR bool futrts_isnan64(double x) {
  return isnan(x);
}

SCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int64_t) x;
  }
}

SCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f64_bool(double x) {
  return x != 0.0;
}

SCALAR_FUN_ATTR double btof_bool_f64(bool x) {
  return x ? 1.0 : 0.0;
}

SCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {
  int64_t res;
  foreach_active (i) {
    uniform double tmp = extract(x, i);
    uniform int64_t r = *((uniform int64_t* uniform)&tmp);
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {
  double res;
  foreach_active (i) {
    uniform int64_t tmp = extract(x, i);
    uniform double r = *((uniform double* uniform)&tmp);
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double fmod64(double x, double y) {
  return x - y * trunc(x/y);
}

SCALAR_FUN_ATTR double fsignum64(double x) {
  return futrts_isnan64(x) ? x : (x > 0 ? 1.0d : 0.0d) - (x < 0 ? 1.0d : 0.0d);
}

SCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {
  return x * pow((double)2.0, (double)y);
}

SCALAR_FUN_ATTR double futrts_copysign64(double x, double y) {
  int64_t xb = futrts_to_bits64(x);
  int64_t yb = futrts_to_bits64(y);
  return futrts_from_bits64((xb & ~(((int64_t)1)<<63)) | (yb & (((int64_t)1)<<63)));
}

SCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float fpconv_f32_f32(float x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f32_f64(float x) {
  return (double) x;
}

SCALAR_FUN_ATTR float fpconv_f64_f32(double x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f64_f64(double x) {
  return (double) x;
}

#else

SCALAR_FUN_ATTR double fdiv64(double x, double y) {
  return x / y;
}

SCALAR_FUN_ATTR double fadd64(double x, double y) {
  return x + y;
}

SCALAR_FUN_ATTR double fsub64(double x, double y) {
  return x - y;
}

SCALAR_FUN_ATTR double fmul64(double x, double y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt64(double x, double y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple64(double x, double y) {
  return x <= y;
}

SCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double fabs64(double x) {
  return fabs(x);
}

SCALAR_FUN_ATTR double fmax64(double x, double y) {
  return fmax(x, y);
}

SCALAR_FUN_ATTR double fmin64(double x, double y) {
  return fmin(x, y);
}

SCALAR_FUN_ATTR double fpow64(double x, double y) {
  return pow(x, y);
}

SCALAR_FUN_ATTR double futrts_log64(double x) {
  return log(x);
}

SCALAR_FUN_ATTR double futrts_log2_64(double x) {
  return log2(x);
}

SCALAR_FUN_ATTR double futrts_log10_64(double x) {
  return log10(x);
}

SCALAR_FUN_ATTR double futrts_log1p_64(double x) {
  return log1p(x);
}

SCALAR_FUN_ATTR double futrts_sqrt64(double x) {
  return sqrt(x);
}

SCALAR_FUN_ATTR double futrts_cbrt64(double x) {
  return cbrt(x);
}

SCALAR_FUN_ATTR double futrts_exp64(double x) {
  return exp(x);
}

SCALAR_FUN_ATTR double futrts_cos64(double x) {
  return cos(x);
}

SCALAR_FUN_ATTR double futrts_sin64(double x) {
  return sin(x);
}

SCALAR_FUN_ATTR double futrts_tan64(double x) {
  return tan(x);
}

SCALAR_FUN_ATTR double futrts_acos64(double x) {
  return acos(x);
}

SCALAR_FUN_ATTR double futrts_asin64(double x) {
  return asin(x);
}

SCALAR_FUN_ATTR double futrts_atan64(double x) {
  return atan(x);
}

SCALAR_FUN_ATTR double futrts_cosh64(double x) {
  return cosh(x);
}

SCALAR_FUN_ATTR double futrts_sinh64(double x) {
  return sinh(x);
}

SCALAR_FUN_ATTR double futrts_tanh64(double x) {
  return tanh(x);
}

SCALAR_FUN_ATTR double futrts_acosh64(double x) {
  return acosh(x);
}

SCALAR_FUN_ATTR double futrts_asinh64(double x) {
  return asinh(x);
}

SCALAR_FUN_ATTR double futrts_atanh64(double x) {
  return atanh(x);
}

SCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {
  return atan2(x, y);
}

SCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {
  return hypot(x, y);
}

SCALAR_FUN_ATTR double futrts_gamma64(double x) {
  return tgamma(x);
}

SCALAR_FUN_ATTR double futrts_lgamma64(double x) {
  return lgamma(x);
}

SCALAR_FUN_ATTR double futrts_erf64(double x) {
  return erf(x);
}

SCALAR_FUN_ATTR double futrts_erfc64(double x) {
  return erfc(x);
}

SCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {
  return fma(a, b, c);
}

SCALAR_FUN_ATTR double futrts_round64(double x) {
  return rint(x);
}

SCALAR_FUN_ATTR double futrts_ceil64(double x) {
  return ceil(x);
}

SCALAR_FUN_ATTR float futrts_nextafter64(float x, float y) {
  return nextafter(x, y);
}

SCALAR_FUN_ATTR double futrts_floor64(double x) {
  return floor(x);
}

SCALAR_FUN_ATTR bool futrts_isnan64(double x) {
  return isnan(x);
}

SCALAR_FUN_ATTR bool futrts_isinf64(double x) {
  return isinf(x);
}

SCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int64_t) x;
  }
}

SCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f64_bool(double x) {
  return x != 0;
}

SCALAR_FUN_ATTR double btof_bool_f64(bool x) {
  return x ? 1 : 0;
}

SCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {
  union {
    double f;
    int64_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {
  union {
    int64_t f;
    double t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR double fmod64(double x, double y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR double fsignum64(double x) {
  return futrts_isnan64(x) ? x : (x > 0) - (x < 0);
}

SCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {
#ifdef __OPENCL_VERSION__
  return mix(v0, v1, t);
#else
  return v0 + (v1 - v0) * t;
#endif
}

SCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {
  return ldexp(x, y);
}

SCALAR_FUN_ATTR float futrts_copysign64(double x, double y) {
  return copysign(x, y);
}

SCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {
#ifdef __OPENCL_VERSION__
  return mad(a, b, c);
#else
  return a * b + c;
#endif
}

SCALAR_FUN_ATTR float fpconv_f32_f32(float x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f32_f64(float x) {
  return (double) x;
}

SCALAR_FUN_ATTR float fpconv_f64_f32(double x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f64_f64(double x) {
  return (double) x;
}

#endif

#endif

// End of scalar.h.
// Start of scalar_f16.h.

// Half-precision is emulated if needed (e.g. in straight C) with the
// native type used if possible.  The emulation works by typedef'ing
// 'float' to 'f16', and then implementing all operations on single
// precision.  To cut down on duplication, we use the same code for
// those Futhark functions that require just operators or casts.  The
// in-memory representation for arrays will still be 16 bits even
// under emulation, so the compiler will have to be careful when
// generating reads or writes.

#if !defined(cl_khr_fp16) && !(defined(__CUDA_ARCH__) && __CUDA_ARCH__ >= 600) && !(defined(ISPC))
#define EMULATE_F16
#endif

#if !defined(EMULATE_F16) && defined(__OPENCL_VERSION__)
#pragma OPENCL EXTENSION cl_khr_fp16 : enable
#endif

#ifdef EMULATE_F16

// Note that the half-precision storage format is still 16 bits - the
// compiler will have to be real careful!
typedef float f16;

#elif ISPC
typedef float16 f16;

#else

#ifdef __CUDA_ARCH__
#include <cuda_fp16.h>
#endif

typedef half f16;

#endif

// Some of these functions convert to single precision because half
// precision versions are not available.

SCALAR_FUN_ATTR f16 fadd16(f16 x, f16 y) {
  return x + y;
}

SCALAR_FUN_ATTR f16 fsub16(f16 x, f16 y) {
  return x - y;
}

SCALAR_FUN_ATTR f16 fmul16(f16 x, f16 y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt16(f16 x, f16 y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple16(f16 x, f16 y) {
  return x <= y;
}

SCALAR_FUN_ATTR f16 sitofp_i8_f16(int8_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 sitofp_i16_f16(int16_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 sitofp_i32_f16(int32_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 sitofp_i64_f16(int64_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i8_f16(uint8_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i16_f16(uint16_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i32_f16(uint32_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i64_f16(uint64_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR int8_t fptosi_f16_i8(f16 x) {
  return (int8_t) (float) x;
}

SCALAR_FUN_ATTR int16_t fptosi_f16_i16(f16 x) {
  return (int16_t) x;
}

SCALAR_FUN_ATTR int32_t fptosi_f16_i32(f16 x) {
  return (int32_t) x;
}

SCALAR_FUN_ATTR int64_t fptosi_f16_i64(f16 x) {
  return (int64_t) x;
}

SCALAR_FUN_ATTR uint8_t fptoui_f16_i8(f16 x) {
  return (uint8_t) (float) x;
}

SCALAR_FUN_ATTR uint16_t fptoui_f16_i16(f16 x) {
  return (uint16_t) x;
}

SCALAR_FUN_ATTR uint32_t fptoui_f16_i32(f16 x) {
  return (uint32_t) x;
}

SCALAR_FUN_ATTR uint64_t fptoui_f16_i64(f16 x) {
  return (uint64_t) x;
}

SCALAR_FUN_ATTR bool ftob_f16_bool(f16 x) {
  return x != (f16)0;
}

SCALAR_FUN_ATTR f16 btof_bool_f16(bool x) {
  return x ? 1 : 0;
}

#ifndef EMULATE_F16
SCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {
  return isnan((float)x);
}

#ifdef __OPENCL_VERSION__

SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return fabs(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return fmax(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return fmin(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return pow(x, y);
}

#elif ISPC
SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return abs(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : max(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : min(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return pow(x, y);
}

#else // Assuming CUDA.

SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return fabsf(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return fmaxf(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return fminf(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return powf(x, y);
}
#endif

#if ISPC
SCALAR_FUN_ATTR bool futrts_isinf16(float x) {
  return !futrts_isnan16(x) && futrts_isnan16(x - x);
}
SCALAR_FUN_ATTR bool futrts_isfinite16(float x) {
  return !futrts_isnan16(x) && !futrts_isinf16(x);
}

#else

SCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {
  return isinf((float)x);
}
#endif

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return log(x);
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return log2(x);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return log10(x);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  return log1p(x);
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return sqrt(x);
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  return cbrt(x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return exp(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return cos(x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return sin(x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return tan(x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return acos(x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return asin(x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return atan(x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return cosh(x);
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return sinh(x);
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return tanh(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  return acosh(x);
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  return asinh(x);
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  return atanh(x);
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return atan2(x, y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return hypot(x, y);
}

SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  return tgamma(x);
}

SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  return lgamma(x);
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  return erf(x);
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  return erfc(x);
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return rint(x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return floor(x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return ceil(x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return nextafter(x, y);
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return mix(v0, v1, t);
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return ldexp(x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return copysign(x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return mad(a, b, c);
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return fma(a, b, c);
}
#elif ISPC

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return futrts_isfinite16(x) || (futrts_isinf16(x) && x < 0) ? log(x) : x;
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return futrts_log16(x) / log(2.0f16);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return futrts_log16(x) / log(10.0f16);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  if(x == -1.0f16 || (futrts_isinf16(x) && x > 0.0f16)) return x / 0.0f16;
  f16 y = 1.0f16 + x;
  f16 z = y - 1.0f16;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return (float16)sqrt((float)x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return exp(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return (float16)cos((float)x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return (float16)sin((float)x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return (float16)tan((float)x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return (float16)acos((float)x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return (float16)asin((float)x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return (float16)atan((float)x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return (exp(x)+exp(-x)) / 2.0f16;
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return (exp(x)-exp(-x)) / 2.0f16;
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return futrts_sinh16(x)/futrts_cosh16(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  float16 f = x+(float16)sqrt((float)(x*x-1));
  if(futrts_isfinite16(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  float16 f = x+(float16)sqrt((float)(x*x+1));
  if(futrts_isfinite16(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  float16 f = (1+x)/(1-x);
  if(futrts_isfinite16(f)) return log(f)/2.0f16;
  return f;
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return (float16)atan2((float)x, (float)y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return (float16)futrts_hypot32((float)x, (float)y);
}

extern "C" unmasked uniform float tgammaf(uniform float x);
SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  f16 res;
  foreach_active (i) {
    uniform f16 r = (f16)tgammaf(extract((float)x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float lgammaf(uniform float x);
SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  f16 res;
  foreach_active (i) {
    uniform f16 r = (f16)lgammaf(extract((float)x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  f16 res = (f16)futrts_cbrt32((float)x);
  return res;
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  f16 res = (f16)futrts_erf32((float)x);
  return res;
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  f16 res = (f16)futrts_erfc32((float)x);
  return res;
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return x - y * (float16)trunc((float) (x/y));
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return (float16)round((float)x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return (float16)floor((float)x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return (float16)ceil((float)x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return (float16)futrts_nextafter32((float)x, (float) y);
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return futrts_ldexp32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return futrts_copysign32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

#else // Assume CUDA.

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return hlog(x);
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return hlog2(x);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return hlog10(x);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  return (f16)log1pf((float)x);
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return hsqrt(x);
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  return cbrtf(x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return hexp(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return hcos(x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return hsin(x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return tanf(x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return acosf(x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return asinf(x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return atanf(x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return coshf(x);
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return sinhf(x);
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return tanhf(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  return acoshf(x);
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  return asinhf(x);
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  return atanhf(x);
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return atan2f(x, y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return hypotf(x, y);
}

SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  return tgammaf(x);
}

SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  return lgammaf(x);
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  return erff(x);
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  return erfcf(x);
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return fmodf(x, y);
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return rintf(x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return hfloor(x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return hceil(x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return __ushort_as_half(halfbitsnextafter(__half_as_ushort(x), __half_as_ushort(y)));
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return futrts_ldexp32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return futrts_copysign32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return fmaf(a, b, c);
}

#endif

// The CUDA __half type cannot be put in unions for some reason, so we
// use bespoke conversion functions instead.
#ifdef __CUDA_ARCH__
SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  return __half_as_ushort(x);
}
SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  return __ushort_as_half(x);
}
#elif ISPC

SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  varying int16_t y = *((varying int16_t * uniform)&x);
  return y;
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  varying f16 y = *((varying f16 * uniform)&x);
  return y;
}
#else
SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  union {
    f16 f;
    int16_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  union {
    int16_t f;
    f16 t;
  } p;

  p.f = x;
  return p.t;
}
#endif

#else // No native f16 - emulate.

SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return fabs32(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return fmax32(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return fmin32(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return fpow32(x, y);
}

SCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {
  return futrts_isnan32(x);
}

SCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {
  return futrts_isinf32(x);
}

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return futrts_log32(x);
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return futrts_log2_32(x);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return futrts_log10_32(x);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  return futrts_log1p_32(x);
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return futrts_sqrt32(x);
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  return futrts_cbrt32(x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return futrts_exp32(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return futrts_cos32(x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return futrts_sin32(x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return futrts_tan32(x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return futrts_acos32(x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return futrts_asin32(x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return futrts_atan32(x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return futrts_cosh32(x);
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return futrts_sinh32(x);
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return futrts_tanh32(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  return futrts_acosh32(x);
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  return futrts_asinh32(x);
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  return futrts_atanh32(x);
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return futrts_atan2_32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return futrts_hypot32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  return futrts_gamma32(x);
}

SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  return futrts_lgamma32(x);
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  return futrts_erf32(x);
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  return futrts_erfc32(x);
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return fmod32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return futrts_round32(x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return futrts_floor32(x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return futrts_ceil32(x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return halfbits2float(halfbitsnextafter(float2halfbits(x), float2halfbits(y)));
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return futrts_lerp32(v0, v1, t);
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return futrts_ldexp32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return futrts_copysign32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return futrts_mad32(a, b, c);
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return futrts_fma32(a, b, c);
}

// Even when we are using an OpenCL that does not support cl_khr_fp16,
// it must still support vload_half for actually creating a
// half-precision number, which can then be efficiently converted to a
// float.  Similarly for vstore_half.
#ifdef __OPENCL_VERSION__

SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  int16_t y;
  // Violating strict aliasing here.
  vstore_half((float)x, 0, (half*)&y);
  return y;
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  return (f16)vload_half(0, (half*)&x);
}

#else

SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  return (int16_t)float2halfbits(x);
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  return halfbits2float((uint16_t)x);
}

SCALAR_FUN_ATTR f16 fsignum16(f16 x) {
  return futrts_isnan16(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);
}

#endif

#endif

SCALAR_FUN_ATTR float fpconv_f16_f16(f16 x) {
  return x;
}

SCALAR_FUN_ATTR float fpconv_f16_f32(f16 x) {
  return x;
}

SCALAR_FUN_ATTR f16 fpconv_f32_f16(float x) {
  return (f16) x;
}

#ifdef FUTHARK_F64_ENABLED

SCALAR_FUN_ATTR double fpconv_f16_f64(f16 x) {
  return (double) x;
}

#if ISPC
SCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {
  return (f16) ((float)x);
}
#else
SCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {
  return (f16) x;
}
#endif
#endif


// End of scalar_f16.h.

// Start of context_prototypes.h
//
// Prototypes for the functions in context.h, or that will be called
// from those functions, that need to be available very early.

struct futhark_context_config;
struct futhark_context;

static void set_error(struct futhark_context* ctx, char *error);

// These are called in context/config new/free functions and contain
// shared setup.  They are generated by the compiler itself.
static int init_constants(struct futhark_context*);
static int free_constants(struct futhark_context*);
static void setup_program(struct futhark_context* ctx);
static void teardown_program(struct futhark_context *ctx);

// Allocate host memory.  Must be freed with host_free().
static void host_alloc(struct futhark_context* ctx, size_t size, const char* tag, size_t* size_out, void** mem_out);
// Allocate memory allocated with host_alloc().
static void host_free(struct futhark_context* ctx, size_t size, const char* tag, void* mem);

// Log that a copy has occurred.
static void log_copy(struct futhark_context* ctx,
                     const char *kind, int r,
                     int64_t dst_offset, int64_t dst_strides[r],
                     int64_t src_offset, int64_t src_strides[r],
                     int64_t shape[r]);

static void log_transpose(struct futhark_context* ctx,
                          int64_t k, int64_t m, int64_t n);

static bool lmad_map_tr(int64_t *num_arrays_out, int64_t *n_out, int64_t *m_out,
                        int r,
                        const int64_t dst_strides[r],
                        const int64_t src_strides[r],
                        const int64_t shape[r]);

static bool lmad_contiguous(int r, int64_t strides[r], int64_t shape[r]);

static bool lmad_memcpyable(int r,
                            int64_t dst_strides[r], int64_t src_strides[r], int64_t shape[r]);

static void add_event(struct futhark_context* ctx,
                      const char* name,
                      char* description,
                      void* data,
                      event_report_fn f);

// Functions that must be defined by the backend.
static void backend_context_config_setup(struct futhark_context_config* cfg);
static void backend_context_config_teardown(struct futhark_context_config* cfg);
static int backend_context_setup(struct futhark_context *ctx);
static void backend_context_teardown(struct futhark_context *ctx);

// End of of context_prototypes.h

struct memblock_device {
    int *references;
    CUdeviceptr mem;
    int64_t size;
    const char *desc;
};
struct memblock {
    int *references;
    unsigned char *mem;
    int64_t size;
    const char *desc;
};
struct constants {
    int dummy;
    struct memblock_device counters_mem_42709;
    struct memblock_device global_dynid_mem_42857;
    struct memblock_device global_dynid_mem_42877;
    struct memblock_device global_dynid_mem_42998;
    struct memblock_device global_dynid_mem_43018;
};
struct tuning_params {
    int dummy;
    int64_t *builtinzhiota_i64zitblock_sizze_42716;
    int64_t *builtinzhreplicate_f32zitblock_sizze_42745;
    int64_t *builtinzhreplicate_f64zitblock_sizze_42745;
    int64_t *builtinzhreplicate_i16zitblock_sizze_42745;
    int64_t *builtinzhreplicate_i32zitblock_sizze_42888;
    int64_t *builtinzhreplicate_i64zitblock_sizze_42719;
    int64_t *builtinzhreplicate_i8zitblock_sizze_42862;
    int64_t *gather_payloads_doublezisegmap_tblock_sizze_39783;
    int64_t *gather_payloads_doublezisegmap_tblock_sizze_39801;
    int64_t *gather_payloads_double_GFURzisegmap_tblock_sizze_40063;
    int64_t *gather_payloads_double_GFURzisegmap_tblock_sizze_40081;
    int64_t *gather_payloads_floatzisegmap_tblock_sizze_39727;
    int64_t *gather_payloads_floatzisegmap_tblock_sizze_39745;
    int64_t *gather_payloads_float_GFURzisegmap_tblock_sizze_40007;
    int64_t *gather_payloads_float_GFURzisegmap_tblock_sizze_40025;
    int64_t *gather_payloads_intzisegmap_tblock_sizze_39615;
    int64_t *gather_payloads_intzisegmap_tblock_sizze_39633;
    int64_t *gather_payloads_int_GFURzisegmap_tblock_sizze_39895;
    int64_t *gather_payloads_int_GFURzisegmap_tblock_sizze_39913;
    int64_t *gather_payloads_longzisegmap_tblock_sizze_39671;
    int64_t *gather_payloads_longzisegmap_tblock_sizze_39689;
    int64_t *gather_payloads_long_GFURzisegmap_tblock_sizze_39951;
    int64_t *gather_payloads_long_GFURzisegmap_tblock_sizze_39969;
    int64_t *gather_payloads_shortzisegmap_tblock_sizze_39559;
    int64_t *gather_payloads_shortzisegmap_tblock_sizze_39577;
    int64_t *gather_payloads_short_GFURzisegmap_tblock_sizze_39839;
    int64_t *gather_payloads_short_GFURzisegmap_tblock_sizze_39857;
    int64_t *inner_SMJ_doublezisegmap_num_tblocks_41345;
    int64_t *inner_SMJ_doublezisegmap_num_tblocks_41387;
    int64_t *inner_SMJ_doublezisegmap_num_tblocks_41395;
    int64_t *inner_SMJ_doublezisegmap_tblock_sizze_41343;
    int64_t *inner_SMJ_doublezisegmap_tblock_sizze_41359;
    int64_t *inner_SMJ_doublezisegmap_tblock_sizze_41385;
    int64_t *inner_SMJ_doublezisegmap_tblock_sizze_41393;
    int64_t *inner_SMJ_doublezisegmap_tblock_sizze_41401;
    int64_t *inner_SMJ_doublezisegscan_num_tblocks_41335;
    int64_t *inner_SMJ_doublezisegscan_num_tblocks_41351;
    int64_t *inner_SMJ_doublezisegscan_tblock_sizze_41333;
    int64_t *inner_SMJ_doublezisegscan_tblock_sizze_41349;
    int64_t *inner_SMJ_doublezisuff_outer_par_0;
    int64_t *inner_SMJ_doublezitblock_sizze_43232;
    int64_t *inner_SMJ_doublezitblock_sizze_43252;
    int64_t *inner_SMJ_doublezitile_sizze_41424;
    int64_t *inner_SMJ_doublezitile_sizze_41779;
    int64_t *inner_SMJ_floatzisegmap_num_tblocks_41085;
    int64_t *inner_SMJ_floatzisegmap_num_tblocks_41127;
    int64_t *inner_SMJ_floatzisegmap_num_tblocks_41135;
    int64_t *inner_SMJ_floatzisegmap_tblock_sizze_41083;
    int64_t *inner_SMJ_floatzisegmap_tblock_sizze_41099;
    int64_t *inner_SMJ_floatzisegmap_tblock_sizze_41125;
    int64_t *inner_SMJ_floatzisegmap_tblock_sizze_41133;
    int64_t *inner_SMJ_floatzisegmap_tblock_sizze_41141;
    int64_t *inner_SMJ_floatzisegscan_num_tblocks_41075;
    int64_t *inner_SMJ_floatzisegscan_num_tblocks_41091;
    int64_t *inner_SMJ_floatzisegscan_tblock_sizze_41073;
    int64_t *inner_SMJ_floatzisegscan_tblock_sizze_41089;
    int64_t *inner_SMJ_floatzisuff_outer_par_0;
    int64_t *inner_SMJ_floatzitblock_sizze_43232;
    int64_t *inner_SMJ_floatzitblock_sizze_43252;
    int64_t *inner_SMJ_floatzitile_sizze_41424;
    int64_t *inner_SMJ_floatzitile_sizze_41779;
    int64_t *inner_SMJ_intzisegmap_num_tblocks_40565;
    int64_t *inner_SMJ_intzisegmap_num_tblocks_40607;
    int64_t *inner_SMJ_intzisegmap_num_tblocks_40615;
    int64_t *inner_SMJ_intzisegmap_tblock_sizze_40563;
    int64_t *inner_SMJ_intzisegmap_tblock_sizze_40579;
    int64_t *inner_SMJ_intzisegmap_tblock_sizze_40605;
    int64_t *inner_SMJ_intzisegmap_tblock_sizze_40613;
    int64_t *inner_SMJ_intzisegmap_tblock_sizze_40621;
    int64_t *inner_SMJ_intzisegscan_num_tblocks_40555;
    int64_t *inner_SMJ_intzisegscan_num_tblocks_40571;
    int64_t *inner_SMJ_intzisegscan_tblock_sizze_40553;
    int64_t *inner_SMJ_intzisegscan_tblock_sizze_40569;
    int64_t *inner_SMJ_intzisuff_outer_par_0;
    int64_t *inner_SMJ_intzitblock_sizze_43212;
    int64_t *inner_SMJ_intzitblock_sizze_43232;
    int64_t *inner_SMJ_intzitile_sizze_41424;
    int64_t *inner_SMJ_intzitile_sizze_41779;
    int64_t *inner_SMJ_longzisegmap_num_tblocks_40825;
    int64_t *inner_SMJ_longzisegmap_num_tblocks_40867;
    int64_t *inner_SMJ_longzisegmap_num_tblocks_40875;
    int64_t *inner_SMJ_longzisegmap_tblock_sizze_40823;
    int64_t *inner_SMJ_longzisegmap_tblock_sizze_40839;
    int64_t *inner_SMJ_longzisegmap_tblock_sizze_40865;
    int64_t *inner_SMJ_longzisegmap_tblock_sizze_40873;
    int64_t *inner_SMJ_longzisegmap_tblock_sizze_40881;
    int64_t *inner_SMJ_longzisegscan_num_tblocks_40815;
    int64_t *inner_SMJ_longzisegscan_num_tblocks_40831;
    int64_t *inner_SMJ_longzisegscan_tblock_sizze_40813;
    int64_t *inner_SMJ_longzisegscan_tblock_sizze_40829;
    int64_t *inner_SMJ_longzisuff_outer_par_0;
    int64_t *inner_SMJ_longzitblock_sizze_43212;
    int64_t *inner_SMJ_longzitblock_sizze_43232;
    int64_t *inner_SMJ_longzitile_sizze_41424;
    int64_t *inner_SMJ_longzitile_sizze_41779;
    int64_t *inner_SMJ_shortzisegmap_num_tblocks_40305;
    int64_t *inner_SMJ_shortzisegmap_num_tblocks_40347;
    int64_t *inner_SMJ_shortzisegmap_num_tblocks_40355;
    int64_t *inner_SMJ_shortzisegmap_tblock_sizze_40303;
    int64_t *inner_SMJ_shortzisegmap_tblock_sizze_40319;
    int64_t *inner_SMJ_shortzisegmap_tblock_sizze_40345;
    int64_t *inner_SMJ_shortzisegmap_tblock_sizze_40353;
    int64_t *inner_SMJ_shortzisegmap_tblock_sizze_40361;
    int64_t *inner_SMJ_shortzisegscan_num_tblocks_40295;
    int64_t *inner_SMJ_shortzisegscan_num_tblocks_40311;
    int64_t *inner_SMJ_shortzisegscan_tblock_sizze_40293;
    int64_t *inner_SMJ_shortzisegscan_tblock_sizze_40309;
    int64_t *inner_SMJ_shortzisuff_outer_par_0;
    int64_t *inner_SMJ_shortzitblock_sizze_43232;
    int64_t *inner_SMJ_shortzitblock_sizze_43252;
    int64_t *inner_SMJ_shortzitile_sizze_41424;
    int64_t *inner_SMJ_shortzitile_sizze_41779;
    int64_t *max_idxzisegred_num_tblocks_39549;
    int64_t *max_idxzisegred_tblock_sizze_39547;
    int64_t *min_idxzisegred_num_tblocks_39539;
    int64_t *min_idxzisegred_tblock_sizze_39537;
};
static const int num_tuning_params = 116;
static const char *tuning_param_names[] = {"builtin#iota_i64.tblock_size_42716", "builtin#replicate_f32.tblock_size_42745", "builtin#replicate_f64.tblock_size_42745", "builtin#replicate_i16.tblock_size_42745", "builtin#replicate_i32.tblock_size_42888", "builtin#replicate_i64.tblock_size_42719", "builtin#replicate_i8.tblock_size_42862", "gather_payloads_double.segmap_tblock_size_39783", "gather_payloads_double.segmap_tblock_size_39801", "gather_payloads_double_GFUR.segmap_tblock_size_40063", "gather_payloads_double_GFUR.segmap_tblock_size_40081", "gather_payloads_float.segmap_tblock_size_39727", "gather_payloads_float.segmap_tblock_size_39745", "gather_payloads_float_GFUR.segmap_tblock_size_40007", "gather_payloads_float_GFUR.segmap_tblock_size_40025", "gather_payloads_int.segmap_tblock_size_39615", "gather_payloads_int.segmap_tblock_size_39633", "gather_payloads_int_GFUR.segmap_tblock_size_39895", "gather_payloads_int_GFUR.segmap_tblock_size_39913", "gather_payloads_long.segmap_tblock_size_39671", "gather_payloads_long.segmap_tblock_size_39689", "gather_payloads_long_GFUR.segmap_tblock_size_39951", "gather_payloads_long_GFUR.segmap_tblock_size_39969", "gather_payloads_short.segmap_tblock_size_39559", "gather_payloads_short.segmap_tblock_size_39577", "gather_payloads_short_GFUR.segmap_tblock_size_39839", "gather_payloads_short_GFUR.segmap_tblock_size_39857", "inner_SMJ_double.segmap_num_tblocks_41345", "inner_SMJ_double.segmap_num_tblocks_41387", "inner_SMJ_double.segmap_num_tblocks_41395", "inner_SMJ_double.segmap_tblock_size_41343", "inner_SMJ_double.segmap_tblock_size_41359", "inner_SMJ_double.segmap_tblock_size_41385", "inner_SMJ_double.segmap_tblock_size_41393", "inner_SMJ_double.segmap_tblock_size_41401", "inner_SMJ_double.segscan_num_tblocks_41335", "inner_SMJ_double.segscan_num_tblocks_41351", "inner_SMJ_double.segscan_tblock_size_41333", "inner_SMJ_double.segscan_tblock_size_41349", "inner_SMJ_double.suff_outer_par_0", "inner_SMJ_double.tblock_size_43232", "inner_SMJ_double.tblock_size_43252", "inner_SMJ_double.tile_size_41424", "inner_SMJ_double.tile_size_41779", "inner_SMJ_float.segmap_num_tblocks_41085", "inner_SMJ_float.segmap_num_tblocks_41127", "inner_SMJ_float.segmap_num_tblocks_41135", "inner_SMJ_float.segmap_tblock_size_41083", "inner_SMJ_float.segmap_tblock_size_41099", "inner_SMJ_float.segmap_tblock_size_41125", "inner_SMJ_float.segmap_tblock_size_41133", "inner_SMJ_float.segmap_tblock_size_41141", "inner_SMJ_float.segscan_num_tblocks_41075", "inner_SMJ_float.segscan_num_tblocks_41091", "inner_SMJ_float.segscan_tblock_size_41073", "inner_SMJ_float.segscan_tblock_size_41089", "inner_SMJ_float.suff_outer_par_0", "inner_SMJ_float.tblock_size_43232", "inner_SMJ_float.tblock_size_43252", "inner_SMJ_float.tile_size_41424", "inner_SMJ_float.tile_size_41779", "inner_SMJ_int.segmap_num_tblocks_40565", "inner_SMJ_int.segmap_num_tblocks_40607", "inner_SMJ_int.segmap_num_tblocks_40615", "inner_SMJ_int.segmap_tblock_size_40563", "inner_SMJ_int.segmap_tblock_size_40579", "inner_SMJ_int.segmap_tblock_size_40605", "inner_SMJ_int.segmap_tblock_size_40613", "inner_SMJ_int.segmap_tblock_size_40621", "inner_SMJ_int.segscan_num_tblocks_40555", "inner_SMJ_int.segscan_num_tblocks_40571", "inner_SMJ_int.segscan_tblock_size_40553", "inner_SMJ_int.segscan_tblock_size_40569", "inner_SMJ_int.suff_outer_par_0", "inner_SMJ_int.tblock_size_43212", "inner_SMJ_int.tblock_size_43232", "inner_SMJ_int.tile_size_41424", "inner_SMJ_int.tile_size_41779", "inner_SMJ_long.segmap_num_tblocks_40825", "inner_SMJ_long.segmap_num_tblocks_40867", "inner_SMJ_long.segmap_num_tblocks_40875", "inner_SMJ_long.segmap_tblock_size_40823", "inner_SMJ_long.segmap_tblock_size_40839", "inner_SMJ_long.segmap_tblock_size_40865", "inner_SMJ_long.segmap_tblock_size_40873", "inner_SMJ_long.segmap_tblock_size_40881", "inner_SMJ_long.segscan_num_tblocks_40815", "inner_SMJ_long.segscan_num_tblocks_40831", "inner_SMJ_long.segscan_tblock_size_40813", "inner_SMJ_long.segscan_tblock_size_40829", "inner_SMJ_long.suff_outer_par_0", "inner_SMJ_long.tblock_size_43212", "inner_SMJ_long.tblock_size_43232", "inner_SMJ_long.tile_size_41424", "inner_SMJ_long.tile_size_41779", "inner_SMJ_short.segmap_num_tblocks_40305", "inner_SMJ_short.segmap_num_tblocks_40347", "inner_SMJ_short.segmap_num_tblocks_40355", "inner_SMJ_short.segmap_tblock_size_40303", "inner_SMJ_short.segmap_tblock_size_40319", "inner_SMJ_short.segmap_tblock_size_40345", "inner_SMJ_short.segmap_tblock_size_40353", "inner_SMJ_short.segmap_tblock_size_40361", "inner_SMJ_short.segscan_num_tblocks_40295", "inner_SMJ_short.segscan_num_tblocks_40311", "inner_SMJ_short.segscan_tblock_size_40293", "inner_SMJ_short.segscan_tblock_size_40309", "inner_SMJ_short.suff_outer_par_0", "inner_SMJ_short.tblock_size_43232", "inner_SMJ_short.tblock_size_43252", "inner_SMJ_short.tile_size_41424", "inner_SMJ_short.tile_size_41779", "max_idx.segred_num_tblocks_39549", "max_idx.segred_tblock_size_39547", "min_idx.segred_num_tblocks_39539", "min_idx.segred_tblock_size_39537", NULL};
static const char *tuning_param_vars[] = {"builtinzhiota_i64zitblock_sizze_42716", "builtinzhreplicate_f32zitblock_sizze_42745", "builtinzhreplicate_f64zitblock_sizze_42745", "builtinzhreplicate_i16zitblock_sizze_42745", "builtinzhreplicate_i32zitblock_sizze_42888", "builtinzhreplicate_i64zitblock_sizze_42719", "builtinzhreplicate_i8zitblock_sizze_42862", "gather_payloads_doublezisegmap_tblock_sizze_39783", "gather_payloads_doublezisegmap_tblock_sizze_39801", "gather_payloads_double_GFURzisegmap_tblock_sizze_40063", "gather_payloads_double_GFURzisegmap_tblock_sizze_40081", "gather_payloads_floatzisegmap_tblock_sizze_39727", "gather_payloads_floatzisegmap_tblock_sizze_39745", "gather_payloads_float_GFURzisegmap_tblock_sizze_40007", "gather_payloads_float_GFURzisegmap_tblock_sizze_40025", "gather_payloads_intzisegmap_tblock_sizze_39615", "gather_payloads_intzisegmap_tblock_sizze_39633", "gather_payloads_int_GFURzisegmap_tblock_sizze_39895", "gather_payloads_int_GFURzisegmap_tblock_sizze_39913", "gather_payloads_longzisegmap_tblock_sizze_39671", "gather_payloads_longzisegmap_tblock_sizze_39689", "gather_payloads_long_GFURzisegmap_tblock_sizze_39951", "gather_payloads_long_GFURzisegmap_tblock_sizze_39969", "gather_payloads_shortzisegmap_tblock_sizze_39559", "gather_payloads_shortzisegmap_tblock_sizze_39577", "gather_payloads_short_GFURzisegmap_tblock_sizze_39839", "gather_payloads_short_GFURzisegmap_tblock_sizze_39857", "inner_SMJ_doublezisegmap_num_tblocks_41345", "inner_SMJ_doublezisegmap_num_tblocks_41387", "inner_SMJ_doublezisegmap_num_tblocks_41395", "inner_SMJ_doublezisegmap_tblock_sizze_41343", "inner_SMJ_doublezisegmap_tblock_sizze_41359", "inner_SMJ_doublezisegmap_tblock_sizze_41385", "inner_SMJ_doublezisegmap_tblock_sizze_41393", "inner_SMJ_doublezisegmap_tblock_sizze_41401", "inner_SMJ_doublezisegscan_num_tblocks_41335", "inner_SMJ_doublezisegscan_num_tblocks_41351", "inner_SMJ_doublezisegscan_tblock_sizze_41333", "inner_SMJ_doublezisegscan_tblock_sizze_41349", "inner_SMJ_doublezisuff_outer_par_0", "inner_SMJ_doublezitblock_sizze_43232", "inner_SMJ_doublezitblock_sizze_43252", "inner_SMJ_doublezitile_sizze_41424", "inner_SMJ_doublezitile_sizze_41779", "inner_SMJ_floatzisegmap_num_tblocks_41085", "inner_SMJ_floatzisegmap_num_tblocks_41127", "inner_SMJ_floatzisegmap_num_tblocks_41135", "inner_SMJ_floatzisegmap_tblock_sizze_41083", "inner_SMJ_floatzisegmap_tblock_sizze_41099", "inner_SMJ_floatzisegmap_tblock_sizze_41125", "inner_SMJ_floatzisegmap_tblock_sizze_41133", "inner_SMJ_floatzisegmap_tblock_sizze_41141", "inner_SMJ_floatzisegscan_num_tblocks_41075", "inner_SMJ_floatzisegscan_num_tblocks_41091", "inner_SMJ_floatzisegscan_tblock_sizze_41073", "inner_SMJ_floatzisegscan_tblock_sizze_41089", "inner_SMJ_floatzisuff_outer_par_0", "inner_SMJ_floatzitblock_sizze_43232", "inner_SMJ_floatzitblock_sizze_43252", "inner_SMJ_floatzitile_sizze_41424", "inner_SMJ_floatzitile_sizze_41779", "inner_SMJ_intzisegmap_num_tblocks_40565", "inner_SMJ_intzisegmap_num_tblocks_40607", "inner_SMJ_intzisegmap_num_tblocks_40615", "inner_SMJ_intzisegmap_tblock_sizze_40563", "inner_SMJ_intzisegmap_tblock_sizze_40579", "inner_SMJ_intzisegmap_tblock_sizze_40605", "inner_SMJ_intzisegmap_tblock_sizze_40613", "inner_SMJ_intzisegmap_tblock_sizze_40621", "inner_SMJ_intzisegscan_num_tblocks_40555", "inner_SMJ_intzisegscan_num_tblocks_40571", "inner_SMJ_intzisegscan_tblock_sizze_40553", "inner_SMJ_intzisegscan_tblock_sizze_40569", "inner_SMJ_intzisuff_outer_par_0", "inner_SMJ_intzitblock_sizze_43212", "inner_SMJ_intzitblock_sizze_43232", "inner_SMJ_intzitile_sizze_41424", "inner_SMJ_intzitile_sizze_41779", "inner_SMJ_longzisegmap_num_tblocks_40825", "inner_SMJ_longzisegmap_num_tblocks_40867", "inner_SMJ_longzisegmap_num_tblocks_40875", "inner_SMJ_longzisegmap_tblock_sizze_40823", "inner_SMJ_longzisegmap_tblock_sizze_40839", "inner_SMJ_longzisegmap_tblock_sizze_40865", "inner_SMJ_longzisegmap_tblock_sizze_40873", "inner_SMJ_longzisegmap_tblock_sizze_40881", "inner_SMJ_longzisegscan_num_tblocks_40815", "inner_SMJ_longzisegscan_num_tblocks_40831", "inner_SMJ_longzisegscan_tblock_sizze_40813", "inner_SMJ_longzisegscan_tblock_sizze_40829", "inner_SMJ_longzisuff_outer_par_0", "inner_SMJ_longzitblock_sizze_43212", "inner_SMJ_longzitblock_sizze_43232", "inner_SMJ_longzitile_sizze_41424", "inner_SMJ_longzitile_sizze_41779", "inner_SMJ_shortzisegmap_num_tblocks_40305", "inner_SMJ_shortzisegmap_num_tblocks_40347", "inner_SMJ_shortzisegmap_num_tblocks_40355", "inner_SMJ_shortzisegmap_tblock_sizze_40303", "inner_SMJ_shortzisegmap_tblock_sizze_40319", "inner_SMJ_shortzisegmap_tblock_sizze_40345", "inner_SMJ_shortzisegmap_tblock_sizze_40353", "inner_SMJ_shortzisegmap_tblock_sizze_40361", "inner_SMJ_shortzisegscan_num_tblocks_40295", "inner_SMJ_shortzisegscan_num_tblocks_40311", "inner_SMJ_shortzisegscan_tblock_sizze_40293", "inner_SMJ_shortzisegscan_tblock_sizze_40309", "inner_SMJ_shortzisuff_outer_par_0", "inner_SMJ_shortzitblock_sizze_43232", "inner_SMJ_shortzitblock_sizze_43252", "inner_SMJ_shortzitile_sizze_41424", "inner_SMJ_shortzitile_sizze_41779", "max_idxzisegred_num_tblocks_39549", "max_idxzisegred_tblock_sizze_39547", "min_idxzisegred_num_tblocks_39539", "min_idxzisegred_tblock_sizze_39537", NULL};
static const char *tuning_param_classes[] = {"thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "threshold(def, )", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "threshold(def, )", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "threshold(def, )", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "threshold(def, )", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "threshold(def, )", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "thread_block_size", "grid_size", "thread_block_size", NULL};
static int64_t tuning_param_defaults[] = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
static const int max_failure_args = 2;
static const int f64_required = 1;
static const char *gpu_program[] = {"#define FUTHARK_CUDA\n// start of prelude.cu\n\n#define SCALAR_FUN_ATTR __device__ static inline\n#define FUTHARK_FUN_ATTR __device__ static\n#define FUTHARK_F64_ENABLED\n\ntypedef char int8_t;\ntypedef short int16_t;\ntypedef int int32_t;\ntypedef long long int64_t;\ntypedef unsigned char uint8_t;\ntypedef unsigned short uint16_t;\ntypedef unsigned int uint32_t;\ntypedef unsigned long long uint64_t;\n\n#define __global\n#define __local\n#define __private\n#define __constant\n#define __write_only\n#define __read_only\n\nstatic inline __device__ int get_tblock_id(int d) {\n  switch (d) {\n  case 0: return blockIdx.x;\n  case 1: return blockIdx.y;\n  case 2: return blockIdx.z;\n  default: return 0;\n  }\n}\n\nstatic inline __device__ int get_num_tblocks(int d) {\n  switch(d) {\n  case 0: return gridDim.x;\n  case 1: return gridDim.y;\n  case 2: return gridDim.z;\n  default: return 0;\n  }\n}\n\nstatic inline __device__ int get_global_id(int d) {\n  switch (d) {\n    case 0: return threadIdx.x + blockIdx.x * blockDim.x;\n    case 1: return threadIdx.y + blockIdx.y * blockDim.y;\n    case 2: return threadIdx.z + blockIdx.z * blockDim.z;\n    default: return 0;\n  }\n}\n\nstatic inline __device__ int get_local_id(int d) {\n  switch (d) {\n    case 0: return threadIdx.x;\n    case 1: return threadIdx.y;\n    case 2: return threadIdx.z;\n    default: return 0;\n  }\n}\n\nstatic inline __device__ int get_local_size(int d) {\n  switch (d) {\n    case 0: return blockDim.x;\n    case 1: return blockDim.y;\n    case 2: return blockDim.z;\n    default: return 0;\n  }\n}\n\nstatic inline __device__ int get_global_size(int d) {\n  switch (d) {\n    case 0: return gridDim.x * blockDim.x;\n    case 1: return gridDim.y * blockDim.y;\n    case 2: return gridDim.z * blockDim.z;\n    default: return 0;\n  }\n}\n\n\n#define CLK_LOCAL_MEM_FENCE 1\n#define CLK_GLOBAL_MEM_FENCE 2\nstatic inline __device__ void barrier(int x) {\n  __syncthreads();\n}\nstatic inline __device__ void mem_fence_local() {\n  __threadfence_block();\n}\nstatic inline __device__ void mem_fence_global", "() {\n  __threadfence();\n}\n\nstatic inline __device__ void barrier_local() {\n  __syncthreads();\n}\n\n#define NAN (0.0/0.0)\n#define INFINITY (1.0/0.0)\nextern volatile __shared__ unsigned char shared_mem[];\n\n#define SHARED_MEM_PARAM\n#define FUTHARK_KERNEL extern \"C\" __global__ __launch_bounds__(MAX_THREADS_PER_BLOCK)\n#define FUTHARK_KERNEL_SIZED(a,b,c) extern \"C\" __global__ __launch_bounds__(a*b*c)\n\n// End of prelude.cu\n// Start of half.h.\n\n// Conversion functions are from http://half.sourceforge.net/, but\n// translated to C.\n//\n// Copyright (c) 2012-2021 Christian Rau\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in\n// all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n// THE SOFTWARE.\n\n#ifndef __OPENCL_VERSION__\n#define __constant\n#endif\n\n__constant static const uint16_t base_table[512] = {\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0", "000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0001, 0x0002, 0x0004, 0x0008, 0x0010, 0x0020, 0x0040, 0x0080, 0x0100,\n  0x0200, 0x0400, 0x0800, 0x0C00, 0x1000, 0x1400, 0x1800, 0x1C00, 0x2000, 0x2400, 0x2800, 0x2C00, 0x3000, 0x3400, 0x3800, 0x3C00,\n  0x4000, 0x4400, 0x4800, 0x4C00, 0x5000, 0x5400, 0x5800, 0x5C00, 0x6000, 0x6400, 0x6800, 0x6C00, 0x7000, 0x7400, 0x7800, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8",
                                    "000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8001, 0x8002, 0x8004, 0x8008, 0x8010, 0x8020, 0x8040, 0x8080, 0x8100,\n  0x8200, 0x8400, 0x8800, 0x8C00, 0x9000, 0x9400, 0x9800, 0x9C00, 0xA000, 0xA400, 0xA800, 0xAC00, 0xB000, 0xB400, 0xB800, 0xBC00,\n  0xC000, 0xC400, 0xC800, 0xCC00, 0xD000, 0xD400, 0xD800, 0xDC00, 0xE000, 0xE400, 0xE800, 0xEC00, 0xF000, 0xF400, 0xF800, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00 };\n\n__constant static const unsigned char shift_table[512] = {\n  24, 24, 24, 24, 24, 24,", " 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 2", "4, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13 };\n\n__constant static const uint32_t mantissa_table[2048] = {\n  0x00000000, 0x33800000, 0x34000000, 0x34400000, 0x34800000, 0x34A00000, 0x34C00000, 0x34E00000, 0x35000000, 0x35100000, 0x35200000, 0x35300000, 0x35400000, 0x35500000, 0x35600000, 0x35700000,\n  0x35800000, 0x35880000, 0x35900000, 0x35980000, 0x35A00000, 0x35A80000, 0x35B00000, 0x35B80000, 0x35C00000, 0x35C80000, 0x35D00000, 0x35D80000, 0x35E00000, 0x35E80000, 0x35F00000, 0x35F80000,\n  0x36000000, 0x36040000, 0x36080000, 0x360C0000, 0x36100000, 0x36140000, 0x36180000, 0x361C0000, 0x36200000, 0x36240000, 0x36280000, 0x362C0000, 0x36300000, 0x36340000, 0x36380000, 0x363C0000,\n  0x36400000, 0x36440000, 0x36480000, 0x364C0000, 0x36500000, 0x36540000, 0x36580000, 0x365C0000, 0x36600000, 0x36640000, 0x36680000, 0x366C0000, 0x36700000, 0x36740000, 0x36780000, 0x367C0000,\n  0x36800000, 0x36820000, 0x36840000, 0x36860000, 0x36880000, 0x368A0000, 0x368C0000, 0x368E0000, 0x36900000, 0x36920000, 0x36940000, 0x36960000, 0x36980000, 0x369A0000, 0x369C0000, 0x369E0000,\n  0x36A00000, 0x36A20000, 0x36A40000, 0x36A60000, 0x36A80000, 0x36AA0000, 0x36AC0000, 0x36AE0000, 0x36B00000, 0x36B20000, 0x36B40000, 0x36B60000, 0x36B80000, 0x36BA0000, 0x36BC0000, 0x36BE0000,\n  0x36C00000, 0x36C20000, 0x36C40000, 0x36C60000, 0x36C80000, 0x36CA0000, 0x36CC0000, 0x36CE0000, 0x36D00000, 0x36D20000, 0x36D40000, 0x36D60000, 0x36D80000, 0x36DA0000, 0x36DC0000, 0x36DE0000,\n  0x36E00000, 0x36E20000, 0x36E40000, 0x36E60000, 0x36E80000, 0x36EA0000, 0x36EC0000, 0x36EE0000, 0x36F00000, 0x36F20000, 0x36F40000, 0x36F60000, 0x36F80000, 0x36FA0000, 0x36FC0000, 0x36FE0000,\n  0x37000000, 0x37010000, 0x37020000, 0x37030000, 0x37040000, 0x37050000, 0x37060000, 0x37070000, 0x37080000, 0x37090000, 0x370A0000, 0x370B0000, 0x370C0000, 0x370D0000, 0x370E0000, 0x370F0000,\n  0x37100000, 0x37110000, 0x37120000, 0x37130000, 0x37140000, 0x37150000, 0x37160000, 0x37170000, 0x37180000, 0x37190000, 0x371A0000, 0x37",
                                    "1B0000, 0x371C0000, 0x371D0000, 0x371E0000, 0x371F0000,\n  0x37200000, 0x37210000, 0x37220000, 0x37230000, 0x37240000, 0x37250000, 0x37260000, 0x37270000, 0x37280000, 0x37290000, 0x372A0000, 0x372B0000, 0x372C0000, 0x372D0000, 0x372E0000, 0x372F0000,\n  0x37300000, 0x37310000, 0x37320000, 0x37330000, 0x37340000, 0x37350000, 0x37360000, 0x37370000, 0x37380000, 0x37390000, 0x373A0000, 0x373B0000, 0x373C0000, 0x373D0000, 0x373E0000, 0x373F0000,\n  0x37400000, 0x37410000, 0x37420000, 0x37430000, 0x37440000, 0x37450000, 0x37460000, 0x37470000, 0x37480000, 0x37490000, 0x374A0000, 0x374B0000, 0x374C0000, 0x374D0000, 0x374E0000, 0x374F0000,\n  0x37500000, 0x37510000, 0x37520000, 0x37530000, 0x37540000, 0x37550000, 0x37560000, 0x37570000, 0x37580000, 0x37590000, 0x375A0000, 0x375B0000, 0x375C0000, 0x375D0000, 0x375E0000, 0x375F0000,\n  0x37600000, 0x37610000, 0x37620000, 0x37630000, 0x37640000, 0x37650000, 0x37660000, 0x37670000, 0x37680000, 0x37690000, 0x376A0000, 0x376B0000, 0x376C0000, 0x376D0000, 0x376E0000, 0x376F0000,\n  0x37700000, 0x37710000, 0x37720000, 0x37730000, 0x37740000, 0x37750000, 0x37760000, 0x37770000, 0x37780000, 0x37790000, 0x377A0000, 0x377B0000, 0x377C0000, 0x377D0000, 0x377E0000, 0x377F0000,\n  0x37800000, 0x37808000, 0x37810000, 0x37818000, 0x37820000, 0x37828000, 0x37830000, 0x37838000, 0x37840000, 0x37848000, 0x37850000, 0x37858000, 0x37860000, 0x37868000, 0x37870000, 0x37878000,\n  0x37880000, 0x37888000, 0x37890000, 0x37898000, 0x378A0000, 0x378A8000, 0x378B0000, 0x378B8000, 0x378C0000, 0x378C8000, 0x378D0000, 0x378D8000, 0x378E0000, 0x378E8000, 0x378F0000, 0x378F8000,\n  0x37900000, 0x37908000, 0x37910000, 0x37918000, 0x37920000, 0x37928000, 0x37930000, 0x37938000, 0x37940000, 0x37948000, 0x37950000, 0x37958000, 0x37960000, 0x37968000, 0x37970000, 0x37978000,\n  0x37980000, 0x37988000, 0x37990000, 0x37998000, 0x379A0000, 0x379A8000, 0x379B0000, 0x379B8000, 0x379C0000, 0x379C8000, 0x379D0000, 0x379D8000, 0x379E0000, 0x379E8000, 0x379F0000, 0x379F8000,\n  0x", "37A00000, 0x37A08000, 0x37A10000, 0x37A18000, 0x37A20000, 0x37A28000, 0x37A30000, 0x37A38000, 0x37A40000, 0x37A48000, 0x37A50000, 0x37A58000, 0x37A60000, 0x37A68000, 0x37A70000, 0x37A78000,\n  0x37A80000, 0x37A88000, 0x37A90000, 0x37A98000, 0x37AA0000, 0x37AA8000, 0x37AB0000, 0x37AB8000, 0x37AC0000, 0x37AC8000, 0x37AD0000, 0x37AD8000, 0x37AE0000, 0x37AE8000, 0x37AF0000, 0x37AF8000,\n  0x37B00000, 0x37B08000, 0x37B10000, 0x37B18000, 0x37B20000, 0x37B28000, 0x37B30000, 0x37B38000, 0x37B40000, 0x37B48000, 0x37B50000, 0x37B58000, 0x37B60000, 0x37B68000, 0x37B70000, 0x37B78000,\n  0x37B80000, 0x37B88000, 0x37B90000, 0x37B98000, 0x37BA0000, 0x37BA8000, 0x37BB0000, 0x37BB8000, 0x37BC0000, 0x37BC8000, 0x37BD0000, 0x37BD8000, 0x37BE0000, 0x37BE8000, 0x37BF0000, 0x37BF8000,\n  0x37C00000, 0x37C08000, 0x37C10000, 0x37C18000, 0x37C20000, 0x37C28000, 0x37C30000, 0x37C38000, 0x37C40000, 0x37C48000, 0x37C50000, 0x37C58000, 0x37C60000, 0x37C68000, 0x37C70000, 0x37C78000,\n  0x37C80000, 0x37C88000, 0x37C90000, 0x37C98000, 0x37CA0000, 0x37CA8000, 0x37CB0000, 0x37CB8000, 0x37CC0000, 0x37CC8000, 0x37CD0000, 0x37CD8000, 0x37CE0000, 0x37CE8000, 0x37CF0000, 0x37CF8000,\n  0x37D00000, 0x37D08000, 0x37D10000, 0x37D18000, 0x37D20000, 0x37D28000, 0x37D30000, 0x37D38000, 0x37D40000, 0x37D48000, 0x37D50000, 0x37D58000, 0x37D60000, 0x37D68000, 0x37D70000, 0x37D78000,\n  0x37D80000, 0x37D88000, 0x37D90000, 0x37D98000, 0x37DA0000, 0x37DA8000, 0x37DB0000, 0x37DB8000, 0x37DC0000, 0x37DC8000, 0x37DD0000, 0x37DD8000, 0x37DE0000, 0x37DE8000, 0x37DF0000, 0x37DF8000,\n  0x37E00000, 0x37E08000, 0x37E10000, 0x37E18000, 0x37E20000, 0x37E28000, 0x37E30000, 0x37E38000, 0x37E40000, 0x37E48000, 0x37E50000, 0x37E58000, 0x37E60000, 0x37E68000, 0x37E70000, 0x37E78000,\n  0x37E80000, 0x37E88000, 0x37E90000, 0x37E98000, 0x37EA0000, 0x37EA8000, 0x37EB0000, 0x37EB8000, 0x37EC0000, 0x37EC8000, 0x37ED0000, 0x37ED8000, 0x37EE0000, 0x37EE8000, 0x37EF0000, 0x37EF8000,\n  0x37F00000, 0x37F08000, 0x37F10000, 0x37F18000, 0x37F20000, 0x", "37F28000, 0x37F30000, 0x37F38000, 0x37F40000, 0x37F48000, 0x37F50000, 0x37F58000, 0x37F60000, 0x37F68000, 0x37F70000, 0x37F78000,\n  0x37F80000, 0x37F88000, 0x37F90000, 0x37F98000, 0x37FA0000, 0x37FA8000, 0x37FB0000, 0x37FB8000, 0x37FC0000, 0x37FC8000, 0x37FD0000, 0x37FD8000, 0x37FE0000, 0x37FE8000, 0x37FF0000, 0x37FF8000,\n  0x38000000, 0x38004000, 0x38008000, 0x3800C000, 0x38010000, 0x38014000, 0x38018000, 0x3801C000, 0x38020000, 0x38024000, 0x38028000, 0x3802C000, 0x38030000, 0x38034000, 0x38038000, 0x3803C000,\n  0x38040000, 0x38044000, 0x38048000, 0x3804C000, 0x38050000, 0x38054000, 0x38058000, 0x3805C000, 0x38060000, 0x38064000, 0x38068000, 0x3806C000, 0x38070000, 0x38074000, 0x38078000, 0x3807C000,\n  0x38080000, 0x38084000, 0x38088000, 0x3808C000, 0x38090000, 0x38094000, 0x38098000, 0x3809C000, 0x380A0000, 0x380A4000, 0x380A8000, 0x380AC000, 0x380B0000, 0x380B4000, 0x380B8000, 0x380BC000,\n  0x380C0000, 0x380C4000, 0x380C8000, 0x380CC000, 0x380D0000, 0x380D4000, 0x380D8000, 0x380DC000, 0x380E0000, 0x380E4000, 0x380E8000, 0x380EC000, 0x380F0000, 0x380F4000, 0x380F8000, 0x380FC000,\n  0x38100000, 0x38104000, 0x38108000, 0x3810C000, 0x38110000, 0x38114000, 0x38118000, 0x3811C000, 0x38120000, 0x38124000, 0x38128000, 0x3812C000, 0x38130000, 0x38134000, 0x38138000, 0x3813C000,\n  0x38140000, 0x38144000, 0x38148000, 0x3814C000, 0x38150000, 0x38154000, 0x38158000, 0x3815C000, 0x38160000, 0x38164000, 0x38168000, 0x3816C000, 0x38170000, 0x38174000, 0x38178000, 0x3817C000,\n  0x38180000, 0x38184000, 0x38188000, 0x3818C000, 0x38190000, 0x38194000, 0x38198000, 0x3819C000, 0x381A0000, 0x381A4000, 0x381A8000, 0x381AC000, 0x381B0000, 0x381B4000, 0x381B8000, 0x381BC000,\n  0x381C0000, 0x381C4000, 0x381C8000, 0x381CC000, 0x381D0000, 0x381D4000, 0x381D8000, 0x381DC000, 0x381E0000, 0x381E4000, 0x381E8000, 0x381EC000, 0x381F0000, 0x381F4000, 0x381F8000, 0x381FC000,\n  0x38200000, 0x38204000, 0x38208000, 0x3820C000, 0x38210000, 0x38214000, 0x38218000, 0x3821C000, 0x38220000, 0x38224000, 0x",
                                    "38228000, 0x3822C000, 0x38230000, 0x38234000, 0x38238000, 0x3823C000,\n  0x38240000, 0x38244000, 0x38248000, 0x3824C000, 0x38250000, 0x38254000, 0x38258000, 0x3825C000, 0x38260000, 0x38264000, 0x38268000, 0x3826C000, 0x38270000, 0x38274000, 0x38278000, 0x3827C000,\n  0x38280000, 0x38284000, 0x38288000, 0x3828C000, 0x38290000, 0x38294000, 0x38298000, 0x3829C000, 0x382A0000, 0x382A4000, 0x382A8000, 0x382AC000, 0x382B0000, 0x382B4000, 0x382B8000, 0x382BC000,\n  0x382C0000, 0x382C4000, 0x382C8000, 0x382CC000, 0x382D0000, 0x382D4000, 0x382D8000, 0x382DC000, 0x382E0000, 0x382E4000, 0x382E8000, 0x382EC000, 0x382F0000, 0x382F4000, 0x382F8000, 0x382FC000,\n  0x38300000, 0x38304000, 0x38308000, 0x3830C000, 0x38310000, 0x38314000, 0x38318000, 0x3831C000, 0x38320000, 0x38324000, 0x38328000, 0x3832C000, 0x38330000, 0x38334000, 0x38338000, 0x3833C000,\n  0x38340000, 0x38344000, 0x38348000, 0x3834C000, 0x38350000, 0x38354000, 0x38358000, 0x3835C000, 0x38360000, 0x38364000, 0x38368000, 0x3836C000, 0x38370000, 0x38374000, 0x38378000, 0x3837C000,\n  0x38380000, 0x38384000, 0x38388000, 0x3838C000, 0x38390000, 0x38394000, 0x38398000, 0x3839C000, 0x383A0000, 0x383A4000, 0x383A8000, 0x383AC000, 0x383B0000, 0x383B4000, 0x383B8000, 0x383BC000,\n  0x383C0000, 0x383C4000, 0x383C8000, 0x383CC000, 0x383D0000, 0x383D4000, 0x383D8000, 0x383DC000, 0x383E0000, 0x383E4000, 0x383E8000, 0x383EC000, 0x383F0000, 0x383F4000, 0x383F8000, 0x383FC000,\n  0x38400000, 0x38404000, 0x38408000, 0x3840C000, 0x38410000, 0x38414000, 0x38418000, 0x3841C000, 0x38420000, 0x38424000, 0x38428000, 0x3842C000, 0x38430000, 0x38434000, 0x38438000, 0x3843C000,\n  0x38440000, 0x38444000, 0x38448000, 0x3844C000, 0x38450000, 0x38454000, 0x38458000, 0x3845C000, 0x38460000, 0x38464000, 0x38468000, 0x3846C000, 0x38470000, 0x38474000, 0x38478000, 0x3847C000,\n  0x38480000, 0x38484000, 0x38488000, 0x3848C000, 0x38490000, 0x38494000, 0x38498000, 0x3849C000, 0x384A0000, 0x384A4000, 0x384A8000, 0x384AC000, 0x384B0000, 0x384B4000, 0x384B8000, 0x", "384BC000,\n  0x384C0000, 0x384C4000, 0x384C8000, 0x384CC000, 0x384D0000, 0x384D4000, 0x384D8000, 0x384DC000, 0x384E0000, 0x384E4000, 0x384E8000, 0x384EC000, 0x384F0000, 0x384F4000, 0x384F8000, 0x384FC000,\n  0x38500000, 0x38504000, 0x38508000, 0x3850C000, 0x38510000, 0x38514000, 0x38518000, 0x3851C000, 0x38520000, 0x38524000, 0x38528000, 0x3852C000, 0x38530000, 0x38534000, 0x38538000, 0x3853C000,\n  0x38540000, 0x38544000, 0x38548000, 0x3854C000, 0x38550000, 0x38554000, 0x38558000, 0x3855C000, 0x38560000, 0x38564000, 0x38568000, 0x3856C000, 0x38570000, 0x38574000, 0x38578000, 0x3857C000,\n  0x38580000, 0x38584000, 0x38588000, 0x3858C000, 0x38590000, 0x38594000, 0x38598000, 0x3859C000, 0x385A0000, 0x385A4000, 0x385A8000, 0x385AC000, 0x385B0000, 0x385B4000, 0x385B8000, 0x385BC000,\n  0x385C0000, 0x385C4000, 0x385C8000, 0x385CC000, 0x385D0000, 0x385D4000, 0x385D8000, 0x385DC000, 0x385E0000, 0x385E4000, 0x385E8000, 0x385EC000, 0x385F0000, 0x385F4000, 0x385F8000, 0x385FC000,\n  0x38600000, 0x38604000, 0x38608000, 0x3860C000, 0x38610000, 0x38614000, 0x38618000, 0x3861C000, 0x38620000, 0x38624000, 0x38628000, 0x3862C000, 0x38630000, 0x38634000, 0x38638000, 0x3863C000,\n  0x38640000, 0x38644000, 0x38648000, 0x3864C000, 0x38650000, 0x38654000, 0x38658000, 0x3865C000, 0x38660000, 0x38664000, 0x38668000, 0x3866C000, 0x38670000, 0x38674000, 0x38678000, 0x3867C000,\n  0x38680000, 0x38684000, 0x38688000, 0x3868C000, 0x38690000, 0x38694000, 0x38698000, 0x3869C000, 0x386A0000, 0x386A4000, 0x386A8000, 0x386AC000, 0x386B0000, 0x386B4000, 0x386B8000, 0x386BC000,\n  0x386C0000, 0x386C4000, 0x386C8000, 0x386CC000, 0x386D0000, 0x386D4000, 0x386D8000, 0x386DC000, 0x386E0000, 0x386E4000, 0x386E8000, 0x386EC000, 0x386F0000, 0x386F4000, 0x386F8000, 0x386FC000,\n  0x38700000, 0x38704000, 0x38708000, 0x3870C000, 0x38710000, 0x38714000, 0x38718000, 0x3871C000, 0x38720000, 0x38724000, 0x38728000, 0x3872C000, 0x38730000, 0x38734000, 0x38738000, 0x3873C000,\n  0x38740000, 0x38744000, 0x38748000, 0x3874C000, ", "0x38750000, 0x38754000, 0x38758000, 0x3875C000, 0x38760000, 0x38764000, 0x38768000, 0x3876C000, 0x38770000, 0x38774000, 0x38778000, 0x3877C000,\n  0x38780000, 0x38784000, 0x38788000, 0x3878C000, 0x38790000, 0x38794000, 0x38798000, 0x3879C000, 0x387A0000, 0x387A4000, 0x387A8000, 0x387AC000, 0x387B0000, 0x387B4000, 0x387B8000, 0x387BC000,\n  0x387C0000, 0x387C4000, 0x387C8000, 0x387CC000, 0x387D0000, 0x387D4000, 0x387D8000, 0x387DC000, 0x387E0000, 0x387E4000, 0x387E8000, 0x387EC000, 0x387F0000, 0x387F4000, 0x387F8000, 0x387FC000,\n  0x38000000, 0x38002000, 0x38004000, 0x38006000, 0x38008000, 0x3800A000, 0x3800C000, 0x3800E000, 0x38010000, 0x38012000, 0x38014000, 0x38016000, 0x38018000, 0x3801A000, 0x3801C000, 0x3801E000,\n  0x38020000, 0x38022000, 0x38024000, 0x38026000, 0x38028000, 0x3802A000, 0x3802C000, 0x3802E000, 0x38030000, 0x38032000, 0x38034000, 0x38036000, 0x38038000, 0x3803A000, 0x3803C000, 0x3803E000,\n  0x38040000, 0x38042000, 0x38044000, 0x38046000, 0x38048000, 0x3804A000, 0x3804C000, 0x3804E000, 0x38050000, 0x38052000, 0x38054000, 0x38056000, 0x38058000, 0x3805A000, 0x3805C000, 0x3805E000,\n  0x38060000, 0x38062000, 0x38064000, 0x38066000, 0x38068000, 0x3806A000, 0x3806C000, 0x3806E000, 0x38070000, 0x38072000, 0x38074000, 0x38076000, 0x38078000, 0x3807A000, 0x3807C000, 0x3807E000,\n  0x38080000, 0x38082000, 0x38084000, 0x38086000, 0x38088000, 0x3808A000, 0x3808C000, 0x3808E000, 0x38090000, 0x38092000, 0x38094000, 0x38096000, 0x38098000, 0x3809A000, 0x3809C000, 0x3809E000,\n  0x380A0000, 0x380A2000, 0x380A4000, 0x380A6000, 0x380A8000, 0x380AA000, 0x380AC000, 0x380AE000, 0x380B0000, 0x380B2000, 0x380B4000, 0x380B6000, 0x380B8000, 0x380BA000, 0x380BC000, 0x380BE000,\n  0x380C0000, 0x380C2000, 0x380C4000, 0x380C6000, 0x380C8000, 0x380CA000, 0x380CC000, 0x380CE000, 0x380D0000, 0x380D2000, 0x380D4000, 0x380D6000, 0x380D8000, 0x380DA000, 0x380DC000, 0x380DE000,\n  0x380E0000, 0x380E2000, 0x380E4000, 0x380E6000, 0x380E8000, 0x380EA000, 0x380EC000, 0x380EE000, 0x380F0000, ",
                                    "0x380F2000, 0x380F4000, 0x380F6000, 0x380F8000, 0x380FA000, 0x380FC000, 0x380FE000,\n  0x38100000, 0x38102000, 0x38104000, 0x38106000, 0x38108000, 0x3810A000, 0x3810C000, 0x3810E000, 0x38110000, 0x38112000, 0x38114000, 0x38116000, 0x38118000, 0x3811A000, 0x3811C000, 0x3811E000,\n  0x38120000, 0x38122000, 0x38124000, 0x38126000, 0x38128000, 0x3812A000, 0x3812C000, 0x3812E000, 0x38130000, 0x38132000, 0x38134000, 0x38136000, 0x38138000, 0x3813A000, 0x3813C000, 0x3813E000,\n  0x38140000, 0x38142000, 0x38144000, 0x38146000, 0x38148000, 0x3814A000, 0x3814C000, 0x3814E000, 0x38150000, 0x38152000, 0x38154000, 0x38156000, 0x38158000, 0x3815A000, 0x3815C000, 0x3815E000,\n  0x38160000, 0x38162000, 0x38164000, 0x38166000, 0x38168000, 0x3816A000, 0x3816C000, 0x3816E000, 0x38170000, 0x38172000, 0x38174000, 0x38176000, 0x38178000, 0x3817A000, 0x3817C000, 0x3817E000,\n  0x38180000, 0x38182000, 0x38184000, 0x38186000, 0x38188000, 0x3818A000, 0x3818C000, 0x3818E000, 0x38190000, 0x38192000, 0x38194000, 0x38196000, 0x38198000, 0x3819A000, 0x3819C000, 0x3819E000,\n  0x381A0000, 0x381A2000, 0x381A4000, 0x381A6000, 0x381A8000, 0x381AA000, 0x381AC000, 0x381AE000, 0x381B0000, 0x381B2000, 0x381B4000, 0x381B6000, 0x381B8000, 0x381BA000, 0x381BC000, 0x381BE000,\n  0x381C0000, 0x381C2000, 0x381C4000, 0x381C6000, 0x381C8000, 0x381CA000, 0x381CC000, 0x381CE000, 0x381D0000, 0x381D2000, 0x381D4000, 0x381D6000, 0x381D8000, 0x381DA000, 0x381DC000, 0x381DE000,\n  0x381E0000, 0x381E2000, 0x381E4000, 0x381E6000, 0x381E8000, 0x381EA000, 0x381EC000, 0x381EE000, 0x381F0000, 0x381F2000, 0x381F4000, 0x381F6000, 0x381F8000, 0x381FA000, 0x381FC000, 0x381FE000,\n  0x38200000, 0x38202000, 0x38204000, 0x38206000, 0x38208000, 0x3820A000, 0x3820C000, 0x3820E000, 0x38210000, 0x38212000, 0x38214000, 0x38216000, 0x38218000, 0x3821A000, 0x3821C000, 0x3821E000,\n  0x38220000, 0x38222000, 0x38224000, 0x38226000, 0x38228000, 0x3822A000, 0x3822C000, 0x3822E000, 0x38230000, 0x38232000, 0x38234000, 0x38236000, 0x38238000, 0x3823A000, ", "0x3823C000, 0x3823E000,\n  0x38240000, 0x38242000, 0x38244000, 0x38246000, 0x38248000, 0x3824A000, 0x3824C000, 0x3824E000, 0x38250000, 0x38252000, 0x38254000, 0x38256000, 0x38258000, 0x3825A000, 0x3825C000, 0x3825E000,\n  0x38260000, 0x38262000, 0x38264000, 0x38266000, 0x38268000, 0x3826A000, 0x3826C000, 0x3826E000, 0x38270000, 0x38272000, 0x38274000, 0x38276000, 0x38278000, 0x3827A000, 0x3827C000, 0x3827E000,\n  0x38280000, 0x38282000, 0x38284000, 0x38286000, 0x38288000, 0x3828A000, 0x3828C000, 0x3828E000, 0x38290000, 0x38292000, 0x38294000, 0x38296000, 0x38298000, 0x3829A000, 0x3829C000, 0x3829E000,\n  0x382A0000, 0x382A2000, 0x382A4000, 0x382A6000, 0x382A8000, 0x382AA000, 0x382AC000, 0x382AE000, 0x382B0000, 0x382B2000, 0x382B4000, 0x382B6000, 0x382B8000, 0x382BA000, 0x382BC000, 0x382BE000,\n  0x382C0000, 0x382C2000, 0x382C4000, 0x382C6000, 0x382C8000, 0x382CA000, 0x382CC000, 0x382CE000, 0x382D0000, 0x382D2000, 0x382D4000, 0x382D6000, 0x382D8000, 0x382DA000, 0x382DC000, 0x382DE000,\n  0x382E0000, 0x382E2000, 0x382E4000, 0x382E6000, 0x382E8000, 0x382EA000, 0x382EC000, 0x382EE000, 0x382F0000, 0x382F2000, 0x382F4000, 0x382F6000, 0x382F8000, 0x382FA000, 0x382FC000, 0x382FE000,\n  0x38300000, 0x38302000, 0x38304000, 0x38306000, 0x38308000, 0x3830A000, 0x3830C000, 0x3830E000, 0x38310000, 0x38312000, 0x38314000, 0x38316000, 0x38318000, 0x3831A000, 0x3831C000, 0x3831E000,\n  0x38320000, 0x38322000, 0x38324000, 0x38326000, 0x38328000, 0x3832A000, 0x3832C000, 0x3832E000, 0x38330000, 0x38332000, 0x38334000, 0x38336000, 0x38338000, 0x3833A000, 0x3833C000, 0x3833E000,\n  0x38340000, 0x38342000, 0x38344000, 0x38346000, 0x38348000, 0x3834A000, 0x3834C000, 0x3834E000, 0x38350000, 0x38352000, 0x38354000, 0x38356000, 0x38358000, 0x3835A000, 0x3835C000, 0x3835E000,\n  0x38360000, 0x38362000, 0x38364000, 0x38366000, 0x38368000, 0x3836A000, 0x3836C000, 0x3836E000, 0x38370000, 0x38372000, 0x38374000, 0x38376000, 0x38378000, 0x3837A000, 0x3837C000, 0x3837E000,\n  0x38380000, 0x38382000, 0x38384000", ", 0x38386000, 0x38388000, 0x3838A000, 0x3838C000, 0x3838E000, 0x38390000, 0x38392000, 0x38394000, 0x38396000, 0x38398000, 0x3839A000, 0x3839C000, 0x3839E000,\n  0x383A0000, 0x383A2000, 0x383A4000, 0x383A6000, 0x383A8000, 0x383AA000, 0x383AC000, 0x383AE000, 0x383B0000, 0x383B2000, 0x383B4000, 0x383B6000, 0x383B8000, 0x383BA000, 0x383BC000, 0x383BE000,\n  0x383C0000, 0x383C2000, 0x383C4000, 0x383C6000, 0x383C8000, 0x383CA000, 0x383CC000, 0x383CE000, 0x383D0000, 0x383D2000, 0x383D4000, 0x383D6000, 0x383D8000, 0x383DA000, 0x383DC000, 0x383DE000,\n  0x383E0000, 0x383E2000, 0x383E4000, 0x383E6000, 0x383E8000, 0x383EA000, 0x383EC000, 0x383EE000, 0x383F0000, 0x383F2000, 0x383F4000, 0x383F6000, 0x383F8000, 0x383FA000, 0x383FC000, 0x383FE000,\n  0x38400000, 0x38402000, 0x38404000, 0x38406000, 0x38408000, 0x3840A000, 0x3840C000, 0x3840E000, 0x38410000, 0x38412000, 0x38414000, 0x38416000, 0x38418000, 0x3841A000, 0x3841C000, 0x3841E000,\n  0x38420000, 0x38422000, 0x38424000, 0x38426000, 0x38428000, 0x3842A000, 0x3842C000, 0x3842E000, 0x38430000, 0x38432000, 0x38434000, 0x38436000, 0x38438000, 0x3843A000, 0x3843C000, 0x3843E000,\n  0x38440000, 0x38442000, 0x38444000, 0x38446000, 0x38448000, 0x3844A000, 0x3844C000, 0x3844E000, 0x38450000, 0x38452000, 0x38454000, 0x38456000, 0x38458000, 0x3845A000, 0x3845C000, 0x3845E000,\n  0x38460000, 0x38462000, 0x38464000, 0x38466000, 0x38468000, 0x3846A000, 0x3846C000, 0x3846E000, 0x38470000, 0x38472000, 0x38474000, 0x38476000, 0x38478000, 0x3847A000, 0x3847C000, 0x3847E000,\n  0x38480000, 0x38482000, 0x38484000, 0x38486000, 0x38488000, 0x3848A000, 0x3848C000, 0x3848E000, 0x38490000, 0x38492000, 0x38494000, 0x38496000, 0x38498000, 0x3849A000, 0x3849C000, 0x3849E000,\n  0x384A0000, 0x384A2000, 0x384A4000, 0x384A6000, 0x384A8000, 0x384AA000, 0x384AC000, 0x384AE000, 0x384B0000, 0x384B2000, 0x384B4000, 0x384B6000, 0x384B8000, 0x384BA000, 0x384BC000, 0x384BE000,\n  0x384C0000, 0x384C2000, 0x384C4000, 0x384C6000, 0x384C8000, 0x384CA000, 0x384CC000, 0x384CE000",
                                    ", 0x384D0000, 0x384D2000, 0x384D4000, 0x384D6000, 0x384D8000, 0x384DA000, 0x384DC000, 0x384DE000,\n  0x384E0000, 0x384E2000, 0x384E4000, 0x384E6000, 0x384E8000, 0x384EA000, 0x384EC000, 0x384EE000, 0x384F0000, 0x384F2000, 0x384F4000, 0x384F6000, 0x384F8000, 0x384FA000, 0x384FC000, 0x384FE000,\n  0x38500000, 0x38502000, 0x38504000, 0x38506000, 0x38508000, 0x3850A000, 0x3850C000, 0x3850E000, 0x38510000, 0x38512000, 0x38514000, 0x38516000, 0x38518000, 0x3851A000, 0x3851C000, 0x3851E000,\n  0x38520000, 0x38522000, 0x38524000, 0x38526000, 0x38528000, 0x3852A000, 0x3852C000, 0x3852E000, 0x38530000, 0x38532000, 0x38534000, 0x38536000, 0x38538000, 0x3853A000, 0x3853C000, 0x3853E000,\n  0x38540000, 0x38542000, 0x38544000, 0x38546000, 0x38548000, 0x3854A000, 0x3854C000, 0x3854E000, 0x38550000, 0x38552000, 0x38554000, 0x38556000, 0x38558000, 0x3855A000, 0x3855C000, 0x3855E000,\n  0x38560000, 0x38562000, 0x38564000, 0x38566000, 0x38568000, 0x3856A000, 0x3856C000, 0x3856E000, 0x38570000, 0x38572000, 0x38574000, 0x38576000, 0x38578000, 0x3857A000, 0x3857C000, 0x3857E000,\n  0x38580000, 0x38582000, 0x38584000, 0x38586000, 0x38588000, 0x3858A000, 0x3858C000, 0x3858E000, 0x38590000, 0x38592000, 0x38594000, 0x38596000, 0x38598000, 0x3859A000, 0x3859C000, 0x3859E000,\n  0x385A0000, 0x385A2000, 0x385A4000, 0x385A6000, 0x385A8000, 0x385AA000, 0x385AC000, 0x385AE000, 0x385B0000, 0x385B2000, 0x385B4000, 0x385B6000, 0x385B8000, 0x385BA000, 0x385BC000, 0x385BE000,\n  0x385C0000, 0x385C2000, 0x385C4000, 0x385C6000, 0x385C8000, 0x385CA000, 0x385CC000, 0x385CE000, 0x385D0000, 0x385D2000, 0x385D4000, 0x385D6000, 0x385D8000, 0x385DA000, 0x385DC000, 0x385DE000,\n  0x385E0000, 0x385E2000, 0x385E4000, 0x385E6000, 0x385E8000, 0x385EA000, 0x385EC000, 0x385EE000, 0x385F0000, 0x385F2000, 0x385F4000, 0x385F6000, 0x385F8000, 0x385FA000, 0x385FC000, 0x385FE000,\n  0x38600000, 0x38602000, 0x38604000, 0x38606000, 0x38608000, 0x3860A000, 0x3860C000, 0x3860E000, 0x38610000, 0x38612000, 0x38614000, 0x38616000, 0x38618000", ", 0x3861A000, 0x3861C000, 0x3861E000,\n  0x38620000, 0x38622000, 0x38624000, 0x38626000, 0x38628000, 0x3862A000, 0x3862C000, 0x3862E000, 0x38630000, 0x38632000, 0x38634000, 0x38636000, 0x38638000, 0x3863A000, 0x3863C000, 0x3863E000,\n  0x38640000, 0x38642000, 0x38644000, 0x38646000, 0x38648000, 0x3864A000, 0x3864C000, 0x3864E000, 0x38650000, 0x38652000, 0x38654000, 0x38656000, 0x38658000, 0x3865A000, 0x3865C000, 0x3865E000,\n  0x38660000, 0x38662000, 0x38664000, 0x38666000, 0x38668000, 0x3866A000, 0x3866C000, 0x3866E000, 0x38670000, 0x38672000, 0x38674000, 0x38676000, 0x38678000, 0x3867A000, 0x3867C000, 0x3867E000,\n  0x38680000, 0x38682000, 0x38684000, 0x38686000, 0x38688000, 0x3868A000, 0x3868C000, 0x3868E000, 0x38690000, 0x38692000, 0x38694000, 0x38696000, 0x38698000, 0x3869A000, 0x3869C000, 0x3869E000,\n  0x386A0000, 0x386A2000, 0x386A4000, 0x386A6000, 0x386A8000, 0x386AA000, 0x386AC000, 0x386AE000, 0x386B0000, 0x386B2000, 0x386B4000, 0x386B6000, 0x386B8000, 0x386BA000, 0x386BC000, 0x386BE000,\n  0x386C0000, 0x386C2000, 0x386C4000, 0x386C6000, 0x386C8000, 0x386CA000, 0x386CC000, 0x386CE000, 0x386D0000, 0x386D2000, 0x386D4000, 0x386D6000, 0x386D8000, 0x386DA000, 0x386DC000, 0x386DE000,\n  0x386E0000, 0x386E2000, 0x386E4000, 0x386E6000, 0x386E8000, 0x386EA000, 0x386EC000, 0x386EE000, 0x386F0000, 0x386F2000, 0x386F4000, 0x386F6000, 0x386F8000, 0x386FA000, 0x386FC000, 0x386FE000,\n  0x38700000, 0x38702000, 0x38704000, 0x38706000, 0x38708000, 0x3870A000, 0x3870C000, 0x3870E000, 0x38710000, 0x38712000, 0x38714000, 0x38716000, 0x38718000, 0x3871A000, 0x3871C000, 0x3871E000,\n  0x38720000, 0x38722000, 0x38724000, 0x38726000, 0x38728000, 0x3872A000, 0x3872C000, 0x3872E000, 0x38730000, 0x38732000, 0x38734000, 0x38736000, 0x38738000, 0x3873A000, 0x3873C000, 0x3873E000,\n  0x38740000, 0x38742000, 0x38744000, 0x38746000, 0x38748000, 0x3874A000, 0x3874C000, 0x3874E000, 0x38750000, 0x38752000, 0x38754000, 0x38756000, 0x38758000, 0x3875A000, 0x3875C000, 0x3875E000,\n  0x38760000, 0x387620", "00, 0x38764000, 0x38766000, 0x38768000, 0x3876A000, 0x3876C000, 0x3876E000, 0x38770000, 0x38772000, 0x38774000, 0x38776000, 0x38778000, 0x3877A000, 0x3877C000, 0x3877E000,\n  0x38780000, 0x38782000, 0x38784000, 0x38786000, 0x38788000, 0x3878A000, 0x3878C000, 0x3878E000, 0x38790000, 0x38792000, 0x38794000, 0x38796000, 0x38798000, 0x3879A000, 0x3879C000, 0x3879E000,\n  0x387A0000, 0x387A2000, 0x387A4000, 0x387A6000, 0x387A8000, 0x387AA000, 0x387AC000, 0x387AE000, 0x387B0000, 0x387B2000, 0x387B4000, 0x387B6000, 0x387B8000, 0x387BA000, 0x387BC000, 0x387BE000,\n  0x387C0000, 0x387C2000, 0x387C4000, 0x387C6000, 0x387C8000, 0x387CA000, 0x387CC000, 0x387CE000, 0x387D0000, 0x387D2000, 0x387D4000, 0x387D6000, 0x387D8000, 0x387DA000, 0x387DC000, 0x387DE000,\n  0x387E0000, 0x387E2000, 0x387E4000, 0x387E6000, 0x387E8000, 0x387EA000, 0x387EC000, 0x387EE000, 0x387F0000, 0x387F2000, 0x387F4000, 0x387F6000, 0x387F8000, 0x387FA000, 0x387FC000, 0x387FE000 };\n__constant static const uint32_t exponent_table[64] = {\n  0x00000000, 0x00800000, 0x01000000, 0x01800000, 0x02000000, 0x02800000, 0x03000000, 0x03800000, 0x04000000, 0x04800000, 0x05000000, 0x05800000, 0x06000000, 0x06800000, 0x07000000, 0x07800000,\n  0x08000000, 0x08800000, 0x09000000, 0x09800000, 0x0A000000, 0x0A800000, 0x0B000000, 0x0B800000, 0x0C000000, 0x0C800000, 0x0D000000, 0x0D800000, 0x0E000000, 0x0E800000, 0x0F000000, 0x47800000,\n  0x80000000, 0x80800000, 0x81000000, 0x81800000, 0x82000000, 0x82800000, 0x83000000, 0x83800000, 0x84000000, 0x84800000, 0x85000000, 0x85800000, 0x86000000, 0x86800000, 0x87000000, 0x87800000,\n  0x88000000, 0x88800000, 0x89000000, 0x89800000, 0x8A000000, 0x8A800000, 0x8B000000, 0x8B800000, 0x8C000000, 0x8C800000, 0x8D000000, 0x8D800000, 0x8E000000, 0x8E800000, 0x8F000000, 0xC7800000 };\n__constant static const unsigned short offset_table[64] = {\n  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1",
                                    "024, 1024, 1024, 1024, 1024, 1024,\n  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024 };\n\nSCALAR_FUN_ATTR uint16_t float2halfbits(float value) {\n  union { float x; uint32_t y; } u;\n  u.x = value;\n  uint32_t bits = u.y;\n\n  uint16_t hbits = base_table[bits>>23] + (uint16_t)((bits&0x7FFFFF)>>shift_table[bits>>23]);;\n\n  return hbits;\n}\n\nSCALAR_FUN_ATTR float halfbits2float(uint16_t value) {\n  uint32_t bits = mantissa_table[offset_table[value>>10]+(value&0x3FF)] + exponent_table[value>>10];\n\n  union { uint32_t x; float y; } u;\n  u.x = bits;\n  return u.y;\n}\n\nSCALAR_FUN_ATTR uint16_t halfbitsnextafter(uint16_t from, uint16_t to) {\n  int fabs = from & 0x7FFF, tabs = to & 0x7FFF;\n  if(fabs > 0x7C00 || tabs > 0x7C00) {\n    return ((from&0x7FFF)>0x7C00) ? (from|0x200) : (to|0x200);\n  }\n  if(from == to || !(fabs|tabs)) {\n    return to;\n  }\n  if(!fabs) {\n    return (to&0x8000)+1;\n  }\n  unsigned int out =\n    from +\n    (((from>>15)^(unsigned int)((from^(0x8000|(0x8000-(from>>15))))<(to^(0x8000|(0x8000-(to>>15))))))<<1)\n    - 1;\n  return out;\n}\n\n// End of half.h.\n// Start of scalar.h.\n\n// Implementation of the primitive scalar operations.  Very\n// repetitive.  This code is inserted directly into both CUDA and\n// OpenCL programs, as well as the CPU code, so it has some #ifdefs to\n// work everywhere.  Some operations are defined as macros because\n// this allows us to use them as constant expressions in things like\n// array sizes and static initialisers.\n\n// Some of the #ifdefs are because OpenCL uses type-generic functions\n// for some operations (e.g. sqrt), while C and CUDA sensibly use\n// distinct functions for different precisions (e.g. sqrtf() and\n// sqrt()).  This is quite annoying.  Due to C's unfortunate casting\n// rules, it is also really easy to accidentally implement\n// floating-point functions in the wrong precision, so be careful.\n\n/", "/ Double-precision definitions are only included if the preprocessor\n// macro FUTHARK_F64_ENABLED is set.\n\nSCALAR_FUN_ATTR int32_t futrts_to_bits32(float x);\nSCALAR_FUN_ATTR float futrts_from_bits32(int32_t x);\n\nSCALAR_FUN_ATTR uint8_t add8(uint8_t x, uint8_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint16_t add16(uint16_t x, uint16_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint32_t add32(uint32_t x, uint32_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint64_t add64(uint64_t x, uint64_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint8_t sub8(uint8_t x, uint8_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint16_t sub16(uint16_t x, uint16_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint32_t sub32(uint32_t x, uint32_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint64_t sub64(uint64_t x, uint64_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint8_t mul8(uint8_t x, uint8_t y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR uint16_t mul16(uint16_t x, uint16_t y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR uint32_t mul32(uint32_t x, uint32_t y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR uint64_t mul64(uint64_t x, uint64_t y) {\n  return x * y;\n}\n\n#if ISPC\n\nSCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {\n  // This strange pattern is used to prevent the ISPC compiler from\n  // causing SIGFPEs and bogus results on divisions where inactive lanes\n  // have 0-valued divisors. It ensures that any inactive lane instead\n  // has a divisor of 1. https://github.com/ispc/ispc/issues/2292\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {\n  uint", "8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALA",
                                    "R_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int8_t q = x / ys;\n  int8_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int16_t q = x / ys;\n  int16_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  int32_t q = x / ys;\n  int32_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int64_t q = x / ys;\n  int64_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {\n  return sdiv8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {\n  return sdiv16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y)", " {\n  return sdiv32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {\n  return sdiv64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int8_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int16_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int32_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int64_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : sdiv8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : sdiv16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : sdiv32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : sdiv64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {\n  return sdiv_safe8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {\n  return sdiv_safe16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {\n  return sdiv_safe32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {\n  return sdiv_safe64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : smod8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : smod16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) ", "{\n  return y == 0 ? 0 : smod32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : smod64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  ",
                                    "foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\n#else\n\nSCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {\n  return", " y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {\n  int8_t q = x / y;\n  int8_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {\n  int16_t q = x / y;\n  int16_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {\n  int32_t q = x / y;\n  int32_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {\n  int64_t q = x / y;\n  int64_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {\n  return sdiv8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {\n  return sdiv16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {\n  return sdiv32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {\n  return sdiv64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {\n  int8_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {\n  int16_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {\n  int32_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {\n  int64_t r = ", "x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : sdiv8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : sdiv16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : sdiv32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : sdiv64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {\n  return sdiv_safe8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {\n  return sdiv_safe16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {\n  return sdiv_safe32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {\n  return sdiv_safe64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : smod8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : smod16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : smod32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : smod64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t ",
                                    "y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\n#endif\n\nSCALAR_FUN_ATTR int8_t smin8(int8_t x, int8_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int16_t smin16(int16_t x, int16_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int32_t smin32(int32_t x, int32_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int64_t smin64(int64_t x, int64_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint8_t umin8(uint8_t x, uint8_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint16_t umin16(uint16_t x, uint16_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint32_t umin32(uint32_t x, uint32_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint64_t umin64(uint64_t x, uint64_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int8_t smax8(int8_t x, int8_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR int16_t smax16(int16_t x, int16_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR int32_t smax32(int32_t x, int32_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR int64_t smax64(int64_t x, int64_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint8_t umax8(uint8_t x, uint8_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint16_t umax16(uint16_t x, uint16_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint32_t umax32(uint32_t x, uint32_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint64_t umax64(uint64_t x, uint64_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint8_t shl8(uint8_t x, uint8_t y) {\n  return (uint8_t)(x << y);\n}\n\nS", "CALAR_FUN_ATTR uint16_t shl16(uint16_t x, uint16_t y) {\n  return (uint16_t)(x << y);\n}\n\nSCALAR_FUN_ATTR uint32_t shl32(uint32_t x, uint32_t y) {\n  return x << y;\n}\n\nSCALAR_FUN_ATTR uint64_t shl64(uint64_t x, uint64_t y) {\n  return x << y;\n}\n\nSCALAR_FUN_ATTR uint8_t lshr8(uint8_t x, uint8_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint16_t lshr16(uint16_t x, uint16_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint32_t lshr32(uint32_t x, uint32_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint64_t lshr64(uint64_t x, uint64_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int8_t ashr8(int8_t x, int8_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int16_t ashr16(int16_t x, int16_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int32_t ashr32(int32_t x, int32_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int64_t ashr64(int64_t x, int64_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint8_t and8(uint8_t x, uint8_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint16_t and16(uint16_t x, uint16_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint32_t and32(uint32_t x, uint32_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint64_t and64(uint64_t x, uint64_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint8_t or8(uint8_t x, uint8_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint16_t or16(uint16_t x, uint16_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint32_t or32(uint32_t x, uint32_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint64_t or64(uint64_t x, uint64_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint8_t xor8(uint8_t x, uint8_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR uint16_t xor16(uint16_t x, uint16_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR uint32_t xor32(uint32_t x, uint32_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR uint64_t xor64(uint64_t x, uint64_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR bool ult8(uint8_t x, uint8_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ult16(uint16_t x, uint16_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ult32(uint32_t x, uint32_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ult64(uint64_t x, uint64", "_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ule8(uint8_t x, uint8_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool ule16(uint16_t x, uint16_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool ule32(uint32_t x, uint32_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool ule64(uint64_t x, uint64_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool slt8(int8_t x, int8_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool slt16(int16_t x, int16_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool slt32(int32_t x, int32_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool slt64(int64_t x, int64_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool sle8(int8_t x, int8_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool sle16(int16_t x, int16_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool sle32(int32_t x, int32_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool sle64(int64_t x, int64_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR uint8_t pow8(uint8_t x, uint8_t y) {\n  uint8_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uint16_t pow16(uint16_t x, uint16_t y) {\n  uint16_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uint32_t pow32(uint32_t x, uint32_t y) {\n  uint32_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uint64_t pow64(uint64_t x, uint64_t y) {\n  uint64_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR bool itob_i8_bool(int8_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR bool itob_i16_bool(int16_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR bool itob_i32_bool(int32_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR bool itob_i64_bool(int64_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR int8_t btoi_bool_i8(bool x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR int16_t btoi_bool_i16(bool x",
                                    ") {\n  return x;\n}\n\nSCALAR_FUN_ATTR int32_t btoi_bool_i32(bool x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR int64_t btoi_bool_i64(bool x) {\n  return x;\n}\n\n#define sext_i8_i8(x) ((int8_t) (int8_t) (x))\n#define sext_i8_i16(x) ((int16_t) (int8_t) (x))\n#define sext_i8_i32(x) ((int32_t) (int8_t) (x))\n#define sext_i8_i64(x) ((int64_t) (int8_t) (x))\n#define sext_i16_i8(x) ((int8_t) (int16_t) (x))\n#define sext_i16_i16(x) ((int16_t) (int16_t) (x))\n#define sext_i16_i32(x) ((int32_t) (int16_t) (x))\n#define sext_i16_i64(x) ((int64_t) (int16_t) (x))\n#define sext_i32_i8(x) ((int8_t) (int32_t) (x))\n#define sext_i32_i16(x) ((int16_t) (int32_t) (x))\n#define sext_i32_i32(x) ((int32_t) (int32_t) (x))\n#define sext_i32_i64(x) ((int64_t) (int32_t) (x))\n#define sext_i64_i8(x) ((int8_t) (int64_t) (x))\n#define sext_i64_i16(x) ((int16_t) (int64_t) (x))\n#define sext_i64_i32(x) ((int32_t) (int64_t) (x))\n#define sext_i64_i64(x) ((int64_t) (int64_t) (x))\n#define zext_i8_i8(x) ((int8_t) (uint8_t) (x))\n#define zext_i8_i16(x) ((int16_t) (uint8_t) (x))\n#define zext_i8_i32(x) ((int32_t) (uint8_t) (x))\n#define zext_i8_i64(x) ((int64_t) (uint8_t) (x))\n#define zext_i16_i8(x) ((int8_t) (uint16_t) (x))\n#define zext_i16_i16(x) ((int16_t) (uint16_t) (x))\n#define zext_i16_i32(x) ((int32_t) (uint16_t) (x))\n#define zext_i16_i64(x) ((int64_t) (uint16_t) (x))\n#define zext_i32_i8(x) ((int8_t) (uint32_t) (x))\n#define zext_i32_i16(x) ((int16_t) (uint32_t) (x))\n#define zext_i32_i32(x) ((int32_t) (uint32_t) (x))\n#define zext_i32_i64(x) ((int64_t) (uint32_t) (x))\n#define zext_i64_i8(x) ((int8_t) (uint64_t) (x))\n#define zext_i64_i16(x) ((int16_t) (uint64_t) (x))\n#define zext_i64_i32(x) ((int32_t) (uint64_t) (x))\n#define zext_i64_i64(x) ((int64_t) (uint64_t) (x))\n\nSCALAR_FUN_ATTR int8_t abs8(int8_t x) {\n  return (int8_t)abs(x);\n}\n\nSCALAR_FUN_ATTR int16_t abs16(int16_t x) {\n  return (int16_t)abs(x);\n}\n\nSCALAR_FUN_ATTR int32_t abs32(int32_t x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR int64_t abs64(int64_t x) {\n#if defined(__OPENCL_VER", "SION__) || defined(ISPC)\n  return abs(x);\n#else\n  return llabs(x);\n#endif\n}\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {\n  return popcount(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {\n  return popcount(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {\n  return popcount(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {\n  return popcount(x);\n}\n#elif defined(__CUDA_ARCH__)\n\nSCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {\n  return __popc(zext_i8_i32(x));\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {\n  return __popc(zext_i16_i32(x));\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {\n  return __popc(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {\n  return __popcll(x);\n}\n\n#else // Not OpenCL or CUDA, but plain C.\n\nSCALAR_FUN_ATTR int32_t futrts_popc8(uint8_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc16(uint16_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc32(uint32_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc64(uint64_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR uint8_t  futrts_umul_hi8 ( uint8_t a,  uint8_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint8_t  futrts_smul_hi8 ( int8_t a,  int8_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return m", "ul_hi(a, b); }\n#elif defined(__CUDA_ARCH__)\nSCALAR_FUN_ATTR  uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return __umulhi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return __umul64hi(a, b); }\nSCALAR_FUN_ATTR  uint8_t futrts_smul_hi8 ( int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return __mulhi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return __mul64hi(a, b); }\n#elif ISPC\nSCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) {\n  uint64_t ah = a >> 32;\n  uint64_t al = a & 0xffffffff;\n  uint64_t bh = b >> 32;\n  uint64_t bl = b & 0xffffffff;\n\n  uint64_t p1 = al * bl;\n  uint64_t p2 = al * bh;\n  uint64_t p3 = ah * bl;\n  uint64_t p4 = ah * bh;\n\n  uint64_t p1h = p1 >> 32;\n  uint64_t p2h = p2 >> 32;\n  uint64_t p3h = p3 >> 32;\n  uint64_t p2l = p2 & 0xffffffff;\n  uint64_t p3l = p3 & 0xffffffff;\n\n  uint64_t l = p1h + p2l + p3l;\n  uint64_t m = (p2 >> 32) + (p3 >> 32);\n  uint64_t h = (l >> 32) + m + p4;\n\n  return h;\n}\nSCALAR_FUN_ATTR  int8_t futrts_smul_hi8 ( int8_t a,  int8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR int",
                                    "32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nSCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) {\n  uint64_t ah = a >> 32;\n  uint64_t al = a & 0xffffffff;\n  uint64_t bh = b >> 32;\n  uint64_t bl = b & 0xffffffff;\n\n  uint64_t p1 =  al * bl;\n  int64_t  p2 = al * bh;\n  int64_t  p3 = ah * bl;\n  uint64_t p4 =  ah * bh;\n\n  uint64_t p1h = p1 >> 32;\n  uint64_t p2h = p2 >> 32;\n  uint64_t p3h = p3 >> 32;\n  uint64_t p2l = p2 & 0xffffffff;\n  uint64_t p3l = p3 & 0xffffffff;\n\n  uint64_t l = p1h + p2l + p3l;\n  uint64_t m = (p2 >> 32) + (p3 >> 32);\n  uint64_t h = (l >> 32) + m + p4;\n\n  return h;\n}\n\n#else // Not OpenCL, ISPC, or CUDA, but plain C.\nSCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return ((__uint128_t)a) * ((__uint128_t)b) >> 64; }\nSCALAR_FUN_ATTR int8_t futrts_smul_hi8(int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }\nSCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }\nSCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((int64_t)a) * ((int64_t)b) >> 32; }\nSCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) { return ((__int128_t)a) * ((__int128_t)b) >> 64; }\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR  uint8_t futrts_umad_hi8 ( uint8_t a,  uint8_t b,  uint8_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t ", "a, uint64_t b, uint64_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR  uint8_t futrts_smad_hi8( int8_t a,  int8_t b,   int8_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return mad_hi(a, b, c); }\n#else // Not OpenCL\n\nSCALAR_FUN_ATTR  uint8_t futrts_umad_hi8( uint8_t a,  uint8_t b,  uint8_t c) { return futrts_umul_hi8(a, b) + c; }\nSCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return futrts_umul_hi16(a, b) + c; }\nSCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return futrts_umul_hi32(a, b) + c; }\nSCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return futrts_umul_hi64(a, b) + c; }\nSCALAR_FUN_ATTR  uint8_t futrts_smad_hi8 ( int8_t a,  int8_t b,  int8_t c) { return futrts_smul_hi8(a, b) + c; }\nSCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return futrts_smul_hi16(a, b) + c; }\nSCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return futrts_smul_hi32(a, b) + c; }\nSCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return futrts_smul_hi64(a, b) + c; }\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  return clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return clz(x);\n}\n\n#elif defined(__CUDA_ARCH__)\n\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return __clz(zext_i8_i32(x)) - 24;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return __clz(zext_i16_i32(x)) - 16;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  retur", "n __clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return __clzll(x);\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return count_leading_zeros((int32_t)(uint8_t)x)-24;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return count_leading_zeros((int32_t)(uint16_t)x)-16;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  return count_leading_zeros(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return count_leading_zeros(x);\n}\n\n#else // Not OpenCL, ISPC or CUDA, but plain C.\n\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return x == 0 ? 8 : __builtin_clz((uint32_t)zext_i8_i32(x)) - 24;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return x == 0 ? 16 : __builtin_clz((uint32_t)zext_i16_i32(x)) - 16;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  return x == 0 ? 32 : __builtin_clz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return x == 0 ? 64 : __builtin_clzll((uint64_t)x);\n}\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  int i = 0;\n  for (; i < 8 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  int i = 0;\n  for (; i < 16 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  int i = 0;\n  for (; i < 32 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  int i = 0;\n  for (; i < 64 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\n#elif defined(__CUDA_ARCH__)\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 8 : y - 1;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 16 : y - 1;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 32 : y - 1;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  int y = __ffsll(x);\n  return y == 0 ? 64 : y - 1",
                                    ";\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  return x == 0 ? 8 : count_trailing_zeros((int32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  return x == 0 ? 16 : count_trailing_zeros((int32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  return count_trailing_zeros(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  return count_trailing_zeros(x);\n}\n\n#else // Not OpenCL or CUDA, but plain C.\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  return x == 0 ? 8 : __builtin_ctz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  return x == 0 ? 16 : __builtin_ctz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  return x == 0 ? 32 : __builtin_ctz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  return x == 0 ? 64 : __builtin_ctzll((uint64_t)x);\n}\n#endif\n\nSCALAR_FUN_ATTR float fdiv32(float x, float y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR float fadd32(float x, float y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR float fsub32(float x, float y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR float fmul32(float x, float y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt32(float x, float y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple32(float x, float y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR float sitofp_i8_f32(int8_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float sitofp_i16_f32(int16_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float sitofp_i32_f32(int32_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float sitofp_i64_f32(int64_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i8_f32(uint8_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i16_f32(uint16_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i32_f32(uint32_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i64_f32(uint64_t x) {\n  return (float) x;\n}\n\n#ifdef __OPENCL_VERSION__\nSCALAR_FUN_ATTR float fabs32(float x) {\n  return fabs(x);\n}\n\nSCALAR_FUN_ATTR float fmax32(float x, f", "loat y) {\n  return fmax(x, y);\n}\n\nSCALAR_FUN_ATTR float fmin32(float x, float y) {\n  return fmin(x, y);\n}\n\nSCALAR_FUN_ATTR float fpow32(float x, float y) {\n  return pow(x, y);\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR float fabs32(float x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR float fmax32(float x, float y) {\n  return isnan(x) ? y : isnan(y) ? x : max(x, y);\n}\n\nSCALAR_FUN_ATTR float fmin32(float x, float y) {\n  return isnan(x) ? y : isnan(y) ? x : min(x, y);\n}\n\nSCALAR_FUN_ATTR float fpow32(float a, float b) {\n  float ret;\n  foreach_active (i) {\n      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));\n      ret = insert(ret, i, r);\n  }\n  return ret;\n}\n\n#else // Not OpenCL, but CUDA or plain C.\n\nSCALAR_FUN_ATTR float fabs32(float x) {\n  return fabsf(x);\n}\n\nSCALAR_FUN_ATTR float fmax32(float x, float y) {\n  return fmaxf(x, y);\n}\n\nSCALAR_FUN_ATTR float fmin32(float x, float y) {\n  return fminf(x, y);\n}\n\nSCALAR_FUN_ATTR float fpow32(float x, float y) {\n  return powf(x, y);\n}\n#endif\n\nSCALAR_FUN_ATTR bool futrts_isnan32(float x) {\n  return isnan(x);\n}\n\n#if ISPC\n\nSCALAR_FUN_ATTR bool futrts_isinf32(float x) {\n  return !isnan(x) && isnan(x - x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isfinite32(float x) {\n  return !isnan(x) && !futrts_isinf32(x);\n}\n\n#else\n\nSCALAR_FUN_ATTR bool futrts_isinf32(float x) {\n  return isinf(x);\n}\n\n#endif\n\nSCALAR_FUN_ATTR int8_t fptosi_f32_i8(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f32_i16(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f32_i32(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f32_i64(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  };\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f32_i8(float x) {", "\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f32_i16(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f32_i32(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f32_i64(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR bool ftob_f32_bool(float x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR float btof_bool_f32(bool x) {\n  return x ? 1 : 0;\n}\n\n#ifdef __OPENCL_VERSION__\nSCALAR_FUN_ATTR float futrts_log32(float x) {\n  return log(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log2_32(float x) {\n  return log2(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log10_32(float x) {\n  return log10(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log1p_32(float x) {\n  return log1p(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sqrt32(float x) {\n  return sqrt(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cbrt32(float x) {\n  return cbrt(x);\n}\n\nSCALAR_FUN_ATTR float futrts_exp32(float x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cos32(float x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sin32(float x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tan32(float x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acos32(float x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asin32(float x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan32(float x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cosh32(float x) {\n  return cosh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sinh32(float x) {\n  return sinh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tanh32(float x) {\n  return tanh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acosh32(float x) {\n  return acosh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asinh32(float x) {\n  return asinh(x);\n}\n\nSC",
                                    "ALAR_FUN_ATTR float futrts_atanh32(float x) {\n  return atanh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {\n  return atan2(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {\n  return hypot(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_gamma32(float x) {\n  return tgamma(x);\n}\n\nSCALAR_FUN_ATTR float futrts_lgamma32(float x) {\n  return lgamma(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erf32(float x) {\n  return erf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erfc32(float x) {\n  return erfc(x);\n}\n\nSCALAR_FUN_ATTR float fmod32(float x, float y) {\n  return fmod(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_round32(float x) {\n  return rint(x);\n}\n\nSCALAR_FUN_ATTR float futrts_floor32(float x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR float futrts_ceil32(float x) {\n  return ceil(x);\n}\n\nSCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {\n  return nextafter(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {\n  return mix(v0, v1, t);\n}\n\nSCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {\n  return ldexp(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {\n  return copysign(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {\n  return mad(a, b, c);\n}\n\nSCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {\n  return fma(a, b, c);\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR float futrts_log32(float x) {\n  return futrts_isfinite32(x) || (futrts_isinf32(x) && x < 0)? log(x) : x;\n}\n\nSCALAR_FUN_ATTR float futrts_log2_32(float x) {\n  return futrts_log32(x) / log(2.0f);\n}\n\nSCALAR_FUN_ATTR float futrts_log10_32(float x) {\n  return futrts_log32(x) / log(10.0f);\n}\n\nSCALAR_FUN_ATTR float futrts_log1p_32(float x) {\n  if(x == -1.0f || (futrts_isinf32(x) && x > 0.0f)) return x / 0.0f;\n  float y = 1.0f + x;\n  float z = y - 1.0f;\n  return log(y) - (z-x)/y;\n}\n\nSCALAR_FUN_ATTR float futrts_sqrt32(float x) {\n  return sqrt(x);\n}\n\nextern \"C\" unmasked uniform float cbrtf(uniform float);\nSCALAR_FUN_ATTR float futrts_cbrt32(float", " x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = cbrtf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR float futrts_exp32(float x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cos32(float x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sin32(float x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tan32(float x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acos32(float x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asin32(float x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan32(float x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cosh32(float x) {\n  return (exp(x)+exp(-x)) / 2.0f;\n}\n\nSCALAR_FUN_ATTR float futrts_sinh32(float x) {\n  return (exp(x)-exp(-x)) / 2.0f;\n}\n\nSCALAR_FUN_ATTR float futrts_tanh32(float x) {\n  return futrts_sinh32(x)/futrts_cosh32(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acosh32(float x) {\n  float f = x+sqrt(x*x-1);\n  if(futrts_isfinite32(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR float futrts_asinh32(float x) {\n  float f = x+sqrt(x*x+1);\n  if(futrts_isfinite32(f)) return log(f);\n  return f;\n\n}\n\nSCALAR_FUN_ATTR float futrts_atanh32(float x) {\n  float f = (1+x)/(1-x);\n  if(futrts_isfinite32(f)) return log(f)/2.0f;\n  return f;\n\n}\n\nSCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {\n  return (x == 0.0f && y == 0.0f) ? 0.0f : atan2(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {\n  if (futrts_isfinite32(x) && futrts_isfinite32(y)) {\n    x = abs(x);\n    y = abs(y);\n    float a;\n    float b;\n    if (x >= y){\n        a = x;\n        b = y;\n    } else {\n        a = y;\n        b = x;\n    }\n    if(b == 0){\n      return a;\n    }\n\n    int e;\n    float an;\n    float bn;\n    an = frexp (a, &e);\n    bn = ldexp (b, - e);\n    float cn;\n    cn = sqrt (an * an + bn * bn);\n    return ldexp (cn, e);\n  } else {\n    if (futrts_isinf32(x) || futrts_isinf32(y)) return INFINITY;\n    else return x + y;\n  }\n\n}\n\nextern \"C\" unmasked uniform float tgammaf(", "uniform float x);\nSCALAR_FUN_ATTR float futrts_gamma32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = tgammaf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float lgammaf(uniform float x);\nSCALAR_FUN_ATTR float futrts_lgamma32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = lgammaf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float erff(uniform float x);\nSCALAR_FUN_ATTR float futrts_erf32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = erff(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float erfcf(uniform float x);\nSCALAR_FUN_ATTR float futrts_erfc32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = erfcf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR float fmod32(float x, float y) {\n  return x - y * trunc(x/y);\n}\n\nSCALAR_FUN_ATTR float futrts_round32(float x) {\n  return round(x);\n}\n\nSCALAR_FUN_ATTR float futrts_floor32(float x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR float futrts_ceil32(float x) {\n  return ceil(x);\n}\n\nextern \"C\" unmasked uniform float nextafterf(uniform float x, uniform float y);\nSCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {\n  float res;\n  foreach_active (i) {\n    uniform float r = nextafterf(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {\n  return x * pow((double)2.0, (double)y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {\n  int32_t xb = futrts_to_bits32(x);\n  int32_t yb = futrts_to_bits32(y);\n  return futrts_from_bits32((xb & ~(1<<31)) | (yb & (1<<31)));\n}\n\nSCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR float futr",
                                    "ts_fma32(float a, float b, float c) {\n  return a * b + c;\n}\n\n#else // Not OpenCL or ISPC, but CUDA or plain C.\n\nSCALAR_FUN_ATTR float futrts_log32(float x) {\n  return logf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log2_32(float x) {\n  return log2f(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log10_32(float x) {\n  return log10f(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log1p_32(float x) {\n  return log1pf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sqrt32(float x) {\n  return sqrtf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cbrt32(float x) {\n  return cbrtf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_exp32(float x) {\n  return expf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cos32(float x) {\n  return cosf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sin32(float x) {\n  return sinf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tan32(float x) {\n  return tanf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acos32(float x) {\n  return acosf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asin32(float x) {\n  return asinf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan32(float x) {\n  return atanf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cosh32(float x) {\n  return coshf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sinh32(float x) {\n  return sinhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tanh32(float x) {\n  return tanhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acosh32(float x) {\n  return acoshf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asinh32(float x) {\n  return asinhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atanh32(float x) {\n  return atanhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {\n  return atan2f(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {\n  return hypotf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_gamma32(float x) {\n  return tgammaf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_lgamma32(float x) {\n  return lgammaf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erf32(float x) {\n  return erff(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erfc32(float x) {\n  return erfcf(x);\n}\n\nSCALAR_FUN_ATTR float fmod32(float x, float y) {\n  return fmodf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_round32(float x) {\n  re", "turn rintf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_floor32(float x) {\n  return floorf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_ceil32(float x) {\n  return ceilf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {\n  return nextafterf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {\n  return ldexpf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {\n  return copysignf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {\n  return fmaf(a, b, c);\n}\n#endif\n\n#if ISPC\nSCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {\n  return intbits(x);\n}\n\nSCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {\n  return floatbits(x);\n}\n#else\nSCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {\n  union {\n    float f;\n    int32_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {\n  union {\n    int32_t f;\n    float t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n#endif\n\nSCALAR_FUN_ATTR float fsignum32(float x) {\n  return futrts_isnan32(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nSCALAR_FUN_ATTR double futrts_from_bits64(int64_t x);\nSCALAR_FUN_ATTR int64_t futrts_to_bits64(double x);\n\n#if ISPC\nSCALAR_FUN_ATTR bool futrts_isinf64(float x) {\n  return !isnan(x) && isnan(x - x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isfinite64(float x) {\n  return !isnan(x) && !futrts_isinf64(x);\n}\n\nSCALAR_FUN_ATTR double fdiv64(double x, double y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR double fadd64(double x, double y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR double fsub64(double x, double y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR double fmul64(double x, double y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt64(double x, double y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple64(double x, double y) {\n  return x <= y;\n}", "\n\nSCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double fabs64(double x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR double fmax64(double x, double y) {\n  return isnan(x) ? y : isnan(y) ? x : max(x, y);\n}\n\nSCALAR_FUN_ATTR double fmin64(double x, double y) {\n  return isnan(x) ? y : isnan(y) ? x : min(x, y);\n}\n\nSCALAR_FUN_ATTR double fpow64(double a, double b) {\n  float ret;\n  foreach_active (i) {\n      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));\n      ret = insert(ret, i, r);\n  }\n  return ret;\n}\n\nSCALAR_FUN_ATTR double futrts_log64(double x) {\n  return futrts_isfinite64(x) || (futrts_isinf64(x) && x < 0)? log(x) : x;\n}\n\nSCALAR_FUN_ATTR double futrts_log2_64(double x) {\n  return futrts_log64(x)/log(2.0d);\n}\n\nSCALAR_FUN_ATTR double futrts_log10_64(double x) {\n  return futrts_log64(x)/log(10.0d);\n}\n\nSCALAR_FUN_ATTR double futrts_log1p_64(double x) {\n  if(x == -1.0d || (futrts_isinf64(x) && x > 0.0d)) return x / 0.0d;\n  double y = 1.0d + x;\n  double z = y - 1.0d;\n  return log(y) - (z-x)/y;\n}\n\nSCALAR_FUN_ATTR double futrts_sqrt64(double x) {\n  return sqrt(x);\n}\n\nextern \"C\" unmasked uniform double cbrt(uniform double);\nSCALAR_FUN_ATTR double futrts_cbrt64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = cbrtf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_exp64(double x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cos64(dou",
                                    "ble x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sin64(double x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_tan64(double x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acos64(double x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_asin64(double x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atan64(double x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cosh64(double x) {\n  return (exp(x)+exp(-x)) / 2.0d;\n}\n\nSCALAR_FUN_ATTR double futrts_sinh64(double x) {\n  return (exp(x)-exp(-x)) / 2.0d;\n}\n\nSCALAR_FUN_ATTR double futrts_tanh64(double x) {\n  return futrts_sinh64(x)/futrts_cosh64(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acosh64(double x) {\n  double f = x+sqrt(x*x-1.0d);\n  if(futrts_isfinite64(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR double futrts_asinh64(double x) {\n  double f = x+sqrt(x*x+1.0d);\n  if(futrts_isfinite64(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR double futrts_atanh64(double x) {\n  double f = (1.0d+x)/(1.0d-x);\n  if(futrts_isfinite64(f)) return log(f)/2.0d;\n  return f;\n\n}\n\nSCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {\n  return atan2(x, y);\n}\n\nextern \"C\" unmasked uniform double hypot(uniform double x, uniform double y);\nSCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {\n  double res;\n  foreach_active (i) {\n    uniform double r = hypot(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double tgamma(uniform double x);\nSCALAR_FUN_ATTR double futrts_gamma64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = tgamma(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double lgamma(uniform double x);\nSCALAR_FUN_ATTR double futrts_lgamma64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = lgamma(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double erf(uniform double x);\nSCALAR_FUN_ATTR do", "uble futrts_erf64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = erf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double erfc(uniform double x);\nSCALAR_FUN_ATTR double futrts_erfc64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = erfc(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR double futrts_round64(double x) {\n  return round(x);\n}\n\nSCALAR_FUN_ATTR double futrts_ceil64(double x) {\n  return ceil(x);\n}\n\nextern \"C\" unmasked uniform double nextafter(uniform float x, uniform double y);\nSCALAR_FUN_ATTR float futrts_nextafter64(double x, double y) {\n  double res;\n  foreach_active (i) {\n    uniform double r = nextafter(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_floor64(double x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isnan64(double x) {\n  return isnan(x);\n}\n\nSCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int", "16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR bool ftob_f64_bool(double x) {\n  return x != 0.0;\n}\n\nSCALAR_FUN_ATTR double btof_bool_f64(bool x) {\n  return x ? 1.0 : 0.0;\n}\n\nSCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {\n  int64_t res;\n  foreach_active (i) {\n    uniform double tmp = extract(x, i);\n    uniform int64_t r = *((uniform int64_t* uniform)&tmp);\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {\n  double res;\n  foreach_active (i) {\n    uniform int64_t tmp = extract(x, i);\n    uniform double r = *((uniform double* uniform)&tmp);\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double fmod64(double x, double y) {\n  return x - y * trunc(x/y);\n}\n\nSCALAR_FUN_ATTR double fsignum64(double x) {\n  return futrts_isnan64(x) ? x : (x > 0 ? 1.0d : 0.0d) - (x < 0 ? 1.0d : 0.0d);\n}\n\nSCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {\n  return x * pow((double)2.0, (double)y);\n}\n\nSCALAR_FUN_ATTR double futrts_copysign64(double x, double y) {\n  int64_t xb = futrts_to_bits64(x);\n  int64_t yb = futrts_to_bits64(y);\n  return futrts_from_bits64((xb & ~(((int64_t)1)<<63)) | (yb & (((int64_t)1)<<63)));\n}\n\nSCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR float fpconv_f32_f32(float x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f32_f64(float x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR float fpconv_f64_f32(double x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f64_f64(double x) {\n  return (double) x;\n}\n\n#e",
                                    "lse\n\nSCALAR_FUN_ATTR double fdiv64(double x, double y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR double fadd64(double x, double y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR double fsub64(double x, double y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR double fmul64(double x, double y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt64(double x, double y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple64(double x, double y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double fabs64(double x) {\n  return fabs(x);\n}\n\nSCALAR_FUN_ATTR double fmax64(double x, double y) {\n  return fmax(x, y);\n}\n\nSCALAR_FUN_ATTR double fmin64(double x, double y) {\n  return fmin(x, y);\n}\n\nSCALAR_FUN_ATTR double fpow64(double x, double y) {\n  return pow(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_log64(double x) {\n  return log(x);\n}\n\nSCALAR_FUN_ATTR double futrts_log2_64(double x) {\n  return log2(x);\n}\n\nSCALAR_FUN_ATTR double futrts_log10_64(double x) {\n  return log10(x);\n}\n\nSCALAR_FUN_ATTR double futrts_log1p_64(double x) {\n  return log1p(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sqrt64(double x) {\n  return sqrt(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cbrt64(double x) {\n  return cbrt(x);\n}\n\nSCALAR_FUN_ATTR double futrts_exp64(double x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cos64(double x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sin64(double x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_tan64(double x) {\n  r", "eturn tan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acos64(double x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_asin64(double x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atan64(double x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cosh64(double x) {\n  return cosh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sinh64(double x) {\n  return sinh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_tanh64(double x) {\n  return tanh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acosh64(double x) {\n  return acosh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_asinh64(double x) {\n  return asinh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atanh64(double x) {\n  return atanh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {\n  return atan2(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {\n  return hypot(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_gamma64(double x) {\n  return tgamma(x);\n}\n\nSCALAR_FUN_ATTR double futrts_lgamma64(double x) {\n  return lgamma(x);\n}\n\nSCALAR_FUN_ATTR double futrts_erf64(double x) {\n  return erf(x);\n}\n\nSCALAR_FUN_ATTR double futrts_erfc64(double x) {\n  return erfc(x);\n}\n\nSCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {\n  return fma(a, b, c);\n}\n\nSCALAR_FUN_ATTR double futrts_round64(double x) {\n  return rint(x);\n}\n\nSCALAR_FUN_ATTR double futrts_ceil64(double x) {\n  return ceil(x);\n}\n\nSCALAR_FUN_ATTR float futrts_nextafter64(float x, float y) {\n  return nextafter(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_floor64(double x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isnan64(double x) {\n  return isnan(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isinf64(double x) {\n  return isinf(x);\n}\n\nSCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x", ") {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR bool ftob_f64_bool(double x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR double btof_bool_f64(bool x) {\n  return x ? 1 : 0;\n}\n\nSCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {\n  union {\n    double f;\n    int64_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {\n  union {\n    int64_t f;\n    double t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR double fmod64(double x, double y) {\n  return fmod(x, y);\n}\n\nSCALAR_FUN_ATTR double fsignum64(double x) {\n  return futrts_isnan64(x) ? x : (x > 0) - (x < 0);\n}\n\nSCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {\n#ifdef __OPENCL_VERSION__\n  return mix(v0, v1, t);\n#else\n  return v0 + (v1 - v0) * t;\n#endif\n}\n\nSCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {\n  return ldexp(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign64(double x, double y) {\n  return copysign(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {\n#ifdef __OPENCL_VERSION__\n  return mad(a, b, c);\n#else\n  return a * b + c;\n#endif\n}\n\nSCALAR",
                                    "_FUN_ATTR float fpconv_f32_f32(float x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f32_f64(float x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR float fpconv_f64_f32(double x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f64_f64(double x) {\n  return (double) x;\n}\n\n#endif\n\n#endif\n\n// End of scalar.h.\n// Start of scalar_f16.h.\n\n// Half-precision is emulated if needed (e.g. in straight C) with the\n// native type used if possible.  The emulation works by typedef'ing\n// 'float' to 'f16', and then implementing all operations on single\n// precision.  To cut down on duplication, we use the same code for\n// those Futhark functions that require just operators or casts.  The\n// in-memory representation for arrays will still be 16 bits even\n// under emulation, so the compiler will have to be careful when\n// generating reads or writes.\n\n#if !defined(cl_khr_fp16) && !(defined(__CUDA_ARCH__) && __CUDA_ARCH__ >= 600) && !(defined(ISPC))\n#define EMULATE_F16\n#endif\n\n#if !defined(EMULATE_F16) && defined(__OPENCL_VERSION__)\n#pragma OPENCL EXTENSION cl_khr_fp16 : enable\n#endif\n\n#ifdef EMULATE_F16\n\n// Note that the half-precision storage format is still 16 bits - the\n// compiler will have to be real careful!\ntypedef float f16;\n\n#elif ISPC\ntypedef float16 f16;\n\n#else\n\n#ifdef __CUDA_ARCH__\n#include <cuda_fp16.h>\n#endif\n\ntypedef half f16;\n\n#endif\n\n// Some of these functions convert to single precision because half\n// precision versions are not available.\n\nSCALAR_FUN_ATTR f16 fadd16(f16 x, f16 y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR f16 fsub16(f16 x, f16 y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR f16 fmul16(f16 x, f16 y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt16(f16 x, f16 y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple16(f16 x, f16 y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR f16 sitofp_i8_f16(int8_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 sitofp_i16_f16(int16_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 sitofp_i32_f16(int32_t x) {\n  return (f16) x;\n}\n\nSCALAR", "_FUN_ATTR f16 sitofp_i64_f16(int64_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i8_f16(uint8_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i16_f16(uint16_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i32_f16(uint32_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i64_f16(uint64_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR int8_t fptosi_f16_i8(f16 x) {\n  return (int8_t) (float) x;\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f16_i16(f16 x) {\n  return (int16_t) x;\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f16_i32(f16 x) {\n  return (int32_t) x;\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f16_i64(f16 x) {\n  return (int64_t) x;\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f16_i8(f16 x) {\n  return (uint8_t) (float) x;\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f16_i16(f16 x) {\n  return (uint16_t) x;\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f16_i32(f16 x) {\n  return (uint32_t) x;\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f16_i64(f16 x) {\n  return (uint64_t) x;\n}\n\nSCALAR_FUN_ATTR bool ftob_f16_bool(f16 x) {\n  return x != (f16)0;\n}\n\nSCALAR_FUN_ATTR f16 btof_bool_f16(bool x) {\n  return x ? 1 : 0;\n}\n\n#ifndef EMULATE_F16\nSCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {\n  return isnan((float)x);\n}\n\n#ifdef __OPENCL_VERSION__\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return fabs(x);\n}\n\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return fmax(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {\n  return fmin(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return pow(x, y);\n}\n\n#elif ISPC\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : max(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {\n  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : min(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return pow(x, y);\n}\n\n#else // Assuming CUDA.\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return fabsf(x);\n}\n\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return fmaxf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 ", "x, f16 y) {\n  return fminf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return powf(x, y);\n}\n#endif\n\n#if ISPC\nSCALAR_FUN_ATTR bool futrts_isinf16(float x) {\n  return !futrts_isnan16(x) && futrts_isnan16(x - x);\n}\nSCALAR_FUN_ATTR bool futrts_isfinite16(float x) {\n  return !futrts_isnan16(x) && !futrts_isinf16(x);\n}\n\n#else\n\nSCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {\n  return isinf((float)x);\n}\n#endif\n\n#ifdef __OPENCL_VERSION__\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return log(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return log2(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return log10(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  return log1p(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return sqrt(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  return cbrt(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  return cosh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return sinh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return tanh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  return acosh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  return asinh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  return atanh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return atan2(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return hypot(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {\n  return tgamma(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  return lgamma(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  return e",
                                    "rf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  return erfc(x);\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return fmod(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return rint(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return ceil(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {\n  return nextafter(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return mix(v0, v1, t);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return ldexp(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return copysign(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return mad(a, b, c);\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return fma(a, b, c);\n}\n#elif ISPC\n\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return futrts_isfinite16(x) || (futrts_isinf16(x) && x < 0) ? log(x) : x;\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return futrts_log16(x) / log(2.0f16);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return futrts_log16(x) / log(10.0f16);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  if(x == -1.0f16 || (futrts_isinf16(x) && x > 0.0f16)) return x / 0.0f16;\n  f16 y = 1.0f16 + x;\n  f16 z = y - 1.0f16;\n  return log(y) - (z-x)/y;\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return (float16)sqrt((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return (float16)cos((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return (float16)sin((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return (float16)tan((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return (float16)acos((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return (float16)asin((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return (float16)atan((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  retu", "rn (exp(x)+exp(-x)) / 2.0f16;\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return (exp(x)-exp(-x)) / 2.0f16;\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return futrts_sinh16(x)/futrts_cosh16(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  float16 f = x+(float16)sqrt((float)(x*x-1));\n  if(futrts_isfinite16(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  float16 f = x+(float16)sqrt((float)(x*x+1));\n  if(futrts_isfinite16(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  float16 f = (1+x)/(1-x);\n  if(futrts_isfinite16(f)) return log(f)/2.0f16;\n  return f;\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return (float16)atan2((float)x, (float)y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return (float16)futrts_hypot32((float)x, (float)y);\n}\n\nextern \"C\" unmasked uniform float tgammaf(uniform float x);\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {\n  f16 res;\n  foreach_active (i) {\n    uniform f16 r = (f16)tgammaf(extract((float)x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float lgammaf(uniform float x);\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  f16 res;\n  foreach_active (i) {\n    uniform f16 r = (f16)lgammaf(extract((float)x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  f16 res = (f16)futrts_cbrt32((float)x);\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  f16 res = (f16)futrts_erf32((float)x);\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  f16 res = (f16)futrts_erfc32((float)x);\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return x - y * (float16)trunc((float) (x/y));\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return (float16)round((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return (float16)floor((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return (float16)ceil((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrt", "s_nextafter16(f16 x, f16 y) {\n  return (float16)futrts_nextafter32((float)x, (float) y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return futrts_ldexp32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return futrts_copysign32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\n#else // Assume CUDA.\n\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return hlog(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return hlog2(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return hlog10(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  return (f16)log1pf((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return hsqrt(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  return cbrtf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return hexp(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return hcos(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return hsin(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return tanf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return acosf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return asinf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return atanf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  return coshf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return sinhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return tanhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  return acoshf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  return asinhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  return atanhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return atan2f(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return hypotf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_gamma16(f1",
                                    "6 x) {\n  return tgammaf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  return lgammaf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  return erff(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  return erfcf(x);\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return fmodf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return rintf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return hfloor(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return hceil(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {\n  return __ushort_as_half(halfbitsnextafter(__half_as_ushort(x), __half_as_ushort(y)));\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return futrts_ldexp32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return futrts_copysign32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return fmaf(a, b, c);\n}\n\n#endif\n\n// The CUDA __half type cannot be put in unions for some reason, so we\n// use bespoke conversion functions instead.\n#ifdef __CUDA_ARCH__\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  return __half_as_ushort(x);\n}\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  return __ushort_as_half(x);\n}\n#elif ISPC\n\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  varying int16_t y = *((varying int16_t * uniform)&x);\n  return y;\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  varying f16 y = *((varying f16 * uniform)&x);\n  return y;\n}\n#else\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  union {\n    f16 f;\n    int16_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  union {\n    int16_t f;\n    f16 t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n#endif\n\n#else // No native f16 - emulate.\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return fabs32(x);\n}\n\nSC", "ALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return fmax32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {\n  return fmin32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return fpow32(x, y);\n}\n\nSCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {\n  return futrts_isnan32(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {\n  return futrts_isinf32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return futrts_log32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return futrts_log2_32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return futrts_log10_32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  return futrts_log1p_32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return futrts_sqrt32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  return futrts_cbrt32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return futrts_exp32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return futrts_cos32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return futrts_sin32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return futrts_tan32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return futrts_acos32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return futrts_asin32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return futrts_atan32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  return futrts_cosh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return futrts_sinh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return futrts_tanh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  return futrts_acosh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  return futrts_asinh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  return futrts_atanh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return futrts_atan2_32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return futrts_hypot32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {\n  return futrts_gamma32(x);\n}\n\nSCA", "LAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  return futrts_lgamma32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  return futrts_erf32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  return futrts_erfc32(x);\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return fmod32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return futrts_round32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return futrts_floor32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return futrts_ceil32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {\n  return halfbits2float(halfbitsnextafter(float2halfbits(x), float2halfbits(y)));\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return futrts_lerp32(v0, v1, t);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return futrts_ldexp32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return futrts_copysign32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return futrts_mad32(a, b, c);\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return futrts_fma32(a, b, c);\n}\n\n// Even when we are using an OpenCL that does not support cl_khr_fp16,\n// it must still support vload_half for actually creating a\n// half-precision number, which can then be efficiently converted to a\n// float.  Similarly for vstore_half.\n#ifdef __OPENCL_VERSION__\n\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  int16_t y;\n  // Violating strict aliasing here.\n  vstore_half((float)x, 0, (half*)&y);\n  return y;\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  return (f16)vload_half(0, (half*)&x);\n}\n\n#else\n\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  return (int16_t)float2halfbits(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  return halfbits2float((uint16_t)x);\n}\n\nSCALAR_FUN_ATTR f16 fsignum16(f16 x) {\n  return futrts_isnan16(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);\n}\n\n#endif\n\n#endif\n\nSCALAR_FUN_ATTR float fpconv_f16_f16(f16 x) {\n  retu",
                                    "rn x;\n}\n\nSCALAR_FUN_ATTR float fpconv_f16_f32(f16 x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR f16 fpconv_f32_f16(float x) {\n  return (f16) x;\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nSCALAR_FUN_ATTR double fpconv_f16_f64(f16 x) {\n  return (double) x;\n}\n\n#if ISPC\nSCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {\n  return (f16) ((float)x);\n}\n#else\nSCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {\n  return (f16) x;\n}\n#endif\n#endif\n\n\n// End of scalar_f16.h.\n// Start of atomics.h\n\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_global(volatile __global int32_t *p,\n                                                         int32_t cmp, int32_t val);\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_shared(volatile __local int32_t *p,\n                                                        int32_t cmp, int32_t val);\nSCALAR_FUN_ATTR int32_t atomic_add_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_add_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR float atomic_fadd_f32_global(volatile __global float *p, float x);\nSCALAR_FUN_ATTR float atomic_fadd_f32_shared(volatile __local float *p, float x);\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_global(volatile __global uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_shared(volatile __local uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_global(volatile __global uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_shared(volatile __local uint32", "_t *p, uint32_t x);\nSCALAR_FUN_ATTR int32_t atomic_and_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_and_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_or_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_or_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_shared(volatile __local int32_t *p, int32_t x);\n\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_global(volatile __global int32_t *p,\n                                                         int32_t cmp, int32_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((int32_t*)p, cmp, val);\n#else\n  return atomic_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_shared(volatile __local int32_t *p,\n                                                        int32_t cmp, int32_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((int32_t*)p, cmp, val);\n#else\n  return atomic_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_add_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((int32_t*)p, x);\n#else\n  return atomic_add(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_add_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((int32_t*)p, x);\n#el", "se\n  return atomic_add(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR float atomic_fadd_f32_global(volatile __global float *p, float x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((float*)p, x);\n  // On OpenCL, use technique from\n  // https://pipinspace.github.io/blog/atomic-float-addition-in-opencl.html\n#elif defined(cl_nv_pragma_unroll)\n  // use hardware-supported atomic addition on Nvidia GPUs with inline\n  // PTX assembly\n  float ret;\n  asm volatile(\"atom.global.add.f32 %0,[%1],%2;\":\"=f\"(ret):\"l\"(p),\"f\"(x):\"memory\");\n  return ret;\n#elif defined(__opencl_c_ext_fp32_global_atomic_add)\n  // use hardware-supported atomic addition on some Intel GPUs\n  return atomic_fetch_add_explicit((volatile __global atomic_float*)p,\n                                   x,\n                                   memory_order_relaxed);\n#elif __has_builtin(__builtin_amdgcn_global_atomic_fadd_f32)\n  // use hardware-supported atomic addition on some AMD GPUs\n  return __builtin_amdgcn_global_atomic_fadd_f32(p, x);\n#else\n  // fallback emulation:\n  // https://forums.developer.nvidia.com/t/atomicadd-float-float-atomicmul-float-float/14639/5\n  float old = x;\n  float ret;\n  while ((old=atomic_xchg(p, ret=atomic_xchg(p, 0.0f)+old))!=0.0f);\n  return ret;\n#endif\n}\n\nSCALAR_FUN_ATTR float atomic_fadd_f32_shared(volatile __local float *p, float x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((float*)p, x);\n#else\n  union { int32_t i; float f; } old;\n  union { int32_t i; float f; } assumed;\n  old.f = *p;\n  do {\n    assumed.f = old.f;\n    old.f = old.f + x;\n    old.i = atomic_cmpxchg_i32_shared((volatile __local int32_t*)p, assumed.i, old.i);\n  } while (assumed.i != old.i);\n  return old.f;\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((int32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_shared(volatile",
                                    " __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((int32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((int32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((int32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_global(volatile __global uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_shared(volatile __local uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_global(volatile __global uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_shared(volatile __local uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_and_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((int32_t*)p, x);\n#else\n  return atomic_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_and_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((int32_t*)p, x);\n#else\n  return atomic_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_or_i32_global(volatile __global int32_t *p, ", "int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((int32_t*)p, x);\n#else\n  return atomic_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_or_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((int32_t*)p, x);\n#else\n  return atomic_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\n// Start of 64 bit atomics\n\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP) || defined(cl_khr_int64_base_atomics) && defined(cl_khr_int64_extended_atomics)\n\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_global(volatile __global int64_t *p,\n                                                         int64_t cmp, int64_t val);\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_shared(volatile __local int64_t *p,\n                                                        int64_t cmp, int64_t val);\nSCALAR_FUN_ATTR int64_t atomic_add_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_add_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR uint", "64_t atomic_umax_i64_global(volatile __global uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_shared(volatile __local uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_global(volatile __global uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_shared(volatile __local uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR int64_t atomic_and_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_and_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_or_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_or_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_shared(volatile __local int64_t *p, int64_t x);\n\n#ifdef FUTHARK_F64_ENABLED\nSCALAR_FUN_ATTR double atomic_fadd_f64_global(volatile __global double *p, double x);\nSCALAR_FUN_ATTR double atomic_fadd_f64_shared(volatile __local double *p, double x);\n#endif\n\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_global(volatile __global int64_t *p,\n                                                         int64_t cmp, int64_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((uint64_t*)p, cmp, val);\n#else\n  return atom_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_shared(volatile __local int64_t *p,\n                                                        int64_t cmp, int64_t val) {\n#if defined(F",
                                    "UTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((uint64_t*)p, cmp, val);\n#else\n  return atom_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_add_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((uint64_t*)p, x);\n#else\n  return atom_add(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_add_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((uint64_t*)p, x);\n#else\n  return atom_add(p, x);\n#endif\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nSCALAR_FUN_ATTR double atomic_fadd_f64_global(volatile __global double *p, double x) {\n#if defined(FUTHARK_CUDA) && __CUDA_ARCH__ >= 600 || defined(FUTHARK_HIP)\n  return atomicAdd((double*)p, x);\n  // On OpenCL, use technique from\n  // https://pipinspace.github.io/blog/atomic-float-addition-in-opencl.html\n#elif defined(cl_nv_pragma_unroll)\n  // use hardware-supported atomic addition on Nvidia GPUs with inline\n  // PTX assembly\n  double ret;\n  asm volatile(\"atom.global.add.f64 %0,[%1],%2;\":\"=d\"(ret):\"l\"(p),\"d\"(x):\"memory\");\n  return ret;\n#elif __has_builtin(__builtin_amdgcn_global_atomic_fadd_f64)\n  // use hardware-supported atomic addition on some AMD GPUs\n  return __builtin_amdgcn_global_atomic_fadd_f64(p, x);\n#else\n  // fallback emulation:\n  // https://forums.developer.nvidia.com/t/atomicadd-float-float-atomicmul-float-float/14639/5\n  union {int64_t i; double f;} old;\n  union {int64_t i; double f;} ret;\n  old.f = x;\n  while (1) {\n    ret.i = atom_xchg((volatile __global int64_t*)p, (int64_t)0);\n    ret.f += old.f;\n    old.i = atom_xchg((volatile __global int64_t*)p, ret.i);\n    if (old.i == 0) {\n      break;\n    }\n  }\n  return ret.f;\n#endif\n}\n\nSCALAR_FUN_ATTR double atomic_fadd_f64_shared(volatile __local double *p, double x) {\n#if defined(FUTHARK_CUDA) && __CUDA_ARCH__ >= 600 || defined(FUTHARK_HIP)\n  return atomicAdd((double*)p, x);\n#else\n  union { int64_t i; double f; } old;\n  u", "nion { int64_t i; double f; } assumed;\n  old.f = *p;\n  do {\n    assumed.f = old.f;\n    old.f = old.f + x;\n    old.i = atomic_cmpxchg_i64_shared((volatile __local int64_t*)p, assumed.i, old.i);\n  } while (assumed.i != old.i);\n  return old.f;\n#endif\n}\n\n#endif\n\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMax((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smax64(old, x);\n    old = atomic_cmpxchg_i64_global((volatile __global int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMax((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smax64(old, x);\n    old = atomic_cmpxchg_i64_shared((volatile __local int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMin((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smin64(old, x);\n    old = atomic_cmpxchg_i64_global((volatile __global int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMin((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do ", "{\n    assumed = old;\n    old = smin64(old, x);\n    old = atomic_cmpxchg_i64_shared((volatile __local int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_global(volatile __global uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint64_t*)p, x);\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_shared(volatile __local uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint64_t*)p, x);\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_global(volatile __global uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint64_t*)p, x);\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_shared(volatile __local uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint64_t*)p, x);\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_and_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((uint64_t*)p, x);\n#else\n  return atom_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_and_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((uint64_t*)p, x);\n#else\n  return atom_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_or_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((uint64_t*)p, x);\n#else\n  return atom_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_or_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((uint64_t*)p, x);\n#else\n  return atom_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_global(v",
                                    "olatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\n#endif // defined(FUTHARK_CUDA) || defined(FUTHARK_HIP) || defined(cl_khr_int64_base_atomics) && defined(cl_khr_int64_extended_atomics)\n\n// End of atomics.h\n// Start of transpose.cl\n\n#define GEN_TRANSPOSE_KERNELS(NAME, ELEM_TYPE)                          \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*2, TR_TILE_DIM/TR_ELEMS_PER_THREAD, 1)\\\nvoid map_transpose_##NAME(SHARED_MEM_PARAM                              \\\n                          __global ELEM_TYPE *dst_mem,                  \\\n                          int64_t dst_offset,                           \\\n                          __global ELEM_TYPE *src_mem,                  \\\n                          int64_t src_offset,                           \\\n                          int32_t num_arrays,                           \\\n                          int32_t x_elems,                              \\\n                          int32_t y_elems,                              \\\n                          int32_t mulx,                                 \\\n                          int32_t muly,                                 \\\n                          int32_t repeat_1,                             \\\n                          int32_t repeat_2) {                           \\\n  (void)mulx; (void)muly;                                               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_g", "lobal_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t x_index = global_id_0;                                    \\\n      int32_t y_index = tblock_id_1 * TR_TILE_DIM + get_local_id(1);    \\\n      if (x_index < x_elems) {                                          \\\n        for (int32_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int32_t index_i = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * x_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < y_elems) { \\\n            block[(get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * (TR_TILE_DIM+1) + \\\n                  get_local_id(0)] =                                    \\\n              src_mem[idata_offset + index_i];                          \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_TILE_DIM + get_local_id(0);            \\\n      y_index = tblock_id_0 * TR_TILE_DIM + get_local_id(1);            \\\n      if (x_index < y_elems) {                                          \\\n        for (int32_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int32_t index_out = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * y_elems + x_index; \\\n          if (y_in", "dex + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < x_elems) { \\\n            dst_mem[(odata_offset + index_out)] =                       \\\n              block[get_local_id(0) * (TR_TILE_DIM+1) +                 \\\n                    get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)]; \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM, TR_BLOCK_DIM, 1)                     \\\nvoid map_transpose_##NAME##_low_height(SHARED_MEM_PARAM                 \\\n                                                __global ELEM_TYPE *dst_mem, \\\n                                                int64_t dst_offset,     \\\n                                                __global ELEM_TYPE *src_mem, \\\n                                                int64_t src_offset,     \\\n                                                int32_t num_arrays,     \\\n                                                int32_t x_elems,        \\\n                                                int32_t y_elems,        \\\n                                                int32_t mulx,           \\\n                                                int32_t muly,           \\\n                                                int32_t repeat_1,       \\\n ",
                                    "                                               int32_t repeat_2) {     \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t x_index =                                                 \\\n        tblock_id_0 * TR_BLOCK_DIM * mulx +                             \\\n        get_local_id(0) +                                               \\\n        get_local_id(1)%mulx * TR_BLOCK_DIM;                            \\\n      int32_t y_index = tblock_id_1 * TR_BLOCK_DIM + get_local_id(1)/mulx; \\\n      int32_t index_in = y_index * x_elems + x_index;                   \\\n      if (x_index < x_elems && y_index < y_elems) {                     \\\n        block[get_local_id(1) * (TR_BLOCK_DIM+1) + get_local_id(0)] =   \\\n          src_mem[idata_offset + index_in];                             \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_BLOCK_DIM + get_local_id(0)/mulx;      \\\n      y_index =                                                         \\\n        tblock_id_0 * TR_BLOCK_DIM * mulx +                             \\\n", "        get_local_id(1) +                                               \\\n        (get_local_id(0)%mulx) * TR_BLOCK_DIM;                          \\\n      int32_t index_out = y_index * y_elems + x_index;                  \\\n      if (x_index < y_elems && y_index < x_elems) {                     \\\n        dst_mem[odata_offset + index_out] =                             \\\n          block[get_local_id(0) * (TR_BLOCK_DIM+1) + get_local_id(1)];  \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM, TR_BLOCK_DIM, 1)                     \\\nvoid map_transpose_##NAME##_low_width(SHARED_MEM_PARAM                  \\\n                                      __global ELEM_TYPE *dst_mem,      \\\n                                      int64_t dst_offset,               \\\n                                      __global ELEM_TYPE *src_mem,      \\\n                                      int64_t src_offset,               \\\n                                      int32_t num_arrays,               \\\n                                      int32_t x_elems,                  \\\n                                      int32_t y_elems,                  \\\n                                      int32_t mulx,                     \\\n                                      int32_t muly,                     \\\n                                      int32_t repeat_1,                 \\\n  ", "                                    int32_t repeat_2) {               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t x_index = tblock_id_0 * TR_BLOCK_DIM + get_local_id(0)/muly; \\\n      int32_t y_index =                                                 \\\n        tblock_id_1 * TR_BLOCK_DIM * muly +                             \\\n        get_local_id(1) + (get_local_id(0)%muly) * TR_BLOCK_DIM;        \\\n      int32_t index_in = y_index * x_elems + x_index;                   \\\n      if (x_index < x_elems && y_index < y_elems) {                     \\\n        block[get_local_id(1) * (TR_BLOCK_DIM+1) + get_local_id(0)] =   \\\n          src_mem[idata_offset + index_in];                             \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_BLOCK_DIM * muly +                     \\\n        get_local_id(0) + (get_local_id(1)%muly) * TR_BLOCK_DIM;        \\\n      y_index = tblock_id_0 * TR_BLOCK_DIM + get_local_id(1)/muly;      \\\n      int32_t index_out = y_index * y_elems + x_index;                  \\\n ",
                                    "     if (x_index < y_elems && y_index < x_elems) {                     \\\n        dst_mem[odata_offset + index_out] =                             \\\n          block[get_local_id(0) * (TR_BLOCK_DIM+1) + get_local_id(1)];  \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_num_tblocks(2) * get_local_size(2);            \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_num_tblocks(1) * get_local_size(1);              \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*TR_BLOCK_DIM, 1, 1)                   \\\nvoid map_transpose_##NAME##_small(SHARED_MEM_PARAM                       \\\n                                  __global ELEM_TYPE *dst_mem,          \\\n                                  int64_t dst_offset,                   \\\n                                  __global ELEM_TYPE *src_mem,          \\\n                                  int64_t src_offset,                   \\\n                                  int32_t num_arrays,                   \\\n                                  int32_t x_elems,                      \\\n                                  int32_t y_elems,                      \\\n                                  int32_t mulx,                         \\\n                                  int32_t muly,                         \\\n                                  int32_t repeat_1,                     \\\n                                  int32_t repeat_2) {                   \\\n  (void)mulx; (void)muly;                                               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  ", "int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = global_id_0/(y_elems * x_elems) * y_elems * x_elems; \\\n      int32_t x_index = (global_id_0 % (y_elems * x_elems))/y_elems;    \\\n      int32_t y_index = global_id_0%y_elems;                            \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t index_in = y_index * x_elems + x_index;                   \\\n      int32_t index_out = x_index * y_elems + y_index;                  \\\n      if (global_id_0 < x_elems * y_elems * num_arrays) {               \\\n        dst_mem[odata_offset + index_out] = src_mem[idata_offset + index_in]; \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*2, TR_TILE_DIM/TR_ELEMS_", "PER_THREAD, 1)\\\nvoid map_transpose_##NAME##_large(SHARED_MEM_PARAM                      \\\n                                  __global ELEM_TYPE *dst_mem,          \\\n                                  int64_t dst_offset,                   \\\n                                  __global ELEM_TYPE *src_mem,          \\\n                                  int64_t src_offset,                   \\\n                                  int64_t num_arrays,                   \\\n                                  int64_t x_elems,                      \\\n                                  int64_t y_elems,                      \\\n                                  int64_t mulx,                         \\\n                                  int64_t muly,                         \\\n                                  int32_t repeat_1,                     \\\n                                  int32_t repeat_2) {                   \\\n  (void)mulx; (void)muly;                                               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;             \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int64_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int64_t odata_offset = dst_offset + our_array_offset;             \\\n      int64_t idata_offset = src_offset + our_array_offset;             \\\n      int64_t x_index = global_id_0;                                    \\\n      int64_t y_index = tblock_id_1 * TR_TILE_DIM + get_loc",
                                    "al_id(1);    \\\n      if (x_index < x_elems) {                                          \\\n        for (int64_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int64_t index_i = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * x_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < y_elems) { \\\n            block[(get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * (TR_TILE_DIM+1) + \\\n                  get_local_id(0)] =                                    \\\n              src_mem[idata_offset + index_i];                          \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_TILE_DIM + get_local_id(0);            \\\n      y_index = tblock_id_0 * TR_TILE_DIM + get_local_id(1);            \\\n      if (x_index < y_elems) {                                          \\\n        for (int64_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int64_t index_out = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * y_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < x_elems) { \\\n            dst_mem[(odata_offset + index_out)] =                       \\\n              block[get_local_id(0) * (TR_TILE_DIM+1) +                 \\\n                    get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)]; \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                      ", "                             \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n\nGEN_TRANSPOSE_KERNELS(1b, uint8_t)\nGEN_TRANSPOSE_KERNELS(2b, uint16_t)\nGEN_TRANSPOSE_KERNELS(4b, uint32_t)\nGEN_TRANSPOSE_KERNELS(8b, uint64_t)\n\n// End of transpose.cl\n// Start of copy.cl\n\n#define GEN_COPY_KERNEL(NAME, ELEM_TYPE) \\\nFUTHARK_KERNEL void lmad_copy_##NAME(SHARED_MEM_PARAM                   \\\n                               __global ELEM_TYPE *dst_mem,             \\\n                               int64_t dst_offset,                      \\\n                               __global ELEM_TYPE *src_mem,             \\\n                               int64_t src_offset,                      \\\n                               int64_t n,                               \\\n                               int r,                                   \\\n                               int64_t shape0, int64_t dst_stride0, int64_t src_stride0, \\\n                               int64_t shape1, int64_t dst_stride1, int64_t src_stride1, \\\n                               int64_t shape2, int64_t dst_stride2, int64_t src_stride2, \\\n                               int64_t shape3, int64_t dst_stride3, int64_t src_stride3, \\\n                               int64_t shape4, int64_t dst_stride4, int64_t src_stride4, \\\n                               int64_t shape5, int64_t dst_stride5, int64_t src_stride5, \\\n                               int64_t shape6, int64_t dst_stride6, int64_t src_stride6, \\\n                               int64_t shape7, int64_t dst_stride7, int64_t src_stride7) { \\\n  int64_t gtid = get_global_id(0);                                      \\\n  int64_t remainder = gtid;                                             \\\n                                             ", "                           \\\n  if (gtid >= n) {                                                      \\\n    return;                                                             \\\n  }                                                                     \\\n                                                                        \\\n  if (r > 0) {                                                          \\\n    int64_t i = remainder % shape0;                                     \\\n    dst_offset += i * dst_stride0;                                      \\\n    src_offset += i * src_stride0;                                      \\\n    remainder /= shape0;                                                \\\n  }                                                                     \\\n  if (r > 1) {                                                          \\\n    int64_t i = remainder % shape1;                                     \\\n    dst_offset += i * dst_stride1;                                      \\\n    src_offset += i * src_stride1;                                      \\\n    remainder /= shape1;                                                \\\n  }                                                                     \\\n  if (r > 2) {                                                          \\\n    int64_t i = remainder % shape2;                                     \\\n    dst_offset += i * dst_stride2;                                      \\\n    src_offset += i * src_stride2;                                      \\\n    remainder /= shape2;                                                \\\n  }                                                                     \\\n  if (r > 3) {                                                          \\\n    int64_t i = remainder % shape3;                                     \\\n    dst_offset += i * dst_stride3;                                      \\\n    src_offset += i * src_stride3;                                      \\\n    remainder /= shape3;                       ",
                                    "                         \\\n  }                                                                     \\\n  if (r > 4) {                                                          \\\n    int64_t i = remainder % shape4;                                     \\\n    dst_offset += i * dst_stride4;                                      \\\n    src_offset += i * src_stride4;                                      \\\n    remainder /= shape4;                                                \\\n  }                                                                     \\\n  if (r > 5) {                                                          \\\n    int64_t i = remainder % shape5;                                     \\\n    dst_offset += i * dst_stride5;                                      \\\n    src_offset += i * src_stride5;                                      \\\n    remainder /= shape5;                                                \\\n  }                                                                     \\\n  if (r > 6) {                                                          \\\n    int64_t i = remainder % shape6;                                     \\\n    dst_offset += i * dst_stride6;                                      \\\n    src_offset += i * src_stride6;                                      \\\n    remainder /= shape6;                                                \\\n  }                                                                     \\\n  if (r > 7) {                                                          \\\n    int64_t i = remainder % shape7;                                     \\\n    dst_offset += i * dst_stride7;                                      \\\n    src_offset += i * src_stride7;                                      \\\n    remainder /= shape7;                                                \\\n  }                                                                     \\\n                                                                        \\\n  dst_mem[dst_offset] = src_mem[src_offset];     ", "                       \\\n}\n\nGEN_COPY_KERNEL(1b, uint8_t)\nGEN_COPY_KERNEL(2b, uint16_t)\nGEN_COPY_KERNEL(4b, uint32_t)\nGEN_COPY_KERNEL(8b, uint64_t)\n\n// End of copy.cl\n\n\n\nFUTHARK_KERNEL\nvoid builtinzhiota_i64ziiota_i64_42712(int64_t n_42708, int64_t x_42709, int64_t s_42710, int64_t virt_num_tblocks_42717, int64_t num_tblocks_42718, __global unsigned char *mem_42707)\n{\n    int32_t iota_ltid_42713;\n    int32_t tblock_sizze_42715;\n    int32_t iota_gid_42714;\n    int32_t iota_gtid_42712;\n    int32_t phys_tblock_id_42719;\n    int32_t iterations_42720;\n    \n    iota_ltid_42713 = get_local_id(0);\n    tblock_sizze_42715 = get_local_size(0);\n    iota_gid_42714 = get_tblock_id(0);\n    iota_gtid_42712 = iota_gid_42714 * tblock_sizze_42715 + iota_ltid_42713;\n    phys_tblock_id_42719 = get_tblock_id(0);\n    iterations_42720 = sdiv_up32(sext_i64_i32(virt_num_tblocks_42717) - phys_tblock_id_42719, sext_i64_i32(num_tblocks_42718));\n    for (int32_t i_42721 = 0; i_42721 < iterations_42720; i_42721++) {\n        int32_t virt_tblock_id_42722;\n        int64_t global_tid_42723;\n        \n        virt_tblock_id_42722 = phys_tblock_id_42719 + i_42721 * sext_i64_i32(num_tblocks_42718);\n        global_tid_42723 = sext_i32_i64(virt_tblock_id_42722) * sext_i32_i64(tblock_sizze_42715) + sext_i32_i64(iota_ltid_42713);\n        if (slt64(global_tid_42723, n_42708)) {\n            ((__global int64_t *) mem_42707)[global_tid_42723] = add64(mul64(global_tid_42723, s_42710), x_42709);\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_f32zireplicate_42741(int64_t num_elems_42737, float val_42738, int64_t replicate_n_42740, int64_t virt_num_tblocks_42746, int64_t num_tblocks_42747, __global unsigned char *mem_42736)\n{\n    int32_t replicate_ltid_42742;\n    int32_t tblock_sizze_42744;\n    int32_t replicate_gid_42743;\n    int32_t replicate_gtid_42741;\n    int32_t phys_tblock_id_42748;\n    int32_t iterations_42749;\n", "    \n    replicate_ltid_42742 = get_local_id(0);\n    tblock_sizze_42744 = get_local_size(0);\n    replicate_gid_42743 = get_tblock_id(0);\n    replicate_gtid_42741 = replicate_gid_42743 * tblock_sizze_42744 + replicate_ltid_42742;\n    phys_tblock_id_42748 = get_tblock_id(0);\n    iterations_42749 = sdiv_up32(sext_i64_i32(virt_num_tblocks_42746) - phys_tblock_id_42748, sext_i64_i32(num_tblocks_42747));\n    for (int32_t i_42750 = 0; i_42750 < iterations_42749; i_42750++) {\n        int32_t virt_tblock_id_42751;\n        int64_t global_tid_42752;\n        int64_t slice_42754;\n        int64_t rep_i_42753;\n        int64_t remnant_42755;\n        \n        virt_tblock_id_42751 = phys_tblock_id_42748 + i_42750 * sext_i64_i32(num_tblocks_42747);\n        global_tid_42752 = sext_i32_i64(virt_tblock_id_42751) * sext_i32_i64(tblock_sizze_42744) + sext_i32_i64(replicate_ltid_42742);\n        slice_42754 = num_elems_42737;\n        rep_i_42753 = global_tid_42752;\n        remnant_42755 = global_tid_42752 - rep_i_42753;\n        if (slt64(global_tid_42752, replicate_n_42740)) {\n            ((__global float *) mem_42736)[rep_i_42753] = val_42738;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_f64zireplicate_42741(int64_t num_elems_42737, double val_42738, int64_t replicate_n_42740, int64_t virt_num_tblocks_42746, int64_t num_tblocks_42747, __global unsigned char *mem_42736)\n{\n    int32_t replicate_ltid_42742;\n    int32_t tblock_sizze_42744;\n    int32_t replicate_gid_42743;\n    int32_t replicate_gtid_42741;\n    int32_t phys_tblock_id_42748;\n    int32_t iterations_42749;\n    \n    replicate_ltid_42742 = get_local_id(0);\n    tblock_sizze_42744 = get_local_size(0);\n    replicate_gid_42743 = get_tblock_id(0);\n    replicate_gtid_42741 = replicate_gid_42743 * tblock_sizze_42744 + replicate_ltid_42742;\n    phys_tblock_id_42748 = get_tblock_id(0);\n    iterations_42749 = sdiv_up32(sext_i64_i32(virt_num_tblo",
                                    "cks_42746) - phys_tblock_id_42748, sext_i64_i32(num_tblocks_42747));\n    for (int32_t i_42750 = 0; i_42750 < iterations_42749; i_42750++) {\n        int32_t virt_tblock_id_42751;\n        int64_t global_tid_42752;\n        int64_t slice_42754;\n        int64_t rep_i_42753;\n        int64_t remnant_42755;\n        \n        virt_tblock_id_42751 = phys_tblock_id_42748 + i_42750 * sext_i64_i32(num_tblocks_42747);\n        global_tid_42752 = sext_i32_i64(virt_tblock_id_42751) * sext_i32_i64(tblock_sizze_42744) + sext_i32_i64(replicate_ltid_42742);\n        slice_42754 = num_elems_42737;\n        rep_i_42753 = global_tid_42752;\n        remnant_42755 = global_tid_42752 - rep_i_42753;\n        if (slt64(global_tid_42752, replicate_n_42740)) {\n            ((__global double *) mem_42736)[rep_i_42753] = val_42738;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_i16zireplicate_42741(int64_t num_elems_42737, int16_t val_42738, int64_t replicate_n_42740, int64_t virt_num_tblocks_42746, int64_t num_tblocks_42747, __global unsigned char *mem_42736)\n{\n    int32_t replicate_ltid_42742;\n    int32_t tblock_sizze_42744;\n    int32_t replicate_gid_42743;\n    int32_t replicate_gtid_42741;\n    int32_t phys_tblock_id_42748;\n    int32_t iterations_42749;\n    \n    replicate_ltid_42742 = get_local_id(0);\n    tblock_sizze_42744 = get_local_size(0);\n    replicate_gid_42743 = get_tblock_id(0);\n    replicate_gtid_42741 = replicate_gid_42743 * tblock_sizze_42744 + replicate_ltid_42742;\n    phys_tblock_id_42748 = get_tblock_id(0);\n    iterations_42749 = sdiv_up32(sext_i64_i32(virt_num_tblocks_42746) - phys_tblock_id_42748, sext_i64_i32(num_tblocks_42747));\n    for (int32_t i_42750 = 0; i_42750 < iterations_42749; i_42750++) {\n        int32_t virt_tblock_id_42751;\n        int64_t global_tid_42752;\n        int64_t slice_42754;\n        int64_t rep_i_42753;\n        int64_t remnant_42755;\n        \n        virt_tblock_i", "d_42751 = phys_tblock_id_42748 + i_42750 * sext_i64_i32(num_tblocks_42747);\n        global_tid_42752 = sext_i32_i64(virt_tblock_id_42751) * sext_i32_i64(tblock_sizze_42744) + sext_i32_i64(replicate_ltid_42742);\n        slice_42754 = num_elems_42737;\n        rep_i_42753 = global_tid_42752;\n        remnant_42755 = global_tid_42752 - rep_i_42753;\n        if (slt64(global_tid_42752, replicate_n_42740)) {\n            ((__global int16_t *) mem_42736)[rep_i_42753] = val_42738;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_i32zireplicate_42884(int64_t num_elems_42880, int32_t val_42881, int64_t replicate_n_42883, int64_t virt_num_tblocks_42889, int64_t num_tblocks_42890, __global unsigned char *mem_42879)\n{\n    int32_t replicate_ltid_42885;\n    int32_t tblock_sizze_42887;\n    int32_t replicate_gid_42886;\n    int32_t replicate_gtid_42884;\n    int32_t phys_tblock_id_42891;\n    int32_t iterations_42892;\n    \n    replicate_ltid_42885 = get_local_id(0);\n    tblock_sizze_42887 = get_local_size(0);\n    replicate_gid_42886 = get_tblock_id(0);\n    replicate_gtid_42884 = replicate_gid_42886 * tblock_sizze_42887 + replicate_ltid_42885;\n    phys_tblock_id_42891 = get_tblock_id(0);\n    iterations_42892 = sdiv_up32(sext_i64_i32(virt_num_tblocks_42889) - phys_tblock_id_42891, sext_i64_i32(num_tblocks_42890));\n    for (int32_t i_42893 = 0; i_42893 < iterations_42892; i_42893++) {\n        int32_t virt_tblock_id_42894;\n        int64_t global_tid_42895;\n        int64_t slice_42897;\n        int64_t rep_i_42896;\n        int64_t remnant_42898;\n        \n        virt_tblock_id_42894 = phys_tblock_id_42891 + i_42893 * sext_i64_i32(num_tblocks_42890);\n        global_tid_42895 = sext_i32_i64(virt_tblock_id_42894) * sext_i32_i64(tblock_sizze_42887) + sext_i32_i64(replicate_ltid_42885);\n        slice_42897 = num_elems_42880;\n        rep_i_42896 = global_tid_42895;\n        remnant_42898 = global_tid_42895", " - rep_i_42896;\n        if (slt64(global_tid_42895, replicate_n_42883)) {\n            ((__global int32_t *) mem_42879)[rep_i_42896] = val_42881;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_i64zireplicate_42715(int64_t num_elems_42711, int64_t val_42712, int64_t replicate_n_42714, int64_t virt_num_tblocks_42720, int64_t num_tblocks_42721, __global unsigned char *mem_42710)\n{\n    int32_t replicate_ltid_42716;\n    int32_t tblock_sizze_42718;\n    int32_t replicate_gid_42717;\n    int32_t replicate_gtid_42715;\n    int32_t phys_tblock_id_42722;\n    int32_t iterations_42723;\n    \n    replicate_ltid_42716 = get_local_id(0);\n    tblock_sizze_42718 = get_local_size(0);\n    replicate_gid_42717 = get_tblock_id(0);\n    replicate_gtid_42715 = replicate_gid_42717 * tblock_sizze_42718 + replicate_ltid_42716;\n    phys_tblock_id_42722 = get_tblock_id(0);\n    iterations_42723 = sdiv_up32(sext_i64_i32(virt_num_tblocks_42720) - phys_tblock_id_42722, sext_i64_i32(num_tblocks_42721));\n    for (int32_t i_42724 = 0; i_42724 < iterations_42723; i_42724++) {\n        int32_t virt_tblock_id_42725;\n        int64_t global_tid_42726;\n        int64_t slice_42728;\n        int64_t rep_i_42727;\n        int64_t remnant_42729;\n        \n        virt_tblock_id_42725 = phys_tblock_id_42722 + i_42724 * sext_i64_i32(num_tblocks_42721);\n        global_tid_42726 = sext_i32_i64(virt_tblock_id_42725) * sext_i32_i64(tblock_sizze_42718) + sext_i32_i64(replicate_ltid_42716);\n        slice_42728 = num_elems_42711;\n        rep_i_42727 = global_tid_42726;\n        remnant_42729 = global_tid_42726 - rep_i_42727;\n        if (slt64(global_tid_42726, replicate_n_42714)) {\n            ((__global int64_t *) mem_42710)[rep_i_42727] = val_42712;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_i8zireplicate_42858(int64_t num_elems_4",
                                    "2854, int8_t val_42855, int64_t replicate_n_42857, int64_t virt_num_tblocks_42863, int64_t num_tblocks_42864, __global unsigned char *mem_42853)\n{\n    int32_t replicate_ltid_42859;\n    int32_t tblock_sizze_42861;\n    int32_t replicate_gid_42860;\n    int32_t replicate_gtid_42858;\n    int32_t phys_tblock_id_42865;\n    int32_t iterations_42866;\n    \n    replicate_ltid_42859 = get_local_id(0);\n    tblock_sizze_42861 = get_local_size(0);\n    replicate_gid_42860 = get_tblock_id(0);\n    replicate_gtid_42858 = replicate_gid_42860 * tblock_sizze_42861 + replicate_ltid_42859;\n    phys_tblock_id_42865 = get_tblock_id(0);\n    iterations_42866 = sdiv_up32(sext_i64_i32(virt_num_tblocks_42863) - phys_tblock_id_42865, sext_i64_i32(num_tblocks_42864));\n    for (int32_t i_42867 = 0; i_42867 < iterations_42866; i_42867++) {\n        int32_t virt_tblock_id_42868;\n        int64_t global_tid_42869;\n        int64_t slice_42871;\n        int64_t rep_i_42870;\n        int64_t remnant_42872;\n        \n        virt_tblock_id_42868 = phys_tblock_id_42865 + i_42867 * sext_i64_i32(num_tblocks_42864);\n        global_tid_42869 = sext_i32_i64(virt_tblock_id_42868) * sext_i32_i64(tblock_sizze_42861) + sext_i32_i64(replicate_ltid_42859);\n        slice_42871 = num_elems_42854;\n        rep_i_42870 = global_tid_42869;\n        remnant_42872 = global_tid_42869 - rep_i_42870;\n        if (slt64(global_tid_42869, replicate_n_42857)) {\n            ((__global int8_t *) mem_42853)[rep_i_42870] = val_42855;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_doublezisegmap_39795_dim1, 1, 1)\nvoid gather_payloads_doublezisegmap_39795(__global int *global_failure, int64_t niz2084U_36170, int64_t incr_36172, __global unsigned char *is_mem_42199, __global unsigned char *mem_42203)\n{\n    #define segmap_tblock_sizze_39791 (gather_payloads_doublezisegmap_39795zisegmap_tblock_sizze_39791)\n    if (*global_failure >= 0)\n        return;\n", "    \n    int32_t local_tid_42709;\n    int32_t tblock_sizze_42712;\n    int32_t wave_sizze_42711;\n    int32_t block_id_42710;\n    int32_t global_tid_42708;\n    int64_t phys_tid_39795;\n    int64_t global_tid_42713;\n    int64_t slice_42714;\n    int64_t gtid_39794;\n    int64_t remnant_42715;\n    \n    local_tid_42709 = get_local_id(0);\n    tblock_sizze_42712 = get_local_size(0);\n    wave_sizze_42711 = LOCKSTEP_WIDTH;\n    block_id_42710 = get_tblock_id(0);\n    global_tid_42708 = block_id_42710 * tblock_sizze_42712 + local_tid_42709;\n    phys_tid_39795 = sext_i32_i64(global_tid_42708);\n    global_tid_42713 = sext_i32_i64(block_id_42710) * segmap_tblock_sizze_39791 + sext_i32_i64(local_tid_42709);\n    slice_42714 = niz2084U_36170;\n    gtid_39794 = global_tid_42713;\n    remnant_42715 = global_tid_42713 - gtid_39794;\n    if (slt64(gtid_39794, niz2084U_36170)) {\n        int64_t eta_p_39796;\n        int64_t lifted_lambda_res_39797;\n        \n        eta_p_39796 = ((__global int64_t *) is_mem_42199)[gtid_39794];\n        lifted_lambda_res_39797 = sub64(eta_p_39796, incr_36172);\n        ((__global int64_t *) mem_42203)[gtid_39794] = lifted_lambda_res_39797;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_39791\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_doublezisegmap_39823_dim1, 1, 1)\nvoid gather_payloads_doublezisegmap_39823(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t niz2084U_36170, int64_t lower_bound_38193, int64_t min_res_38195, int64_t j_m_i_38196, __global unsigned char *ys_mem_42200, __global unsigned char *mem_param_42208, __global unsigned char *mem_param_42211, __global unsigned char *mem_42216)\n{\n    #define segmap_tblock_sizze_39819 (gather_payloads_doublezisegmap_39823zisegmap_tblock_sizze_39819)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42744;\n    int32_t tblock_sizze_42747;\n    int32_t wave_sizze_42746;\n    int32_t block_id_42745;\n    int32_t global_tid_42743;\n    i", "nt64_t phys_tid_39823;\n    int64_t global_tid_42748;\n    int64_t slice_42749;\n    int64_t gtid_39822;\n    int64_t remnant_42750;\n    \n    local_tid_42744 = get_local_id(0);\n    tblock_sizze_42747 = get_local_size(0);\n    wave_sizze_42746 = LOCKSTEP_WIDTH;\n    block_id_42745 = get_tblock_id(0);\n    global_tid_42743 = block_id_42745 * tblock_sizze_42747 + local_tid_42744;\n    phys_tid_39823 = sext_i32_i64(global_tid_42743);\n    global_tid_42748 = sext_i32_i64(block_id_42745) * segmap_tblock_sizze_39819 + sext_i32_i64(local_tid_42744);\n    slice_42749 = niz2084U_36170;\n    gtid_39822 = global_tid_42748;\n    remnant_42750 = global_tid_42748 - gtid_39822;\n    if (slt64(gtid_39822, niz2084U_36170)) {\n        int64_t eta_p_39824;\n        bool cond_39826;\n        bool cond_t_res_39827;\n        bool x_39828;\n        double lifted_lambda_res_39829;\n        \n        eta_p_39824 = ((__global int64_t *) mem_param_42208)[gtid_39822];\n        cond_39826 = sle64(lower_bound_38193, eta_p_39824);\n        cond_t_res_39827 = slt64(eta_p_39824, min_res_38195);\n        x_39828 = cond_39826 && cond_t_res_39827;\n        if (x_39828) {\n            int64_t tmp_39830;\n            bool x_39831;\n            bool y_39832;\n            bool bounds_check_39833;\n            bool index_certs_39834;\n            double tmp_39835;\n            \n            tmp_39830 = sub64(eta_p_39824, lower_bound_38193);\n            x_39831 = sle64((int64_t) 0, tmp_39830);\n            y_39832 = slt64(tmp_39830, j_m_i_38196);\n            bounds_check_39833 = x_39831 && y_39832;\n            if (!bounds_check_39833) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 0) == -1) {\n                        global_failure_args[0] = (int64_t) tmp_39830;\n                        global_failure_args[1] = (int64_t) j_m_i_38196;\n                        ;\n                    }\n                    return;\n                }\n            }\n            tmp_39835 = ((__global double *) ys_mem_42200)[et",
                                    "a_p_39824];\n            lifted_lambda_res_39829 = tmp_39835;\n        } else {\n            double eta_p_39825 = ((__global double *) mem_param_42211)[gtid_39822];\n            \n            lifted_lambda_res_39829 = eta_p_39825;\n        }\n        ((__global double *) mem_42216)[gtid_39822] = lifted_lambda_res_39829;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_39819\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_double_GFURzisegmap_40075_dim1, 1, 1)\nvoid gather_payloads_double_GFURzisegmap_40075(__global int *global_failure, int64_t ni_37677, int64_t incr_37679, __global unsigned char *is_mem_42200, __global unsigned char *mem_42204)\n{\n    #define segmap_tblock_sizze_40071 (gather_payloads_double_GFURzisegmap_40075zisegmap_tblock_sizze_40071)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42709;\n    int32_t tblock_sizze_42712;\n    int32_t wave_sizze_42711;\n    int32_t block_id_42710;\n    int32_t global_tid_42708;\n    int64_t phys_tid_40075;\n    int64_t global_tid_42713;\n    int64_t slice_42714;\n    int64_t gtid_40074;\n    int64_t remnant_42715;\n    \n    local_tid_42709 = get_local_id(0);\n    tblock_sizze_42712 = get_local_size(0);\n    wave_sizze_42711 = LOCKSTEP_WIDTH;\n    block_id_42710 = get_tblock_id(0);\n    global_tid_42708 = block_id_42710 * tblock_sizze_42712 + local_tid_42709;\n    phys_tid_40075 = sext_i32_i64(global_tid_42708);\n    global_tid_42713 = sext_i32_i64(block_id_42710) * segmap_tblock_sizze_40071 + sext_i32_i64(local_tid_42709);\n    slice_42714 = ni_37677;\n    gtid_40074 = global_tid_42713;\n    remnant_42715 = global_tid_42713 - gtid_40074;\n    if (slt64(gtid_40074, ni_37677)) {\n        int64_t eta_p_40076;\n        int64_t lifted_lambda_res_40077;\n        \n        eta_p_40076 = ((__global int64_t *) is_mem_42200)[gtid_40074];\n        lifted_lambda_res_40077 = sub64(eta_p_40076, incr_37679);\n        ((__global int64_t *) mem_42204)[gtid_40074] = lifted_lambda_res_40077;\n    }\n    \n  error_0:\n    return;\n    #undef ", "segmap_tblock_sizze_40071\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_double_GFURzisegmap_40103_dim1, 1, 1)\nvoid gather_payloads_double_GFURzisegmap_40103(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t ni_37677, int64_t lower_bound_38193, int64_t min_res_38195, int64_t j_m_i_38196, __global unsigned char *ys_mem_42201, __global unsigned char *mem_param_42207, __global unsigned char *mem_param_42210, __global unsigned char *mem_42215)\n{\n    #define segmap_tblock_sizze_40099 (gather_payloads_double_GFURzisegmap_40103zisegmap_tblock_sizze_40099)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42724;\n    int32_t tblock_sizze_42727;\n    int32_t wave_sizze_42726;\n    int32_t block_id_42725;\n    int32_t global_tid_42723;\n    int64_t phys_tid_40103;\n    int64_t global_tid_42728;\n    int64_t slice_42729;\n    int64_t gtid_40102;\n    int64_t remnant_42730;\n    \n    local_tid_42724 = get_local_id(0);\n    tblock_sizze_42727 = get_local_size(0);\n    wave_sizze_42726 = LOCKSTEP_WIDTH;\n    block_id_42725 = get_tblock_id(0);\n    global_tid_42723 = block_id_42725 * tblock_sizze_42727 + local_tid_42724;\n    phys_tid_40103 = sext_i32_i64(global_tid_42723);\n    global_tid_42728 = sext_i32_i64(block_id_42725) * segmap_tblock_sizze_40099 + sext_i32_i64(local_tid_42724);\n    slice_42729 = ni_37677;\n    gtid_40102 = global_tid_42728;\n    remnant_42730 = global_tid_42728 - gtid_40102;\n    if (slt64(gtid_40102, ni_37677)) {\n        int64_t eta_p_40104;\n        bool cond_40106;\n        bool cond_t_res_40107;\n        bool x_40108;\n        double lifted_lambda_res_40109;\n        \n        eta_p_40104 = ((__global int64_t *) mem_param_42207)[gtid_40102];\n        cond_40106 = sle64(lower_bound_38193, eta_p_40104);\n        cond_t_res_40107 = slt64(eta_p_40104, min_res_38195);\n        x_40108 = cond_40106 && cond_t_res_40107;\n        if (x_40108) {\n            int64_t tmp_40110;\n            bool x_40111;\n            bool y_40", "112;\n            bool bounds_check_40113;\n            bool index_certs_40114;\n            double tmp_40115;\n            \n            tmp_40110 = sub64(eta_p_40104, lower_bound_38193);\n            x_40111 = sle64((int64_t) 0, tmp_40110);\n            y_40112 = slt64(tmp_40110, j_m_i_38196);\n            bounds_check_40113 = x_40111 && y_40112;\n            if (!bounds_check_40113) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 1) == -1) {\n                        global_failure_args[0] = (int64_t) tmp_40110;\n                        global_failure_args[1] = (int64_t) j_m_i_38196;\n                        ;\n                    }\n                    return;\n                }\n            }\n            tmp_40115 = ((__global double *) ys_mem_42201)[eta_p_40104];\n            lifted_lambda_res_40109 = tmp_40115;\n        } else {\n            double eta_p_40105 = ((__global double *) mem_param_42210)[gtid_40102];\n            \n            lifted_lambda_res_40109 = eta_p_40105;\n        }\n        ((__global double *) mem_42215)[gtid_40102] = lifted_lambda_res_40109;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_40099\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_floatzisegmap_39739_dim1, 1, 1)\nvoid gather_payloads_floatzisegmap_39739(__global int *global_failure, int64_t niz2084U_35830, int64_t incr_35832, __global unsigned char *is_mem_42199, __global unsigned char *mem_42203)\n{\n    #define segmap_tblock_sizze_39735 (gather_payloads_floatzisegmap_39739zisegmap_tblock_sizze_39735)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42709;\n    int32_t tblock_sizze_42712;\n    int32_t wave_sizze_42711;\n    int32_t block_id_42710;\n    int32_t global_tid_42708;\n    int64_t phys_tid_39739;\n    int64_t global_tid_42713;\n    int64_t slice_42714;\n    int64_t gtid_39738;\n    int64_t remnant_42715;\n    \n    local_tid_42709 = get_local_id(0);\n    tblock_sizze_42712 = get_local_size(0);\n    wave_sizze_42711 = LOCKSTEP_WID",
                                    "TH;\n    block_id_42710 = get_tblock_id(0);\n    global_tid_42708 = block_id_42710 * tblock_sizze_42712 + local_tid_42709;\n    phys_tid_39739 = sext_i32_i64(global_tid_42708);\n    global_tid_42713 = sext_i32_i64(block_id_42710) * segmap_tblock_sizze_39735 + sext_i32_i64(local_tid_42709);\n    slice_42714 = niz2084U_35830;\n    gtid_39738 = global_tid_42713;\n    remnant_42715 = global_tid_42713 - gtid_39738;\n    if (slt64(gtid_39738, niz2084U_35830)) {\n        int64_t eta_p_39740;\n        int64_t lifted_lambda_res_39741;\n        \n        eta_p_39740 = ((__global int64_t *) is_mem_42199)[gtid_39738];\n        lifted_lambda_res_39741 = sub64(eta_p_39740, incr_35832);\n        ((__global int64_t *) mem_42203)[gtid_39738] = lifted_lambda_res_39741;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_39735\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_floatzisegmap_39767_dim1, 1, 1)\nvoid gather_payloads_floatzisegmap_39767(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t niz2084U_35830, int64_t lower_bound_38193, int64_t min_res_38195, int64_t j_m_i_38196, __global unsigned char *ys_mem_42200, __global unsigned char *mem_param_42208, __global unsigned char *mem_param_42211, __global unsigned char *mem_42216)\n{\n    #define segmap_tblock_sizze_39763 (gather_payloads_floatzisegmap_39767zisegmap_tblock_sizze_39763)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42744;\n    int32_t tblock_sizze_42747;\n    int32_t wave_sizze_42746;\n    int32_t block_id_42745;\n    int32_t global_tid_42743;\n    int64_t phys_tid_39767;\n    int64_t global_tid_42748;\n    int64_t slice_42749;\n    int64_t gtid_39766;\n    int64_t remnant_42750;\n    \n    local_tid_42744 = get_local_id(0);\n    tblock_sizze_42747 = get_local_size(0);\n    wave_sizze_42746 = LOCKSTEP_WIDTH;\n    block_id_42745 = get_tblock_id(0);\n    global_tid_42743 = block_id_42745 * tblock_sizze_42747 + local_tid_42744;\n    phys_tid_39767 = sext_i32_i64(global_", "tid_42743);\n    global_tid_42748 = sext_i32_i64(block_id_42745) * segmap_tblock_sizze_39763 + sext_i32_i64(local_tid_42744);\n    slice_42749 = niz2084U_35830;\n    gtid_39766 = global_tid_42748;\n    remnant_42750 = global_tid_42748 - gtid_39766;\n    if (slt64(gtid_39766, niz2084U_35830)) {\n        int64_t eta_p_39768;\n        bool cond_39770;\n        bool cond_t_res_39771;\n        bool x_39772;\n        float lifted_lambda_res_39773;\n        \n        eta_p_39768 = ((__global int64_t *) mem_param_42208)[gtid_39766];\n        cond_39770 = sle64(lower_bound_38193, eta_p_39768);\n        cond_t_res_39771 = slt64(eta_p_39768, min_res_38195);\n        x_39772 = cond_39770 && cond_t_res_39771;\n        if (x_39772) {\n            int64_t tmp_39774;\n            bool x_39775;\n            bool y_39776;\n            bool bounds_check_39777;\n            bool index_certs_39778;\n            float tmp_39779;\n            \n            tmp_39774 = sub64(eta_p_39768, lower_bound_38193);\n            x_39775 = sle64((int64_t) 0, tmp_39774);\n            y_39776 = slt64(tmp_39774, j_m_i_38196);\n            bounds_check_39777 = x_39775 && y_39776;\n            if (!bounds_check_39777) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 2) == -1) {\n                        global_failure_args[0] = (int64_t) tmp_39774;\n                        global_failure_args[1] = (int64_t) j_m_i_38196;\n                        ;\n                    }\n                    return;\n                }\n            }\n            tmp_39779 = ((__global float *) ys_mem_42200)[eta_p_39768];\n            lifted_lambda_res_39773 = tmp_39779;\n        } else {\n            float eta_p_39769 = ((__global float *) mem_param_42211)[gtid_39766];\n            \n            lifted_lambda_res_39773 = eta_p_39769;\n        }\n        ((__global float *) mem_42216)[gtid_39766] = lifted_lambda_res_39773;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_39763\n}\nFUTHARK_KERNEL_SIZED(gather_payl", "oads_float_GFURzisegmap_40019_dim1, 1, 1)\nvoid gather_payloads_float_GFURzisegmap_40019(__global int *global_failure, int64_t ni_37376, int64_t incr_37378, __global unsigned char *is_mem_42200, __global unsigned char *mem_42204)\n{\n    #define segmap_tblock_sizze_40015 (gather_payloads_float_GFURzisegmap_40019zisegmap_tblock_sizze_40015)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42709;\n    int32_t tblock_sizze_42712;\n    int32_t wave_sizze_42711;\n    int32_t block_id_42710;\n    int32_t global_tid_42708;\n    int64_t phys_tid_40019;\n    int64_t global_tid_42713;\n    int64_t slice_42714;\n    int64_t gtid_40018;\n    int64_t remnant_42715;\n    \n    local_tid_42709 = get_local_id(0);\n    tblock_sizze_42712 = get_local_size(0);\n    wave_sizze_42711 = LOCKSTEP_WIDTH;\n    block_id_42710 = get_tblock_id(0);\n    global_tid_42708 = block_id_42710 * tblock_sizze_42712 + local_tid_42709;\n    phys_tid_40019 = sext_i32_i64(global_tid_42708);\n    global_tid_42713 = sext_i32_i64(block_id_42710) * segmap_tblock_sizze_40015 + sext_i32_i64(local_tid_42709);\n    slice_42714 = ni_37376;\n    gtid_40018 = global_tid_42713;\n    remnant_42715 = global_tid_42713 - gtid_40018;\n    if (slt64(gtid_40018, ni_37376)) {\n        int64_t eta_p_40020;\n        int64_t lifted_lambda_res_40021;\n        \n        eta_p_40020 = ((__global int64_t *) is_mem_42200)[gtid_40018];\n        lifted_lambda_res_40021 = sub64(eta_p_40020, incr_37378);\n        ((__global int64_t *) mem_42204)[gtid_40018] = lifted_lambda_res_40021;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_40015\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_float_GFURzisegmap_40047_dim1, 1, 1)\nvoid gather_payloads_float_GFURzisegmap_40047(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t ni_37376, int64_t lower_bound_38193, int64_t min_res_38195, int64_t j_m_i_38196, __global unsigned char *ys_mem_42201, __global unsigned char *mem_param_42207, __global uns",
                                    "igned char *mem_param_42210, __global unsigned char *mem_42215)\n{\n    #define segmap_tblock_sizze_40043 (gather_payloads_float_GFURzisegmap_40047zisegmap_tblock_sizze_40043)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42724;\n    int32_t tblock_sizze_42727;\n    int32_t wave_sizze_42726;\n    int32_t block_id_42725;\n    int32_t global_tid_42723;\n    int64_t phys_tid_40047;\n    int64_t global_tid_42728;\n    int64_t slice_42729;\n    int64_t gtid_40046;\n    int64_t remnant_42730;\n    \n    local_tid_42724 = get_local_id(0);\n    tblock_sizze_42727 = get_local_size(0);\n    wave_sizze_42726 = LOCKSTEP_WIDTH;\n    block_id_42725 = get_tblock_id(0);\n    global_tid_42723 = block_id_42725 * tblock_sizze_42727 + local_tid_42724;\n    phys_tid_40047 = sext_i32_i64(global_tid_42723);\n    global_tid_42728 = sext_i32_i64(block_id_42725) * segmap_tblock_sizze_40043 + sext_i32_i64(local_tid_42724);\n    slice_42729 = ni_37376;\n    gtid_40046 = global_tid_42728;\n    remnant_42730 = global_tid_42728 - gtid_40046;\n    if (slt64(gtid_40046, ni_37376)) {\n        int64_t eta_p_40048;\n        bool cond_40050;\n        bool cond_t_res_40051;\n        bool x_40052;\n        float lifted_lambda_res_40053;\n        \n        eta_p_40048 = ((__global int64_t *) mem_param_42207)[gtid_40046];\n        cond_40050 = sle64(lower_bound_38193, eta_p_40048);\n        cond_t_res_40051 = slt64(eta_p_40048, min_res_38195);\n        x_40052 = cond_40050 && cond_t_res_40051;\n        if (x_40052) {\n            int64_t tmp_40054;\n            bool x_40055;\n            bool y_40056;\n            bool bounds_check_40057;\n            bool index_certs_40058;\n            float tmp_40059;\n            \n            tmp_40054 = sub64(eta_p_40048, lower_bound_38193);\n            x_40055 = sle64((int64_t) 0, tmp_40054);\n            y_40056 = slt64(tmp_40054, j_m_i_38196);\n            bounds_check_40057 = x_40055 && y_40056;\n            if (!bounds_check_40057) {\n                {\n                    if (atom", "ic_cmpxchg_i32_global(global_failure, -1, 3) == -1) {\n                        global_failure_args[0] = (int64_t) tmp_40054;\n                        global_failure_args[1] = (int64_t) j_m_i_38196;\n                        ;\n                    }\n                    return;\n                }\n            }\n            tmp_40059 = ((__global float *) ys_mem_42201)[eta_p_40048];\n            lifted_lambda_res_40053 = tmp_40059;\n        } else {\n            float eta_p_40049 = ((__global float *) mem_param_42210)[gtid_40046];\n            \n            lifted_lambda_res_40053 = eta_p_40049;\n        }\n        ((__global float *) mem_42215)[gtid_40046] = lifted_lambda_res_40053;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_40043\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_intzisegmap_39627_dim1, 1, 1)\nvoid gather_payloads_intzisegmap_39627(__global int *global_failure, int64_t niz2084U_35181, int64_t incr_35183, __global unsigned char *is_mem_42199, __global unsigned char *mem_42203)\n{\n    #define segmap_tblock_sizze_39623 (gather_payloads_intzisegmap_39627zisegmap_tblock_sizze_39623)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42709;\n    int32_t tblock_sizze_42712;\n    int32_t wave_sizze_42711;\n    int32_t block_id_42710;\n    int32_t global_tid_42708;\n    int64_t phys_tid_39627;\n    int64_t global_tid_42713;\n    int64_t slice_42714;\n    int64_t gtid_39626;\n    int64_t remnant_42715;\n    \n    local_tid_42709 = get_local_id(0);\n    tblock_sizze_42712 = get_local_size(0);\n    wave_sizze_42711 = LOCKSTEP_WIDTH;\n    block_id_42710 = get_tblock_id(0);\n    global_tid_42708 = block_id_42710 * tblock_sizze_42712 + local_tid_42709;\n    phys_tid_39627 = sext_i32_i64(global_tid_42708);\n    global_tid_42713 = sext_i32_i64(block_id_42710) * segmap_tblock_sizze_39623 + sext_i32_i64(local_tid_42709);\n    slice_42714 = niz2084U_35181;\n    gtid_39626 = global_tid_42713;\n    remnant_42715 = global_tid_42713 - gtid_39626;\n    if (slt64(gtid_39626, niz20", "84U_35181)) {\n        int64_t eta_p_39628;\n        int64_t lifted_lambda_res_39629;\n        \n        eta_p_39628 = ((__global int64_t *) is_mem_42199)[gtid_39626];\n        lifted_lambda_res_39629 = sub64(eta_p_39628, incr_35183);\n        ((__global int64_t *) mem_42203)[gtid_39626] = lifted_lambda_res_39629;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_39623\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_intzisegmap_39655_dim1, 1, 1)\nvoid gather_payloads_intzisegmap_39655(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t niz2084U_35181, int64_t lower_bound_38193, int64_t min_res_38195, int64_t j_m_i_38196, __global unsigned char *ys_mem_42200, __global unsigned char *mem_param_42208, __global unsigned char *mem_param_42211, __global unsigned char *mem_42216)\n{\n    #define segmap_tblock_sizze_39651 (gather_payloads_intzisegmap_39655zisegmap_tblock_sizze_39651)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42744;\n    int32_t tblock_sizze_42747;\n    int32_t wave_sizze_42746;\n    int32_t block_id_42745;\n    int32_t global_tid_42743;\n    int64_t phys_tid_39655;\n    int64_t global_tid_42748;\n    int64_t slice_42749;\n    int64_t gtid_39654;\n    int64_t remnant_42750;\n    \n    local_tid_42744 = get_local_id(0);\n    tblock_sizze_42747 = get_local_size(0);\n    wave_sizze_42746 = LOCKSTEP_WIDTH;\n    block_id_42745 = get_tblock_id(0);\n    global_tid_42743 = block_id_42745 * tblock_sizze_42747 + local_tid_42744;\n    phys_tid_39655 = sext_i32_i64(global_tid_42743);\n    global_tid_42748 = sext_i32_i64(block_id_42745) * segmap_tblock_sizze_39651 + sext_i32_i64(local_tid_42744);\n    slice_42749 = niz2084U_35181;\n    gtid_39654 = global_tid_42748;\n    remnant_42750 = global_tid_42748 - gtid_39654;\n    if (slt64(gtid_39654, niz2084U_35181)) {\n        int64_t eta_p_39656;\n        bool cond_39658;\n        bool cond_t_res_39659;\n        bool x_39660;\n        int32_t lifted_lambda_res_39661;\n      ",
                                    "  \n        eta_p_39656 = ((__global int64_t *) mem_param_42208)[gtid_39654];\n        cond_39658 = sle64(lower_bound_38193, eta_p_39656);\n        cond_t_res_39659 = slt64(eta_p_39656, min_res_38195);\n        x_39660 = cond_39658 && cond_t_res_39659;\n        if (x_39660) {\n            int64_t tmp_39662;\n            bool x_39663;\n            bool y_39664;\n            bool bounds_check_39665;\n            bool index_certs_39666;\n            int32_t tmp_39667;\n            \n            tmp_39662 = sub64(eta_p_39656, lower_bound_38193);\n            x_39663 = sle64((int64_t) 0, tmp_39662);\n            y_39664 = slt64(tmp_39662, j_m_i_38196);\n            bounds_check_39665 = x_39663 && y_39664;\n            if (!bounds_check_39665) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 4) == -1) {\n                        global_failure_args[0] = (int64_t) tmp_39662;\n                        global_failure_args[1] = (int64_t) j_m_i_38196;\n                        ;\n                    }\n                    return;\n                }\n            }\n            tmp_39667 = ((__global int32_t *) ys_mem_42200)[eta_p_39656];\n            lifted_lambda_res_39661 = tmp_39667;\n        } else {\n            int32_t eta_p_39657 = ((__global int32_t *) mem_param_42211)[gtid_39654];\n            \n            lifted_lambda_res_39661 = eta_p_39657;\n        }\n        ((__global int32_t *) mem_42216)[gtid_39654] = lifted_lambda_res_39661;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_39651\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_int_GFURzisegmap_39907_dim1, 1, 1)\nvoid gather_payloads_int_GFURzisegmap_39907(__global int *global_failure, int64_t ni_36774, int64_t incr_36776, __global unsigned char *is_mem_42200, __global unsigned char *mem_42204)\n{\n    #define segmap_tblock_sizze_39903 (gather_payloads_int_GFURzisegmap_39907zisegmap_tblock_sizze_39903)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42709;\n    int32_t tblock_", "sizze_42712;\n    int32_t wave_sizze_42711;\n    int32_t block_id_42710;\n    int32_t global_tid_42708;\n    int64_t phys_tid_39907;\n    int64_t global_tid_42713;\n    int64_t slice_42714;\n    int64_t gtid_39906;\n    int64_t remnant_42715;\n    \n    local_tid_42709 = get_local_id(0);\n    tblock_sizze_42712 = get_local_size(0);\n    wave_sizze_42711 = LOCKSTEP_WIDTH;\n    block_id_42710 = get_tblock_id(0);\n    global_tid_42708 = block_id_42710 * tblock_sizze_42712 + local_tid_42709;\n    phys_tid_39907 = sext_i32_i64(global_tid_42708);\n    global_tid_42713 = sext_i32_i64(block_id_42710) * segmap_tblock_sizze_39903 + sext_i32_i64(local_tid_42709);\n    slice_42714 = ni_36774;\n    gtid_39906 = global_tid_42713;\n    remnant_42715 = global_tid_42713 - gtid_39906;\n    if (slt64(gtid_39906, ni_36774)) {\n        int64_t eta_p_39908;\n        int64_t lifted_lambda_res_39909;\n        \n        eta_p_39908 = ((__global int64_t *) is_mem_42200)[gtid_39906];\n        lifted_lambda_res_39909 = sub64(eta_p_39908, incr_36776);\n        ((__global int64_t *) mem_42204)[gtid_39906] = lifted_lambda_res_39909;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_39903\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_int_GFURzisegmap_39935_dim1, 1, 1)\nvoid gather_payloads_int_GFURzisegmap_39935(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t ni_36774, int64_t lower_bound_38193, int64_t min_res_38195, int64_t j_m_i_38196, __global unsigned char *ys_mem_42201, __global unsigned char *mem_param_42207, __global unsigned char *mem_param_42210, __global unsigned char *mem_42215)\n{\n    #define segmap_tblock_sizze_39931 (gather_payloads_int_GFURzisegmap_39935zisegmap_tblock_sizze_39931)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42724;\n    int32_t tblock_sizze_42727;\n    int32_t wave_sizze_42726;\n    int32_t block_id_42725;\n    int32_t global_tid_42723;\n    int64_t phys_tid_39935;\n    int64_t global_tid_42728;\n    int64_t ", "slice_42729;\n    int64_t gtid_39934;\n    int64_t remnant_42730;\n    \n    local_tid_42724 = get_local_id(0);\n    tblock_sizze_42727 = get_local_size(0);\n    wave_sizze_42726 = LOCKSTEP_WIDTH;\n    block_id_42725 = get_tblock_id(0);\n    global_tid_42723 = block_id_42725 * tblock_sizze_42727 + local_tid_42724;\n    phys_tid_39935 = sext_i32_i64(global_tid_42723);\n    global_tid_42728 = sext_i32_i64(block_id_42725) * segmap_tblock_sizze_39931 + sext_i32_i64(local_tid_42724);\n    slice_42729 = ni_36774;\n    gtid_39934 = global_tid_42728;\n    remnant_42730 = global_tid_42728 - gtid_39934;\n    if (slt64(gtid_39934, ni_36774)) {\n        int64_t eta_p_39936;\n        bool cond_39938;\n        bool cond_t_res_39939;\n        bool x_39940;\n        int32_t lifted_lambda_res_39941;\n        \n        eta_p_39936 = ((__global int64_t *) mem_param_42207)[gtid_39934];\n        cond_39938 = sle64(lower_bound_38193, eta_p_39936);\n        cond_t_res_39939 = slt64(eta_p_39936, min_res_38195);\n        x_39940 = cond_39938 && cond_t_res_39939;\n        if (x_39940) {\n            int64_t tmp_39942;\n            bool x_39943;\n            bool y_39944;\n            bool bounds_check_39945;\n            bool index_certs_39946;\n            int32_t tmp_39947;\n            \n            tmp_39942 = sub64(eta_p_39936, lower_bound_38193);\n            x_39943 = sle64((int64_t) 0, tmp_39942);\n            y_39944 = slt64(tmp_39942, j_m_i_38196);\n            bounds_check_39945 = x_39943 && y_39944;\n            if (!bounds_check_39945) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 5) == -1) {\n                        global_failure_args[0] = (int64_t) tmp_39942;\n                        global_failure_args[1] = (int64_t) j_m_i_38196;\n                        ;\n                    }\n                    return;\n                }\n            }\n            tmp_39947 = ((__global int32_t *) ys_mem_42201)[eta_p_39936];\n            lifted_lambda_res_39941 = tmp_39947;\n        } els",
                                    "e {\n            int32_t eta_p_39937 = ((__global int32_t *) mem_param_42210)[gtid_39934];\n            \n            lifted_lambda_res_39941 = eta_p_39937;\n        }\n        ((__global int32_t *) mem_42215)[gtid_39934] = lifted_lambda_res_39941;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_39931\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_longzisegmap_39683_dim1, 1, 1)\nvoid gather_payloads_longzisegmap_39683(__global int *global_failure, int64_t niz2084U_35490, int64_t incr_35492, __global unsigned char *is_mem_42199, __global unsigned char *mem_42203)\n{\n    #define segmap_tblock_sizze_39679 (gather_payloads_longzisegmap_39683zisegmap_tblock_sizze_39679)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42709;\n    int32_t tblock_sizze_42712;\n    int32_t wave_sizze_42711;\n    int32_t block_id_42710;\n    int32_t global_tid_42708;\n    int64_t phys_tid_39683;\n    int64_t global_tid_42713;\n    int64_t slice_42714;\n    int64_t gtid_39682;\n    int64_t remnant_42715;\n    \n    local_tid_42709 = get_local_id(0);\n    tblock_sizze_42712 = get_local_size(0);\n    wave_sizze_42711 = LOCKSTEP_WIDTH;\n    block_id_42710 = get_tblock_id(0);\n    global_tid_42708 = block_id_42710 * tblock_sizze_42712 + local_tid_42709;\n    phys_tid_39683 = sext_i32_i64(global_tid_42708);\n    global_tid_42713 = sext_i32_i64(block_id_42710) * segmap_tblock_sizze_39679 + sext_i32_i64(local_tid_42709);\n    slice_42714 = niz2084U_35490;\n    gtid_39682 = global_tid_42713;\n    remnant_42715 = global_tid_42713 - gtid_39682;\n    if (slt64(gtid_39682, niz2084U_35490)) {\n        int64_t eta_p_39684;\n        int64_t lifted_lambda_res_39685;\n        \n        eta_p_39684 = ((__global int64_t *) is_mem_42199)[gtid_39682];\n        lifted_lambda_res_39685 = sub64(eta_p_39684, incr_35492);\n        ((__global int64_t *) mem_42203)[gtid_39682] = lifted_lambda_res_39685;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_39679\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_longziseg", "map_39711_dim1, 1, 1)\nvoid gather_payloads_longzisegmap_39711(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t niz2084U_35490, int64_t lower_bound_38193, int64_t min_res_38195, int64_t j_m_i_38196, __global unsigned char *ys_mem_42200, __global unsigned char *mem_param_42208, __global unsigned char *mem_param_42211, __global unsigned char *mem_42216)\n{\n    #define segmap_tblock_sizze_39707 (gather_payloads_longzisegmap_39711zisegmap_tblock_sizze_39707)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42744;\n    int32_t tblock_sizze_42747;\n    int32_t wave_sizze_42746;\n    int32_t block_id_42745;\n    int32_t global_tid_42743;\n    int64_t phys_tid_39711;\n    int64_t global_tid_42748;\n    int64_t slice_42749;\n    int64_t gtid_39710;\n    int64_t remnant_42750;\n    \n    local_tid_42744 = get_local_id(0);\n    tblock_sizze_42747 = get_local_size(0);\n    wave_sizze_42746 = LOCKSTEP_WIDTH;\n    block_id_42745 = get_tblock_id(0);\n    global_tid_42743 = block_id_42745 * tblock_sizze_42747 + local_tid_42744;\n    phys_tid_39711 = sext_i32_i64(global_tid_42743);\n    global_tid_42748 = sext_i32_i64(block_id_42745) * segmap_tblock_sizze_39707 + sext_i32_i64(local_tid_42744);\n    slice_42749 = niz2084U_35490;\n    gtid_39710 = global_tid_42748;\n    remnant_42750 = global_tid_42748 - gtid_39710;\n    if (slt64(gtid_39710, niz2084U_35490)) {\n        int64_t eta_p_39712;\n        bool cond_39714;\n        bool cond_t_res_39715;\n        bool x_39716;\n        int64_t lifted_lambda_res_39717;\n        \n        eta_p_39712 = ((__global int64_t *) mem_param_42208)[gtid_39710];\n        cond_39714 = sle64(lower_bound_38193, eta_p_39712);\n        cond_t_res_39715 = slt64(eta_p_39712, min_res_38195);\n        x_39716 = cond_39714 && cond_t_res_39715;\n        if (x_39716) {\n            int64_t tmp_39718;\n            bool x_39719;\n            bool y_39720;\n            bool bounds_check_39721;\n            bool index_certs_39722", ";\n            int64_t tmp_39723;\n            \n            tmp_39718 = sub64(eta_p_39712, lower_bound_38193);\n            x_39719 = sle64((int64_t) 0, tmp_39718);\n            y_39720 = slt64(tmp_39718, j_m_i_38196);\n            bounds_check_39721 = x_39719 && y_39720;\n            if (!bounds_check_39721) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 6) == -1) {\n                        global_failure_args[0] = (int64_t) tmp_39718;\n                        global_failure_args[1] = (int64_t) j_m_i_38196;\n                        ;\n                    }\n                    return;\n                }\n            }\n            tmp_39723 = ((__global int64_t *) ys_mem_42200)[eta_p_39712];\n            lifted_lambda_res_39717 = tmp_39723;\n        } else {\n            int64_t eta_p_39713 = ((__global int64_t *) mem_param_42211)[gtid_39710];\n            \n            lifted_lambda_res_39717 = eta_p_39713;\n        }\n        ((__global int64_t *) mem_42216)[gtid_39710] = lifted_lambda_res_39717;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_39707\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_long_GFURzisegmap_39963_dim1, 1, 1)\nvoid gather_payloads_long_GFURzisegmap_39963(__global int *global_failure, int64_t ni_37075, int64_t incr_37077, __global unsigned char *is_mem_42200, __global unsigned char *mem_42204)\n{\n    #define segmap_tblock_sizze_39959 (gather_payloads_long_GFURzisegmap_39963zisegmap_tblock_sizze_39959)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42709;\n    int32_t tblock_sizze_42712;\n    int32_t wave_sizze_42711;\n    int32_t block_id_42710;\n    int32_t global_tid_42708;\n    int64_t phys_tid_39963;\n    int64_t global_tid_42713;\n    int64_t slice_42714;\n    int64_t gtid_39962;\n    int64_t remnant_42715;\n    \n    local_tid_42709 = get_local_id(0);\n    tblock_sizze_42712 = get_local_size(0);\n    wave_sizze_42711 = LOCKSTEP_WIDTH;\n    block_id_42710 = get_tblock_id(0);\n    global_tid_42708 =",
                                    " block_id_42710 * tblock_sizze_42712 + local_tid_42709;\n    phys_tid_39963 = sext_i32_i64(global_tid_42708);\n    global_tid_42713 = sext_i32_i64(block_id_42710) * segmap_tblock_sizze_39959 + sext_i32_i64(local_tid_42709);\n    slice_42714 = ni_37075;\n    gtid_39962 = global_tid_42713;\n    remnant_42715 = global_tid_42713 - gtid_39962;\n    if (slt64(gtid_39962, ni_37075)) {\n        int64_t eta_p_39964;\n        int64_t lifted_lambda_res_39965;\n        \n        eta_p_39964 = ((__global int64_t *) is_mem_42200)[gtid_39962];\n        lifted_lambda_res_39965 = sub64(eta_p_39964, incr_37077);\n        ((__global int64_t *) mem_42204)[gtid_39962] = lifted_lambda_res_39965;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_39959\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_long_GFURzisegmap_39991_dim1, 1, 1)\nvoid gather_payloads_long_GFURzisegmap_39991(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t ni_37075, int64_t lower_bound_38193, int64_t min_res_38195, int64_t j_m_i_38196, __global unsigned char *ys_mem_42201, __global unsigned char *mem_param_42207, __global unsigned char *mem_param_42210, __global unsigned char *mem_42215)\n{\n    #define segmap_tblock_sizze_39987 (gather_payloads_long_GFURzisegmap_39991zisegmap_tblock_sizze_39987)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42724;\n    int32_t tblock_sizze_42727;\n    int32_t wave_sizze_42726;\n    int32_t block_id_42725;\n    int32_t global_tid_42723;\n    int64_t phys_tid_39991;\n    int64_t global_tid_42728;\n    int64_t slice_42729;\n    int64_t gtid_39990;\n    int64_t remnant_42730;\n    \n    local_tid_42724 = get_local_id(0);\n    tblock_sizze_42727 = get_local_size(0);\n    wave_sizze_42726 = LOCKSTEP_WIDTH;\n    block_id_42725 = get_tblock_id(0);\n    global_tid_42723 = block_id_42725 * tblock_sizze_42727 + local_tid_42724;\n    phys_tid_39991 = sext_i32_i64(global_tid_42723);\n    global_tid_42728 = sext_i32_i64(block_id_42725) * segma", "p_tblock_sizze_39987 + sext_i32_i64(local_tid_42724);\n    slice_42729 = ni_37075;\n    gtid_39990 = global_tid_42728;\n    remnant_42730 = global_tid_42728 - gtid_39990;\n    if (slt64(gtid_39990, ni_37075)) {\n        int64_t eta_p_39992;\n        bool cond_39994;\n        bool cond_t_res_39995;\n        bool x_39996;\n        int64_t lifted_lambda_res_39997;\n        \n        eta_p_39992 = ((__global int64_t *) mem_param_42207)[gtid_39990];\n        cond_39994 = sle64(lower_bound_38193, eta_p_39992);\n        cond_t_res_39995 = slt64(eta_p_39992, min_res_38195);\n        x_39996 = cond_39994 && cond_t_res_39995;\n        if (x_39996) {\n            int64_t tmp_39998;\n            bool x_39999;\n            bool y_40000;\n            bool bounds_check_40001;\n            bool index_certs_40002;\n            int64_t tmp_40003;\n            \n            tmp_39998 = sub64(eta_p_39992, lower_bound_38193);\n            x_39999 = sle64((int64_t) 0, tmp_39998);\n            y_40000 = slt64(tmp_39998, j_m_i_38196);\n            bounds_check_40001 = x_39999 && y_40000;\n            if (!bounds_check_40001) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 7) == -1) {\n                        global_failure_args[0] = (int64_t) tmp_39998;\n                        global_failure_args[1] = (int64_t) j_m_i_38196;\n                        ;\n                    }\n                    return;\n                }\n            }\n            tmp_40003 = ((__global int64_t *) ys_mem_42201)[eta_p_39992];\n            lifted_lambda_res_39997 = tmp_40003;\n        } else {\n            int64_t eta_p_39993 = ((__global int64_t *) mem_param_42210)[gtid_39990];\n            \n            lifted_lambda_res_39997 = eta_p_39993;\n        }\n        ((__global int64_t *) mem_42215)[gtid_39990] = lifted_lambda_res_39997;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_39987\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_shortzisegmap_39571_dim1, 1, 1)\nvoid gather_payloads_shortzisegmap", "_39571(__global int *global_failure, int64_t niz2084U_34869, int64_t incr_34871, __global unsigned char *is_mem_42199, __global unsigned char *mem_42203)\n{\n    #define segmap_tblock_sizze_39567 (gather_payloads_shortzisegmap_39571zisegmap_tblock_sizze_39567)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42709;\n    int32_t tblock_sizze_42712;\n    int32_t wave_sizze_42711;\n    int32_t block_id_42710;\n    int32_t global_tid_42708;\n    int64_t phys_tid_39571;\n    int64_t global_tid_42713;\n    int64_t slice_42714;\n    int64_t gtid_39570;\n    int64_t remnant_42715;\n    \n    local_tid_42709 = get_local_id(0);\n    tblock_sizze_42712 = get_local_size(0);\n    wave_sizze_42711 = LOCKSTEP_WIDTH;\n    block_id_42710 = get_tblock_id(0);\n    global_tid_42708 = block_id_42710 * tblock_sizze_42712 + local_tid_42709;\n    phys_tid_39571 = sext_i32_i64(global_tid_42708);\n    global_tid_42713 = sext_i32_i64(block_id_42710) * segmap_tblock_sizze_39567 + sext_i32_i64(local_tid_42709);\n    slice_42714 = niz2084U_34869;\n    gtid_39570 = global_tid_42713;\n    remnant_42715 = global_tid_42713 - gtid_39570;\n    if (slt64(gtid_39570, niz2084U_34869)) {\n        int64_t eta_p_39572;\n        int64_t lifted_lambda_res_39573;\n        \n        eta_p_39572 = ((__global int64_t *) is_mem_42199)[gtid_39570];\n        lifted_lambda_res_39573 = sub64(eta_p_39572, incr_34871);\n        ((__global int64_t *) mem_42203)[gtid_39570] = lifted_lambda_res_39573;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_39567\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_shortzisegmap_39599_dim1, 1, 1)\nvoid gather_payloads_shortzisegmap_39599(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t niz2084U_34869, int64_t lower_bound_38193, int64_t min_res_38195, int64_t j_m_i_38196, __global unsigned char *ys_mem_42200, __global unsigned char *mem_param_42208, __global unsigned char *mem_param_42211, __global unsigned char *mem_42216)\n{\n    #d",
                                    "efine segmap_tblock_sizze_39595 (gather_payloads_shortzisegmap_39599zisegmap_tblock_sizze_39595)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42744;\n    int32_t tblock_sizze_42747;\n    int32_t wave_sizze_42746;\n    int32_t block_id_42745;\n    int32_t global_tid_42743;\n    int64_t phys_tid_39599;\n    int64_t global_tid_42748;\n    int64_t slice_42749;\n    int64_t gtid_39598;\n    int64_t remnant_42750;\n    \n    local_tid_42744 = get_local_id(0);\n    tblock_sizze_42747 = get_local_size(0);\n    wave_sizze_42746 = LOCKSTEP_WIDTH;\n    block_id_42745 = get_tblock_id(0);\n    global_tid_42743 = block_id_42745 * tblock_sizze_42747 + local_tid_42744;\n    phys_tid_39599 = sext_i32_i64(global_tid_42743);\n    global_tid_42748 = sext_i32_i64(block_id_42745) * segmap_tblock_sizze_39595 + sext_i32_i64(local_tid_42744);\n    slice_42749 = niz2084U_34869;\n    gtid_39598 = global_tid_42748;\n    remnant_42750 = global_tid_42748 - gtid_39598;\n    if (slt64(gtid_39598, niz2084U_34869)) {\n        int64_t eta_p_39600;\n        bool cond_39602;\n        bool cond_t_res_39603;\n        bool x_39604;\n        int16_t lifted_lambda_res_39605;\n        \n        eta_p_39600 = ((__global int64_t *) mem_param_42208)[gtid_39598];\n        cond_39602 = sle64(lower_bound_38193, eta_p_39600);\n        cond_t_res_39603 = slt64(eta_p_39600, min_res_38195);\n        x_39604 = cond_39602 && cond_t_res_39603;\n        if (x_39604) {\n            int64_t tmp_39606;\n            bool x_39607;\n            bool y_39608;\n            bool bounds_check_39609;\n            bool index_certs_39610;\n            int16_t tmp_39611;\n            \n            tmp_39606 = sub64(eta_p_39600, lower_bound_38193);\n            x_39607 = sle64((int64_t) 0, tmp_39606);\n            y_39608 = slt64(tmp_39606, j_m_i_38196);\n            bounds_check_39609 = x_39607 && y_39608;\n            if (!bounds_check_39609) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 8) == -1) {\n       ", "                 global_failure_args[0] = (int64_t) tmp_39606;\n                        global_failure_args[1] = (int64_t) j_m_i_38196;\n                        ;\n                    }\n                    return;\n                }\n            }\n            tmp_39611 = ((__global int16_t *) ys_mem_42200)[eta_p_39600];\n            lifted_lambda_res_39605 = tmp_39611;\n        } else {\n            int16_t eta_p_39601 = ((__global int16_t *) mem_param_42211)[gtid_39598];\n            \n            lifted_lambda_res_39605 = eta_p_39601;\n        }\n        ((__global int16_t *) mem_42216)[gtid_39598] = lifted_lambda_res_39605;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_39595\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_short_GFURzisegmap_39851_dim1, 1, 1)\nvoid gather_payloads_short_GFURzisegmap_39851(__global int *global_failure, int64_t ni_36473, int64_t incr_36475, __global unsigned char *is_mem_42200, __global unsigned char *mem_42204)\n{\n    #define segmap_tblock_sizze_39847 (gather_payloads_short_GFURzisegmap_39851zisegmap_tblock_sizze_39847)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42709;\n    int32_t tblock_sizze_42712;\n    int32_t wave_sizze_42711;\n    int32_t block_id_42710;\n    int32_t global_tid_42708;\n    int64_t phys_tid_39851;\n    int64_t global_tid_42713;\n    int64_t slice_42714;\n    int64_t gtid_39850;\n    int64_t remnant_42715;\n    \n    local_tid_42709 = get_local_id(0);\n    tblock_sizze_42712 = get_local_size(0);\n    wave_sizze_42711 = LOCKSTEP_WIDTH;\n    block_id_42710 = get_tblock_id(0);\n    global_tid_42708 = block_id_42710 * tblock_sizze_42712 + local_tid_42709;\n    phys_tid_39851 = sext_i32_i64(global_tid_42708);\n    global_tid_42713 = sext_i32_i64(block_id_42710) * segmap_tblock_sizze_39847 + sext_i32_i64(local_tid_42709);\n    slice_42714 = ni_36473;\n    gtid_39850 = global_tid_42713;\n    remnant_42715 = global_tid_42713 - gtid_39850;\n    if (slt64(gtid_39850, ni_36473)) {\n        int64_t eta_p_39852;\n       ", " int64_t lifted_lambda_res_39853;\n        \n        eta_p_39852 = ((__global int64_t *) is_mem_42200)[gtid_39850];\n        lifted_lambda_res_39853 = sub64(eta_p_39852, incr_36475);\n        ((__global int64_t *) mem_42204)[gtid_39850] = lifted_lambda_res_39853;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_39847\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_short_GFURzisegmap_39879_dim1, 1, 1)\nvoid gather_payloads_short_GFURzisegmap_39879(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t ni_36473, int64_t lower_bound_38193, int64_t min_res_38195, int64_t j_m_i_38196, __global unsigned char *ys_mem_42201, __global unsigned char *mem_param_42207, __global unsigned char *mem_param_42210, __global unsigned char *mem_42215)\n{\n    #define segmap_tblock_sizze_39875 (gather_payloads_short_GFURzisegmap_39879zisegmap_tblock_sizze_39875)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42724;\n    int32_t tblock_sizze_42727;\n    int32_t wave_sizze_42726;\n    int32_t block_id_42725;\n    int32_t global_tid_42723;\n    int64_t phys_tid_39879;\n    int64_t global_tid_42728;\n    int64_t slice_42729;\n    int64_t gtid_39878;\n    int64_t remnant_42730;\n    \n    local_tid_42724 = get_local_id(0);\n    tblock_sizze_42727 = get_local_size(0);\n    wave_sizze_42726 = LOCKSTEP_WIDTH;\n    block_id_42725 = get_tblock_id(0);\n    global_tid_42723 = block_id_42725 * tblock_sizze_42727 + local_tid_42724;\n    phys_tid_39879 = sext_i32_i64(global_tid_42723);\n    global_tid_42728 = sext_i32_i64(block_id_42725) * segmap_tblock_sizze_39875 + sext_i32_i64(local_tid_42724);\n    slice_42729 = ni_36473;\n    gtid_39878 = global_tid_42728;\n    remnant_42730 = global_tid_42728 - gtid_39878;\n    if (slt64(gtid_39878, ni_36473)) {\n        int64_t eta_p_39880;\n        bool cond_39882;\n        bool cond_t_res_39883;\n        bool x_39884;\n        int16_t lifted_lambda_res_39885;\n        \n        eta_p_39880 = ((__global int64_t *) ",
                                    "mem_param_42207)[gtid_39878];\n        cond_39882 = sle64(lower_bound_38193, eta_p_39880);\n        cond_t_res_39883 = slt64(eta_p_39880, min_res_38195);\n        x_39884 = cond_39882 && cond_t_res_39883;\n        if (x_39884) {\n            int64_t tmp_39886;\n            bool x_39887;\n            bool y_39888;\n            bool bounds_check_39889;\n            bool index_certs_39890;\n            int16_t tmp_39891;\n            \n            tmp_39886 = sub64(eta_p_39880, lower_bound_38193);\n            x_39887 = sle64((int64_t) 0, tmp_39886);\n            y_39888 = slt64(tmp_39886, j_m_i_38196);\n            bounds_check_39889 = x_39887 && y_39888;\n            if (!bounds_check_39889) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 9) == -1) {\n                        global_failure_args[0] = (int64_t) tmp_39886;\n                        global_failure_args[1] = (int64_t) j_m_i_38196;\n                        ;\n                    }\n                    return;\n                }\n            }\n            tmp_39891 = ((__global int16_t *) ys_mem_42201)[eta_p_39880];\n            lifted_lambda_res_39885 = tmp_39891;\n        } else {\n            int16_t eta_p_39881 = ((__global int16_t *) mem_param_42210)[gtid_39878];\n            \n            lifted_lambda_res_39885 = eta_p_39881;\n        }\n        ((__global int16_t *) mem_42215)[gtid_39878] = lifted_lambda_res_39885;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_39875\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_doublezigpuseq_42730_dim1, 1, 1)\nvoid inner_SMJ_doublezigpuseq_42730(__global int *global_failure, __global unsigned char *tS_mem_42200, __global unsigned char *mem_42207)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42732;\n    int32_t tblock_sizze_42735;\n    int32_t wave_sizze_42734;\n    int32_t block_id_42733;\n    int32_t global_tid_42731;\n    int64_t tid_42730;\n    double x_42152;\n    \n    local_tid_42732 = get_local_id(0);\n    tblock_sizze_42", "735 = get_local_size(0);\n    wave_sizze_42734 = LOCKSTEP_WIDTH;\n    block_id_42733 = get_tblock_id(0);\n    global_tid_42731 = block_id_42733 * tblock_sizze_42735 + local_tid_42732;\n    tid_42730 = sext_i32_i64(global_tid_42731);\n    x_42152 = ((__global double *) tS_mem_42200)[(int64_t) 0];\n    ((__global double *) mem_42207)[(int64_t) 0] = x_42152;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_doublezigpuseq_42756_dim1, 1, 1)\nvoid inner_SMJ_doublezigpuseq_42756(__global int *global_failure, int64_t tmp_39078, __global unsigned char *tS_mem_42200, __global unsigned char *mem_42210)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42758;\n    int32_t tblock_sizze_42761;\n    int32_t wave_sizze_42760;\n    int32_t block_id_42759;\n    int32_t global_tid_42757;\n    int64_t tid_42756;\n    double x_42156;\n    \n    local_tid_42758 = get_local_id(0);\n    tblock_sizze_42761 = get_local_size(0);\n    wave_sizze_42760 = LOCKSTEP_WIDTH;\n    block_id_42759 = get_tblock_id(0);\n    global_tid_42757 = block_id_42759 * tblock_sizze_42761 + local_tid_42758;\n    tid_42756 = sext_i32_i64(global_tid_42757);\n    x_42156 = ((__global double *) tS_mem_42200)[tmp_39078];\n    ((__global double *) mem_42210)[(int64_t) 0] = x_42156;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_doublezigpuseq_42772_dim1, 1, 1)\nvoid inner_SMJ_doublezigpuseq_42772(__global int *global_failure, int64_t start_39100, int64_t i_p_m_t_s_39106, __global unsigned char *tR_mem_42199, __global unsigned char *mem_42218, __global unsigned char *mem_42219)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42774;\n    int32_t tblock_sizze_42777;\n    int32_t wave_sizze_42776;\n    int32_t block_id_42775;\n    int32_t global_tid_42773;\n    int64_t tid_42772;\n    double r_max_42160;\n    double r_min_42163;\n    \n    local_tid_42774 = get_local_id(0);\n    tblock_sizze_42777 = get_local_size(0);\n    wave_sizze_42776 = LOCKSTEP_WIDTH;\n    block_id_42775 = get", "_tblock_id(0);\n    global_tid_42773 = block_id_42775 * tblock_sizze_42777 + local_tid_42774;\n    tid_42772 = sext_i32_i64(global_tid_42773);\n    r_max_42160 = ((__global double *) tR_mem_42199)[i_p_m_t_s_39106];\n    r_min_42163 = ((__global double *) tR_mem_42199)[start_39100];\n    ((__global double *) mem_42218)[(int64_t) 0] = r_max_42160;\n    ((__global double *) mem_42219)[(int64_t) 0] = r_min_42163;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_doublezigpuseq_42778_dim1, 1, 1)\nvoid inner_SMJ_doublezigpuseq_42778(__global int *global_failure, __global unsigned char *mem_42219, __global unsigned char *ext_mem_42220, __global unsigned char *mem_42222)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42780;\n    int32_t tblock_sizze_42783;\n    int32_t wave_sizze_42782;\n    int32_t block_id_42781;\n    int32_t global_tid_42779;\n    int64_t tid_42778;\n    double s_max_42165;\n    double r_min_42166;\n    bool defunc_0_gt_res_42167;\n    \n    local_tid_42780 = get_local_id(0);\n    tblock_sizze_42783 = get_local_size(0);\n    wave_sizze_42782 = LOCKSTEP_WIDTH;\n    block_id_42781 = get_tblock_id(0);\n    global_tid_42779 = block_id_42781 * tblock_sizze_42783 + local_tid_42780;\n    tid_42778 = sext_i32_i64(global_tid_42779);\n    s_max_42165 = ((__global double *) ext_mem_42220)[(int64_t) 0];\n    r_min_42166 = ((__global double *) mem_42219)[(int64_t) 0];\n    defunc_0_gt_res_42167 = s_max_42165 < r_min_42166;\n    ((__global bool *) mem_42222)[(int64_t) 0] = defunc_0_gt_res_42167;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_doublezigpuseq_42784_dim1, 1, 1)\nvoid inner_SMJ_doublezigpuseq_42784(__global int *global_failure, __global unsigned char *mem_42218, __global unsigned char *ext_mem_42221, __global unsigned char *mem_42223)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42786;\n    int32_t tblock_sizze_42789;\n    int32_t wave_sizze_42788;\n    int32_t block_id_42787;\n    int32_t global_tid_4278",
                                    "5;\n    int64_t tid_42784;\n    double r_max_42170;\n    double s_min_42171;\n    bool defunc_0_gt_res_42172;\n    \n    local_tid_42786 = get_local_id(0);\n    tblock_sizze_42789 = get_local_size(0);\n    wave_sizze_42788 = LOCKSTEP_WIDTH;\n    block_id_42787 = get_tblock_id(0);\n    global_tid_42785 = block_id_42787 * tblock_sizze_42789 + local_tid_42786;\n    tid_42784 = sext_i32_i64(global_tid_42785);\n    r_max_42170 = ((__global double *) mem_42218)[(int64_t) 0];\n    s_min_42171 = ((__global double *) ext_mem_42221)[(int64_t) 0];\n    defunc_0_gt_res_42172 = r_max_42170 < s_min_42171;\n    ((__global bool *) mem_42223)[(int64_t) 0] = defunc_0_gt_res_42172;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_doublezigpuseq_43162_dim1, 1, 1)\nvoid inner_SMJ_doublezigpuseq_43162(__global int *global_failure, int64_t m_39210, __global unsigned char *mem_42394, __global unsigned char *mem_42396)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43164;\n    int32_t tblock_sizze_43167;\n    int32_t wave_sizze_43166;\n    int32_t block_id_43165;\n    int32_t global_tid_43163;\n    int64_t tid_43162;\n    int64_t x_42174;\n    \n    local_tid_43164 = get_local_id(0);\n    tblock_sizze_43167 = get_local_size(0);\n    wave_sizze_43166 = LOCKSTEP_WIDTH;\n    block_id_43165 = get_tblock_id(0);\n    global_tid_43163 = block_id_43165 * tblock_sizze_43167 + local_tid_43164;\n    tid_43162 = sext_i32_i64(global_tid_43163);\n    x_42174 = ((__global int64_t *) mem_42394)[m_39210];\n    ((__global int64_t *) mem_42396)[(int64_t) 0] = x_42174;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_doublezigpuseq_43168_dim1, 1, 1)\nvoid inner_SMJ_doublezigpuseq_43168(__global int *global_failure, int64_t m_39210, __global unsigned char *mem_42377, __global unsigned char *mem_42399)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43170;\n    int32_t tblock_sizze_43173;\n    int32_t wave_sizze_43172;\n    int32_t block_id_43171;\n    int32_t global_ti", "d_43169;\n    int64_t tid_43168;\n    int64_t x_42178;\n    \n    local_tid_43170 = get_local_id(0);\n    tblock_sizze_43173 = get_local_size(0);\n    wave_sizze_43172 = LOCKSTEP_WIDTH;\n    block_id_43171 = get_tblock_id(0);\n    global_tid_43169 = block_id_43171 * tblock_sizze_43173 + local_tid_43170;\n    tid_43168 = sext_i32_i64(global_tid_43169);\n    x_42178 = ((__global int64_t *) mem_42377)[m_39210];\n    ((__global int64_t *) mem_42399)[(int64_t) 0] = x_42178;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_doublezigpuseq_43174_dim1, 1, 1)\nvoid inner_SMJ_doublezigpuseq_43174(__global int *global_failure, __global unsigned char *ext_mem_42397, __global unsigned char *ext_mem_42400, __global unsigned char *mem_42406)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43176;\n    int32_t tblock_sizze_43179;\n    int32_t wave_sizze_43178;\n    int32_t block_id_43177;\n    int32_t global_tid_43175;\n    int64_t tid_43174;\n    int64_t zp_lhs_42182;\n    int64_t n_pairs_t_res_42183;\n    int64_t n_pairs_t_res_42184;\n    \n    local_tid_43176 = get_local_id(0);\n    tblock_sizze_43179 = get_local_size(0);\n    wave_sizze_43178 = LOCKSTEP_WIDTH;\n    block_id_43177 = get_tblock_id(0);\n    global_tid_43175 = block_id_43177 * tblock_sizze_43179 + local_tid_43176;\n    tid_43174 = sext_i32_i64(global_tid_43175);\n    zp_lhs_42182 = ((__global int64_t *) ext_mem_42397)[(int64_t) 0];\n    n_pairs_t_res_42183 = ((__global int64_t *) ext_mem_42400)[(int64_t) 0];\n    n_pairs_t_res_42184 = add64(zp_lhs_42182, n_pairs_t_res_42183);\n    ((__global int64_t *) mem_42406)[(int64_t) 0] = n_pairs_t_res_42184;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_doublezigpuseq_43221_dim1, 1, 1)\nvoid inner_SMJ_doublezigpuseq_43221(__global int *global_failure, int64_t loopres_39384, __global unsigned char *mem_param_42440, __global unsigned char *mem_param_42443, __global unsigned char *mem_param_42446, __global unsigned char *mem_42453, __global unsigned char *me", "m_42454, __global unsigned char *mem_42455)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43223;\n    int32_t tblock_sizze_43226;\n    int32_t wave_sizze_43225;\n    int32_t block_id_43224;\n    int32_t global_tid_43222;\n    int64_t tid_43221;\n    double loopres_42186;\n    int64_t loopres_42188;\n    int64_t loopres_42190;\n    \n    local_tid_43223 = get_local_id(0);\n    tblock_sizze_43226 = get_local_size(0);\n    wave_sizze_43225 = LOCKSTEP_WIDTH;\n    block_id_43224 = get_tblock_id(0);\n    global_tid_43222 = block_id_43224 * tblock_sizze_43226 + local_tid_43223;\n    tid_43221 = sext_i32_i64(global_tid_43222);\n    loopres_42186 = ((__global double *) mem_param_42440)[loopres_39384];\n    loopres_42188 = ((__global int64_t *) mem_param_42443)[loopres_39384];\n    loopres_42190 = ((__global int64_t *) mem_param_42446)[loopres_39384];\n    ((__global double *) mem_42453)[(int64_t) 0] = loopres_42186;\n    ((__global int64_t *) mem_42454)[(int64_t) 0] = loopres_42188;\n    ((__global int64_t *) mem_42455)[(int64_t) 0] = loopres_42190;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL\nvoid inner_SMJ_doublezireplicate_43228(int64_t loopres_39385, int64_t replicate_n_43227, int64_t virt_num_tblocks_43233, int64_t num_tblocks_43234, __global unsigned char *mem_42453, __global unsigned char *mem_42457)\n{\n    int32_t replicate_ltid_43229;\n    int32_t tblock_sizze_43231;\n    int32_t replicate_gid_43230;\n    int32_t replicate_gtid_43228;\n    int32_t phys_tblock_id_43235;\n    int32_t iterations_43236;\n    \n    replicate_ltid_43229 = get_local_id(0);\n    tblock_sizze_43231 = get_local_size(0);\n    replicate_gid_43230 = get_tblock_id(0);\n    replicate_gtid_43228 = replicate_gid_43230 * tblock_sizze_43231 + replicate_ltid_43229;\n    phys_tblock_id_43235 = get_tblock_id(0);\n    iterations_43236 = sdiv_up32(sext_i64_i32(virt_num_tblocks_43233) - phys_tblock_id_43235, sext_i64_i32(num_tblocks_43234));\n    for (int32_t i_43237 = 0; i_43237 < iterations_43236; i_43237++) {\n",
                                    "        int32_t virt_tblock_id_43238;\n        int64_t global_tid_43239;\n        int64_t slice_43242;\n        int64_t slice_43243;\n        int64_t rep_i_43240;\n        int64_t remnant_43244;\n        int64_t rep_i_43241;\n        int64_t remnant_43245;\n        \n        virt_tblock_id_43238 = phys_tblock_id_43235 + i_43237 * sext_i64_i32(num_tblocks_43234);\n        global_tid_43239 = sext_i32_i64(virt_tblock_id_43238) * sext_i32_i64(tblock_sizze_43231) + sext_i32_i64(replicate_ltid_43229);\n        slice_43242 = (int64_t) 1;\n        slice_43243 = loopres_39385 * slice_43242;\n        rep_i_43240 = squot64(global_tid_43239, slice_43242);\n        remnant_43244 = global_tid_43239 - rep_i_43240 * slice_43242;\n        rep_i_43241 = remnant_43244;\n        remnant_43245 = remnant_43244 - rep_i_43241;\n        if (slt64(global_tid_43239, replicate_n_43227)) {\n            double tmp_43246 = ((__global double *) mem_42453)[rep_i_43241];\n            \n            ((__global double *) mem_42457)[rep_i_43240 + rep_i_43241] = tmp_43246;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid inner_SMJ_doublezireplicate_43248(int64_t loopres_39385, int64_t replicate_n_43247, int64_t virt_num_tblocks_43253, int64_t num_tblocks_43254, __global unsigned char *mem_42454, __global unsigned char *mem_42459)\n{\n    int32_t replicate_ltid_43249;\n    int32_t tblock_sizze_43251;\n    int32_t replicate_gid_43250;\n    int32_t replicate_gtid_43248;\n    int32_t phys_tblock_id_43255;\n    int32_t iterations_43256;\n    \n    replicate_ltid_43249 = get_local_id(0);\n    tblock_sizze_43251 = get_local_size(0);\n    replicate_gid_43250 = get_tblock_id(0);\n    replicate_gtid_43248 = replicate_gid_43250 * tblock_sizze_43251 + replicate_ltid_43249;\n    phys_tblock_id_43255 = get_tblock_id(0);\n    iterations_43256 = sdiv_up32(sext_i64_i32(virt_num_tblocks_43253) - phys_tblock_id_43255, sext_i64_i32(num_tblocks_43254));\n    for (int32_t i_43257 = 0", "; i_43257 < iterations_43256; i_43257++) {\n        int32_t virt_tblock_id_43258;\n        int64_t global_tid_43259;\n        int64_t slice_43262;\n        int64_t slice_43263;\n        int64_t rep_i_43260;\n        int64_t remnant_43264;\n        int64_t rep_i_43261;\n        int64_t remnant_43265;\n        \n        virt_tblock_id_43258 = phys_tblock_id_43255 + i_43257 * sext_i64_i32(num_tblocks_43254);\n        global_tid_43259 = sext_i32_i64(virt_tblock_id_43258) * sext_i32_i64(tblock_sizze_43251) + sext_i32_i64(replicate_ltid_43249);\n        slice_43262 = (int64_t) 1;\n        slice_43263 = loopres_39385 * slice_43262;\n        rep_i_43260 = squot64(global_tid_43259, slice_43262);\n        remnant_43264 = global_tid_43259 - rep_i_43260 * slice_43262;\n        rep_i_43261 = remnant_43264;\n        remnant_43265 = remnant_43264 - rep_i_43261;\n        if (slt64(global_tid_43259, replicate_n_43247)) {\n            int64_t tmp_43266 = ((__global int64_t *) mem_42454)[rep_i_43261];\n            \n            ((__global int64_t *) mem_42459)[rep_i_43260 + rep_i_43261] = tmp_43266;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_doublezisegmap_41341_dim1, 1, 1)\nvoid inner_SMJ_doublezisegmap_41341(__global int *global_failure, int64_t nR_34519, int64_t m_39200, int64_t num_tblocks_41346, int64_t ext_42365, int64_t ext_42366, int64_t ext_42367, int64_t ext_42368, int32_t virt_num_tblocks_42987, __global unsigned char *tR_mem_42199, __global unsigned char *ext_mem_42201, __global unsigned char *ext_mem_42369, __global unsigned char *ext_mem_42370, __global unsigned char *mem_42373, __global unsigned char *mem_42375, __global unsigned char *mem_42377, __global unsigned char *mem_42379, __global unsigned char *mem_42381, __global unsigned char *mem_42383)\n{\n    #define segmap_tblock_sizze_41344 (inner_SMJ_doublezisegmap_41341zisegmap_tblock_sizze_41344)\n    if (*global_failure >= 0)\n        return;\n    \n", "    int32_t local_tid_42989;\n    int32_t tblock_sizze_42992;\n    int32_t wave_sizze_42991;\n    int32_t block_id_42990;\n    int32_t global_tid_42988;\n    int64_t phys_tid_41341;\n    int32_t phys_tblock_id_42993;\n    int32_t iterations_42994;\n    \n    local_tid_42989 = get_local_id(0);\n    tblock_sizze_42992 = get_local_size(0);\n    wave_sizze_42991 = LOCKSTEP_WIDTH;\n    block_id_42990 = get_tblock_id(0);\n    global_tid_42988 = block_id_42990 * tblock_sizze_42992 + local_tid_42989;\n    phys_tid_41341 = sext_i32_i64(global_tid_42988);\n    phys_tblock_id_42993 = get_tblock_id(0);\n    iterations_42994 = sdiv_up32(virt_num_tblocks_42987 - phys_tblock_id_42993, sext_i64_i32(num_tblocks_41346));\n    for (int32_t i_42995 = 0; i_42995 < iterations_42994; i_42995++) {\n        int32_t virt_tblock_id_42996;\n        int64_t global_tid_42997;\n        int64_t slice_42998;\n        int64_t write_i_41340;\n        int64_t remnant_42999;\n        \n        virt_tblock_id_42996 = phys_tblock_id_42993 + i_42995 * sext_i64_i32(num_tblocks_41346);\n        global_tid_42997 = sext_i32_i64(virt_tblock_id_42996) * segmap_tblock_sizze_41344 + sext_i32_i64(local_tid_42989);\n        slice_42998 = nR_34519;\n        write_i_41340 = global_tid_42997;\n        remnant_42999 = global_tid_42997 - write_i_41340;\n        if (slt64(write_i_41340, nR_34519)) {\n            int64_t eta_p_39447;\n            double write_value_39449;\n            int64_t write_value_39450;\n            int64_t write_value_39451;\n            int64_t write_value_39452;\n            bool cond_39453;\n            int64_t lifted_lambda_res_39454;\n            \n            eta_p_39447 = ((__global int64_t *) mem_42375)[write_i_41340];\n            write_value_39449 = ((__global double *) tR_mem_42199)[write_i_41340];\n            write_value_39450 = ((__global int64_t *) ext_mem_42201)[write_i_41340];\n            write_value_39451 = ((__global int64_t *) ext_mem_42369)[ext_42366 + write_i_41340 * ext_42365];\n            write_value_39452 = ((_",
                                    "_global int64_t *) ext_mem_42370)[ext_42368 + write_i_41340 * ext_42367];\n            cond_39453 = eta_p_39447 == (int64_t) 1;\n            if (cond_39453) {\n                int64_t eta_p_39448;\n                int64_t lifted_lambda_res_t_res_39514;\n                \n                eta_p_39448 = ((__global int64_t *) mem_42373)[write_i_41340];\n                lifted_lambda_res_t_res_39514 = sub64(eta_p_39448, (int64_t) 1);\n                lifted_lambda_res_39454 = lifted_lambda_res_t_res_39514;\n            } else {\n                lifted_lambda_res_39454 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39454) && slt64(lifted_lambda_res_39454, m_39200)) {\n                ((__global double *) mem_42383)[lifted_lambda_res_39454] = write_value_39449;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39454) && slt64(lifted_lambda_res_39454, m_39200)) {\n                ((__global int64_t *) mem_42381)[lifted_lambda_res_39454] = write_value_39450;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39454) && slt64(lifted_lambda_res_39454, m_39200)) {\n                ((__global int64_t *) mem_42379)[lifted_lambda_res_39454] = write_value_39451;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39454) && slt64(lifted_lambda_res_39454, m_39200)) {\n                ((__global int64_t *) mem_42377)[lifted_lambda_res_39454] = write_value_39452;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_41344\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_doublezisegmap_41375_dim1, 1, 1)\nvoid inner_SMJ_doublezisegmap_41375(__global int *global_failure, int64_t m_39200, __global unsigned char *mem_42387, __global unsigned char *mem_42394)\n{\n    #define segmap_tblock_sizze_41371 (inner_SMJ_doublezisegmap_41375zisegmap_tblock_sizze_41371)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43155;\n    int32_", "t tblock_sizze_43158;\n    int32_t wave_sizze_43157;\n    int32_t block_id_43156;\n    int32_t global_tid_43154;\n    int64_t phys_tid_41375;\n    int64_t global_tid_43159;\n    int64_t slice_43160;\n    int64_t gtid_41374;\n    int64_t remnant_43161;\n    \n    local_tid_43155 = get_local_id(0);\n    tblock_sizze_43158 = get_local_size(0);\n    wave_sizze_43157 = LOCKSTEP_WIDTH;\n    block_id_43156 = get_tblock_id(0);\n    global_tid_43154 = block_id_43156 * tblock_sizze_43158 + local_tid_43155;\n    phys_tid_41375 = sext_i32_i64(global_tid_43154);\n    global_tid_43159 = sext_i32_i64(block_id_43156) * segmap_tblock_sizze_41371 + sext_i32_i64(local_tid_43155);\n    slice_43160 = m_39200;\n    gtid_41374 = global_tid_43159;\n    remnant_43161 = global_tid_43159 - gtid_41374;\n    if (slt64(gtid_41374, m_39200)) {\n        int64_t zv_lhs_41377;\n        int64_t tmp_41378;\n        bool cond_41380;\n        int64_t lifted_lambda_res_41381;\n        \n        zv_lhs_41377 = add64((int64_t) -1, gtid_41374);\n        tmp_41378 = smod64(zv_lhs_41377, m_39200);\n        cond_41380 = gtid_41374 == (int64_t) 0;\n        if (cond_41380) {\n            lifted_lambda_res_41381 = (int64_t) 0;\n        } else {\n            int64_t lifted_lambda_res_41379 = ((__global int64_t *) mem_42387)[tmp_41378];\n            \n            lifted_lambda_res_41381 = lifted_lambda_res_41379;\n        }\n        ((__global int64_t *) mem_42394)[gtid_41374] = lifted_lambda_res_41381;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_41371\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_doublezisegmap_41383_dim1, 1, 1)\nvoid inner_SMJ_doublezisegmap_41383(__global int *global_failure, int64_t m_39200, int64_t lower_bound_39283, int64_t min_res_39285, int64_t j_m_i_39286, int64_t num_tblocks_41388, int32_t virt_num_tblocks_43200, __global unsigned char *mem_42379, __global unsigned char *mem_42381, __global unsigned char *mem_42383, __global unsigned char *mem_42394, __global unsigned char *mem_42423, __global unsigned char *mem_4242", "5, __global unsigned char *mem_42427)\n{\n    #define segmap_tblock_sizze_41386 (inner_SMJ_doublezisegmap_41383zisegmap_tblock_sizze_41386)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43202;\n    int32_t tblock_sizze_43205;\n    int32_t wave_sizze_43204;\n    int32_t block_id_43203;\n    int32_t global_tid_43201;\n    int64_t phys_tid_41383;\n    int32_t phys_tblock_id_43206;\n    int32_t iterations_43207;\n    \n    local_tid_43202 = get_local_id(0);\n    tblock_sizze_43205 = get_local_size(0);\n    wave_sizze_43204 = LOCKSTEP_WIDTH;\n    block_id_43203 = get_tblock_id(0);\n    global_tid_43201 = block_id_43203 * tblock_sizze_43205 + local_tid_43202;\n    phys_tid_41383 = sext_i32_i64(global_tid_43201);\n    phys_tblock_id_43206 = get_tblock_id(0);\n    iterations_43207 = sdiv_up32(virt_num_tblocks_43200 - phys_tblock_id_43206, sext_i64_i32(num_tblocks_41388));\n    for (int32_t i_43208 = 0; i_43208 < iterations_43207; i_43208++) {\n        int32_t virt_tblock_id_43209;\n        int64_t global_tid_43210;\n        int64_t slice_43211;\n        int64_t write_i_41382;\n        int64_t remnant_43212;\n        \n        virt_tblock_id_43209 = phys_tblock_id_43206 + i_43208 * sext_i64_i32(num_tblocks_41388);\n        global_tid_43210 = sext_i32_i64(virt_tblock_id_43209) * segmap_tblock_sizze_41386 + sext_i32_i64(local_tid_43202);\n        slice_43211 = m_39200;\n        write_i_41382 = global_tid_43210;\n        remnant_43212 = global_tid_43210 - write_i_41382;\n        if (slt64(write_i_41382, m_39200)) {\n            int64_t eta_p_39484;\n            double write_value_39485;\n            int64_t write_value_39486;\n            int64_t write_value_39487;\n            bool cond_39488;\n            bool cond_t_res_39489;\n            bool x_39490;\n            int64_t lifted_lambda_res_39491;\n            \n            eta_p_39484 = ((__global int64_t *) mem_42394)[write_i_41382];\n            write_value_39485 = ((__global double *) mem_42383)[write_i_41382];\n            write_value",
                                    "_39486 = ((__global int64_t *) mem_42381)[write_i_41382];\n            write_value_39487 = ((__global int64_t *) mem_42379)[write_i_41382];\n            cond_39488 = sle64(lower_bound_39283, eta_p_39484);\n            cond_t_res_39489 = slt64(eta_p_39484, min_res_39285);\n            x_39490 = cond_39488 && cond_t_res_39489;\n            if (x_39490) {\n                int64_t lifted_lambda_res_t_res_39517 = sub64(eta_p_39484, lower_bound_39283);\n                \n                lifted_lambda_res_39491 = lifted_lambda_res_t_res_39517;\n            } else {\n                lifted_lambda_res_39491 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39491) && slt64(lifted_lambda_res_39491, j_m_i_39286)) {\n                ((__global double *) mem_42423)[lifted_lambda_res_39491] = write_value_39485;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39491) && slt64(lifted_lambda_res_39491, j_m_i_39286)) {\n                ((__global int64_t *) mem_42425)[lifted_lambda_res_39491] = write_value_39486;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39491) && slt64(lifted_lambda_res_39491, j_m_i_39286)) {\n                ((__global int64_t *) mem_42427)[lifted_lambda_res_39491] = write_value_39487;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_41386\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_doublezisegmap_41391_dim1, 1, 1)\nvoid inner_SMJ_doublezisegmap_41391(__global int *global_failure, int64_t m_39200, int64_t m_39340, int64_t num_tblocks_41396, int32_t virt_num_tblocks_43182, __global unsigned char *mem_42377, __global unsigned char *mem_42389, __global unsigned char *mem_42391, __global unsigned char *mem_42394, __global unsigned char *mem_42402, __global unsigned char *mem_42404)\n{\n    #define segmap_tblock_sizze_41394 (inner_SMJ_doublezisegmap_41391zisegmap_tblock_sizze_41394)\n    if (*global_failure >= 0)\n        ret", "urn;\n    \n    int32_t local_tid_43184;\n    int32_t tblock_sizze_43187;\n    int32_t wave_sizze_43186;\n    int32_t block_id_43185;\n    int32_t global_tid_43183;\n    int64_t phys_tid_41391;\n    int32_t phys_tblock_id_43188;\n    int32_t iterations_43189;\n    \n    local_tid_43184 = get_local_id(0);\n    tblock_sizze_43187 = get_local_size(0);\n    wave_sizze_43186 = LOCKSTEP_WIDTH;\n    block_id_43185 = get_tblock_id(0);\n    global_tid_43183 = block_id_43185 * tblock_sizze_43187 + local_tid_43184;\n    phys_tid_41391 = sext_i32_i64(global_tid_43183);\n    phys_tblock_id_43188 = get_tblock_id(0);\n    iterations_43189 = sdiv_up32(virt_num_tblocks_43182 - phys_tblock_id_43188, sext_i64_i32(num_tblocks_41396));\n    for (int32_t i_43190 = 0; i_43190 < iterations_43189; i_43190++) {\n        int32_t virt_tblock_id_43191;\n        int64_t global_tid_43192;\n        int64_t slice_43193;\n        int64_t write_i_41390;\n        int64_t remnant_43194;\n        \n        virt_tblock_id_43191 = phys_tblock_id_43188 + i_43190 * sext_i64_i32(num_tblocks_41396);\n        global_tid_43192 = sext_i32_i64(virt_tblock_id_43191) * segmap_tblock_sizze_41394 + sext_i32_i64(local_tid_43184);\n        slice_43193 = m_39200;\n        write_i_41390 = global_tid_43192;\n        remnant_43194 = global_tid_43192 - write_i_41390;\n        if (slt64(write_i_41390, m_39200)) {\n            int64_t eta_p_39424;\n            int64_t write_value_39426;\n            int64_t write_value_39427;\n            bool cond_39428;\n            int64_t lifted_lambda_res_39429;\n            \n            eta_p_39424 = ((__global int64_t *) mem_42391)[write_i_41390];\n            write_value_39426 = ((__global int64_t *) mem_42394)[write_i_41390];\n            write_value_39427 = ((__global int64_t *) mem_42377)[write_i_41390];\n            cond_39428 = eta_p_39424 == (int64_t) 1;\n            if (cond_39428) {\n                int64_t eta_p_39425;\n                int64_t lifted_lambda_res_t_res_39522;\n                \n                eta_p_39425", " = ((__global int64_t *) mem_42389)[write_i_41390];\n                lifted_lambda_res_t_res_39522 = sub64(eta_p_39425, (int64_t) 1);\n                lifted_lambda_res_39429 = lifted_lambda_res_t_res_39522;\n            } else {\n                lifted_lambda_res_39429 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39429) && slt64(lifted_lambda_res_39429, m_39340)) {\n                ((__global int64_t *) mem_42404)[lifted_lambda_res_39429] = write_value_39426;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39429) && slt64(lifted_lambda_res_39429, m_39340)) {\n                ((__global int64_t *) mem_42402)[lifted_lambda_res_39429] = write_value_39427;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_41394\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_doublezisegmap_41413_dim1, 1, 1)\nvoid inner_SMJ_doublezisegmap_41413(__global int *global_failure, int64_t loopres_39384, int64_t loopres_39385, __global unsigned char *mem_42452, __global unsigned char *mem_42455)\n{\n    #define segmap_tblock_sizze_41409 (inner_SMJ_doublezisegmap_41413zisegmap_tblock_sizze_41409)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43269;\n    int32_t tblock_sizze_43272;\n    int32_t wave_sizze_43271;\n    int32_t block_id_43270;\n    int32_t global_tid_43268;\n    int64_t phys_tid_41413;\n    int64_t global_tid_43273;\n    int64_t slice_43274;\n    int64_t gtid_41412;\n    int64_t remnant_43275;\n    \n    local_tid_43269 = get_local_id(0);\n    tblock_sizze_43272 = get_local_size(0);\n    wave_sizze_43271 = LOCKSTEP_WIDTH;\n    block_id_43270 = get_tblock_id(0);\n    global_tid_43268 = block_id_43270 * tblock_sizze_43272 + local_tid_43269;\n    phys_tid_41413 = sext_i32_i64(global_tid_43268);\n    global_tid_43273 = sext_i32_i64(block_id_43270) * segmap_tblock_sizze_41409 + sext_i32_i64(local_tid_43269);\n    slice_43274 = loopres_39385;\n    gt",
                                    "id_41412 = global_tid_43273;\n    remnant_43275 = global_tid_43273 - gtid_41412;\n    if (slt64(gtid_41412, loopres_39385)) {\n        int64_t loopres_42194;\n        int64_t tmp_41415;\n        \n        loopres_42194 = ((__global int64_t *) mem_42455)[(int64_t) 0];\n        tmp_41415 = add64(gtid_41412, loopres_42194);\n        ((__global int64_t *) mem_42452)[loopres_39384 + gtid_41412] = tmp_41415;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_41409\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_doublezisegmap_intrablock_41423_dim1, 1, 1)\nvoid inner_SMJ_doublezisegmap_intrablock_41423(__global int *global_failure, int64_t nS_34520, int64_t start_39100, int64_t min_res_39102, int64_t ldim_41426, int64_t num_whole_tiles_41441, int64_t residual_input_41665, unsigned char cond_41666_bits, int64_t binop_x_41682, __global unsigned char *tR_mem_42199, __global unsigned char *tS_mem_42200, __global unsigned char *ext_mem_42224, __global unsigned char *mem_42344, __global unsigned char *mem_42346)\n{\n    bool cond_41666 = cond_41666_bits;\n    \n    #define tile_sizze_41425 (inner_SMJ_doublezisegmap_intrablock_41423zitile_sizze_41425)\n    #define bytes_42306 (inner_SMJ_doublezisegmap_intrablock_41423zibytes_42306)\n    \n    volatile __local unsigned char *color_42702_backing_2 = &shared_mem[0];\n    const int64_t color_42702_backing_2_offset = 0 + (bytes_42306 + srem64((int64_t) 8 - srem64(bytes_42306, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_42701_backing_1 = &shared_mem[color_42702_backing_2_offset];\n    const int64_t color_42701_backing_1_offset = color_42702_backing_2_offset + (bytes_42306 + srem64((int64_t) 8 - srem64(bytes_42306, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_42700_backing_0 = &shared_mem[color_42701_backing_1_offset];\n    const int64_t color_42700_backing_0_offset = color_42701_backing_1_offset + (bytes_42306 + srem64((int64_t) 8 - srem64(bytes_42306, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_f", "ailure >= 0)\n        return;\n    \n    int32_t local_tid_42793;\n    int32_t tblock_sizze_42796;\n    int32_t wave_sizze_42795;\n    int32_t block_id_42794;\n    int32_t global_tid_42792;\n    int64_t gid_flat_41423;\n    int64_t slice_42798;\n    int64_t ltid_pre_42797;\n    int64_t remnant_42799;\n    int64_t slice_42800;\n    int64_t gid_41422;\n    int64_t remnant_42801;\n    __local unsigned char *color_42700;\n    __local unsigned char *color_42701;\n    __local unsigned char *color_42702;\n    int64_t binop_x_41433;\n    double mem_42290[1];\n    int64_t ltid_flat_41428;\n    int64_t ltid_41427;\n    int64_t gtid_41434;\n    bool cond_41435;\n    double pre_41436;\n    int64_t mem_42294[1];\n    double mem_42298[1];\n    int64_t mem_42302[1];\n    int64_t ltid_flat_41443;\n    int64_t ltid_41442;\n    int64_t gtid_41453;\n    bool cond_41454;\n    int64_t neutral_41455;\n    double neutral_41456;\n    int64_t ext_mem_42326[1];\n    double ext_mem_42325[1];\n    int64_t ext_mem_42324[1];\n    int64_t mem_param_42303[1];\n    double mem_param_42304[1];\n    int64_t mem_param_42305[1];\n    int64_t mem_42336[1];\n    int64_t mem_42340[1];\n    int64_t ext_mem_42342[1];\n    int64_t ext_mem_42341[1];\n    \n    local_tid_42793 = get_local_id(0);\n    tblock_sizze_42796 = get_local_size(0);\n    wave_sizze_42795 = LOCKSTEP_WIDTH;\n    block_id_42794 = get_tblock_id(0);\n    global_tid_42792 = block_id_42794 * tblock_sizze_42796 + local_tid_42793;\n    gid_flat_41423 = sext_i32_i64(block_id_42794);\n    slice_42798 = tile_sizze_41425;\n    ltid_pre_42797 = sext_i32_i64(local_tid_42793);\n    remnant_42799 = sext_i32_i64(local_tid_42793) - ltid_pre_42797;\n    slice_42800 = ldim_41426;\n    gid_41422 = sext_i32_i64(block_id_42794);\n    remnant_42801 = sext_i32_i64(block_id_42794) - gid_41422;\n    color_42700 = (__local unsigned char *) color_42700_backing_0;\n    color_42701 = (__local unsigned char *) color_42701_backing_1;\n    color_42702 = (__local unsigned char *) color_42702_backing_2;\n    binop_x_41433 = gid_4142", "2 * tile_sizze_41425;\n    ltid_flat_41428 = sext_i32_i64(local_tid_42793);\n    ltid_41427 = sext_i32_i64(sext_i64_i32(ltid_pre_42797));\n    gtid_41434 = ltid_41427 + binop_x_41433;\n    cond_41435 = slt64(gtid_41434, min_res_39102);\n    if (cond_41435) {\n        int64_t slice_41437;\n        double eta_p_41438;\n        \n        slice_41437 = start_39100 + gtid_41434;\n        eta_p_41438 = ((__global double *) tR_mem_42199)[slice_41437];\n        pre_41436 = eta_p_41438;\n    } else {\n        pre_41436 = 0.0;\n    }\n    mem_42290[(int64_t) 0] = pre_41436;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    ltid_flat_41443 = sext_i32_i64(local_tid_42793);\n    ltid_41442 = sext_i32_i64(sext_i64_i32(ltid_pre_42797));\n    gtid_41453 = binop_x_41433 + ltid_41442;\n    cond_41454 = slt64(gtid_41453, min_res_39102);\n    if (cond_41454) {\n        neutral_41455 = (int64_t) -1;\n    } else {\n        neutral_41455 = (int64_t) 0;\n    }\n    if (cond_41454) {\n        double eta_p_41458 = mem_42290[(int64_t) 0];\n        \n        neutral_41456 = eta_p_41458;\n    } else {\n        neutral_41456 = 0.0;\n    }\n    mem_42294[(int64_t) 0] = neutral_41455;\n    mem_42298[(int64_t) 0] = neutral_41456;\n    mem_42302[(int64_t) 0] = (int64_t) 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    for (int32_t i_3 = 0; i_3 < 1; i_3++)\n        mem_param_42303[i_3] = mem_42294[i_3];\n    for (int32_t i_4 = 0; i_4 < 1; i_4++)\n        mem_param_42304[i_4] = mem_42298[i_4];\n    for (int32_t i_5 = 0; i_5 < 1; i_5++)\n        mem_param_42305[i_5] = mem_42302[i_5];\n    for (int64_t tile_id_41468 = 0; tile_id_41468 < num_whole_tiles_41441; tile_id_41468++) {\n        int64_t binop_x_41567;\n        int64_t ltid_flat_41566;\n        int64_t ltid_41565;\n        int64_t j_41568;\n        bool cond_41572;\n        int64_t pre1d_41575;\n        int64_t pre1d_41573;\n        double pre1d_41574;\n        int64_t mem_42315[1];\n        double mem_42319[1];\n        int64_t mem_42323[1];\n        int64_t ltid_flat_41586;\n      ",
                                    "  int64_t ltid_41585;\n        int64_t gtid_41588;\n        int64_t acc_41590;\n        double acc_41591;\n        int64_t acc_41592;\n        bool cond_41593;\n        int64_t acc_41594;\n        double acc_41595;\n        int64_t acc_41596;\n        int64_t mem_param_tmp_42802[1];\n        double mem_param_tmp_42803[1];\n        int64_t mem_param_tmp_42804[1];\n        \n        binop_x_41567 = tile_sizze_41425 * tile_id_41468;\n        ltid_flat_41566 = sext_i32_i64(local_tid_42793);\n        ltid_41565 = sext_i32_i64(sext_i64_i32(ltid_pre_42797));\n        j_41568 = ltid_41565 + binop_x_41567;\n        cond_41572 = slt64(j_41568, nS_34520);\n        pre1d_41575 = btoi_bool_i64(cond_41572);\n        if (cond_41572) {\n            int64_t tile_elem_41576;\n            double tile_elem_41577;\n            \n            tile_elem_41576 = ((__global int64_t *) ext_mem_42224)[j_41568];\n            tile_elem_41577 = ((__global double *) tS_mem_42200)[j_41568];\n            pre1d_41573 = tile_elem_41576;\n            pre1d_41574 = tile_elem_41577;\n        } else {\n            pre1d_41573 = (int64_t) 0;\n            pre1d_41574 = 0.0;\n        }\n        ((__local int64_t *) color_42702)[ltid_41565] = pre1d_41573;\n        ((__local double *) color_42701)[ltid_41565] = pre1d_41574;\n        ((__local int64_t *) color_42700)[ltid_41565] = pre1d_41575;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_41586 = sext_i32_i64(local_tid_42793);\n        ltid_41585 = sext_i32_i64(sext_i64_i32(ltid_pre_42797));\n        gtid_41588 = binop_x_41433 + ltid_41585;\n        acc_41590 = mem_param_42303[(int64_t) 0];\n        acc_41591 = mem_param_42304[(int64_t) 0];\n        acc_41592 = mem_param_42305[(int64_t) 0];\n        cond_41593 = slt64(gtid_41588, min_res_39102);\n        if (cond_41593) {\n            double eta_p_41589;\n            int64_t x_41597;\n            double x_41598;\n            int64_t x_41599;\n            int64_t redout_42136;\n            double redout_42137;\n            int64_t redout_42138;\n   ", "         \n            eta_p_41589 = mem_42290[(int64_t) 0];\n            redout_42136 = acc_41590;\n            redout_42137 = acc_41591;\n            redout_42138 = acc_41592;\n            for (int64_t i_42139 = 0; i_42139 < tile_sizze_41425; i_42139++) {\n                int64_t x_41600;\n                double x_41601;\n                bool defunc_0_neq_res_41609;\n                bool defunc_0_neq_res_41610;\n                bool cond_f_res_41611;\n                bool y_41612;\n                bool cond_41613;\n                bool defunc_0_neq_res_41614;\n                bool defunc_0_neq_res_41615;\n                bool cond_t_res_f_res_41616;\n                bool y_41617;\n                bool cond_t_res_41618;\n                bool x_41619;\n                int64_t defunc_0_op_res_41620;\n                double defunc_0_op_res_41621;\n                int64_t defunc_0_op_res_41622;\n                int64_t redout_tmp_42808;\n                double redout_tmp_42809;\n                int64_t redout_tmp_42810;\n                \n                x_41600 = ((__local int64_t *) color_42702)[i_42139];\n                x_41601 = ((__local double *) color_42701)[i_42139];\n                defunc_0_neq_res_41609 = redout_42137 == eta_p_41589;\n                defunc_0_neq_res_41610 = !defunc_0_neq_res_41609;\n                cond_f_res_41611 = slt64(redout_42136, (int64_t) 0);\n                y_41612 = defunc_0_neq_res_41609 && cond_f_res_41611;\n                cond_41613 = defunc_0_neq_res_41610 || y_41612;\n                defunc_0_neq_res_41614 = x_41601 == eta_p_41589;\n                defunc_0_neq_res_41615 = !defunc_0_neq_res_41614;\n                cond_t_res_f_res_41616 = slt64(x_41600, (int64_t) 0);\n                y_41617 = defunc_0_neq_res_41614 && cond_t_res_f_res_41616;\n                cond_t_res_41618 = defunc_0_neq_res_41615 || y_41617;\n                x_41619 = cond_41613 && cond_t_res_41618;\n                if (x_41619) {\n                    defunc_0_op_res_41620 = (int64_t) -1;\n  ", "                  defunc_0_op_res_41621 = eta_p_41589;\n                    defunc_0_op_res_41622 = (int64_t) 0;\n                } else {\n                    int64_t x_41602;\n                    int64_t defunc_0_op_res_f_res_41623;\n                    double defunc_0_op_res_f_res_41624;\n                    int64_t defunc_0_op_res_f_res_41625;\n                    \n                    x_41602 = ((__local int64_t *) color_42700)[i_42139];\n                    if (cond_41613) {\n                        defunc_0_op_res_f_res_41623 = x_41600;\n                        defunc_0_op_res_f_res_41624 = x_41601;\n                        defunc_0_op_res_f_res_41625 = x_41602;\n                    } else {\n                        double defunc_0_op_res_f_res_f_res_41626;\n                        int64_t defunc_0_op_res_f_res_f_res_41627;\n                        int64_t defunc_0_op_res_f_res_f_res_41628;\n                        \n                        if (cond_t_res_41618) {\n                            defunc_0_op_res_f_res_f_res_41626 = redout_42137;\n                        } else {\n                            defunc_0_op_res_f_res_f_res_41626 = eta_p_41589;\n                        }\n                        if (cond_t_res_41618) {\n                            defunc_0_op_res_f_res_f_res_41627 = redout_42136;\n                            defunc_0_op_res_f_res_f_res_41628 = redout_42138;\n                        } else {\n                            int64_t min_res_41629;\n                            int64_t tmp_41630;\n                            \n                            min_res_41629 = smin64(x_41600, redout_42136);\n                            tmp_41630 = add64(x_41602, redout_42138);\n                            defunc_0_op_res_f_res_f_res_41627 = min_res_41629;\n                            defunc_0_op_res_f_res_f_res_41628 = tmp_41630;\n                        }\n                        defunc_0_op_res_f_res_41623 = defunc_0_op_res_f_res_f_res_41627;\n                        defunc_0_op_res_",
                                    "f_res_41624 = defunc_0_op_res_f_res_f_res_41626;\n                        defunc_0_op_res_f_res_41625 = defunc_0_op_res_f_res_f_res_41628;\n                    }\n                    defunc_0_op_res_41620 = defunc_0_op_res_f_res_41623;\n                    defunc_0_op_res_41621 = defunc_0_op_res_f_res_41624;\n                    defunc_0_op_res_41622 = defunc_0_op_res_f_res_41625;\n                }\n                redout_tmp_42808 = defunc_0_op_res_41620;\n                redout_tmp_42809 = defunc_0_op_res_41621;\n                redout_tmp_42810 = defunc_0_op_res_41622;\n                redout_42136 = redout_tmp_42808;\n                redout_42137 = redout_tmp_42809;\n                redout_42138 = redout_tmp_42810;\n            }\n            x_41597 = redout_42136;\n            x_41598 = redout_42137;\n            x_41599 = redout_42138;\n            acc_41594 = x_41597;\n            acc_41595 = x_41598;\n            acc_41596 = x_41599;\n        } else {\n            acc_41594 = acc_41590;\n            acc_41595 = acc_41591;\n            acc_41596 = acc_41592;\n        }\n        mem_42315[(int64_t) 0] = acc_41594;\n        mem_42319[(int64_t) 0] = acc_41595;\n        mem_42323[(int64_t) 0] = acc_41596;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_6 = 0; i_6 < 1; i_6++)\n            mem_param_tmp_42802[i_6] = mem_42315[i_6];\n        for (int32_t i_7 = 0; i_7 < 1; i_7++)\n            mem_param_tmp_42803[i_7] = mem_42319[i_7];\n        for (int32_t i_8 = 0; i_8 < 1; i_8++)\n            mem_param_tmp_42804[i_8] = mem_42323[i_8];\n        for (int32_t i_9 = 0; i_9 < 1; i_9++)\n            mem_param_42303[i_9] = mem_param_tmp_42802[i_9];\n        for (int32_t i_10 = 0; i_10 < 1; i_10++)\n            mem_param_42304[i_10] = mem_param_tmp_42803[i_10];\n        for (int32_t i_11 = 0; i_11 < 1; i_11++)\n            mem_param_42305[i_11] = mem_param_tmp_42804[i_11];\n    }\n    for (int32_t i_12 = 0; i_12 < 1; i_12++)\n        ext_mem_42326[i_12] = mem_param_42303[i_12];\n    for (int32_t i_13", " = 0; i_13 < 1; i_13++)\n        ext_mem_42325[i_13] = mem_param_42304[i_13];\n    for (int32_t i_14 = 0; i_14 < 1; i_14++)\n        ext_mem_42324[i_14] = mem_param_42305[i_14];\n    barrier(CLK_LOCAL_MEM_FENCE);\n    if (cond_41666) {\n        for (int32_t i_15 = 0; i_15 < 1; i_15++)\n            ext_mem_42342[i_15] = ext_mem_42326[i_15];\n        for (int32_t i_16 = 0; i_16 < 1; i_16++)\n            ext_mem_42341[i_16] = ext_mem_42324[i_16];\n    } else {\n        int64_t ltid_flat_41668;\n        int64_t ltid_41667;\n        int64_t j_41683;\n        bool cond_41687;\n        int64_t pre1d_41690;\n        int64_t pre1d_41688;\n        double pre1d_41689;\n        int64_t ltid_flat_41704;\n        int64_t ltid_41703;\n        int64_t gtid_41717;\n        int64_t acc_41719;\n        int64_t acc_41721;\n        bool cond_41722;\n        int64_t acc_41723;\n        int64_t acc_41725;\n        \n        ltid_flat_41668 = sext_i32_i64(local_tid_42793);\n        ltid_41667 = sext_i32_i64(sext_i64_i32(ltid_pre_42797));\n        j_41683 = ltid_41667 + binop_x_41682;\n        cond_41687 = slt64(j_41683, nS_34520);\n        pre1d_41690 = btoi_bool_i64(cond_41687);\n        if (cond_41687) {\n            int64_t tile_elem_41691;\n            double tile_elem_41692;\n            \n            tile_elem_41691 = ((__global int64_t *) ext_mem_42224)[j_41683];\n            tile_elem_41692 = ((__global double *) tS_mem_42200)[j_41683];\n            pre1d_41688 = tile_elem_41691;\n            pre1d_41689 = tile_elem_41692;\n        } else {\n            pre1d_41688 = (int64_t) 0;\n            pre1d_41689 = 0.0;\n        }\n        ((__local int64_t *) color_42702)[ltid_41667] = pre1d_41688;\n        ((__local double *) color_42701)[ltid_41667] = pre1d_41689;\n        ((__local int64_t *) color_42700)[ltid_41667] = pre1d_41690;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_41704 = sext_i32_i64(local_tid_42793);\n        ltid_41703 = sext_i32_i64(sext_i64_i32(ltid_pre_42797));\n        gtid_41717 = binop_x_41433 + ltid_4", "1703;\n        acc_41719 = ext_mem_42326[(int64_t) 0];\n        acc_41721 = ext_mem_42324[(int64_t) 0];\n        cond_41722 = slt64(gtid_41717, min_res_39102);\n        if (cond_41722) {\n            double eta_p_41718;\n            double acc_41720;\n            int64_t x_41726;\n            double x_41727;\n            int64_t x_41728;\n            int64_t redout_42140;\n            double redout_42141;\n            int64_t redout_42142;\n            \n            eta_p_41718 = mem_42290[(int64_t) 0];\n            acc_41720 = ext_mem_42325[(int64_t) 0];\n            redout_42140 = acc_41719;\n            redout_42141 = acc_41720;\n            redout_42142 = acc_41721;\n            for (int64_t i_42143 = 0; i_42143 < residual_input_41665; i_42143++) {\n                int64_t x_41729;\n                double x_41730;\n                bool defunc_0_neq_res_41738;\n                bool defunc_0_neq_res_41739;\n                bool cond_f_res_41740;\n                bool y_41741;\n                bool cond_41742;\n                bool defunc_0_neq_res_41743;\n                bool defunc_0_neq_res_41744;\n                bool cond_t_res_f_res_41745;\n                bool y_41746;\n                bool cond_t_res_41747;\n                bool x_41748;\n                int64_t defunc_0_op_res_41749;\n                double defunc_0_op_res_41750;\n                int64_t defunc_0_op_res_41751;\n                int64_t redout_tmp_42811;\n                double redout_tmp_42812;\n                int64_t redout_tmp_42813;\n                \n                x_41729 = ((__local int64_t *) color_42702)[i_42143];\n                x_41730 = ((__local double *) color_42701)[i_42143];\n                defunc_0_neq_res_41738 = redout_42141 == eta_p_41718;\n                defunc_0_neq_res_41739 = !defunc_0_neq_res_41738;\n                cond_f_res_41740 = slt64(redout_42140, (int64_t) 0);\n                y_41741 = defunc_0_neq_res_41738 && cond_f_res_41740;\n                cond_41742 = defunc_0_neq_res_41739 || y_41741;\n     ",
                                    "           defunc_0_neq_res_41743 = x_41730 == eta_p_41718;\n                defunc_0_neq_res_41744 = !defunc_0_neq_res_41743;\n                cond_t_res_f_res_41745 = slt64(x_41729, (int64_t) 0);\n                y_41746 = defunc_0_neq_res_41743 && cond_t_res_f_res_41745;\n                cond_t_res_41747 = defunc_0_neq_res_41744 || y_41746;\n                x_41748 = cond_41742 && cond_t_res_41747;\n                if (x_41748) {\n                    defunc_0_op_res_41749 = (int64_t) -1;\n                    defunc_0_op_res_41750 = eta_p_41718;\n                    defunc_0_op_res_41751 = (int64_t) 0;\n                } else {\n                    int64_t x_41731;\n                    int64_t defunc_0_op_res_f_res_41752;\n                    double defunc_0_op_res_f_res_41753;\n                    int64_t defunc_0_op_res_f_res_41754;\n                    \n                    x_41731 = ((__local int64_t *) color_42700)[i_42143];\n                    if (cond_41742) {\n                        defunc_0_op_res_f_res_41752 = x_41729;\n                        defunc_0_op_res_f_res_41753 = x_41730;\n                        defunc_0_op_res_f_res_41754 = x_41731;\n                    } else {\n                        double defunc_0_op_res_f_res_f_res_41755;\n                        int64_t defunc_0_op_res_f_res_f_res_41756;\n                        int64_t defunc_0_op_res_f_res_f_res_41757;\n                        \n                        if (cond_t_res_41747) {\n                            defunc_0_op_res_f_res_f_res_41755 = redout_42141;\n                        } else {\n                            defunc_0_op_res_f_res_f_res_41755 = eta_p_41718;\n                        }\n                        if (cond_t_res_41747) {\n                            defunc_0_op_res_f_res_f_res_41756 = redout_42140;\n                            defunc_0_op_res_f_res_f_res_41757 = redout_42142;\n                        } else {\n                            int64_t min_res_41758;\n                            int64_t tmp", "_41759;\n                            \n                            min_res_41758 = smin64(x_41729, redout_42140);\n                            tmp_41759 = add64(x_41731, redout_42142);\n                            defunc_0_op_res_f_res_f_res_41756 = min_res_41758;\n                            defunc_0_op_res_f_res_f_res_41757 = tmp_41759;\n                        }\n                        defunc_0_op_res_f_res_41752 = defunc_0_op_res_f_res_f_res_41756;\n                        defunc_0_op_res_f_res_41753 = defunc_0_op_res_f_res_f_res_41755;\n                        defunc_0_op_res_f_res_41754 = defunc_0_op_res_f_res_f_res_41757;\n                    }\n                    defunc_0_op_res_41749 = defunc_0_op_res_f_res_41752;\n                    defunc_0_op_res_41750 = defunc_0_op_res_f_res_41753;\n                    defunc_0_op_res_41751 = defunc_0_op_res_f_res_41754;\n                }\n                redout_tmp_42811 = defunc_0_op_res_41749;\n                redout_tmp_42812 = defunc_0_op_res_41750;\n                redout_tmp_42813 = defunc_0_op_res_41751;\n                redout_42140 = redout_tmp_42811;\n                redout_42141 = redout_tmp_42812;\n                redout_42142 = redout_tmp_42813;\n            }\n            x_41726 = redout_42140;\n            x_41727 = redout_42141;\n            x_41728 = redout_42142;\n            acc_41723 = x_41726;\n            acc_41725 = x_41728;\n        } else {\n            acc_41723 = acc_41719;\n            acc_41725 = acc_41721;\n        }\n        mem_42336[(int64_t) 0] = acc_41723;\n        mem_42340[(int64_t) 0] = acc_41725;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_17 = 0; i_17 < 1; i_17++)\n            ext_mem_42342[i_17] = mem_42336[i_17];\n        for (int32_t i_18 = 0; i_18 < 1; i_18++)\n            ext_mem_42341[i_18] = mem_42340[i_18];\n    }\n    if (slt64(sext_i32_i64(local_tid_42793) + tile_sizze_41425 * sext_i32_i64(block_id_42794), min_res_39102)) {\n        int64_t tmp_42814 = ext_mem_42342[(int64_t) 0];\n     ", "   \n        ((__global int64_t *) mem_42344)[sext_i32_i64(local_tid_42793) + tile_sizze_41425 * sext_i32_i64(block_id_42794)] = tmp_42814;\n    }\n    if (slt64(sext_i32_i64(local_tid_42793) + tile_sizze_41425 * sext_i32_i64(block_id_42794), min_res_39102)) {\n        int64_t tmp_42815 = ext_mem_42341[(int64_t) 0];\n        \n        ((__global int64_t *) mem_42346)[sext_i32_i64(local_tid_42793) + tile_sizze_41425 * sext_i32_i64(block_id_42794)] = tmp_42815;\n    }\n    \n  error_8:\n    return;\n    #undef tile_sizze_41425\n    #undef bytes_42306\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_doublezisegmap_intrablock_41778_dim1, 1, 1)\nvoid inner_SMJ_doublezisegmap_intrablock_41778(__global int *global_failure, int64_t nS_34520, int64_t start_39100, int64_t min_res_39102, int64_t ldim_41781, int64_t num_whole_tiles_41796, int64_t residual_input_42020, unsigned char cond_42021_bits, int64_t binop_x_42037, __global unsigned char *tR_mem_42199, __global unsigned char *tS_mem_42200, __global unsigned char *ext_mem_42224, __global unsigned char *mem_42283, __global unsigned char *mem_42285)\n{\n    bool cond_42021 = cond_42021_bits;\n    \n    #define tile_sizze_41780 (inner_SMJ_doublezisegmap_intrablock_41778zitile_sizze_41780)\n    #define bytes_42245 (inner_SMJ_doublezisegmap_intrablock_41778zibytes_42245)\n    \n    volatile __local unsigned char *color_42705_backing_2 = &shared_mem[0];\n    const int64_t color_42705_backing_2_offset = 0 + (bytes_42245 + srem64((int64_t) 8 - srem64(bytes_42245, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_42704_backing_1 = &shared_mem[color_42705_backing_2_offset];\n    const int64_t color_42704_backing_1_offset = color_42705_backing_2_offset + (bytes_42245 + srem64((int64_t) 8 - srem64(bytes_42245, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_42703_backing_0 = &shared_mem[color_42704_backing_1_offset];\n    const int64_t color_42703_backing_0_offset = color_42704_backing_1_offset + (bytes_42245 + srem64((int64_t) 8",
                                    " - srem64(bytes_42245, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42819;\n    int32_t tblock_sizze_42822;\n    int32_t wave_sizze_42821;\n    int32_t block_id_42820;\n    int32_t global_tid_42818;\n    int64_t gid_flat_41778;\n    int64_t slice_42824;\n    int64_t ltid_pre_42823;\n    int64_t remnant_42825;\n    int64_t slice_42826;\n    int64_t gid_41777;\n    int64_t remnant_42827;\n    __local unsigned char *color_42703;\n    __local unsigned char *color_42704;\n    __local unsigned char *color_42705;\n    int64_t binop_x_41788;\n    double mem_42229[1];\n    int64_t ltid_flat_41783;\n    int64_t ltid_41782;\n    int64_t gtid_41789;\n    bool cond_41790;\n    double pre_41791;\n    int64_t mem_42233[1];\n    double mem_42237[1];\n    int64_t mem_42241[1];\n    int64_t ltid_flat_41798;\n    int64_t ltid_41797;\n    int64_t gtid_41808;\n    bool cond_41809;\n    int64_t neutral_41810;\n    double neutral_41811;\n    int64_t ext_mem_42265[1];\n    double ext_mem_42264[1];\n    int64_t ext_mem_42263[1];\n    int64_t mem_param_42242[1];\n    double mem_param_42243[1];\n    int64_t mem_param_42244[1];\n    int64_t mem_42275[1];\n    int64_t mem_42279[1];\n    int64_t ext_mem_42281[1];\n    int64_t ext_mem_42280[1];\n    \n    local_tid_42819 = get_local_id(0);\n    tblock_sizze_42822 = get_local_size(0);\n    wave_sizze_42821 = LOCKSTEP_WIDTH;\n    block_id_42820 = get_tblock_id(0);\n    global_tid_42818 = block_id_42820 * tblock_sizze_42822 + local_tid_42819;\n    gid_flat_41778 = sext_i32_i64(block_id_42820);\n    slice_42824 = tile_sizze_41780;\n    ltid_pre_42823 = sext_i32_i64(local_tid_42819);\n    remnant_42825 = sext_i32_i64(local_tid_42819) - ltid_pre_42823;\n    slice_42826 = ldim_41781;\n    gid_41777 = sext_i32_i64(block_id_42820);\n    remnant_42827 = sext_i32_i64(block_id_42820) - gid_41777;\n    color_42703 = (__local unsigned char *) color_42703_backing_0;\n    color_42704 = (__local unsigned char *) color_42704_backing_1;\n    color_42705 = (__", "local unsigned char *) color_42705_backing_2;\n    binop_x_41788 = gid_41777 * tile_sizze_41780;\n    ltid_flat_41783 = sext_i32_i64(local_tid_42819);\n    ltid_41782 = sext_i32_i64(sext_i64_i32(ltid_pre_42823));\n    gtid_41789 = ltid_41782 + binop_x_41788;\n    cond_41790 = slt64(gtid_41789, min_res_39102);\n    if (cond_41790) {\n        int64_t slice_41792;\n        double eta_p_41793;\n        \n        slice_41792 = start_39100 + gtid_41789;\n        eta_p_41793 = ((__global double *) tR_mem_42199)[slice_41792];\n        pre_41791 = eta_p_41793;\n    } else {\n        pre_41791 = 0.0;\n    }\n    mem_42229[(int64_t) 0] = pre_41791;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    ltid_flat_41798 = sext_i32_i64(local_tid_42819);\n    ltid_41797 = sext_i32_i64(sext_i64_i32(ltid_pre_42823));\n    gtid_41808 = binop_x_41788 + ltid_41797;\n    cond_41809 = slt64(gtid_41808, min_res_39102);\n    if (cond_41809) {\n        neutral_41810 = (int64_t) -1;\n    } else {\n        neutral_41810 = (int64_t) 0;\n    }\n    if (cond_41809) {\n        double eta_p_41813 = mem_42229[(int64_t) 0];\n        \n        neutral_41811 = eta_p_41813;\n    } else {\n        neutral_41811 = 0.0;\n    }\n    mem_42233[(int64_t) 0] = neutral_41810;\n    mem_42237[(int64_t) 0] = neutral_41811;\n    mem_42241[(int64_t) 0] = (int64_t) 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    for (int32_t i_3 = 0; i_3 < 1; i_3++)\n        mem_param_42242[i_3] = mem_42233[i_3];\n    for (int32_t i_4 = 0; i_4 < 1; i_4++)\n        mem_param_42243[i_4] = mem_42237[i_4];\n    for (int32_t i_5 = 0; i_5 < 1; i_5++)\n        mem_param_42244[i_5] = mem_42241[i_5];\n    for (int64_t tile_id_41823 = 0; tile_id_41823 < num_whole_tiles_41796; tile_id_41823++) {\n        int64_t binop_x_41922;\n        int64_t ltid_flat_41921;\n        int64_t ltid_41920;\n        int64_t j_41923;\n        bool cond_41927;\n        int64_t pre1d_41930;\n        int64_t pre1d_41928;\n        double pre1d_41929;\n        int64_t mem_42254[1];\n        double mem_42258", "[1];\n        int64_t mem_42262[1];\n        int64_t ltid_flat_41941;\n        int64_t ltid_41940;\n        int64_t gtid_41943;\n        int64_t acc_41945;\n        double acc_41946;\n        int64_t acc_41947;\n        bool cond_41948;\n        int64_t acc_41949;\n        double acc_41950;\n        int64_t acc_41951;\n        int64_t mem_param_tmp_42828[1];\n        double mem_param_tmp_42829[1];\n        int64_t mem_param_tmp_42830[1];\n        \n        binop_x_41922 = tile_sizze_41780 * tile_id_41823;\n        ltid_flat_41921 = sext_i32_i64(local_tid_42819);\n        ltid_41920 = sext_i32_i64(sext_i64_i32(ltid_pre_42823));\n        j_41923 = ltid_41920 + binop_x_41922;\n        cond_41927 = slt64(j_41923, nS_34520);\n        pre1d_41930 = btoi_bool_i64(cond_41927);\n        if (cond_41927) {\n            int64_t tile_elem_41931;\n            double tile_elem_41932;\n            \n            tile_elem_41931 = ((__global int64_t *) ext_mem_42224)[j_41923];\n            tile_elem_41932 = ((__global double *) tS_mem_42200)[j_41923];\n            pre1d_41928 = tile_elem_41931;\n            pre1d_41929 = tile_elem_41932;\n        } else {\n            pre1d_41928 = (int64_t) 0;\n            pre1d_41929 = 0.0;\n        }\n        ((__local int64_t *) color_42705)[ltid_41920] = pre1d_41928;\n        ((__local double *) color_42704)[ltid_41920] = pre1d_41929;\n        ((__local int64_t *) color_42703)[ltid_41920] = pre1d_41930;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_41941 = sext_i32_i64(local_tid_42819);\n        ltid_41940 = sext_i32_i64(sext_i64_i32(ltid_pre_42823));\n        gtid_41943 = binop_x_41788 + ltid_41940;\n        acc_41945 = mem_param_42242[(int64_t) 0];\n        acc_41946 = mem_param_42243[(int64_t) 0];\n        acc_41947 = mem_param_42244[(int64_t) 0];\n        cond_41948 = slt64(gtid_41943, min_res_39102);\n        if (cond_41948) {\n            double eta_p_41944;\n            int64_t x_41952;\n            double x_41953;\n            int64_t x_41954;\n            int64_t redout_421",
                                    "44;\n            double redout_42145;\n            int64_t redout_42146;\n            \n            eta_p_41944 = mem_42229[(int64_t) 0];\n            redout_42144 = acc_41945;\n            redout_42145 = acc_41946;\n            redout_42146 = acc_41947;\n            for (int64_t i_42147 = 0; i_42147 < tile_sizze_41780; i_42147++) {\n                int64_t x_41955;\n                double x_41956;\n                bool defunc_0_neq_res_41964;\n                bool defunc_0_neq_res_41965;\n                bool cond_f_res_41966;\n                bool y_41967;\n                bool cond_41968;\n                bool defunc_0_neq_res_41969;\n                bool defunc_0_neq_res_41970;\n                bool cond_t_res_f_res_41971;\n                bool y_41972;\n                bool cond_t_res_41973;\n                bool x_41974;\n                int64_t defunc_0_op_res_41975;\n                double defunc_0_op_res_41976;\n                int64_t defunc_0_op_res_41977;\n                int64_t redout_tmp_42834;\n                double redout_tmp_42835;\n                int64_t redout_tmp_42836;\n                \n                x_41955 = ((__local int64_t *) color_42705)[i_42147];\n                x_41956 = ((__local double *) color_42704)[i_42147];\n                defunc_0_neq_res_41964 = redout_42145 == eta_p_41944;\n                defunc_0_neq_res_41965 = !defunc_0_neq_res_41964;\n                cond_f_res_41966 = slt64(redout_42144, (int64_t) 0);\n                y_41967 = defunc_0_neq_res_41964 && cond_f_res_41966;\n                cond_41968 = defunc_0_neq_res_41965 || y_41967;\n                defunc_0_neq_res_41969 = x_41956 == eta_p_41944;\n                defunc_0_neq_res_41970 = !defunc_0_neq_res_41969;\n                cond_t_res_f_res_41971 = slt64(x_41955, (int64_t) 0);\n                y_41972 = defunc_0_neq_res_41969 && cond_t_res_f_res_41971;\n                cond_t_res_41973 = defunc_0_neq_res_41970 || y_41972;\n                x_41974 = cond_41968 && cond_t_res_41973;\n                i", "f (x_41974) {\n                    defunc_0_op_res_41975 = (int64_t) -1;\n                    defunc_0_op_res_41976 = eta_p_41944;\n                    defunc_0_op_res_41977 = (int64_t) 0;\n                } else {\n                    int64_t x_41957;\n                    int64_t defunc_0_op_res_f_res_41978;\n                    double defunc_0_op_res_f_res_41979;\n                    int64_t defunc_0_op_res_f_res_41980;\n                    \n                    x_41957 = ((__local int64_t *) color_42703)[i_42147];\n                    if (cond_41968) {\n                        defunc_0_op_res_f_res_41978 = x_41955;\n                        defunc_0_op_res_f_res_41979 = x_41956;\n                        defunc_0_op_res_f_res_41980 = x_41957;\n                    } else {\n                        double defunc_0_op_res_f_res_f_res_41981;\n                        int64_t defunc_0_op_res_f_res_f_res_41982;\n                        int64_t defunc_0_op_res_f_res_f_res_41983;\n                        \n                        if (cond_t_res_41973) {\n                            defunc_0_op_res_f_res_f_res_41981 = redout_42145;\n                        } else {\n                            defunc_0_op_res_f_res_f_res_41981 = eta_p_41944;\n                        }\n                        if (cond_t_res_41973) {\n                            defunc_0_op_res_f_res_f_res_41982 = redout_42144;\n                            defunc_0_op_res_f_res_f_res_41983 = redout_42146;\n                        } else {\n                            int64_t min_res_41984;\n                            int64_t tmp_41985;\n                            \n                            min_res_41984 = smin64(x_41955, redout_42144);\n                            tmp_41985 = add64(x_41957, redout_42146);\n                            defunc_0_op_res_f_res_f_res_41982 = min_res_41984;\n                            defunc_0_op_res_f_res_f_res_41983 = tmp_41985;\n                        }\n                        defunc_0_op_res_f_res_41978 = d", "efunc_0_op_res_f_res_f_res_41982;\n                        defunc_0_op_res_f_res_41979 = defunc_0_op_res_f_res_f_res_41981;\n                        defunc_0_op_res_f_res_41980 = defunc_0_op_res_f_res_f_res_41983;\n                    }\n                    defunc_0_op_res_41975 = defunc_0_op_res_f_res_41978;\n                    defunc_0_op_res_41976 = defunc_0_op_res_f_res_41979;\n                    defunc_0_op_res_41977 = defunc_0_op_res_f_res_41980;\n                }\n                redout_tmp_42834 = defunc_0_op_res_41975;\n                redout_tmp_42835 = defunc_0_op_res_41976;\n                redout_tmp_42836 = defunc_0_op_res_41977;\n                redout_42144 = redout_tmp_42834;\n                redout_42145 = redout_tmp_42835;\n                redout_42146 = redout_tmp_42836;\n            }\n            x_41952 = redout_42144;\n            x_41953 = redout_42145;\n            x_41954 = redout_42146;\n            acc_41949 = x_41952;\n            acc_41950 = x_41953;\n            acc_41951 = x_41954;\n        } else {\n            acc_41949 = acc_41945;\n            acc_41950 = acc_41946;\n            acc_41951 = acc_41947;\n        }\n        mem_42254[(int64_t) 0] = acc_41949;\n        mem_42258[(int64_t) 0] = acc_41950;\n        mem_42262[(int64_t) 0] = acc_41951;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_6 = 0; i_6 < 1; i_6++)\n            mem_param_tmp_42828[i_6] = mem_42254[i_6];\n        for (int32_t i_7 = 0; i_7 < 1; i_7++)\n            mem_param_tmp_42829[i_7] = mem_42258[i_7];\n        for (int32_t i_8 = 0; i_8 < 1; i_8++)\n            mem_param_tmp_42830[i_8] = mem_42262[i_8];\n        for (int32_t i_9 = 0; i_9 < 1; i_9++)\n            mem_param_42242[i_9] = mem_param_tmp_42828[i_9];\n        for (int32_t i_10 = 0; i_10 < 1; i_10++)\n            mem_param_42243[i_10] = mem_param_tmp_42829[i_10];\n        for (int32_t i_11 = 0; i_11 < 1; i_11++)\n            mem_param_42244[i_11] = mem_param_tmp_42830[i_11];\n    }\n    for (int32_t i_12 = 0; i_12 < 1; i_12++)\n",
                                    "        ext_mem_42265[i_12] = mem_param_42242[i_12];\n    for (int32_t i_13 = 0; i_13 < 1; i_13++)\n        ext_mem_42264[i_13] = mem_param_42243[i_13];\n    for (int32_t i_14 = 0; i_14 < 1; i_14++)\n        ext_mem_42263[i_14] = mem_param_42244[i_14];\n    barrier(CLK_LOCAL_MEM_FENCE);\n    if (cond_42021) {\n        for (int32_t i_15 = 0; i_15 < 1; i_15++)\n            ext_mem_42281[i_15] = ext_mem_42265[i_15];\n        for (int32_t i_16 = 0; i_16 < 1; i_16++)\n            ext_mem_42280[i_16] = ext_mem_42263[i_16];\n    } else {\n        int64_t ltid_flat_42023;\n        int64_t ltid_42022;\n        int64_t j_42038;\n        bool cond_42042;\n        int64_t pre1d_42045;\n        int64_t pre1d_42043;\n        double pre1d_42044;\n        int64_t ltid_flat_42059;\n        int64_t ltid_42058;\n        int64_t gtid_42072;\n        int64_t acc_42074;\n        int64_t acc_42076;\n        bool cond_42077;\n        int64_t acc_42078;\n        int64_t acc_42080;\n        \n        ltid_flat_42023 = sext_i32_i64(local_tid_42819);\n        ltid_42022 = sext_i32_i64(sext_i64_i32(ltid_pre_42823));\n        j_42038 = ltid_42022 + binop_x_42037;\n        cond_42042 = slt64(j_42038, nS_34520);\n        pre1d_42045 = btoi_bool_i64(cond_42042);\n        if (cond_42042) {\n            int64_t tile_elem_42046;\n            double tile_elem_42047;\n            \n            tile_elem_42046 = ((__global int64_t *) ext_mem_42224)[j_42038];\n            tile_elem_42047 = ((__global double *) tS_mem_42200)[j_42038];\n            pre1d_42043 = tile_elem_42046;\n            pre1d_42044 = tile_elem_42047;\n        } else {\n            pre1d_42043 = (int64_t) 0;\n            pre1d_42044 = 0.0;\n        }\n        ((__local int64_t *) color_42705)[ltid_42022] = pre1d_42043;\n        ((__local double *) color_42704)[ltid_42022] = pre1d_42044;\n        ((__local int64_t *) color_42703)[ltid_42022] = pre1d_42045;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_42059 = sext_i32_i64(local_tid_42819);\n        ltid_42058 = sext_i32_i64(", "sext_i64_i32(ltid_pre_42823));\n        gtid_42072 = binop_x_41788 + ltid_42058;\n        acc_42074 = ext_mem_42265[(int64_t) 0];\n        acc_42076 = ext_mem_42263[(int64_t) 0];\n        cond_42077 = slt64(gtid_42072, min_res_39102);\n        if (cond_42077) {\n            double eta_p_42073;\n            double acc_42075;\n            int64_t x_42081;\n            double x_42082;\n            int64_t x_42083;\n            int64_t redout_42148;\n            double redout_42149;\n            int64_t redout_42150;\n            \n            eta_p_42073 = mem_42229[(int64_t) 0];\n            acc_42075 = ext_mem_42264[(int64_t) 0];\n            redout_42148 = acc_42074;\n            redout_42149 = acc_42075;\n            redout_42150 = acc_42076;\n            for (int64_t i_42151 = 0; i_42151 < residual_input_42020; i_42151++) {\n                int64_t x_42084;\n                double x_42085;\n                bool defunc_0_neq_res_42093;\n                bool defunc_0_neq_res_42094;\n                bool cond_f_res_42095;\n                bool y_42096;\n                bool cond_42097;\n                bool defunc_0_neq_res_42098;\n                bool defunc_0_neq_res_42099;\n                bool cond_t_res_f_res_42100;\n                bool y_42101;\n                bool cond_t_res_42102;\n                bool x_42103;\n                int64_t defunc_0_op_res_42104;\n                double defunc_0_op_res_42105;\n                int64_t defunc_0_op_res_42106;\n                int64_t redout_tmp_42837;\n                double redout_tmp_42838;\n                int64_t redout_tmp_42839;\n                \n                x_42084 = ((__local int64_t *) color_42705)[i_42151];\n                x_42085 = ((__local double *) color_42704)[i_42151];\n                defunc_0_neq_res_42093 = redout_42149 == eta_p_42073;\n                defunc_0_neq_res_42094 = !defunc_0_neq_res_42093;\n                cond_f_res_42095 = slt64(redout_42148, (int64_t) 0);\n                y_42096 = defunc_0_neq_res_42093 && cond_f_res_42", "095;\n                cond_42097 = defunc_0_neq_res_42094 || y_42096;\n                defunc_0_neq_res_42098 = x_42085 == eta_p_42073;\n                defunc_0_neq_res_42099 = !defunc_0_neq_res_42098;\n                cond_t_res_f_res_42100 = slt64(x_42084, (int64_t) 0);\n                y_42101 = defunc_0_neq_res_42098 && cond_t_res_f_res_42100;\n                cond_t_res_42102 = defunc_0_neq_res_42099 || y_42101;\n                x_42103 = cond_42097 && cond_t_res_42102;\n                if (x_42103) {\n                    defunc_0_op_res_42104 = (int64_t) -1;\n                    defunc_0_op_res_42105 = eta_p_42073;\n                    defunc_0_op_res_42106 = (int64_t) 0;\n                } else {\n                    int64_t x_42086;\n                    int64_t defunc_0_op_res_f_res_42107;\n                    double defunc_0_op_res_f_res_42108;\n                    int64_t defunc_0_op_res_f_res_42109;\n                    \n                    x_42086 = ((__local int64_t *) color_42703)[i_42151];\n                    if (cond_42097) {\n                        defunc_0_op_res_f_res_42107 = x_42084;\n                        defunc_0_op_res_f_res_42108 = x_42085;\n                        defunc_0_op_res_f_res_42109 = x_42086;\n                    } else {\n                        double defunc_0_op_res_f_res_f_res_42110;\n                        int64_t defunc_0_op_res_f_res_f_res_42111;\n                        int64_t defunc_0_op_res_f_res_f_res_42112;\n                        \n                        if (cond_t_res_42102) {\n                            defunc_0_op_res_f_res_f_res_42110 = redout_42149;\n                        } else {\n                            defunc_0_op_res_f_res_f_res_42110 = eta_p_42073;\n                        }\n                        if (cond_t_res_42102) {\n                            defunc_0_op_res_f_res_f_res_42111 = redout_42148;\n                            defunc_0_op_res_f_res_f_res_42112 = redout_42150;\n                        } else {\n                ",
                                    "            int64_t min_res_42113;\n                            int64_t tmp_42114;\n                            \n                            min_res_42113 = smin64(x_42084, redout_42148);\n                            tmp_42114 = add64(x_42086, redout_42150);\n                            defunc_0_op_res_f_res_f_res_42111 = min_res_42113;\n                            defunc_0_op_res_f_res_f_res_42112 = tmp_42114;\n                        }\n                        defunc_0_op_res_f_res_42107 = defunc_0_op_res_f_res_f_res_42111;\n                        defunc_0_op_res_f_res_42108 = defunc_0_op_res_f_res_f_res_42110;\n                        defunc_0_op_res_f_res_42109 = defunc_0_op_res_f_res_f_res_42112;\n                    }\n                    defunc_0_op_res_42104 = defunc_0_op_res_f_res_42107;\n                    defunc_0_op_res_42105 = defunc_0_op_res_f_res_42108;\n                    defunc_0_op_res_42106 = defunc_0_op_res_f_res_42109;\n                }\n                redout_tmp_42837 = defunc_0_op_res_42104;\n                redout_tmp_42838 = defunc_0_op_res_42105;\n                redout_tmp_42839 = defunc_0_op_res_42106;\n                redout_42148 = redout_tmp_42837;\n                redout_42149 = redout_tmp_42838;\n                redout_42150 = redout_tmp_42839;\n            }\n            x_42081 = redout_42148;\n            x_42082 = redout_42149;\n            x_42083 = redout_42150;\n            acc_42078 = x_42081;\n            acc_42080 = x_42083;\n        } else {\n            acc_42078 = acc_42074;\n            acc_42080 = acc_42076;\n        }\n        mem_42275[(int64_t) 0] = acc_42078;\n        mem_42279[(int64_t) 0] = acc_42080;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_17 = 0; i_17 < 1; i_17++)\n            ext_mem_42281[i_17] = mem_42275[i_17];\n        for (int32_t i_18 = 0; i_18 < 1; i_18++)\n            ext_mem_42280[i_18] = mem_42279[i_18];\n    }\n    if (slt64(sext_i32_i64(local_tid_42819) + tile_sizze_41780 * sext_i32_i64(block_id_42820), min_r", "es_39102)) {\n        int64_t tmp_42840 = ext_mem_42281[(int64_t) 0];\n        \n        ((__global int64_t *) mem_42283)[sext_i32_i64(local_tid_42819) + tile_sizze_41780 * sext_i32_i64(block_id_42820)] = tmp_42840;\n    }\n    if (slt64(sext_i32_i64(local_tid_42819) + tile_sizze_41780 * sext_i32_i64(block_id_42820), min_res_39102)) {\n        int64_t tmp_42841 = ext_mem_42280[(int64_t) 0];\n        \n        ((__global int64_t *) mem_42285)[sext_i32_i64(local_tid_42819) + tile_sizze_41780 * sext_i32_i64(block_id_42820)] = tmp_42841;\n    }\n    \n  error_8:\n    return;\n    #undef tile_sizze_41780\n    #undef bytes_42245\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_doublezisegscan_41339_dim1, 1, 1)\nvoid inner_SMJ_doublezisegscan_41339(__global int *global_failure, int64_t nR_34519, int64_t num_tblocks_41336, int64_t ext_42367, int64_t ext_42368, int64_t num_virt_blocks_42849, int64_t num_virt_threads_42850, __global unsigned char *ext_mem_42370, __global unsigned char *mem_42373, __global unsigned char *mem_42375, __global unsigned char *status_flags_mem_42851, __global unsigned char *aggregates_mem_42873, __global unsigned char *incprefixes_mem_42875, __global unsigned char *global_dynid_mem_42877)\n{\n    #define segscan_tblock_sizze_41334 (inner_SMJ_doublezisegscan_41339zisegscan_tblock_sizze_41334)\n    #define chunk_sizze_42848 (inner_SMJ_doublezisegscan_41339zichunk_sizze_42848)\n    \n    volatile __local unsigned char *local_mem_42907_backing_0 = &shared_mem[0];\n    const int64_t local_mem_42907_backing_0_offset = 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_41334), chunk_sizze_42848 * segscan_tblock_sizze_41334 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_41334), chunk_sizze_42848 * segscan_tblock_sizze_41334 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42900;\n    int32_t tblock_sizze_42903;\n    int32_t wave_sizze_42902;\n ", "   int32_t block_id_42901;\n    int32_t global_tid_42899;\n    int64_t phys_tid_41339;\n    int32_t chunk_sizze_32b_42904;\n    int64_t byte_offsets_42905;\n    int64_t warp_byte_offset_42906;\n    __local unsigned char *local_mem_42907;\n    int64_t trans_arr_len_42908;\n    int64_t phys_block_id_42914;\n    int64_t virtloop_bound_42915;\n    \n    local_tid_42900 = get_local_id(0);\n    tblock_sizze_42903 = get_local_size(0);\n    wave_sizze_42902 = LOCKSTEP_WIDTH;\n    block_id_42901 = get_tblock_id(0);\n    global_tid_42899 = block_id_42901 * tblock_sizze_42903 + local_tid_42900;\n    phys_tid_41339 = sext_i32_i64(global_tid_42899);\n    chunk_sizze_32b_42904 = sext_i64_i32(chunk_sizze_42848);\n    byte_offsets_42905 = segscan_tblock_sizze_41334 * (int64_t) 8;\n    warp_byte_offset_42906 = (int64_t) 288;\n    // Allocate reusable shared memory\n    { }\n    local_mem_42907 = (__local unsigned char *) local_mem_42907_backing_0;\n    trans_arr_len_42908 = chunk_sizze_42848 * segscan_tblock_sizze_41334;\n    phys_block_id_42914 = get_tblock_id(0);\n    virtloop_bound_42915 = sdiv_up64(num_virt_blocks_42849 - phys_block_id_42914, num_tblocks_41336);\n    for (int64_t virtloop_i_42916 = 0; virtloop_i_42916 < virtloop_bound_42915; virtloop_i_42916++) {\n        int64_t dynamic_id_42917;\n        int64_t block_offset_42918;\n        int64_t sgm_idx_42919;\n        int32_t boundary_42920;\n        int32_t segsizze_compact_42921;\n        int64_t private_mem_42922[chunk_sizze_42848];\n        int64_t thd_offset_42924;\n        int64_t acc_42940;\n        int64_t prefix_42950;\n        bool block_new_sgm_42951;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_42900 == 0) {\n                dynamic_id_42917 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_42877)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_42907)[(int64_t) 0] = dynami",
                                    "c_id_42917;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_42917 == num_virt_blocks_42849 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_42877)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_42917 = ((__local int32_t *) local_mem_42907)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_42918 = dynamic_id_42917 * chunk_sizze_42848 * segscan_tblock_sizze_41334;\n        sgm_idx_42919 = smod64(block_offset_42918, nR_34519);\n        boundary_42920 = sext_i64_i32(smin64(chunk_sizze_42848 * segscan_tblock_sizze_41334, nR_34519 - sgm_idx_42919));\n        segsizze_compact_42921 = sext_i64_i32(smin64(chunk_sizze_42848 * segscan_tblock_sizze_41334, nR_34519));\n        thd_offset_42924 = block_offset_42918 + sext_i32_i64(local_tid_42900);\n        // Load and map\n        {\n            for (int64_t i_42925 = 0; i_42925 < chunk_sizze_42848; i_42925++) {\n                int64_t virt_tid_42926 = thd_offset_42924 + i_42925 * segscan_tblock_sizze_41334;\n                int64_t slice_42927 = nR_34519;\n                int64_t gtid_41338 = virt_tid_42926;\n                int64_t remnant_42928 = virt_tid_42926 - gtid_41338;\n                \n                if (slt64(virt_tid_42926, nR_34519)) {\n                    int64_t eta_p_39458 = ((__global int64_t *) ext_mem_42370)[ext_42368 + gtid_41338 * ext_42367];\n                    bool lifted_lambda_res_39459 = slt64((int64_t) 0, eta_p_39458);\n                    int64_t defunc_0_f_res_39460 = btoi_bool_i64(lifted_lambda_res_39459);\n                    \n                    ((__global int64_t *) mem_42375)[gtid_41338] = defunc_0_f_res_39460;\n                    private_mem_42922[i_42925] = defunc_0_f_res_39460;\n                } else {\n                    private_mem_42922[i_42925] = (int64_t) ", "0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_42929 = 0; i_42929 < chunk_sizze_42848; i_42929++) {\n                int64_t sharedIdx_42930 = sext_i32_i64(local_tid_42900) + i_42929 * segscan_tblock_sizze_41334;\n                int64_t tmp_42931 = private_mem_42922[i_42929];\n                \n                ((__local int64_t *) local_mem_42907)[sharedIdx_42930] = tmp_42931;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_42932 = 0; i_42932 < chunk_sizze_42848; i_42932++) {\n                int64_t sharedIdx_42933 = sext_i32_i64(local_tid_42900) * chunk_sizze_42848 + i_42932;\n                int64_t tmp_42934 = ((__local int64_t *) local_mem_42907)[sharedIdx_42933];\n                \n                private_mem_42922[i_42932] = tmp_42934;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_42935 = 0; i_42935 < chunk_sizze_42848 - (int64_t) 1; i_42935++) {\n                int64_t eta_p_39187;\n                int64_t eta_p_39188;\n                \n                eta_p_39187 = private_mem_42922[i_42935];\n                eta_p_39188 = private_mem_42922[i_42935 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_39189 = add64(eta_p_39187, eta_p_39188);\n                \n                private_mem_42922[i_42935 + (int64_t) 1] = defunc_0_op_res_39189;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_42936 = private_mem_42922[chunk_sizze_42848 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_42907)[sext_i32_i64(local_tid_42900)] = tmp_42936;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_42937;\n            int64_t eta_p_42938;\n            int64_t eta_p_42941;\n            int64_t eta_p_4", "2942;\n            bool ltid_in_bounds_42944 = slt64(sext_i32_i64(local_tid_42900), num_virt_threads_42850);\n            int32_t skip_threads_42945;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_42944) {\n                    eta_p_42938 = ((volatile __local int64_t *) local_mem_42907)[sext_i32_i64(local_tid_42900)];\n                    if ((local_tid_42900 - squot32(local_tid_42900, 32) * 32) == 0) {\n                        eta_p_42937 = eta_p_42938;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_42945 = 1;\n                while (slt32(skip_threads_42945, 32)) {\n                    bool thread_active_42946 = sle32(skip_threads_42945, local_tid_42900 - squot32(local_tid_42900, 32) * 32) && ltid_in_bounds_42944;\n                    \n                    if (thread_active_42946) {\n                        // read operands\n                        {\n                            eta_p_42937 = ((volatile __local int64_t *) local_mem_42907)[sext_i32_i64(local_tid_42900) - sext_i32_i64(skip_threads_42945)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_42946) {\n                            int64_t defunc_0_op_res_42939 = add64(eta_p_42937, eta_p_42938);\n                            \n                            eta_p_42937 = defunc_0_op_res_42939;\n                        }\n                    }\n                    if (sle32(wave_sizze_42902, skip_threads_42945)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_42946) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_42907)[sext_i32_i64(local_tid_42900)] = eta_p_42937;\n                            eta_p_42938 = e",
                                    "ta_p_42937;\n                        }\n                    }\n                    if (sle32(wave_sizze_42902, skip_threads_42945)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_42945 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_42900 - squot32(local_tid_42900, 32) * 32) == 31 && ltid_in_bounds_42944) {\n                    ((volatile __local int64_t *) local_mem_42907)[sext_i32_i64(squot32(local_tid_42900, 32))] = eta_p_42937;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_42947;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_42900, 32) == 0 && ltid_in_bounds_42944) {\n                        eta_p_42942 = ((volatile __local int64_t *) local_mem_42907)[sext_i32_i64(local_tid_42900)];\n                        if ((local_tid_42900 - squot32(local_tid_42900, 32) * 32) == 0) {\n                            eta_p_42941 = eta_p_42942;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_42947 = 1;\n                    while (slt32(skip_threads_42947, 32)) {\n                        bool thread_active_42948 = sle32(skip_threads_42947, local_tid_42900 - squot32(local_tid_42900, 32) * 32) && (squot32(local_tid_42900, 32) == 0 && ltid_in_bounds_42944);\n                        \n                        if (thread_active_42948) {\n                            // read operands\n                            {\n                                eta_p_42941 = ((volatile __local int64_t *) local_mem_42907)[sext_i32_", "i64(local_tid_42900) - sext_i32_i64(skip_threads_42947)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_42948) {\n                                int64_t defunc_0_op_res_42943 = add64(eta_p_42941, eta_p_42942);\n                                \n                                eta_p_42941 = defunc_0_op_res_42943;\n                            }\n                        }\n                        if (sle32(wave_sizze_42902, skip_threads_42947)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_42948) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_42907)[sext_i32_i64(local_tid_42900)] = eta_p_42941;\n                                eta_p_42942 = eta_p_42941;\n                            }\n                        }\n                        if (sle32(wave_sizze_42902, skip_threads_42947)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_42947 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_42949 = squot32(local_tid_42900, 32) == 0 || !ltid_in_bounds_42944;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_42949) {\n                        eta_p_42938 = eta_p_42937;\n                        eta_p_42937 = ((__local int64_t *) local_mem_42907)[sext_i32_i64(squot32(local_tid_42900, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_42949) {\n                        int64_t defunc_0_op_res_42939 = add", "64(eta_p_42937, eta_p_42938);\n                        \n                        eta_p_42937 = defunc_0_op_res_42939;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_42949) {\n                        ((__local int64_t *) local_mem_42907)[sext_i32_i64(local_tid_42900)] = eta_p_42937;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_42900, 32) == 0 && ltid_in_bounds_42944) {\n                    ((__local int64_t *) local_mem_42907)[sext_i32_i64(local_tid_42900)] = eta_p_42938;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_42900 == 0) {\n                acc_42940 = ((__local int64_t *) local_mem_42907)[segscan_tblock_sizze_41334 - (int64_t) 1];\n            } else {\n                acc_42940 = ((__local int64_t *) local_mem_42907)[sext_i32_i64(local_tid_42900) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_42950 = (int64_t) 0;\n        block_new_sgm_42951 = sgm_idx_42919 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_42951 && local_tid_42900 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_42875)[dynamic_id_42917] = acc_42940;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_42851)[dynamic_id_42917] = (int8_t) 2;\n                acc_42940 = (int64_t) 0;\n            }\n            if (!block_new_sgm_42951 && slt32(local_tid_42900, wave_sizze_42902)) {\n                if (local_tid_42900 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_42873)[dynamic_id_42917] = acc_42940;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_f",
                                    "lags_mem_42851)[dynamic_id_42917] = (int8_t) 1;\n                    \n                    int8_t tmp_42952 = ((volatile __global int8_t *) status_flags_mem_42851)[dynamic_id_42917 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_42907)[(int64_t) 0] = tmp_42952;\n                }\n                mem_fence_local();\n                \n                int8_t status_42953 = ((__local int8_t *) local_mem_42907)[(int64_t) 0];\n                \n                if (status_42953 == (int8_t) 2) {\n                    if (local_tid_42900 == 0) {\n                        prefix_42950 = ((volatile __global int64_t *) incprefixes_mem_42875)[dynamic_id_42917 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_42954 = sext_i64_i32(dynamic_id_42917 - sext_i32_i64(wave_sizze_42902));\n                    \n                    while (slt32(wave_sizze_42902 * -1, readOffset_42954)) {\n                        int32_t read_i_42955 = readOffset_42954 + local_tid_42900;\n                        int64_t aggr_42956 = (int64_t) 0;\n                        int8_t flag_42957 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_42955)) {\n                            flag_42957 = ((volatile __global int8_t *) status_flags_mem_42851)[sext_i32_i64(read_i_42955)];\n                            if (flag_42957 == (int8_t) 2) {\n                                aggr_42956 = ((volatile __global int64_t *) incprefixes_mem_42875)[sext_i32_i64(read_i_42955)];\n                            } else if (flag_42957 == (int8_t) 1) {\n                                aggr_42956 = ((volatile __global int64_t *) aggregates_mem_42873)[sext_i32_i64(read_i_42955)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_42907)[(int64_t) 4 + sext_i32_i64(local_tid_42900)] = aggr_42956;\n                        ((__local int8_t *) local_mem_42907)[sext_i32_i64(lo", "cal_tid_42900)] = flag_42957;\n                        flag_42957 = ((__local int8_t *) local_mem_42907)[sext_i32_i64(wave_sizze_42902) - (int64_t) 1];\n                        if (slt8(flag_42957, (int8_t) 2)) {\n                            int8_t flg_x_42961;\n                            int8_t flg_y_42962;\n                            int64_t eta_p_42958;\n                            int64_t eta_p_42959;\n                            int32_t skip_threads_42963;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_42962 = ((volatile __local int8_t *) local_mem_42907)[sext_i32_i64(local_tid_42900)];\n                                eta_p_42959 = ((volatile __local int64_t *) local_mem_42907)[(int64_t) 4 + sext_i32_i64(local_tid_42900)];\n                                if ((local_tid_42900 - squot32(local_tid_42900, 32) * 32) == 0) {\n                                    eta_p_42958 = eta_p_42959;\n                                    flg_x_42961 = flg_y_42962;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_42963 = 1;\n                                while (slt32(skip_threads_42963, 32)) {\n                                    if (sle32(skip_threads_42963, local_tid_42900 - squot32(local_tid_42900, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_42961 = ((volatile __local int8_t *) local_mem_42907)[sext_i32_i64(local_tid_42900) - sext_i32_i64(skip_threads_42963)];\n                                            eta_p_42958 = ((volatile __local int64_t *) local_mem_42907)[(int64_t) 4 + (sext_i32_i64(local_tid_42900) - sext_i32_i64(skip_threads_42963))];\n                                        }\n             ", "                           // perform operation\n                                        {\n                                            if (flg_y_42962 == (int8_t) 2 || flg_y_42962 == (int8_t) 0) {\n                                                flg_x_42961 = flg_y_42962;\n                                                eta_p_42958 = eta_p_42959;\n                                            } else {\n                                                int64_t defunc_0_op_res_42960 = add64(eta_p_42958, eta_p_42959);\n                                                \n                                                eta_p_42958 = defunc_0_op_res_42960;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_42907)[sext_i32_i64(local_tid_42900)] = flg_x_42961;\n                                            flg_y_42962 = flg_x_42961;\n                                            ((volatile __local int64_t *) local_mem_42907)[(int64_t) 4 + sext_i32_i64(local_tid_42900)] = eta_p_42958;\n                                            eta_p_42959 = eta_p_42958;\n                                        }\n                                    }\n                                    skip_threads_42963 *= 2;\n                                }\n                            }\n                        }\n                        flag_42957 = ((__local int8_t *) local_mem_42907)[sext_i32_i64(wave_sizze_42902) - (int64_t) 1];\n                        aggr_42956 = ((__local int64_t *) local_mem_42907)[(int64_t) 4 + (sext_i32_i64(wave_sizze_42902) - (int64_t) 1)];\n                        if (flag_42957 == (int8_t) 2) {\n                            readOffset_42954 = wave_sizze_42902 * -1;\n                        } else if (flag_42957 == (int8_t) 1) {\n                            readOffset_42954 -= wave_sizze_4",
                                    "2902;\n                        }\n                        if (slt8((int8_t) 0, flag_42957)) {\n                            int64_t eta_p_42964 = aggr_42956;\n                            int64_t eta_p_42965 = prefix_42950;\n                            int64_t defunc_0_op_res_42966 = add64(eta_p_42964, eta_p_42965);\n                            \n                            prefix_42950 = defunc_0_op_res_42966;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_42900 == 0) {\n                    if (boundary_42920 == sext_i64_i32(segscan_tblock_sizze_41334 * chunk_sizze_42848)) {\n                        int64_t eta_p_42967 = prefix_42950;\n                        int64_t eta_p_42968 = acc_42940;\n                        int64_t defunc_0_op_res_42969 = add64(eta_p_42967, eta_p_42968);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_42875)[dynamic_id_42917] = defunc_0_op_res_42969;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_42851)[dynamic_id_42917] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_42907)[(int64_t) 4] = prefix_42950;\n                    acc_42940 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_42917 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_42950 = ((__local int64_t *) local_mem_42907)[(int64_t) 4];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_42970;\n            int64_t eta_p_42971;\n            int64_t eta_p_42973 = prefix_42950;\n            int64_t eta_p_42974 = acc_42940;\n            \n            if (slt32(local_tid_42900 * chunk_sizze_32b_42904, boundary_42920) && !block_new_sgm_42951) {\n                int64_t defunc_0_op_res_42975 = add64(eta_p_42973, eta_p", "_42974);\n                \n                eta_p_42970 = defunc_0_op_res_42975;\n            } else {\n                eta_p_42970 = acc_42940;\n            }\n            \n            int32_t stopping_point_42976 = segsizze_compact_42921 - srem32(local_tid_42900 * chunk_sizze_32b_42904 - 1 + segsizze_compact_42921 - boundary_42920, segsizze_compact_42921);\n            \n            for (int64_t i_42977 = 0; i_42977 < chunk_sizze_42848; i_42977++) {\n                if (slt32(sext_i64_i32(i_42977), stopping_point_42976 - 1)) {\n                    eta_p_42971 = private_mem_42922[i_42977];\n                    \n                    int64_t defunc_0_op_res_42972 = add64(eta_p_42970, eta_p_42971);\n                    \n                    private_mem_42922[i_42977] = defunc_0_op_res_42972;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_42978 = 0; i_42978 < chunk_sizze_42848; i_42978++) {\n                int64_t sharedIdx_42979 = sext_i32_i64(local_tid_42900) * chunk_sizze_42848 + i_42978;\n                int64_t tmp_42980 = private_mem_42922[i_42978];\n                \n                ((__local int64_t *) local_mem_42907)[sharedIdx_42979] = tmp_42980;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_42981 = 0; i_42981 < chunk_sizze_42848; i_42981++) {\n                int64_t flat_idx_42982 = thd_offset_42924 + i_42981 * segscan_tblock_sizze_41334;\n                int64_t slice_42983 = nR_34519;\n                int64_t gtid_41338 = flat_idx_42982;\n                int64_t remnant_42984 = flat_idx_42982 - gtid_41338;\n                \n                if (slt64(flat_idx_42982, nR_34519)) {\n                    int64_t tmp_42985 = ((__local int64_t *) local_mem_42907)[flat_idx_42982 - block_offset_42918];\n                    \n                    ((__global int64_t *) mem_42373)[gtid_41338] = tmp_42985;\n                }\n            }\n      ", "      barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_41334\n    #undef chunk_sizze_42848\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_doublezisegscan_41355_dim1, 1, 1)\nvoid inner_SMJ_doublezisegscan_41355(__global int *global_failure, int64_t m_39200, int64_t num_tblocks_41352, int64_t num_virt_blocks_43006, int64_t num_virt_threads_43007, __global unsigned char *mem_42377, __global unsigned char *mem_42387, __global unsigned char *mem_42389, __global unsigned char *mem_42391, __global unsigned char *status_flags_mem_43008, __global unsigned char *aggregates_mem_43010, __global unsigned char *incprefixes_mem_43012, __global unsigned char *aggregates_mem_43014, __global unsigned char *incprefixes_mem_43016, __global unsigned char *global_dynid_mem_43018)\n{\n    #define segscan_tblock_sizze_41350 (inner_SMJ_doublezisegscan_41355zisegscan_tblock_sizze_41350)\n    #define chunk_sizze_43005 (inner_SMJ_doublezisegscan_41355zichunk_sizze_43005)\n    \n    volatile __local unsigned char *local_mem_43030_backing_0 = &shared_mem[0];\n    const int64_t local_mem_43030_backing_0_offset = 0 + (smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_41350, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_41350), smax64(chunk_sizze_43005 * segscan_tblock_sizze_41350 * (int64_t) 8, chunk_sizze_43005 * segscan_tblock_sizze_41350 * (int64_t) 8)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_41350, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_41350), smax64(chunk_sizze_43005 * segscan_tblock_sizze_41350 * (int64_t) 8, chunk_sizze_43005 * segscan_tblock_sizze_41350 * (int64_t) 8)), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43021;\n    int32_t tblock_sizze_43024;\n    int32_t wave_sizze_43023;\n    int32_t block_id_43022;\n    int32_t global_tid_43020;\n    int64_t phys_tid_41355",
                                    ";\n    int32_t chunk_sizze_32b_43025;\n    int64_t byte_offsets_43026;\n    int64_t byte_offsets_43027;\n    int64_t warp_byte_offset_43028;\n    int64_t warp_byte_offset_43029;\n    __local unsigned char *local_mem_43030;\n    int64_t trans_arr_len_43031;\n    int64_t phys_block_id_43040;\n    int64_t virtloop_bound_43041;\n    \n    local_tid_43021 = get_local_id(0);\n    tblock_sizze_43024 = get_local_size(0);\n    wave_sizze_43023 = LOCKSTEP_WIDTH;\n    block_id_43022 = get_tblock_id(0);\n    global_tid_43020 = block_id_43022 * tblock_sizze_43024 + local_tid_43021;\n    phys_tid_41355 = sext_i32_i64(global_tid_43020);\n    chunk_sizze_32b_43025 = sext_i64_i32(chunk_sizze_43005);\n    byte_offsets_43026 = segscan_tblock_sizze_41350 * (int64_t) 8;\n    byte_offsets_43027 = sdiv_up64(byte_offsets_43026, (int64_t) 8) * (int64_t) 8 + segscan_tblock_sizze_41350 * (int64_t) 8;\n    warp_byte_offset_43028 = (int64_t) 288;\n    warp_byte_offset_43029 = sdiv_up64(warp_byte_offset_43028, (int64_t) 8) * (int64_t) 8 + (int64_t) 256;\n    // Allocate reusable shared memory\n    { }\n    local_mem_43030 = (__local unsigned char *) local_mem_43030_backing_0;\n    trans_arr_len_43031 = chunk_sizze_43005 * segscan_tblock_sizze_41350;\n    phys_block_id_43040 = get_tblock_id(0);\n    virtloop_bound_43041 = sdiv_up64(num_virt_blocks_43006 - phys_block_id_43040, num_tblocks_41352);\n    for (int64_t virtloop_i_43042 = 0; virtloop_i_43042 < virtloop_bound_43041; virtloop_i_43042++) {\n        int64_t dynamic_id_43043;\n        int64_t block_offset_43044;\n        int64_t sgm_idx_43045;\n        int32_t boundary_43046;\n        int32_t segsizze_compact_43047;\n        int64_t private_mem_43048[chunk_sizze_43005];\n        int64_t private_mem_43050[chunk_sizze_43005];\n        int64_t thd_offset_43052;\n        int64_t acc_43078;\n        int64_t acc_43079;\n        int64_t prefix_43092;\n        int64_t prefix_43093;\n        bool block_new_sgm_43094;\n        \n        // First thread in block fetches this block's dynamic_id\n", "        {\n            if (local_tid_43021 == 0) {\n                dynamic_id_43043 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_43018)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_43030)[(int64_t) 0] = dynamic_id_43043;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_43043 == num_virt_blocks_43006 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_43018)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_43043 = ((__local int32_t *) local_mem_43030)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_43044 = dynamic_id_43043 * chunk_sizze_43005 * segscan_tblock_sizze_41350;\n        sgm_idx_43045 = smod64(block_offset_43044, m_39200);\n        boundary_43046 = sext_i64_i32(smin64(chunk_sizze_43005 * segscan_tblock_sizze_41350, m_39200 - sgm_idx_43045));\n        segsizze_compact_43047 = sext_i64_i32(smin64(chunk_sizze_43005 * segscan_tblock_sizze_41350, m_39200));\n        thd_offset_43052 = block_offset_43044 + sext_i32_i64(local_tid_43021);\n        // Load and map\n        {\n            for (int64_t i_43053 = 0; i_43053 < chunk_sizze_43005; i_43053++) {\n                int64_t virt_tid_43054 = thd_offset_43052 + i_43053 * segscan_tblock_sizze_41350;\n                int64_t slice_43055 = m_39200;\n                int64_t gtid_41354 = virt_tid_43054;\n                int64_t remnant_43056 = virt_tid_43054 - gtid_41354;\n                \n                if (slt64(virt_tid_43054, m_39200)) {\n                    int64_t x_39463 = ((__global int64_t *) mem_42377)[gtid_41354];\n                    bool lifted_lambda_res_39465 = slt64((int64_t) 1, x_39463);\n                    int64_t defunc_0_f_res_39466 = btoi_bool_i64(lif", "ted_lambda_res_39465);\n                    \n                    ((__global int64_t *) mem_42391)[gtid_41354] = defunc_0_f_res_39466;\n                    private_mem_43048[i_43053] = x_39463;\n                    private_mem_43050[i_43053] = defunc_0_f_res_39466;\n                } else {\n                    private_mem_43048[i_43053] = (int64_t) 0;\n                    private_mem_43050[i_43053] = (int64_t) 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_43057 = 0; i_43057 < chunk_sizze_43005; i_43057++) {\n                int64_t sharedIdx_43058 = sext_i32_i64(local_tid_43021) + i_43057 * segscan_tblock_sizze_41350;\n                int64_t tmp_43059 = private_mem_43048[i_43057];\n                \n                ((__local int64_t *) local_mem_43030)[sharedIdx_43058] = tmp_43059;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_43060 = 0; i_43060 < chunk_sizze_43005; i_43060++) {\n                int64_t sharedIdx_43061 = sext_i32_i64(local_tid_43021) * chunk_sizze_43005 + i_43060;\n                int64_t tmp_43062 = ((__local int64_t *) local_mem_43030)[sharedIdx_43061];\n                \n                private_mem_43048[i_43060] = tmp_43062;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_43063 = 0; i_43063 < chunk_sizze_43005; i_43063++) {\n                int64_t sharedIdx_43064 = sext_i32_i64(local_tid_43021) + i_43063 * segscan_tblock_sizze_41350;\n                int64_t tmp_43065 = private_mem_43050[i_43063];\n                \n                ((__local int64_t *) local_mem_43030)[sharedIdx_43064] = tmp_43065;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_43066 = 0; i_43066 < chunk_sizze_43005; i_43066++) {\n                int64_t sharedIdx_43067 = sext_i32_i64(local_tid_43021) * chunk_sizze_43005 + i_43066;\n                int64_t tmp_43068 = ((__local int64_t",
                                    " *) local_mem_43030)[sharedIdx_43067];\n                \n                private_mem_43050[i_43066] = tmp_43068;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_43069 = 0; i_43069 < chunk_sizze_43005 - (int64_t) 1; i_43069++) {\n                int64_t eta_p_39237;\n                int64_t eta_p_39238;\n                \n                eta_p_39237 = private_mem_43048[i_43069];\n                eta_p_39238 = private_mem_43048[i_43069 + (int64_t) 1];\n                \n                int64_t eta_p_39330;\n                int64_t eta_p_39331;\n                \n                eta_p_39330 = private_mem_43050[i_43069];\n                eta_p_39331 = private_mem_43050[i_43069 + (int64_t) 1];\n                \n                int64_t lifted_lambda_res_39239 = add64(eta_p_39237, eta_p_39238);\n                int64_t defunc_0_op_res_39332 = add64(eta_p_39330, eta_p_39331);\n                \n                private_mem_43048[i_43069 + (int64_t) 1] = lifted_lambda_res_39239;\n                private_mem_43050[i_43069 + (int64_t) 1] = defunc_0_op_res_39332;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_43070 = private_mem_43048[chunk_sizze_43005 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_43030)[sext_i32_i64(local_tid_43021)] = tmp_43070;\n            \n            int64_t tmp_43071 = private_mem_43050[chunk_sizze_43005 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + sext_i32_i64(local_tid_43021)] = tmp_43071;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_43072;\n            int64_t eta_p_43073;\n            int64_t eta_p_43074;\n            int64_t eta_p_43075;\n            int64_t eta_p_43080;\n            int64_t eta_p_43081;\n            int64_t eta_p_43082;\n            int64_", "t eta_p_43083;\n            bool ltid_in_bounds_43086 = slt64(sext_i32_i64(local_tid_43021), num_virt_threads_43007);\n            int32_t skip_threads_43087;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_43086) {\n                    eta_p_43074 = ((volatile __local int64_t *) local_mem_43030)[sext_i32_i64(local_tid_43021)];\n                    eta_p_43075 = ((volatile __local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + sext_i32_i64(local_tid_43021)];\n                    if ((local_tid_43021 - squot32(local_tid_43021, 32) * 32) == 0) {\n                        eta_p_43072 = eta_p_43074;\n                        eta_p_43073 = eta_p_43075;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_43087 = 1;\n                while (slt32(skip_threads_43087, 32)) {\n                    bool thread_active_43088 = sle32(skip_threads_43087, local_tid_43021 - squot32(local_tid_43021, 32) * 32) && ltid_in_bounds_43086;\n                    \n                    if (thread_active_43088) {\n                        // read operands\n                        {\n                            eta_p_43072 = ((volatile __local int64_t *) local_mem_43030)[sext_i32_i64(local_tid_43021) - sext_i32_i64(skip_threads_43087)];\n                            eta_p_43073 = ((volatile __local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + (sext_i32_i64(local_tid_43021) - sext_i32_i64(skip_threads_43087))];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_43088) {\n                            int64_t lifted_lambda_res_43076 = add64(eta_p_43072, eta_p_43074);\n                            int64_t defunc_0_op_res_43077 = add64(eta_p_43073, eta_p_43075);\n                            \n                         ", "   eta_p_43072 = lifted_lambda_res_43076;\n                            eta_p_43073 = defunc_0_op_res_43077;\n                        }\n                    }\n                    if (sle32(wave_sizze_43023, skip_threads_43087)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_43088) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_43030)[sext_i32_i64(local_tid_43021)] = eta_p_43072;\n                            eta_p_43074 = eta_p_43072;\n                            ((volatile __local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + sext_i32_i64(local_tid_43021)] = eta_p_43073;\n                            eta_p_43075 = eta_p_43073;\n                        }\n                    }\n                    if (sle32(wave_sizze_43023, skip_threads_43087)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_43087 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_43021 - squot32(local_tid_43021, 32) * 32) == 31 && ltid_in_bounds_43086) {\n                    ((volatile __local int64_t *) local_mem_43030)[sext_i32_i64(squot32(local_tid_43021, 32))] = eta_p_43072;\n                    ((volatile __local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + sext_i32_i64(squot32(local_tid_43021, 32))] = eta_p_43073;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_43089;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_43021, 32) == 0 && ltid_in_bounds_430",
                                    "86) {\n                        eta_p_43082 = ((volatile __local int64_t *) local_mem_43030)[sext_i32_i64(local_tid_43021)];\n                        eta_p_43083 = ((volatile __local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + sext_i32_i64(local_tid_43021)];\n                        if ((local_tid_43021 - squot32(local_tid_43021, 32) * 32) == 0) {\n                            eta_p_43080 = eta_p_43082;\n                            eta_p_43081 = eta_p_43083;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_43089 = 1;\n                    while (slt32(skip_threads_43089, 32)) {\n                        bool thread_active_43090 = sle32(skip_threads_43089, local_tid_43021 - squot32(local_tid_43021, 32) * 32) && (squot32(local_tid_43021, 32) == 0 && ltid_in_bounds_43086);\n                        \n                        if (thread_active_43090) {\n                            // read operands\n                            {\n                                eta_p_43080 = ((volatile __local int64_t *) local_mem_43030)[sext_i32_i64(local_tid_43021) - sext_i32_i64(skip_threads_43089)];\n                                eta_p_43081 = ((volatile __local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + (sext_i32_i64(local_tid_43021) - sext_i32_i64(skip_threads_43089))];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_43090) {\n                                int64_t lifted_lambda_res_43084 = add64(eta_p_43080, eta_p_43082);\n                                int64_t defunc_0_op_res_43085 = add64(eta_p_43081, eta_p_43083);\n                                \n                                eta_p_43080 = lifted_lambda_res_43084;\n                                eta_p_43081 = defunc_0_op_res_43085;\n    ", "                        }\n                        }\n                        if (sle32(wave_sizze_43023, skip_threads_43089)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_43090) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_43030)[sext_i32_i64(local_tid_43021)] = eta_p_43080;\n                                eta_p_43082 = eta_p_43080;\n                                ((volatile __local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + sext_i32_i64(local_tid_43021)] = eta_p_43081;\n                                eta_p_43083 = eta_p_43081;\n                            }\n                        }\n                        if (sle32(wave_sizze_43023, skip_threads_43089)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_43089 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_43091 = squot32(local_tid_43021, 32) == 0 || !ltid_in_bounds_43086;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_43091) {\n                        eta_p_43074 = eta_p_43072;\n                        eta_p_43075 = eta_p_43073;\n                        eta_p_43072 = ((__local int64_t *) local_mem_43030)[sext_i32_i64(squot32(local_tid_43021, 32)) - (int64_t) 1];\n                        eta_p_43073 = ((__local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + (sext_i32_i64(squot32(local_tid_43021, 32)) - (int64_t) 1)];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_43091) {\n                        int64_t lifted_lambd", "a_res_43076 = add64(eta_p_43072, eta_p_43074);\n                        int64_t defunc_0_op_res_43077 = add64(eta_p_43073, eta_p_43075);\n                        \n                        eta_p_43072 = lifted_lambda_res_43076;\n                        eta_p_43073 = defunc_0_op_res_43077;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_43091) {\n                        ((__local int64_t *) local_mem_43030)[sext_i32_i64(local_tid_43021)] = eta_p_43072;\n                        ((__local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + sext_i32_i64(local_tid_43021)] = eta_p_43073;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_43021, 32) == 0 && ltid_in_bounds_43086) {\n                    ((__local int64_t *) local_mem_43030)[sext_i32_i64(local_tid_43021)] = eta_p_43074;\n                    ((__local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + sext_i32_i64(local_tid_43021)] = eta_p_43075;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_43021 == 0) {\n                acc_43078 = ((__local int64_t *) local_mem_43030)[segscan_tblock_sizze_41350 - (int64_t) 1];\n                acc_43079 = ((__local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + (segscan_tblock_sizze_41350 - (int64_t) 1)];\n            } else {\n                acc_43078 = ((__local int64_t *) local_mem_43030)[sext_i32_i64(local_tid_43021) - (int64_t) 1];\n                acc_43079 = ((__local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + (sext_i32_i64(local_tid_43021) - (int64_t) 1)];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_43092 = (int64_t) 0;\n       ",
                                    " prefix_43093 = (int64_t) 0;\n        block_new_sgm_43094 = sgm_idx_43045 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_43094 && local_tid_43021 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_43012)[dynamic_id_43043] = acc_43078;\n                ((volatile __global int64_t *) incprefixes_mem_43016)[dynamic_id_43043] = acc_43079;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_43008)[dynamic_id_43043] = (int8_t) 2;\n                acc_43078 = (int64_t) 0;\n                acc_43079 = (int64_t) 0;\n            }\n            if (!block_new_sgm_43094 && slt32(local_tid_43021, wave_sizze_43023)) {\n                if (local_tid_43021 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_43010)[dynamic_id_43043] = acc_43078;\n                    ((volatile __global int64_t *) aggregates_mem_43014)[dynamic_id_43043] = acc_43079;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_43008)[dynamic_id_43043] = (int8_t) 1;\n                    \n                    int8_t tmp_43095 = ((volatile __global int8_t *) status_flags_mem_43008)[dynamic_id_43043 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_43030)[(int64_t) 0] = tmp_43095;\n                }\n                mem_fence_local();\n                \n                int8_t status_43096 = ((__local int8_t *) local_mem_43030)[(int64_t) 0];\n                \n                if (status_43096 == (int8_t) 2) {\n                    if (local_tid_43021 == 0) {\n                        prefix_43092 = ((volatile __global int64_t *) incprefixes_mem_43012)[dynamic_id_43043 - (int64_t) 1];\n                        prefix_43093 = ((volatile __global int64_t *) incprefixes_mem_43016)[dynamic_id_43043 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_43097 = sext_i64_i32", "(dynamic_id_43043 - sext_i32_i64(wave_sizze_43023));\n                    \n                    while (slt32(wave_sizze_43023 * -1, readOffset_43097)) {\n                        int32_t read_i_43098 = readOffset_43097 + local_tid_43021;\n                        int64_t aggr_43099 = (int64_t) 0;\n                        int64_t aggr_43100 = (int64_t) 0;\n                        int8_t flag_43101 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_43098)) {\n                            flag_43101 = ((volatile __global int8_t *) status_flags_mem_43008)[sext_i32_i64(read_i_43098)];\n                            if (flag_43101 == (int8_t) 2) {\n                                aggr_43099 = ((volatile __global int64_t *) incprefixes_mem_43012)[sext_i32_i64(read_i_43098)];\n                                aggr_43100 = ((volatile __global int64_t *) incprefixes_mem_43016)[sext_i32_i64(read_i_43098)];\n                            } else if (flag_43101 == (int8_t) 1) {\n                                aggr_43099 = ((volatile __global int64_t *) aggregates_mem_43010)[sext_i32_i64(read_i_43098)];\n                                aggr_43100 = ((volatile __global int64_t *) aggregates_mem_43014)[sext_i32_i64(read_i_43098)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_43030)[(int64_t) 4 + sext_i32_i64(local_tid_43021)] = aggr_43099;\n                        ((__local int64_t *) local_mem_43030)[squot64(warp_byte_offset_43028, (int64_t) 8) + sext_i32_i64(local_tid_43021)] = aggr_43100;\n                        ((__local int8_t *) local_mem_43030)[sext_i32_i64(local_tid_43021)] = flag_43101;\n                        flag_43101 = ((__local int8_t *) local_mem_43030)[sext_i32_i64(wave_sizze_43023) - (int64_t) 1];\n                        if (slt8(flag_43101, (int8_t) 2)) {\n                            int8_t flg_x_43108;\n                            int8_t flg_y_43109;\n                            int64_t eta_", "p_43102;\n                            int64_t eta_p_43103;\n                            int64_t eta_p_43104;\n                            int64_t eta_p_43105;\n                            int32_t skip_threads_43110;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_43109 = ((volatile __local int8_t *) local_mem_43030)[sext_i32_i64(local_tid_43021)];\n                                eta_p_43104 = ((volatile __local int64_t *) local_mem_43030)[(int64_t) 4 + sext_i32_i64(local_tid_43021)];\n                                eta_p_43105 = ((volatile __local int64_t *) local_mem_43030)[squot64(warp_byte_offset_43028, (int64_t) 8) + sext_i32_i64(local_tid_43021)];\n                                if ((local_tid_43021 - squot32(local_tid_43021, 32) * 32) == 0) {\n                                    eta_p_43102 = eta_p_43104;\n                                    eta_p_43103 = eta_p_43105;\n                                    flg_x_43108 = flg_y_43109;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_43110 = 1;\n                                while (slt32(skip_threads_43110, 32)) {\n                                    if (sle32(skip_threads_43110, local_tid_43021 - squot32(local_tid_43021, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_43108 = ((volatile __local int8_t *) local_mem_43030)[sext_i32_i64(local_tid_43021) - sext_i32_i64(skip_threads_43110)];\n                                            eta_p_43102 = ((volatile __local int64_t *) local_mem_43030)[(int64_t) 4 + (sext_i32_i64(local_tid_43021) - sext_i32_i64(skip_threads_43110))];\n                                            eta_p_43103 = ((volatile ",
                                    "__local int64_t *) local_mem_43030)[squot64(warp_byte_offset_43028, (int64_t) 8) + (sext_i32_i64(local_tid_43021) - sext_i32_i64(skip_threads_43110))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_43109 == (int8_t) 2 || flg_y_43109 == (int8_t) 0) {\n                                                flg_x_43108 = flg_y_43109;\n                                                eta_p_43102 = eta_p_43104;\n                                                eta_p_43103 = eta_p_43105;\n                                            } else {\n                                                int64_t lifted_lambda_res_43106 = add64(eta_p_43102, eta_p_43104);\n                                                int64_t defunc_0_op_res_43107 = add64(eta_p_43103, eta_p_43105);\n                                                \n                                                eta_p_43102 = lifted_lambda_res_43106;\n                                                eta_p_43103 = defunc_0_op_res_43107;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_43030)[sext_i32_i64(local_tid_43021)] = flg_x_43108;\n                                            flg_y_43109 = flg_x_43108;\n                                            ((volatile __local int64_t *) local_mem_43030)[(int64_t) 4 + sext_i32_i64(local_tid_43021)] = eta_p_43102;\n                                            eta_p_43104 = eta_p_43102;\n                                            ((volatile __local int64_t *) local_mem_43030)[squot64(warp_byte_offset_43028, (int64_t) 8) + sext_i32_i64(local_tid_43021)] = eta_p_43103;\n                                            eta_p_43105 = eta_p_43103;\n", "                                        }\n                                    }\n                                    skip_threads_43110 *= 2;\n                                }\n                            }\n                        }\n                        flag_43101 = ((__local int8_t *) local_mem_43030)[sext_i32_i64(wave_sizze_43023) - (int64_t) 1];\n                        aggr_43099 = ((__local int64_t *) local_mem_43030)[(int64_t) 4 + (sext_i32_i64(wave_sizze_43023) - (int64_t) 1)];\n                        aggr_43100 = ((__local int64_t *) local_mem_43030)[squot64(warp_byte_offset_43028, (int64_t) 8) + (sext_i32_i64(wave_sizze_43023) - (int64_t) 1)];\n                        if (flag_43101 == (int8_t) 2) {\n                            readOffset_43097 = wave_sizze_43023 * -1;\n                        } else if (flag_43101 == (int8_t) 1) {\n                            readOffset_43097 -= wave_sizze_43023;\n                        }\n                        if (slt8((int8_t) 0, flag_43101)) {\n                            int64_t eta_p_43111 = aggr_43099;\n                            int64_t eta_p_43112 = aggr_43100;\n                            int64_t eta_p_43113 = prefix_43092;\n                            int64_t eta_p_43114 = prefix_43093;\n                            int64_t lifted_lambda_res_43115 = add64(eta_p_43111, eta_p_43113);\n                            int64_t defunc_0_op_res_43116 = add64(eta_p_43112, eta_p_43114);\n                            \n                            prefix_43092 = lifted_lambda_res_43115;\n                            prefix_43093 = defunc_0_op_res_43116;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_43021 == 0) {\n                    if (boundary_43046 == sext_i64_i32(segscan_tblock_sizze_41350 * chunk_sizze_43005)) {\n                        int64_t eta_p_43117 = prefix_43092;\n                        int64_t eta_p_43118 = prefix_43093;\n                ", "        int64_t eta_p_43119 = acc_43078;\n                        int64_t eta_p_43120 = acc_43079;\n                        int64_t lifted_lambda_res_43121 = add64(eta_p_43117, eta_p_43119);\n                        int64_t defunc_0_op_res_43122 = add64(eta_p_43118, eta_p_43120);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_43012)[dynamic_id_43043] = lifted_lambda_res_43121;\n                        ((volatile __global int64_t *) incprefixes_mem_43016)[dynamic_id_43043] = defunc_0_op_res_43122;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_43008)[dynamic_id_43043] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_43030)[(int64_t) 4] = prefix_43092;\n                    ((__local int64_t *) local_mem_43030)[squot64(warp_byte_offset_43028, (int64_t) 8)] = prefix_43093;\n                    acc_43078 = (int64_t) 0;\n                    acc_43079 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_43043 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_43092 = ((__local int64_t *) local_mem_43030)[(int64_t) 4];\n                prefix_43093 = ((__local int64_t *) local_mem_43030)[squot64(warp_byte_offset_43028, (int64_t) 8)];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_43123;\n            int64_t eta_p_43125;\n            int64_t eta_p_43129 = prefix_43092;\n            int64_t eta_p_43131 = acc_43078;\n            int64_t eta_p_43124;\n            int64_t eta_p_43126;\n            int64_t eta_p_43130 = prefix_43093;\n            int64_t eta_p_43132 = acc_43079;\n            \n            if (slt32(local_tid_43021 * chunk_sizze_32b_43025, boundary_43046) && !block_new_sgm_43094) {\n                int64_t lifted_lambda_res_43133 = add64(eta_p_43129, eta_p_43131);\n                int",
                                    "64_t defunc_0_op_res_43134 = add64(eta_p_43130, eta_p_43132);\n                \n                eta_p_43123 = lifted_lambda_res_43133;\n                eta_p_43124 = defunc_0_op_res_43134;\n            } else {\n                eta_p_43123 = acc_43078;\n                eta_p_43124 = acc_43079;\n            }\n            \n            int32_t stopping_point_43135 = segsizze_compact_43047 - srem32(local_tid_43021 * chunk_sizze_32b_43025 - 1 + segsizze_compact_43047 - boundary_43046, segsizze_compact_43047);\n            \n            for (int64_t i_43136 = 0; i_43136 < chunk_sizze_43005; i_43136++) {\n                if (slt32(sext_i64_i32(i_43136), stopping_point_43135 - 1)) {\n                    eta_p_43125 = private_mem_43048[i_43136];\n                    eta_p_43126 = private_mem_43050[i_43136];\n                    \n                    int64_t lifted_lambda_res_43127 = add64(eta_p_43123, eta_p_43125);\n                    int64_t defunc_0_op_res_43128 = add64(eta_p_43124, eta_p_43126);\n                    \n                    private_mem_43048[i_43136] = lifted_lambda_res_43127;\n                    private_mem_43050[i_43136] = defunc_0_op_res_43128;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_43137 = 0; i_43137 < chunk_sizze_43005; i_43137++) {\n                int64_t sharedIdx_43138 = sext_i32_i64(local_tid_43021) * chunk_sizze_43005 + i_43137;\n                int64_t tmp_43139 = private_mem_43048[i_43137];\n                \n                ((__local int64_t *) local_mem_43030)[sharedIdx_43138] = tmp_43139;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_43140 = 0; i_43140 < chunk_sizze_43005; i_43140++) {\n                int64_t flat_idx_43141 = thd_offset_43052 + i_43140 * segscan_tblock_sizze_41350;\n                int64_t slice_43142 = m_39200;\n                int64_t gtid_41354 = flat_idx_43141;\n                int64_t", " remnant_43143 = flat_idx_43141 - gtid_41354;\n                \n                if (slt64(flat_idx_43141, m_39200)) {\n                    int64_t tmp_43144 = ((__local int64_t *) local_mem_43030)[flat_idx_43141 - block_offset_43044];\n                    \n                    ((__global int64_t *) mem_42387)[gtid_41354] = tmp_43144;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_43145 = 0; i_43145 < chunk_sizze_43005; i_43145++) {\n                int64_t sharedIdx_43146 = sext_i32_i64(local_tid_43021) * chunk_sizze_43005 + i_43145;\n                int64_t tmp_43147 = private_mem_43050[i_43145];\n                \n                ((__local int64_t *) local_mem_43030)[sharedIdx_43146] = tmp_43147;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_43148 = 0; i_43148 < chunk_sizze_43005; i_43148++) {\n                int64_t flat_idx_43149 = thd_offset_43052 + i_43148 * segscan_tblock_sizze_41350;\n                int64_t slice_43150 = m_39200;\n                int64_t gtid_41354 = flat_idx_43149;\n                int64_t remnant_43151 = flat_idx_43149 - gtid_41354;\n                \n                if (slt64(flat_idx_43149, m_39200)) {\n                    int64_t tmp_43152 = ((__local int64_t *) local_mem_43030)[flat_idx_43149 - block_offset_43044];\n                    \n                    ((__global int64_t *) mem_42389)[gtid_41354] = tmp_43152;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_41350\n    #undef chunk_sizze_43005\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_floatzigpuseq_42730_dim1, 1, 1)\nvoid inner_SMJ_floatzigpuseq_42730(__global int *global_failure, __global unsigned char *tS_mem_42200, __global unsigned char *mem_42207)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42732;\n    int32_t tblock_sizze_42735;\n    int32_t wave_sizze_42734;\n    int32_t block_id_4273", "3;\n    int32_t global_tid_42731;\n    int64_t tid_42730;\n    float x_42152;\n    \n    local_tid_42732 = get_local_id(0);\n    tblock_sizze_42735 = get_local_size(0);\n    wave_sizze_42734 = LOCKSTEP_WIDTH;\n    block_id_42733 = get_tblock_id(0);\n    global_tid_42731 = block_id_42733 * tblock_sizze_42735 + local_tid_42732;\n    tid_42730 = sext_i32_i64(global_tid_42731);\n    x_42152 = ((__global float *) tS_mem_42200)[(int64_t) 0];\n    ((__global float *) mem_42207)[(int64_t) 0] = x_42152;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_floatzigpuseq_42756_dim1, 1, 1)\nvoid inner_SMJ_floatzigpuseq_42756(__global int *global_failure, int64_t tmp_39078, __global unsigned char *tS_mem_42200, __global unsigned char *mem_42210)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42758;\n    int32_t tblock_sizze_42761;\n    int32_t wave_sizze_42760;\n    int32_t block_id_42759;\n    int32_t global_tid_42757;\n    int64_t tid_42756;\n    float x_42156;\n    \n    local_tid_42758 = get_local_id(0);\n    tblock_sizze_42761 = get_local_size(0);\n    wave_sizze_42760 = LOCKSTEP_WIDTH;\n    block_id_42759 = get_tblock_id(0);\n    global_tid_42757 = block_id_42759 * tblock_sizze_42761 + local_tid_42758;\n    tid_42756 = sext_i32_i64(global_tid_42757);\n    x_42156 = ((__global float *) tS_mem_42200)[tmp_39078];\n    ((__global float *) mem_42210)[(int64_t) 0] = x_42156;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_floatzigpuseq_42772_dim1, 1, 1)\nvoid inner_SMJ_floatzigpuseq_42772(__global int *global_failure, int64_t start_39100, int64_t i_p_m_t_s_39106, __global unsigned char *tR_mem_42199, __global unsigned char *mem_42218, __global unsigned char *mem_42219)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42774;\n    int32_t tblock_sizze_42777;\n    int32_t wave_sizze_42776;\n    int32_t block_id_42775;\n    int32_t global_tid_42773;\n    int64_t tid_42772;\n    float r_max_42160;\n    float r_min_42163;\n    \n    local_tid_42774",
                                    " = get_local_id(0);\n    tblock_sizze_42777 = get_local_size(0);\n    wave_sizze_42776 = LOCKSTEP_WIDTH;\n    block_id_42775 = get_tblock_id(0);\n    global_tid_42773 = block_id_42775 * tblock_sizze_42777 + local_tid_42774;\n    tid_42772 = sext_i32_i64(global_tid_42773);\n    r_max_42160 = ((__global float *) tR_mem_42199)[i_p_m_t_s_39106];\n    r_min_42163 = ((__global float *) tR_mem_42199)[start_39100];\n    ((__global float *) mem_42218)[(int64_t) 0] = r_max_42160;\n    ((__global float *) mem_42219)[(int64_t) 0] = r_min_42163;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_floatzigpuseq_42778_dim1, 1, 1)\nvoid inner_SMJ_floatzigpuseq_42778(__global int *global_failure, __global unsigned char *mem_42219, __global unsigned char *ext_mem_42220, __global unsigned char *mem_42222)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42780;\n    int32_t tblock_sizze_42783;\n    int32_t wave_sizze_42782;\n    int32_t block_id_42781;\n    int32_t global_tid_42779;\n    int64_t tid_42778;\n    float s_max_42165;\n    float r_min_42166;\n    bool defunc_0_gt_res_42167;\n    \n    local_tid_42780 = get_local_id(0);\n    tblock_sizze_42783 = get_local_size(0);\n    wave_sizze_42782 = LOCKSTEP_WIDTH;\n    block_id_42781 = get_tblock_id(0);\n    global_tid_42779 = block_id_42781 * tblock_sizze_42783 + local_tid_42780;\n    tid_42778 = sext_i32_i64(global_tid_42779);\n    s_max_42165 = ((__global float *) ext_mem_42220)[(int64_t) 0];\n    r_min_42166 = ((__global float *) mem_42219)[(int64_t) 0];\n    defunc_0_gt_res_42167 = s_max_42165 < r_min_42166;\n    ((__global bool *) mem_42222)[(int64_t) 0] = defunc_0_gt_res_42167;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_floatzigpuseq_42784_dim1, 1, 1)\nvoid inner_SMJ_floatzigpuseq_42784(__global int *global_failure, __global unsigned char *mem_42218, __global unsigned char *ext_mem_42221, __global unsigned char *mem_42223)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42786;\n  ", "  int32_t tblock_sizze_42789;\n    int32_t wave_sizze_42788;\n    int32_t block_id_42787;\n    int32_t global_tid_42785;\n    int64_t tid_42784;\n    float r_max_42170;\n    float s_min_42171;\n    bool defunc_0_gt_res_42172;\n    \n    local_tid_42786 = get_local_id(0);\n    tblock_sizze_42789 = get_local_size(0);\n    wave_sizze_42788 = LOCKSTEP_WIDTH;\n    block_id_42787 = get_tblock_id(0);\n    global_tid_42785 = block_id_42787 * tblock_sizze_42789 + local_tid_42786;\n    tid_42784 = sext_i32_i64(global_tid_42785);\n    r_max_42170 = ((__global float *) mem_42218)[(int64_t) 0];\n    s_min_42171 = ((__global float *) ext_mem_42221)[(int64_t) 0];\n    defunc_0_gt_res_42172 = r_max_42170 < s_min_42171;\n    ((__global bool *) mem_42223)[(int64_t) 0] = defunc_0_gt_res_42172;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_floatzigpuseq_43162_dim1, 1, 1)\nvoid inner_SMJ_floatzigpuseq_43162(__global int *global_failure, int64_t m_39210, __global unsigned char *mem_42394, __global unsigned char *mem_42396)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43164;\n    int32_t tblock_sizze_43167;\n    int32_t wave_sizze_43166;\n    int32_t block_id_43165;\n    int32_t global_tid_43163;\n    int64_t tid_43162;\n    int64_t x_42174;\n    \n    local_tid_43164 = get_local_id(0);\n    tblock_sizze_43167 = get_local_size(0);\n    wave_sizze_43166 = LOCKSTEP_WIDTH;\n    block_id_43165 = get_tblock_id(0);\n    global_tid_43163 = block_id_43165 * tblock_sizze_43167 + local_tid_43164;\n    tid_43162 = sext_i32_i64(global_tid_43163);\n    x_42174 = ((__global int64_t *) mem_42394)[m_39210];\n    ((__global int64_t *) mem_42396)[(int64_t) 0] = x_42174;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_floatzigpuseq_43168_dim1, 1, 1)\nvoid inner_SMJ_floatzigpuseq_43168(__global int *global_failure, int64_t m_39210, __global unsigned char *mem_42377, __global unsigned char *mem_42399)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43170;\n    ", "int32_t tblock_sizze_43173;\n    int32_t wave_sizze_43172;\n    int32_t block_id_43171;\n    int32_t global_tid_43169;\n    int64_t tid_43168;\n    int64_t x_42178;\n    \n    local_tid_43170 = get_local_id(0);\n    tblock_sizze_43173 = get_local_size(0);\n    wave_sizze_43172 = LOCKSTEP_WIDTH;\n    block_id_43171 = get_tblock_id(0);\n    global_tid_43169 = block_id_43171 * tblock_sizze_43173 + local_tid_43170;\n    tid_43168 = sext_i32_i64(global_tid_43169);\n    x_42178 = ((__global int64_t *) mem_42377)[m_39210];\n    ((__global int64_t *) mem_42399)[(int64_t) 0] = x_42178;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_floatzigpuseq_43174_dim1, 1, 1)\nvoid inner_SMJ_floatzigpuseq_43174(__global int *global_failure, __global unsigned char *ext_mem_42397, __global unsigned char *ext_mem_42400, __global unsigned char *mem_42406)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43176;\n    int32_t tblock_sizze_43179;\n    int32_t wave_sizze_43178;\n    int32_t block_id_43177;\n    int32_t global_tid_43175;\n    int64_t tid_43174;\n    int64_t zp_lhs_42182;\n    int64_t n_pairs_t_res_42183;\n    int64_t n_pairs_t_res_42184;\n    \n    local_tid_43176 = get_local_id(0);\n    tblock_sizze_43179 = get_local_size(0);\n    wave_sizze_43178 = LOCKSTEP_WIDTH;\n    block_id_43177 = get_tblock_id(0);\n    global_tid_43175 = block_id_43177 * tblock_sizze_43179 + local_tid_43176;\n    tid_43174 = sext_i32_i64(global_tid_43175);\n    zp_lhs_42182 = ((__global int64_t *) ext_mem_42397)[(int64_t) 0];\n    n_pairs_t_res_42183 = ((__global int64_t *) ext_mem_42400)[(int64_t) 0];\n    n_pairs_t_res_42184 = add64(zp_lhs_42182, n_pairs_t_res_42183);\n    ((__global int64_t *) mem_42406)[(int64_t) 0] = n_pairs_t_res_42184;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_floatzigpuseq_43221_dim1, 1, 1)\nvoid inner_SMJ_floatzigpuseq_43221(__global int *global_failure, int64_t loopres_39384, __global unsigned char *mem_param_42440, __global unsigned char *mem_param_42443,",
                                    " __global unsigned char *mem_param_42446, __global unsigned char *mem_42453, __global unsigned char *mem_42454, __global unsigned char *mem_42455)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43223;\n    int32_t tblock_sizze_43226;\n    int32_t wave_sizze_43225;\n    int32_t block_id_43224;\n    int32_t global_tid_43222;\n    int64_t tid_43221;\n    float loopres_42186;\n    int64_t loopres_42188;\n    int64_t loopres_42190;\n    \n    local_tid_43223 = get_local_id(0);\n    tblock_sizze_43226 = get_local_size(0);\n    wave_sizze_43225 = LOCKSTEP_WIDTH;\n    block_id_43224 = get_tblock_id(0);\n    global_tid_43222 = block_id_43224 * tblock_sizze_43226 + local_tid_43223;\n    tid_43221 = sext_i32_i64(global_tid_43222);\n    loopres_42186 = ((__global float *) mem_param_42440)[loopres_39384];\n    loopres_42188 = ((__global int64_t *) mem_param_42443)[loopres_39384];\n    loopres_42190 = ((__global int64_t *) mem_param_42446)[loopres_39384];\n    ((__global float *) mem_42453)[(int64_t) 0] = loopres_42186;\n    ((__global int64_t *) mem_42454)[(int64_t) 0] = loopres_42188;\n    ((__global int64_t *) mem_42455)[(int64_t) 0] = loopres_42190;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL\nvoid inner_SMJ_floatzireplicate_43228(int64_t loopres_39385, int64_t replicate_n_43227, int64_t virt_num_tblocks_43233, int64_t num_tblocks_43234, __global unsigned char *mem_42453, __global unsigned char *mem_42457)\n{\n    int32_t replicate_ltid_43229;\n    int32_t tblock_sizze_43231;\n    int32_t replicate_gid_43230;\n    int32_t replicate_gtid_43228;\n    int32_t phys_tblock_id_43235;\n    int32_t iterations_43236;\n    \n    replicate_ltid_43229 = get_local_id(0);\n    tblock_sizze_43231 = get_local_size(0);\n    replicate_gid_43230 = get_tblock_id(0);\n    replicate_gtid_43228 = replicate_gid_43230 * tblock_sizze_43231 + replicate_ltid_43229;\n    phys_tblock_id_43235 = get_tblock_id(0);\n    iterations_43236 = sdiv_up32(sext_i64_i32(virt_num_tblocks_43233) - phys_tblock_id_43235, sext_i", "64_i32(num_tblocks_43234));\n    for (int32_t i_43237 = 0; i_43237 < iterations_43236; i_43237++) {\n        int32_t virt_tblock_id_43238;\n        int64_t global_tid_43239;\n        int64_t slice_43242;\n        int64_t slice_43243;\n        int64_t rep_i_43240;\n        int64_t remnant_43244;\n        int64_t rep_i_43241;\n        int64_t remnant_43245;\n        \n        virt_tblock_id_43238 = phys_tblock_id_43235 + i_43237 * sext_i64_i32(num_tblocks_43234);\n        global_tid_43239 = sext_i32_i64(virt_tblock_id_43238) * sext_i32_i64(tblock_sizze_43231) + sext_i32_i64(replicate_ltid_43229);\n        slice_43242 = (int64_t) 1;\n        slice_43243 = loopres_39385 * slice_43242;\n        rep_i_43240 = squot64(global_tid_43239, slice_43242);\n        remnant_43244 = global_tid_43239 - rep_i_43240 * slice_43242;\n        rep_i_43241 = remnant_43244;\n        remnant_43245 = remnant_43244 - rep_i_43241;\n        if (slt64(global_tid_43239, replicate_n_43227)) {\n            float tmp_43246 = ((__global float *) mem_42453)[rep_i_43241];\n            \n            ((__global float *) mem_42457)[rep_i_43240 + rep_i_43241] = tmp_43246;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid inner_SMJ_floatzireplicate_43248(int64_t loopres_39385, int64_t replicate_n_43247, int64_t virt_num_tblocks_43253, int64_t num_tblocks_43254, __global unsigned char *mem_42454, __global unsigned char *mem_42459)\n{\n    int32_t replicate_ltid_43249;\n    int32_t tblock_sizze_43251;\n    int32_t replicate_gid_43250;\n    int32_t replicate_gtid_43248;\n    int32_t phys_tblock_id_43255;\n    int32_t iterations_43256;\n    \n    replicate_ltid_43249 = get_local_id(0);\n    tblock_sizze_43251 = get_local_size(0);\n    replicate_gid_43250 = get_tblock_id(0);\n    replicate_gtid_43248 = replicate_gid_43250 * tblock_sizze_43251 + replicate_ltid_43249;\n    phys_tblock_id_43255 = get_tblock_id(0);\n    iterations_43256 = sdiv_up32(sext_i64_i32(virt_num_tblock", "s_43253) - phys_tblock_id_43255, sext_i64_i32(num_tblocks_43254));\n    for (int32_t i_43257 = 0; i_43257 < iterations_43256; i_43257++) {\n        int32_t virt_tblock_id_43258;\n        int64_t global_tid_43259;\n        int64_t slice_43262;\n        int64_t slice_43263;\n        int64_t rep_i_43260;\n        int64_t remnant_43264;\n        int64_t rep_i_43261;\n        int64_t remnant_43265;\n        \n        virt_tblock_id_43258 = phys_tblock_id_43255 + i_43257 * sext_i64_i32(num_tblocks_43254);\n        global_tid_43259 = sext_i32_i64(virt_tblock_id_43258) * sext_i32_i64(tblock_sizze_43251) + sext_i32_i64(replicate_ltid_43249);\n        slice_43262 = (int64_t) 1;\n        slice_43263 = loopres_39385 * slice_43262;\n        rep_i_43260 = squot64(global_tid_43259, slice_43262);\n        remnant_43264 = global_tid_43259 - rep_i_43260 * slice_43262;\n        rep_i_43261 = remnant_43264;\n        remnant_43265 = remnant_43264 - rep_i_43261;\n        if (slt64(global_tid_43259, replicate_n_43247)) {\n            int64_t tmp_43266 = ((__global int64_t *) mem_42454)[rep_i_43261];\n            \n            ((__global int64_t *) mem_42459)[rep_i_43260 + rep_i_43261] = tmp_43266;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_floatzisegmap_41081_dim1, 1, 1)\nvoid inner_SMJ_floatzisegmap_41081(__global int *global_failure, int64_t nR_32229, int64_t m_39200, int64_t num_tblocks_41086, int64_t ext_42365, int64_t ext_42366, int64_t ext_42367, int64_t ext_42368, int32_t virt_num_tblocks_42987, __global unsigned char *tR_mem_42199, __global unsigned char *ext_mem_42201, __global unsigned char *ext_mem_42369, __global unsigned char *ext_mem_42370, __global unsigned char *mem_42373, __global unsigned char *mem_42375, __global unsigned char *mem_42377, __global unsigned char *mem_42379, __global unsigned char *mem_42381, __global unsigned char *mem_42383)\n{\n    #define segmap_tblock_sizze_41084 (inner_SMJ_floatzi",
                                    "segmap_41081zisegmap_tblock_sizze_41084)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42989;\n    int32_t tblock_sizze_42992;\n    int32_t wave_sizze_42991;\n    int32_t block_id_42990;\n    int32_t global_tid_42988;\n    int64_t phys_tid_41081;\n    int32_t phys_tblock_id_42993;\n    int32_t iterations_42994;\n    \n    local_tid_42989 = get_local_id(0);\n    tblock_sizze_42992 = get_local_size(0);\n    wave_sizze_42991 = LOCKSTEP_WIDTH;\n    block_id_42990 = get_tblock_id(0);\n    global_tid_42988 = block_id_42990 * tblock_sizze_42992 + local_tid_42989;\n    phys_tid_41081 = sext_i32_i64(global_tid_42988);\n    phys_tblock_id_42993 = get_tblock_id(0);\n    iterations_42994 = sdiv_up32(virt_num_tblocks_42987 - phys_tblock_id_42993, sext_i64_i32(num_tblocks_41086));\n    for (int32_t i_42995 = 0; i_42995 < iterations_42994; i_42995++) {\n        int32_t virt_tblock_id_42996;\n        int64_t global_tid_42997;\n        int64_t slice_42998;\n        int64_t write_i_41080;\n        int64_t remnant_42999;\n        \n        virt_tblock_id_42996 = phys_tblock_id_42993 + i_42995 * sext_i64_i32(num_tblocks_41086);\n        global_tid_42997 = sext_i32_i64(virt_tblock_id_42996) * segmap_tblock_sizze_41084 + sext_i32_i64(local_tid_42989);\n        slice_42998 = nR_32229;\n        write_i_41080 = global_tid_42997;\n        remnant_42999 = global_tid_42997 - write_i_41080;\n        if (slt64(write_i_41080, nR_32229)) {\n            int64_t eta_p_39447;\n            float write_value_39449;\n            int64_t write_value_39450;\n            int64_t write_value_39451;\n            int64_t write_value_39452;\n            bool cond_39453;\n            int64_t lifted_lambda_res_39454;\n            \n            eta_p_39447 = ((__global int64_t *) mem_42375)[write_i_41080];\n            write_value_39449 = ((__global float *) tR_mem_42199)[write_i_41080];\n            write_value_39450 = ((__global int64_t *) ext_mem_42201)[write_i_41080];\n            write_value_39451 = ((__global int64_t *) ", "ext_mem_42369)[ext_42366 + write_i_41080 * ext_42365];\n            write_value_39452 = ((__global int64_t *) ext_mem_42370)[ext_42368 + write_i_41080 * ext_42367];\n            cond_39453 = eta_p_39447 == (int64_t) 1;\n            if (cond_39453) {\n                int64_t eta_p_39448;\n                int64_t lifted_lambda_res_t_res_39514;\n                \n                eta_p_39448 = ((__global int64_t *) mem_42373)[write_i_41080];\n                lifted_lambda_res_t_res_39514 = sub64(eta_p_39448, (int64_t) 1);\n                lifted_lambda_res_39454 = lifted_lambda_res_t_res_39514;\n            } else {\n                lifted_lambda_res_39454 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39454) && slt64(lifted_lambda_res_39454, m_39200)) {\n                ((__global float *) mem_42383)[lifted_lambda_res_39454] = write_value_39449;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39454) && slt64(lifted_lambda_res_39454, m_39200)) {\n                ((__global int64_t *) mem_42381)[lifted_lambda_res_39454] = write_value_39450;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39454) && slt64(lifted_lambda_res_39454, m_39200)) {\n                ((__global int64_t *) mem_42379)[lifted_lambda_res_39454] = write_value_39451;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39454) && slt64(lifted_lambda_res_39454, m_39200)) {\n                ((__global int64_t *) mem_42377)[lifted_lambda_res_39454] = write_value_39452;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_41084\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_floatzisegmap_41115_dim1, 1, 1)\nvoid inner_SMJ_floatzisegmap_41115(__global int *global_failure, int64_t m_39200, __global unsigned char *mem_42387, __global unsigned char *mem_42394)\n{\n    #define segmap_tblock_sizze_41111 (inner_SMJ_floatzisegmap_41115zisegmap_tblock_sizze_41111)\n    ", "if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43155;\n    int32_t tblock_sizze_43158;\n    int32_t wave_sizze_43157;\n    int32_t block_id_43156;\n    int32_t global_tid_43154;\n    int64_t phys_tid_41115;\n    int64_t global_tid_43159;\n    int64_t slice_43160;\n    int64_t gtid_41114;\n    int64_t remnant_43161;\n    \n    local_tid_43155 = get_local_id(0);\n    tblock_sizze_43158 = get_local_size(0);\n    wave_sizze_43157 = LOCKSTEP_WIDTH;\n    block_id_43156 = get_tblock_id(0);\n    global_tid_43154 = block_id_43156 * tblock_sizze_43158 + local_tid_43155;\n    phys_tid_41115 = sext_i32_i64(global_tid_43154);\n    global_tid_43159 = sext_i32_i64(block_id_43156) * segmap_tblock_sizze_41111 + sext_i32_i64(local_tid_43155);\n    slice_43160 = m_39200;\n    gtid_41114 = global_tid_43159;\n    remnant_43161 = global_tid_43159 - gtid_41114;\n    if (slt64(gtid_41114, m_39200)) {\n        int64_t zv_lhs_41117;\n        int64_t tmp_41118;\n        bool cond_41120;\n        int64_t lifted_lambda_res_41121;\n        \n        zv_lhs_41117 = add64((int64_t) -1, gtid_41114);\n        tmp_41118 = smod64(zv_lhs_41117, m_39200);\n        cond_41120 = gtid_41114 == (int64_t) 0;\n        if (cond_41120) {\n            lifted_lambda_res_41121 = (int64_t) 0;\n        } else {\n            int64_t lifted_lambda_res_41119 = ((__global int64_t *) mem_42387)[tmp_41118];\n            \n            lifted_lambda_res_41121 = lifted_lambda_res_41119;\n        }\n        ((__global int64_t *) mem_42394)[gtid_41114] = lifted_lambda_res_41121;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_41111\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_floatzisegmap_41123_dim1, 1, 1)\nvoid inner_SMJ_floatzisegmap_41123(__global int *global_failure, int64_t m_39200, int64_t lower_bound_39283, int64_t min_res_39285, int64_t j_m_i_39286, int64_t num_tblocks_41128, int32_t virt_num_tblocks_43200, __global unsigned char *mem_42379, __global unsigned char *mem_42381, __global unsigned char *mem_42383, __global unsigned ",
                                    "char *mem_42394, __global unsigned char *mem_42423, __global unsigned char *mem_42425, __global unsigned char *mem_42427)\n{\n    #define segmap_tblock_sizze_41126 (inner_SMJ_floatzisegmap_41123zisegmap_tblock_sizze_41126)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43202;\n    int32_t tblock_sizze_43205;\n    int32_t wave_sizze_43204;\n    int32_t block_id_43203;\n    int32_t global_tid_43201;\n    int64_t phys_tid_41123;\n    int32_t phys_tblock_id_43206;\n    int32_t iterations_43207;\n    \n    local_tid_43202 = get_local_id(0);\n    tblock_sizze_43205 = get_local_size(0);\n    wave_sizze_43204 = LOCKSTEP_WIDTH;\n    block_id_43203 = get_tblock_id(0);\n    global_tid_43201 = block_id_43203 * tblock_sizze_43205 + local_tid_43202;\n    phys_tid_41123 = sext_i32_i64(global_tid_43201);\n    phys_tblock_id_43206 = get_tblock_id(0);\n    iterations_43207 = sdiv_up32(virt_num_tblocks_43200 - phys_tblock_id_43206, sext_i64_i32(num_tblocks_41128));\n    for (int32_t i_43208 = 0; i_43208 < iterations_43207; i_43208++) {\n        int32_t virt_tblock_id_43209;\n        int64_t global_tid_43210;\n        int64_t slice_43211;\n        int64_t write_i_41122;\n        int64_t remnant_43212;\n        \n        virt_tblock_id_43209 = phys_tblock_id_43206 + i_43208 * sext_i64_i32(num_tblocks_41128);\n        global_tid_43210 = sext_i32_i64(virt_tblock_id_43209) * segmap_tblock_sizze_41126 + sext_i32_i64(local_tid_43202);\n        slice_43211 = m_39200;\n        write_i_41122 = global_tid_43210;\n        remnant_43212 = global_tid_43210 - write_i_41122;\n        if (slt64(write_i_41122, m_39200)) {\n            int64_t eta_p_39484;\n            float write_value_39485;\n            int64_t write_value_39486;\n            int64_t write_value_39487;\n            bool cond_39488;\n            bool cond_t_res_39489;\n            bool x_39490;\n            int64_t lifted_lambda_res_39491;\n            \n            eta_p_39484 = ((__global int64_t *) mem_42394)[write_i_41122];\n            write_val", "ue_39485 = ((__global float *) mem_42383)[write_i_41122];\n            write_value_39486 = ((__global int64_t *) mem_42381)[write_i_41122];\n            write_value_39487 = ((__global int64_t *) mem_42379)[write_i_41122];\n            cond_39488 = sle64(lower_bound_39283, eta_p_39484);\n            cond_t_res_39489 = slt64(eta_p_39484, min_res_39285);\n            x_39490 = cond_39488 && cond_t_res_39489;\n            if (x_39490) {\n                int64_t lifted_lambda_res_t_res_39517 = sub64(eta_p_39484, lower_bound_39283);\n                \n                lifted_lambda_res_39491 = lifted_lambda_res_t_res_39517;\n            } else {\n                lifted_lambda_res_39491 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39491) && slt64(lifted_lambda_res_39491, j_m_i_39286)) {\n                ((__global float *) mem_42423)[lifted_lambda_res_39491] = write_value_39485;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39491) && slt64(lifted_lambda_res_39491, j_m_i_39286)) {\n                ((__global int64_t *) mem_42425)[lifted_lambda_res_39491] = write_value_39486;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39491) && slt64(lifted_lambda_res_39491, j_m_i_39286)) {\n                ((__global int64_t *) mem_42427)[lifted_lambda_res_39491] = write_value_39487;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_41126\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_floatzisegmap_41131_dim1, 1, 1)\nvoid inner_SMJ_floatzisegmap_41131(__global int *global_failure, int64_t m_39200, int64_t m_39340, int64_t num_tblocks_41136, int32_t virt_num_tblocks_43182, __global unsigned char *mem_42377, __global unsigned char *mem_42389, __global unsigned char *mem_42391, __global unsigned char *mem_42394, __global unsigned char *mem_42402, __global unsigned char *mem_42404)\n{\n    #define segmap_tblock_sizze_41134 (inner_SMJ_floatzisegma", "p_41131zisegmap_tblock_sizze_41134)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43184;\n    int32_t tblock_sizze_43187;\n    int32_t wave_sizze_43186;\n    int32_t block_id_43185;\n    int32_t global_tid_43183;\n    int64_t phys_tid_41131;\n    int32_t phys_tblock_id_43188;\n    int32_t iterations_43189;\n    \n    local_tid_43184 = get_local_id(0);\n    tblock_sizze_43187 = get_local_size(0);\n    wave_sizze_43186 = LOCKSTEP_WIDTH;\n    block_id_43185 = get_tblock_id(0);\n    global_tid_43183 = block_id_43185 * tblock_sizze_43187 + local_tid_43184;\n    phys_tid_41131 = sext_i32_i64(global_tid_43183);\n    phys_tblock_id_43188 = get_tblock_id(0);\n    iterations_43189 = sdiv_up32(virt_num_tblocks_43182 - phys_tblock_id_43188, sext_i64_i32(num_tblocks_41136));\n    for (int32_t i_43190 = 0; i_43190 < iterations_43189; i_43190++) {\n        int32_t virt_tblock_id_43191;\n        int64_t global_tid_43192;\n        int64_t slice_43193;\n        int64_t write_i_41130;\n        int64_t remnant_43194;\n        \n        virt_tblock_id_43191 = phys_tblock_id_43188 + i_43190 * sext_i64_i32(num_tblocks_41136);\n        global_tid_43192 = sext_i32_i64(virt_tblock_id_43191) * segmap_tblock_sizze_41134 + sext_i32_i64(local_tid_43184);\n        slice_43193 = m_39200;\n        write_i_41130 = global_tid_43192;\n        remnant_43194 = global_tid_43192 - write_i_41130;\n        if (slt64(write_i_41130, m_39200)) {\n            int64_t eta_p_39424;\n            int64_t write_value_39426;\n            int64_t write_value_39427;\n            bool cond_39428;\n            int64_t lifted_lambda_res_39429;\n            \n            eta_p_39424 = ((__global int64_t *) mem_42391)[write_i_41130];\n            write_value_39426 = ((__global int64_t *) mem_42394)[write_i_41130];\n            write_value_39427 = ((__global int64_t *) mem_42377)[write_i_41130];\n            cond_39428 = eta_p_39424 == (int64_t) 1;\n            if (cond_39428) {\n                int64_t eta_p_39425;\n                int64_",
                                    "t lifted_lambda_res_t_res_39522;\n                \n                eta_p_39425 = ((__global int64_t *) mem_42389)[write_i_41130];\n                lifted_lambda_res_t_res_39522 = sub64(eta_p_39425, (int64_t) 1);\n                lifted_lambda_res_39429 = lifted_lambda_res_t_res_39522;\n            } else {\n                lifted_lambda_res_39429 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39429) && slt64(lifted_lambda_res_39429, m_39340)) {\n                ((__global int64_t *) mem_42404)[lifted_lambda_res_39429] = write_value_39426;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39429) && slt64(lifted_lambda_res_39429, m_39340)) {\n                ((__global int64_t *) mem_42402)[lifted_lambda_res_39429] = write_value_39427;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_41134\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_floatzisegmap_41153_dim1, 1, 1)\nvoid inner_SMJ_floatzisegmap_41153(__global int *global_failure, int64_t loopres_39384, int64_t loopres_39385, __global unsigned char *mem_42452, __global unsigned char *mem_42455)\n{\n    #define segmap_tblock_sizze_41149 (inner_SMJ_floatzisegmap_41153zisegmap_tblock_sizze_41149)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43269;\n    int32_t tblock_sizze_43272;\n    int32_t wave_sizze_43271;\n    int32_t block_id_43270;\n    int32_t global_tid_43268;\n    int64_t phys_tid_41153;\n    int64_t global_tid_43273;\n    int64_t slice_43274;\n    int64_t gtid_41152;\n    int64_t remnant_43275;\n    \n    local_tid_43269 = get_local_id(0);\n    tblock_sizze_43272 = get_local_size(0);\n    wave_sizze_43271 = LOCKSTEP_WIDTH;\n    block_id_43270 = get_tblock_id(0);\n    global_tid_43268 = block_id_43270 * tblock_sizze_43272 + local_tid_43269;\n    phys_tid_41153 = sext_i32_i64(global_tid_43268);\n    global_tid_43273 = sext_i32_i64(block_id_43270) * segmap_tblock_sizze_4114", "9 + sext_i32_i64(local_tid_43269);\n    slice_43274 = loopres_39385;\n    gtid_41152 = global_tid_43273;\n    remnant_43275 = global_tid_43273 - gtid_41152;\n    if (slt64(gtid_41152, loopres_39385)) {\n        int64_t loopres_42194;\n        int64_t tmp_41155;\n        \n        loopres_42194 = ((__global int64_t *) mem_42455)[(int64_t) 0];\n        tmp_41155 = add64(gtid_41152, loopres_42194);\n        ((__global int64_t *) mem_42452)[loopres_39384 + gtid_41152] = tmp_41155;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_41149\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_floatzisegmap_intrablock_41423_dim1, 1, 1)\nvoid inner_SMJ_floatzisegmap_intrablock_41423(__global int *global_failure, int64_t nS_32230, int64_t start_39100, int64_t min_res_39102, int64_t ldim_41426, int64_t num_whole_tiles_41441, int64_t residual_input_41665, unsigned char cond_41666_bits, int64_t binop_x_41682, __global unsigned char *tR_mem_42199, __global unsigned char *tS_mem_42200, __global unsigned char *ext_mem_42224, __global unsigned char *mem_42344, __global unsigned char *mem_42346)\n{\n    bool cond_41666 = cond_41666_bits;\n    \n    #define tile_sizze_41425 (inner_SMJ_floatzisegmap_intrablock_41423zitile_sizze_41425)\n    #define bytes_42306 (inner_SMJ_floatzisegmap_intrablock_41423zibytes_42306)\n    #define bytes_42308 (inner_SMJ_floatzisegmap_intrablock_41423zibytes_42308)\n    \n    volatile __local unsigned char *color_42702_backing_2 = &shared_mem[0];\n    const int64_t color_42702_backing_2_offset = 0 + (bytes_42306 + srem64((int64_t) 8 - srem64(bytes_42306, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_42701_backing_1 = &shared_mem[color_42702_backing_2_offset];\n    const int64_t color_42701_backing_1_offset = color_42702_backing_2_offset + (bytes_42308 + srem64((int64_t) 8 - srem64(bytes_42308, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_42700_backing_0 = &shared_mem[color_42701_backing_1_offset];\n    const int64_t color_42700_backing", "_0_offset = color_42701_backing_1_offset + (bytes_42306 + srem64((int64_t) 8 - srem64(bytes_42306, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42793;\n    int32_t tblock_sizze_42796;\n    int32_t wave_sizze_42795;\n    int32_t block_id_42794;\n    int32_t global_tid_42792;\n    int64_t gid_flat_41423;\n    int64_t slice_42798;\n    int64_t ltid_pre_42797;\n    int64_t remnant_42799;\n    int64_t slice_42800;\n    int64_t gid_41422;\n    int64_t remnant_42801;\n    __local unsigned char *color_42700;\n    __local unsigned char *color_42701;\n    __local unsigned char *color_42702;\n    int64_t binop_x_41433;\n    float mem_42290[1];\n    int64_t ltid_flat_41428;\n    int64_t ltid_41427;\n    int64_t gtid_41434;\n    bool cond_41435;\n    float pre_41436;\n    int64_t mem_42294[1];\n    float mem_42298[1];\n    int64_t mem_42302[1];\n    int64_t ltid_flat_41443;\n    int64_t ltid_41442;\n    int64_t gtid_41453;\n    bool cond_41454;\n    int64_t neutral_41455;\n    float neutral_41456;\n    int64_t ext_mem_42326[1];\n    float ext_mem_42325[1];\n    int64_t ext_mem_42324[1];\n    int64_t mem_param_42303[1];\n    float mem_param_42304[1];\n    int64_t mem_param_42305[1];\n    int64_t mem_42336[1];\n    int64_t mem_42340[1];\n    int64_t ext_mem_42342[1];\n    int64_t ext_mem_42341[1];\n    \n    local_tid_42793 = get_local_id(0);\n    tblock_sizze_42796 = get_local_size(0);\n    wave_sizze_42795 = LOCKSTEP_WIDTH;\n    block_id_42794 = get_tblock_id(0);\n    global_tid_42792 = block_id_42794 * tblock_sizze_42796 + local_tid_42793;\n    gid_flat_41423 = sext_i32_i64(block_id_42794);\n    slice_42798 = tile_sizze_41425;\n    ltid_pre_42797 = sext_i32_i64(local_tid_42793);\n    remnant_42799 = sext_i32_i64(local_tid_42793) - ltid_pre_42797;\n    slice_42800 = ldim_41426;\n    gid_41422 = sext_i32_i64(block_id_42794);\n    remnant_42801 = sext_i32_i64(block_id_42794) - gid_41422;\n    color_42700 = (__local unsigned char *) color_42700_backing_0;\n    color_42701 = ",
                                    "(__local unsigned char *) color_42701_backing_1;\n    color_42702 = (__local unsigned char *) color_42702_backing_2;\n    binop_x_41433 = gid_41422 * tile_sizze_41425;\n    ltid_flat_41428 = sext_i32_i64(local_tid_42793);\n    ltid_41427 = sext_i32_i64(sext_i64_i32(ltid_pre_42797));\n    gtid_41434 = ltid_41427 + binop_x_41433;\n    cond_41435 = slt64(gtid_41434, min_res_39102);\n    if (cond_41435) {\n        int64_t slice_41437;\n        float eta_p_41438;\n        \n        slice_41437 = start_39100 + gtid_41434;\n        eta_p_41438 = ((__global float *) tR_mem_42199)[slice_41437];\n        pre_41436 = eta_p_41438;\n    } else {\n        pre_41436 = 0.0F;\n    }\n    mem_42290[(int64_t) 0] = pre_41436;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    ltid_flat_41443 = sext_i32_i64(local_tid_42793);\n    ltid_41442 = sext_i32_i64(sext_i64_i32(ltid_pre_42797));\n    gtid_41453 = binop_x_41433 + ltid_41442;\n    cond_41454 = slt64(gtid_41453, min_res_39102);\n    if (cond_41454) {\n        neutral_41455 = (int64_t) -1;\n    } else {\n        neutral_41455 = (int64_t) 0;\n    }\n    if (cond_41454) {\n        float eta_p_41458 = mem_42290[(int64_t) 0];\n        \n        neutral_41456 = eta_p_41458;\n    } else {\n        neutral_41456 = 0.0F;\n    }\n    mem_42294[(int64_t) 0] = neutral_41455;\n    mem_42298[(int64_t) 0] = neutral_41456;\n    mem_42302[(int64_t) 0] = (int64_t) 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    for (int32_t i_3 = 0; i_3 < 1; i_3++)\n        mem_param_42303[i_3] = mem_42294[i_3];\n    for (int32_t i_4 = 0; i_4 < 1; i_4++)\n        mem_param_42304[i_4] = mem_42298[i_4];\n    for (int32_t i_5 = 0; i_5 < 1; i_5++)\n        mem_param_42305[i_5] = mem_42302[i_5];\n    for (int64_t tile_id_41468 = 0; tile_id_41468 < num_whole_tiles_41441; tile_id_41468++) {\n        int64_t binop_x_41567;\n        int64_t ltid_flat_41566;\n        int64_t ltid_41565;\n        int64_t j_41568;\n        bool cond_41572;\n        int64_t pre1d_41575;\n        int64_t pre1d_41573;\n        float", " pre1d_41574;\n        int64_t mem_42315[1];\n        float mem_42319[1];\n        int64_t mem_42323[1];\n        int64_t ltid_flat_41586;\n        int64_t ltid_41585;\n        int64_t gtid_41588;\n        int64_t acc_41590;\n        float acc_41591;\n        int64_t acc_41592;\n        bool cond_41593;\n        int64_t acc_41594;\n        float acc_41595;\n        int64_t acc_41596;\n        int64_t mem_param_tmp_42802[1];\n        float mem_param_tmp_42803[1];\n        int64_t mem_param_tmp_42804[1];\n        \n        binop_x_41567 = tile_sizze_41425 * tile_id_41468;\n        ltid_flat_41566 = sext_i32_i64(local_tid_42793);\n        ltid_41565 = sext_i32_i64(sext_i64_i32(ltid_pre_42797));\n        j_41568 = ltid_41565 + binop_x_41567;\n        cond_41572 = slt64(j_41568, nS_32230);\n        pre1d_41575 = btoi_bool_i64(cond_41572);\n        if (cond_41572) {\n            int64_t tile_elem_41576;\n            float tile_elem_41577;\n            \n            tile_elem_41576 = ((__global int64_t *) ext_mem_42224)[j_41568];\n            tile_elem_41577 = ((__global float *) tS_mem_42200)[j_41568];\n            pre1d_41573 = tile_elem_41576;\n            pre1d_41574 = tile_elem_41577;\n        } else {\n            pre1d_41573 = (int64_t) 0;\n            pre1d_41574 = 0.0F;\n        }\n        ((__local int64_t *) color_42702)[ltid_41565] = pre1d_41573;\n        ((__local float *) color_42701)[ltid_41565] = pre1d_41574;\n        ((__local int64_t *) color_42700)[ltid_41565] = pre1d_41575;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_41586 = sext_i32_i64(local_tid_42793);\n        ltid_41585 = sext_i32_i64(sext_i64_i32(ltid_pre_42797));\n        gtid_41588 = binop_x_41433 + ltid_41585;\n        acc_41590 = mem_param_42303[(int64_t) 0];\n        acc_41591 = mem_param_42304[(int64_t) 0];\n        acc_41592 = mem_param_42305[(int64_t) 0];\n        cond_41593 = slt64(gtid_41588, min_res_39102);\n        if (cond_41593) {\n            float eta_p_41589;\n            int64_t x_41597;\n            float x_41598;", "\n            int64_t x_41599;\n            int64_t redout_42136;\n            float redout_42137;\n            int64_t redout_42138;\n            \n            eta_p_41589 = mem_42290[(int64_t) 0];\n            redout_42136 = acc_41590;\n            redout_42137 = acc_41591;\n            redout_42138 = acc_41592;\n            for (int64_t i_42139 = 0; i_42139 < tile_sizze_41425; i_42139++) {\n                int64_t x_41600;\n                float x_41601;\n                bool defunc_0_neq_res_41609;\n                bool defunc_0_neq_res_41610;\n                bool cond_f_res_41611;\n                bool y_41612;\n                bool cond_41613;\n                bool defunc_0_neq_res_41614;\n                bool defunc_0_neq_res_41615;\n                bool cond_t_res_f_res_41616;\n                bool y_41617;\n                bool cond_t_res_41618;\n                bool x_41619;\n                int64_t defunc_0_op_res_41620;\n                float defunc_0_op_res_41621;\n                int64_t defunc_0_op_res_41622;\n                int64_t redout_tmp_42808;\n                float redout_tmp_42809;\n                int64_t redout_tmp_42810;\n                \n                x_41600 = ((__local int64_t *) color_42702)[i_42139];\n                x_41601 = ((__local float *) color_42701)[i_42139];\n                defunc_0_neq_res_41609 = redout_42137 == eta_p_41589;\n                defunc_0_neq_res_41610 = !defunc_0_neq_res_41609;\n                cond_f_res_41611 = slt64(redout_42136, (int64_t) 0);\n                y_41612 = defunc_0_neq_res_41609 && cond_f_res_41611;\n                cond_41613 = defunc_0_neq_res_41610 || y_41612;\n                defunc_0_neq_res_41614 = x_41601 == eta_p_41589;\n                defunc_0_neq_res_41615 = !defunc_0_neq_res_41614;\n                cond_t_res_f_res_41616 = slt64(x_41600, (int64_t) 0);\n                y_41617 = defunc_0_neq_res_41614 && cond_t_res_f_res_41616;\n                cond_t_res_41618 = defunc_0_neq_res_41615 || y_41617;\n                x_41",
                                    "619 = cond_41613 && cond_t_res_41618;\n                if (x_41619) {\n                    defunc_0_op_res_41620 = (int64_t) -1;\n                    defunc_0_op_res_41621 = eta_p_41589;\n                    defunc_0_op_res_41622 = (int64_t) 0;\n                } else {\n                    int64_t x_41602;\n                    int64_t defunc_0_op_res_f_res_41623;\n                    float defunc_0_op_res_f_res_41624;\n                    int64_t defunc_0_op_res_f_res_41625;\n                    \n                    x_41602 = ((__local int64_t *) color_42700)[i_42139];\n                    if (cond_41613) {\n                        defunc_0_op_res_f_res_41623 = x_41600;\n                        defunc_0_op_res_f_res_41624 = x_41601;\n                        defunc_0_op_res_f_res_41625 = x_41602;\n                    } else {\n                        float defunc_0_op_res_f_res_f_res_41626;\n                        int64_t defunc_0_op_res_f_res_f_res_41627;\n                        int64_t defunc_0_op_res_f_res_f_res_41628;\n                        \n                        if (cond_t_res_41618) {\n                            defunc_0_op_res_f_res_f_res_41626 = redout_42137;\n                        } else {\n                            defunc_0_op_res_f_res_f_res_41626 = eta_p_41589;\n                        }\n                        if (cond_t_res_41618) {\n                            defunc_0_op_res_f_res_f_res_41627 = redout_42136;\n                            defunc_0_op_res_f_res_f_res_41628 = redout_42138;\n                        } else {\n                            int64_t min_res_41629;\n                            int64_t tmp_41630;\n                            \n                            min_res_41629 = smin64(x_41600, redout_42136);\n                            tmp_41630 = add64(x_41602, redout_42138);\n                            defunc_0_op_res_f_res_f_res_41627 = min_res_41629;\n                            defunc_0_op_res_f_res_f_res_41628 = tmp_41630;\n                        }\n  ", "                      defunc_0_op_res_f_res_41623 = defunc_0_op_res_f_res_f_res_41627;\n                        defunc_0_op_res_f_res_41624 = defunc_0_op_res_f_res_f_res_41626;\n                        defunc_0_op_res_f_res_41625 = defunc_0_op_res_f_res_f_res_41628;\n                    }\n                    defunc_0_op_res_41620 = defunc_0_op_res_f_res_41623;\n                    defunc_0_op_res_41621 = defunc_0_op_res_f_res_41624;\n                    defunc_0_op_res_41622 = defunc_0_op_res_f_res_41625;\n                }\n                redout_tmp_42808 = defunc_0_op_res_41620;\n                redout_tmp_42809 = defunc_0_op_res_41621;\n                redout_tmp_42810 = defunc_0_op_res_41622;\n                redout_42136 = redout_tmp_42808;\n                redout_42137 = redout_tmp_42809;\n                redout_42138 = redout_tmp_42810;\n            }\n            x_41597 = redout_42136;\n            x_41598 = redout_42137;\n            x_41599 = redout_42138;\n            acc_41594 = x_41597;\n            acc_41595 = x_41598;\n            acc_41596 = x_41599;\n        } else {\n            acc_41594 = acc_41590;\n            acc_41595 = acc_41591;\n            acc_41596 = acc_41592;\n        }\n        mem_42315[(int64_t) 0] = acc_41594;\n        mem_42319[(int64_t) 0] = acc_41595;\n        mem_42323[(int64_t) 0] = acc_41596;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_6 = 0; i_6 < 1; i_6++)\n            mem_param_tmp_42802[i_6] = mem_42315[i_6];\n        for (int32_t i_7 = 0; i_7 < 1; i_7++)\n            mem_param_tmp_42803[i_7] = mem_42319[i_7];\n        for (int32_t i_8 = 0; i_8 < 1; i_8++)\n            mem_param_tmp_42804[i_8] = mem_42323[i_8];\n        for (int32_t i_9 = 0; i_9 < 1; i_9++)\n            mem_param_42303[i_9] = mem_param_tmp_42802[i_9];\n        for (int32_t i_10 = 0; i_10 < 1; i_10++)\n            mem_param_42304[i_10] = mem_param_tmp_42803[i_10];\n        for (int32_t i_11 = 0; i_11 < 1; i_11++)\n            mem_param_42305[i_11] = mem_param_tmp_42804[i_11]", ";\n    }\n    for (int32_t i_12 = 0; i_12 < 1; i_12++)\n        ext_mem_42326[i_12] = mem_param_42303[i_12];\n    for (int32_t i_13 = 0; i_13 < 1; i_13++)\n        ext_mem_42325[i_13] = mem_param_42304[i_13];\n    for (int32_t i_14 = 0; i_14 < 1; i_14++)\n        ext_mem_42324[i_14] = mem_param_42305[i_14];\n    barrier(CLK_LOCAL_MEM_FENCE);\n    if (cond_41666) {\n        for (int32_t i_15 = 0; i_15 < 1; i_15++)\n            ext_mem_42342[i_15] = ext_mem_42326[i_15];\n        for (int32_t i_16 = 0; i_16 < 1; i_16++)\n            ext_mem_42341[i_16] = ext_mem_42324[i_16];\n    } else {\n        int64_t ltid_flat_41668;\n        int64_t ltid_41667;\n        int64_t j_41683;\n        bool cond_41687;\n        int64_t pre1d_41690;\n        int64_t pre1d_41688;\n        float pre1d_41689;\n        int64_t ltid_flat_41704;\n        int64_t ltid_41703;\n        int64_t gtid_41717;\n        int64_t acc_41719;\n        int64_t acc_41721;\n        bool cond_41722;\n        int64_t acc_41723;\n        int64_t acc_41725;\n        \n        ltid_flat_41668 = sext_i32_i64(local_tid_42793);\n        ltid_41667 = sext_i32_i64(sext_i64_i32(ltid_pre_42797));\n        j_41683 = ltid_41667 + binop_x_41682;\n        cond_41687 = slt64(j_41683, nS_32230);\n        pre1d_41690 = btoi_bool_i64(cond_41687);\n        if (cond_41687) {\n            int64_t tile_elem_41691;\n            float tile_elem_41692;\n            \n            tile_elem_41691 = ((__global int64_t *) ext_mem_42224)[j_41683];\n            tile_elem_41692 = ((__global float *) tS_mem_42200)[j_41683];\n            pre1d_41688 = tile_elem_41691;\n            pre1d_41689 = tile_elem_41692;\n        } else {\n            pre1d_41688 = (int64_t) 0;\n            pre1d_41689 = 0.0F;\n        }\n        ((__local int64_t *) color_42702)[ltid_41667] = pre1d_41688;\n        ((__local float *) color_42701)[ltid_41667] = pre1d_41689;\n        ((__local int64_t *) color_42700)[ltid_41667] = pre1d_41690;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_41704 = sext_i32_i64(lo",
                                    "cal_tid_42793);\n        ltid_41703 = sext_i32_i64(sext_i64_i32(ltid_pre_42797));\n        gtid_41717 = binop_x_41433 + ltid_41703;\n        acc_41719 = ext_mem_42326[(int64_t) 0];\n        acc_41721 = ext_mem_42324[(int64_t) 0];\n        cond_41722 = slt64(gtid_41717, min_res_39102);\n        if (cond_41722) {\n            float eta_p_41718;\n            float acc_41720;\n            int64_t x_41726;\n            float x_41727;\n            int64_t x_41728;\n            int64_t redout_42140;\n            float redout_42141;\n            int64_t redout_42142;\n            \n            eta_p_41718 = mem_42290[(int64_t) 0];\n            acc_41720 = ext_mem_42325[(int64_t) 0];\n            redout_42140 = acc_41719;\n            redout_42141 = acc_41720;\n            redout_42142 = acc_41721;\n            for (int64_t i_42143 = 0; i_42143 < residual_input_41665; i_42143++) {\n                int64_t x_41729;\n                float x_41730;\n                bool defunc_0_neq_res_41738;\n                bool defunc_0_neq_res_41739;\n                bool cond_f_res_41740;\n                bool y_41741;\n                bool cond_41742;\n                bool defunc_0_neq_res_41743;\n                bool defunc_0_neq_res_41744;\n                bool cond_t_res_f_res_41745;\n                bool y_41746;\n                bool cond_t_res_41747;\n                bool x_41748;\n                int64_t defunc_0_op_res_41749;\n                float defunc_0_op_res_41750;\n                int64_t defunc_0_op_res_41751;\n                int64_t redout_tmp_42811;\n                float redout_tmp_42812;\n                int64_t redout_tmp_42813;\n                \n                x_41729 = ((__local int64_t *) color_42702)[i_42143];\n                x_41730 = ((__local float *) color_42701)[i_42143];\n                defunc_0_neq_res_41738 = redout_42141 == eta_p_41718;\n                defunc_0_neq_res_41739 = !defunc_0_neq_res_41738;\n                cond_f_res_41740 = slt64(redout_42140, (int64_t) 0);\n                y_41741", " = defunc_0_neq_res_41738 && cond_f_res_41740;\n                cond_41742 = defunc_0_neq_res_41739 || y_41741;\n                defunc_0_neq_res_41743 = x_41730 == eta_p_41718;\n                defunc_0_neq_res_41744 = !defunc_0_neq_res_41743;\n                cond_t_res_f_res_41745 = slt64(x_41729, (int64_t) 0);\n                y_41746 = defunc_0_neq_res_41743 && cond_t_res_f_res_41745;\n                cond_t_res_41747 = defunc_0_neq_res_41744 || y_41746;\n                x_41748 = cond_41742 && cond_t_res_41747;\n                if (x_41748) {\n                    defunc_0_op_res_41749 = (int64_t) -1;\n                    defunc_0_op_res_41750 = eta_p_41718;\n                    defunc_0_op_res_41751 = (int64_t) 0;\n                } else {\n                    int64_t x_41731;\n                    int64_t defunc_0_op_res_f_res_41752;\n                    float defunc_0_op_res_f_res_41753;\n                    int64_t defunc_0_op_res_f_res_41754;\n                    \n                    x_41731 = ((__local int64_t *) color_42700)[i_42143];\n                    if (cond_41742) {\n                        defunc_0_op_res_f_res_41752 = x_41729;\n                        defunc_0_op_res_f_res_41753 = x_41730;\n                        defunc_0_op_res_f_res_41754 = x_41731;\n                    } else {\n                        float defunc_0_op_res_f_res_f_res_41755;\n                        int64_t defunc_0_op_res_f_res_f_res_41756;\n                        int64_t defunc_0_op_res_f_res_f_res_41757;\n                        \n                        if (cond_t_res_41747) {\n                            defunc_0_op_res_f_res_f_res_41755 = redout_42141;\n                        } else {\n                            defunc_0_op_res_f_res_f_res_41755 = eta_p_41718;\n                        }\n                        if (cond_t_res_41747) {\n                            defunc_0_op_res_f_res_f_res_41756 = redout_42140;\n                            defunc_0_op_res_f_res_f_res_41757 = redout_42142;\n         ", "               } else {\n                            int64_t min_res_41758;\n                            int64_t tmp_41759;\n                            \n                            min_res_41758 = smin64(x_41729, redout_42140);\n                            tmp_41759 = add64(x_41731, redout_42142);\n                            defunc_0_op_res_f_res_f_res_41756 = min_res_41758;\n                            defunc_0_op_res_f_res_f_res_41757 = tmp_41759;\n                        }\n                        defunc_0_op_res_f_res_41752 = defunc_0_op_res_f_res_f_res_41756;\n                        defunc_0_op_res_f_res_41753 = defunc_0_op_res_f_res_f_res_41755;\n                        defunc_0_op_res_f_res_41754 = defunc_0_op_res_f_res_f_res_41757;\n                    }\n                    defunc_0_op_res_41749 = defunc_0_op_res_f_res_41752;\n                    defunc_0_op_res_41750 = defunc_0_op_res_f_res_41753;\n                    defunc_0_op_res_41751 = defunc_0_op_res_f_res_41754;\n                }\n                redout_tmp_42811 = defunc_0_op_res_41749;\n                redout_tmp_42812 = defunc_0_op_res_41750;\n                redout_tmp_42813 = defunc_0_op_res_41751;\n                redout_42140 = redout_tmp_42811;\n                redout_42141 = redout_tmp_42812;\n                redout_42142 = redout_tmp_42813;\n            }\n            x_41726 = redout_42140;\n            x_41727 = redout_42141;\n            x_41728 = redout_42142;\n            acc_41723 = x_41726;\n            acc_41725 = x_41728;\n        } else {\n            acc_41723 = acc_41719;\n            acc_41725 = acc_41721;\n        }\n        mem_42336[(int64_t) 0] = acc_41723;\n        mem_42340[(int64_t) 0] = acc_41725;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_17 = 0; i_17 < 1; i_17++)\n            ext_mem_42342[i_17] = mem_42336[i_17];\n        for (int32_t i_18 = 0; i_18 < 1; i_18++)\n            ext_mem_42341[i_18] = mem_42340[i_18];\n    }\n    if (slt64(sext_i32_i64(local_tid_42793) + tile_sizze_414",
                                    "25 * sext_i32_i64(block_id_42794), min_res_39102)) {\n        int64_t tmp_42814 = ext_mem_42342[(int64_t) 0];\n        \n        ((__global int64_t *) mem_42344)[sext_i32_i64(local_tid_42793) + tile_sizze_41425 * sext_i32_i64(block_id_42794)] = tmp_42814;\n    }\n    if (slt64(sext_i32_i64(local_tid_42793) + tile_sizze_41425 * sext_i32_i64(block_id_42794), min_res_39102)) {\n        int64_t tmp_42815 = ext_mem_42341[(int64_t) 0];\n        \n        ((__global int64_t *) mem_42346)[sext_i32_i64(local_tid_42793) + tile_sizze_41425 * sext_i32_i64(block_id_42794)] = tmp_42815;\n    }\n    \n  error_8:\n    return;\n    #undef tile_sizze_41425\n    #undef bytes_42306\n    #undef bytes_42308\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_floatzisegmap_intrablock_41778_dim1, 1, 1)\nvoid inner_SMJ_floatzisegmap_intrablock_41778(__global int *global_failure, int64_t nS_32230, int64_t start_39100, int64_t min_res_39102, int64_t ldim_41781, int64_t num_whole_tiles_41796, int64_t residual_input_42020, unsigned char cond_42021_bits, int64_t binop_x_42037, __global unsigned char *tR_mem_42199, __global unsigned char *tS_mem_42200, __global unsigned char *ext_mem_42224, __global unsigned char *mem_42283, __global unsigned char *mem_42285)\n{\n    bool cond_42021 = cond_42021_bits;\n    \n    #define tile_sizze_41780 (inner_SMJ_floatzisegmap_intrablock_41778zitile_sizze_41780)\n    #define bytes_42245 (inner_SMJ_floatzisegmap_intrablock_41778zibytes_42245)\n    #define bytes_42247 (inner_SMJ_floatzisegmap_intrablock_41778zibytes_42247)\n    \n    volatile __local unsigned char *color_42705_backing_2 = &shared_mem[0];\n    const int64_t color_42705_backing_2_offset = 0 + (bytes_42245 + srem64((int64_t) 8 - srem64(bytes_42245, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_42704_backing_1 = &shared_mem[color_42705_backing_2_offset];\n    const int64_t color_42704_backing_1_offset = color_42705_backing_2_offset + (bytes_42247 + srem64((int64_t) 8 - srem64(bytes_42247, (int64_t) 8), (int64_t) 8));\n   ", " volatile __local unsigned char *color_42703_backing_0 = &shared_mem[color_42704_backing_1_offset];\n    const int64_t color_42703_backing_0_offset = color_42704_backing_1_offset + (bytes_42245 + srem64((int64_t) 8 - srem64(bytes_42245, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42819;\n    int32_t tblock_sizze_42822;\n    int32_t wave_sizze_42821;\n    int32_t block_id_42820;\n    int32_t global_tid_42818;\n    int64_t gid_flat_41778;\n    int64_t slice_42824;\n    int64_t ltid_pre_42823;\n    int64_t remnant_42825;\n    int64_t slice_42826;\n    int64_t gid_41777;\n    int64_t remnant_42827;\n    __local unsigned char *color_42703;\n    __local unsigned char *color_42704;\n    __local unsigned char *color_42705;\n    int64_t binop_x_41788;\n    float mem_42229[1];\n    int64_t ltid_flat_41783;\n    int64_t ltid_41782;\n    int64_t gtid_41789;\n    bool cond_41790;\n    float pre_41791;\n    int64_t mem_42233[1];\n    float mem_42237[1];\n    int64_t mem_42241[1];\n    int64_t ltid_flat_41798;\n    int64_t ltid_41797;\n    int64_t gtid_41808;\n    bool cond_41809;\n    int64_t neutral_41810;\n    float neutral_41811;\n    int64_t ext_mem_42265[1];\n    float ext_mem_42264[1];\n    int64_t ext_mem_42263[1];\n    int64_t mem_param_42242[1];\n    float mem_param_42243[1];\n    int64_t mem_param_42244[1];\n    int64_t mem_42275[1];\n    int64_t mem_42279[1];\n    int64_t ext_mem_42281[1];\n    int64_t ext_mem_42280[1];\n    \n    local_tid_42819 = get_local_id(0);\n    tblock_sizze_42822 = get_local_size(0);\n    wave_sizze_42821 = LOCKSTEP_WIDTH;\n    block_id_42820 = get_tblock_id(0);\n    global_tid_42818 = block_id_42820 * tblock_sizze_42822 + local_tid_42819;\n    gid_flat_41778 = sext_i32_i64(block_id_42820);\n    slice_42824 = tile_sizze_41780;\n    ltid_pre_42823 = sext_i32_i64(local_tid_42819);\n    remnant_42825 = sext_i32_i64(local_tid_42819) - ltid_pre_42823;\n    slice_42826 = ldim_41781;\n    gid_41777 = sext_i32_i64(block_id_42820);\n    remnan", "t_42827 = sext_i32_i64(block_id_42820) - gid_41777;\n    color_42703 = (__local unsigned char *) color_42703_backing_0;\n    color_42704 = (__local unsigned char *) color_42704_backing_1;\n    color_42705 = (__local unsigned char *) color_42705_backing_2;\n    binop_x_41788 = gid_41777 * tile_sizze_41780;\n    ltid_flat_41783 = sext_i32_i64(local_tid_42819);\n    ltid_41782 = sext_i32_i64(sext_i64_i32(ltid_pre_42823));\n    gtid_41789 = ltid_41782 + binop_x_41788;\n    cond_41790 = slt64(gtid_41789, min_res_39102);\n    if (cond_41790) {\n        int64_t slice_41792;\n        float eta_p_41793;\n        \n        slice_41792 = start_39100 + gtid_41789;\n        eta_p_41793 = ((__global float *) tR_mem_42199)[slice_41792];\n        pre_41791 = eta_p_41793;\n    } else {\n        pre_41791 = 0.0F;\n    }\n    mem_42229[(int64_t) 0] = pre_41791;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    ltid_flat_41798 = sext_i32_i64(local_tid_42819);\n    ltid_41797 = sext_i32_i64(sext_i64_i32(ltid_pre_42823));\n    gtid_41808 = binop_x_41788 + ltid_41797;\n    cond_41809 = slt64(gtid_41808, min_res_39102);\n    if (cond_41809) {\n        neutral_41810 = (int64_t) -1;\n    } else {\n        neutral_41810 = (int64_t) 0;\n    }\n    if (cond_41809) {\n        float eta_p_41813 = mem_42229[(int64_t) 0];\n        \n        neutral_41811 = eta_p_41813;\n    } else {\n        neutral_41811 = 0.0F;\n    }\n    mem_42233[(int64_t) 0] = neutral_41810;\n    mem_42237[(int64_t) 0] = neutral_41811;\n    mem_42241[(int64_t) 0] = (int64_t) 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    for (int32_t i_3 = 0; i_3 < 1; i_3++)\n        mem_param_42242[i_3] = mem_42233[i_3];\n    for (int32_t i_4 = 0; i_4 < 1; i_4++)\n        mem_param_42243[i_4] = mem_42237[i_4];\n    for (int32_t i_5 = 0; i_5 < 1; i_5++)\n        mem_param_42244[i_5] = mem_42241[i_5];\n    for (int64_t tile_id_41823 = 0; tile_id_41823 < num_whole_tiles_41796; tile_id_41823++) {\n        int64_t binop_x_41922;\n        int64_t ltid_flat_41921;\n        int6",
                                    "4_t ltid_41920;\n        int64_t j_41923;\n        bool cond_41927;\n        int64_t pre1d_41930;\n        int64_t pre1d_41928;\n        float pre1d_41929;\n        int64_t mem_42254[1];\n        float mem_42258[1];\n        int64_t mem_42262[1];\n        int64_t ltid_flat_41941;\n        int64_t ltid_41940;\n        int64_t gtid_41943;\n        int64_t acc_41945;\n        float acc_41946;\n        int64_t acc_41947;\n        bool cond_41948;\n        int64_t acc_41949;\n        float acc_41950;\n        int64_t acc_41951;\n        int64_t mem_param_tmp_42828[1];\n        float mem_param_tmp_42829[1];\n        int64_t mem_param_tmp_42830[1];\n        \n        binop_x_41922 = tile_sizze_41780 * tile_id_41823;\n        ltid_flat_41921 = sext_i32_i64(local_tid_42819);\n        ltid_41920 = sext_i32_i64(sext_i64_i32(ltid_pre_42823));\n        j_41923 = ltid_41920 + binop_x_41922;\n        cond_41927 = slt64(j_41923, nS_32230);\n        pre1d_41930 = btoi_bool_i64(cond_41927);\n        if (cond_41927) {\n            int64_t tile_elem_41931;\n            float tile_elem_41932;\n            \n            tile_elem_41931 = ((__global int64_t *) ext_mem_42224)[j_41923];\n            tile_elem_41932 = ((__global float *) tS_mem_42200)[j_41923];\n            pre1d_41928 = tile_elem_41931;\n            pre1d_41929 = tile_elem_41932;\n        } else {\n            pre1d_41928 = (int64_t) 0;\n            pre1d_41929 = 0.0F;\n        }\n        ((__local int64_t *) color_42705)[ltid_41920] = pre1d_41928;\n        ((__local float *) color_42704)[ltid_41920] = pre1d_41929;\n        ((__local int64_t *) color_42703)[ltid_41920] = pre1d_41930;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_41941 = sext_i32_i64(local_tid_42819);\n        ltid_41940 = sext_i32_i64(sext_i64_i32(ltid_pre_42823));\n        gtid_41943 = binop_x_41788 + ltid_41940;\n        acc_41945 = mem_param_42242[(int64_t) 0];\n        acc_41946 = mem_param_42243[(int64_t) 0];\n        acc_41947 = mem_param_42244[(int64_t) 0];\n        cond_41948 = slt64(gti", "d_41943, min_res_39102);\n        if (cond_41948) {\n            float eta_p_41944;\n            int64_t x_41952;\n            float x_41953;\n            int64_t x_41954;\n            int64_t redout_42144;\n            float redout_42145;\n            int64_t redout_42146;\n            \n            eta_p_41944 = mem_42229[(int64_t) 0];\n            redout_42144 = acc_41945;\n            redout_42145 = acc_41946;\n            redout_42146 = acc_41947;\n            for (int64_t i_42147 = 0; i_42147 < tile_sizze_41780; i_42147++) {\n                int64_t x_41955;\n                float x_41956;\n                bool defunc_0_neq_res_41964;\n                bool defunc_0_neq_res_41965;\n                bool cond_f_res_41966;\n                bool y_41967;\n                bool cond_41968;\n                bool defunc_0_neq_res_41969;\n                bool defunc_0_neq_res_41970;\n                bool cond_t_res_f_res_41971;\n                bool y_41972;\n                bool cond_t_res_41973;\n                bool x_41974;\n                int64_t defunc_0_op_res_41975;\n                float defunc_0_op_res_41976;\n                int64_t defunc_0_op_res_41977;\n                int64_t redout_tmp_42834;\n                float redout_tmp_42835;\n                int64_t redout_tmp_42836;\n                \n                x_41955 = ((__local int64_t *) color_42705)[i_42147];\n                x_41956 = ((__local float *) color_42704)[i_42147];\n                defunc_0_neq_res_41964 = redout_42145 == eta_p_41944;\n                defunc_0_neq_res_41965 = !defunc_0_neq_res_41964;\n                cond_f_res_41966 = slt64(redout_42144, (int64_t) 0);\n                y_41967 = defunc_0_neq_res_41964 && cond_f_res_41966;\n                cond_41968 = defunc_0_neq_res_41965 || y_41967;\n                defunc_0_neq_res_41969 = x_41956 == eta_p_41944;\n                defunc_0_neq_res_41970 = !defunc_0_neq_res_41969;\n                cond_t_res_f_res_41971 = slt64(x_41955, (int64_t) 0);\n                y_41972 = def", "unc_0_neq_res_41969 && cond_t_res_f_res_41971;\n                cond_t_res_41973 = defunc_0_neq_res_41970 || y_41972;\n                x_41974 = cond_41968 && cond_t_res_41973;\n                if (x_41974) {\n                    defunc_0_op_res_41975 = (int64_t) -1;\n                    defunc_0_op_res_41976 = eta_p_41944;\n                    defunc_0_op_res_41977 = (int64_t) 0;\n                } else {\n                    int64_t x_41957;\n                    int64_t defunc_0_op_res_f_res_41978;\n                    float defunc_0_op_res_f_res_41979;\n                    int64_t defunc_0_op_res_f_res_41980;\n                    \n                    x_41957 = ((__local int64_t *) color_42703)[i_42147];\n                    if (cond_41968) {\n                        defunc_0_op_res_f_res_41978 = x_41955;\n                        defunc_0_op_res_f_res_41979 = x_41956;\n                        defunc_0_op_res_f_res_41980 = x_41957;\n                    } else {\n                        float defunc_0_op_res_f_res_f_res_41981;\n                        int64_t defunc_0_op_res_f_res_f_res_41982;\n                        int64_t defunc_0_op_res_f_res_f_res_41983;\n                        \n                        if (cond_t_res_41973) {\n                            defunc_0_op_res_f_res_f_res_41981 = redout_42145;\n                        } else {\n                            defunc_0_op_res_f_res_f_res_41981 = eta_p_41944;\n                        }\n                        if (cond_t_res_41973) {\n                            defunc_0_op_res_f_res_f_res_41982 = redout_42144;\n                            defunc_0_op_res_f_res_f_res_41983 = redout_42146;\n                        } else {\n                            int64_t min_res_41984;\n                            int64_t tmp_41985;\n                            \n                            min_res_41984 = smin64(x_41955, redout_42144);\n                            tmp_41985 = add64(x_41957, redout_42146);\n                            defunc_0_op_res_f",
                                    "_res_f_res_41982 = min_res_41984;\n                            defunc_0_op_res_f_res_f_res_41983 = tmp_41985;\n                        }\n                        defunc_0_op_res_f_res_41978 = defunc_0_op_res_f_res_f_res_41982;\n                        defunc_0_op_res_f_res_41979 = defunc_0_op_res_f_res_f_res_41981;\n                        defunc_0_op_res_f_res_41980 = defunc_0_op_res_f_res_f_res_41983;\n                    }\n                    defunc_0_op_res_41975 = defunc_0_op_res_f_res_41978;\n                    defunc_0_op_res_41976 = defunc_0_op_res_f_res_41979;\n                    defunc_0_op_res_41977 = defunc_0_op_res_f_res_41980;\n                }\n                redout_tmp_42834 = defunc_0_op_res_41975;\n                redout_tmp_42835 = defunc_0_op_res_41976;\n                redout_tmp_42836 = defunc_0_op_res_41977;\n                redout_42144 = redout_tmp_42834;\n                redout_42145 = redout_tmp_42835;\n                redout_42146 = redout_tmp_42836;\n            }\n            x_41952 = redout_42144;\n            x_41953 = redout_42145;\n            x_41954 = redout_42146;\n            acc_41949 = x_41952;\n            acc_41950 = x_41953;\n            acc_41951 = x_41954;\n        } else {\n            acc_41949 = acc_41945;\n            acc_41950 = acc_41946;\n            acc_41951 = acc_41947;\n        }\n        mem_42254[(int64_t) 0] = acc_41949;\n        mem_42258[(int64_t) 0] = acc_41950;\n        mem_42262[(int64_t) 0] = acc_41951;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_6 = 0; i_6 < 1; i_6++)\n            mem_param_tmp_42828[i_6] = mem_42254[i_6];\n        for (int32_t i_7 = 0; i_7 < 1; i_7++)\n            mem_param_tmp_42829[i_7] = mem_42258[i_7];\n        for (int32_t i_8 = 0; i_8 < 1; i_8++)\n            mem_param_tmp_42830[i_8] = mem_42262[i_8];\n        for (int32_t i_9 = 0; i_9 < 1; i_9++)\n            mem_param_42242[i_9] = mem_param_tmp_42828[i_9];\n        for (int32_t i_10 = 0; i_10 < 1; i_10++)\n            mem_param_42243[i_10] = ", "mem_param_tmp_42829[i_10];\n        for (int32_t i_11 = 0; i_11 < 1; i_11++)\n            mem_param_42244[i_11] = mem_param_tmp_42830[i_11];\n    }\n    for (int32_t i_12 = 0; i_12 < 1; i_12++)\n        ext_mem_42265[i_12] = mem_param_42242[i_12];\n    for (int32_t i_13 = 0; i_13 < 1; i_13++)\n        ext_mem_42264[i_13] = mem_param_42243[i_13];\n    for (int32_t i_14 = 0; i_14 < 1; i_14++)\n        ext_mem_42263[i_14] = mem_param_42244[i_14];\n    barrier(CLK_LOCAL_MEM_FENCE);\n    if (cond_42021) {\n        for (int32_t i_15 = 0; i_15 < 1; i_15++)\n            ext_mem_42281[i_15] = ext_mem_42265[i_15];\n        for (int32_t i_16 = 0; i_16 < 1; i_16++)\n            ext_mem_42280[i_16] = ext_mem_42263[i_16];\n    } else {\n        int64_t ltid_flat_42023;\n        int64_t ltid_42022;\n        int64_t j_42038;\n        bool cond_42042;\n        int64_t pre1d_42045;\n        int64_t pre1d_42043;\n        float pre1d_42044;\n        int64_t ltid_flat_42059;\n        int64_t ltid_42058;\n        int64_t gtid_42072;\n        int64_t acc_42074;\n        int64_t acc_42076;\n        bool cond_42077;\n        int64_t acc_42078;\n        int64_t acc_42080;\n        \n        ltid_flat_42023 = sext_i32_i64(local_tid_42819);\n        ltid_42022 = sext_i32_i64(sext_i64_i32(ltid_pre_42823));\n        j_42038 = ltid_42022 + binop_x_42037;\n        cond_42042 = slt64(j_42038, nS_32230);\n        pre1d_42045 = btoi_bool_i64(cond_42042);\n        if (cond_42042) {\n            int64_t tile_elem_42046;\n            float tile_elem_42047;\n            \n            tile_elem_42046 = ((__global int64_t *) ext_mem_42224)[j_42038];\n            tile_elem_42047 = ((__global float *) tS_mem_42200)[j_42038];\n            pre1d_42043 = tile_elem_42046;\n            pre1d_42044 = tile_elem_42047;\n        } else {\n            pre1d_42043 = (int64_t) 0;\n            pre1d_42044 = 0.0F;\n        }\n        ((__local int64_t *) color_42705)[ltid_42022] = pre1d_42043;\n        ((__local float *) color_42704)[ltid_42022] = pre1d_42044;\n        ((_", "_local int64_t *) color_42703)[ltid_42022] = pre1d_42045;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_42059 = sext_i32_i64(local_tid_42819);\n        ltid_42058 = sext_i32_i64(sext_i64_i32(ltid_pre_42823));\n        gtid_42072 = binop_x_41788 + ltid_42058;\n        acc_42074 = ext_mem_42265[(int64_t) 0];\n        acc_42076 = ext_mem_42263[(int64_t) 0];\n        cond_42077 = slt64(gtid_42072, min_res_39102);\n        if (cond_42077) {\n            float eta_p_42073;\n            float acc_42075;\n            int64_t x_42081;\n            float x_42082;\n            int64_t x_42083;\n            int64_t redout_42148;\n            float redout_42149;\n            int64_t redout_42150;\n            \n            eta_p_42073 = mem_42229[(int64_t) 0];\n            acc_42075 = ext_mem_42264[(int64_t) 0];\n            redout_42148 = acc_42074;\n            redout_42149 = acc_42075;\n            redout_42150 = acc_42076;\n            for (int64_t i_42151 = 0; i_42151 < residual_input_42020; i_42151++) {\n                int64_t x_42084;\n                float x_42085;\n                bool defunc_0_neq_res_42093;\n                bool defunc_0_neq_res_42094;\n                bool cond_f_res_42095;\n                bool y_42096;\n                bool cond_42097;\n                bool defunc_0_neq_res_42098;\n                bool defunc_0_neq_res_42099;\n                bool cond_t_res_f_res_42100;\n                bool y_42101;\n                bool cond_t_res_42102;\n                bool x_42103;\n                int64_t defunc_0_op_res_42104;\n                float defunc_0_op_res_42105;\n                int64_t defunc_0_op_res_42106;\n                int64_t redout_tmp_42837;\n                float redout_tmp_42838;\n                int64_t redout_tmp_42839;\n                \n                x_42084 = ((__local int64_t *) color_42705)[i_42151];\n                x_42085 = ((__local float *) color_42704)[i_42151];\n                defunc_0_neq_res_42093 = redout_42149 == eta_p_42073;\n                defun",
                                    "c_0_neq_res_42094 = !defunc_0_neq_res_42093;\n                cond_f_res_42095 = slt64(redout_42148, (int64_t) 0);\n                y_42096 = defunc_0_neq_res_42093 && cond_f_res_42095;\n                cond_42097 = defunc_0_neq_res_42094 || y_42096;\n                defunc_0_neq_res_42098 = x_42085 == eta_p_42073;\n                defunc_0_neq_res_42099 = !defunc_0_neq_res_42098;\n                cond_t_res_f_res_42100 = slt64(x_42084, (int64_t) 0);\n                y_42101 = defunc_0_neq_res_42098 && cond_t_res_f_res_42100;\n                cond_t_res_42102 = defunc_0_neq_res_42099 || y_42101;\n                x_42103 = cond_42097 && cond_t_res_42102;\n                if (x_42103) {\n                    defunc_0_op_res_42104 = (int64_t) -1;\n                    defunc_0_op_res_42105 = eta_p_42073;\n                    defunc_0_op_res_42106 = (int64_t) 0;\n                } else {\n                    int64_t x_42086;\n                    int64_t defunc_0_op_res_f_res_42107;\n                    float defunc_0_op_res_f_res_42108;\n                    int64_t defunc_0_op_res_f_res_42109;\n                    \n                    x_42086 = ((__local int64_t *) color_42703)[i_42151];\n                    if (cond_42097) {\n                        defunc_0_op_res_f_res_42107 = x_42084;\n                        defunc_0_op_res_f_res_42108 = x_42085;\n                        defunc_0_op_res_f_res_42109 = x_42086;\n                    } else {\n                        float defunc_0_op_res_f_res_f_res_42110;\n                        int64_t defunc_0_op_res_f_res_f_res_42111;\n                        int64_t defunc_0_op_res_f_res_f_res_42112;\n                        \n                        if (cond_t_res_42102) {\n                            defunc_0_op_res_f_res_f_res_42110 = redout_42149;\n                        } else {\n                            defunc_0_op_res_f_res_f_res_42110 = eta_p_42073;\n                        }\n                        if (cond_t_res_42102) {\n                            ", "defunc_0_op_res_f_res_f_res_42111 = redout_42148;\n                            defunc_0_op_res_f_res_f_res_42112 = redout_42150;\n                        } else {\n                            int64_t min_res_42113;\n                            int64_t tmp_42114;\n                            \n                            min_res_42113 = smin64(x_42084, redout_42148);\n                            tmp_42114 = add64(x_42086, redout_42150);\n                            defunc_0_op_res_f_res_f_res_42111 = min_res_42113;\n                            defunc_0_op_res_f_res_f_res_42112 = tmp_42114;\n                        }\n                        defunc_0_op_res_f_res_42107 = defunc_0_op_res_f_res_f_res_42111;\n                        defunc_0_op_res_f_res_42108 = defunc_0_op_res_f_res_f_res_42110;\n                        defunc_0_op_res_f_res_42109 = defunc_0_op_res_f_res_f_res_42112;\n                    }\n                    defunc_0_op_res_42104 = defunc_0_op_res_f_res_42107;\n                    defunc_0_op_res_42105 = defunc_0_op_res_f_res_42108;\n                    defunc_0_op_res_42106 = defunc_0_op_res_f_res_42109;\n                }\n                redout_tmp_42837 = defunc_0_op_res_42104;\n                redout_tmp_42838 = defunc_0_op_res_42105;\n                redout_tmp_42839 = defunc_0_op_res_42106;\n                redout_42148 = redout_tmp_42837;\n                redout_42149 = redout_tmp_42838;\n                redout_42150 = redout_tmp_42839;\n            }\n            x_42081 = redout_42148;\n            x_42082 = redout_42149;\n            x_42083 = redout_42150;\n            acc_42078 = x_42081;\n            acc_42080 = x_42083;\n        } else {\n            acc_42078 = acc_42074;\n            acc_42080 = acc_42076;\n        }\n        mem_42275[(int64_t) 0] = acc_42078;\n        mem_42279[(int64_t) 0] = acc_42080;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_17 = 0; i_17 < 1; i_17++)\n            ext_mem_42281[i_17] = mem_42275[i_17];\n        for (int32_t i_18 = 0", "; i_18 < 1; i_18++)\n            ext_mem_42280[i_18] = mem_42279[i_18];\n    }\n    if (slt64(sext_i32_i64(local_tid_42819) + tile_sizze_41780 * sext_i32_i64(block_id_42820), min_res_39102)) {\n        int64_t tmp_42840 = ext_mem_42281[(int64_t) 0];\n        \n        ((__global int64_t *) mem_42283)[sext_i32_i64(local_tid_42819) + tile_sizze_41780 * sext_i32_i64(block_id_42820)] = tmp_42840;\n    }\n    if (slt64(sext_i32_i64(local_tid_42819) + tile_sizze_41780 * sext_i32_i64(block_id_42820), min_res_39102)) {\n        int64_t tmp_42841 = ext_mem_42280[(int64_t) 0];\n        \n        ((__global int64_t *) mem_42285)[sext_i32_i64(local_tid_42819) + tile_sizze_41780 * sext_i32_i64(block_id_42820)] = tmp_42841;\n    }\n    \n  error_8:\n    return;\n    #undef tile_sizze_41780\n    #undef bytes_42245\n    #undef bytes_42247\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_floatzisegscan_41079_dim1, 1, 1)\nvoid inner_SMJ_floatzisegscan_41079(__global int *global_failure, int64_t nR_32229, int64_t num_tblocks_41076, int64_t ext_42367, int64_t ext_42368, int64_t num_virt_blocks_42849, int64_t num_virt_threads_42850, __global unsigned char *ext_mem_42370, __global unsigned char *mem_42373, __global unsigned char *mem_42375, __global unsigned char *status_flags_mem_42851, __global unsigned char *aggregates_mem_42873, __global unsigned char *incprefixes_mem_42875, __global unsigned char *global_dynid_mem_42877)\n{\n    #define segscan_tblock_sizze_41074 (inner_SMJ_floatzisegscan_41079zisegscan_tblock_sizze_41074)\n    #define chunk_sizze_42848 (inner_SMJ_floatzisegscan_41079zichunk_sizze_42848)\n    \n    volatile __local unsigned char *local_mem_42907_backing_0 = &shared_mem[0];\n    const int64_t local_mem_42907_backing_0_offset = 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_41074), chunk_sizze_42848 * segscan_tblock_sizze_41074 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_41074), chunk_sizze_42848 * segscan_tblock_sizze_410",
                                    "74 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42900;\n    int32_t tblock_sizze_42903;\n    int32_t wave_sizze_42902;\n    int32_t block_id_42901;\n    int32_t global_tid_42899;\n    int64_t phys_tid_41079;\n    int32_t chunk_sizze_32b_42904;\n    int64_t byte_offsets_42905;\n    int64_t warp_byte_offset_42906;\n    __local unsigned char *local_mem_42907;\n    int64_t trans_arr_len_42908;\n    int64_t phys_block_id_42914;\n    int64_t virtloop_bound_42915;\n    \n    local_tid_42900 = get_local_id(0);\n    tblock_sizze_42903 = get_local_size(0);\n    wave_sizze_42902 = LOCKSTEP_WIDTH;\n    block_id_42901 = get_tblock_id(0);\n    global_tid_42899 = block_id_42901 * tblock_sizze_42903 + local_tid_42900;\n    phys_tid_41079 = sext_i32_i64(global_tid_42899);\n    chunk_sizze_32b_42904 = sext_i64_i32(chunk_sizze_42848);\n    byte_offsets_42905 = segscan_tblock_sizze_41074 * (int64_t) 8;\n    warp_byte_offset_42906 = (int64_t) 288;\n    // Allocate reusable shared memory\n    { }\n    local_mem_42907 = (__local unsigned char *) local_mem_42907_backing_0;\n    trans_arr_len_42908 = chunk_sizze_42848 * segscan_tblock_sizze_41074;\n    phys_block_id_42914 = get_tblock_id(0);\n    virtloop_bound_42915 = sdiv_up64(num_virt_blocks_42849 - phys_block_id_42914, num_tblocks_41076);\n    for (int64_t virtloop_i_42916 = 0; virtloop_i_42916 < virtloop_bound_42915; virtloop_i_42916++) {\n        int64_t dynamic_id_42917;\n        int64_t block_offset_42918;\n        int64_t sgm_idx_42919;\n        int32_t boundary_42920;\n        int32_t segsizze_compact_42921;\n        int64_t private_mem_42922[chunk_sizze_42848];\n        int64_t thd_offset_42924;\n        int64_t acc_42940;\n        int64_t prefix_42950;\n        bool block_new_sgm_42951;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_42900 == 0) {\n                dynamic_id_42917 = atomic_add_i32_global(&((volatile __global int *", ") global_dynid_mem_42877)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_42907)[(int64_t) 0] = dynamic_id_42917;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_42917 == num_virt_blocks_42849 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_42877)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_42917 = ((__local int32_t *) local_mem_42907)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_42918 = dynamic_id_42917 * chunk_sizze_42848 * segscan_tblock_sizze_41074;\n        sgm_idx_42919 = smod64(block_offset_42918, nR_32229);\n        boundary_42920 = sext_i64_i32(smin64(chunk_sizze_42848 * segscan_tblock_sizze_41074, nR_32229 - sgm_idx_42919));\n        segsizze_compact_42921 = sext_i64_i32(smin64(chunk_sizze_42848 * segscan_tblock_sizze_41074, nR_32229));\n        thd_offset_42924 = block_offset_42918 + sext_i32_i64(local_tid_42900);\n        // Load and map\n        {\n            for (int64_t i_42925 = 0; i_42925 < chunk_sizze_42848; i_42925++) {\n                int64_t virt_tid_42926 = thd_offset_42924 + i_42925 * segscan_tblock_sizze_41074;\n                int64_t slice_42927 = nR_32229;\n                int64_t gtid_41078 = virt_tid_42926;\n                int64_t remnant_42928 = virt_tid_42926 - gtid_41078;\n                \n                if (slt64(virt_tid_42926, nR_32229)) {\n                    int64_t eta_p_39458 = ((__global int64_t *) ext_mem_42370)[ext_42368 + gtid_41078 * ext_42367];\n                    bool lifted_lambda_res_39459 = slt64((int64_t) 0, eta_p_39458);\n                    int64_t defunc_0_f_res_39460 = btoi_bool_i64(lifted_lambda_res_39459);\n                    \n                    ((__global int64_t *) mem_42", "375)[gtid_41078] = defunc_0_f_res_39460;\n                    private_mem_42922[i_42925] = defunc_0_f_res_39460;\n                } else {\n                    private_mem_42922[i_42925] = (int64_t) 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_42929 = 0; i_42929 < chunk_sizze_42848; i_42929++) {\n                int64_t sharedIdx_42930 = sext_i32_i64(local_tid_42900) + i_42929 * segscan_tblock_sizze_41074;\n                int64_t tmp_42931 = private_mem_42922[i_42929];\n                \n                ((__local int64_t *) local_mem_42907)[sharedIdx_42930] = tmp_42931;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_42932 = 0; i_42932 < chunk_sizze_42848; i_42932++) {\n                int64_t sharedIdx_42933 = sext_i32_i64(local_tid_42900) * chunk_sizze_42848 + i_42932;\n                int64_t tmp_42934 = ((__local int64_t *) local_mem_42907)[sharedIdx_42933];\n                \n                private_mem_42922[i_42932] = tmp_42934;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_42935 = 0; i_42935 < chunk_sizze_42848 - (int64_t) 1; i_42935++) {\n                int64_t eta_p_39187;\n                int64_t eta_p_39188;\n                \n                eta_p_39187 = private_mem_42922[i_42935];\n                eta_p_39188 = private_mem_42922[i_42935 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_39189 = add64(eta_p_39187, eta_p_39188);\n                \n                private_mem_42922[i_42935 + (int64_t) 1] = defunc_0_op_res_39189;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_42936 = private_mem_42922[chunk_sizze_42848 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_42907)[sext_i32_i64(local_tid_42900)] = tmp_42936;\n            barrier(CLK_LOCAL_MEM",
                                    "_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_42937;\n            int64_t eta_p_42938;\n            int64_t eta_p_42941;\n            int64_t eta_p_42942;\n            bool ltid_in_bounds_42944 = slt64(sext_i32_i64(local_tid_42900), num_virt_threads_42850);\n            int32_t skip_threads_42945;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_42944) {\n                    eta_p_42938 = ((volatile __local int64_t *) local_mem_42907)[sext_i32_i64(local_tid_42900)];\n                    if ((local_tid_42900 - squot32(local_tid_42900, 32) * 32) == 0) {\n                        eta_p_42937 = eta_p_42938;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_42945 = 1;\n                while (slt32(skip_threads_42945, 32)) {\n                    bool thread_active_42946 = sle32(skip_threads_42945, local_tid_42900 - squot32(local_tid_42900, 32) * 32) && ltid_in_bounds_42944;\n                    \n                    if (thread_active_42946) {\n                        // read operands\n                        {\n                            eta_p_42937 = ((volatile __local int64_t *) local_mem_42907)[sext_i32_i64(local_tid_42900) - sext_i32_i64(skip_threads_42945)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_42946) {\n                            int64_t defunc_0_op_res_42939 = add64(eta_p_42937, eta_p_42938);\n                            \n                            eta_p_42937 = defunc_0_op_res_42939;\n                        }\n                    }\n                    if (sle32(wave_sizze_42902, skip_threads_42945)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_42946) {\n                        // write r", "esult\n                        {\n                            ((volatile __local int64_t *) local_mem_42907)[sext_i32_i64(local_tid_42900)] = eta_p_42937;\n                            eta_p_42938 = eta_p_42937;\n                        }\n                    }\n                    if (sle32(wave_sizze_42902, skip_threads_42945)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_42945 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_42900 - squot32(local_tid_42900, 32) * 32) == 31 && ltid_in_bounds_42944) {\n                    ((volatile __local int64_t *) local_mem_42907)[sext_i32_i64(squot32(local_tid_42900, 32))] = eta_p_42937;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_42947;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_42900, 32) == 0 && ltid_in_bounds_42944) {\n                        eta_p_42942 = ((volatile __local int64_t *) local_mem_42907)[sext_i32_i64(local_tid_42900)];\n                        if ((local_tid_42900 - squot32(local_tid_42900, 32) * 32) == 0) {\n                            eta_p_42941 = eta_p_42942;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_42947 = 1;\n                    while (slt32(skip_threads_42947, 32)) {\n                        bool thread_active_42948 = sle32(skip_threads_42947, local_tid_42900 - squot32(local_tid_42900, 32) * 32) && (squot32(local_tid_42900, 32) == 0 && ltid_in_bounds_42944);\n                        \n                        if (thre", "ad_active_42948) {\n                            // read operands\n                            {\n                                eta_p_42941 = ((volatile __local int64_t *) local_mem_42907)[sext_i32_i64(local_tid_42900) - sext_i32_i64(skip_threads_42947)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_42948) {\n                                int64_t defunc_0_op_res_42943 = add64(eta_p_42941, eta_p_42942);\n                                \n                                eta_p_42941 = defunc_0_op_res_42943;\n                            }\n                        }\n                        if (sle32(wave_sizze_42902, skip_threads_42947)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_42948) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_42907)[sext_i32_i64(local_tid_42900)] = eta_p_42941;\n                                eta_p_42942 = eta_p_42941;\n                            }\n                        }\n                        if (sle32(wave_sizze_42902, skip_threads_42947)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_42947 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_42949 = squot32(local_tid_42900, 32) == 0 || !ltid_in_bounds_42944;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_42949) {\n                        eta_p_42938 = eta_p_42937;\n                        eta_p_42937 = ((__local int64_t *) local_mem_42907)[sext_i32_i64(squot32(local_tid_42900, 32)) - (int64_t) 1];\n    ",
                                    "                }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_42949) {\n                        int64_t defunc_0_op_res_42939 = add64(eta_p_42937, eta_p_42938);\n                        \n                        eta_p_42937 = defunc_0_op_res_42939;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_42949) {\n                        ((__local int64_t *) local_mem_42907)[sext_i32_i64(local_tid_42900)] = eta_p_42937;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_42900, 32) == 0 && ltid_in_bounds_42944) {\n                    ((__local int64_t *) local_mem_42907)[sext_i32_i64(local_tid_42900)] = eta_p_42938;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_42900 == 0) {\n                acc_42940 = ((__local int64_t *) local_mem_42907)[segscan_tblock_sizze_41074 - (int64_t) 1];\n            } else {\n                acc_42940 = ((__local int64_t *) local_mem_42907)[sext_i32_i64(local_tid_42900) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_42950 = (int64_t) 0;\n        block_new_sgm_42951 = sgm_idx_42919 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_42951 && local_tid_42900 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_42875)[dynamic_id_42917] = acc_42940;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_42851)[dynamic_id_42917] = (int8_t) 2;\n                acc_42940 = (int64_t) 0;\n            }\n            if (!block_new_sgm_42951 && slt32(local_tid_42900, wave_sizze_42902)) {\n                if (local_tid_42900 == 0) {\n      ", "              ((volatile __global int64_t *) aggregates_mem_42873)[dynamic_id_42917] = acc_42940;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_42851)[dynamic_id_42917] = (int8_t) 1;\n                    \n                    int8_t tmp_42952 = ((volatile __global int8_t *) status_flags_mem_42851)[dynamic_id_42917 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_42907)[(int64_t) 0] = tmp_42952;\n                }\n                mem_fence_local();\n                \n                int8_t status_42953 = ((__local int8_t *) local_mem_42907)[(int64_t) 0];\n                \n                if (status_42953 == (int8_t) 2) {\n                    if (local_tid_42900 == 0) {\n                        prefix_42950 = ((volatile __global int64_t *) incprefixes_mem_42875)[dynamic_id_42917 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_42954 = sext_i64_i32(dynamic_id_42917 - sext_i32_i64(wave_sizze_42902));\n                    \n                    while (slt32(wave_sizze_42902 * -1, readOffset_42954)) {\n                        int32_t read_i_42955 = readOffset_42954 + local_tid_42900;\n                        int64_t aggr_42956 = (int64_t) 0;\n                        int8_t flag_42957 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_42955)) {\n                            flag_42957 = ((volatile __global int8_t *) status_flags_mem_42851)[sext_i32_i64(read_i_42955)];\n                            if (flag_42957 == (int8_t) 2) {\n                                aggr_42956 = ((volatile __global int64_t *) incprefixes_mem_42875)[sext_i32_i64(read_i_42955)];\n                            } else if (flag_42957 == (int8_t) 1) {\n                                aggr_42956 = ((volatile __global int64_t *) aggregates_mem_42873)[sext_i32_i64(read_i_42955)];\n                            }\n                        }\n ", "                       ((__local int64_t *) local_mem_42907)[(int64_t) 4 + sext_i32_i64(local_tid_42900)] = aggr_42956;\n                        ((__local int8_t *) local_mem_42907)[sext_i32_i64(local_tid_42900)] = flag_42957;\n                        flag_42957 = ((__local int8_t *) local_mem_42907)[sext_i32_i64(wave_sizze_42902) - (int64_t) 1];\n                        if (slt8(flag_42957, (int8_t) 2)) {\n                            int8_t flg_x_42961;\n                            int8_t flg_y_42962;\n                            int64_t eta_p_42958;\n                            int64_t eta_p_42959;\n                            int32_t skip_threads_42963;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_42962 = ((volatile __local int8_t *) local_mem_42907)[sext_i32_i64(local_tid_42900)];\n                                eta_p_42959 = ((volatile __local int64_t *) local_mem_42907)[(int64_t) 4 + sext_i32_i64(local_tid_42900)];\n                                if ((local_tid_42900 - squot32(local_tid_42900, 32) * 32) == 0) {\n                                    eta_p_42958 = eta_p_42959;\n                                    flg_x_42961 = flg_y_42962;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_42963 = 1;\n                                while (slt32(skip_threads_42963, 32)) {\n                                    if (sle32(skip_threads_42963, local_tid_42900 - squot32(local_tid_42900, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_42961 = ((volatile __local int8_t *) local_mem_42907)[sext_i32_i64(local_tid_42900) - sext_i32_i64(skip_threads_42963)];\n                                            eta",
                                    "_p_42958 = ((volatile __local int64_t *) local_mem_42907)[(int64_t) 4 + (sext_i32_i64(local_tid_42900) - sext_i32_i64(skip_threads_42963))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_42962 == (int8_t) 2 || flg_y_42962 == (int8_t) 0) {\n                                                flg_x_42961 = flg_y_42962;\n                                                eta_p_42958 = eta_p_42959;\n                                            } else {\n                                                int64_t defunc_0_op_res_42960 = add64(eta_p_42958, eta_p_42959);\n                                                \n                                                eta_p_42958 = defunc_0_op_res_42960;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_42907)[sext_i32_i64(local_tid_42900)] = flg_x_42961;\n                                            flg_y_42962 = flg_x_42961;\n                                            ((volatile __local int64_t *) local_mem_42907)[(int64_t) 4 + sext_i32_i64(local_tid_42900)] = eta_p_42958;\n                                            eta_p_42959 = eta_p_42958;\n                                        }\n                                    }\n                                    skip_threads_42963 *= 2;\n                                }\n                            }\n                        }\n                        flag_42957 = ((__local int8_t *) local_mem_42907)[sext_i32_i64(wave_sizze_42902) - (int64_t) 1];\n                        aggr_42956 = ((__local int64_t *) local_mem_42907)[(int64_t) 4 + (sext_i32_i64(wave_sizze_42902) - (int64_t) 1)];\n                        if (flag_42957 == (int8_t) 2)", " {\n                            readOffset_42954 = wave_sizze_42902 * -1;\n                        } else if (flag_42957 == (int8_t) 1) {\n                            readOffset_42954 -= wave_sizze_42902;\n                        }\n                        if (slt8((int8_t) 0, flag_42957)) {\n                            int64_t eta_p_42964 = aggr_42956;\n                            int64_t eta_p_42965 = prefix_42950;\n                            int64_t defunc_0_op_res_42966 = add64(eta_p_42964, eta_p_42965);\n                            \n                            prefix_42950 = defunc_0_op_res_42966;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_42900 == 0) {\n                    if (boundary_42920 == sext_i64_i32(segscan_tblock_sizze_41074 * chunk_sizze_42848)) {\n                        int64_t eta_p_42967 = prefix_42950;\n                        int64_t eta_p_42968 = acc_42940;\n                        int64_t defunc_0_op_res_42969 = add64(eta_p_42967, eta_p_42968);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_42875)[dynamic_id_42917] = defunc_0_op_res_42969;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_42851)[dynamic_id_42917] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_42907)[(int64_t) 4] = prefix_42950;\n                    acc_42940 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_42917 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_42950 = ((__local int64_t *) local_mem_42907)[(int64_t) 4];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_42970;\n            int64_t eta_p_42971;\n            int64_t eta_p_42973 = prefix_42950;\n            int64_t eta_p_42974 = acc_42", "940;\n            \n            if (slt32(local_tid_42900 * chunk_sizze_32b_42904, boundary_42920) && !block_new_sgm_42951) {\n                int64_t defunc_0_op_res_42975 = add64(eta_p_42973, eta_p_42974);\n                \n                eta_p_42970 = defunc_0_op_res_42975;\n            } else {\n                eta_p_42970 = acc_42940;\n            }\n            \n            int32_t stopping_point_42976 = segsizze_compact_42921 - srem32(local_tid_42900 * chunk_sizze_32b_42904 - 1 + segsizze_compact_42921 - boundary_42920, segsizze_compact_42921);\n            \n            for (int64_t i_42977 = 0; i_42977 < chunk_sizze_42848; i_42977++) {\n                if (slt32(sext_i64_i32(i_42977), stopping_point_42976 - 1)) {\n                    eta_p_42971 = private_mem_42922[i_42977];\n                    \n                    int64_t defunc_0_op_res_42972 = add64(eta_p_42970, eta_p_42971);\n                    \n                    private_mem_42922[i_42977] = defunc_0_op_res_42972;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_42978 = 0; i_42978 < chunk_sizze_42848; i_42978++) {\n                int64_t sharedIdx_42979 = sext_i32_i64(local_tid_42900) * chunk_sizze_42848 + i_42978;\n                int64_t tmp_42980 = private_mem_42922[i_42978];\n                \n                ((__local int64_t *) local_mem_42907)[sharedIdx_42979] = tmp_42980;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_42981 = 0; i_42981 < chunk_sizze_42848; i_42981++) {\n                int64_t flat_idx_42982 = thd_offset_42924 + i_42981 * segscan_tblock_sizze_41074;\n                int64_t slice_42983 = nR_32229;\n                int64_t gtid_41078 = flat_idx_42982;\n                int64_t remnant_42984 = flat_idx_42982 - gtid_41078;\n                \n                if (slt64(flat_idx_42982, nR_32229)) {\n                    int64_t tmp_42985 = ((__local int64_t",
                                    " *) local_mem_42907)[flat_idx_42982 - block_offset_42918];\n                    \n                    ((__global int64_t *) mem_42373)[gtid_41078] = tmp_42985;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_41074\n    #undef chunk_sizze_42848\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_floatzisegscan_41095_dim1, 1, 1)\nvoid inner_SMJ_floatzisegscan_41095(__global int *global_failure, int64_t m_39200, int64_t num_tblocks_41092, int64_t num_virt_blocks_43006, int64_t num_virt_threads_43007, __global unsigned char *mem_42377, __global unsigned char *mem_42387, __global unsigned char *mem_42389, __global unsigned char *mem_42391, __global unsigned char *status_flags_mem_43008, __global unsigned char *aggregates_mem_43010, __global unsigned char *incprefixes_mem_43012, __global unsigned char *aggregates_mem_43014, __global unsigned char *incprefixes_mem_43016, __global unsigned char *global_dynid_mem_43018)\n{\n    #define segscan_tblock_sizze_41090 (inner_SMJ_floatzisegscan_41095zisegscan_tblock_sizze_41090)\n    #define chunk_sizze_43005 (inner_SMJ_floatzisegscan_41095zichunk_sizze_43005)\n    \n    volatile __local unsigned char *local_mem_43030_backing_0 = &shared_mem[0];\n    const int64_t local_mem_43030_backing_0_offset = 0 + (smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_41090, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_41090), smax64(chunk_sizze_43005 * segscan_tblock_sizze_41090 * (int64_t) 8, chunk_sizze_43005 * segscan_tblock_sizze_41090 * (int64_t) 8)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_41090, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_41090), smax64(chunk_sizze_43005 * segscan_tblock_sizze_41090 * (int64_t) 8, chunk_sizze_43005 * segscan_tblock_sizze_41090 * (int64_t) 8)), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n    ", "    return;\n    \n    int32_t local_tid_43021;\n    int32_t tblock_sizze_43024;\n    int32_t wave_sizze_43023;\n    int32_t block_id_43022;\n    int32_t global_tid_43020;\n    int64_t phys_tid_41095;\n    int32_t chunk_sizze_32b_43025;\n    int64_t byte_offsets_43026;\n    int64_t byte_offsets_43027;\n    int64_t warp_byte_offset_43028;\n    int64_t warp_byte_offset_43029;\n    __local unsigned char *local_mem_43030;\n    int64_t trans_arr_len_43031;\n    int64_t phys_block_id_43040;\n    int64_t virtloop_bound_43041;\n    \n    local_tid_43021 = get_local_id(0);\n    tblock_sizze_43024 = get_local_size(0);\n    wave_sizze_43023 = LOCKSTEP_WIDTH;\n    block_id_43022 = get_tblock_id(0);\n    global_tid_43020 = block_id_43022 * tblock_sizze_43024 + local_tid_43021;\n    phys_tid_41095 = sext_i32_i64(global_tid_43020);\n    chunk_sizze_32b_43025 = sext_i64_i32(chunk_sizze_43005);\n    byte_offsets_43026 = segscan_tblock_sizze_41090 * (int64_t) 8;\n    byte_offsets_43027 = sdiv_up64(byte_offsets_43026, (int64_t) 8) * (int64_t) 8 + segscan_tblock_sizze_41090 * (int64_t) 8;\n    warp_byte_offset_43028 = (int64_t) 288;\n    warp_byte_offset_43029 = sdiv_up64(warp_byte_offset_43028, (int64_t) 8) * (int64_t) 8 + (int64_t) 256;\n    // Allocate reusable shared memory\n    { }\n    local_mem_43030 = (__local unsigned char *) local_mem_43030_backing_0;\n    trans_arr_len_43031 = chunk_sizze_43005 * segscan_tblock_sizze_41090;\n    phys_block_id_43040 = get_tblock_id(0);\n    virtloop_bound_43041 = sdiv_up64(num_virt_blocks_43006 - phys_block_id_43040, num_tblocks_41092);\n    for (int64_t virtloop_i_43042 = 0; virtloop_i_43042 < virtloop_bound_43041; virtloop_i_43042++) {\n        int64_t dynamic_id_43043;\n        int64_t block_offset_43044;\n        int64_t sgm_idx_43045;\n        int32_t boundary_43046;\n        int32_t segsizze_compact_43047;\n        int64_t private_mem_43048[chunk_sizze_43005];\n        int64_t private_mem_43050[chunk_sizze_43005];\n        int64_t thd_offset_43052;\n        int64_t acc_43078;\n   ", "     int64_t acc_43079;\n        int64_t prefix_43092;\n        int64_t prefix_43093;\n        bool block_new_sgm_43094;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_43021 == 0) {\n                dynamic_id_43043 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_43018)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_43030)[(int64_t) 0] = dynamic_id_43043;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_43043 == num_virt_blocks_43006 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_43018)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_43043 = ((__local int32_t *) local_mem_43030)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_43044 = dynamic_id_43043 * chunk_sizze_43005 * segscan_tblock_sizze_41090;\n        sgm_idx_43045 = smod64(block_offset_43044, m_39200);\n        boundary_43046 = sext_i64_i32(smin64(chunk_sizze_43005 * segscan_tblock_sizze_41090, m_39200 - sgm_idx_43045));\n        segsizze_compact_43047 = sext_i64_i32(smin64(chunk_sizze_43005 * segscan_tblock_sizze_41090, m_39200));\n        thd_offset_43052 = block_offset_43044 + sext_i32_i64(local_tid_43021);\n        // Load and map\n        {\n            for (int64_t i_43053 = 0; i_43053 < chunk_sizze_43005; i_43053++) {\n                int64_t virt_tid_43054 = thd_offset_43052 + i_43053 * segscan_tblock_sizze_41090;\n                int64_t slice_43055 = m_39200;\n                int64_t gtid_41094 = virt_tid_43054;\n                int64_t remnant_43056 = virt_tid_43054 - gtid_41094;\n                \n                if (slt64(virt_tid_43054, m_39200)) {\n                    int64_t x_39463 = ((",
                                    "__global int64_t *) mem_42377)[gtid_41094];\n                    bool lifted_lambda_res_39465 = slt64((int64_t) 1, x_39463);\n                    int64_t defunc_0_f_res_39466 = btoi_bool_i64(lifted_lambda_res_39465);\n                    \n                    ((__global int64_t *) mem_42391)[gtid_41094] = defunc_0_f_res_39466;\n                    private_mem_43048[i_43053] = x_39463;\n                    private_mem_43050[i_43053] = defunc_0_f_res_39466;\n                } else {\n                    private_mem_43048[i_43053] = (int64_t) 0;\n                    private_mem_43050[i_43053] = (int64_t) 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_43057 = 0; i_43057 < chunk_sizze_43005; i_43057++) {\n                int64_t sharedIdx_43058 = sext_i32_i64(local_tid_43021) + i_43057 * segscan_tblock_sizze_41090;\n                int64_t tmp_43059 = private_mem_43048[i_43057];\n                \n                ((__local int64_t *) local_mem_43030)[sharedIdx_43058] = tmp_43059;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_43060 = 0; i_43060 < chunk_sizze_43005; i_43060++) {\n                int64_t sharedIdx_43061 = sext_i32_i64(local_tid_43021) * chunk_sizze_43005 + i_43060;\n                int64_t tmp_43062 = ((__local int64_t *) local_mem_43030)[sharedIdx_43061];\n                \n                private_mem_43048[i_43060] = tmp_43062;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_43063 = 0; i_43063 < chunk_sizze_43005; i_43063++) {\n                int64_t sharedIdx_43064 = sext_i32_i64(local_tid_43021) + i_43063 * segscan_tblock_sizze_41090;\n                int64_t tmp_43065 = private_mem_43050[i_43063];\n                \n                ((__local int64_t *) local_mem_43030)[sharedIdx_43064] = tmp_43065;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_43066 = 0; i_4306", "6 < chunk_sizze_43005; i_43066++) {\n                int64_t sharedIdx_43067 = sext_i32_i64(local_tid_43021) * chunk_sizze_43005 + i_43066;\n                int64_t tmp_43068 = ((__local int64_t *) local_mem_43030)[sharedIdx_43067];\n                \n                private_mem_43050[i_43066] = tmp_43068;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_43069 = 0; i_43069 < chunk_sizze_43005 - (int64_t) 1; i_43069++) {\n                int64_t eta_p_39237;\n                int64_t eta_p_39238;\n                \n                eta_p_39237 = private_mem_43048[i_43069];\n                eta_p_39238 = private_mem_43048[i_43069 + (int64_t) 1];\n                \n                int64_t eta_p_39330;\n                int64_t eta_p_39331;\n                \n                eta_p_39330 = private_mem_43050[i_43069];\n                eta_p_39331 = private_mem_43050[i_43069 + (int64_t) 1];\n                \n                int64_t lifted_lambda_res_39239 = add64(eta_p_39237, eta_p_39238);\n                int64_t defunc_0_op_res_39332 = add64(eta_p_39330, eta_p_39331);\n                \n                private_mem_43048[i_43069 + (int64_t) 1] = lifted_lambda_res_39239;\n                private_mem_43050[i_43069 + (int64_t) 1] = defunc_0_op_res_39332;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_43070 = private_mem_43048[chunk_sizze_43005 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_43030)[sext_i32_i64(local_tid_43021)] = tmp_43070;\n            \n            int64_t tmp_43071 = private_mem_43050[chunk_sizze_43005 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + sext_i32_i64(local_tid_43021)] = tmp_43071;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_43072;\n            int64_t eta_", "p_43073;\n            int64_t eta_p_43074;\n            int64_t eta_p_43075;\n            int64_t eta_p_43080;\n            int64_t eta_p_43081;\n            int64_t eta_p_43082;\n            int64_t eta_p_43083;\n            bool ltid_in_bounds_43086 = slt64(sext_i32_i64(local_tid_43021), num_virt_threads_43007);\n            int32_t skip_threads_43087;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_43086) {\n                    eta_p_43074 = ((volatile __local int64_t *) local_mem_43030)[sext_i32_i64(local_tid_43021)];\n                    eta_p_43075 = ((volatile __local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + sext_i32_i64(local_tid_43021)];\n                    if ((local_tid_43021 - squot32(local_tid_43021, 32) * 32) == 0) {\n                        eta_p_43072 = eta_p_43074;\n                        eta_p_43073 = eta_p_43075;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_43087 = 1;\n                while (slt32(skip_threads_43087, 32)) {\n                    bool thread_active_43088 = sle32(skip_threads_43087, local_tid_43021 - squot32(local_tid_43021, 32) * 32) && ltid_in_bounds_43086;\n                    \n                    if (thread_active_43088) {\n                        // read operands\n                        {\n                            eta_p_43072 = ((volatile __local int64_t *) local_mem_43030)[sext_i32_i64(local_tid_43021) - sext_i32_i64(skip_threads_43087)];\n                            eta_p_43073 = ((volatile __local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + (sext_i32_i64(local_tid_43021) - sext_i32_i64(skip_threads_43087))];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_43088) {\n                            int64_t lifted_lambda_",
                                    "res_43076 = add64(eta_p_43072, eta_p_43074);\n                            int64_t defunc_0_op_res_43077 = add64(eta_p_43073, eta_p_43075);\n                            \n                            eta_p_43072 = lifted_lambda_res_43076;\n                            eta_p_43073 = defunc_0_op_res_43077;\n                        }\n                    }\n                    if (sle32(wave_sizze_43023, skip_threads_43087)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_43088) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_43030)[sext_i32_i64(local_tid_43021)] = eta_p_43072;\n                            eta_p_43074 = eta_p_43072;\n                            ((volatile __local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + sext_i32_i64(local_tid_43021)] = eta_p_43073;\n                            eta_p_43075 = eta_p_43073;\n                        }\n                    }\n                    if (sle32(wave_sizze_43023, skip_threads_43087)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_43087 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_43021 - squot32(local_tid_43021, 32) * 32) == 31 && ltid_in_bounds_43086) {\n                    ((volatile __local int64_t *) local_mem_43030)[sext_i32_i64(squot32(local_tid_43021, 32))] = eta_p_43072;\n                    ((volatile __local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + sext_i32_i64(squot32(local_tid_43021, 32))] = eta_p_43073;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n              ", "  int32_t skip_threads_43089;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_43021, 32) == 0 && ltid_in_bounds_43086) {\n                        eta_p_43082 = ((volatile __local int64_t *) local_mem_43030)[sext_i32_i64(local_tid_43021)];\n                        eta_p_43083 = ((volatile __local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + sext_i32_i64(local_tid_43021)];\n                        if ((local_tid_43021 - squot32(local_tid_43021, 32) * 32) == 0) {\n                            eta_p_43080 = eta_p_43082;\n                            eta_p_43081 = eta_p_43083;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_43089 = 1;\n                    while (slt32(skip_threads_43089, 32)) {\n                        bool thread_active_43090 = sle32(skip_threads_43089, local_tid_43021 - squot32(local_tid_43021, 32) * 32) && (squot32(local_tid_43021, 32) == 0 && ltid_in_bounds_43086);\n                        \n                        if (thread_active_43090) {\n                            // read operands\n                            {\n                                eta_p_43080 = ((volatile __local int64_t *) local_mem_43030)[sext_i32_i64(local_tid_43021) - sext_i32_i64(skip_threads_43089)];\n                                eta_p_43081 = ((volatile __local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + (sext_i32_i64(local_tid_43021) - sext_i32_i64(skip_threads_43089))];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_43090) {\n                                int64_t lifted_lambda_res_43084 = add64(eta_p_43080, eta_p_43082);\n                                int64_t defunc_0_op_res_43085 = add64(eta_p_43081,", " eta_p_43083);\n                                \n                                eta_p_43080 = lifted_lambda_res_43084;\n                                eta_p_43081 = defunc_0_op_res_43085;\n                            }\n                        }\n                        if (sle32(wave_sizze_43023, skip_threads_43089)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_43090) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_43030)[sext_i32_i64(local_tid_43021)] = eta_p_43080;\n                                eta_p_43082 = eta_p_43080;\n                                ((volatile __local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + sext_i32_i64(local_tid_43021)] = eta_p_43081;\n                                eta_p_43083 = eta_p_43081;\n                            }\n                        }\n                        if (sle32(wave_sizze_43023, skip_threads_43089)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_43089 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_43091 = squot32(local_tid_43021, 32) == 0 || !ltid_in_bounds_43086;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_43091) {\n                        eta_p_43074 = eta_p_43072;\n                        eta_p_43075 = eta_p_43073;\n                        eta_p_43072 = ((__local int64_t *) local_mem_43030)[sext_i32_i64(squot32(local_tid_43021, 32)) - (int64_t) 1];\n                        eta_p_43073 = ((__local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + (sext_i32_i64(squot32(local_tid_43021, 32)) - (int64_t",
                                    ") 1)];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_43091) {\n                        int64_t lifted_lambda_res_43076 = add64(eta_p_43072, eta_p_43074);\n                        int64_t defunc_0_op_res_43077 = add64(eta_p_43073, eta_p_43075);\n                        \n                        eta_p_43072 = lifted_lambda_res_43076;\n                        eta_p_43073 = defunc_0_op_res_43077;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_43091) {\n                        ((__local int64_t *) local_mem_43030)[sext_i32_i64(local_tid_43021)] = eta_p_43072;\n                        ((__local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + sext_i32_i64(local_tid_43021)] = eta_p_43073;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_43021, 32) == 0 && ltid_in_bounds_43086) {\n                    ((__local int64_t *) local_mem_43030)[sext_i32_i64(local_tid_43021)] = eta_p_43074;\n                    ((__local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + sext_i32_i64(local_tid_43021)] = eta_p_43075;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_43021 == 0) {\n                acc_43078 = ((__local int64_t *) local_mem_43030)[segscan_tblock_sizze_41090 - (int64_t) 1];\n                acc_43079 = ((__local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + (segscan_tblock_sizze_41090 - (int64_t) 1)];\n            } else {\n                acc_43078 = ((__local int64_t *) local_mem_43030)[sext_i32_i64(local_tid_43021) - (int64_t) 1];\n                acc_43079 = ((__local int64_t *) local_mem_43030)[squot64(", "byte_offsets_43026, (int64_t) 8) + (sext_i32_i64(local_tid_43021) - (int64_t) 1)];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_43092 = (int64_t) 0;\n        prefix_43093 = (int64_t) 0;\n        block_new_sgm_43094 = sgm_idx_43045 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_43094 && local_tid_43021 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_43012)[dynamic_id_43043] = acc_43078;\n                ((volatile __global int64_t *) incprefixes_mem_43016)[dynamic_id_43043] = acc_43079;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_43008)[dynamic_id_43043] = (int8_t) 2;\n                acc_43078 = (int64_t) 0;\n                acc_43079 = (int64_t) 0;\n            }\n            if (!block_new_sgm_43094 && slt32(local_tid_43021, wave_sizze_43023)) {\n                if (local_tid_43021 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_43010)[dynamic_id_43043] = acc_43078;\n                    ((volatile __global int64_t *) aggregates_mem_43014)[dynamic_id_43043] = acc_43079;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_43008)[dynamic_id_43043] = (int8_t) 1;\n                    \n                    int8_t tmp_43095 = ((volatile __global int8_t *) status_flags_mem_43008)[dynamic_id_43043 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_43030)[(int64_t) 0] = tmp_43095;\n                }\n                mem_fence_local();\n                \n                int8_t status_43096 = ((__local int8_t *) local_mem_43030)[(int64_t) 0];\n                \n                if (status_43096 == (int8_t) 2) {\n                    if (local_tid_43021 == 0) {\n                        prefix_43092 = ((volatile __global int64_t *) incprefixes_mem_43012)[dynamic_id_43043 - (int64_t) 1];\n                        prefix_43093 = (", "(volatile __global int64_t *) incprefixes_mem_43016)[dynamic_id_43043 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_43097 = sext_i64_i32(dynamic_id_43043 - sext_i32_i64(wave_sizze_43023));\n                    \n                    while (slt32(wave_sizze_43023 * -1, readOffset_43097)) {\n                        int32_t read_i_43098 = readOffset_43097 + local_tid_43021;\n                        int64_t aggr_43099 = (int64_t) 0;\n                        int64_t aggr_43100 = (int64_t) 0;\n                        int8_t flag_43101 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_43098)) {\n                            flag_43101 = ((volatile __global int8_t *) status_flags_mem_43008)[sext_i32_i64(read_i_43098)];\n                            if (flag_43101 == (int8_t) 2) {\n                                aggr_43099 = ((volatile __global int64_t *) incprefixes_mem_43012)[sext_i32_i64(read_i_43098)];\n                                aggr_43100 = ((volatile __global int64_t *) incprefixes_mem_43016)[sext_i32_i64(read_i_43098)];\n                            } else if (flag_43101 == (int8_t) 1) {\n                                aggr_43099 = ((volatile __global int64_t *) aggregates_mem_43010)[sext_i32_i64(read_i_43098)];\n                                aggr_43100 = ((volatile __global int64_t *) aggregates_mem_43014)[sext_i32_i64(read_i_43098)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_43030)[(int64_t) 4 + sext_i32_i64(local_tid_43021)] = aggr_43099;\n                        ((__local int64_t *) local_mem_43030)[squot64(warp_byte_offset_43028, (int64_t) 8) + sext_i32_i64(local_tid_43021)] = aggr_43100;\n                        ((__local int8_t *) local_mem_43030)[sext_i32_i64(local_tid_43021)] = flag_43101;\n                        flag_43101 = ((__local int8_t *) local_mem_43030)[sext_i32_i64(wave_sizze_43023) - (int64_t) 1];\n    ",
                                    "                    if (slt8(flag_43101, (int8_t) 2)) {\n                            int8_t flg_x_43108;\n                            int8_t flg_y_43109;\n                            int64_t eta_p_43102;\n                            int64_t eta_p_43103;\n                            int64_t eta_p_43104;\n                            int64_t eta_p_43105;\n                            int32_t skip_threads_43110;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_43109 = ((volatile __local int8_t *) local_mem_43030)[sext_i32_i64(local_tid_43021)];\n                                eta_p_43104 = ((volatile __local int64_t *) local_mem_43030)[(int64_t) 4 + sext_i32_i64(local_tid_43021)];\n                                eta_p_43105 = ((volatile __local int64_t *) local_mem_43030)[squot64(warp_byte_offset_43028, (int64_t) 8) + sext_i32_i64(local_tid_43021)];\n                                if ((local_tid_43021 - squot32(local_tid_43021, 32) * 32) == 0) {\n                                    eta_p_43102 = eta_p_43104;\n                                    eta_p_43103 = eta_p_43105;\n                                    flg_x_43108 = flg_y_43109;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_43110 = 1;\n                                while (slt32(skip_threads_43110, 32)) {\n                                    if (sle32(skip_threads_43110, local_tid_43021 - squot32(local_tid_43021, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_43108 = ((volatile __local int8_t *) local_mem_43030)[sext_i32_i64(local_tid_43021) - sext_i32_i64(skip_threads_43110)];\n                                            eta_p_43102 = ((volat", "ile __local int64_t *) local_mem_43030)[(int64_t) 4 + (sext_i32_i64(local_tid_43021) - sext_i32_i64(skip_threads_43110))];\n                                            eta_p_43103 = ((volatile __local int64_t *) local_mem_43030)[squot64(warp_byte_offset_43028, (int64_t) 8) + (sext_i32_i64(local_tid_43021) - sext_i32_i64(skip_threads_43110))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_43109 == (int8_t) 2 || flg_y_43109 == (int8_t) 0) {\n                                                flg_x_43108 = flg_y_43109;\n                                                eta_p_43102 = eta_p_43104;\n                                                eta_p_43103 = eta_p_43105;\n                                            } else {\n                                                int64_t lifted_lambda_res_43106 = add64(eta_p_43102, eta_p_43104);\n                                                int64_t defunc_0_op_res_43107 = add64(eta_p_43103, eta_p_43105);\n                                                \n                                                eta_p_43102 = lifted_lambda_res_43106;\n                                                eta_p_43103 = defunc_0_op_res_43107;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_43030)[sext_i32_i64(local_tid_43021)] = flg_x_43108;\n                                            flg_y_43109 = flg_x_43108;\n                                            ((volatile __local int64_t *) local_mem_43030)[(int64_t) 4 + sext_i32_i64(local_tid_43021)] = eta_p_43102;\n                                            eta_p_43104 = eta_p_43102;\n                                            ((volatile __local ", "int64_t *) local_mem_43030)[squot64(warp_byte_offset_43028, (int64_t) 8) + sext_i32_i64(local_tid_43021)] = eta_p_43103;\n                                            eta_p_43105 = eta_p_43103;\n                                        }\n                                    }\n                                    skip_threads_43110 *= 2;\n                                }\n                            }\n                        }\n                        flag_43101 = ((__local int8_t *) local_mem_43030)[sext_i32_i64(wave_sizze_43023) - (int64_t) 1];\n                        aggr_43099 = ((__local int64_t *) local_mem_43030)[(int64_t) 4 + (sext_i32_i64(wave_sizze_43023) - (int64_t) 1)];\n                        aggr_43100 = ((__local int64_t *) local_mem_43030)[squot64(warp_byte_offset_43028, (int64_t) 8) + (sext_i32_i64(wave_sizze_43023) - (int64_t) 1)];\n                        if (flag_43101 == (int8_t) 2) {\n                            readOffset_43097 = wave_sizze_43023 * -1;\n                        } else if (flag_43101 == (int8_t) 1) {\n                            readOffset_43097 -= wave_sizze_43023;\n                        }\n                        if (slt8((int8_t) 0, flag_43101)) {\n                            int64_t eta_p_43111 = aggr_43099;\n                            int64_t eta_p_43112 = aggr_43100;\n                            int64_t eta_p_43113 = prefix_43092;\n                            int64_t eta_p_43114 = prefix_43093;\n                            int64_t lifted_lambda_res_43115 = add64(eta_p_43111, eta_p_43113);\n                            int64_t defunc_0_op_res_43116 = add64(eta_p_43112, eta_p_43114);\n                            \n                            prefix_43092 = lifted_lambda_res_43115;\n                            prefix_43093 = defunc_0_op_res_43116;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_43021 == 0) {\n                    if (boundary_43046 == sext_i64",
                                    "_i32(segscan_tblock_sizze_41090 * chunk_sizze_43005)) {\n                        int64_t eta_p_43117 = prefix_43092;\n                        int64_t eta_p_43118 = prefix_43093;\n                        int64_t eta_p_43119 = acc_43078;\n                        int64_t eta_p_43120 = acc_43079;\n                        int64_t lifted_lambda_res_43121 = add64(eta_p_43117, eta_p_43119);\n                        int64_t defunc_0_op_res_43122 = add64(eta_p_43118, eta_p_43120);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_43012)[dynamic_id_43043] = lifted_lambda_res_43121;\n                        ((volatile __global int64_t *) incprefixes_mem_43016)[dynamic_id_43043] = defunc_0_op_res_43122;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_43008)[dynamic_id_43043] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_43030)[(int64_t) 4] = prefix_43092;\n                    ((__local int64_t *) local_mem_43030)[squot64(warp_byte_offset_43028, (int64_t) 8)] = prefix_43093;\n                    acc_43078 = (int64_t) 0;\n                    acc_43079 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_43043 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_43092 = ((__local int64_t *) local_mem_43030)[(int64_t) 4];\n                prefix_43093 = ((__local int64_t *) local_mem_43030)[squot64(warp_byte_offset_43028, (int64_t) 8)];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_43123;\n            int64_t eta_p_43125;\n            int64_t eta_p_43129 = prefix_43092;\n            int64_t eta_p_43131 = acc_43078;\n            int64_t eta_p_43124;\n            int64_t eta_p_43126;\n            int64_t eta_p_43130 = prefix_43093;\n            int64_t eta_p_43132 = acc_43079;\n            \n            if (", "slt32(local_tid_43021 * chunk_sizze_32b_43025, boundary_43046) && !block_new_sgm_43094) {\n                int64_t lifted_lambda_res_43133 = add64(eta_p_43129, eta_p_43131);\n                int64_t defunc_0_op_res_43134 = add64(eta_p_43130, eta_p_43132);\n                \n                eta_p_43123 = lifted_lambda_res_43133;\n                eta_p_43124 = defunc_0_op_res_43134;\n            } else {\n                eta_p_43123 = acc_43078;\n                eta_p_43124 = acc_43079;\n            }\n            \n            int32_t stopping_point_43135 = segsizze_compact_43047 - srem32(local_tid_43021 * chunk_sizze_32b_43025 - 1 + segsizze_compact_43047 - boundary_43046, segsizze_compact_43047);\n            \n            for (int64_t i_43136 = 0; i_43136 < chunk_sizze_43005; i_43136++) {\n                if (slt32(sext_i64_i32(i_43136), stopping_point_43135 - 1)) {\n                    eta_p_43125 = private_mem_43048[i_43136];\n                    eta_p_43126 = private_mem_43050[i_43136];\n                    \n                    int64_t lifted_lambda_res_43127 = add64(eta_p_43123, eta_p_43125);\n                    int64_t defunc_0_op_res_43128 = add64(eta_p_43124, eta_p_43126);\n                    \n                    private_mem_43048[i_43136] = lifted_lambda_res_43127;\n                    private_mem_43050[i_43136] = defunc_0_op_res_43128;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_43137 = 0; i_43137 < chunk_sizze_43005; i_43137++) {\n                int64_t sharedIdx_43138 = sext_i32_i64(local_tid_43021) * chunk_sizze_43005 + i_43137;\n                int64_t tmp_43139 = private_mem_43048[i_43137];\n                \n                ((__local int64_t *) local_mem_43030)[sharedIdx_43138] = tmp_43139;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_43140 = 0; i_43140 < chunk_sizze_43005; i_43140++) {\n                int64_t flat_", "idx_43141 = thd_offset_43052 + i_43140 * segscan_tblock_sizze_41090;\n                int64_t slice_43142 = m_39200;\n                int64_t gtid_41094 = flat_idx_43141;\n                int64_t remnant_43143 = flat_idx_43141 - gtid_41094;\n                \n                if (slt64(flat_idx_43141, m_39200)) {\n                    int64_t tmp_43144 = ((__local int64_t *) local_mem_43030)[flat_idx_43141 - block_offset_43044];\n                    \n                    ((__global int64_t *) mem_42387)[gtid_41094] = tmp_43144;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_43145 = 0; i_43145 < chunk_sizze_43005; i_43145++) {\n                int64_t sharedIdx_43146 = sext_i32_i64(local_tid_43021) * chunk_sizze_43005 + i_43145;\n                int64_t tmp_43147 = private_mem_43050[i_43145];\n                \n                ((__local int64_t *) local_mem_43030)[sharedIdx_43146] = tmp_43147;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_43148 = 0; i_43148 < chunk_sizze_43005; i_43148++) {\n                int64_t flat_idx_43149 = thd_offset_43052 + i_43148 * segscan_tblock_sizze_41090;\n                int64_t slice_43150 = m_39200;\n                int64_t gtid_41094 = flat_idx_43149;\n                int64_t remnant_43151 = flat_idx_43149 - gtid_41094;\n                \n                if (slt64(flat_idx_43149, m_39200)) {\n                    int64_t tmp_43152 = ((__local int64_t *) local_mem_43030)[flat_idx_43149 - block_offset_43044];\n                    \n                    ((__global int64_t *) mem_42389)[gtid_41094] = tmp_43152;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_41090\n    #undef chunk_sizze_43005\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzigpuseq_42730_dim1, 1, 1)\nvoid inner_SMJ_intzigpuseq_42730(__global int *global_failure, __global unsigned char *tS_mem_42200, __global unsigne",
                                    "d char *mem_42207)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42732;\n    int32_t tblock_sizze_42735;\n    int32_t wave_sizze_42734;\n    int32_t block_id_42733;\n    int32_t global_tid_42731;\n    int64_t tid_42730;\n    int32_t x_42152;\n    \n    local_tid_42732 = get_local_id(0);\n    tblock_sizze_42735 = get_local_size(0);\n    wave_sizze_42734 = LOCKSTEP_WIDTH;\n    block_id_42733 = get_tblock_id(0);\n    global_tid_42731 = block_id_42733 * tblock_sizze_42735 + local_tid_42732;\n    tid_42730 = sext_i32_i64(global_tid_42731);\n    x_42152 = ((__global int32_t *) tS_mem_42200)[(int64_t) 0];\n    ((__global int32_t *) mem_42207)[(int64_t) 0] = x_42152;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzigpuseq_42756_dim1, 1, 1)\nvoid inner_SMJ_intzigpuseq_42756(__global int *global_failure, int64_t tmp_39078, __global unsigned char *tS_mem_42200, __global unsigned char *mem_42210)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42758;\n    int32_t tblock_sizze_42761;\n    int32_t wave_sizze_42760;\n    int32_t block_id_42759;\n    int32_t global_tid_42757;\n    int64_t tid_42756;\n    int32_t x_42156;\n    \n    local_tid_42758 = get_local_id(0);\n    tblock_sizze_42761 = get_local_size(0);\n    wave_sizze_42760 = LOCKSTEP_WIDTH;\n    block_id_42759 = get_tblock_id(0);\n    global_tid_42757 = block_id_42759 * tblock_sizze_42761 + local_tid_42758;\n    tid_42756 = sext_i32_i64(global_tid_42757);\n    x_42156 = ((__global int32_t *) tS_mem_42200)[tmp_39078];\n    ((__global int32_t *) mem_42210)[(int64_t) 0] = x_42156;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzigpuseq_42772_dim1, 1, 1)\nvoid inner_SMJ_intzigpuseq_42772(__global int *global_failure, int64_t start_39100, int64_t i_p_m_t_s_39106, __global unsigned char *tR_mem_42199, __global unsigned char *mem_42218, __global unsigned char *mem_42219)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42774;\n    int32_t tblock_si", "zze_42777;\n    int32_t wave_sizze_42776;\n    int32_t block_id_42775;\n    int32_t global_tid_42773;\n    int64_t tid_42772;\n    int32_t r_max_42160;\n    int32_t r_min_42163;\n    \n    local_tid_42774 = get_local_id(0);\n    tblock_sizze_42777 = get_local_size(0);\n    wave_sizze_42776 = LOCKSTEP_WIDTH;\n    block_id_42775 = get_tblock_id(0);\n    global_tid_42773 = block_id_42775 * tblock_sizze_42777 + local_tid_42774;\n    tid_42772 = sext_i32_i64(global_tid_42773);\n    r_max_42160 = ((__global int32_t *) tR_mem_42199)[i_p_m_t_s_39106];\n    r_min_42163 = ((__global int32_t *) tR_mem_42199)[start_39100];\n    ((__global int32_t *) mem_42218)[(int64_t) 0] = r_max_42160;\n    ((__global int32_t *) mem_42219)[(int64_t) 0] = r_min_42163;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzigpuseq_42778_dim1, 1, 1)\nvoid inner_SMJ_intzigpuseq_42778(__global int *global_failure, __global unsigned char *mem_42219, __global unsigned char *ext_mem_42220, __global unsigned char *mem_42222)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42780;\n    int32_t tblock_sizze_42783;\n    int32_t wave_sizze_42782;\n    int32_t block_id_42781;\n    int32_t global_tid_42779;\n    int64_t tid_42778;\n    int32_t s_max_42165;\n    int32_t r_min_42166;\n    bool defunc_0_gt_res_42167;\n    \n    local_tid_42780 = get_local_id(0);\n    tblock_sizze_42783 = get_local_size(0);\n    wave_sizze_42782 = LOCKSTEP_WIDTH;\n    block_id_42781 = get_tblock_id(0);\n    global_tid_42779 = block_id_42781 * tblock_sizze_42783 + local_tid_42780;\n    tid_42778 = sext_i32_i64(global_tid_42779);\n    s_max_42165 = ((__global int32_t *) ext_mem_42220)[(int64_t) 0];\n    r_min_42166 = ((__global int32_t *) mem_42219)[(int64_t) 0];\n    defunc_0_gt_res_42167 = slt32(s_max_42165, r_min_42166);\n    ((__global bool *) mem_42222)[(int64_t) 0] = defunc_0_gt_res_42167;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzigpuseq_42784_dim1, 1, 1)\nvoid inner_SMJ_intzigpuseq_42784(__global int ", "*global_failure, __global unsigned char *mem_42218, __global unsigned char *ext_mem_42221, __global unsigned char *mem_42223)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42786;\n    int32_t tblock_sizze_42789;\n    int32_t wave_sizze_42788;\n    int32_t block_id_42787;\n    int32_t global_tid_42785;\n    int64_t tid_42784;\n    int32_t r_max_42170;\n    int32_t s_min_42171;\n    bool defunc_0_gt_res_42172;\n    \n    local_tid_42786 = get_local_id(0);\n    tblock_sizze_42789 = get_local_size(0);\n    wave_sizze_42788 = LOCKSTEP_WIDTH;\n    block_id_42787 = get_tblock_id(0);\n    global_tid_42785 = block_id_42787 * tblock_sizze_42789 + local_tid_42786;\n    tid_42784 = sext_i32_i64(global_tid_42785);\n    r_max_42170 = ((__global int32_t *) mem_42218)[(int64_t) 0];\n    s_min_42171 = ((__global int32_t *) ext_mem_42221)[(int64_t) 0];\n    defunc_0_gt_res_42172 = slt32(r_max_42170, s_min_42171);\n    ((__global bool *) mem_42223)[(int64_t) 0] = defunc_0_gt_res_42172;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzigpuseq_43142_dim1, 1, 1)\nvoid inner_SMJ_intzigpuseq_43142(__global int *global_failure, int64_t m_39210, __global unsigned char *mem_42394, __global unsigned char *mem_42396)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43144;\n    int32_t tblock_sizze_43147;\n    int32_t wave_sizze_43146;\n    int32_t block_id_43145;\n    int32_t global_tid_43143;\n    int64_t tid_43142;\n    int64_t x_42174;\n    \n    local_tid_43144 = get_local_id(0);\n    tblock_sizze_43147 = get_local_size(0);\n    wave_sizze_43146 = LOCKSTEP_WIDTH;\n    block_id_43145 = get_tblock_id(0);\n    global_tid_43143 = block_id_43145 * tblock_sizze_43147 + local_tid_43144;\n    tid_43142 = sext_i32_i64(global_tid_43143);\n    x_42174 = ((__global int64_t *) mem_42394)[m_39210];\n    ((__global int64_t *) mem_42396)[(int64_t) 0] = x_42174;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzigpuseq_43148_dim1, 1, 1)\nvoid inner_SMJ_intzi",
                                    "gpuseq_43148(__global int *global_failure, int64_t m_39210, __global unsigned char *mem_42377, __global unsigned char *mem_42399)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43150;\n    int32_t tblock_sizze_43153;\n    int32_t wave_sizze_43152;\n    int32_t block_id_43151;\n    int32_t global_tid_43149;\n    int64_t tid_43148;\n    int64_t x_42178;\n    \n    local_tid_43150 = get_local_id(0);\n    tblock_sizze_43153 = get_local_size(0);\n    wave_sizze_43152 = LOCKSTEP_WIDTH;\n    block_id_43151 = get_tblock_id(0);\n    global_tid_43149 = block_id_43151 * tblock_sizze_43153 + local_tid_43150;\n    tid_43148 = sext_i32_i64(global_tid_43149);\n    x_42178 = ((__global int64_t *) mem_42377)[m_39210];\n    ((__global int64_t *) mem_42399)[(int64_t) 0] = x_42178;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzigpuseq_43154_dim1, 1, 1)\nvoid inner_SMJ_intzigpuseq_43154(__global int *global_failure, __global unsigned char *ext_mem_42397, __global unsigned char *ext_mem_42400, __global unsigned char *mem_42406)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43156;\n    int32_t tblock_sizze_43159;\n    int32_t wave_sizze_43158;\n    int32_t block_id_43157;\n    int32_t global_tid_43155;\n    int64_t tid_43154;\n    int64_t zp_lhs_42182;\n    int64_t n_pairs_t_res_42183;\n    int64_t n_pairs_t_res_42184;\n    \n    local_tid_43156 = get_local_id(0);\n    tblock_sizze_43159 = get_local_size(0);\n    wave_sizze_43158 = LOCKSTEP_WIDTH;\n    block_id_43157 = get_tblock_id(0);\n    global_tid_43155 = block_id_43157 * tblock_sizze_43159 + local_tid_43156;\n    tid_43154 = sext_i32_i64(global_tid_43155);\n    zp_lhs_42182 = ((__global int64_t *) ext_mem_42397)[(int64_t) 0];\n    n_pairs_t_res_42183 = ((__global int64_t *) ext_mem_42400)[(int64_t) 0];\n    n_pairs_t_res_42184 = add64(zp_lhs_42182, n_pairs_t_res_42183);\n    ((__global int64_t *) mem_42406)[(int64_t) 0] = n_pairs_t_res_42184;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED", "(inner_SMJ_intzigpuseq_43201_dim1, 1, 1)\nvoid inner_SMJ_intzigpuseq_43201(__global int *global_failure, int64_t loopres_39384, __global unsigned char *mem_param_42440, __global unsigned char *mem_param_42443, __global unsigned char *mem_param_42446, __global unsigned char *mem_42453, __global unsigned char *mem_42454, __global unsigned char *mem_42455)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43203;\n    int32_t tblock_sizze_43206;\n    int32_t wave_sizze_43205;\n    int32_t block_id_43204;\n    int32_t global_tid_43202;\n    int64_t tid_43201;\n    int32_t loopres_42186;\n    int64_t loopres_42188;\n    int64_t loopres_42190;\n    \n    local_tid_43203 = get_local_id(0);\n    tblock_sizze_43206 = get_local_size(0);\n    wave_sizze_43205 = LOCKSTEP_WIDTH;\n    block_id_43204 = get_tblock_id(0);\n    global_tid_43202 = block_id_43204 * tblock_sizze_43206 + local_tid_43203;\n    tid_43201 = sext_i32_i64(global_tid_43202);\n    loopres_42186 = ((__global int32_t *) mem_param_42440)[loopres_39384];\n    loopres_42188 = ((__global int64_t *) mem_param_42443)[loopres_39384];\n    loopres_42190 = ((__global int64_t *) mem_param_42446)[loopres_39384];\n    ((__global int32_t *) mem_42453)[(int64_t) 0] = loopres_42186;\n    ((__global int64_t *) mem_42454)[(int64_t) 0] = loopres_42188;\n    ((__global int64_t *) mem_42455)[(int64_t) 0] = loopres_42190;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL\nvoid inner_SMJ_intzireplicate_43208(int64_t loopres_39385, int64_t replicate_n_43207, int64_t virt_num_tblocks_43213, int64_t num_tblocks_43214, __global unsigned char *mem_42453, __global unsigned char *mem_42457)\n{\n    int32_t replicate_ltid_43209;\n    int32_t tblock_sizze_43211;\n    int32_t replicate_gid_43210;\n    int32_t replicate_gtid_43208;\n    int32_t phys_tblock_id_43215;\n    int32_t iterations_43216;\n    \n    replicate_ltid_43209 = get_local_id(0);\n    tblock_sizze_43211 = get_local_size(0);\n    replicate_gid_43210 = get_tblock_id(0);\n    replicate_gtid_43208 ", "= replicate_gid_43210 * tblock_sizze_43211 + replicate_ltid_43209;\n    phys_tblock_id_43215 = get_tblock_id(0);\n    iterations_43216 = sdiv_up32(sext_i64_i32(virt_num_tblocks_43213) - phys_tblock_id_43215, sext_i64_i32(num_tblocks_43214));\n    for (int32_t i_43217 = 0; i_43217 < iterations_43216; i_43217++) {\n        int32_t virt_tblock_id_43218;\n        int64_t global_tid_43219;\n        int64_t slice_43222;\n        int64_t slice_43223;\n        int64_t rep_i_43220;\n        int64_t remnant_43224;\n        int64_t rep_i_43221;\n        int64_t remnant_43225;\n        \n        virt_tblock_id_43218 = phys_tblock_id_43215 + i_43217 * sext_i64_i32(num_tblocks_43214);\n        global_tid_43219 = sext_i32_i64(virt_tblock_id_43218) * sext_i32_i64(tblock_sizze_43211) + sext_i32_i64(replicate_ltid_43209);\n        slice_43222 = (int64_t) 1;\n        slice_43223 = loopres_39385 * slice_43222;\n        rep_i_43220 = squot64(global_tid_43219, slice_43222);\n        remnant_43224 = global_tid_43219 - rep_i_43220 * slice_43222;\n        rep_i_43221 = remnant_43224;\n        remnant_43225 = remnant_43224 - rep_i_43221;\n        if (slt64(global_tid_43219, replicate_n_43207)) {\n            int32_t tmp_43226 = ((__global int32_t *) mem_42453)[rep_i_43221];\n            \n            ((__global int32_t *) mem_42457)[rep_i_43220 + rep_i_43221] = tmp_43226;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid inner_SMJ_intzireplicate_43228(int64_t loopres_39385, int64_t replicate_n_43227, int64_t virt_num_tblocks_43233, int64_t num_tblocks_43234, __global unsigned char *mem_42454, __global unsigned char *mem_42459)\n{\n    int32_t replicate_ltid_43229;\n    int32_t tblock_sizze_43231;\n    int32_t replicate_gid_43230;\n    int32_t replicate_gtid_43228;\n    int32_t phys_tblock_id_43235;\n    int32_t iterations_43236;\n    \n    replicate_ltid_43229 = get_local_id(0);\n    tblock_sizze_43231 = get_local_size(0);\n    replicate_gid_43230 = ",
                                    "get_tblock_id(0);\n    replicate_gtid_43228 = replicate_gid_43230 * tblock_sizze_43231 + replicate_ltid_43229;\n    phys_tblock_id_43235 = get_tblock_id(0);\n    iterations_43236 = sdiv_up32(sext_i64_i32(virt_num_tblocks_43233) - phys_tblock_id_43235, sext_i64_i32(num_tblocks_43234));\n    for (int32_t i_43237 = 0; i_43237 < iterations_43236; i_43237++) {\n        int32_t virt_tblock_id_43238;\n        int64_t global_tid_43239;\n        int64_t slice_43242;\n        int64_t slice_43243;\n        int64_t rep_i_43240;\n        int64_t remnant_43244;\n        int64_t rep_i_43241;\n        int64_t remnant_43245;\n        \n        virt_tblock_id_43238 = phys_tblock_id_43235 + i_43237 * sext_i64_i32(num_tblocks_43234);\n        global_tid_43239 = sext_i32_i64(virt_tblock_id_43238) * sext_i32_i64(tblock_sizze_43231) + sext_i32_i64(replicate_ltid_43229);\n        slice_43242 = (int64_t) 1;\n        slice_43243 = loopres_39385 * slice_43242;\n        rep_i_43240 = squot64(global_tid_43239, slice_43242);\n        remnant_43244 = global_tid_43239 - rep_i_43240 * slice_43242;\n        rep_i_43241 = remnant_43244;\n        remnant_43245 = remnant_43244 - rep_i_43241;\n        if (slt64(global_tid_43239, replicate_n_43227)) {\n            int64_t tmp_43246 = ((__global int64_t *) mem_42454)[rep_i_43241];\n            \n            ((__global int64_t *) mem_42459)[rep_i_43240 + rep_i_43241] = tmp_43246;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzisegmap_40561_dim1, 1, 1)\nvoid inner_SMJ_intzisegmap_40561(__global int *global_failure, int64_t nR_27729, int64_t m_39200, int64_t num_tblocks_40566, int64_t ext_42365, int64_t ext_42366, int64_t ext_42367, int64_t ext_42368, int32_t virt_num_tblocks_42967, __global unsigned char *tR_mem_42199, __global unsigned char *ext_mem_42201, __global unsigned char *ext_mem_42369, __global unsigned char *ext_mem_42370, __global unsigned char *mem_42373, __global unsigned cha", "r *mem_42375, __global unsigned char *mem_42377, __global unsigned char *mem_42379, __global unsigned char *mem_42381, __global unsigned char *mem_42383)\n{\n    #define segmap_tblock_sizze_40564 (inner_SMJ_intzisegmap_40561zisegmap_tblock_sizze_40564)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42969;\n    int32_t tblock_sizze_42972;\n    int32_t wave_sizze_42971;\n    int32_t block_id_42970;\n    int32_t global_tid_42968;\n    int64_t phys_tid_40561;\n    int32_t phys_tblock_id_42973;\n    int32_t iterations_42974;\n    \n    local_tid_42969 = get_local_id(0);\n    tblock_sizze_42972 = get_local_size(0);\n    wave_sizze_42971 = LOCKSTEP_WIDTH;\n    block_id_42970 = get_tblock_id(0);\n    global_tid_42968 = block_id_42970 * tblock_sizze_42972 + local_tid_42969;\n    phys_tid_40561 = sext_i32_i64(global_tid_42968);\n    phys_tblock_id_42973 = get_tblock_id(0);\n    iterations_42974 = sdiv_up32(virt_num_tblocks_42967 - phys_tblock_id_42973, sext_i64_i32(num_tblocks_40566));\n    for (int32_t i_42975 = 0; i_42975 < iterations_42974; i_42975++) {\n        int32_t virt_tblock_id_42976;\n        int64_t global_tid_42977;\n        int64_t slice_42978;\n        int64_t write_i_40560;\n        int64_t remnant_42979;\n        \n        virt_tblock_id_42976 = phys_tblock_id_42973 + i_42975 * sext_i64_i32(num_tblocks_40566);\n        global_tid_42977 = sext_i32_i64(virt_tblock_id_42976) * segmap_tblock_sizze_40564 + sext_i32_i64(local_tid_42969);\n        slice_42978 = nR_27729;\n        write_i_40560 = global_tid_42977;\n        remnant_42979 = global_tid_42977 - write_i_40560;\n        if (slt64(write_i_40560, nR_27729)) {\n            int64_t eta_p_39447;\n            int32_t write_value_39449;\n            int64_t write_value_39450;\n            int64_t write_value_39451;\n            int64_t write_value_39452;\n            bool cond_39453;\n            int64_t lifted_lambda_res_39454;\n            \n            eta_p_39447 = ((__global int64_t *) mem_42375)[write_i_40560];\n         ", "   write_value_39449 = ((__global int32_t *) tR_mem_42199)[write_i_40560];\n            write_value_39450 = ((__global int64_t *) ext_mem_42201)[write_i_40560];\n            write_value_39451 = ((__global int64_t *) ext_mem_42369)[ext_42366 + write_i_40560 * ext_42365];\n            write_value_39452 = ((__global int64_t *) ext_mem_42370)[ext_42368 + write_i_40560 * ext_42367];\n            cond_39453 = eta_p_39447 == (int64_t) 1;\n            if (cond_39453) {\n                int64_t eta_p_39448;\n                int64_t lifted_lambda_res_t_res_39514;\n                \n                eta_p_39448 = ((__global int64_t *) mem_42373)[write_i_40560];\n                lifted_lambda_res_t_res_39514 = sub64(eta_p_39448, (int64_t) 1);\n                lifted_lambda_res_39454 = lifted_lambda_res_t_res_39514;\n            } else {\n                lifted_lambda_res_39454 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39454) && slt64(lifted_lambda_res_39454, m_39200)) {\n                ((__global int32_t *) mem_42383)[lifted_lambda_res_39454] = write_value_39449;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39454) && slt64(lifted_lambda_res_39454, m_39200)) {\n                ((__global int64_t *) mem_42381)[lifted_lambda_res_39454] = write_value_39450;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39454) && slt64(lifted_lambda_res_39454, m_39200)) {\n                ((__global int64_t *) mem_42379)[lifted_lambda_res_39454] = write_value_39451;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39454) && slt64(lifted_lambda_res_39454, m_39200)) {\n                ((__global int64_t *) mem_42377)[lifted_lambda_res_39454] = write_value_39452;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_40564\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzisegmap_40595_dim1, 1, 1)\nvoid inner_SMJ_intzisegmap_40595(__global",
                                    " int *global_failure, int64_t m_39200, __global unsigned char *mem_42387, __global unsigned char *mem_42394)\n{\n    #define segmap_tblock_sizze_40591 (inner_SMJ_intzisegmap_40595zisegmap_tblock_sizze_40591)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43135;\n    int32_t tblock_sizze_43138;\n    int32_t wave_sizze_43137;\n    int32_t block_id_43136;\n    int32_t global_tid_43134;\n    int64_t phys_tid_40595;\n    int64_t global_tid_43139;\n    int64_t slice_43140;\n    int64_t gtid_40594;\n    int64_t remnant_43141;\n    \n    local_tid_43135 = get_local_id(0);\n    tblock_sizze_43138 = get_local_size(0);\n    wave_sizze_43137 = LOCKSTEP_WIDTH;\n    block_id_43136 = get_tblock_id(0);\n    global_tid_43134 = block_id_43136 * tblock_sizze_43138 + local_tid_43135;\n    phys_tid_40595 = sext_i32_i64(global_tid_43134);\n    global_tid_43139 = sext_i32_i64(block_id_43136) * segmap_tblock_sizze_40591 + sext_i32_i64(local_tid_43135);\n    slice_43140 = m_39200;\n    gtid_40594 = global_tid_43139;\n    remnant_43141 = global_tid_43139 - gtid_40594;\n    if (slt64(gtid_40594, m_39200)) {\n        int64_t zv_lhs_40597;\n        int64_t tmp_40598;\n        bool cond_40600;\n        int64_t lifted_lambda_res_40601;\n        \n        zv_lhs_40597 = add64((int64_t) -1, gtid_40594);\n        tmp_40598 = smod64(zv_lhs_40597, m_39200);\n        cond_40600 = gtid_40594 == (int64_t) 0;\n        if (cond_40600) {\n            lifted_lambda_res_40601 = (int64_t) 0;\n        } else {\n            int64_t lifted_lambda_res_40599 = ((__global int64_t *) mem_42387)[tmp_40598];\n            \n            lifted_lambda_res_40601 = lifted_lambda_res_40599;\n        }\n        ((__global int64_t *) mem_42394)[gtid_40594] = lifted_lambda_res_40601;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_40591\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzisegmap_40603_dim1, 1, 1)\nvoid inner_SMJ_intzisegmap_40603(__global int *global_failure, int64_t m_39200, int64_t lower_bound_39283, int64_t min_res_3928", "5, int64_t j_m_i_39286, int64_t num_tblocks_40608, int32_t virt_num_tblocks_43180, __global unsigned char *mem_42379, __global unsigned char *mem_42381, __global unsigned char *mem_42383, __global unsigned char *mem_42394, __global unsigned char *mem_42423, __global unsigned char *mem_42425, __global unsigned char *mem_42427)\n{\n    #define segmap_tblock_sizze_40606 (inner_SMJ_intzisegmap_40603zisegmap_tblock_sizze_40606)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43182;\n    int32_t tblock_sizze_43185;\n    int32_t wave_sizze_43184;\n    int32_t block_id_43183;\n    int32_t global_tid_43181;\n    int64_t phys_tid_40603;\n    int32_t phys_tblock_id_43186;\n    int32_t iterations_43187;\n    \n    local_tid_43182 = get_local_id(0);\n    tblock_sizze_43185 = get_local_size(0);\n    wave_sizze_43184 = LOCKSTEP_WIDTH;\n    block_id_43183 = get_tblock_id(0);\n    global_tid_43181 = block_id_43183 * tblock_sizze_43185 + local_tid_43182;\n    phys_tid_40603 = sext_i32_i64(global_tid_43181);\n    phys_tblock_id_43186 = get_tblock_id(0);\n    iterations_43187 = sdiv_up32(virt_num_tblocks_43180 - phys_tblock_id_43186, sext_i64_i32(num_tblocks_40608));\n    for (int32_t i_43188 = 0; i_43188 < iterations_43187; i_43188++) {\n        int32_t virt_tblock_id_43189;\n        int64_t global_tid_43190;\n        int64_t slice_43191;\n        int64_t write_i_40602;\n        int64_t remnant_43192;\n        \n        virt_tblock_id_43189 = phys_tblock_id_43186 + i_43188 * sext_i64_i32(num_tblocks_40608);\n        global_tid_43190 = sext_i32_i64(virt_tblock_id_43189) * segmap_tblock_sizze_40606 + sext_i32_i64(local_tid_43182);\n        slice_43191 = m_39200;\n        write_i_40602 = global_tid_43190;\n        remnant_43192 = global_tid_43190 - write_i_40602;\n        if (slt64(write_i_40602, m_39200)) {\n            int64_t eta_p_39484;\n            int32_t write_value_39485;\n            int64_t write_value_39486;\n            int64_t write_value_39487;\n            bool cond_39488;\n         ", "   bool cond_t_res_39489;\n            bool x_39490;\n            int64_t lifted_lambda_res_39491;\n            \n            eta_p_39484 = ((__global int64_t *) mem_42394)[write_i_40602];\n            write_value_39485 = ((__global int32_t *) mem_42383)[write_i_40602];\n            write_value_39486 = ((__global int64_t *) mem_42381)[write_i_40602];\n            write_value_39487 = ((__global int64_t *) mem_42379)[write_i_40602];\n            cond_39488 = sle64(lower_bound_39283, eta_p_39484);\n            cond_t_res_39489 = slt64(eta_p_39484, min_res_39285);\n            x_39490 = cond_39488 && cond_t_res_39489;\n            if (x_39490) {\n                int64_t lifted_lambda_res_t_res_39517 = sub64(eta_p_39484, lower_bound_39283);\n                \n                lifted_lambda_res_39491 = lifted_lambda_res_t_res_39517;\n            } else {\n                lifted_lambda_res_39491 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39491) && slt64(lifted_lambda_res_39491, j_m_i_39286)) {\n                ((__global int32_t *) mem_42423)[lifted_lambda_res_39491] = write_value_39485;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39491) && slt64(lifted_lambda_res_39491, j_m_i_39286)) {\n                ((__global int64_t *) mem_42425)[lifted_lambda_res_39491] = write_value_39486;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39491) && slt64(lifted_lambda_res_39491, j_m_i_39286)) {\n                ((__global int64_t *) mem_42427)[lifted_lambda_res_39491] = write_value_39487;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_40606\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzisegmap_40611_dim1, 1, 1)\nvoid inner_SMJ_intzisegmap_40611(__global int *global_failure, int64_t m_39200, int64_t m_39340, int64_t num_tblocks_40616, int32_t virt_num_tblocks_43162, __global unsigned char *mem_42377, __global unsigned char *mem_4238",
                                    "9, __global unsigned char *mem_42391, __global unsigned char *mem_42394, __global unsigned char *mem_42402, __global unsigned char *mem_42404)\n{\n    #define segmap_tblock_sizze_40614 (inner_SMJ_intzisegmap_40611zisegmap_tblock_sizze_40614)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43164;\n    int32_t tblock_sizze_43167;\n    int32_t wave_sizze_43166;\n    int32_t block_id_43165;\n    int32_t global_tid_43163;\n    int64_t phys_tid_40611;\n    int32_t phys_tblock_id_43168;\n    int32_t iterations_43169;\n    \n    local_tid_43164 = get_local_id(0);\n    tblock_sizze_43167 = get_local_size(0);\n    wave_sizze_43166 = LOCKSTEP_WIDTH;\n    block_id_43165 = get_tblock_id(0);\n    global_tid_43163 = block_id_43165 * tblock_sizze_43167 + local_tid_43164;\n    phys_tid_40611 = sext_i32_i64(global_tid_43163);\n    phys_tblock_id_43168 = get_tblock_id(0);\n    iterations_43169 = sdiv_up32(virt_num_tblocks_43162 - phys_tblock_id_43168, sext_i64_i32(num_tblocks_40616));\n    for (int32_t i_43170 = 0; i_43170 < iterations_43169; i_43170++) {\n        int32_t virt_tblock_id_43171;\n        int64_t global_tid_43172;\n        int64_t slice_43173;\n        int64_t write_i_40610;\n        int64_t remnant_43174;\n        \n        virt_tblock_id_43171 = phys_tblock_id_43168 + i_43170 * sext_i64_i32(num_tblocks_40616);\n        global_tid_43172 = sext_i32_i64(virt_tblock_id_43171) * segmap_tblock_sizze_40614 + sext_i32_i64(local_tid_43164);\n        slice_43173 = m_39200;\n        write_i_40610 = global_tid_43172;\n        remnant_43174 = global_tid_43172 - write_i_40610;\n        if (slt64(write_i_40610, m_39200)) {\n            int64_t eta_p_39424;\n            int64_t write_value_39426;\n            int64_t write_value_39427;\n            bool cond_39428;\n            int64_t lifted_lambda_res_39429;\n            \n            eta_p_39424 = ((__global int64_t *) mem_42391)[write_i_40610];\n            write_value_39426 = ((__global int64_t *) mem_42394)[write_i_40610];\n            write_v", "alue_39427 = ((__global int64_t *) mem_42377)[write_i_40610];\n            cond_39428 = eta_p_39424 == (int64_t) 1;\n            if (cond_39428) {\n                int64_t eta_p_39425;\n                int64_t lifted_lambda_res_t_res_39522;\n                \n                eta_p_39425 = ((__global int64_t *) mem_42389)[write_i_40610];\n                lifted_lambda_res_t_res_39522 = sub64(eta_p_39425, (int64_t) 1);\n                lifted_lambda_res_39429 = lifted_lambda_res_t_res_39522;\n            } else {\n                lifted_lambda_res_39429 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39429) && slt64(lifted_lambda_res_39429, m_39340)) {\n                ((__global int64_t *) mem_42404)[lifted_lambda_res_39429] = write_value_39426;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39429) && slt64(lifted_lambda_res_39429, m_39340)) {\n                ((__global int64_t *) mem_42402)[lifted_lambda_res_39429] = write_value_39427;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_40614\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzisegmap_40633_dim1, 1, 1)\nvoid inner_SMJ_intzisegmap_40633(__global int *global_failure, int64_t loopres_39384, int64_t loopres_39385, __global unsigned char *mem_42452, __global unsigned char *mem_42455)\n{\n    #define segmap_tblock_sizze_40629 (inner_SMJ_intzisegmap_40633zisegmap_tblock_sizze_40629)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43249;\n    int32_t tblock_sizze_43252;\n    int32_t wave_sizze_43251;\n    int32_t block_id_43250;\n    int32_t global_tid_43248;\n    int64_t phys_tid_40633;\n    int64_t global_tid_43253;\n    int64_t slice_43254;\n    int64_t gtid_40632;\n    int64_t remnant_43255;\n    \n    local_tid_43249 = get_local_id(0);\n    tblock_sizze_43252 = get_local_size(0);\n    wave_sizze_43251 = LOCKSTEP_WIDTH;\n    block_id_43250 = get_tblock_id(0);\n    global_", "tid_43248 = block_id_43250 * tblock_sizze_43252 + local_tid_43249;\n    phys_tid_40633 = sext_i32_i64(global_tid_43248);\n    global_tid_43253 = sext_i32_i64(block_id_43250) * segmap_tblock_sizze_40629 + sext_i32_i64(local_tid_43249);\n    slice_43254 = loopres_39385;\n    gtid_40632 = global_tid_43253;\n    remnant_43255 = global_tid_43253 - gtid_40632;\n    if (slt64(gtid_40632, loopres_39385)) {\n        int64_t loopres_42194;\n        int64_t tmp_40635;\n        \n        loopres_42194 = ((__global int64_t *) mem_42455)[(int64_t) 0];\n        tmp_40635 = add64(gtid_40632, loopres_42194);\n        ((__global int64_t *) mem_42452)[loopres_39384 + gtid_40632] = tmp_40635;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_40629\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzisegmap_intrablock_41423_dim1, 1, 1)\nvoid inner_SMJ_intzisegmap_intrablock_41423(__global int *global_failure, int64_t nS_27730, int64_t start_39100, int64_t min_res_39102, int64_t ldim_41426, int64_t num_whole_tiles_41441, int64_t residual_input_41665, unsigned char cond_41666_bits, int64_t binop_x_41682, __global unsigned char *tR_mem_42199, __global unsigned char *tS_mem_42200, __global unsigned char *ext_mem_42224, __global unsigned char *mem_42344, __global unsigned char *mem_42346)\n{\n    bool cond_41666 = cond_41666_bits;\n    \n    #define tile_sizze_41425 (inner_SMJ_intzisegmap_intrablock_41423zitile_sizze_41425)\n    #define bytes_42306 (inner_SMJ_intzisegmap_intrablock_41423zibytes_42306)\n    #define bytes_42308 (inner_SMJ_intzisegmap_intrablock_41423zibytes_42308)\n    \n    volatile __local unsigned char *color_42702_backing_2 = &shared_mem[0];\n    const int64_t color_42702_backing_2_offset = 0 + (bytes_42306 + srem64((int64_t) 8 - srem64(bytes_42306, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_42701_backing_1 = &shared_mem[color_42702_backing_2_offset];\n    const int64_t color_42701_backing_1_offset = color_42702_backing_2_offset + (bytes_42308 + srem64((int64_t) 8 - s",
                                    "rem64(bytes_42308, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_42700_backing_0 = &shared_mem[color_42701_backing_1_offset];\n    const int64_t color_42700_backing_0_offset = color_42701_backing_1_offset + (bytes_42306 + srem64((int64_t) 8 - srem64(bytes_42306, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42793;\n    int32_t tblock_sizze_42796;\n    int32_t wave_sizze_42795;\n    int32_t block_id_42794;\n    int32_t global_tid_42792;\n    int64_t gid_flat_41423;\n    int64_t slice_42798;\n    int64_t ltid_pre_42797;\n    int64_t remnant_42799;\n    int64_t slice_42800;\n    int64_t gid_41422;\n    int64_t remnant_42801;\n    __local unsigned char *color_42700;\n    __local unsigned char *color_42701;\n    __local unsigned char *color_42702;\n    int64_t binop_x_41433;\n    int32_t mem_42290[1];\n    int64_t ltid_flat_41428;\n    int64_t ltid_41427;\n    int64_t gtid_41434;\n    bool cond_41435;\n    int32_t pre_41436;\n    int64_t mem_42294[1];\n    int32_t mem_42298[1];\n    int64_t mem_42302[1];\n    int64_t ltid_flat_41443;\n    int64_t ltid_41442;\n    int64_t gtid_41453;\n    bool cond_41454;\n    int64_t neutral_41455;\n    int32_t neutral_41456;\n    int64_t ext_mem_42326[1];\n    int32_t ext_mem_42325[1];\n    int64_t ext_mem_42324[1];\n    int64_t mem_param_42303[1];\n    int32_t mem_param_42304[1];\n    int64_t mem_param_42305[1];\n    int64_t mem_42336[1];\n    int64_t mem_42340[1];\n    int64_t ext_mem_42342[1];\n    int64_t ext_mem_42341[1];\n    \n    local_tid_42793 = get_local_id(0);\n    tblock_sizze_42796 = get_local_size(0);\n    wave_sizze_42795 = LOCKSTEP_WIDTH;\n    block_id_42794 = get_tblock_id(0);\n    global_tid_42792 = block_id_42794 * tblock_sizze_42796 + local_tid_42793;\n    gid_flat_41423 = sext_i32_i64(block_id_42794);\n    slice_42798 = tile_sizze_41425;\n    ltid_pre_42797 = sext_i32_i64(local_tid_42793);\n    remnant_42799 = sext_i32_i64(local_tid_42793) - ltid_pre_42797;\n    slice_42800 = ldim_", "41426;\n    gid_41422 = sext_i32_i64(block_id_42794);\n    remnant_42801 = sext_i32_i64(block_id_42794) - gid_41422;\n    color_42700 = (__local unsigned char *) color_42700_backing_0;\n    color_42701 = (__local unsigned char *) color_42701_backing_1;\n    color_42702 = (__local unsigned char *) color_42702_backing_2;\n    binop_x_41433 = gid_41422 * tile_sizze_41425;\n    ltid_flat_41428 = sext_i32_i64(local_tid_42793);\n    ltid_41427 = sext_i32_i64(sext_i64_i32(ltid_pre_42797));\n    gtid_41434 = ltid_41427 + binop_x_41433;\n    cond_41435 = slt64(gtid_41434, min_res_39102);\n    if (cond_41435) {\n        int64_t slice_41437;\n        int32_t eta_p_41438;\n        \n        slice_41437 = start_39100 + gtid_41434;\n        eta_p_41438 = ((__global int32_t *) tR_mem_42199)[slice_41437];\n        pre_41436 = eta_p_41438;\n    } else {\n        pre_41436 = 0;\n    }\n    mem_42290[(int64_t) 0] = pre_41436;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    ltid_flat_41443 = sext_i32_i64(local_tid_42793);\n    ltid_41442 = sext_i32_i64(sext_i64_i32(ltid_pre_42797));\n    gtid_41453 = binop_x_41433 + ltid_41442;\n    cond_41454 = slt64(gtid_41453, min_res_39102);\n    if (cond_41454) {\n        neutral_41455 = (int64_t) -1;\n    } else {\n        neutral_41455 = (int64_t) 0;\n    }\n    if (cond_41454) {\n        int32_t eta_p_41458 = mem_42290[(int64_t) 0];\n        \n        neutral_41456 = eta_p_41458;\n    } else {\n        neutral_41456 = 0;\n    }\n    mem_42294[(int64_t) 0] = neutral_41455;\n    mem_42298[(int64_t) 0] = neutral_41456;\n    mem_42302[(int64_t) 0] = (int64_t) 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    for (int32_t i_3 = 0; i_3 < 1; i_3++)\n        mem_param_42303[i_3] = mem_42294[i_3];\n    for (int32_t i_4 = 0; i_4 < 1; i_4++)\n        mem_param_42304[i_4] = mem_42298[i_4];\n    for (int32_t i_5 = 0; i_5 < 1; i_5++)\n        mem_param_42305[i_5] = mem_42302[i_5];\n    for (int64_t tile_id_41468 = 0; tile_id_41468 < num_whole_tiles_41441; tile_id_41468++) {\n        int64", "_t binop_x_41567;\n        int64_t ltid_flat_41566;\n        int64_t ltid_41565;\n        int64_t j_41568;\n        bool cond_41572;\n        int64_t pre1d_41575;\n        int64_t pre1d_41573;\n        int32_t pre1d_41574;\n        int64_t mem_42315[1];\n        int32_t mem_42319[1];\n        int64_t mem_42323[1];\n        int64_t ltid_flat_41586;\n        int64_t ltid_41585;\n        int64_t gtid_41588;\n        int64_t acc_41590;\n        int32_t acc_41591;\n        int64_t acc_41592;\n        bool cond_41593;\n        int64_t acc_41594;\n        int32_t acc_41595;\n        int64_t acc_41596;\n        int64_t mem_param_tmp_42802[1];\n        int32_t mem_param_tmp_42803[1];\n        int64_t mem_param_tmp_42804[1];\n        \n        binop_x_41567 = tile_sizze_41425 * tile_id_41468;\n        ltid_flat_41566 = sext_i32_i64(local_tid_42793);\n        ltid_41565 = sext_i32_i64(sext_i64_i32(ltid_pre_42797));\n        j_41568 = ltid_41565 + binop_x_41567;\n        cond_41572 = slt64(j_41568, nS_27730);\n        pre1d_41575 = btoi_bool_i64(cond_41572);\n        if (cond_41572) {\n            int64_t tile_elem_41576;\n            int32_t tile_elem_41577;\n            \n            tile_elem_41576 = ((__global int64_t *) ext_mem_42224)[j_41568];\n            tile_elem_41577 = ((__global int32_t *) tS_mem_42200)[j_41568];\n            pre1d_41573 = tile_elem_41576;\n            pre1d_41574 = tile_elem_41577;\n        } else {\n            pre1d_41573 = (int64_t) 0;\n            pre1d_41574 = 0;\n        }\n        ((__local int64_t *) color_42702)[ltid_41565] = pre1d_41573;\n        ((__local int32_t *) color_42701)[ltid_41565] = pre1d_41574;\n        ((__local int64_t *) color_42700)[ltid_41565] = pre1d_41575;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_41586 = sext_i32_i64(local_tid_42793);\n        ltid_41585 = sext_i32_i64(sext_i64_i32(ltid_pre_42797));\n        gtid_41588 = binop_x_41433 + ltid_41585;\n        acc_41590 = mem_param_42303[(int64_t) 0];\n        acc_41591 = mem_param_42304[(int64_t) 0];\n    ",
                                    "    acc_41592 = mem_param_42305[(int64_t) 0];\n        cond_41593 = slt64(gtid_41588, min_res_39102);\n        if (cond_41593) {\n            int32_t eta_p_41589;\n            int64_t x_41597;\n            int32_t x_41598;\n            int64_t x_41599;\n            int64_t redout_42136;\n            int32_t redout_42137;\n            int64_t redout_42138;\n            \n            eta_p_41589 = mem_42290[(int64_t) 0];\n            redout_42136 = acc_41590;\n            redout_42137 = acc_41591;\n            redout_42138 = acc_41592;\n            for (int64_t i_42139 = 0; i_42139 < tile_sizze_41425; i_42139++) {\n                int64_t x_41600;\n                int32_t x_41601;\n                bool defunc_0_neq_res_41609;\n                bool defunc_0_neq_res_41610;\n                bool cond_f_res_41611;\n                bool y_41612;\n                bool cond_41613;\n                bool defunc_0_neq_res_41614;\n                bool defunc_0_neq_res_41615;\n                bool cond_t_res_f_res_41616;\n                bool y_41617;\n                bool cond_t_res_41618;\n                bool x_41619;\n                int64_t defunc_0_op_res_41620;\n                int32_t defunc_0_op_res_41621;\n                int64_t defunc_0_op_res_41622;\n                int64_t redout_tmp_42808;\n                int32_t redout_tmp_42809;\n                int64_t redout_tmp_42810;\n                \n                x_41600 = ((__local int64_t *) color_42702)[i_42139];\n                x_41601 = ((__local int32_t *) color_42701)[i_42139];\n                defunc_0_neq_res_41609 = redout_42137 == eta_p_41589;\n                defunc_0_neq_res_41610 = !defunc_0_neq_res_41609;\n                cond_f_res_41611 = slt64(redout_42136, (int64_t) 0);\n                y_41612 = defunc_0_neq_res_41609 && cond_f_res_41611;\n                cond_41613 = defunc_0_neq_res_41610 || y_41612;\n                defunc_0_neq_res_41614 = x_41601 == eta_p_41589;\n                defunc_0_neq_res_41615 = !defunc_0_neq_res_41614;\n         ", "       cond_t_res_f_res_41616 = slt64(x_41600, (int64_t) 0);\n                y_41617 = defunc_0_neq_res_41614 && cond_t_res_f_res_41616;\n                cond_t_res_41618 = defunc_0_neq_res_41615 || y_41617;\n                x_41619 = cond_41613 && cond_t_res_41618;\n                if (x_41619) {\n                    defunc_0_op_res_41620 = (int64_t) -1;\n                    defunc_0_op_res_41621 = eta_p_41589;\n                    defunc_0_op_res_41622 = (int64_t) 0;\n                } else {\n                    int64_t x_41602;\n                    int64_t defunc_0_op_res_f_res_41623;\n                    int32_t defunc_0_op_res_f_res_41624;\n                    int64_t defunc_0_op_res_f_res_41625;\n                    \n                    x_41602 = ((__local int64_t *) color_42700)[i_42139];\n                    if (cond_41613) {\n                        defunc_0_op_res_f_res_41623 = x_41600;\n                        defunc_0_op_res_f_res_41624 = x_41601;\n                        defunc_0_op_res_f_res_41625 = x_41602;\n                    } else {\n                        int32_t defunc_0_op_res_f_res_f_res_41626;\n                        int64_t defunc_0_op_res_f_res_f_res_41627;\n                        int64_t defunc_0_op_res_f_res_f_res_41628;\n                        \n                        if (cond_t_res_41618) {\n                            defunc_0_op_res_f_res_f_res_41626 = redout_42137;\n                        } else {\n                            defunc_0_op_res_f_res_f_res_41626 = eta_p_41589;\n                        }\n                        if (cond_t_res_41618) {\n                            defunc_0_op_res_f_res_f_res_41627 = redout_42136;\n                            defunc_0_op_res_f_res_f_res_41628 = redout_42138;\n                        } else {\n                            int64_t min_res_41629;\n                            int64_t tmp_41630;\n                            \n                            min_res_41629 = smin64(x_41600, redout_42136);\n                     ", "       tmp_41630 = add64(x_41602, redout_42138);\n                            defunc_0_op_res_f_res_f_res_41627 = min_res_41629;\n                            defunc_0_op_res_f_res_f_res_41628 = tmp_41630;\n                        }\n                        defunc_0_op_res_f_res_41623 = defunc_0_op_res_f_res_f_res_41627;\n                        defunc_0_op_res_f_res_41624 = defunc_0_op_res_f_res_f_res_41626;\n                        defunc_0_op_res_f_res_41625 = defunc_0_op_res_f_res_f_res_41628;\n                    }\n                    defunc_0_op_res_41620 = defunc_0_op_res_f_res_41623;\n                    defunc_0_op_res_41621 = defunc_0_op_res_f_res_41624;\n                    defunc_0_op_res_41622 = defunc_0_op_res_f_res_41625;\n                }\n                redout_tmp_42808 = defunc_0_op_res_41620;\n                redout_tmp_42809 = defunc_0_op_res_41621;\n                redout_tmp_42810 = defunc_0_op_res_41622;\n                redout_42136 = redout_tmp_42808;\n                redout_42137 = redout_tmp_42809;\n                redout_42138 = redout_tmp_42810;\n            }\n            x_41597 = redout_42136;\n            x_41598 = redout_42137;\n            x_41599 = redout_42138;\n            acc_41594 = x_41597;\n            acc_41595 = x_41598;\n            acc_41596 = x_41599;\n        } else {\n            acc_41594 = acc_41590;\n            acc_41595 = acc_41591;\n            acc_41596 = acc_41592;\n        }\n        mem_42315[(int64_t) 0] = acc_41594;\n        mem_42319[(int64_t) 0] = acc_41595;\n        mem_42323[(int64_t) 0] = acc_41596;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_6 = 0; i_6 < 1; i_6++)\n            mem_param_tmp_42802[i_6] = mem_42315[i_6];\n        for (int32_t i_7 = 0; i_7 < 1; i_7++)\n            mem_param_tmp_42803[i_7] = mem_42319[i_7];\n        for (int32_t i_8 = 0; i_8 < 1; i_8++)\n            mem_param_tmp_42804[i_8] = mem_42323[i_8];\n        for (int32_t i_9 = 0; i_9 < 1; i_9++)\n            mem_param_42303[i_9] = mem_param_tmp_428",
                                    "02[i_9];\n        for (int32_t i_10 = 0; i_10 < 1; i_10++)\n            mem_param_42304[i_10] = mem_param_tmp_42803[i_10];\n        for (int32_t i_11 = 0; i_11 < 1; i_11++)\n            mem_param_42305[i_11] = mem_param_tmp_42804[i_11];\n    }\n    for (int32_t i_12 = 0; i_12 < 1; i_12++)\n        ext_mem_42326[i_12] = mem_param_42303[i_12];\n    for (int32_t i_13 = 0; i_13 < 1; i_13++)\n        ext_mem_42325[i_13] = mem_param_42304[i_13];\n    for (int32_t i_14 = 0; i_14 < 1; i_14++)\n        ext_mem_42324[i_14] = mem_param_42305[i_14];\n    barrier(CLK_LOCAL_MEM_FENCE);\n    if (cond_41666) {\n        for (int32_t i_15 = 0; i_15 < 1; i_15++)\n            ext_mem_42342[i_15] = ext_mem_42326[i_15];\n        for (int32_t i_16 = 0; i_16 < 1; i_16++)\n            ext_mem_42341[i_16] = ext_mem_42324[i_16];\n    } else {\n        int64_t ltid_flat_41668;\n        int64_t ltid_41667;\n        int64_t j_41683;\n        bool cond_41687;\n        int64_t pre1d_41690;\n        int64_t pre1d_41688;\n        int32_t pre1d_41689;\n        int64_t ltid_flat_41704;\n        int64_t ltid_41703;\n        int64_t gtid_41717;\n        int64_t acc_41719;\n        int64_t acc_41721;\n        bool cond_41722;\n        int64_t acc_41723;\n        int64_t acc_41725;\n        \n        ltid_flat_41668 = sext_i32_i64(local_tid_42793);\n        ltid_41667 = sext_i32_i64(sext_i64_i32(ltid_pre_42797));\n        j_41683 = ltid_41667 + binop_x_41682;\n        cond_41687 = slt64(j_41683, nS_27730);\n        pre1d_41690 = btoi_bool_i64(cond_41687);\n        if (cond_41687) {\n            int64_t tile_elem_41691;\n            int32_t tile_elem_41692;\n            \n            tile_elem_41691 = ((__global int64_t *) ext_mem_42224)[j_41683];\n            tile_elem_41692 = ((__global int32_t *) tS_mem_42200)[j_41683];\n            pre1d_41688 = tile_elem_41691;\n            pre1d_41689 = tile_elem_41692;\n        } else {\n            pre1d_41688 = (int64_t) 0;\n            pre1d_41689 = 0;\n        }\n        ((__local int64_t *) color_42702)[ltid_416", "67] = pre1d_41688;\n        ((__local int32_t *) color_42701)[ltid_41667] = pre1d_41689;\n        ((__local int64_t *) color_42700)[ltid_41667] = pre1d_41690;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_41704 = sext_i32_i64(local_tid_42793);\n        ltid_41703 = sext_i32_i64(sext_i64_i32(ltid_pre_42797));\n        gtid_41717 = binop_x_41433 + ltid_41703;\n        acc_41719 = ext_mem_42326[(int64_t) 0];\n        acc_41721 = ext_mem_42324[(int64_t) 0];\n        cond_41722 = slt64(gtid_41717, min_res_39102);\n        if (cond_41722) {\n            int32_t eta_p_41718;\n            int32_t acc_41720;\n            int64_t x_41726;\n            int32_t x_41727;\n            int64_t x_41728;\n            int64_t redout_42140;\n            int32_t redout_42141;\n            int64_t redout_42142;\n            \n            eta_p_41718 = mem_42290[(int64_t) 0];\n            acc_41720 = ext_mem_42325[(int64_t) 0];\n            redout_42140 = acc_41719;\n            redout_42141 = acc_41720;\n            redout_42142 = acc_41721;\n            for (int64_t i_42143 = 0; i_42143 < residual_input_41665; i_42143++) {\n                int64_t x_41729;\n                int32_t x_41730;\n                bool defunc_0_neq_res_41738;\n                bool defunc_0_neq_res_41739;\n                bool cond_f_res_41740;\n                bool y_41741;\n                bool cond_41742;\n                bool defunc_0_neq_res_41743;\n                bool defunc_0_neq_res_41744;\n                bool cond_t_res_f_res_41745;\n                bool y_41746;\n                bool cond_t_res_41747;\n                bool x_41748;\n                int64_t defunc_0_op_res_41749;\n                int32_t defunc_0_op_res_41750;\n                int64_t defunc_0_op_res_41751;\n                int64_t redout_tmp_42811;\n                int32_t redout_tmp_42812;\n                int64_t redout_tmp_42813;\n                \n                x_41729 = ((__local int64_t *) color_42702)[i_42143];\n                x_41730 = ((__local int32_t *)", " color_42701)[i_42143];\n                defunc_0_neq_res_41738 = redout_42141 == eta_p_41718;\n                defunc_0_neq_res_41739 = !defunc_0_neq_res_41738;\n                cond_f_res_41740 = slt64(redout_42140, (int64_t) 0);\n                y_41741 = defunc_0_neq_res_41738 && cond_f_res_41740;\n                cond_41742 = defunc_0_neq_res_41739 || y_41741;\n                defunc_0_neq_res_41743 = x_41730 == eta_p_41718;\n                defunc_0_neq_res_41744 = !defunc_0_neq_res_41743;\n                cond_t_res_f_res_41745 = slt64(x_41729, (int64_t) 0);\n                y_41746 = defunc_0_neq_res_41743 && cond_t_res_f_res_41745;\n                cond_t_res_41747 = defunc_0_neq_res_41744 || y_41746;\n                x_41748 = cond_41742 && cond_t_res_41747;\n                if (x_41748) {\n                    defunc_0_op_res_41749 = (int64_t) -1;\n                    defunc_0_op_res_41750 = eta_p_41718;\n                    defunc_0_op_res_41751 = (int64_t) 0;\n                } else {\n                    int64_t x_41731;\n                    int64_t defunc_0_op_res_f_res_41752;\n                    int32_t defunc_0_op_res_f_res_41753;\n                    int64_t defunc_0_op_res_f_res_41754;\n                    \n                    x_41731 = ((__local int64_t *) color_42700)[i_42143];\n                    if (cond_41742) {\n                        defunc_0_op_res_f_res_41752 = x_41729;\n                        defunc_0_op_res_f_res_41753 = x_41730;\n                        defunc_0_op_res_f_res_41754 = x_41731;\n                    } else {\n                        int32_t defunc_0_op_res_f_res_f_res_41755;\n                        int64_t defunc_0_op_res_f_res_f_res_41756;\n                        int64_t defunc_0_op_res_f_res_f_res_41757;\n                        \n                        if (cond_t_res_41747) {\n                            defunc_0_op_res_f_res_f_res_41755 = redout_42141;\n                        } else {\n                            defunc_0_op_res_f_res_f_res_4175",
                                    "5 = eta_p_41718;\n                        }\n                        if (cond_t_res_41747) {\n                            defunc_0_op_res_f_res_f_res_41756 = redout_42140;\n                            defunc_0_op_res_f_res_f_res_41757 = redout_42142;\n                        } else {\n                            int64_t min_res_41758;\n                            int64_t tmp_41759;\n                            \n                            min_res_41758 = smin64(x_41729, redout_42140);\n                            tmp_41759 = add64(x_41731, redout_42142);\n                            defunc_0_op_res_f_res_f_res_41756 = min_res_41758;\n                            defunc_0_op_res_f_res_f_res_41757 = tmp_41759;\n                        }\n                        defunc_0_op_res_f_res_41752 = defunc_0_op_res_f_res_f_res_41756;\n                        defunc_0_op_res_f_res_41753 = defunc_0_op_res_f_res_f_res_41755;\n                        defunc_0_op_res_f_res_41754 = defunc_0_op_res_f_res_f_res_41757;\n                    }\n                    defunc_0_op_res_41749 = defunc_0_op_res_f_res_41752;\n                    defunc_0_op_res_41750 = defunc_0_op_res_f_res_41753;\n                    defunc_0_op_res_41751 = defunc_0_op_res_f_res_41754;\n                }\n                redout_tmp_42811 = defunc_0_op_res_41749;\n                redout_tmp_42812 = defunc_0_op_res_41750;\n                redout_tmp_42813 = defunc_0_op_res_41751;\n                redout_42140 = redout_tmp_42811;\n                redout_42141 = redout_tmp_42812;\n                redout_42142 = redout_tmp_42813;\n            }\n            x_41726 = redout_42140;\n            x_41727 = redout_42141;\n            x_41728 = redout_42142;\n            acc_41723 = x_41726;\n            acc_41725 = x_41728;\n        } else {\n            acc_41723 = acc_41719;\n            acc_41725 = acc_41721;\n        }\n        mem_42336[(int64_t) 0] = acc_41723;\n        mem_42340[(int64_t) 0] = acc_41725;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        fo", "r (int32_t i_17 = 0; i_17 < 1; i_17++)\n            ext_mem_42342[i_17] = mem_42336[i_17];\n        for (int32_t i_18 = 0; i_18 < 1; i_18++)\n            ext_mem_42341[i_18] = mem_42340[i_18];\n    }\n    if (slt64(sext_i32_i64(local_tid_42793) + tile_sizze_41425 * sext_i32_i64(block_id_42794), min_res_39102)) {\n        int64_t tmp_42814 = ext_mem_42342[(int64_t) 0];\n        \n        ((__global int64_t *) mem_42344)[sext_i32_i64(local_tid_42793) + tile_sizze_41425 * sext_i32_i64(block_id_42794)] = tmp_42814;\n    }\n    if (slt64(sext_i32_i64(local_tid_42793) + tile_sizze_41425 * sext_i32_i64(block_id_42794), min_res_39102)) {\n        int64_t tmp_42815 = ext_mem_42341[(int64_t) 0];\n        \n        ((__global int64_t *) mem_42346)[sext_i32_i64(local_tid_42793) + tile_sizze_41425 * sext_i32_i64(block_id_42794)] = tmp_42815;\n    }\n    \n  error_8:\n    return;\n    #undef tile_sizze_41425\n    #undef bytes_42306\n    #undef bytes_42308\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzisegmap_intrablock_41778_dim1, 1, 1)\nvoid inner_SMJ_intzisegmap_intrablock_41778(__global int *global_failure, int64_t nS_27730, int64_t start_39100, int64_t min_res_39102, int64_t ldim_41781, int64_t num_whole_tiles_41796, int64_t residual_input_42020, unsigned char cond_42021_bits, int64_t binop_x_42037, __global unsigned char *tR_mem_42199, __global unsigned char *tS_mem_42200, __global unsigned char *ext_mem_42224, __global unsigned char *mem_42283, __global unsigned char *mem_42285)\n{\n    bool cond_42021 = cond_42021_bits;\n    \n    #define tile_sizze_41780 (inner_SMJ_intzisegmap_intrablock_41778zitile_sizze_41780)\n    #define bytes_42245 (inner_SMJ_intzisegmap_intrablock_41778zibytes_42245)\n    #define bytes_42247 (inner_SMJ_intzisegmap_intrablock_41778zibytes_42247)\n    \n    volatile __local unsigned char *color_42705_backing_2 = &shared_mem[0];\n    const int64_t color_42705_backing_2_offset = 0 + (bytes_42245 + srem64((int64_t) 8 - srem64(bytes_42245, (int64_t) 8), (int64_t) 8));\n    volatile __local unsi", "gned char *color_42704_backing_1 = &shared_mem[color_42705_backing_2_offset];\n    const int64_t color_42704_backing_1_offset = color_42705_backing_2_offset + (bytes_42247 + srem64((int64_t) 8 - srem64(bytes_42247, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_42703_backing_0 = &shared_mem[color_42704_backing_1_offset];\n    const int64_t color_42703_backing_0_offset = color_42704_backing_1_offset + (bytes_42245 + srem64((int64_t) 8 - srem64(bytes_42245, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42819;\n    int32_t tblock_sizze_42822;\n    int32_t wave_sizze_42821;\n    int32_t block_id_42820;\n    int32_t global_tid_42818;\n    int64_t gid_flat_41778;\n    int64_t slice_42824;\n    int64_t ltid_pre_42823;\n    int64_t remnant_42825;\n    int64_t slice_42826;\n    int64_t gid_41777;\n    int64_t remnant_42827;\n    __local unsigned char *color_42703;\n    __local unsigned char *color_42704;\n    __local unsigned char *color_42705;\n    int64_t binop_x_41788;\n    int32_t mem_42229[1];\n    int64_t ltid_flat_41783;\n    int64_t ltid_41782;\n    int64_t gtid_41789;\n    bool cond_41790;\n    int32_t pre_41791;\n    int64_t mem_42233[1];\n    int32_t mem_42237[1];\n    int64_t mem_42241[1];\n    int64_t ltid_flat_41798;\n    int64_t ltid_41797;\n    int64_t gtid_41808;\n    bool cond_41809;\n    int64_t neutral_41810;\n    int32_t neutral_41811;\n    int64_t ext_mem_42265[1];\n    int32_t ext_mem_42264[1];\n    int64_t ext_mem_42263[1];\n    int64_t mem_param_42242[1];\n    int32_t mem_param_42243[1];\n    int64_t mem_param_42244[1];\n    int64_t mem_42275[1];\n    int64_t mem_42279[1];\n    int64_t ext_mem_42281[1];\n    int64_t ext_mem_42280[1];\n    \n    local_tid_42819 = get_local_id(0);\n    tblock_sizze_42822 = get_local_size(0);\n    wave_sizze_42821 = LOCKSTEP_WIDTH;\n    block_id_42820 = get_tblock_id(0);\n    global_tid_42818 = block_id_42820 * tblock_sizze_42822 + local_tid_42819;\n    gid_flat_41778 = sext_i32_i64(b",
                                    "lock_id_42820);\n    slice_42824 = tile_sizze_41780;\n    ltid_pre_42823 = sext_i32_i64(local_tid_42819);\n    remnant_42825 = sext_i32_i64(local_tid_42819) - ltid_pre_42823;\n    slice_42826 = ldim_41781;\n    gid_41777 = sext_i32_i64(block_id_42820);\n    remnant_42827 = sext_i32_i64(block_id_42820) - gid_41777;\n    color_42703 = (__local unsigned char *) color_42703_backing_0;\n    color_42704 = (__local unsigned char *) color_42704_backing_1;\n    color_42705 = (__local unsigned char *) color_42705_backing_2;\n    binop_x_41788 = gid_41777 * tile_sizze_41780;\n    ltid_flat_41783 = sext_i32_i64(local_tid_42819);\n    ltid_41782 = sext_i32_i64(sext_i64_i32(ltid_pre_42823));\n    gtid_41789 = ltid_41782 + binop_x_41788;\n    cond_41790 = slt64(gtid_41789, min_res_39102);\n    if (cond_41790) {\n        int64_t slice_41792;\n        int32_t eta_p_41793;\n        \n        slice_41792 = start_39100 + gtid_41789;\n        eta_p_41793 = ((__global int32_t *) tR_mem_42199)[slice_41792];\n        pre_41791 = eta_p_41793;\n    } else {\n        pre_41791 = 0;\n    }\n    mem_42229[(int64_t) 0] = pre_41791;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    ltid_flat_41798 = sext_i32_i64(local_tid_42819);\n    ltid_41797 = sext_i32_i64(sext_i64_i32(ltid_pre_42823));\n    gtid_41808 = binop_x_41788 + ltid_41797;\n    cond_41809 = slt64(gtid_41808, min_res_39102);\n    if (cond_41809) {\n        neutral_41810 = (int64_t) -1;\n    } else {\n        neutral_41810 = (int64_t) 0;\n    }\n    if (cond_41809) {\n        int32_t eta_p_41813 = mem_42229[(int64_t) 0];\n        \n        neutral_41811 = eta_p_41813;\n    } else {\n        neutral_41811 = 0;\n    }\n    mem_42233[(int64_t) 0] = neutral_41810;\n    mem_42237[(int64_t) 0] = neutral_41811;\n    mem_42241[(int64_t) 0] = (int64_t) 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    for (int32_t i_3 = 0; i_3 < 1; i_3++)\n        mem_param_42242[i_3] = mem_42233[i_3];\n    for (int32_t i_4 = 0; i_4 < 1; i_4++)\n        mem_param_42243[i_4] = mem_42237[i_4];\n ", "   for (int32_t i_5 = 0; i_5 < 1; i_5++)\n        mem_param_42244[i_5] = mem_42241[i_5];\n    for (int64_t tile_id_41823 = 0; tile_id_41823 < num_whole_tiles_41796; tile_id_41823++) {\n        int64_t binop_x_41922;\n        int64_t ltid_flat_41921;\n        int64_t ltid_41920;\n        int64_t j_41923;\n        bool cond_41927;\n        int64_t pre1d_41930;\n        int64_t pre1d_41928;\n        int32_t pre1d_41929;\n        int64_t mem_42254[1];\n        int32_t mem_42258[1];\n        int64_t mem_42262[1];\n        int64_t ltid_flat_41941;\n        int64_t ltid_41940;\n        int64_t gtid_41943;\n        int64_t acc_41945;\n        int32_t acc_41946;\n        int64_t acc_41947;\n        bool cond_41948;\n        int64_t acc_41949;\n        int32_t acc_41950;\n        int64_t acc_41951;\n        int64_t mem_param_tmp_42828[1];\n        int32_t mem_param_tmp_42829[1];\n        int64_t mem_param_tmp_42830[1];\n        \n        binop_x_41922 = tile_sizze_41780 * tile_id_41823;\n        ltid_flat_41921 = sext_i32_i64(local_tid_42819);\n        ltid_41920 = sext_i32_i64(sext_i64_i32(ltid_pre_42823));\n        j_41923 = ltid_41920 + binop_x_41922;\n        cond_41927 = slt64(j_41923, nS_27730);\n        pre1d_41930 = btoi_bool_i64(cond_41927);\n        if (cond_41927) {\n            int64_t tile_elem_41931;\n            int32_t tile_elem_41932;\n            \n            tile_elem_41931 = ((__global int64_t *) ext_mem_42224)[j_41923];\n            tile_elem_41932 = ((__global int32_t *) tS_mem_42200)[j_41923];\n            pre1d_41928 = tile_elem_41931;\n            pre1d_41929 = tile_elem_41932;\n        } else {\n            pre1d_41928 = (int64_t) 0;\n            pre1d_41929 = 0;\n        }\n        ((__local int64_t *) color_42705)[ltid_41920] = pre1d_41928;\n        ((__local int32_t *) color_42704)[ltid_41920] = pre1d_41929;\n        ((__local int64_t *) color_42703)[ltid_41920] = pre1d_41930;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_41941 = sext_i32_i64(local_tid_42819);\n        ltid_41940 = se", "xt_i32_i64(sext_i64_i32(ltid_pre_42823));\n        gtid_41943 = binop_x_41788 + ltid_41940;\n        acc_41945 = mem_param_42242[(int64_t) 0];\n        acc_41946 = mem_param_42243[(int64_t) 0];\n        acc_41947 = mem_param_42244[(int64_t) 0];\n        cond_41948 = slt64(gtid_41943, min_res_39102);\n        if (cond_41948) {\n            int32_t eta_p_41944;\n            int64_t x_41952;\n            int32_t x_41953;\n            int64_t x_41954;\n            int64_t redout_42144;\n            int32_t redout_42145;\n            int64_t redout_42146;\n            \n            eta_p_41944 = mem_42229[(int64_t) 0];\n            redout_42144 = acc_41945;\n            redout_42145 = acc_41946;\n            redout_42146 = acc_41947;\n            for (int64_t i_42147 = 0; i_42147 < tile_sizze_41780; i_42147++) {\n                int64_t x_41955;\n                int32_t x_41956;\n                bool defunc_0_neq_res_41964;\n                bool defunc_0_neq_res_41965;\n                bool cond_f_res_41966;\n                bool y_41967;\n                bool cond_41968;\n                bool defunc_0_neq_res_41969;\n                bool defunc_0_neq_res_41970;\n                bool cond_t_res_f_res_41971;\n                bool y_41972;\n                bool cond_t_res_41973;\n                bool x_41974;\n                int64_t defunc_0_op_res_41975;\n                int32_t defunc_0_op_res_41976;\n                int64_t defunc_0_op_res_41977;\n                int64_t redout_tmp_42834;\n                int32_t redout_tmp_42835;\n                int64_t redout_tmp_42836;\n                \n                x_41955 = ((__local int64_t *) color_42705)[i_42147];\n                x_41956 = ((__local int32_t *) color_42704)[i_42147];\n                defunc_0_neq_res_41964 = redout_42145 == eta_p_41944;\n                defunc_0_neq_res_41965 = !defunc_0_neq_res_41964;\n                cond_f_res_41966 = slt64(redout_42144, (int64_t) 0);\n                y_41967 = defunc_0_neq_res_41964 && cond_f_res_41966;\n         ",
                                    "       cond_41968 = defunc_0_neq_res_41965 || y_41967;\n                defunc_0_neq_res_41969 = x_41956 == eta_p_41944;\n                defunc_0_neq_res_41970 = !defunc_0_neq_res_41969;\n                cond_t_res_f_res_41971 = slt64(x_41955, (int64_t) 0);\n                y_41972 = defunc_0_neq_res_41969 && cond_t_res_f_res_41971;\n                cond_t_res_41973 = defunc_0_neq_res_41970 || y_41972;\n                x_41974 = cond_41968 && cond_t_res_41973;\n                if (x_41974) {\n                    defunc_0_op_res_41975 = (int64_t) -1;\n                    defunc_0_op_res_41976 = eta_p_41944;\n                    defunc_0_op_res_41977 = (int64_t) 0;\n                } else {\n                    int64_t x_41957;\n                    int64_t defunc_0_op_res_f_res_41978;\n                    int32_t defunc_0_op_res_f_res_41979;\n                    int64_t defunc_0_op_res_f_res_41980;\n                    \n                    x_41957 = ((__local int64_t *) color_42703)[i_42147];\n                    if (cond_41968) {\n                        defunc_0_op_res_f_res_41978 = x_41955;\n                        defunc_0_op_res_f_res_41979 = x_41956;\n                        defunc_0_op_res_f_res_41980 = x_41957;\n                    } else {\n                        int32_t defunc_0_op_res_f_res_f_res_41981;\n                        int64_t defunc_0_op_res_f_res_f_res_41982;\n                        int64_t defunc_0_op_res_f_res_f_res_41983;\n                        \n                        if (cond_t_res_41973) {\n                            defunc_0_op_res_f_res_f_res_41981 = redout_42145;\n                        } else {\n                            defunc_0_op_res_f_res_f_res_41981 = eta_p_41944;\n                        }\n                        if (cond_t_res_41973) {\n                            defunc_0_op_res_f_res_f_res_41982 = redout_42144;\n                            defunc_0_op_res_f_res_f_res_41983 = redout_42146;\n                        } else {\n                            ", "int64_t min_res_41984;\n                            int64_t tmp_41985;\n                            \n                            min_res_41984 = smin64(x_41955, redout_42144);\n                            tmp_41985 = add64(x_41957, redout_42146);\n                            defunc_0_op_res_f_res_f_res_41982 = min_res_41984;\n                            defunc_0_op_res_f_res_f_res_41983 = tmp_41985;\n                        }\n                        defunc_0_op_res_f_res_41978 = defunc_0_op_res_f_res_f_res_41982;\n                        defunc_0_op_res_f_res_41979 = defunc_0_op_res_f_res_f_res_41981;\n                        defunc_0_op_res_f_res_41980 = defunc_0_op_res_f_res_f_res_41983;\n                    }\n                    defunc_0_op_res_41975 = defunc_0_op_res_f_res_41978;\n                    defunc_0_op_res_41976 = defunc_0_op_res_f_res_41979;\n                    defunc_0_op_res_41977 = defunc_0_op_res_f_res_41980;\n                }\n                redout_tmp_42834 = defunc_0_op_res_41975;\n                redout_tmp_42835 = defunc_0_op_res_41976;\n                redout_tmp_42836 = defunc_0_op_res_41977;\n                redout_42144 = redout_tmp_42834;\n                redout_42145 = redout_tmp_42835;\n                redout_42146 = redout_tmp_42836;\n            }\n            x_41952 = redout_42144;\n            x_41953 = redout_42145;\n            x_41954 = redout_42146;\n            acc_41949 = x_41952;\n            acc_41950 = x_41953;\n            acc_41951 = x_41954;\n        } else {\n            acc_41949 = acc_41945;\n            acc_41950 = acc_41946;\n            acc_41951 = acc_41947;\n        }\n        mem_42254[(int64_t) 0] = acc_41949;\n        mem_42258[(int64_t) 0] = acc_41950;\n        mem_42262[(int64_t) 0] = acc_41951;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_6 = 0; i_6 < 1; i_6++)\n            mem_param_tmp_42828[i_6] = mem_42254[i_6];\n        for (int32_t i_7 = 0; i_7 < 1; i_7++)\n            mem_param_tmp_42829[i_7] = mem_42258[i_7];\n    ", "    for (int32_t i_8 = 0; i_8 < 1; i_8++)\n            mem_param_tmp_42830[i_8] = mem_42262[i_8];\n        for (int32_t i_9 = 0; i_9 < 1; i_9++)\n            mem_param_42242[i_9] = mem_param_tmp_42828[i_9];\n        for (int32_t i_10 = 0; i_10 < 1; i_10++)\n            mem_param_42243[i_10] = mem_param_tmp_42829[i_10];\n        for (int32_t i_11 = 0; i_11 < 1; i_11++)\n            mem_param_42244[i_11] = mem_param_tmp_42830[i_11];\n    }\n    for (int32_t i_12 = 0; i_12 < 1; i_12++)\n        ext_mem_42265[i_12] = mem_param_42242[i_12];\n    for (int32_t i_13 = 0; i_13 < 1; i_13++)\n        ext_mem_42264[i_13] = mem_param_42243[i_13];\n    for (int32_t i_14 = 0; i_14 < 1; i_14++)\n        ext_mem_42263[i_14] = mem_param_42244[i_14];\n    barrier(CLK_LOCAL_MEM_FENCE);\n    if (cond_42021) {\n        for (int32_t i_15 = 0; i_15 < 1; i_15++)\n            ext_mem_42281[i_15] = ext_mem_42265[i_15];\n        for (int32_t i_16 = 0; i_16 < 1; i_16++)\n            ext_mem_42280[i_16] = ext_mem_42263[i_16];\n    } else {\n        int64_t ltid_flat_42023;\n        int64_t ltid_42022;\n        int64_t j_42038;\n        bool cond_42042;\n        int64_t pre1d_42045;\n        int64_t pre1d_42043;\n        int32_t pre1d_42044;\n        int64_t ltid_flat_42059;\n        int64_t ltid_42058;\n        int64_t gtid_42072;\n        int64_t acc_42074;\n        int64_t acc_42076;\n        bool cond_42077;\n        int64_t acc_42078;\n        int64_t acc_42080;\n        \n        ltid_flat_42023 = sext_i32_i64(local_tid_42819);\n        ltid_42022 = sext_i32_i64(sext_i64_i32(ltid_pre_42823));\n        j_42038 = ltid_42022 + binop_x_42037;\n        cond_42042 = slt64(j_42038, nS_27730);\n        pre1d_42045 = btoi_bool_i64(cond_42042);\n        if (cond_42042) {\n            int64_t tile_elem_42046;\n            int32_t tile_elem_42047;\n            \n            tile_elem_42046 = ((__global int64_t *) ext_mem_42224)[j_42038];\n            tile_elem_42047 = ((__global int32_t *) tS_mem_42200)[j_42038];\n            pre1d_42043 = tile_elem_",
                                    "42046;\n            pre1d_42044 = tile_elem_42047;\n        } else {\n            pre1d_42043 = (int64_t) 0;\n            pre1d_42044 = 0;\n        }\n        ((__local int64_t *) color_42705)[ltid_42022] = pre1d_42043;\n        ((__local int32_t *) color_42704)[ltid_42022] = pre1d_42044;\n        ((__local int64_t *) color_42703)[ltid_42022] = pre1d_42045;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_42059 = sext_i32_i64(local_tid_42819);\n        ltid_42058 = sext_i32_i64(sext_i64_i32(ltid_pre_42823));\n        gtid_42072 = binop_x_41788 + ltid_42058;\n        acc_42074 = ext_mem_42265[(int64_t) 0];\n        acc_42076 = ext_mem_42263[(int64_t) 0];\n        cond_42077 = slt64(gtid_42072, min_res_39102);\n        if (cond_42077) {\n            int32_t eta_p_42073;\n            int32_t acc_42075;\n            int64_t x_42081;\n            int32_t x_42082;\n            int64_t x_42083;\n            int64_t redout_42148;\n            int32_t redout_42149;\n            int64_t redout_42150;\n            \n            eta_p_42073 = mem_42229[(int64_t) 0];\n            acc_42075 = ext_mem_42264[(int64_t) 0];\n            redout_42148 = acc_42074;\n            redout_42149 = acc_42075;\n            redout_42150 = acc_42076;\n            for (int64_t i_42151 = 0; i_42151 < residual_input_42020; i_42151++) {\n                int64_t x_42084;\n                int32_t x_42085;\n                bool defunc_0_neq_res_42093;\n                bool defunc_0_neq_res_42094;\n                bool cond_f_res_42095;\n                bool y_42096;\n                bool cond_42097;\n                bool defunc_0_neq_res_42098;\n                bool defunc_0_neq_res_42099;\n                bool cond_t_res_f_res_42100;\n                bool y_42101;\n                bool cond_t_res_42102;\n                bool x_42103;\n                int64_t defunc_0_op_res_42104;\n                int32_t defunc_0_op_res_42105;\n                int64_t defunc_0_op_res_42106;\n                int64_t redout_tmp_42837;\n                int32_", "t redout_tmp_42838;\n                int64_t redout_tmp_42839;\n                \n                x_42084 = ((__local int64_t *) color_42705)[i_42151];\n                x_42085 = ((__local int32_t *) color_42704)[i_42151];\n                defunc_0_neq_res_42093 = redout_42149 == eta_p_42073;\n                defunc_0_neq_res_42094 = !defunc_0_neq_res_42093;\n                cond_f_res_42095 = slt64(redout_42148, (int64_t) 0);\n                y_42096 = defunc_0_neq_res_42093 && cond_f_res_42095;\n                cond_42097 = defunc_0_neq_res_42094 || y_42096;\n                defunc_0_neq_res_42098 = x_42085 == eta_p_42073;\n                defunc_0_neq_res_42099 = !defunc_0_neq_res_42098;\n                cond_t_res_f_res_42100 = slt64(x_42084, (int64_t) 0);\n                y_42101 = defunc_0_neq_res_42098 && cond_t_res_f_res_42100;\n                cond_t_res_42102 = defunc_0_neq_res_42099 || y_42101;\n                x_42103 = cond_42097 && cond_t_res_42102;\n                if (x_42103) {\n                    defunc_0_op_res_42104 = (int64_t) -1;\n                    defunc_0_op_res_42105 = eta_p_42073;\n                    defunc_0_op_res_42106 = (int64_t) 0;\n                } else {\n                    int64_t x_42086;\n                    int64_t defunc_0_op_res_f_res_42107;\n                    int32_t defunc_0_op_res_f_res_42108;\n                    int64_t defunc_0_op_res_f_res_42109;\n                    \n                    x_42086 = ((__local int64_t *) color_42703)[i_42151];\n                    if (cond_42097) {\n                        defunc_0_op_res_f_res_42107 = x_42084;\n                        defunc_0_op_res_f_res_42108 = x_42085;\n                        defunc_0_op_res_f_res_42109 = x_42086;\n                    } else {\n                        int32_t defunc_0_op_res_f_res_f_res_42110;\n                        int64_t defunc_0_op_res_f_res_f_res_42111;\n                        int64_t defunc_0_op_res_f_res_f_res_42112;\n                        \n                        ", "if (cond_t_res_42102) {\n                            defunc_0_op_res_f_res_f_res_42110 = redout_42149;\n                        } else {\n                            defunc_0_op_res_f_res_f_res_42110 = eta_p_42073;\n                        }\n                        if (cond_t_res_42102) {\n                            defunc_0_op_res_f_res_f_res_42111 = redout_42148;\n                            defunc_0_op_res_f_res_f_res_42112 = redout_42150;\n                        } else {\n                            int64_t min_res_42113;\n                            int64_t tmp_42114;\n                            \n                            min_res_42113 = smin64(x_42084, redout_42148);\n                            tmp_42114 = add64(x_42086, redout_42150);\n                            defunc_0_op_res_f_res_f_res_42111 = min_res_42113;\n                            defunc_0_op_res_f_res_f_res_42112 = tmp_42114;\n                        }\n                        defunc_0_op_res_f_res_42107 = defunc_0_op_res_f_res_f_res_42111;\n                        defunc_0_op_res_f_res_42108 = defunc_0_op_res_f_res_f_res_42110;\n                        defunc_0_op_res_f_res_42109 = defunc_0_op_res_f_res_f_res_42112;\n                    }\n                    defunc_0_op_res_42104 = defunc_0_op_res_f_res_42107;\n                    defunc_0_op_res_42105 = defunc_0_op_res_f_res_42108;\n                    defunc_0_op_res_42106 = defunc_0_op_res_f_res_42109;\n                }\n                redout_tmp_42837 = defunc_0_op_res_42104;\n                redout_tmp_42838 = defunc_0_op_res_42105;\n                redout_tmp_42839 = defunc_0_op_res_42106;\n                redout_42148 = redout_tmp_42837;\n                redout_42149 = redout_tmp_42838;\n                redout_42150 = redout_tmp_42839;\n            }\n            x_42081 = redout_42148;\n            x_42082 = redout_42149;\n            x_42083 = redout_42150;\n            acc_42078 = x_42081;\n            acc_42080 = x_42083;\n        } else {\n            acc_42078",
                                    " = acc_42074;\n            acc_42080 = acc_42076;\n        }\n        mem_42275[(int64_t) 0] = acc_42078;\n        mem_42279[(int64_t) 0] = acc_42080;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_17 = 0; i_17 < 1; i_17++)\n            ext_mem_42281[i_17] = mem_42275[i_17];\n        for (int32_t i_18 = 0; i_18 < 1; i_18++)\n            ext_mem_42280[i_18] = mem_42279[i_18];\n    }\n    if (slt64(sext_i32_i64(local_tid_42819) + tile_sizze_41780 * sext_i32_i64(block_id_42820), min_res_39102)) {\n        int64_t tmp_42840 = ext_mem_42281[(int64_t) 0];\n        \n        ((__global int64_t *) mem_42283)[sext_i32_i64(local_tid_42819) + tile_sizze_41780 * sext_i32_i64(block_id_42820)] = tmp_42840;\n    }\n    if (slt64(sext_i32_i64(local_tid_42819) + tile_sizze_41780 * sext_i32_i64(block_id_42820), min_res_39102)) {\n        int64_t tmp_42841 = ext_mem_42280[(int64_t) 0];\n        \n        ((__global int64_t *) mem_42285)[sext_i32_i64(local_tid_42819) + tile_sizze_41780 * sext_i32_i64(block_id_42820)] = tmp_42841;\n    }\n    \n  error_8:\n    return;\n    #undef tile_sizze_41780\n    #undef bytes_42245\n    #undef bytes_42247\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzisegscan_40559_dim1, 1, 1)\nvoid inner_SMJ_intzisegscan_40559(__global int *global_failure, int64_t nR_27729, int64_t num_tblocks_40556, int64_t ext_42367, int64_t ext_42368, int64_t num_virt_blocks_42849, int64_t num_virt_threads_42850, __global unsigned char *ext_mem_42370, __global unsigned char *mem_42373, __global unsigned char *mem_42375, __global unsigned char *status_flags_mem_42851, __global unsigned char *aggregates_mem_42873, __global unsigned char *incprefixes_mem_42875, __global unsigned char *global_dynid_mem_42877)\n{\n    #define segscan_tblock_sizze_40554 (inner_SMJ_intzisegscan_40559zisegscan_tblock_sizze_40554)\n    #define chunk_sizze_42848 (inner_SMJ_intzisegscan_40559zichunk_sizze_42848)\n    \n    volatile __local unsigned char *local_mem_42887_backing_0 = &shared_mem[0];\n    const int64_t local_mem_4288", "7_backing_0_offset = 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_40554), chunk_sizze_42848 * segscan_tblock_sizze_40554 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_40554), chunk_sizze_42848 * segscan_tblock_sizze_40554 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42880;\n    int32_t tblock_sizze_42883;\n    int32_t wave_sizze_42882;\n    int32_t block_id_42881;\n    int32_t global_tid_42879;\n    int64_t phys_tid_40559;\n    int32_t chunk_sizze_32b_42884;\n    int64_t byte_offsets_42885;\n    int64_t warp_byte_offset_42886;\n    __local unsigned char *local_mem_42887;\n    int64_t trans_arr_len_42888;\n    int64_t phys_block_id_42894;\n    int64_t virtloop_bound_42895;\n    \n    local_tid_42880 = get_local_id(0);\n    tblock_sizze_42883 = get_local_size(0);\n    wave_sizze_42882 = LOCKSTEP_WIDTH;\n    block_id_42881 = get_tblock_id(0);\n    global_tid_42879 = block_id_42881 * tblock_sizze_42883 + local_tid_42880;\n    phys_tid_40559 = sext_i32_i64(global_tid_42879);\n    chunk_sizze_32b_42884 = sext_i64_i32(chunk_sizze_42848);\n    byte_offsets_42885 = segscan_tblock_sizze_40554 * (int64_t) 8;\n    warp_byte_offset_42886 = (int64_t) 288;\n    // Allocate reusable shared memory\n    { }\n    local_mem_42887 = (__local unsigned char *) local_mem_42887_backing_0;\n    trans_arr_len_42888 = chunk_sizze_42848 * segscan_tblock_sizze_40554;\n    phys_block_id_42894 = get_tblock_id(0);\n    virtloop_bound_42895 = sdiv_up64(num_virt_blocks_42849 - phys_block_id_42894, num_tblocks_40556);\n    for (int64_t virtloop_i_42896 = 0; virtloop_i_42896 < virtloop_bound_42895; virtloop_i_42896++) {\n        int64_t dynamic_id_42897;\n        int64_t block_offset_42898;\n        int64_t sgm_idx_42899;\n        int32_t boundary_42900;\n        int32_t segsizze_compact_42901;\n        int64_t private_mem_42902[chunk_sizze_42848];\n        int64_t thd_offset", "_42904;\n        int64_t acc_42920;\n        int64_t prefix_42930;\n        bool block_new_sgm_42931;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_42880 == 0) {\n                dynamic_id_42897 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_42877)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_42887)[(int64_t) 0] = dynamic_id_42897;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_42897 == num_virt_blocks_42849 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_42877)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_42897 = ((__local int32_t *) local_mem_42887)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_42898 = dynamic_id_42897 * chunk_sizze_42848 * segscan_tblock_sizze_40554;\n        sgm_idx_42899 = smod64(block_offset_42898, nR_27729);\n        boundary_42900 = sext_i64_i32(smin64(chunk_sizze_42848 * segscan_tblock_sizze_40554, nR_27729 - sgm_idx_42899));\n        segsizze_compact_42901 = sext_i64_i32(smin64(chunk_sizze_42848 * segscan_tblock_sizze_40554, nR_27729));\n        thd_offset_42904 = block_offset_42898 + sext_i32_i64(local_tid_42880);\n        // Load and map\n        {\n            for (int64_t i_42905 = 0; i_42905 < chunk_sizze_42848; i_42905++) {\n                int64_t virt_tid_42906 = thd_offset_42904 + i_42905 * segscan_tblock_sizze_40554;\n                int64_t slice_42907 = nR_27729;\n                int64_t gtid_40558 = virt_tid_42906;\n                int64_t remnant_42908 = virt_tid_42906 - gtid_40558;\n                \n                if (slt64(virt_tid_42906, nR_27729)) {\n                    int64_t eta_p_39458 = ((__global i",
                                    "nt64_t *) ext_mem_42370)[ext_42368 + gtid_40558 * ext_42367];\n                    bool lifted_lambda_res_39459 = slt64((int64_t) 0, eta_p_39458);\n                    int64_t defunc_0_f_res_39460 = btoi_bool_i64(lifted_lambda_res_39459);\n                    \n                    ((__global int64_t *) mem_42375)[gtid_40558] = defunc_0_f_res_39460;\n                    private_mem_42902[i_42905] = defunc_0_f_res_39460;\n                } else {\n                    private_mem_42902[i_42905] = (int64_t) 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_42909 = 0; i_42909 < chunk_sizze_42848; i_42909++) {\n                int64_t sharedIdx_42910 = sext_i32_i64(local_tid_42880) + i_42909 * segscan_tblock_sizze_40554;\n                int64_t tmp_42911 = private_mem_42902[i_42909];\n                \n                ((__local int64_t *) local_mem_42887)[sharedIdx_42910] = tmp_42911;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_42912 = 0; i_42912 < chunk_sizze_42848; i_42912++) {\n                int64_t sharedIdx_42913 = sext_i32_i64(local_tid_42880) * chunk_sizze_42848 + i_42912;\n                int64_t tmp_42914 = ((__local int64_t *) local_mem_42887)[sharedIdx_42913];\n                \n                private_mem_42902[i_42912] = tmp_42914;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_42915 = 0; i_42915 < chunk_sizze_42848 - (int64_t) 1; i_42915++) {\n                int64_t eta_p_39187;\n                int64_t eta_p_39188;\n                \n                eta_p_39187 = private_mem_42902[i_42915];\n                eta_p_39188 = private_mem_42902[i_42915 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_39189 = add64(eta_p_39187, eta_p_39188);\n                \n                private_mem_42902[i_42915 + (int64_t) 1] = defunc_0_op_res_391", "89;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_42916 = private_mem_42902[chunk_sizze_42848 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_42887)[sext_i32_i64(local_tid_42880)] = tmp_42916;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_42917;\n            int64_t eta_p_42918;\n            int64_t eta_p_42921;\n            int64_t eta_p_42922;\n            bool ltid_in_bounds_42924 = slt64(sext_i32_i64(local_tid_42880), num_virt_threads_42850);\n            int32_t skip_threads_42925;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_42924) {\n                    eta_p_42918 = ((volatile __local int64_t *) local_mem_42887)[sext_i32_i64(local_tid_42880)];\n                    if ((local_tid_42880 - squot32(local_tid_42880, 32) * 32) == 0) {\n                        eta_p_42917 = eta_p_42918;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_42925 = 1;\n                while (slt32(skip_threads_42925, 32)) {\n                    bool thread_active_42926 = sle32(skip_threads_42925, local_tid_42880 - squot32(local_tid_42880, 32) * 32) && ltid_in_bounds_42924;\n                    \n                    if (thread_active_42926) {\n                        // read operands\n                        {\n                            eta_p_42917 = ((volatile __local int64_t *) local_mem_42887)[sext_i32_i64(local_tid_42880) - sext_i32_i64(skip_threads_42925)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_42926) {\n                            int64_t defunc_0_op_res_42919 = add64(eta_p_42917, eta_p_42918);\n                            \n                            eta_p_4", "2917 = defunc_0_op_res_42919;\n                        }\n                    }\n                    if (sle32(wave_sizze_42882, skip_threads_42925)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_42926) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_42887)[sext_i32_i64(local_tid_42880)] = eta_p_42917;\n                            eta_p_42918 = eta_p_42917;\n                        }\n                    }\n                    if (sle32(wave_sizze_42882, skip_threads_42925)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_42925 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_42880 - squot32(local_tid_42880, 32) * 32) == 31 && ltid_in_bounds_42924) {\n                    ((volatile __local int64_t *) local_mem_42887)[sext_i32_i64(squot32(local_tid_42880, 32))] = eta_p_42917;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_42927;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_42880, 32) == 0 && ltid_in_bounds_42924) {\n                        eta_p_42922 = ((volatile __local int64_t *) local_mem_42887)[sext_i32_i64(local_tid_42880)];\n                        if ((local_tid_42880 - squot32(local_tid_42880, 32) * 32) == 0) {\n                            eta_p_42921 = eta_p_42922;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_42927 = 1;\n     ",
                                    "               while (slt32(skip_threads_42927, 32)) {\n                        bool thread_active_42928 = sle32(skip_threads_42927, local_tid_42880 - squot32(local_tid_42880, 32) * 32) && (squot32(local_tid_42880, 32) == 0 && ltid_in_bounds_42924);\n                        \n                        if (thread_active_42928) {\n                            // read operands\n                            {\n                                eta_p_42921 = ((volatile __local int64_t *) local_mem_42887)[sext_i32_i64(local_tid_42880) - sext_i32_i64(skip_threads_42927)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_42928) {\n                                int64_t defunc_0_op_res_42923 = add64(eta_p_42921, eta_p_42922);\n                                \n                                eta_p_42921 = defunc_0_op_res_42923;\n                            }\n                        }\n                        if (sle32(wave_sizze_42882, skip_threads_42927)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_42928) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_42887)[sext_i32_i64(local_tid_42880)] = eta_p_42921;\n                                eta_p_42922 = eta_p_42921;\n                            }\n                        }\n                        if (sle32(wave_sizze_42882, skip_threads_42927)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_42927 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_42929 = squot32(local_tid_42880, 32) == 0 || !ltid_in_bounds_42924;\n            \n            // carry-in for every block except the f", "irst\n            {\n                // read operands\n                {\n                    if (!no_carry_in_42929) {\n                        eta_p_42918 = eta_p_42917;\n                        eta_p_42917 = ((__local int64_t *) local_mem_42887)[sext_i32_i64(squot32(local_tid_42880, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_42929) {\n                        int64_t defunc_0_op_res_42919 = add64(eta_p_42917, eta_p_42918);\n                        \n                        eta_p_42917 = defunc_0_op_res_42919;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_42929) {\n                        ((__local int64_t *) local_mem_42887)[sext_i32_i64(local_tid_42880)] = eta_p_42917;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_42880, 32) == 0 && ltid_in_bounds_42924) {\n                    ((__local int64_t *) local_mem_42887)[sext_i32_i64(local_tid_42880)] = eta_p_42918;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_42880 == 0) {\n                acc_42920 = ((__local int64_t *) local_mem_42887)[segscan_tblock_sizze_40554 - (int64_t) 1];\n            } else {\n                acc_42920 = ((__local int64_t *) local_mem_42887)[sext_i32_i64(local_tid_42880) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_42930 = (int64_t) 0;\n        block_new_sgm_42931 = sgm_idx_42899 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_42931 && local_tid_42880 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_42875)[dynamic_id_42897] = acc_42920;\n                mem_f", "ence_global();\n                ((volatile __global int8_t *) status_flags_mem_42851)[dynamic_id_42897] = (int8_t) 2;\n                acc_42920 = (int64_t) 0;\n            }\n            if (!block_new_sgm_42931 && slt32(local_tid_42880, wave_sizze_42882)) {\n                if (local_tid_42880 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_42873)[dynamic_id_42897] = acc_42920;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_42851)[dynamic_id_42897] = (int8_t) 1;\n                    \n                    int8_t tmp_42932 = ((volatile __global int8_t *) status_flags_mem_42851)[dynamic_id_42897 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_42887)[(int64_t) 0] = tmp_42932;\n                }\n                mem_fence_local();\n                \n                int8_t status_42933 = ((__local int8_t *) local_mem_42887)[(int64_t) 0];\n                \n                if (status_42933 == (int8_t) 2) {\n                    if (local_tid_42880 == 0) {\n                        prefix_42930 = ((volatile __global int64_t *) incprefixes_mem_42875)[dynamic_id_42897 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_42934 = sext_i64_i32(dynamic_id_42897 - sext_i32_i64(wave_sizze_42882));\n                    \n                    while (slt32(wave_sizze_42882 * -1, readOffset_42934)) {\n                        int32_t read_i_42935 = readOffset_42934 + local_tid_42880;\n                        int64_t aggr_42936 = (int64_t) 0;\n                        int8_t flag_42937 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_42935)) {\n                            flag_42937 = ((volatile __global int8_t *) status_flags_mem_42851)[sext_i32_i64(read_i_42935)];\n                            if (flag_42937 == (int8_t) 2) {\n                                aggr_42936 = ((volatile __global int64_t ",
                                    "*) incprefixes_mem_42875)[sext_i32_i64(read_i_42935)];\n                            } else if (flag_42937 == (int8_t) 1) {\n                                aggr_42936 = ((volatile __global int64_t *) aggregates_mem_42873)[sext_i32_i64(read_i_42935)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_42887)[(int64_t) 4 + sext_i32_i64(local_tid_42880)] = aggr_42936;\n                        ((__local int8_t *) local_mem_42887)[sext_i32_i64(local_tid_42880)] = flag_42937;\n                        flag_42937 = ((__local int8_t *) local_mem_42887)[sext_i32_i64(wave_sizze_42882) - (int64_t) 1];\n                        if (slt8(flag_42937, (int8_t) 2)) {\n                            int8_t flg_x_42941;\n                            int8_t flg_y_42942;\n                            int64_t eta_p_42938;\n                            int64_t eta_p_42939;\n                            int32_t skip_threads_42943;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_42942 = ((volatile __local int8_t *) local_mem_42887)[sext_i32_i64(local_tid_42880)];\n                                eta_p_42939 = ((volatile __local int64_t *) local_mem_42887)[(int64_t) 4 + sext_i32_i64(local_tid_42880)];\n                                if ((local_tid_42880 - squot32(local_tid_42880, 32) * 32) == 0) {\n                                    eta_p_42938 = eta_p_42939;\n                                    flg_x_42941 = flg_y_42942;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_42943 = 1;\n                                while (slt32(skip_threads_42943, 32)) {\n                                    if (sle32(skip_threads_42943, local_tid_42880 - squot32(local_tid_42880, 32) * 32)) {\n           ", "                             // read operands\n                                        {\n                                            flg_x_42941 = ((volatile __local int8_t *) local_mem_42887)[sext_i32_i64(local_tid_42880) - sext_i32_i64(skip_threads_42943)];\n                                            eta_p_42938 = ((volatile __local int64_t *) local_mem_42887)[(int64_t) 4 + (sext_i32_i64(local_tid_42880) - sext_i32_i64(skip_threads_42943))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_42942 == (int8_t) 2 || flg_y_42942 == (int8_t) 0) {\n                                                flg_x_42941 = flg_y_42942;\n                                                eta_p_42938 = eta_p_42939;\n                                            } else {\n                                                int64_t defunc_0_op_res_42940 = add64(eta_p_42938, eta_p_42939);\n                                                \n                                                eta_p_42938 = defunc_0_op_res_42940;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_42887)[sext_i32_i64(local_tid_42880)] = flg_x_42941;\n                                            flg_y_42942 = flg_x_42941;\n                                            ((volatile __local int64_t *) local_mem_42887)[(int64_t) 4 + sext_i32_i64(local_tid_42880)] = eta_p_42938;\n                                            eta_p_42939 = eta_p_42938;\n                                        }\n                                    }\n                                    skip_threads_42943 *= 2;\n                                }\n                            }\n                        }\n      ", "                  flag_42937 = ((__local int8_t *) local_mem_42887)[sext_i32_i64(wave_sizze_42882) - (int64_t) 1];\n                        aggr_42936 = ((__local int64_t *) local_mem_42887)[(int64_t) 4 + (sext_i32_i64(wave_sizze_42882) - (int64_t) 1)];\n                        if (flag_42937 == (int8_t) 2) {\n                            readOffset_42934 = wave_sizze_42882 * -1;\n                        } else if (flag_42937 == (int8_t) 1) {\n                            readOffset_42934 -= wave_sizze_42882;\n                        }\n                        if (slt8((int8_t) 0, flag_42937)) {\n                            int64_t eta_p_42944 = aggr_42936;\n                            int64_t eta_p_42945 = prefix_42930;\n                            int64_t defunc_0_op_res_42946 = add64(eta_p_42944, eta_p_42945);\n                            \n                            prefix_42930 = defunc_0_op_res_42946;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_42880 == 0) {\n                    if (boundary_42900 == sext_i64_i32(segscan_tblock_sizze_40554 * chunk_sizze_42848)) {\n                        int64_t eta_p_42947 = prefix_42930;\n                        int64_t eta_p_42948 = acc_42920;\n                        int64_t defunc_0_op_res_42949 = add64(eta_p_42947, eta_p_42948);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_42875)[dynamic_id_42897] = defunc_0_op_res_42949;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_42851)[dynamic_id_42897] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_42887)[(int64_t) 4] = prefix_42930;\n                    acc_42920 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_42897 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_42930 = ((__local ",
                                    "int64_t *) local_mem_42887)[(int64_t) 4];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_42950;\n            int64_t eta_p_42951;\n            int64_t eta_p_42953 = prefix_42930;\n            int64_t eta_p_42954 = acc_42920;\n            \n            if (slt32(local_tid_42880 * chunk_sizze_32b_42884, boundary_42900) && !block_new_sgm_42931) {\n                int64_t defunc_0_op_res_42955 = add64(eta_p_42953, eta_p_42954);\n                \n                eta_p_42950 = defunc_0_op_res_42955;\n            } else {\n                eta_p_42950 = acc_42920;\n            }\n            \n            int32_t stopping_point_42956 = segsizze_compact_42901 - srem32(local_tid_42880 * chunk_sizze_32b_42884 - 1 + segsizze_compact_42901 - boundary_42900, segsizze_compact_42901);\n            \n            for (int64_t i_42957 = 0; i_42957 < chunk_sizze_42848; i_42957++) {\n                if (slt32(sext_i64_i32(i_42957), stopping_point_42956 - 1)) {\n                    eta_p_42951 = private_mem_42902[i_42957];\n                    \n                    int64_t defunc_0_op_res_42952 = add64(eta_p_42950, eta_p_42951);\n                    \n                    private_mem_42902[i_42957] = defunc_0_op_res_42952;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_42958 = 0; i_42958 < chunk_sizze_42848; i_42958++) {\n                int64_t sharedIdx_42959 = sext_i32_i64(local_tid_42880) * chunk_sizze_42848 + i_42958;\n                int64_t tmp_42960 = private_mem_42902[i_42958];\n                \n                ((__local int64_t *) local_mem_42887)[sharedIdx_42959] = tmp_42960;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_42961 = 0; i_42961 < chunk_sizze_42848; i_42961++) {\n                int64_t flat_idx_42962 = thd_offset_42904 + i_42961 * segscan_tblock_sizze_", "40554;\n                int64_t slice_42963 = nR_27729;\n                int64_t gtid_40558 = flat_idx_42962;\n                int64_t remnant_42964 = flat_idx_42962 - gtid_40558;\n                \n                if (slt64(flat_idx_42962, nR_27729)) {\n                    int64_t tmp_42965 = ((__local int64_t *) local_mem_42887)[flat_idx_42962 - block_offset_42898];\n                    \n                    ((__global int64_t *) mem_42373)[gtid_40558] = tmp_42965;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_40554\n    #undef chunk_sizze_42848\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzisegscan_40575_dim1, 1, 1)\nvoid inner_SMJ_intzisegscan_40575(__global int *global_failure, int64_t m_39200, int64_t num_tblocks_40572, int64_t num_virt_blocks_42986, int64_t num_virt_threads_42987, __global unsigned char *mem_42377, __global unsigned char *mem_42387, __global unsigned char *mem_42389, __global unsigned char *mem_42391, __global unsigned char *status_flags_mem_42988, __global unsigned char *aggregates_mem_42990, __global unsigned char *incprefixes_mem_42992, __global unsigned char *aggregates_mem_42994, __global unsigned char *incprefixes_mem_42996, __global unsigned char *global_dynid_mem_42998)\n{\n    #define segscan_tblock_sizze_40570 (inner_SMJ_intzisegscan_40575zisegscan_tblock_sizze_40570)\n    #define chunk_sizze_42985 (inner_SMJ_intzisegscan_40575zichunk_sizze_42985)\n    \n    volatile __local unsigned char *local_mem_43010_backing_0 = &shared_mem[0];\n    const int64_t local_mem_43010_backing_0_offset = 0 + (smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_40570, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_40570), smax64(chunk_sizze_42985 * segscan_tblock_sizze_40570 * (int64_t) 8, chunk_sizze_42985 * segscan_tblock_sizze_40570 * (int64_t) 8)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * seg", "scan_tblock_sizze_40570, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_40570), smax64(chunk_sizze_42985 * segscan_tblock_sizze_40570 * (int64_t) 8, chunk_sizze_42985 * segscan_tblock_sizze_40570 * (int64_t) 8)), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43001;\n    int32_t tblock_sizze_43004;\n    int32_t wave_sizze_43003;\n    int32_t block_id_43002;\n    int32_t global_tid_43000;\n    int64_t phys_tid_40575;\n    int32_t chunk_sizze_32b_43005;\n    int64_t byte_offsets_43006;\n    int64_t byte_offsets_43007;\n    int64_t warp_byte_offset_43008;\n    int64_t warp_byte_offset_43009;\n    __local unsigned char *local_mem_43010;\n    int64_t trans_arr_len_43011;\n    int64_t phys_block_id_43020;\n    int64_t virtloop_bound_43021;\n    \n    local_tid_43001 = get_local_id(0);\n    tblock_sizze_43004 = get_local_size(0);\n    wave_sizze_43003 = LOCKSTEP_WIDTH;\n    block_id_43002 = get_tblock_id(0);\n    global_tid_43000 = block_id_43002 * tblock_sizze_43004 + local_tid_43001;\n    phys_tid_40575 = sext_i32_i64(global_tid_43000);\n    chunk_sizze_32b_43005 = sext_i64_i32(chunk_sizze_42985);\n    byte_offsets_43006 = segscan_tblock_sizze_40570 * (int64_t) 8;\n    byte_offsets_43007 = sdiv_up64(byte_offsets_43006, (int64_t) 8) * (int64_t) 8 + segscan_tblock_sizze_40570 * (int64_t) 8;\n    warp_byte_offset_43008 = (int64_t) 288;\n    warp_byte_offset_43009 = sdiv_up64(warp_byte_offset_43008, (int64_t) 8) * (int64_t) 8 + (int64_t) 256;\n    // Allocate reusable shared memory\n    { }\n    local_mem_43010 = (__local unsigned char *) local_mem_43010_backing_0;\n    trans_arr_len_43011 = chunk_sizze_42985 * segscan_tblock_sizze_40570;\n    phys_block_id_43020 = get_tblock_id(0);\n    virtloop_bound_43021 = sdiv_up64(num_virt_blocks_42986 - phys_block_id_43020, num_tblocks_40572);\n    for (int64_t virtloop_i_43022 = 0; virtloop_i_43022 < virtloop_bound_43021; virtloop_i_43022++) {\n        int64_t dynamic_id_43023;\n        int64",
                                    "_t block_offset_43024;\n        int64_t sgm_idx_43025;\n        int32_t boundary_43026;\n        int32_t segsizze_compact_43027;\n        int64_t private_mem_43028[chunk_sizze_42985];\n        int64_t private_mem_43030[chunk_sizze_42985];\n        int64_t thd_offset_43032;\n        int64_t acc_43058;\n        int64_t acc_43059;\n        int64_t prefix_43072;\n        int64_t prefix_43073;\n        bool block_new_sgm_43074;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_43001 == 0) {\n                dynamic_id_43023 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_42998)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_43010)[(int64_t) 0] = dynamic_id_43023;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_43023 == num_virt_blocks_42986 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_42998)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_43023 = ((__local int32_t *) local_mem_43010)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_43024 = dynamic_id_43023 * chunk_sizze_42985 * segscan_tblock_sizze_40570;\n        sgm_idx_43025 = smod64(block_offset_43024, m_39200);\n        boundary_43026 = sext_i64_i32(smin64(chunk_sizze_42985 * segscan_tblock_sizze_40570, m_39200 - sgm_idx_43025));\n        segsizze_compact_43027 = sext_i64_i32(smin64(chunk_sizze_42985 * segscan_tblock_sizze_40570, m_39200));\n        thd_offset_43032 = block_offset_43024 + sext_i32_i64(local_tid_43001);\n        // Load and map\n        {\n            for (int64_t i_43033 = 0; i_43033 < chunk_sizze_42985; i_43033++) {\n                int64_t virt_tid_43034 = thd_offset_43032 + i_43033 * segscan_tb", "lock_sizze_40570;\n                int64_t slice_43035 = m_39200;\n                int64_t gtid_40574 = virt_tid_43034;\n                int64_t remnant_43036 = virt_tid_43034 - gtid_40574;\n                \n                if (slt64(virt_tid_43034, m_39200)) {\n                    int64_t x_39463 = ((__global int64_t *) mem_42377)[gtid_40574];\n                    bool lifted_lambda_res_39465 = slt64((int64_t) 1, x_39463);\n                    int64_t defunc_0_f_res_39466 = btoi_bool_i64(lifted_lambda_res_39465);\n                    \n                    ((__global int64_t *) mem_42391)[gtid_40574] = defunc_0_f_res_39466;\n                    private_mem_43028[i_43033] = x_39463;\n                    private_mem_43030[i_43033] = defunc_0_f_res_39466;\n                } else {\n                    private_mem_43028[i_43033] = (int64_t) 0;\n                    private_mem_43030[i_43033] = (int64_t) 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_43037 = 0; i_43037 < chunk_sizze_42985; i_43037++) {\n                int64_t sharedIdx_43038 = sext_i32_i64(local_tid_43001) + i_43037 * segscan_tblock_sizze_40570;\n                int64_t tmp_43039 = private_mem_43028[i_43037];\n                \n                ((__local int64_t *) local_mem_43010)[sharedIdx_43038] = tmp_43039;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_43040 = 0; i_43040 < chunk_sizze_42985; i_43040++) {\n                int64_t sharedIdx_43041 = sext_i32_i64(local_tid_43001) * chunk_sizze_42985 + i_43040;\n                int64_t tmp_43042 = ((__local int64_t *) local_mem_43010)[sharedIdx_43041];\n                \n                private_mem_43028[i_43040] = tmp_43042;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_43043 = 0; i_43043 < chunk_sizze_42985; i_43043++) {\n                int64_t sharedIdx_43044 = sext_i32_i64(local_tid_43001) + i_430", "43 * segscan_tblock_sizze_40570;\n                int64_t tmp_43045 = private_mem_43030[i_43043];\n                \n                ((__local int64_t *) local_mem_43010)[sharedIdx_43044] = tmp_43045;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_43046 = 0; i_43046 < chunk_sizze_42985; i_43046++) {\n                int64_t sharedIdx_43047 = sext_i32_i64(local_tid_43001) * chunk_sizze_42985 + i_43046;\n                int64_t tmp_43048 = ((__local int64_t *) local_mem_43010)[sharedIdx_43047];\n                \n                private_mem_43030[i_43046] = tmp_43048;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_43049 = 0; i_43049 < chunk_sizze_42985 - (int64_t) 1; i_43049++) {\n                int64_t eta_p_39237;\n                int64_t eta_p_39238;\n                \n                eta_p_39237 = private_mem_43028[i_43049];\n                eta_p_39238 = private_mem_43028[i_43049 + (int64_t) 1];\n                \n                int64_t eta_p_39330;\n                int64_t eta_p_39331;\n                \n                eta_p_39330 = private_mem_43030[i_43049];\n                eta_p_39331 = private_mem_43030[i_43049 + (int64_t) 1];\n                \n                int64_t lifted_lambda_res_39239 = add64(eta_p_39237, eta_p_39238);\n                int64_t defunc_0_op_res_39332 = add64(eta_p_39330, eta_p_39331);\n                \n                private_mem_43028[i_43049 + (int64_t) 1] = lifted_lambda_res_39239;\n                private_mem_43030[i_43049 + (int64_t) 1] = defunc_0_op_res_39332;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_43050 = private_mem_43028[chunk_sizze_42985 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_43010)[sext_i32_i64(local_tid_43001)] = tmp_43050;\n            \n            int64_t tmp_43051 = private_mem_43030[chunk_sizze_42985 - (int64_t) 1];\n            ",
                                    "\n            ((__local int64_t *) local_mem_43010)[squot64(byte_offsets_43006, (int64_t) 8) + sext_i32_i64(local_tid_43001)] = tmp_43051;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_43052;\n            int64_t eta_p_43053;\n            int64_t eta_p_43054;\n            int64_t eta_p_43055;\n            int64_t eta_p_43060;\n            int64_t eta_p_43061;\n            int64_t eta_p_43062;\n            int64_t eta_p_43063;\n            bool ltid_in_bounds_43066 = slt64(sext_i32_i64(local_tid_43001), num_virt_threads_42987);\n            int32_t skip_threads_43067;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_43066) {\n                    eta_p_43054 = ((volatile __local int64_t *) local_mem_43010)[sext_i32_i64(local_tid_43001)];\n                    eta_p_43055 = ((volatile __local int64_t *) local_mem_43010)[squot64(byte_offsets_43006, (int64_t) 8) + sext_i32_i64(local_tid_43001)];\n                    if ((local_tid_43001 - squot32(local_tid_43001, 32) * 32) == 0) {\n                        eta_p_43052 = eta_p_43054;\n                        eta_p_43053 = eta_p_43055;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_43067 = 1;\n                while (slt32(skip_threads_43067, 32)) {\n                    bool thread_active_43068 = sle32(skip_threads_43067, local_tid_43001 - squot32(local_tid_43001, 32) * 32) && ltid_in_bounds_43066;\n                    \n                    if (thread_active_43068) {\n                        // read operands\n                        {\n                            eta_p_43052 = ((volatile __local int64_t *) local_mem_43010)[sext_i32_i64(local_tid_43001) - sext_i32_i64(skip_threads_43067)];\n                            eta_p_43053 = ((volatile __local int64_t *) local_mem_43010)[squot64(byte_offsets_43006", ", (int64_t) 8) + (sext_i32_i64(local_tid_43001) - sext_i32_i64(skip_threads_43067))];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_43068) {\n                            int64_t lifted_lambda_res_43056 = add64(eta_p_43052, eta_p_43054);\n                            int64_t defunc_0_op_res_43057 = add64(eta_p_43053, eta_p_43055);\n                            \n                            eta_p_43052 = lifted_lambda_res_43056;\n                            eta_p_43053 = defunc_0_op_res_43057;\n                        }\n                    }\n                    if (sle32(wave_sizze_43003, skip_threads_43067)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_43068) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_43010)[sext_i32_i64(local_tid_43001)] = eta_p_43052;\n                            eta_p_43054 = eta_p_43052;\n                            ((volatile __local int64_t *) local_mem_43010)[squot64(byte_offsets_43006, (int64_t) 8) + sext_i32_i64(local_tid_43001)] = eta_p_43053;\n                            eta_p_43055 = eta_p_43053;\n                        }\n                    }\n                    if (sle32(wave_sizze_43003, skip_threads_43067)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_43067 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_43001 - squot32(local_tid_43001, 32) * 32) == 31 && ltid_in_bounds_43066) {\n                    ((volatile __local int64_t *) local_mem_43010)[sext_i32_i64(squot32(local_tid_43001, 32))] = eta_p_43052;\n                    ((volatile __local int64_t *) local_mem_43010)[", "squot64(byte_offsets_43006, (int64_t) 8) + sext_i32_i64(squot32(local_tid_43001, 32))] = eta_p_43053;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_43069;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_43001, 32) == 0 && ltid_in_bounds_43066) {\n                        eta_p_43062 = ((volatile __local int64_t *) local_mem_43010)[sext_i32_i64(local_tid_43001)];\n                        eta_p_43063 = ((volatile __local int64_t *) local_mem_43010)[squot64(byte_offsets_43006, (int64_t) 8) + sext_i32_i64(local_tid_43001)];\n                        if ((local_tid_43001 - squot32(local_tid_43001, 32) * 32) == 0) {\n                            eta_p_43060 = eta_p_43062;\n                            eta_p_43061 = eta_p_43063;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_43069 = 1;\n                    while (slt32(skip_threads_43069, 32)) {\n                        bool thread_active_43070 = sle32(skip_threads_43069, local_tid_43001 - squot32(local_tid_43001, 32) * 32) && (squot32(local_tid_43001, 32) == 0 && ltid_in_bounds_43066);\n                        \n                        if (thread_active_43070) {\n                            // read operands\n                            {\n                                eta_p_43060 = ((volatile __local int64_t *) local_mem_43010)[sext_i32_i64(local_tid_43001) - sext_i32_i64(skip_threads_43069)];\n                                eta_p_43061 = ((volatile __local int64_t *) local_mem_43010)[squot64(byte_offsets_43006, (int64_t) 8) + (sext_i32_i64(local_tid_43001) - sext_i32_i64(skip_threads_43069))];\n                            }\n                        }\n         ",
                                    "               // perform operation\n                        {\n                            if (thread_active_43070) {\n                                int64_t lifted_lambda_res_43064 = add64(eta_p_43060, eta_p_43062);\n                                int64_t defunc_0_op_res_43065 = add64(eta_p_43061, eta_p_43063);\n                                \n                                eta_p_43060 = lifted_lambda_res_43064;\n                                eta_p_43061 = defunc_0_op_res_43065;\n                            }\n                        }\n                        if (sle32(wave_sizze_43003, skip_threads_43069)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_43070) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_43010)[sext_i32_i64(local_tid_43001)] = eta_p_43060;\n                                eta_p_43062 = eta_p_43060;\n                                ((volatile __local int64_t *) local_mem_43010)[squot64(byte_offsets_43006, (int64_t) 8) + sext_i32_i64(local_tid_43001)] = eta_p_43061;\n                                eta_p_43063 = eta_p_43061;\n                            }\n                        }\n                        if (sle32(wave_sizze_43003, skip_threads_43069)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_43069 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_43071 = squot32(local_tid_43001, 32) == 0 || !ltid_in_bounds_43066;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_43071) {\n                        eta_p_43054 = eta_p_43052;\n                        eta_p_43055 = eta_p_43053;\n          ", "              eta_p_43052 = ((__local int64_t *) local_mem_43010)[sext_i32_i64(squot32(local_tid_43001, 32)) - (int64_t) 1];\n                        eta_p_43053 = ((__local int64_t *) local_mem_43010)[squot64(byte_offsets_43006, (int64_t) 8) + (sext_i32_i64(squot32(local_tid_43001, 32)) - (int64_t) 1)];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_43071) {\n                        int64_t lifted_lambda_res_43056 = add64(eta_p_43052, eta_p_43054);\n                        int64_t defunc_0_op_res_43057 = add64(eta_p_43053, eta_p_43055);\n                        \n                        eta_p_43052 = lifted_lambda_res_43056;\n                        eta_p_43053 = defunc_0_op_res_43057;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_43071) {\n                        ((__local int64_t *) local_mem_43010)[sext_i32_i64(local_tid_43001)] = eta_p_43052;\n                        ((__local int64_t *) local_mem_43010)[squot64(byte_offsets_43006, (int64_t) 8) + sext_i32_i64(local_tid_43001)] = eta_p_43053;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_43001, 32) == 0 && ltid_in_bounds_43066) {\n                    ((__local int64_t *) local_mem_43010)[sext_i32_i64(local_tid_43001)] = eta_p_43054;\n                    ((__local int64_t *) local_mem_43010)[squot64(byte_offsets_43006, (int64_t) 8) + sext_i32_i64(local_tid_43001)] = eta_p_43055;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_43001 == 0) {\n                acc_43058 = ((__local int64_t *) local_mem_43010)[segscan_tblock_sizze_40570 - (int64_t) 1];\n                acc_43059 = ((__local int64_t *) local_mem_4301", "0)[squot64(byte_offsets_43006, (int64_t) 8) + (segscan_tblock_sizze_40570 - (int64_t) 1)];\n            } else {\n                acc_43058 = ((__local int64_t *) local_mem_43010)[sext_i32_i64(local_tid_43001) - (int64_t) 1];\n                acc_43059 = ((__local int64_t *) local_mem_43010)[squot64(byte_offsets_43006, (int64_t) 8) + (sext_i32_i64(local_tid_43001) - (int64_t) 1)];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_43072 = (int64_t) 0;\n        prefix_43073 = (int64_t) 0;\n        block_new_sgm_43074 = sgm_idx_43025 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_43074 && local_tid_43001 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_42992)[dynamic_id_43023] = acc_43058;\n                ((volatile __global int64_t *) incprefixes_mem_42996)[dynamic_id_43023] = acc_43059;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_42988)[dynamic_id_43023] = (int8_t) 2;\n                acc_43058 = (int64_t) 0;\n                acc_43059 = (int64_t) 0;\n            }\n            if (!block_new_sgm_43074 && slt32(local_tid_43001, wave_sizze_43003)) {\n                if (local_tid_43001 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_42990)[dynamic_id_43023] = acc_43058;\n                    ((volatile __global int64_t *) aggregates_mem_42994)[dynamic_id_43023] = acc_43059;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_42988)[dynamic_id_43023] = (int8_t) 1;\n                    \n                    int8_t tmp_43075 = ((volatile __global int8_t *) status_flags_mem_42988)[dynamic_id_43023 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_43010)[(int64_t) 0] = tmp_43075;\n                }\n                mem_fence_local();\n                \n                int8_t status_43076 = ((__local int8_t *) local_mem_4301",
                                    "0)[(int64_t) 0];\n                \n                if (status_43076 == (int8_t) 2) {\n                    if (local_tid_43001 == 0) {\n                        prefix_43072 = ((volatile __global int64_t *) incprefixes_mem_42992)[dynamic_id_43023 - (int64_t) 1];\n                        prefix_43073 = ((volatile __global int64_t *) incprefixes_mem_42996)[dynamic_id_43023 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_43077 = sext_i64_i32(dynamic_id_43023 - sext_i32_i64(wave_sizze_43003));\n                    \n                    while (slt32(wave_sizze_43003 * -1, readOffset_43077)) {\n                        int32_t read_i_43078 = readOffset_43077 + local_tid_43001;\n                        int64_t aggr_43079 = (int64_t) 0;\n                        int64_t aggr_43080 = (int64_t) 0;\n                        int8_t flag_43081 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_43078)) {\n                            flag_43081 = ((volatile __global int8_t *) status_flags_mem_42988)[sext_i32_i64(read_i_43078)];\n                            if (flag_43081 == (int8_t) 2) {\n                                aggr_43079 = ((volatile __global int64_t *) incprefixes_mem_42992)[sext_i32_i64(read_i_43078)];\n                                aggr_43080 = ((volatile __global int64_t *) incprefixes_mem_42996)[sext_i32_i64(read_i_43078)];\n                            } else if (flag_43081 == (int8_t) 1) {\n                                aggr_43079 = ((volatile __global int64_t *) aggregates_mem_42990)[sext_i32_i64(read_i_43078)];\n                                aggr_43080 = ((volatile __global int64_t *) aggregates_mem_42994)[sext_i32_i64(read_i_43078)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_43010)[(int64_t) 4 + sext_i32_i64(local_tid_43001)] = aggr_43079;\n                        ((__local int64_t *) local_mem_43010)[squot64(warp_byte_offset_", "43008, (int64_t) 8) + sext_i32_i64(local_tid_43001)] = aggr_43080;\n                        ((__local int8_t *) local_mem_43010)[sext_i32_i64(local_tid_43001)] = flag_43081;\n                        flag_43081 = ((__local int8_t *) local_mem_43010)[sext_i32_i64(wave_sizze_43003) - (int64_t) 1];\n                        if (slt8(flag_43081, (int8_t) 2)) {\n                            int8_t flg_x_43088;\n                            int8_t flg_y_43089;\n                            int64_t eta_p_43082;\n                            int64_t eta_p_43083;\n                            int64_t eta_p_43084;\n                            int64_t eta_p_43085;\n                            int32_t skip_threads_43090;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_43089 = ((volatile __local int8_t *) local_mem_43010)[sext_i32_i64(local_tid_43001)];\n                                eta_p_43084 = ((volatile __local int64_t *) local_mem_43010)[(int64_t) 4 + sext_i32_i64(local_tid_43001)];\n                                eta_p_43085 = ((volatile __local int64_t *) local_mem_43010)[squot64(warp_byte_offset_43008, (int64_t) 8) + sext_i32_i64(local_tid_43001)];\n                                if ((local_tid_43001 - squot32(local_tid_43001, 32) * 32) == 0) {\n                                    eta_p_43082 = eta_p_43084;\n                                    eta_p_43083 = eta_p_43085;\n                                    flg_x_43088 = flg_y_43089;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_43090 = 1;\n                                while (slt32(skip_threads_43090, 32)) {\n                                    if (sle32(skip_threads_43090, local_tid_43001 - squot32(local_tid_43001, 32) * 32)) {\n                                     ", "   // read operands\n                                        {\n                                            flg_x_43088 = ((volatile __local int8_t *) local_mem_43010)[sext_i32_i64(local_tid_43001) - sext_i32_i64(skip_threads_43090)];\n                                            eta_p_43082 = ((volatile __local int64_t *) local_mem_43010)[(int64_t) 4 + (sext_i32_i64(local_tid_43001) - sext_i32_i64(skip_threads_43090))];\n                                            eta_p_43083 = ((volatile __local int64_t *) local_mem_43010)[squot64(warp_byte_offset_43008, (int64_t) 8) + (sext_i32_i64(local_tid_43001) - sext_i32_i64(skip_threads_43090))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_43089 == (int8_t) 2 || flg_y_43089 == (int8_t) 0) {\n                                                flg_x_43088 = flg_y_43089;\n                                                eta_p_43082 = eta_p_43084;\n                                                eta_p_43083 = eta_p_43085;\n                                            } else {\n                                                int64_t lifted_lambda_res_43086 = add64(eta_p_43082, eta_p_43084);\n                                                int64_t defunc_0_op_res_43087 = add64(eta_p_43083, eta_p_43085);\n                                                \n                                                eta_p_43082 = lifted_lambda_res_43086;\n                                                eta_p_43083 = defunc_0_op_res_43087;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_43010)[sext_i32_i64(local_tid_43001)] = flg_x_43088;\n                                            flg_y_43089 = ",
                                    "flg_x_43088;\n                                            ((volatile __local int64_t *) local_mem_43010)[(int64_t) 4 + sext_i32_i64(local_tid_43001)] = eta_p_43082;\n                                            eta_p_43084 = eta_p_43082;\n                                            ((volatile __local int64_t *) local_mem_43010)[squot64(warp_byte_offset_43008, (int64_t) 8) + sext_i32_i64(local_tid_43001)] = eta_p_43083;\n                                            eta_p_43085 = eta_p_43083;\n                                        }\n                                    }\n                                    skip_threads_43090 *= 2;\n                                }\n                            }\n                        }\n                        flag_43081 = ((__local int8_t *) local_mem_43010)[sext_i32_i64(wave_sizze_43003) - (int64_t) 1];\n                        aggr_43079 = ((__local int64_t *) local_mem_43010)[(int64_t) 4 + (sext_i32_i64(wave_sizze_43003) - (int64_t) 1)];\n                        aggr_43080 = ((__local int64_t *) local_mem_43010)[squot64(warp_byte_offset_43008, (int64_t) 8) + (sext_i32_i64(wave_sizze_43003) - (int64_t) 1)];\n                        if (flag_43081 == (int8_t) 2) {\n                            readOffset_43077 = wave_sizze_43003 * -1;\n                        } else if (flag_43081 == (int8_t) 1) {\n                            readOffset_43077 -= wave_sizze_43003;\n                        }\n                        if (slt8((int8_t) 0, flag_43081)) {\n                            int64_t eta_p_43091 = aggr_43079;\n                            int64_t eta_p_43092 = aggr_43080;\n                            int64_t eta_p_43093 = prefix_43072;\n                            int64_t eta_p_43094 = prefix_43073;\n                            int64_t lifted_lambda_res_43095 = add64(eta_p_43091, eta_p_43093);\n                            int64_t defunc_0_op_res_43096 = add64(eta_p_43092, eta_p_43094);\n                            \n                            prefix_4307", "2 = lifted_lambda_res_43095;\n                            prefix_43073 = defunc_0_op_res_43096;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_43001 == 0) {\n                    if (boundary_43026 == sext_i64_i32(segscan_tblock_sizze_40570 * chunk_sizze_42985)) {\n                        int64_t eta_p_43097 = prefix_43072;\n                        int64_t eta_p_43098 = prefix_43073;\n                        int64_t eta_p_43099 = acc_43058;\n                        int64_t eta_p_43100 = acc_43059;\n                        int64_t lifted_lambda_res_43101 = add64(eta_p_43097, eta_p_43099);\n                        int64_t defunc_0_op_res_43102 = add64(eta_p_43098, eta_p_43100);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_42992)[dynamic_id_43023] = lifted_lambda_res_43101;\n                        ((volatile __global int64_t *) incprefixes_mem_42996)[dynamic_id_43023] = defunc_0_op_res_43102;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_42988)[dynamic_id_43023] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_43010)[(int64_t) 4] = prefix_43072;\n                    ((__local int64_t *) local_mem_43010)[squot64(warp_byte_offset_43008, (int64_t) 8)] = prefix_43073;\n                    acc_43058 = (int64_t) 0;\n                    acc_43059 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_43023 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_43072 = ((__local int64_t *) local_mem_43010)[(int64_t) 4];\n                prefix_43073 = ((__local int64_t *) local_mem_43010)[squot64(warp_byte_offset_43008, (int64_t) 8)];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_43103;\n            int6", "4_t eta_p_43105;\n            int64_t eta_p_43109 = prefix_43072;\n            int64_t eta_p_43111 = acc_43058;\n            int64_t eta_p_43104;\n            int64_t eta_p_43106;\n            int64_t eta_p_43110 = prefix_43073;\n            int64_t eta_p_43112 = acc_43059;\n            \n            if (slt32(local_tid_43001 * chunk_sizze_32b_43005, boundary_43026) && !block_new_sgm_43074) {\n                int64_t lifted_lambda_res_43113 = add64(eta_p_43109, eta_p_43111);\n                int64_t defunc_0_op_res_43114 = add64(eta_p_43110, eta_p_43112);\n                \n                eta_p_43103 = lifted_lambda_res_43113;\n                eta_p_43104 = defunc_0_op_res_43114;\n            } else {\n                eta_p_43103 = acc_43058;\n                eta_p_43104 = acc_43059;\n            }\n            \n            int32_t stopping_point_43115 = segsizze_compact_43027 - srem32(local_tid_43001 * chunk_sizze_32b_43005 - 1 + segsizze_compact_43027 - boundary_43026, segsizze_compact_43027);\n            \n            for (int64_t i_43116 = 0; i_43116 < chunk_sizze_42985; i_43116++) {\n                if (slt32(sext_i64_i32(i_43116), stopping_point_43115 - 1)) {\n                    eta_p_43105 = private_mem_43028[i_43116];\n                    eta_p_43106 = private_mem_43030[i_43116];\n                    \n                    int64_t lifted_lambda_res_43107 = add64(eta_p_43103, eta_p_43105);\n                    int64_t defunc_0_op_res_43108 = add64(eta_p_43104, eta_p_43106);\n                    \n                    private_mem_43028[i_43116] = lifted_lambda_res_43107;\n                    private_mem_43030[i_43116] = defunc_0_op_res_43108;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_43117 = 0; i_43117 < chunk_sizze_42985; i_43117++) {\n                int64_t sharedIdx_43118 = sext_i32_i64(local_tid_43001) * chunk_sizze_42985 + i_43117;\n                int64_t tmp_4311",
                                    "9 = private_mem_43028[i_43117];\n                \n                ((__local int64_t *) local_mem_43010)[sharedIdx_43118] = tmp_43119;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_43120 = 0; i_43120 < chunk_sizze_42985; i_43120++) {\n                int64_t flat_idx_43121 = thd_offset_43032 + i_43120 * segscan_tblock_sizze_40570;\n                int64_t slice_43122 = m_39200;\n                int64_t gtid_40574 = flat_idx_43121;\n                int64_t remnant_43123 = flat_idx_43121 - gtid_40574;\n                \n                if (slt64(flat_idx_43121, m_39200)) {\n                    int64_t tmp_43124 = ((__local int64_t *) local_mem_43010)[flat_idx_43121 - block_offset_43024];\n                    \n                    ((__global int64_t *) mem_42387)[gtid_40574] = tmp_43124;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_43125 = 0; i_43125 < chunk_sizze_42985; i_43125++) {\n                int64_t sharedIdx_43126 = sext_i32_i64(local_tid_43001) * chunk_sizze_42985 + i_43125;\n                int64_t tmp_43127 = private_mem_43030[i_43125];\n                \n                ((__local int64_t *) local_mem_43010)[sharedIdx_43126] = tmp_43127;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_43128 = 0; i_43128 < chunk_sizze_42985; i_43128++) {\n                int64_t flat_idx_43129 = thd_offset_43032 + i_43128 * segscan_tblock_sizze_40570;\n                int64_t slice_43130 = m_39200;\n                int64_t gtid_40574 = flat_idx_43129;\n                int64_t remnant_43131 = flat_idx_43129 - gtid_40574;\n                \n                if (slt64(flat_idx_43129, m_39200)) {\n                    int64_t tmp_43132 = ((__local int64_t *) local_mem_43010)[flat_idx_43129 - block_offset_43024];\n                    \n                    ((__global int64_t *) mem_42389)[gtid_40574] = tmp_43132;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_F", "ENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_40570\n    #undef chunk_sizze_42985\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_longzigpuseq_42730_dim1, 1, 1)\nvoid inner_SMJ_longzigpuseq_42730(__global int *global_failure, __global unsigned char *tS_mem_42200, __global unsigned char *mem_42207)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42732;\n    int32_t tblock_sizze_42735;\n    int32_t wave_sizze_42734;\n    int32_t block_id_42733;\n    int32_t global_tid_42731;\n    int64_t tid_42730;\n    int64_t x_42152;\n    \n    local_tid_42732 = get_local_id(0);\n    tblock_sizze_42735 = get_local_size(0);\n    wave_sizze_42734 = LOCKSTEP_WIDTH;\n    block_id_42733 = get_tblock_id(0);\n    global_tid_42731 = block_id_42733 * tblock_sizze_42735 + local_tid_42732;\n    tid_42730 = sext_i32_i64(global_tid_42731);\n    x_42152 = ((__global int64_t *) tS_mem_42200)[(int64_t) 0];\n    ((__global int64_t *) mem_42207)[(int64_t) 0] = x_42152;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_longzigpuseq_42736_dim1, 1, 1)\nvoid inner_SMJ_longzigpuseq_42736(__global int *global_failure, int64_t tmp_39078, __global unsigned char *tS_mem_42200, __global unsigned char *mem_42210)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42738;\n    int32_t tblock_sizze_42741;\n    int32_t wave_sizze_42740;\n    int32_t block_id_42739;\n    int32_t global_tid_42737;\n    int64_t tid_42736;\n    int64_t x_42156;\n    \n    local_tid_42738 = get_local_id(0);\n    tblock_sizze_42741 = get_local_size(0);\n    wave_sizze_42740 = LOCKSTEP_WIDTH;\n    block_id_42739 = get_tblock_id(0);\n    global_tid_42737 = block_id_42739 * tblock_sizze_42741 + local_tid_42738;\n    tid_42736 = sext_i32_i64(global_tid_42737);\n    x_42156 = ((__global int64_t *) tS_mem_42200)[tmp_39078];\n    ((__global int64_t *) mem_42210)[(int64_t) 0] = x_42156;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_longzigpuseq_42752_dim1, 1, 1)\nvoid inner_SMJ_lo", "ngzigpuseq_42752(__global int *global_failure, int64_t start_39100, int64_t i_p_m_t_s_39106, __global unsigned char *tR_mem_42199, __global unsigned char *mem_42218, __global unsigned char *mem_42219)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42754;\n    int32_t tblock_sizze_42757;\n    int32_t wave_sizze_42756;\n    int32_t block_id_42755;\n    int32_t global_tid_42753;\n    int64_t tid_42752;\n    int64_t r_max_42160;\n    int64_t r_min_42163;\n    \n    local_tid_42754 = get_local_id(0);\n    tblock_sizze_42757 = get_local_size(0);\n    wave_sizze_42756 = LOCKSTEP_WIDTH;\n    block_id_42755 = get_tblock_id(0);\n    global_tid_42753 = block_id_42755 * tblock_sizze_42757 + local_tid_42754;\n    tid_42752 = sext_i32_i64(global_tid_42753);\n    r_max_42160 = ((__global int64_t *) tR_mem_42199)[i_p_m_t_s_39106];\n    r_min_42163 = ((__global int64_t *) tR_mem_42199)[start_39100];\n    ((__global int64_t *) mem_42218)[(int64_t) 0] = r_max_42160;\n    ((__global int64_t *) mem_42219)[(int64_t) 0] = r_min_42163;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_longzigpuseq_42758_dim1, 1, 1)\nvoid inner_SMJ_longzigpuseq_42758(__global int *global_failure, __global unsigned char *mem_42219, __global unsigned char *ext_mem_42220, __global unsigned char *mem_42222)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42760;\n    int32_t tblock_sizze_42763;\n    int32_t wave_sizze_42762;\n    int32_t block_id_42761;\n    int32_t global_tid_42759;\n    int64_t tid_42758;\n    int64_t s_max_42165;\n    int64_t r_min_42166;\n    bool defunc_0_gt_res_42167;\n    \n    local_tid_42760 = get_local_id(0);\n    tblock_sizze_42763 = get_local_size(0);\n    wave_sizze_42762 = LOCKSTEP_WIDTH;\n    block_id_42761 = get_tblock_id(0);\n    global_tid_42759 = block_id_42761 * tblock_sizze_42763 + local_tid_42760;\n    tid_42758 = sext_i32_i64(global_tid_42759);\n    s_max_42165 = ((__global int64_t *) ext_mem_42220)[(int64_t) 0];\n    r_min_42166 = ((__global ",
                                    "int64_t *) mem_42219)[(int64_t) 0];\n    defunc_0_gt_res_42167 = slt64(s_max_42165, r_min_42166);\n    ((__global bool *) mem_42222)[(int64_t) 0] = defunc_0_gt_res_42167;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_longzigpuseq_42764_dim1, 1, 1)\nvoid inner_SMJ_longzigpuseq_42764(__global int *global_failure, __global unsigned char *mem_42218, __global unsigned char *ext_mem_42221, __global unsigned char *mem_42223)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42766;\n    int32_t tblock_sizze_42769;\n    int32_t wave_sizze_42768;\n    int32_t block_id_42767;\n    int32_t global_tid_42765;\n    int64_t tid_42764;\n    int64_t r_max_42170;\n    int64_t s_min_42171;\n    bool defunc_0_gt_res_42172;\n    \n    local_tid_42766 = get_local_id(0);\n    tblock_sizze_42769 = get_local_size(0);\n    wave_sizze_42768 = LOCKSTEP_WIDTH;\n    block_id_42767 = get_tblock_id(0);\n    global_tid_42765 = block_id_42767 * tblock_sizze_42769 + local_tid_42766;\n    tid_42764 = sext_i32_i64(global_tid_42765);\n    r_max_42170 = ((__global int64_t *) mem_42218)[(int64_t) 0];\n    s_min_42171 = ((__global int64_t *) ext_mem_42221)[(int64_t) 0];\n    defunc_0_gt_res_42172 = slt64(r_max_42170, s_min_42171);\n    ((__global bool *) mem_42223)[(int64_t) 0] = defunc_0_gt_res_42172;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_longzigpuseq_43142_dim1, 1, 1)\nvoid inner_SMJ_longzigpuseq_43142(__global int *global_failure, int64_t m_39210, __global unsigned char *mem_42394, __global unsigned char *mem_42396)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43144;\n    int32_t tblock_sizze_43147;\n    int32_t wave_sizze_43146;\n    int32_t block_id_43145;\n    int32_t global_tid_43143;\n    int64_t tid_43142;\n    int64_t x_42174;\n    \n    local_tid_43144 = get_local_id(0);\n    tblock_sizze_43147 = get_local_size(0);\n    wave_sizze_43146 = LOCKSTEP_WIDTH;\n    block_id_43145 = get_tblock_id(0);\n    global_tid_43143 = block_id_43145 * tbloc", "k_sizze_43147 + local_tid_43144;\n    tid_43142 = sext_i32_i64(global_tid_43143);\n    x_42174 = ((__global int64_t *) mem_42394)[m_39210];\n    ((__global int64_t *) mem_42396)[(int64_t) 0] = x_42174;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_longzigpuseq_43148_dim1, 1, 1)\nvoid inner_SMJ_longzigpuseq_43148(__global int *global_failure, int64_t m_39210, __global unsigned char *mem_42377, __global unsigned char *mem_42399)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43150;\n    int32_t tblock_sizze_43153;\n    int32_t wave_sizze_43152;\n    int32_t block_id_43151;\n    int32_t global_tid_43149;\n    int64_t tid_43148;\n    int64_t x_42178;\n    \n    local_tid_43150 = get_local_id(0);\n    tblock_sizze_43153 = get_local_size(0);\n    wave_sizze_43152 = LOCKSTEP_WIDTH;\n    block_id_43151 = get_tblock_id(0);\n    global_tid_43149 = block_id_43151 * tblock_sizze_43153 + local_tid_43150;\n    tid_43148 = sext_i32_i64(global_tid_43149);\n    x_42178 = ((__global int64_t *) mem_42377)[m_39210];\n    ((__global int64_t *) mem_42399)[(int64_t) 0] = x_42178;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_longzigpuseq_43154_dim1, 1, 1)\nvoid inner_SMJ_longzigpuseq_43154(__global int *global_failure, __global unsigned char *ext_mem_42397, __global unsigned char *ext_mem_42400, __global unsigned char *mem_42406)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43156;\n    int32_t tblock_sizze_43159;\n    int32_t wave_sizze_43158;\n    int32_t block_id_43157;\n    int32_t global_tid_43155;\n    int64_t tid_43154;\n    int64_t zp_lhs_42182;\n    int64_t n_pairs_t_res_42183;\n    int64_t n_pairs_t_res_42184;\n    \n    local_tid_43156 = get_local_id(0);\n    tblock_sizze_43159 = get_local_size(0);\n    wave_sizze_43158 = LOCKSTEP_WIDTH;\n    block_id_43157 = get_tblock_id(0);\n    global_tid_43155 = block_id_43157 * tblock_sizze_43159 + local_tid_43156;\n    tid_43154 = sext_i32_i64(global_tid_43155);\n    zp_lhs_42182 = ((__g", "lobal int64_t *) ext_mem_42397)[(int64_t) 0];\n    n_pairs_t_res_42183 = ((__global int64_t *) ext_mem_42400)[(int64_t) 0];\n    n_pairs_t_res_42184 = add64(zp_lhs_42182, n_pairs_t_res_42183);\n    ((__global int64_t *) mem_42406)[(int64_t) 0] = n_pairs_t_res_42184;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_longzigpuseq_43201_dim1, 1, 1)\nvoid inner_SMJ_longzigpuseq_43201(__global int *global_failure, int64_t loopres_39384, __global unsigned char *mem_param_42440, __global unsigned char *mem_param_42443, __global unsigned char *mem_param_42446, __global unsigned char *mem_42453, __global unsigned char *mem_42454, __global unsigned char *mem_42455)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43203;\n    int32_t tblock_sizze_43206;\n    int32_t wave_sizze_43205;\n    int32_t block_id_43204;\n    int32_t global_tid_43202;\n    int64_t tid_43201;\n    int64_t loopres_42186;\n    int64_t loopres_42188;\n    int64_t loopres_42190;\n    \n    local_tid_43203 = get_local_id(0);\n    tblock_sizze_43206 = get_local_size(0);\n    wave_sizze_43205 = LOCKSTEP_WIDTH;\n    block_id_43204 = get_tblock_id(0);\n    global_tid_43202 = block_id_43204 * tblock_sizze_43206 + local_tid_43203;\n    tid_43201 = sext_i32_i64(global_tid_43202);\n    loopres_42186 = ((__global int64_t *) mem_param_42440)[loopres_39384];\n    loopres_42188 = ((__global int64_t *) mem_param_42443)[loopres_39384];\n    loopres_42190 = ((__global int64_t *) mem_param_42446)[loopres_39384];\n    ((__global int64_t *) mem_42453)[(int64_t) 0] = loopres_42186;\n    ((__global int64_t *) mem_42454)[(int64_t) 0] = loopres_42188;\n    ((__global int64_t *) mem_42455)[(int64_t) 0] = loopres_42190;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL\nvoid inner_SMJ_longzireplicate_43208(int64_t loopres_39385, int64_t replicate_n_43207, int64_t virt_num_tblocks_43213, int64_t num_tblocks_43214, __global unsigned char *mem_42453, __global unsigned char *mem_42457)\n{\n    int32_t replicate_ltid_43209;\n    int3",
                                    "2_t tblock_sizze_43211;\n    int32_t replicate_gid_43210;\n    int32_t replicate_gtid_43208;\n    int32_t phys_tblock_id_43215;\n    int32_t iterations_43216;\n    \n    replicate_ltid_43209 = get_local_id(0);\n    tblock_sizze_43211 = get_local_size(0);\n    replicate_gid_43210 = get_tblock_id(0);\n    replicate_gtid_43208 = replicate_gid_43210 * tblock_sizze_43211 + replicate_ltid_43209;\n    phys_tblock_id_43215 = get_tblock_id(0);\n    iterations_43216 = sdiv_up32(sext_i64_i32(virt_num_tblocks_43213) - phys_tblock_id_43215, sext_i64_i32(num_tblocks_43214));\n    for (int32_t i_43217 = 0; i_43217 < iterations_43216; i_43217++) {\n        int32_t virt_tblock_id_43218;\n        int64_t global_tid_43219;\n        int64_t slice_43222;\n        int64_t slice_43223;\n        int64_t rep_i_43220;\n        int64_t remnant_43224;\n        int64_t rep_i_43221;\n        int64_t remnant_43225;\n        \n        virt_tblock_id_43218 = phys_tblock_id_43215 + i_43217 * sext_i64_i32(num_tblocks_43214);\n        global_tid_43219 = sext_i32_i64(virt_tblock_id_43218) * sext_i32_i64(tblock_sizze_43211) + sext_i32_i64(replicate_ltid_43209);\n        slice_43222 = (int64_t) 1;\n        slice_43223 = loopres_39385 * slice_43222;\n        rep_i_43220 = squot64(global_tid_43219, slice_43222);\n        remnant_43224 = global_tid_43219 - rep_i_43220 * slice_43222;\n        rep_i_43221 = remnant_43224;\n        remnant_43225 = remnant_43224 - rep_i_43221;\n        if (slt64(global_tid_43219, replicate_n_43207)) {\n            int64_t tmp_43226 = ((__global int64_t *) mem_42453)[rep_i_43221];\n            \n            ((__global int64_t *) mem_42457)[rep_i_43220 + rep_i_43221] = tmp_43226;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid inner_SMJ_longzireplicate_43228(int64_t loopres_39385, int64_t replicate_n_43227, int64_t virt_num_tblocks_43233, int64_t num_tblocks_43234, __global unsigned char *mem_42454, __global unsigned char *mem_42459)\n", "{\n    int32_t replicate_ltid_43229;\n    int32_t tblock_sizze_43231;\n    int32_t replicate_gid_43230;\n    int32_t replicate_gtid_43228;\n    int32_t phys_tblock_id_43235;\n    int32_t iterations_43236;\n    \n    replicate_ltid_43229 = get_local_id(0);\n    tblock_sizze_43231 = get_local_size(0);\n    replicate_gid_43230 = get_tblock_id(0);\n    replicate_gtid_43228 = replicate_gid_43230 * tblock_sizze_43231 + replicate_ltid_43229;\n    phys_tblock_id_43235 = get_tblock_id(0);\n    iterations_43236 = sdiv_up32(sext_i64_i32(virt_num_tblocks_43233) - phys_tblock_id_43235, sext_i64_i32(num_tblocks_43234));\n    for (int32_t i_43237 = 0; i_43237 < iterations_43236; i_43237++) {\n        int32_t virt_tblock_id_43238;\n        int64_t global_tid_43239;\n        int64_t slice_43242;\n        int64_t slice_43243;\n        int64_t rep_i_43240;\n        int64_t remnant_43244;\n        int64_t rep_i_43241;\n        int64_t remnant_43245;\n        \n        virt_tblock_id_43238 = phys_tblock_id_43235 + i_43237 * sext_i64_i32(num_tblocks_43234);\n        global_tid_43239 = sext_i32_i64(virt_tblock_id_43238) * sext_i32_i64(tblock_sizze_43231) + sext_i32_i64(replicate_ltid_43229);\n        slice_43242 = (int64_t) 1;\n        slice_43243 = loopres_39385 * slice_43242;\n        rep_i_43240 = squot64(global_tid_43239, slice_43242);\n        remnant_43244 = global_tid_43239 - rep_i_43240 * slice_43242;\n        rep_i_43241 = remnant_43244;\n        remnant_43245 = remnant_43244 - rep_i_43241;\n        if (slt64(global_tid_43239, replicate_n_43227)) {\n            int64_t tmp_43246 = ((__global int64_t *) mem_42454)[rep_i_43241];\n            \n            ((__global int64_t *) mem_42459)[rep_i_43240 + rep_i_43241] = tmp_43246;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_longzisegmap_40821_dim1, 1, 1)\nvoid inner_SMJ_longzisegmap_40821(__global int *global_failure, int64_t nR_29939, int64_t m_39200, int64_t num_tblocks_40826,", " int64_t ext_42365, int64_t ext_42366, int64_t ext_42367, int64_t ext_42368, int32_t virt_num_tblocks_42967, __global unsigned char *tR_mem_42199, __global unsigned char *ext_mem_42201, __global unsigned char *ext_mem_42369, __global unsigned char *ext_mem_42370, __global unsigned char *mem_42373, __global unsigned char *mem_42375, __global unsigned char *mem_42377, __global unsigned char *mem_42379, __global unsigned char *mem_42381, __global unsigned char *mem_42383)\n{\n    #define segmap_tblock_sizze_40824 (inner_SMJ_longzisegmap_40821zisegmap_tblock_sizze_40824)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42969;\n    int32_t tblock_sizze_42972;\n    int32_t wave_sizze_42971;\n    int32_t block_id_42970;\n    int32_t global_tid_42968;\n    int64_t phys_tid_40821;\n    int32_t phys_tblock_id_42973;\n    int32_t iterations_42974;\n    \n    local_tid_42969 = get_local_id(0);\n    tblock_sizze_42972 = get_local_size(0);\n    wave_sizze_42971 = LOCKSTEP_WIDTH;\n    block_id_42970 = get_tblock_id(0);\n    global_tid_42968 = block_id_42970 * tblock_sizze_42972 + local_tid_42969;\n    phys_tid_40821 = sext_i32_i64(global_tid_42968);\n    phys_tblock_id_42973 = get_tblock_id(0);\n    iterations_42974 = sdiv_up32(virt_num_tblocks_42967 - phys_tblock_id_42973, sext_i64_i32(num_tblocks_40826));\n    for (int32_t i_42975 = 0; i_42975 < iterations_42974; i_42975++) {\n        int32_t virt_tblock_id_42976;\n        int64_t global_tid_42977;\n        int64_t slice_42978;\n        int64_t write_i_40820;\n        int64_t remnant_42979;\n        \n        virt_tblock_id_42976 = phys_tblock_id_42973 + i_42975 * sext_i64_i32(num_tblocks_40826);\n        global_tid_42977 = sext_i32_i64(virt_tblock_id_42976) * segmap_tblock_sizze_40824 + sext_i32_i64(local_tid_42969);\n        slice_42978 = nR_29939;\n        write_i_40820 = global_tid_42977;\n        remnant_42979 = global_tid_42977 - write_i_40820;\n        if (slt64(write_i_40820, nR_29939)) {\n            int64_t eta_p_39447;\n      ",
                                    "      int64_t write_value_39449;\n            int64_t write_value_39450;\n            int64_t write_value_39451;\n            int64_t write_value_39452;\n            bool cond_39453;\n            int64_t lifted_lambda_res_39454;\n            \n            eta_p_39447 = ((__global int64_t *) mem_42375)[write_i_40820];\n            write_value_39449 = ((__global int64_t *) tR_mem_42199)[write_i_40820];\n            write_value_39450 = ((__global int64_t *) ext_mem_42201)[write_i_40820];\n            write_value_39451 = ((__global int64_t *) ext_mem_42369)[ext_42366 + write_i_40820 * ext_42365];\n            write_value_39452 = ((__global int64_t *) ext_mem_42370)[ext_42368 + write_i_40820 * ext_42367];\n            cond_39453 = eta_p_39447 == (int64_t) 1;\n            if (cond_39453) {\n                int64_t eta_p_39448;\n                int64_t lifted_lambda_res_t_res_39514;\n                \n                eta_p_39448 = ((__global int64_t *) mem_42373)[write_i_40820];\n                lifted_lambda_res_t_res_39514 = sub64(eta_p_39448, (int64_t) 1);\n                lifted_lambda_res_39454 = lifted_lambda_res_t_res_39514;\n            } else {\n                lifted_lambda_res_39454 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39454) && slt64(lifted_lambda_res_39454, m_39200)) {\n                ((__global int64_t *) mem_42383)[lifted_lambda_res_39454] = write_value_39449;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39454) && slt64(lifted_lambda_res_39454, m_39200)) {\n                ((__global int64_t *) mem_42381)[lifted_lambda_res_39454] = write_value_39450;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39454) && slt64(lifted_lambda_res_39454, m_39200)) {\n                ((__global int64_t *) mem_42379)[lifted_lambda_res_39454] = write_value_39451;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39454) && slt64(lifted_lambda_res_39454, m_39200)) {\n                ((__global int64_t", " *) mem_42377)[lifted_lambda_res_39454] = write_value_39452;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_40824\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_longzisegmap_40855_dim1, 1, 1)\nvoid inner_SMJ_longzisegmap_40855(__global int *global_failure, int64_t m_39200, __global unsigned char *mem_42387, __global unsigned char *mem_42394)\n{\n    #define segmap_tblock_sizze_40851 (inner_SMJ_longzisegmap_40855zisegmap_tblock_sizze_40851)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43135;\n    int32_t tblock_sizze_43138;\n    int32_t wave_sizze_43137;\n    int32_t block_id_43136;\n    int32_t global_tid_43134;\n    int64_t phys_tid_40855;\n    int64_t global_tid_43139;\n    int64_t slice_43140;\n    int64_t gtid_40854;\n    int64_t remnant_43141;\n    \n    local_tid_43135 = get_local_id(0);\n    tblock_sizze_43138 = get_local_size(0);\n    wave_sizze_43137 = LOCKSTEP_WIDTH;\n    block_id_43136 = get_tblock_id(0);\n    global_tid_43134 = block_id_43136 * tblock_sizze_43138 + local_tid_43135;\n    phys_tid_40855 = sext_i32_i64(global_tid_43134);\n    global_tid_43139 = sext_i32_i64(block_id_43136) * segmap_tblock_sizze_40851 + sext_i32_i64(local_tid_43135);\n    slice_43140 = m_39200;\n    gtid_40854 = global_tid_43139;\n    remnant_43141 = global_tid_43139 - gtid_40854;\n    if (slt64(gtid_40854, m_39200)) {\n        int64_t zv_lhs_40857;\n        int64_t tmp_40858;\n        bool cond_40860;\n        int64_t lifted_lambda_res_40861;\n        \n        zv_lhs_40857 = add64((int64_t) -1, gtid_40854);\n        tmp_40858 = smod64(zv_lhs_40857, m_39200);\n        cond_40860 = gtid_40854 == (int64_t) 0;\n        if (cond_40860) {\n            lifted_lambda_res_40861 = (int64_t) 0;\n        } else {\n            int64_t lifted_lambda_res_40859 = ((__global int64_t *) mem_42387)[tmp_40858];\n            \n            lifted_lambda_res_40861 = lifted_lambda_res_40859;\n        }\n        ((__globa", "l int64_t *) mem_42394)[gtid_40854] = lifted_lambda_res_40861;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_40851\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_longzisegmap_40863_dim1, 1, 1)\nvoid inner_SMJ_longzisegmap_40863(__global int *global_failure, int64_t m_39200, int64_t lower_bound_39283, int64_t min_res_39285, int64_t j_m_i_39286, int64_t num_tblocks_40868, int32_t virt_num_tblocks_43180, __global unsigned char *mem_42379, __global unsigned char *mem_42381, __global unsigned char *mem_42383, __global unsigned char *mem_42394, __global unsigned char *mem_42423, __global unsigned char *mem_42425, __global unsigned char *mem_42427)\n{\n    #define segmap_tblock_sizze_40866 (inner_SMJ_longzisegmap_40863zisegmap_tblock_sizze_40866)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43182;\n    int32_t tblock_sizze_43185;\n    int32_t wave_sizze_43184;\n    int32_t block_id_43183;\n    int32_t global_tid_43181;\n    int64_t phys_tid_40863;\n    int32_t phys_tblock_id_43186;\n    int32_t iterations_43187;\n    \n    local_tid_43182 = get_local_id(0);\n    tblock_sizze_43185 = get_local_size(0);\n    wave_sizze_43184 = LOCKSTEP_WIDTH;\n    block_id_43183 = get_tblock_id(0);\n    global_tid_43181 = block_id_43183 * tblock_sizze_43185 + local_tid_43182;\n    phys_tid_40863 = sext_i32_i64(global_tid_43181);\n    phys_tblock_id_43186 = get_tblock_id(0);\n    iterations_43187 = sdiv_up32(virt_num_tblocks_43180 - phys_tblock_id_43186, sext_i64_i32(num_tblocks_40868));\n    for (int32_t i_43188 = 0; i_43188 < iterations_43187; i_43188++) {\n        int32_t virt_tblock_id_43189;\n        int64_t global_tid_43190;\n        int64_t slice_43191;\n        int64_t write_i_40862;\n        int64_t remnant_43192;\n        \n        virt_tblock_id_43189 = phys_tblock_id_43186 + i_43188 * sext_i64_i32(num_tblocks_40868);\n        global_tid_43190 = sext_i32_i64(virt_tblock_id_43189) * segmap_tblock_sizze_40866 + sext_i32_i64(local_tid_43182);\n        slice_43191 = m_39200;\n      ",
                                    "  write_i_40862 = global_tid_43190;\n        remnant_43192 = global_tid_43190 - write_i_40862;\n        if (slt64(write_i_40862, m_39200)) {\n            int64_t eta_p_39484;\n            int64_t write_value_39485;\n            int64_t write_value_39486;\n            int64_t write_value_39487;\n            bool cond_39488;\n            bool cond_t_res_39489;\n            bool x_39490;\n            int64_t lifted_lambda_res_39491;\n            \n            eta_p_39484 = ((__global int64_t *) mem_42394)[write_i_40862];\n            write_value_39485 = ((__global int64_t *) mem_42383)[write_i_40862];\n            write_value_39486 = ((__global int64_t *) mem_42381)[write_i_40862];\n            write_value_39487 = ((__global int64_t *) mem_42379)[write_i_40862];\n            cond_39488 = sle64(lower_bound_39283, eta_p_39484);\n            cond_t_res_39489 = slt64(eta_p_39484, min_res_39285);\n            x_39490 = cond_39488 && cond_t_res_39489;\n            if (x_39490) {\n                int64_t lifted_lambda_res_t_res_39517 = sub64(eta_p_39484, lower_bound_39283);\n                \n                lifted_lambda_res_39491 = lifted_lambda_res_t_res_39517;\n            } else {\n                lifted_lambda_res_39491 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39491) && slt64(lifted_lambda_res_39491, j_m_i_39286)) {\n                ((__global int64_t *) mem_42423)[lifted_lambda_res_39491] = write_value_39485;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39491) && slt64(lifted_lambda_res_39491, j_m_i_39286)) {\n                ((__global int64_t *) mem_42425)[lifted_lambda_res_39491] = write_value_39486;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39491) && slt64(lifted_lambda_res_39491, j_m_i_39286)) {\n                ((__global int64_t *) mem_42427)[lifted_lambda_res_39491] = write_value_39487;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    retu", "rn;\n    #undef segmap_tblock_sizze_40866\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_longzisegmap_40871_dim1, 1, 1)\nvoid inner_SMJ_longzisegmap_40871(__global int *global_failure, int64_t m_39200, int64_t m_39340, int64_t num_tblocks_40876, int32_t virt_num_tblocks_43162, __global unsigned char *mem_42377, __global unsigned char *mem_42389, __global unsigned char *mem_42391, __global unsigned char *mem_42394, __global unsigned char *mem_42402, __global unsigned char *mem_42404)\n{\n    #define segmap_tblock_sizze_40874 (inner_SMJ_longzisegmap_40871zisegmap_tblock_sizze_40874)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43164;\n    int32_t tblock_sizze_43167;\n    int32_t wave_sizze_43166;\n    int32_t block_id_43165;\n    int32_t global_tid_43163;\n    int64_t phys_tid_40871;\n    int32_t phys_tblock_id_43168;\n    int32_t iterations_43169;\n    \n    local_tid_43164 = get_local_id(0);\n    tblock_sizze_43167 = get_local_size(0);\n    wave_sizze_43166 = LOCKSTEP_WIDTH;\n    block_id_43165 = get_tblock_id(0);\n    global_tid_43163 = block_id_43165 * tblock_sizze_43167 + local_tid_43164;\n    phys_tid_40871 = sext_i32_i64(global_tid_43163);\n    phys_tblock_id_43168 = get_tblock_id(0);\n    iterations_43169 = sdiv_up32(virt_num_tblocks_43162 - phys_tblock_id_43168, sext_i64_i32(num_tblocks_40876));\n    for (int32_t i_43170 = 0; i_43170 < iterations_43169; i_43170++) {\n        int32_t virt_tblock_id_43171;\n        int64_t global_tid_43172;\n        int64_t slice_43173;\n        int64_t write_i_40870;\n        int64_t remnant_43174;\n        \n        virt_tblock_id_43171 = phys_tblock_id_43168 + i_43170 * sext_i64_i32(num_tblocks_40876);\n        global_tid_43172 = sext_i32_i64(virt_tblock_id_43171) * segmap_tblock_sizze_40874 + sext_i32_i64(local_tid_43164);\n        slice_43173 = m_39200;\n        write_i_40870 = global_tid_43172;\n        remnant_43174 = global_tid_43172 - write_i_40870;\n        if (slt64(write_i_40870, m_39200)) {\n            int64_t eta_p_39424;\n          ", "  int64_t write_value_39426;\n            int64_t write_value_39427;\n            bool cond_39428;\n            int64_t lifted_lambda_res_39429;\n            \n            eta_p_39424 = ((__global int64_t *) mem_42391)[write_i_40870];\n            write_value_39426 = ((__global int64_t *) mem_42394)[write_i_40870];\n            write_value_39427 = ((__global int64_t *) mem_42377)[write_i_40870];\n            cond_39428 = eta_p_39424 == (int64_t) 1;\n            if (cond_39428) {\n                int64_t eta_p_39425;\n                int64_t lifted_lambda_res_t_res_39522;\n                \n                eta_p_39425 = ((__global int64_t *) mem_42389)[write_i_40870];\n                lifted_lambda_res_t_res_39522 = sub64(eta_p_39425, (int64_t) 1);\n                lifted_lambda_res_39429 = lifted_lambda_res_t_res_39522;\n            } else {\n                lifted_lambda_res_39429 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39429) && slt64(lifted_lambda_res_39429, m_39340)) {\n                ((__global int64_t *) mem_42404)[lifted_lambda_res_39429] = write_value_39426;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39429) && slt64(lifted_lambda_res_39429, m_39340)) {\n                ((__global int64_t *) mem_42402)[lifted_lambda_res_39429] = write_value_39427;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_40874\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_longzisegmap_40893_dim1, 1, 1)\nvoid inner_SMJ_longzisegmap_40893(__global int *global_failure, int64_t loopres_39384, int64_t loopres_39385, __global unsigned char *mem_42452, __global unsigned char *mem_42455)\n{\n    #define segmap_tblock_sizze_40889 (inner_SMJ_longzisegmap_40893zisegmap_tblock_sizze_40889)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43249;\n    int32_t tblock_sizze_43252;\n    int32_t wave_sizze_43251;\n    int32_t block_id_43250;\n    int3",
                                    "2_t global_tid_43248;\n    int64_t phys_tid_40893;\n    int64_t global_tid_43253;\n    int64_t slice_43254;\n    int64_t gtid_40892;\n    int64_t remnant_43255;\n    \n    local_tid_43249 = get_local_id(0);\n    tblock_sizze_43252 = get_local_size(0);\n    wave_sizze_43251 = LOCKSTEP_WIDTH;\n    block_id_43250 = get_tblock_id(0);\n    global_tid_43248 = block_id_43250 * tblock_sizze_43252 + local_tid_43249;\n    phys_tid_40893 = sext_i32_i64(global_tid_43248);\n    global_tid_43253 = sext_i32_i64(block_id_43250) * segmap_tblock_sizze_40889 + sext_i32_i64(local_tid_43249);\n    slice_43254 = loopres_39385;\n    gtid_40892 = global_tid_43253;\n    remnant_43255 = global_tid_43253 - gtid_40892;\n    if (slt64(gtid_40892, loopres_39385)) {\n        int64_t loopres_42194;\n        int64_t tmp_40895;\n        \n        loopres_42194 = ((__global int64_t *) mem_42455)[(int64_t) 0];\n        tmp_40895 = add64(gtid_40892, loopres_42194);\n        ((__global int64_t *) mem_42452)[loopres_39384 + gtid_40892] = tmp_40895;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_40889\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_longzisegmap_intrablock_41423_dim1, 1, 1)\nvoid inner_SMJ_longzisegmap_intrablock_41423(__global int *global_failure, int64_t nS_29940, int64_t start_39100, int64_t min_res_39102, int64_t ldim_41426, int64_t num_whole_tiles_41441, int64_t residual_input_41665, unsigned char cond_41666_bits, int64_t binop_x_41682, __global unsigned char *tR_mem_42199, __global unsigned char *tS_mem_42200, __global unsigned char *ext_mem_42224, __global unsigned char *mem_42344, __global unsigned char *mem_42346)\n{\n    bool cond_41666 = cond_41666_bits;\n    \n    #define tile_sizze_41425 (inner_SMJ_longzisegmap_intrablock_41423zitile_sizze_41425)\n    #define bytes_42306 (inner_SMJ_longzisegmap_intrablock_41423zibytes_42306)\n    \n    volatile __local unsigned char *color_42702_backing_2 = &shared_mem[0];\n    const int64_t color_42702_backing_2_offset = 0 + (bytes_42306 + srem64((int64_t) 8 - srem64(byt", "es_42306, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_42701_backing_1 = &shared_mem[color_42702_backing_2_offset];\n    const int64_t color_42701_backing_1_offset = color_42702_backing_2_offset + (bytes_42306 + srem64((int64_t) 8 - srem64(bytes_42306, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_42700_backing_0 = &shared_mem[color_42701_backing_1_offset];\n    const int64_t color_42700_backing_0_offset = color_42701_backing_1_offset + (bytes_42306 + srem64((int64_t) 8 - srem64(bytes_42306, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42773;\n    int32_t tblock_sizze_42776;\n    int32_t wave_sizze_42775;\n    int32_t block_id_42774;\n    int32_t global_tid_42772;\n    int64_t gid_flat_41423;\n    int64_t slice_42778;\n    int64_t ltid_pre_42777;\n    int64_t remnant_42779;\n    int64_t slice_42780;\n    int64_t gid_41422;\n    int64_t remnant_42781;\n    __local unsigned char *color_42700;\n    __local unsigned char *color_42701;\n    __local unsigned char *color_42702;\n    int64_t binop_x_41433;\n    int64_t mem_42290[1];\n    int64_t ltid_flat_41428;\n    int64_t ltid_41427;\n    int64_t gtid_41434;\n    bool cond_41435;\n    int64_t pre_41436;\n    int64_t mem_42294[1];\n    int64_t mem_42298[1];\n    int64_t mem_42302[1];\n    int64_t ltid_flat_41443;\n    int64_t ltid_41442;\n    int64_t gtid_41453;\n    bool cond_41454;\n    int64_t neutral_41455;\n    int64_t neutral_41456;\n    int64_t ext_mem_42326[1];\n    int64_t ext_mem_42325[1];\n    int64_t ext_mem_42324[1];\n    int64_t mem_param_42303[1];\n    int64_t mem_param_42304[1];\n    int64_t mem_param_42305[1];\n    int64_t mem_42336[1];\n    int64_t mem_42340[1];\n    int64_t ext_mem_42342[1];\n    int64_t ext_mem_42341[1];\n    \n    local_tid_42773 = get_local_id(0);\n    tblock_sizze_42776 = get_local_size(0);\n    wave_sizze_42775 = LOCKSTEP_WIDTH;\n    block_id_42774 = get_tblock_id(0);\n    global_tid_42772 = block_id_42774 * tblock_si", "zze_42776 + local_tid_42773;\n    gid_flat_41423 = sext_i32_i64(block_id_42774);\n    slice_42778 = tile_sizze_41425;\n    ltid_pre_42777 = sext_i32_i64(local_tid_42773);\n    remnant_42779 = sext_i32_i64(local_tid_42773) - ltid_pre_42777;\n    slice_42780 = ldim_41426;\n    gid_41422 = sext_i32_i64(block_id_42774);\n    remnant_42781 = sext_i32_i64(block_id_42774) - gid_41422;\n    color_42700 = (__local unsigned char *) color_42700_backing_0;\n    color_42701 = (__local unsigned char *) color_42701_backing_1;\n    color_42702 = (__local unsigned char *) color_42702_backing_2;\n    binop_x_41433 = gid_41422 * tile_sizze_41425;\n    ltid_flat_41428 = sext_i32_i64(local_tid_42773);\n    ltid_41427 = sext_i32_i64(sext_i64_i32(ltid_pre_42777));\n    gtid_41434 = ltid_41427 + binop_x_41433;\n    cond_41435 = slt64(gtid_41434, min_res_39102);\n    if (cond_41435) {\n        int64_t slice_41437;\n        int64_t eta_p_41438;\n        \n        slice_41437 = start_39100 + gtid_41434;\n        eta_p_41438 = ((__global int64_t *) tR_mem_42199)[slice_41437];\n        pre_41436 = eta_p_41438;\n    } else {\n        pre_41436 = (int64_t) 0;\n    }\n    mem_42290[(int64_t) 0] = pre_41436;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    ltid_flat_41443 = sext_i32_i64(local_tid_42773);\n    ltid_41442 = sext_i32_i64(sext_i64_i32(ltid_pre_42777));\n    gtid_41453 = binop_x_41433 + ltid_41442;\n    cond_41454 = slt64(gtid_41453, min_res_39102);\n    if (cond_41454) {\n        neutral_41455 = (int64_t) -1;\n    } else {\n        neutral_41455 = (int64_t) 0;\n    }\n    if (cond_41454) {\n        int64_t eta_p_41458 = mem_42290[(int64_t) 0];\n        \n        neutral_41456 = eta_p_41458;\n    } else {\n        neutral_41456 = (int64_t) 0;\n    }\n    mem_42294[(int64_t) 0] = neutral_41455;\n    mem_42298[(int64_t) 0] = neutral_41456;\n    mem_42302[(int64_t) 0] = (int64_t) 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    for (int32_t i_3 = 0; i_3 < 1; i_3++)\n        mem_param_42303[i_3] = mem_42294[i_3];\n    fo",
                                    "r (int32_t i_4 = 0; i_4 < 1; i_4++)\n        mem_param_42304[i_4] = mem_42298[i_4];\n    for (int32_t i_5 = 0; i_5 < 1; i_5++)\n        mem_param_42305[i_5] = mem_42302[i_5];\n    for (int64_t tile_id_41468 = 0; tile_id_41468 < num_whole_tiles_41441; tile_id_41468++) {\n        int64_t binop_x_41567;\n        int64_t ltid_flat_41566;\n        int64_t ltid_41565;\n        int64_t j_41568;\n        bool cond_41572;\n        int64_t pre1d_41575;\n        int64_t pre1d_41573;\n        int64_t pre1d_41574;\n        int64_t mem_42315[1];\n        int64_t mem_42319[1];\n        int64_t mem_42323[1];\n        int64_t ltid_flat_41586;\n        int64_t ltid_41585;\n        int64_t gtid_41588;\n        int64_t acc_41590;\n        int64_t acc_41591;\n        int64_t acc_41592;\n        bool cond_41593;\n        int64_t acc_41594;\n        int64_t acc_41595;\n        int64_t acc_41596;\n        int64_t mem_param_tmp_42782[1];\n        int64_t mem_param_tmp_42783[1];\n        int64_t mem_param_tmp_42784[1];\n        \n        binop_x_41567 = tile_sizze_41425 * tile_id_41468;\n        ltid_flat_41566 = sext_i32_i64(local_tid_42773);\n        ltid_41565 = sext_i32_i64(sext_i64_i32(ltid_pre_42777));\n        j_41568 = ltid_41565 + binop_x_41567;\n        cond_41572 = slt64(j_41568, nS_29940);\n        pre1d_41575 = btoi_bool_i64(cond_41572);\n        if (cond_41572) {\n            int64_t tile_elem_41576;\n            int64_t tile_elem_41577;\n            \n            tile_elem_41576 = ((__global int64_t *) ext_mem_42224)[j_41568];\n            tile_elem_41577 = ((__global int64_t *) tS_mem_42200)[j_41568];\n            pre1d_41573 = tile_elem_41576;\n            pre1d_41574 = tile_elem_41577;\n        } else {\n            pre1d_41573 = (int64_t) 0;\n            pre1d_41574 = (int64_t) 0;\n        }\n        ((__local int64_t *) color_42702)[ltid_41565] = pre1d_41573;\n        ((__local int64_t *) color_42701)[ltid_41565] = pre1d_41574;\n        ((__local int64_t *) color_42700)[ltid_41565] = pre1d_41575;\n        barrier(CLK_LOCA", "L_MEM_FENCE);\n        ltid_flat_41586 = sext_i32_i64(local_tid_42773);\n        ltid_41585 = sext_i32_i64(sext_i64_i32(ltid_pre_42777));\n        gtid_41588 = binop_x_41433 + ltid_41585;\n        acc_41590 = mem_param_42303[(int64_t) 0];\n        acc_41591 = mem_param_42304[(int64_t) 0];\n        acc_41592 = mem_param_42305[(int64_t) 0];\n        cond_41593 = slt64(gtid_41588, min_res_39102);\n        if (cond_41593) {\n            int64_t eta_p_41589;\n            int64_t x_41597;\n            int64_t x_41598;\n            int64_t x_41599;\n            int64_t redout_42136;\n            int64_t redout_42137;\n            int64_t redout_42138;\n            \n            eta_p_41589 = mem_42290[(int64_t) 0];\n            redout_42136 = acc_41590;\n            redout_42137 = acc_41591;\n            redout_42138 = acc_41592;\n            for (int64_t i_42139 = 0; i_42139 < tile_sizze_41425; i_42139++) {\n                int64_t x_41600;\n                int64_t x_41601;\n                bool defunc_0_neq_res_41609;\n                bool defunc_0_neq_res_41610;\n                bool cond_f_res_41611;\n                bool y_41612;\n                bool cond_41613;\n                bool defunc_0_neq_res_41614;\n                bool defunc_0_neq_res_41615;\n                bool cond_t_res_f_res_41616;\n                bool y_41617;\n                bool cond_t_res_41618;\n                bool x_41619;\n                int64_t defunc_0_op_res_41620;\n                int64_t defunc_0_op_res_41621;\n                int64_t defunc_0_op_res_41622;\n                int64_t redout_tmp_42788;\n                int64_t redout_tmp_42789;\n                int64_t redout_tmp_42790;\n                \n                x_41600 = ((__local int64_t *) color_42702)[i_42139];\n                x_41601 = ((__local int64_t *) color_42701)[i_42139];\n                defunc_0_neq_res_41609 = redout_42137 == eta_p_41589;\n                defunc_0_neq_res_41610 = !defunc_0_neq_res_41609;\n                cond_f_res_41611 = slt64(redout_42136,", " (int64_t) 0);\n                y_41612 = defunc_0_neq_res_41609 && cond_f_res_41611;\n                cond_41613 = defunc_0_neq_res_41610 || y_41612;\n                defunc_0_neq_res_41614 = x_41601 == eta_p_41589;\n                defunc_0_neq_res_41615 = !defunc_0_neq_res_41614;\n                cond_t_res_f_res_41616 = slt64(x_41600, (int64_t) 0);\n                y_41617 = defunc_0_neq_res_41614 && cond_t_res_f_res_41616;\n                cond_t_res_41618 = defunc_0_neq_res_41615 || y_41617;\n                x_41619 = cond_41613 && cond_t_res_41618;\n                if (x_41619) {\n                    defunc_0_op_res_41620 = (int64_t) -1;\n                    defunc_0_op_res_41621 = eta_p_41589;\n                    defunc_0_op_res_41622 = (int64_t) 0;\n                } else {\n                    int64_t x_41602;\n                    int64_t defunc_0_op_res_f_res_41623;\n                    int64_t defunc_0_op_res_f_res_41624;\n                    int64_t defunc_0_op_res_f_res_41625;\n                    \n                    x_41602 = ((__local int64_t *) color_42700)[i_42139];\n                    if (cond_41613) {\n                        defunc_0_op_res_f_res_41623 = x_41600;\n                        defunc_0_op_res_f_res_41624 = x_41601;\n                        defunc_0_op_res_f_res_41625 = x_41602;\n                    } else {\n                        int64_t defunc_0_op_res_f_res_f_res_41626;\n                        int64_t defunc_0_op_res_f_res_f_res_41627;\n                        int64_t defunc_0_op_res_f_res_f_res_41628;\n                        \n                        if (cond_t_res_41618) {\n                            defunc_0_op_res_f_res_f_res_41626 = redout_42137;\n                        } else {\n                            defunc_0_op_res_f_res_f_res_41626 = eta_p_41589;\n                        }\n                        if (cond_t_res_41618) {\n                            defunc_0_op_res_f_res_f_res_41627 = redout_42136;\n                            defunc_0_op_res_f",
                                    "_res_f_res_41628 = redout_42138;\n                        } else {\n                            int64_t min_res_41629;\n                            int64_t tmp_41630;\n                            \n                            min_res_41629 = smin64(x_41600, redout_42136);\n                            tmp_41630 = add64(x_41602, redout_42138);\n                            defunc_0_op_res_f_res_f_res_41627 = min_res_41629;\n                            defunc_0_op_res_f_res_f_res_41628 = tmp_41630;\n                        }\n                        defunc_0_op_res_f_res_41623 = defunc_0_op_res_f_res_f_res_41627;\n                        defunc_0_op_res_f_res_41624 = defunc_0_op_res_f_res_f_res_41626;\n                        defunc_0_op_res_f_res_41625 = defunc_0_op_res_f_res_f_res_41628;\n                    }\n                    defunc_0_op_res_41620 = defunc_0_op_res_f_res_41623;\n                    defunc_0_op_res_41621 = defunc_0_op_res_f_res_41624;\n                    defunc_0_op_res_41622 = defunc_0_op_res_f_res_41625;\n                }\n                redout_tmp_42788 = defunc_0_op_res_41620;\n                redout_tmp_42789 = defunc_0_op_res_41621;\n                redout_tmp_42790 = defunc_0_op_res_41622;\n                redout_42136 = redout_tmp_42788;\n                redout_42137 = redout_tmp_42789;\n                redout_42138 = redout_tmp_42790;\n            }\n            x_41597 = redout_42136;\n            x_41598 = redout_42137;\n            x_41599 = redout_42138;\n            acc_41594 = x_41597;\n            acc_41595 = x_41598;\n            acc_41596 = x_41599;\n        } else {\n            acc_41594 = acc_41590;\n            acc_41595 = acc_41591;\n            acc_41596 = acc_41592;\n        }\n        mem_42315[(int64_t) 0] = acc_41594;\n        mem_42319[(int64_t) 0] = acc_41595;\n        mem_42323[(int64_t) 0] = acc_41596;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_6 = 0; i_6 < 1; i_6++)\n            mem_param_tmp_42782[i_6] = mem_42315[i_6];\n        for", " (int32_t i_7 = 0; i_7 < 1; i_7++)\n            mem_param_tmp_42783[i_7] = mem_42319[i_7];\n        for (int32_t i_8 = 0; i_8 < 1; i_8++)\n            mem_param_tmp_42784[i_8] = mem_42323[i_8];\n        for (int32_t i_9 = 0; i_9 < 1; i_9++)\n            mem_param_42303[i_9] = mem_param_tmp_42782[i_9];\n        for (int32_t i_10 = 0; i_10 < 1; i_10++)\n            mem_param_42304[i_10] = mem_param_tmp_42783[i_10];\n        for (int32_t i_11 = 0; i_11 < 1; i_11++)\n            mem_param_42305[i_11] = mem_param_tmp_42784[i_11];\n    }\n    for (int32_t i_12 = 0; i_12 < 1; i_12++)\n        ext_mem_42326[i_12] = mem_param_42303[i_12];\n    for (int32_t i_13 = 0; i_13 < 1; i_13++)\n        ext_mem_42325[i_13] = mem_param_42304[i_13];\n    for (int32_t i_14 = 0; i_14 < 1; i_14++)\n        ext_mem_42324[i_14] = mem_param_42305[i_14];\n    barrier(CLK_LOCAL_MEM_FENCE);\n    if (cond_41666) {\n        for (int32_t i_15 = 0; i_15 < 1; i_15++)\n            ext_mem_42342[i_15] = ext_mem_42326[i_15];\n        for (int32_t i_16 = 0; i_16 < 1; i_16++)\n            ext_mem_42341[i_16] = ext_mem_42324[i_16];\n    } else {\n        int64_t ltid_flat_41668;\n        int64_t ltid_41667;\n        int64_t j_41683;\n        bool cond_41687;\n        int64_t pre1d_41690;\n        int64_t pre1d_41688;\n        int64_t pre1d_41689;\n        int64_t ltid_flat_41704;\n        int64_t ltid_41703;\n        int64_t gtid_41717;\n        int64_t acc_41719;\n        int64_t acc_41721;\n        bool cond_41722;\n        int64_t acc_41723;\n        int64_t acc_41725;\n        \n        ltid_flat_41668 = sext_i32_i64(local_tid_42773);\n        ltid_41667 = sext_i32_i64(sext_i64_i32(ltid_pre_42777));\n        j_41683 = ltid_41667 + binop_x_41682;\n        cond_41687 = slt64(j_41683, nS_29940);\n        pre1d_41690 = btoi_bool_i64(cond_41687);\n        if (cond_41687) {\n            int64_t tile_elem_41691;\n            int64_t tile_elem_41692;\n            \n            tile_elem_41691 = ((__global int64_t *) ext_mem_42224)[j_41683];\n            tile_e", "lem_41692 = ((__global int64_t *) tS_mem_42200)[j_41683];\n            pre1d_41688 = tile_elem_41691;\n            pre1d_41689 = tile_elem_41692;\n        } else {\n            pre1d_41688 = (int64_t) 0;\n            pre1d_41689 = (int64_t) 0;\n        }\n        ((__local int64_t *) color_42702)[ltid_41667] = pre1d_41688;\n        ((__local int64_t *) color_42701)[ltid_41667] = pre1d_41689;\n        ((__local int64_t *) color_42700)[ltid_41667] = pre1d_41690;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_41704 = sext_i32_i64(local_tid_42773);\n        ltid_41703 = sext_i32_i64(sext_i64_i32(ltid_pre_42777));\n        gtid_41717 = binop_x_41433 + ltid_41703;\n        acc_41719 = ext_mem_42326[(int64_t) 0];\n        acc_41721 = ext_mem_42324[(int64_t) 0];\n        cond_41722 = slt64(gtid_41717, min_res_39102);\n        if (cond_41722) {\n            int64_t eta_p_41718;\n            int64_t acc_41720;\n            int64_t x_41726;\n            int64_t x_41727;\n            int64_t x_41728;\n            int64_t redout_42140;\n            int64_t redout_42141;\n            int64_t redout_42142;\n            \n            eta_p_41718 = mem_42290[(int64_t) 0];\n            acc_41720 = ext_mem_42325[(int64_t) 0];\n            redout_42140 = acc_41719;\n            redout_42141 = acc_41720;\n            redout_42142 = acc_41721;\n            for (int64_t i_42143 = 0; i_42143 < residual_input_41665; i_42143++) {\n                int64_t x_41729;\n                int64_t x_41730;\n                bool defunc_0_neq_res_41738;\n                bool defunc_0_neq_res_41739;\n                bool cond_f_res_41740;\n                bool y_41741;\n                bool cond_41742;\n                bool defunc_0_neq_res_41743;\n                bool defunc_0_neq_res_41744;\n                bool cond_t_res_f_res_41745;\n                bool y_41746;\n                bool cond_t_res_41747;\n                bool x_41748;\n                int64_t defunc_0_op_res_41749;\n                int64_t defunc_0_op_res_41750;\n       ",
                                    "         int64_t defunc_0_op_res_41751;\n                int64_t redout_tmp_42791;\n                int64_t redout_tmp_42792;\n                int64_t redout_tmp_42793;\n                \n                x_41729 = ((__local int64_t *) color_42702)[i_42143];\n                x_41730 = ((__local int64_t *) color_42701)[i_42143];\n                defunc_0_neq_res_41738 = redout_42141 == eta_p_41718;\n                defunc_0_neq_res_41739 = !defunc_0_neq_res_41738;\n                cond_f_res_41740 = slt64(redout_42140, (int64_t) 0);\n                y_41741 = defunc_0_neq_res_41738 && cond_f_res_41740;\n                cond_41742 = defunc_0_neq_res_41739 || y_41741;\n                defunc_0_neq_res_41743 = x_41730 == eta_p_41718;\n                defunc_0_neq_res_41744 = !defunc_0_neq_res_41743;\n                cond_t_res_f_res_41745 = slt64(x_41729, (int64_t) 0);\n                y_41746 = defunc_0_neq_res_41743 && cond_t_res_f_res_41745;\n                cond_t_res_41747 = defunc_0_neq_res_41744 || y_41746;\n                x_41748 = cond_41742 && cond_t_res_41747;\n                if (x_41748) {\n                    defunc_0_op_res_41749 = (int64_t) -1;\n                    defunc_0_op_res_41750 = eta_p_41718;\n                    defunc_0_op_res_41751 = (int64_t) 0;\n                } else {\n                    int64_t x_41731;\n                    int64_t defunc_0_op_res_f_res_41752;\n                    int64_t defunc_0_op_res_f_res_41753;\n                    int64_t defunc_0_op_res_f_res_41754;\n                    \n                    x_41731 = ((__local int64_t *) color_42700)[i_42143];\n                    if (cond_41742) {\n                        defunc_0_op_res_f_res_41752 = x_41729;\n                        defunc_0_op_res_f_res_41753 = x_41730;\n                        defunc_0_op_res_f_res_41754 = x_41731;\n                    } else {\n                        int64_t defunc_0_op_res_f_res_f_res_41755;\n                        int64_t defunc_0_op_res_f_res_f_res_41756;\n            ", "            int64_t defunc_0_op_res_f_res_f_res_41757;\n                        \n                        if (cond_t_res_41747) {\n                            defunc_0_op_res_f_res_f_res_41755 = redout_42141;\n                        } else {\n                            defunc_0_op_res_f_res_f_res_41755 = eta_p_41718;\n                        }\n                        if (cond_t_res_41747) {\n                            defunc_0_op_res_f_res_f_res_41756 = redout_42140;\n                            defunc_0_op_res_f_res_f_res_41757 = redout_42142;\n                        } else {\n                            int64_t min_res_41758;\n                            int64_t tmp_41759;\n                            \n                            min_res_41758 = smin64(x_41729, redout_42140);\n                            tmp_41759 = add64(x_41731, redout_42142);\n                            defunc_0_op_res_f_res_f_res_41756 = min_res_41758;\n                            defunc_0_op_res_f_res_f_res_41757 = tmp_41759;\n                        }\n                        defunc_0_op_res_f_res_41752 = defunc_0_op_res_f_res_f_res_41756;\n                        defunc_0_op_res_f_res_41753 = defunc_0_op_res_f_res_f_res_41755;\n                        defunc_0_op_res_f_res_41754 = defunc_0_op_res_f_res_f_res_41757;\n                    }\n                    defunc_0_op_res_41749 = defunc_0_op_res_f_res_41752;\n                    defunc_0_op_res_41750 = defunc_0_op_res_f_res_41753;\n                    defunc_0_op_res_41751 = defunc_0_op_res_f_res_41754;\n                }\n                redout_tmp_42791 = defunc_0_op_res_41749;\n                redout_tmp_42792 = defunc_0_op_res_41750;\n                redout_tmp_42793 = defunc_0_op_res_41751;\n                redout_42140 = redout_tmp_42791;\n                redout_42141 = redout_tmp_42792;\n                redout_42142 = redout_tmp_42793;\n            }\n            x_41726 = redout_42140;\n            x_41727 = redout_42141;\n            x_41728 = redout_42142;\n", "            acc_41723 = x_41726;\n            acc_41725 = x_41728;\n        } else {\n            acc_41723 = acc_41719;\n            acc_41725 = acc_41721;\n        }\n        mem_42336[(int64_t) 0] = acc_41723;\n        mem_42340[(int64_t) 0] = acc_41725;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_17 = 0; i_17 < 1; i_17++)\n            ext_mem_42342[i_17] = mem_42336[i_17];\n        for (int32_t i_18 = 0; i_18 < 1; i_18++)\n            ext_mem_42341[i_18] = mem_42340[i_18];\n    }\n    if (slt64(sext_i32_i64(local_tid_42773) + tile_sizze_41425 * sext_i32_i64(block_id_42774), min_res_39102)) {\n        int64_t tmp_42794 = ext_mem_42342[(int64_t) 0];\n        \n        ((__global int64_t *) mem_42344)[sext_i32_i64(local_tid_42773) + tile_sizze_41425 * sext_i32_i64(block_id_42774)] = tmp_42794;\n    }\n    if (slt64(sext_i32_i64(local_tid_42773) + tile_sizze_41425 * sext_i32_i64(block_id_42774), min_res_39102)) {\n        int64_t tmp_42795 = ext_mem_42341[(int64_t) 0];\n        \n        ((__global int64_t *) mem_42346)[sext_i32_i64(local_tid_42773) + tile_sizze_41425 * sext_i32_i64(block_id_42774)] = tmp_42795;\n    }\n    \n  error_8:\n    return;\n    #undef tile_sizze_41425\n    #undef bytes_42306\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_longzisegmap_intrablock_41778_dim1, 1, 1)\nvoid inner_SMJ_longzisegmap_intrablock_41778(__global int *global_failure, int64_t nS_29940, int64_t start_39100, int64_t min_res_39102, int64_t ldim_41781, int64_t num_whole_tiles_41796, int64_t residual_input_42020, unsigned char cond_42021_bits, int64_t binop_x_42037, __global unsigned char *tR_mem_42199, __global unsigned char *tS_mem_42200, __global unsigned char *ext_mem_42224, __global unsigned char *mem_42283, __global unsigned char *mem_42285)\n{\n    bool cond_42021 = cond_42021_bits;\n    \n    #define tile_sizze_41780 (inner_SMJ_longzisegmap_intrablock_41778zitile_sizze_41780)\n    #define bytes_42245 (inner_SMJ_longzisegmap_intrablock_41778zibytes_42245)\n    \n    volatile __local unsigned char *c",
                                    "olor_42705_backing_2 = &shared_mem[0];\n    const int64_t color_42705_backing_2_offset = 0 + (bytes_42245 + srem64((int64_t) 8 - srem64(bytes_42245, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_42704_backing_1 = &shared_mem[color_42705_backing_2_offset];\n    const int64_t color_42704_backing_1_offset = color_42705_backing_2_offset + (bytes_42245 + srem64((int64_t) 8 - srem64(bytes_42245, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_42703_backing_0 = &shared_mem[color_42704_backing_1_offset];\n    const int64_t color_42703_backing_0_offset = color_42704_backing_1_offset + (bytes_42245 + srem64((int64_t) 8 - srem64(bytes_42245, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42799;\n    int32_t tblock_sizze_42802;\n    int32_t wave_sizze_42801;\n    int32_t block_id_42800;\n    int32_t global_tid_42798;\n    int64_t gid_flat_41778;\n    int64_t slice_42804;\n    int64_t ltid_pre_42803;\n    int64_t remnant_42805;\n    int64_t slice_42806;\n    int64_t gid_41777;\n    int64_t remnant_42807;\n    __local unsigned char *color_42703;\n    __local unsigned char *color_42704;\n    __local unsigned char *color_42705;\n    int64_t binop_x_41788;\n    int64_t mem_42229[1];\n    int64_t ltid_flat_41783;\n    int64_t ltid_41782;\n    int64_t gtid_41789;\n    bool cond_41790;\n    int64_t pre_41791;\n    int64_t mem_42233[1];\n    int64_t mem_42237[1];\n    int64_t mem_42241[1];\n    int64_t ltid_flat_41798;\n    int64_t ltid_41797;\n    int64_t gtid_41808;\n    bool cond_41809;\n    int64_t neutral_41810;\n    int64_t neutral_41811;\n    int64_t ext_mem_42265[1];\n    int64_t ext_mem_42264[1];\n    int64_t ext_mem_42263[1];\n    int64_t mem_param_42242[1];\n    int64_t mem_param_42243[1];\n    int64_t mem_param_42244[1];\n    int64_t mem_42275[1];\n    int64_t mem_42279[1];\n    int64_t ext_mem_42281[1];\n    int64_t ext_mem_42280[1];\n    \n    local_tid_42799 = get_local_id(0);\n    tblock_sizze_42802 = get_loca", "l_size(0);\n    wave_sizze_42801 = LOCKSTEP_WIDTH;\n    block_id_42800 = get_tblock_id(0);\n    global_tid_42798 = block_id_42800 * tblock_sizze_42802 + local_tid_42799;\n    gid_flat_41778 = sext_i32_i64(block_id_42800);\n    slice_42804 = tile_sizze_41780;\n    ltid_pre_42803 = sext_i32_i64(local_tid_42799);\n    remnant_42805 = sext_i32_i64(local_tid_42799) - ltid_pre_42803;\n    slice_42806 = ldim_41781;\n    gid_41777 = sext_i32_i64(block_id_42800);\n    remnant_42807 = sext_i32_i64(block_id_42800) - gid_41777;\n    color_42703 = (__local unsigned char *) color_42703_backing_0;\n    color_42704 = (__local unsigned char *) color_42704_backing_1;\n    color_42705 = (__local unsigned char *) color_42705_backing_2;\n    binop_x_41788 = gid_41777 * tile_sizze_41780;\n    ltid_flat_41783 = sext_i32_i64(local_tid_42799);\n    ltid_41782 = sext_i32_i64(sext_i64_i32(ltid_pre_42803));\n    gtid_41789 = ltid_41782 + binop_x_41788;\n    cond_41790 = slt64(gtid_41789, min_res_39102);\n    if (cond_41790) {\n        int64_t slice_41792;\n        int64_t eta_p_41793;\n        \n        slice_41792 = start_39100 + gtid_41789;\n        eta_p_41793 = ((__global int64_t *) tR_mem_42199)[slice_41792];\n        pre_41791 = eta_p_41793;\n    } else {\n        pre_41791 = (int64_t) 0;\n    }\n    mem_42229[(int64_t) 0] = pre_41791;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    ltid_flat_41798 = sext_i32_i64(local_tid_42799);\n    ltid_41797 = sext_i32_i64(sext_i64_i32(ltid_pre_42803));\n    gtid_41808 = binop_x_41788 + ltid_41797;\n    cond_41809 = slt64(gtid_41808, min_res_39102);\n    if (cond_41809) {\n        neutral_41810 = (int64_t) -1;\n    } else {\n        neutral_41810 = (int64_t) 0;\n    }\n    if (cond_41809) {\n        int64_t eta_p_41813 = mem_42229[(int64_t) 0];\n        \n        neutral_41811 = eta_p_41813;\n    } else {\n        neutral_41811 = (int64_t) 0;\n    }\n    mem_42233[(int64_t) 0] = neutral_41810;\n    mem_42237[(int64_t) 0] = neutral_41811;\n    mem_42241[(int64_t) 0] = (int64_t) 0;\n    barrier(CLK_LOCAL_MEM", "_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    for (int32_t i_3 = 0; i_3 < 1; i_3++)\n        mem_param_42242[i_3] = mem_42233[i_3];\n    for (int32_t i_4 = 0; i_4 < 1; i_4++)\n        mem_param_42243[i_4] = mem_42237[i_4];\n    for (int32_t i_5 = 0; i_5 < 1; i_5++)\n        mem_param_42244[i_5] = mem_42241[i_5];\n    for (int64_t tile_id_41823 = 0; tile_id_41823 < num_whole_tiles_41796; tile_id_41823++) {\n        int64_t binop_x_41922;\n        int64_t ltid_flat_41921;\n        int64_t ltid_41920;\n        int64_t j_41923;\n        bool cond_41927;\n        int64_t pre1d_41930;\n        int64_t pre1d_41928;\n        int64_t pre1d_41929;\n        int64_t mem_42254[1];\n        int64_t mem_42258[1];\n        int64_t mem_42262[1];\n        int64_t ltid_flat_41941;\n        int64_t ltid_41940;\n        int64_t gtid_41943;\n        int64_t acc_41945;\n        int64_t acc_41946;\n        int64_t acc_41947;\n        bool cond_41948;\n        int64_t acc_41949;\n        int64_t acc_41950;\n        int64_t acc_41951;\n        int64_t mem_param_tmp_42808[1];\n        int64_t mem_param_tmp_42809[1];\n        int64_t mem_param_tmp_42810[1];\n        \n        binop_x_41922 = tile_sizze_41780 * tile_id_41823;\n        ltid_flat_41921 = sext_i32_i64(local_tid_42799);\n        ltid_41920 = sext_i32_i64(sext_i64_i32(ltid_pre_42803));\n        j_41923 = ltid_41920 + binop_x_41922;\n        cond_41927 = slt64(j_41923, nS_29940);\n        pre1d_41930 = btoi_bool_i64(cond_41927);\n        if (cond_41927) {\n            int64_t tile_elem_41931;\n            int64_t tile_elem_41932;\n            \n            tile_elem_41931 = ((__global int64_t *) ext_mem_42224)[j_41923];\n            tile_elem_41932 = ((__global int64_t *) tS_mem_42200)[j_41923];\n            pre1d_41928 = tile_elem_41931;\n            pre1d_41929 = tile_elem_41932;\n        } else {\n            pre1d_41928 = (int64_t) 0;\n            pre1d_41929 = (int64_t) 0;\n        }\n        ((__local int64_t *) color_42705)[ltid_41920] = pre1d_41928;\n        ((__local int64_",
                                    "t *) color_42704)[ltid_41920] = pre1d_41929;\n        ((__local int64_t *) color_42703)[ltid_41920] = pre1d_41930;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_41941 = sext_i32_i64(local_tid_42799);\n        ltid_41940 = sext_i32_i64(sext_i64_i32(ltid_pre_42803));\n        gtid_41943 = binop_x_41788 + ltid_41940;\n        acc_41945 = mem_param_42242[(int64_t) 0];\n        acc_41946 = mem_param_42243[(int64_t) 0];\n        acc_41947 = mem_param_42244[(int64_t) 0];\n        cond_41948 = slt64(gtid_41943, min_res_39102);\n        if (cond_41948) {\n            int64_t eta_p_41944;\n            int64_t x_41952;\n            int64_t x_41953;\n            int64_t x_41954;\n            int64_t redout_42144;\n            int64_t redout_42145;\n            int64_t redout_42146;\n            \n            eta_p_41944 = mem_42229[(int64_t) 0];\n            redout_42144 = acc_41945;\n            redout_42145 = acc_41946;\n            redout_42146 = acc_41947;\n            for (int64_t i_42147 = 0; i_42147 < tile_sizze_41780; i_42147++) {\n                int64_t x_41955;\n                int64_t x_41956;\n                bool defunc_0_neq_res_41964;\n                bool defunc_0_neq_res_41965;\n                bool cond_f_res_41966;\n                bool y_41967;\n                bool cond_41968;\n                bool defunc_0_neq_res_41969;\n                bool defunc_0_neq_res_41970;\n                bool cond_t_res_f_res_41971;\n                bool y_41972;\n                bool cond_t_res_41973;\n                bool x_41974;\n                int64_t defunc_0_op_res_41975;\n                int64_t defunc_0_op_res_41976;\n                int64_t defunc_0_op_res_41977;\n                int64_t redout_tmp_42814;\n                int64_t redout_tmp_42815;\n                int64_t redout_tmp_42816;\n                \n                x_41955 = ((__local int64_t *) color_42705)[i_42147];\n                x_41956 = ((__local int64_t *) color_42704)[i_42147];\n                defunc_0_neq_res_41964 = redout_4214", "5 == eta_p_41944;\n                defunc_0_neq_res_41965 = !defunc_0_neq_res_41964;\n                cond_f_res_41966 = slt64(redout_42144, (int64_t) 0);\n                y_41967 = defunc_0_neq_res_41964 && cond_f_res_41966;\n                cond_41968 = defunc_0_neq_res_41965 || y_41967;\n                defunc_0_neq_res_41969 = x_41956 == eta_p_41944;\n                defunc_0_neq_res_41970 = !defunc_0_neq_res_41969;\n                cond_t_res_f_res_41971 = slt64(x_41955, (int64_t) 0);\n                y_41972 = defunc_0_neq_res_41969 && cond_t_res_f_res_41971;\n                cond_t_res_41973 = defunc_0_neq_res_41970 || y_41972;\n                x_41974 = cond_41968 && cond_t_res_41973;\n                if (x_41974) {\n                    defunc_0_op_res_41975 = (int64_t) -1;\n                    defunc_0_op_res_41976 = eta_p_41944;\n                    defunc_0_op_res_41977 = (int64_t) 0;\n                } else {\n                    int64_t x_41957;\n                    int64_t defunc_0_op_res_f_res_41978;\n                    int64_t defunc_0_op_res_f_res_41979;\n                    int64_t defunc_0_op_res_f_res_41980;\n                    \n                    x_41957 = ((__local int64_t *) color_42703)[i_42147];\n                    if (cond_41968) {\n                        defunc_0_op_res_f_res_41978 = x_41955;\n                        defunc_0_op_res_f_res_41979 = x_41956;\n                        defunc_0_op_res_f_res_41980 = x_41957;\n                    } else {\n                        int64_t defunc_0_op_res_f_res_f_res_41981;\n                        int64_t defunc_0_op_res_f_res_f_res_41982;\n                        int64_t defunc_0_op_res_f_res_f_res_41983;\n                        \n                        if (cond_t_res_41973) {\n                            defunc_0_op_res_f_res_f_res_41981 = redout_42145;\n                        } else {\n                            defunc_0_op_res_f_res_f_res_41981 = eta_p_41944;\n                        }\n                        if (cond_", "t_res_41973) {\n                            defunc_0_op_res_f_res_f_res_41982 = redout_42144;\n                            defunc_0_op_res_f_res_f_res_41983 = redout_42146;\n                        } else {\n                            int64_t min_res_41984;\n                            int64_t tmp_41985;\n                            \n                            min_res_41984 = smin64(x_41955, redout_42144);\n                            tmp_41985 = add64(x_41957, redout_42146);\n                            defunc_0_op_res_f_res_f_res_41982 = min_res_41984;\n                            defunc_0_op_res_f_res_f_res_41983 = tmp_41985;\n                        }\n                        defunc_0_op_res_f_res_41978 = defunc_0_op_res_f_res_f_res_41982;\n                        defunc_0_op_res_f_res_41979 = defunc_0_op_res_f_res_f_res_41981;\n                        defunc_0_op_res_f_res_41980 = defunc_0_op_res_f_res_f_res_41983;\n                    }\n                    defunc_0_op_res_41975 = defunc_0_op_res_f_res_41978;\n                    defunc_0_op_res_41976 = defunc_0_op_res_f_res_41979;\n                    defunc_0_op_res_41977 = defunc_0_op_res_f_res_41980;\n                }\n                redout_tmp_42814 = defunc_0_op_res_41975;\n                redout_tmp_42815 = defunc_0_op_res_41976;\n                redout_tmp_42816 = defunc_0_op_res_41977;\n                redout_42144 = redout_tmp_42814;\n                redout_42145 = redout_tmp_42815;\n                redout_42146 = redout_tmp_42816;\n            }\n            x_41952 = redout_42144;\n            x_41953 = redout_42145;\n            x_41954 = redout_42146;\n            acc_41949 = x_41952;\n            acc_41950 = x_41953;\n            acc_41951 = x_41954;\n        } else {\n            acc_41949 = acc_41945;\n            acc_41950 = acc_41946;\n            acc_41951 = acc_41947;\n        }\n        mem_42254[(int64_t) 0] = acc_41949;\n        mem_42258[(int64_t) 0] = acc_41950;\n        mem_42262[(int64_t) 0] = acc_41951;\n        barr",
                                    "ier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_6 = 0; i_6 < 1; i_6++)\n            mem_param_tmp_42808[i_6] = mem_42254[i_6];\n        for (int32_t i_7 = 0; i_7 < 1; i_7++)\n            mem_param_tmp_42809[i_7] = mem_42258[i_7];\n        for (int32_t i_8 = 0; i_8 < 1; i_8++)\n            mem_param_tmp_42810[i_8] = mem_42262[i_8];\n        for (int32_t i_9 = 0; i_9 < 1; i_9++)\n            mem_param_42242[i_9] = mem_param_tmp_42808[i_9];\n        for (int32_t i_10 = 0; i_10 < 1; i_10++)\n            mem_param_42243[i_10] = mem_param_tmp_42809[i_10];\n        for (int32_t i_11 = 0; i_11 < 1; i_11++)\n            mem_param_42244[i_11] = mem_param_tmp_42810[i_11];\n    }\n    for (int32_t i_12 = 0; i_12 < 1; i_12++)\n        ext_mem_42265[i_12] = mem_param_42242[i_12];\n    for (int32_t i_13 = 0; i_13 < 1; i_13++)\n        ext_mem_42264[i_13] = mem_param_42243[i_13];\n    for (int32_t i_14 = 0; i_14 < 1; i_14++)\n        ext_mem_42263[i_14] = mem_param_42244[i_14];\n    barrier(CLK_LOCAL_MEM_FENCE);\n    if (cond_42021) {\n        for (int32_t i_15 = 0; i_15 < 1; i_15++)\n            ext_mem_42281[i_15] = ext_mem_42265[i_15];\n        for (int32_t i_16 = 0; i_16 < 1; i_16++)\n            ext_mem_42280[i_16] = ext_mem_42263[i_16];\n    } else {\n        int64_t ltid_flat_42023;\n        int64_t ltid_42022;\n        int64_t j_42038;\n        bool cond_42042;\n        int64_t pre1d_42045;\n        int64_t pre1d_42043;\n        int64_t pre1d_42044;\n        int64_t ltid_flat_42059;\n        int64_t ltid_42058;\n        int64_t gtid_42072;\n        int64_t acc_42074;\n        int64_t acc_42076;\n        bool cond_42077;\n        int64_t acc_42078;\n        int64_t acc_42080;\n        \n        ltid_flat_42023 = sext_i32_i64(local_tid_42799);\n        ltid_42022 = sext_i32_i64(sext_i64_i32(ltid_pre_42803));\n        j_42038 = ltid_42022 + binop_x_42037;\n        cond_42042 = slt64(j_42038, nS_29940);\n        pre1d_42045 = btoi_bool_i64(cond_42042);\n        if (cond_42042) {\n            int64_t tile_elem_42046;\n       ", "     int64_t tile_elem_42047;\n            \n            tile_elem_42046 = ((__global int64_t *) ext_mem_42224)[j_42038];\n            tile_elem_42047 = ((__global int64_t *) tS_mem_42200)[j_42038];\n            pre1d_42043 = tile_elem_42046;\n            pre1d_42044 = tile_elem_42047;\n        } else {\n            pre1d_42043 = (int64_t) 0;\n            pre1d_42044 = (int64_t) 0;\n        }\n        ((__local int64_t *) color_42705)[ltid_42022] = pre1d_42043;\n        ((__local int64_t *) color_42704)[ltid_42022] = pre1d_42044;\n        ((__local int64_t *) color_42703)[ltid_42022] = pre1d_42045;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_42059 = sext_i32_i64(local_tid_42799);\n        ltid_42058 = sext_i32_i64(sext_i64_i32(ltid_pre_42803));\n        gtid_42072 = binop_x_41788 + ltid_42058;\n        acc_42074 = ext_mem_42265[(int64_t) 0];\n        acc_42076 = ext_mem_42263[(int64_t) 0];\n        cond_42077 = slt64(gtid_42072, min_res_39102);\n        if (cond_42077) {\n            int64_t eta_p_42073;\n            int64_t acc_42075;\n            int64_t x_42081;\n            int64_t x_42082;\n            int64_t x_42083;\n            int64_t redout_42148;\n            int64_t redout_42149;\n            int64_t redout_42150;\n            \n            eta_p_42073 = mem_42229[(int64_t) 0];\n            acc_42075 = ext_mem_42264[(int64_t) 0];\n            redout_42148 = acc_42074;\n            redout_42149 = acc_42075;\n            redout_42150 = acc_42076;\n            for (int64_t i_42151 = 0; i_42151 < residual_input_42020; i_42151++) {\n                int64_t x_42084;\n                int64_t x_42085;\n                bool defunc_0_neq_res_42093;\n                bool defunc_0_neq_res_42094;\n                bool cond_f_res_42095;\n                bool y_42096;\n                bool cond_42097;\n                bool defunc_0_neq_res_42098;\n                bool defunc_0_neq_res_42099;\n                bool cond_t_res_f_res_42100;\n                bool y_42101;\n                bool cond_t_res_", "42102;\n                bool x_42103;\n                int64_t defunc_0_op_res_42104;\n                int64_t defunc_0_op_res_42105;\n                int64_t defunc_0_op_res_42106;\n                int64_t redout_tmp_42817;\n                int64_t redout_tmp_42818;\n                int64_t redout_tmp_42819;\n                \n                x_42084 = ((__local int64_t *) color_42705)[i_42151];\n                x_42085 = ((__local int64_t *) color_42704)[i_42151];\n                defunc_0_neq_res_42093 = redout_42149 == eta_p_42073;\n                defunc_0_neq_res_42094 = !defunc_0_neq_res_42093;\n                cond_f_res_42095 = slt64(redout_42148, (int64_t) 0);\n                y_42096 = defunc_0_neq_res_42093 && cond_f_res_42095;\n                cond_42097 = defunc_0_neq_res_42094 || y_42096;\n                defunc_0_neq_res_42098 = x_42085 == eta_p_42073;\n                defunc_0_neq_res_42099 = !defunc_0_neq_res_42098;\n                cond_t_res_f_res_42100 = slt64(x_42084, (int64_t) 0);\n                y_42101 = defunc_0_neq_res_42098 && cond_t_res_f_res_42100;\n                cond_t_res_42102 = defunc_0_neq_res_42099 || y_42101;\n                x_42103 = cond_42097 && cond_t_res_42102;\n                if (x_42103) {\n                    defunc_0_op_res_42104 = (int64_t) -1;\n                    defunc_0_op_res_42105 = eta_p_42073;\n                    defunc_0_op_res_42106 = (int64_t) 0;\n                } else {\n                    int64_t x_42086;\n                    int64_t defunc_0_op_res_f_res_42107;\n                    int64_t defunc_0_op_res_f_res_42108;\n                    int64_t defunc_0_op_res_f_res_42109;\n                    \n                    x_42086 = ((__local int64_t *) color_42703)[i_42151];\n                    if (cond_42097) {\n                        defunc_0_op_res_f_res_42107 = x_42084;\n                        defunc_0_op_res_f_res_42108 = x_42085;\n                        defunc_0_op_res_f_res_42109 = x_42086;\n                    } else {\n        ",
                                    "                int64_t defunc_0_op_res_f_res_f_res_42110;\n                        int64_t defunc_0_op_res_f_res_f_res_42111;\n                        int64_t defunc_0_op_res_f_res_f_res_42112;\n                        \n                        if (cond_t_res_42102) {\n                            defunc_0_op_res_f_res_f_res_42110 = redout_42149;\n                        } else {\n                            defunc_0_op_res_f_res_f_res_42110 = eta_p_42073;\n                        }\n                        if (cond_t_res_42102) {\n                            defunc_0_op_res_f_res_f_res_42111 = redout_42148;\n                            defunc_0_op_res_f_res_f_res_42112 = redout_42150;\n                        } else {\n                            int64_t min_res_42113;\n                            int64_t tmp_42114;\n                            \n                            min_res_42113 = smin64(x_42084, redout_42148);\n                            tmp_42114 = add64(x_42086, redout_42150);\n                            defunc_0_op_res_f_res_f_res_42111 = min_res_42113;\n                            defunc_0_op_res_f_res_f_res_42112 = tmp_42114;\n                        }\n                        defunc_0_op_res_f_res_42107 = defunc_0_op_res_f_res_f_res_42111;\n                        defunc_0_op_res_f_res_42108 = defunc_0_op_res_f_res_f_res_42110;\n                        defunc_0_op_res_f_res_42109 = defunc_0_op_res_f_res_f_res_42112;\n                    }\n                    defunc_0_op_res_42104 = defunc_0_op_res_f_res_42107;\n                    defunc_0_op_res_42105 = defunc_0_op_res_f_res_42108;\n                    defunc_0_op_res_42106 = defunc_0_op_res_f_res_42109;\n                }\n                redout_tmp_42817 = defunc_0_op_res_42104;\n                redout_tmp_42818 = defunc_0_op_res_42105;\n                redout_tmp_42819 = defunc_0_op_res_42106;\n                redout_42148 = redout_tmp_42817;\n                redout_42149 = redout_tmp_42818;\n                redout_42150 = re", "dout_tmp_42819;\n            }\n            x_42081 = redout_42148;\n            x_42082 = redout_42149;\n            x_42083 = redout_42150;\n            acc_42078 = x_42081;\n            acc_42080 = x_42083;\n        } else {\n            acc_42078 = acc_42074;\n            acc_42080 = acc_42076;\n        }\n        mem_42275[(int64_t) 0] = acc_42078;\n        mem_42279[(int64_t) 0] = acc_42080;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_17 = 0; i_17 < 1; i_17++)\n            ext_mem_42281[i_17] = mem_42275[i_17];\n        for (int32_t i_18 = 0; i_18 < 1; i_18++)\n            ext_mem_42280[i_18] = mem_42279[i_18];\n    }\n    if (slt64(sext_i32_i64(local_tid_42799) + tile_sizze_41780 * sext_i32_i64(block_id_42800), min_res_39102)) {\n        int64_t tmp_42820 = ext_mem_42281[(int64_t) 0];\n        \n        ((__global int64_t *) mem_42283)[sext_i32_i64(local_tid_42799) + tile_sizze_41780 * sext_i32_i64(block_id_42800)] = tmp_42820;\n    }\n    if (slt64(sext_i32_i64(local_tid_42799) + tile_sizze_41780 * sext_i32_i64(block_id_42800), min_res_39102)) {\n        int64_t tmp_42821 = ext_mem_42280[(int64_t) 0];\n        \n        ((__global int64_t *) mem_42285)[sext_i32_i64(local_tid_42799) + tile_sizze_41780 * sext_i32_i64(block_id_42800)] = tmp_42821;\n    }\n    \n  error_8:\n    return;\n    #undef tile_sizze_41780\n    #undef bytes_42245\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_longzisegscan_40819_dim1, 1, 1)\nvoid inner_SMJ_longzisegscan_40819(__global int *global_failure, int64_t nR_29939, int64_t num_tblocks_40816, int64_t ext_42367, int64_t ext_42368, int64_t num_virt_blocks_42829, int64_t num_virt_threads_42830, __global unsigned char *ext_mem_42370, __global unsigned char *mem_42373, __global unsigned char *mem_42375, __global unsigned char *status_flags_mem_42831, __global unsigned char *aggregates_mem_42853, __global unsigned char *incprefixes_mem_42855, __global unsigned char *global_dynid_mem_42857)\n{\n    #define segscan_tblock_sizze_40814 (inner_SMJ_longzisegscan_40819ziseg", "scan_tblock_sizze_40814)\n    #define chunk_sizze_42828 (inner_SMJ_longzisegscan_40819zichunk_sizze_42828)\n    \n    volatile __local unsigned char *local_mem_42887_backing_0 = &shared_mem[0];\n    const int64_t local_mem_42887_backing_0_offset = 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_40814), chunk_sizze_42828 * segscan_tblock_sizze_40814 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_40814), chunk_sizze_42828 * segscan_tblock_sizze_40814 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42880;\n    int32_t tblock_sizze_42883;\n    int32_t wave_sizze_42882;\n    int32_t block_id_42881;\n    int32_t global_tid_42879;\n    int64_t phys_tid_40819;\n    int32_t chunk_sizze_32b_42884;\n    int64_t byte_offsets_42885;\n    int64_t warp_byte_offset_42886;\n    __local unsigned char *local_mem_42887;\n    int64_t trans_arr_len_42888;\n    int64_t phys_block_id_42894;\n    int64_t virtloop_bound_42895;\n    \n    local_tid_42880 = get_local_id(0);\n    tblock_sizze_42883 = get_local_size(0);\n    wave_sizze_42882 = LOCKSTEP_WIDTH;\n    block_id_42881 = get_tblock_id(0);\n    global_tid_42879 = block_id_42881 * tblock_sizze_42883 + local_tid_42880;\n    phys_tid_40819 = sext_i32_i64(global_tid_42879);\n    chunk_sizze_32b_42884 = sext_i64_i32(chunk_sizze_42828);\n    byte_offsets_42885 = segscan_tblock_sizze_40814 * (int64_t) 8;\n    warp_byte_offset_42886 = (int64_t) 288;\n    // Allocate reusable shared memory\n    { }\n    local_mem_42887 = (__local unsigned char *) local_mem_42887_backing_0;\n    trans_arr_len_42888 = chunk_sizze_42828 * segscan_tblock_sizze_40814;\n    phys_block_id_42894 = get_tblock_id(0);\n    virtloop_bound_42895 = sdiv_up64(num_virt_blocks_42829 - phys_block_id_42894, num_tblocks_40816);\n    for (int64_t virtloop_i_42896 = 0; virtloop_i_42896 < virtloop_bound_42895; virtloop_i_42896++) {\n        int64_t dynamic_id_428",
                                    "97;\n        int64_t block_offset_42898;\n        int64_t sgm_idx_42899;\n        int32_t boundary_42900;\n        int32_t segsizze_compact_42901;\n        int64_t private_mem_42902[chunk_sizze_42828];\n        int64_t thd_offset_42904;\n        int64_t acc_42920;\n        int64_t prefix_42930;\n        bool block_new_sgm_42931;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_42880 == 0) {\n                dynamic_id_42897 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_42857)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_42887)[(int64_t) 0] = dynamic_id_42897;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_42897 == num_virt_blocks_42829 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_42857)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_42897 = ((__local int32_t *) local_mem_42887)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_42898 = dynamic_id_42897 * chunk_sizze_42828 * segscan_tblock_sizze_40814;\n        sgm_idx_42899 = smod64(block_offset_42898, nR_29939);\n        boundary_42900 = sext_i64_i32(smin64(chunk_sizze_42828 * segscan_tblock_sizze_40814, nR_29939 - sgm_idx_42899));\n        segsizze_compact_42901 = sext_i64_i32(smin64(chunk_sizze_42828 * segscan_tblock_sizze_40814, nR_29939));\n        thd_offset_42904 = block_offset_42898 + sext_i32_i64(local_tid_42880);\n        // Load and map\n        {\n            for (int64_t i_42905 = 0; i_42905 < chunk_sizze_42828; i_42905++) {\n                int64_t virt_tid_42906 = thd_offset_42904 + i_42905 * segscan_tblock_sizze_40814;\n                int64_t slice_42907 = nR_29939;\n                int64_t g", "tid_40818 = virt_tid_42906;\n                int64_t remnant_42908 = virt_tid_42906 - gtid_40818;\n                \n                if (slt64(virt_tid_42906, nR_29939)) {\n                    int64_t eta_p_39458 = ((__global int64_t *) ext_mem_42370)[ext_42368 + gtid_40818 * ext_42367];\n                    bool lifted_lambda_res_39459 = slt64((int64_t) 0, eta_p_39458);\n                    int64_t defunc_0_f_res_39460 = btoi_bool_i64(lifted_lambda_res_39459);\n                    \n                    ((__global int64_t *) mem_42375)[gtid_40818] = defunc_0_f_res_39460;\n                    private_mem_42902[i_42905] = defunc_0_f_res_39460;\n                } else {\n                    private_mem_42902[i_42905] = (int64_t) 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_42909 = 0; i_42909 < chunk_sizze_42828; i_42909++) {\n                int64_t sharedIdx_42910 = sext_i32_i64(local_tid_42880) + i_42909 * segscan_tblock_sizze_40814;\n                int64_t tmp_42911 = private_mem_42902[i_42909];\n                \n                ((__local int64_t *) local_mem_42887)[sharedIdx_42910] = tmp_42911;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_42912 = 0; i_42912 < chunk_sizze_42828; i_42912++) {\n                int64_t sharedIdx_42913 = sext_i32_i64(local_tid_42880) * chunk_sizze_42828 + i_42912;\n                int64_t tmp_42914 = ((__local int64_t *) local_mem_42887)[sharedIdx_42913];\n                \n                private_mem_42902[i_42912] = tmp_42914;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_42915 = 0; i_42915 < chunk_sizze_42828 - (int64_t) 1; i_42915++) {\n                int64_t eta_p_39187;\n                int64_t eta_p_39188;\n                \n                eta_p_39187 = private_mem_42902[i_42915];\n                eta_p_39188 = private_mem_", "42902[i_42915 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_39189 = add64(eta_p_39187, eta_p_39188);\n                \n                private_mem_42902[i_42915 + (int64_t) 1] = defunc_0_op_res_39189;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_42916 = private_mem_42902[chunk_sizze_42828 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_42887)[sext_i32_i64(local_tid_42880)] = tmp_42916;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_42917;\n            int64_t eta_p_42918;\n            int64_t eta_p_42921;\n            int64_t eta_p_42922;\n            bool ltid_in_bounds_42924 = slt64(sext_i32_i64(local_tid_42880), num_virt_threads_42830);\n            int32_t skip_threads_42925;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_42924) {\n                    eta_p_42918 = ((volatile __local int64_t *) local_mem_42887)[sext_i32_i64(local_tid_42880)];\n                    if ((local_tid_42880 - squot32(local_tid_42880, 32) * 32) == 0) {\n                        eta_p_42917 = eta_p_42918;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_42925 = 1;\n                while (slt32(skip_threads_42925, 32)) {\n                    bool thread_active_42926 = sle32(skip_threads_42925, local_tid_42880 - squot32(local_tid_42880, 32) * 32) && ltid_in_bounds_42924;\n                    \n                    if (thread_active_42926) {\n                        // read operands\n                        {\n                            eta_p_42917 = ((volatile __local int64_t *) local_mem_42887)[sext_i32_i64(local_tid_42880) - sext_i32_i64(skip_threads_42925)];\n                        }\n                    }\n                    // perform operation\n       ",
                                    "             {\n                        if (thread_active_42926) {\n                            int64_t defunc_0_op_res_42919 = add64(eta_p_42917, eta_p_42918);\n                            \n                            eta_p_42917 = defunc_0_op_res_42919;\n                        }\n                    }\n                    if (sle32(wave_sizze_42882, skip_threads_42925)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_42926) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_42887)[sext_i32_i64(local_tid_42880)] = eta_p_42917;\n                            eta_p_42918 = eta_p_42917;\n                        }\n                    }\n                    if (sle32(wave_sizze_42882, skip_threads_42925)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_42925 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_42880 - squot32(local_tid_42880, 32) * 32) == 31 && ltid_in_bounds_42924) {\n                    ((volatile __local int64_t *) local_mem_42887)[sext_i32_i64(squot32(local_tid_42880, 32))] = eta_p_42917;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_42927;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_42880, 32) == 0 && ltid_in_bounds_42924) {\n                        eta_p_42922 = ((volatile __local int64_t *) local_mem_42887)[sext_i32_i64(local_tid_42880)];\n                        if ((local_tid_42880 - squot32(local_tid_42880, 32) * 32) == 0) {\n                            e", "ta_p_42921 = eta_p_42922;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_42927 = 1;\n                    while (slt32(skip_threads_42927, 32)) {\n                        bool thread_active_42928 = sle32(skip_threads_42927, local_tid_42880 - squot32(local_tid_42880, 32) * 32) && (squot32(local_tid_42880, 32) == 0 && ltid_in_bounds_42924);\n                        \n                        if (thread_active_42928) {\n                            // read operands\n                            {\n                                eta_p_42921 = ((volatile __local int64_t *) local_mem_42887)[sext_i32_i64(local_tid_42880) - sext_i32_i64(skip_threads_42927)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_42928) {\n                                int64_t defunc_0_op_res_42923 = add64(eta_p_42921, eta_p_42922);\n                                \n                                eta_p_42921 = defunc_0_op_res_42923;\n                            }\n                        }\n                        if (sle32(wave_sizze_42882, skip_threads_42927)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_42928) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_42887)[sext_i32_i64(local_tid_42880)] = eta_p_42921;\n                                eta_p_42922 = eta_p_42921;\n                            }\n                        }\n                        if (sle32(wave_sizze_42882, skip_threads_42927)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_42927 *= 2;\n                    }\n                }\n        ", "    }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_42929 = squot32(local_tid_42880, 32) == 0 || !ltid_in_bounds_42924;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_42929) {\n                        eta_p_42918 = eta_p_42917;\n                        eta_p_42917 = ((__local int64_t *) local_mem_42887)[sext_i32_i64(squot32(local_tid_42880, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_42929) {\n                        int64_t defunc_0_op_res_42919 = add64(eta_p_42917, eta_p_42918);\n                        \n                        eta_p_42917 = defunc_0_op_res_42919;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_42929) {\n                        ((__local int64_t *) local_mem_42887)[sext_i32_i64(local_tid_42880)] = eta_p_42917;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_42880, 32) == 0 && ltid_in_bounds_42924) {\n                    ((__local int64_t *) local_mem_42887)[sext_i32_i64(local_tid_42880)] = eta_p_42918;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_42880 == 0) {\n                acc_42920 = ((__local int64_t *) local_mem_42887)[segscan_tblock_sizze_40814 - (int64_t) 1];\n            } else {\n                acc_42920 = ((__local int64_t *) local_mem_42887)[sext_i32_i64(local_tid_42880) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_42930 = (int64_t) 0;\n        block_new_sgm_42931 = sgm_idx_42899 == (int64_t) 0;\n",
                                    "        // Perform lookback\n        {\n            if (block_new_sgm_42931 && local_tid_42880 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_42855)[dynamic_id_42897] = acc_42920;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_42831)[dynamic_id_42897] = (int8_t) 2;\n                acc_42920 = (int64_t) 0;\n            }\n            if (!block_new_sgm_42931 && slt32(local_tid_42880, wave_sizze_42882)) {\n                if (local_tid_42880 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_42853)[dynamic_id_42897] = acc_42920;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_42831)[dynamic_id_42897] = (int8_t) 1;\n                    \n                    int8_t tmp_42932 = ((volatile __global int8_t *) status_flags_mem_42831)[dynamic_id_42897 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_42887)[(int64_t) 0] = tmp_42932;\n                }\n                mem_fence_local();\n                \n                int8_t status_42933 = ((__local int8_t *) local_mem_42887)[(int64_t) 0];\n                \n                if (status_42933 == (int8_t) 2) {\n                    if (local_tid_42880 == 0) {\n                        prefix_42930 = ((volatile __global int64_t *) incprefixes_mem_42855)[dynamic_id_42897 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_42934 = sext_i64_i32(dynamic_id_42897 - sext_i32_i64(wave_sizze_42882));\n                    \n                    while (slt32(wave_sizze_42882 * -1, readOffset_42934)) {\n                        int32_t read_i_42935 = readOffset_42934 + local_tid_42880;\n                        int64_t aggr_42936 = (int64_t) 0;\n                        int8_t flag_42937 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_42935)) {\n                            flag_4", "2937 = ((volatile __global int8_t *) status_flags_mem_42831)[sext_i32_i64(read_i_42935)];\n                            if (flag_42937 == (int8_t) 2) {\n                                aggr_42936 = ((volatile __global int64_t *) incprefixes_mem_42855)[sext_i32_i64(read_i_42935)];\n                            } else if (flag_42937 == (int8_t) 1) {\n                                aggr_42936 = ((volatile __global int64_t *) aggregates_mem_42853)[sext_i32_i64(read_i_42935)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_42887)[(int64_t) 4 + sext_i32_i64(local_tid_42880)] = aggr_42936;\n                        ((__local int8_t *) local_mem_42887)[sext_i32_i64(local_tid_42880)] = flag_42937;\n                        flag_42937 = ((__local int8_t *) local_mem_42887)[sext_i32_i64(wave_sizze_42882) - (int64_t) 1];\n                        if (slt8(flag_42937, (int8_t) 2)) {\n                            int8_t flg_x_42941;\n                            int8_t flg_y_42942;\n                            int64_t eta_p_42938;\n                            int64_t eta_p_42939;\n                            int32_t skip_threads_42943;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_42942 = ((volatile __local int8_t *) local_mem_42887)[sext_i32_i64(local_tid_42880)];\n                                eta_p_42939 = ((volatile __local int64_t *) local_mem_42887)[(int64_t) 4 + sext_i32_i64(local_tid_42880)];\n                                if ((local_tid_42880 - squot32(local_tid_42880, 32) * 32) == 0) {\n                                    eta_p_42938 = eta_p_42939;\n                                    flg_x_42941 = flg_y_42942;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_t", "hreads_42943 = 1;\n                                while (slt32(skip_threads_42943, 32)) {\n                                    if (sle32(skip_threads_42943, local_tid_42880 - squot32(local_tid_42880, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_42941 = ((volatile __local int8_t *) local_mem_42887)[sext_i32_i64(local_tid_42880) - sext_i32_i64(skip_threads_42943)];\n                                            eta_p_42938 = ((volatile __local int64_t *) local_mem_42887)[(int64_t) 4 + (sext_i32_i64(local_tid_42880) - sext_i32_i64(skip_threads_42943))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_42942 == (int8_t) 2 || flg_y_42942 == (int8_t) 0) {\n                                                flg_x_42941 = flg_y_42942;\n                                                eta_p_42938 = eta_p_42939;\n                                            } else {\n                                                int64_t defunc_0_op_res_42940 = add64(eta_p_42938, eta_p_42939);\n                                                \n                                                eta_p_42938 = defunc_0_op_res_42940;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_42887)[sext_i32_i64(local_tid_42880)] = flg_x_42941;\n                                            flg_y_42942 = flg_x_42941;\n                                            ((volatile __local int64_t *) local_mem_42887)[(int64_t) 4 + sext_i32_i64(local_tid_42880)] = eta_p_42938;\n                                            eta_p_42939 = eta_p_42938;\n              ",
                                    "                          }\n                                    }\n                                    skip_threads_42943 *= 2;\n                                }\n                            }\n                        }\n                        flag_42937 = ((__local int8_t *) local_mem_42887)[sext_i32_i64(wave_sizze_42882) - (int64_t) 1];\n                        aggr_42936 = ((__local int64_t *) local_mem_42887)[(int64_t) 4 + (sext_i32_i64(wave_sizze_42882) - (int64_t) 1)];\n                        if (flag_42937 == (int8_t) 2) {\n                            readOffset_42934 = wave_sizze_42882 * -1;\n                        } else if (flag_42937 == (int8_t) 1) {\n                            readOffset_42934 -= wave_sizze_42882;\n                        }\n                        if (slt8((int8_t) 0, flag_42937)) {\n                            int64_t eta_p_42944 = aggr_42936;\n                            int64_t eta_p_42945 = prefix_42930;\n                            int64_t defunc_0_op_res_42946 = add64(eta_p_42944, eta_p_42945);\n                            \n                            prefix_42930 = defunc_0_op_res_42946;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_42880 == 0) {\n                    if (boundary_42900 == sext_i64_i32(segscan_tblock_sizze_40814 * chunk_sizze_42828)) {\n                        int64_t eta_p_42947 = prefix_42930;\n                        int64_t eta_p_42948 = acc_42920;\n                        int64_t defunc_0_op_res_42949 = add64(eta_p_42947, eta_p_42948);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_42855)[dynamic_id_42897] = defunc_0_op_res_42949;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_42831)[dynamic_id_42897] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_42887)[(int64_t) 4] = prefix_42", "930;\n                    acc_42920 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_42897 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_42930 = ((__local int64_t *) local_mem_42887)[(int64_t) 4];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_42950;\n            int64_t eta_p_42951;\n            int64_t eta_p_42953 = prefix_42930;\n            int64_t eta_p_42954 = acc_42920;\n            \n            if (slt32(local_tid_42880 * chunk_sizze_32b_42884, boundary_42900) && !block_new_sgm_42931) {\n                int64_t defunc_0_op_res_42955 = add64(eta_p_42953, eta_p_42954);\n                \n                eta_p_42950 = defunc_0_op_res_42955;\n            } else {\n                eta_p_42950 = acc_42920;\n            }\n            \n            int32_t stopping_point_42956 = segsizze_compact_42901 - srem32(local_tid_42880 * chunk_sizze_32b_42884 - 1 + segsizze_compact_42901 - boundary_42900, segsizze_compact_42901);\n            \n            for (int64_t i_42957 = 0; i_42957 < chunk_sizze_42828; i_42957++) {\n                if (slt32(sext_i64_i32(i_42957), stopping_point_42956 - 1)) {\n                    eta_p_42951 = private_mem_42902[i_42957];\n                    \n                    int64_t defunc_0_op_res_42952 = add64(eta_p_42950, eta_p_42951);\n                    \n                    private_mem_42902[i_42957] = defunc_0_op_res_42952;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_42958 = 0; i_42958 < chunk_sizze_42828; i_42958++) {\n                int64_t sharedIdx_42959 = sext_i32_i64(local_tid_42880) * chunk_sizze_42828 + i_42958;\n                int64_t tmp_42960 = private_mem_42902[i_42958];\n                \n                ((__local int64_t *) local_mem_42887)[sharedIdx_42959] = tmp_42960;\n    ", "        }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_42961 = 0; i_42961 < chunk_sizze_42828; i_42961++) {\n                int64_t flat_idx_42962 = thd_offset_42904 + i_42961 * segscan_tblock_sizze_40814;\n                int64_t slice_42963 = nR_29939;\n                int64_t gtid_40818 = flat_idx_42962;\n                int64_t remnant_42964 = flat_idx_42962 - gtid_40818;\n                \n                if (slt64(flat_idx_42962, nR_29939)) {\n                    int64_t tmp_42965 = ((__local int64_t *) local_mem_42887)[flat_idx_42962 - block_offset_42898];\n                    \n                    ((__global int64_t *) mem_42373)[gtid_40818] = tmp_42965;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_40814\n    #undef chunk_sizze_42828\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_longzisegscan_40835_dim1, 1, 1)\nvoid inner_SMJ_longzisegscan_40835(__global int *global_failure, int64_t m_39200, int64_t num_tblocks_40832, int64_t num_virt_blocks_42986, int64_t num_virt_threads_42987, __global unsigned char *mem_42377, __global unsigned char *mem_42387, __global unsigned char *mem_42389, __global unsigned char *mem_42391, __global unsigned char *status_flags_mem_42988, __global unsigned char *aggregates_mem_42990, __global unsigned char *incprefixes_mem_42992, __global unsigned char *aggregates_mem_42994, __global unsigned char *incprefixes_mem_42996, __global unsigned char *global_dynid_mem_42998)\n{\n    #define segscan_tblock_sizze_40830 (inner_SMJ_longzisegscan_40835zisegscan_tblock_sizze_40830)\n    #define chunk_sizze_42985 (inner_SMJ_longzisegscan_40835zichunk_sizze_42985)\n    \n    volatile __local unsigned char *local_mem_43010_backing_0 = &shared_mem[0];\n    const int64_t local_mem_43010_backing_0_offset = 0 + (smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_40830, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze",
                                    "_40830), smax64(chunk_sizze_42985 * segscan_tblock_sizze_40830 * (int64_t) 8, chunk_sizze_42985 * segscan_tblock_sizze_40830 * (int64_t) 8)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_40830, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_40830), smax64(chunk_sizze_42985 * segscan_tblock_sizze_40830 * (int64_t) 8, chunk_sizze_42985 * segscan_tblock_sizze_40830 * (int64_t) 8)), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43001;\n    int32_t tblock_sizze_43004;\n    int32_t wave_sizze_43003;\n    int32_t block_id_43002;\n    int32_t global_tid_43000;\n    int64_t phys_tid_40835;\n    int32_t chunk_sizze_32b_43005;\n    int64_t byte_offsets_43006;\n    int64_t byte_offsets_43007;\n    int64_t warp_byte_offset_43008;\n    int64_t warp_byte_offset_43009;\n    __local unsigned char *local_mem_43010;\n    int64_t trans_arr_len_43011;\n    int64_t phys_block_id_43020;\n    int64_t virtloop_bound_43021;\n    \n    local_tid_43001 = get_local_id(0);\n    tblock_sizze_43004 = get_local_size(0);\n    wave_sizze_43003 = LOCKSTEP_WIDTH;\n    block_id_43002 = get_tblock_id(0);\n    global_tid_43000 = block_id_43002 * tblock_sizze_43004 + local_tid_43001;\n    phys_tid_40835 = sext_i32_i64(global_tid_43000);\n    chunk_sizze_32b_43005 = sext_i64_i32(chunk_sizze_42985);\n    byte_offsets_43006 = segscan_tblock_sizze_40830 * (int64_t) 8;\n    byte_offsets_43007 = sdiv_up64(byte_offsets_43006, (int64_t) 8) * (int64_t) 8 + segscan_tblock_sizze_40830 * (int64_t) 8;\n    warp_byte_offset_43008 = (int64_t) 288;\n    warp_byte_offset_43009 = sdiv_up64(warp_byte_offset_43008, (int64_t) 8) * (int64_t) 8 + (int64_t) 256;\n    // Allocate reusable shared memory\n    { }\n    local_mem_43010 = (__local unsigned char *) local_mem_43010_backing_0;\n    trans_arr_len_43011 = chunk_sizze_42985 * segscan_tblock_sizze_40830;\n    phys_block_id_43020 = get_tblock_id(0);\n    virtloop_bound_43021", " = sdiv_up64(num_virt_blocks_42986 - phys_block_id_43020, num_tblocks_40832);\n    for (int64_t virtloop_i_43022 = 0; virtloop_i_43022 < virtloop_bound_43021; virtloop_i_43022++) {\n        int64_t dynamic_id_43023;\n        int64_t block_offset_43024;\n        int64_t sgm_idx_43025;\n        int32_t boundary_43026;\n        int32_t segsizze_compact_43027;\n        int64_t private_mem_43028[chunk_sizze_42985];\n        int64_t private_mem_43030[chunk_sizze_42985];\n        int64_t thd_offset_43032;\n        int64_t acc_43058;\n        int64_t acc_43059;\n        int64_t prefix_43072;\n        int64_t prefix_43073;\n        bool block_new_sgm_43074;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_43001 == 0) {\n                dynamic_id_43023 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_42998)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_43010)[(int64_t) 0] = dynamic_id_43023;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_43023 == num_virt_blocks_42986 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_42998)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_43023 = ((__local int32_t *) local_mem_43010)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_43024 = dynamic_id_43023 * chunk_sizze_42985 * segscan_tblock_sizze_40830;\n        sgm_idx_43025 = smod64(block_offset_43024, m_39200);\n        boundary_43026 = sext_i64_i32(smin64(chunk_sizze_42985 * segscan_tblock_sizze_40830, m_39200 - sgm_idx_43025));\n        segsizze_compact_43027 = sext_i64_i32(smin64(chunk_sizze_42985 * segscan_tblock_sizze_40830, m_39200));\n        thd_offset_43032 = block_offset_43024 ", "+ sext_i32_i64(local_tid_43001);\n        // Load and map\n        {\n            for (int64_t i_43033 = 0; i_43033 < chunk_sizze_42985; i_43033++) {\n                int64_t virt_tid_43034 = thd_offset_43032 + i_43033 * segscan_tblock_sizze_40830;\n                int64_t slice_43035 = m_39200;\n                int64_t gtid_40834 = virt_tid_43034;\n                int64_t remnant_43036 = virt_tid_43034 - gtid_40834;\n                \n                if (slt64(virt_tid_43034, m_39200)) {\n                    int64_t x_39463 = ((__global int64_t *) mem_42377)[gtid_40834];\n                    bool lifted_lambda_res_39465 = slt64((int64_t) 1, x_39463);\n                    int64_t defunc_0_f_res_39466 = btoi_bool_i64(lifted_lambda_res_39465);\n                    \n                    ((__global int64_t *) mem_42391)[gtid_40834] = defunc_0_f_res_39466;\n                    private_mem_43028[i_43033] = x_39463;\n                    private_mem_43030[i_43033] = defunc_0_f_res_39466;\n                } else {\n                    private_mem_43028[i_43033] = (int64_t) 0;\n                    private_mem_43030[i_43033] = (int64_t) 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_43037 = 0; i_43037 < chunk_sizze_42985; i_43037++) {\n                int64_t sharedIdx_43038 = sext_i32_i64(local_tid_43001) + i_43037 * segscan_tblock_sizze_40830;\n                int64_t tmp_43039 = private_mem_43028[i_43037];\n                \n                ((__local int64_t *) local_mem_43010)[sharedIdx_43038] = tmp_43039;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_43040 = 0; i_43040 < chunk_sizze_42985; i_43040++) {\n                int64_t sharedIdx_43041 = sext_i32_i64(local_tid_43001) * chunk_sizze_42985 + i_43040;\n                int64_t tmp_43042 = ((__local int64_t *) local_mem_43010)[sharedIdx_43041];\n                \n                private_mem_43028[i_43040] =",
                                    " tmp_43042;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_43043 = 0; i_43043 < chunk_sizze_42985; i_43043++) {\n                int64_t sharedIdx_43044 = sext_i32_i64(local_tid_43001) + i_43043 * segscan_tblock_sizze_40830;\n                int64_t tmp_43045 = private_mem_43030[i_43043];\n                \n                ((__local int64_t *) local_mem_43010)[sharedIdx_43044] = tmp_43045;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_43046 = 0; i_43046 < chunk_sizze_42985; i_43046++) {\n                int64_t sharedIdx_43047 = sext_i32_i64(local_tid_43001) * chunk_sizze_42985 + i_43046;\n                int64_t tmp_43048 = ((__local int64_t *) local_mem_43010)[sharedIdx_43047];\n                \n                private_mem_43030[i_43046] = tmp_43048;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_43049 = 0; i_43049 < chunk_sizze_42985 - (int64_t) 1; i_43049++) {\n                int64_t eta_p_39237;\n                int64_t eta_p_39238;\n                \n                eta_p_39237 = private_mem_43028[i_43049];\n                eta_p_39238 = private_mem_43028[i_43049 + (int64_t) 1];\n                \n                int64_t eta_p_39330;\n                int64_t eta_p_39331;\n                \n                eta_p_39330 = private_mem_43030[i_43049];\n                eta_p_39331 = private_mem_43030[i_43049 + (int64_t) 1];\n                \n                int64_t lifted_lambda_res_39239 = add64(eta_p_39237, eta_p_39238);\n                int64_t defunc_0_op_res_39332 = add64(eta_p_39330, eta_p_39331);\n                \n                private_mem_43028[i_43049 + (int64_t) 1] = lifted_lambda_res_39239;\n                private_mem_43030[i_43049 + (int64_t) 1] = defunc_0_op_res_39332;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_43050 = private_mem_43028[chunk_sizze_42985 - (in", "t64_t) 1];\n            \n            ((__local int64_t *) local_mem_43010)[sext_i32_i64(local_tid_43001)] = tmp_43050;\n            \n            int64_t tmp_43051 = private_mem_43030[chunk_sizze_42985 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_43010)[squot64(byte_offsets_43006, (int64_t) 8) + sext_i32_i64(local_tid_43001)] = tmp_43051;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_43052;\n            int64_t eta_p_43053;\n            int64_t eta_p_43054;\n            int64_t eta_p_43055;\n            int64_t eta_p_43060;\n            int64_t eta_p_43061;\n            int64_t eta_p_43062;\n            int64_t eta_p_43063;\n            bool ltid_in_bounds_43066 = slt64(sext_i32_i64(local_tid_43001), num_virt_threads_42987);\n            int32_t skip_threads_43067;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_43066) {\n                    eta_p_43054 = ((volatile __local int64_t *) local_mem_43010)[sext_i32_i64(local_tid_43001)];\n                    eta_p_43055 = ((volatile __local int64_t *) local_mem_43010)[squot64(byte_offsets_43006, (int64_t) 8) + sext_i32_i64(local_tid_43001)];\n                    if ((local_tid_43001 - squot32(local_tid_43001, 32) * 32) == 0) {\n                        eta_p_43052 = eta_p_43054;\n                        eta_p_43053 = eta_p_43055;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_43067 = 1;\n                while (slt32(skip_threads_43067, 32)) {\n                    bool thread_active_43068 = sle32(skip_threads_43067, local_tid_43001 - squot32(local_tid_43001, 32) * 32) && ltid_in_bounds_43066;\n                    \n                    if (thread_active_43068) {\n                        // read operands\n                        {\n                            eta_p_43052 = ((", "volatile __local int64_t *) local_mem_43010)[sext_i32_i64(local_tid_43001) - sext_i32_i64(skip_threads_43067)];\n                            eta_p_43053 = ((volatile __local int64_t *) local_mem_43010)[squot64(byte_offsets_43006, (int64_t) 8) + (sext_i32_i64(local_tid_43001) - sext_i32_i64(skip_threads_43067))];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_43068) {\n                            int64_t lifted_lambda_res_43056 = add64(eta_p_43052, eta_p_43054);\n                            int64_t defunc_0_op_res_43057 = add64(eta_p_43053, eta_p_43055);\n                            \n                            eta_p_43052 = lifted_lambda_res_43056;\n                            eta_p_43053 = defunc_0_op_res_43057;\n                        }\n                    }\n                    if (sle32(wave_sizze_43003, skip_threads_43067)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_43068) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_43010)[sext_i32_i64(local_tid_43001)] = eta_p_43052;\n                            eta_p_43054 = eta_p_43052;\n                            ((volatile __local int64_t *) local_mem_43010)[squot64(byte_offsets_43006, (int64_t) 8) + sext_i32_i64(local_tid_43001)] = eta_p_43053;\n                            eta_p_43055 = eta_p_43053;\n                        }\n                    }\n                    if (sle32(wave_sizze_43003, skip_threads_43067)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_43067 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_43001 - squot32(local_tid_43001, 32) * 32)",
                                    " == 31 && ltid_in_bounds_43066) {\n                    ((volatile __local int64_t *) local_mem_43010)[sext_i32_i64(squot32(local_tid_43001, 32))] = eta_p_43052;\n                    ((volatile __local int64_t *) local_mem_43010)[squot64(byte_offsets_43006, (int64_t) 8) + sext_i32_i64(squot32(local_tid_43001, 32))] = eta_p_43053;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_43069;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_43001, 32) == 0 && ltid_in_bounds_43066) {\n                        eta_p_43062 = ((volatile __local int64_t *) local_mem_43010)[sext_i32_i64(local_tid_43001)];\n                        eta_p_43063 = ((volatile __local int64_t *) local_mem_43010)[squot64(byte_offsets_43006, (int64_t) 8) + sext_i32_i64(local_tid_43001)];\n                        if ((local_tid_43001 - squot32(local_tid_43001, 32) * 32) == 0) {\n                            eta_p_43060 = eta_p_43062;\n                            eta_p_43061 = eta_p_43063;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_43069 = 1;\n                    while (slt32(skip_threads_43069, 32)) {\n                        bool thread_active_43070 = sle32(skip_threads_43069, local_tid_43001 - squot32(local_tid_43001, 32) * 32) && (squot32(local_tid_43001, 32) == 0 && ltid_in_bounds_43066);\n                        \n                        if (thread_active_43070) {\n                            // read operands\n                            {\n                                eta_p_43060 = ((volatile __local int64_t *) local_mem_43010)[sext_i32_i64(local_tid_43001) - sext_i32_i64(skip_threads_43069)];\n                                eta_p_43061", " = ((volatile __local int64_t *) local_mem_43010)[squot64(byte_offsets_43006, (int64_t) 8) + (sext_i32_i64(local_tid_43001) - sext_i32_i64(skip_threads_43069))];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_43070) {\n                                int64_t lifted_lambda_res_43064 = add64(eta_p_43060, eta_p_43062);\n                                int64_t defunc_0_op_res_43065 = add64(eta_p_43061, eta_p_43063);\n                                \n                                eta_p_43060 = lifted_lambda_res_43064;\n                                eta_p_43061 = defunc_0_op_res_43065;\n                            }\n                        }\n                        if (sle32(wave_sizze_43003, skip_threads_43069)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_43070) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_43010)[sext_i32_i64(local_tid_43001)] = eta_p_43060;\n                                eta_p_43062 = eta_p_43060;\n                                ((volatile __local int64_t *) local_mem_43010)[squot64(byte_offsets_43006, (int64_t) 8) + sext_i32_i64(local_tid_43001)] = eta_p_43061;\n                                eta_p_43063 = eta_p_43061;\n                            }\n                        }\n                        if (sle32(wave_sizze_43003, skip_threads_43069)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_43069 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_43071 = squot32(local_tid_43001, 32) == 0 || !ltid_in_bounds_43066;\n            \n            // carry-in for every block except the fi", "rst\n            {\n                // read operands\n                {\n                    if (!no_carry_in_43071) {\n                        eta_p_43054 = eta_p_43052;\n                        eta_p_43055 = eta_p_43053;\n                        eta_p_43052 = ((__local int64_t *) local_mem_43010)[sext_i32_i64(squot32(local_tid_43001, 32)) - (int64_t) 1];\n                        eta_p_43053 = ((__local int64_t *) local_mem_43010)[squot64(byte_offsets_43006, (int64_t) 8) + (sext_i32_i64(squot32(local_tid_43001, 32)) - (int64_t) 1)];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_43071) {\n                        int64_t lifted_lambda_res_43056 = add64(eta_p_43052, eta_p_43054);\n                        int64_t defunc_0_op_res_43057 = add64(eta_p_43053, eta_p_43055);\n                        \n                        eta_p_43052 = lifted_lambda_res_43056;\n                        eta_p_43053 = defunc_0_op_res_43057;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_43071) {\n                        ((__local int64_t *) local_mem_43010)[sext_i32_i64(local_tid_43001)] = eta_p_43052;\n                        ((__local int64_t *) local_mem_43010)[squot64(byte_offsets_43006, (int64_t) 8) + sext_i32_i64(local_tid_43001)] = eta_p_43053;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_43001, 32) == 0 && ltid_in_bounds_43066) {\n                    ((__local int64_t *) local_mem_43010)[sext_i32_i64(local_tid_43001)] = eta_p_43054;\n                    ((__local int64_t *) local_mem_43010)[squot64(byte_offsets_43006, (int64_t) 8) + sext_i32_i64(local_tid_43001)] = eta_p_43055;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOC",
                                    "AL_MEM_FENCE);\n            if (local_tid_43001 == 0) {\n                acc_43058 = ((__local int64_t *) local_mem_43010)[segscan_tblock_sizze_40830 - (int64_t) 1];\n                acc_43059 = ((__local int64_t *) local_mem_43010)[squot64(byte_offsets_43006, (int64_t) 8) + (segscan_tblock_sizze_40830 - (int64_t) 1)];\n            } else {\n                acc_43058 = ((__local int64_t *) local_mem_43010)[sext_i32_i64(local_tid_43001) - (int64_t) 1];\n                acc_43059 = ((__local int64_t *) local_mem_43010)[squot64(byte_offsets_43006, (int64_t) 8) + (sext_i32_i64(local_tid_43001) - (int64_t) 1)];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_43072 = (int64_t) 0;\n        prefix_43073 = (int64_t) 0;\n        block_new_sgm_43074 = sgm_idx_43025 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_43074 && local_tid_43001 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_42992)[dynamic_id_43023] = acc_43058;\n                ((volatile __global int64_t *) incprefixes_mem_42996)[dynamic_id_43023] = acc_43059;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_42988)[dynamic_id_43023] = (int8_t) 2;\n                acc_43058 = (int64_t) 0;\n                acc_43059 = (int64_t) 0;\n            }\n            if (!block_new_sgm_43074 && slt32(local_tid_43001, wave_sizze_43003)) {\n                if (local_tid_43001 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_42990)[dynamic_id_43023] = acc_43058;\n                    ((volatile __global int64_t *) aggregates_mem_42994)[dynamic_id_43023] = acc_43059;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_42988)[dynamic_id_43023] = (int8_t) 1;\n                    \n                    int8_t tmp_43075 = ((volatile __global int8_t *) status_flags_mem_42988)[dynamic_id_43023 - (int64_t) 1];\n                    \n       ", "             ((volatile __local int8_t *) local_mem_43010)[(int64_t) 0] = tmp_43075;\n                }\n                mem_fence_local();\n                \n                int8_t status_43076 = ((__local int8_t *) local_mem_43010)[(int64_t) 0];\n                \n                if (status_43076 == (int8_t) 2) {\n                    if (local_tid_43001 == 0) {\n                        prefix_43072 = ((volatile __global int64_t *) incprefixes_mem_42992)[dynamic_id_43023 - (int64_t) 1];\n                        prefix_43073 = ((volatile __global int64_t *) incprefixes_mem_42996)[dynamic_id_43023 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_43077 = sext_i64_i32(dynamic_id_43023 - sext_i32_i64(wave_sizze_43003));\n                    \n                    while (slt32(wave_sizze_43003 * -1, readOffset_43077)) {\n                        int32_t read_i_43078 = readOffset_43077 + local_tid_43001;\n                        int64_t aggr_43079 = (int64_t) 0;\n                        int64_t aggr_43080 = (int64_t) 0;\n                        int8_t flag_43081 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_43078)) {\n                            flag_43081 = ((volatile __global int8_t *) status_flags_mem_42988)[sext_i32_i64(read_i_43078)];\n                            if (flag_43081 == (int8_t) 2) {\n                                aggr_43079 = ((volatile __global int64_t *) incprefixes_mem_42992)[sext_i32_i64(read_i_43078)];\n                                aggr_43080 = ((volatile __global int64_t *) incprefixes_mem_42996)[sext_i32_i64(read_i_43078)];\n                            } else if (flag_43081 == (int8_t) 1) {\n                                aggr_43079 = ((volatile __global int64_t *) aggregates_mem_42990)[sext_i32_i64(read_i_43078)];\n                                aggr_43080 = ((volatile __global int64_t *) aggregates_mem_42994)[sext_i32_i64(read_i_43078)];\n                            }\n       ", "                 }\n                        ((__local int64_t *) local_mem_43010)[(int64_t) 4 + sext_i32_i64(local_tid_43001)] = aggr_43079;\n                        ((__local int64_t *) local_mem_43010)[squot64(warp_byte_offset_43008, (int64_t) 8) + sext_i32_i64(local_tid_43001)] = aggr_43080;\n                        ((__local int8_t *) local_mem_43010)[sext_i32_i64(local_tid_43001)] = flag_43081;\n                        flag_43081 = ((__local int8_t *) local_mem_43010)[sext_i32_i64(wave_sizze_43003) - (int64_t) 1];\n                        if (slt8(flag_43081, (int8_t) 2)) {\n                            int8_t flg_x_43088;\n                            int8_t flg_y_43089;\n                            int64_t eta_p_43082;\n                            int64_t eta_p_43083;\n                            int64_t eta_p_43084;\n                            int64_t eta_p_43085;\n                            int32_t skip_threads_43090;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_43089 = ((volatile __local int8_t *) local_mem_43010)[sext_i32_i64(local_tid_43001)];\n                                eta_p_43084 = ((volatile __local int64_t *) local_mem_43010)[(int64_t) 4 + sext_i32_i64(local_tid_43001)];\n                                eta_p_43085 = ((volatile __local int64_t *) local_mem_43010)[squot64(warp_byte_offset_43008, (int64_t) 8) + sext_i32_i64(local_tid_43001)];\n                                if ((local_tid_43001 - squot32(local_tid_43001, 32) * 32) == 0) {\n                                    eta_p_43082 = eta_p_43084;\n                                    eta_p_43083 = eta_p_43085;\n                                    flg_x_43088 = flg_y_43089;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_43090 = 1;\n    ",
                                    "                            while (slt32(skip_threads_43090, 32)) {\n                                    if (sle32(skip_threads_43090, local_tid_43001 - squot32(local_tid_43001, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_43088 = ((volatile __local int8_t *) local_mem_43010)[sext_i32_i64(local_tid_43001) - sext_i32_i64(skip_threads_43090)];\n                                            eta_p_43082 = ((volatile __local int64_t *) local_mem_43010)[(int64_t) 4 + (sext_i32_i64(local_tid_43001) - sext_i32_i64(skip_threads_43090))];\n                                            eta_p_43083 = ((volatile __local int64_t *) local_mem_43010)[squot64(warp_byte_offset_43008, (int64_t) 8) + (sext_i32_i64(local_tid_43001) - sext_i32_i64(skip_threads_43090))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_43089 == (int8_t) 2 || flg_y_43089 == (int8_t) 0) {\n                                                flg_x_43088 = flg_y_43089;\n                                                eta_p_43082 = eta_p_43084;\n                                                eta_p_43083 = eta_p_43085;\n                                            } else {\n                                                int64_t lifted_lambda_res_43086 = add64(eta_p_43082, eta_p_43084);\n                                                int64_t defunc_0_op_res_43087 = add64(eta_p_43083, eta_p_43085);\n                                                \n                                                eta_p_43082 = lifted_lambda_res_43086;\n                                                eta_p_43083 = defunc_0_op_res_43087;\n                                            }\n                                        }\n                                        // write result\n         ", "                               {\n                                            ((volatile __local int8_t *) local_mem_43010)[sext_i32_i64(local_tid_43001)] = flg_x_43088;\n                                            flg_y_43089 = flg_x_43088;\n                                            ((volatile __local int64_t *) local_mem_43010)[(int64_t) 4 + sext_i32_i64(local_tid_43001)] = eta_p_43082;\n                                            eta_p_43084 = eta_p_43082;\n                                            ((volatile __local int64_t *) local_mem_43010)[squot64(warp_byte_offset_43008, (int64_t) 8) + sext_i32_i64(local_tid_43001)] = eta_p_43083;\n                                            eta_p_43085 = eta_p_43083;\n                                        }\n                                    }\n                                    skip_threads_43090 *= 2;\n                                }\n                            }\n                        }\n                        flag_43081 = ((__local int8_t *) local_mem_43010)[sext_i32_i64(wave_sizze_43003) - (int64_t) 1];\n                        aggr_43079 = ((__local int64_t *) local_mem_43010)[(int64_t) 4 + (sext_i32_i64(wave_sizze_43003) - (int64_t) 1)];\n                        aggr_43080 = ((__local int64_t *) local_mem_43010)[squot64(warp_byte_offset_43008, (int64_t) 8) + (sext_i32_i64(wave_sizze_43003) - (int64_t) 1)];\n                        if (flag_43081 == (int8_t) 2) {\n                            readOffset_43077 = wave_sizze_43003 * -1;\n                        } else if (flag_43081 == (int8_t) 1) {\n                            readOffset_43077 -= wave_sizze_43003;\n                        }\n                        if (slt8((int8_t) 0, flag_43081)) {\n                            int64_t eta_p_43091 = aggr_43079;\n                            int64_t eta_p_43092 = aggr_43080;\n                            int64_t eta_p_43093 = prefix_43072;\n                            int64_t eta_p_43094 = prefix_43073;\n                            i", "nt64_t lifted_lambda_res_43095 = add64(eta_p_43091, eta_p_43093);\n                            int64_t defunc_0_op_res_43096 = add64(eta_p_43092, eta_p_43094);\n                            \n                            prefix_43072 = lifted_lambda_res_43095;\n                            prefix_43073 = defunc_0_op_res_43096;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_43001 == 0) {\n                    if (boundary_43026 == sext_i64_i32(segscan_tblock_sizze_40830 * chunk_sizze_42985)) {\n                        int64_t eta_p_43097 = prefix_43072;\n                        int64_t eta_p_43098 = prefix_43073;\n                        int64_t eta_p_43099 = acc_43058;\n                        int64_t eta_p_43100 = acc_43059;\n                        int64_t lifted_lambda_res_43101 = add64(eta_p_43097, eta_p_43099);\n                        int64_t defunc_0_op_res_43102 = add64(eta_p_43098, eta_p_43100);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_42992)[dynamic_id_43023] = lifted_lambda_res_43101;\n                        ((volatile __global int64_t *) incprefixes_mem_42996)[dynamic_id_43023] = defunc_0_op_res_43102;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_42988)[dynamic_id_43023] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_43010)[(int64_t) 4] = prefix_43072;\n                    ((__local int64_t *) local_mem_43010)[squot64(warp_byte_offset_43008, (int64_t) 8)] = prefix_43073;\n                    acc_43058 = (int64_t) 0;\n                    acc_43059 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_43023 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_43072 = ((__local int64_t *) local_mem_43010)[(int64_t) 4];\n                prefix_43073 = ((__local int64_t",
                                    " *) local_mem_43010)[squot64(warp_byte_offset_43008, (int64_t) 8)];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_43103;\n            int64_t eta_p_43105;\n            int64_t eta_p_43109 = prefix_43072;\n            int64_t eta_p_43111 = acc_43058;\n            int64_t eta_p_43104;\n            int64_t eta_p_43106;\n            int64_t eta_p_43110 = prefix_43073;\n            int64_t eta_p_43112 = acc_43059;\n            \n            if (slt32(local_tid_43001 * chunk_sizze_32b_43005, boundary_43026) && !block_new_sgm_43074) {\n                int64_t lifted_lambda_res_43113 = add64(eta_p_43109, eta_p_43111);\n                int64_t defunc_0_op_res_43114 = add64(eta_p_43110, eta_p_43112);\n                \n                eta_p_43103 = lifted_lambda_res_43113;\n                eta_p_43104 = defunc_0_op_res_43114;\n            } else {\n                eta_p_43103 = acc_43058;\n                eta_p_43104 = acc_43059;\n            }\n            \n            int32_t stopping_point_43115 = segsizze_compact_43027 - srem32(local_tid_43001 * chunk_sizze_32b_43005 - 1 + segsizze_compact_43027 - boundary_43026, segsizze_compact_43027);\n            \n            for (int64_t i_43116 = 0; i_43116 < chunk_sizze_42985; i_43116++) {\n                if (slt32(sext_i64_i32(i_43116), stopping_point_43115 - 1)) {\n                    eta_p_43105 = private_mem_43028[i_43116];\n                    eta_p_43106 = private_mem_43030[i_43116];\n                    \n                    int64_t lifted_lambda_res_43107 = add64(eta_p_43103, eta_p_43105);\n                    int64_t defunc_0_op_res_43108 = add64(eta_p_43104, eta_p_43106);\n                    \n                    private_mem_43028[i_43116] = lifted_lambda_res_43107;\n                    private_mem_43030[i_43116] = defunc_0_op_res_43108;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashio", "n\n        {\n            for (int64_t i_43117 = 0; i_43117 < chunk_sizze_42985; i_43117++) {\n                int64_t sharedIdx_43118 = sext_i32_i64(local_tid_43001) * chunk_sizze_42985 + i_43117;\n                int64_t tmp_43119 = private_mem_43028[i_43117];\n                \n                ((__local int64_t *) local_mem_43010)[sharedIdx_43118] = tmp_43119;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_43120 = 0; i_43120 < chunk_sizze_42985; i_43120++) {\n                int64_t flat_idx_43121 = thd_offset_43032 + i_43120 * segscan_tblock_sizze_40830;\n                int64_t slice_43122 = m_39200;\n                int64_t gtid_40834 = flat_idx_43121;\n                int64_t remnant_43123 = flat_idx_43121 - gtid_40834;\n                \n                if (slt64(flat_idx_43121, m_39200)) {\n                    int64_t tmp_43124 = ((__local int64_t *) local_mem_43010)[flat_idx_43121 - block_offset_43024];\n                    \n                    ((__global int64_t *) mem_42387)[gtid_40834] = tmp_43124;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_43125 = 0; i_43125 < chunk_sizze_42985; i_43125++) {\n                int64_t sharedIdx_43126 = sext_i32_i64(local_tid_43001) * chunk_sizze_42985 + i_43125;\n                int64_t tmp_43127 = private_mem_43030[i_43125];\n                \n                ((__local int64_t *) local_mem_43010)[sharedIdx_43126] = tmp_43127;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_43128 = 0; i_43128 < chunk_sizze_42985; i_43128++) {\n                int64_t flat_idx_43129 = thd_offset_43032 + i_43128 * segscan_tblock_sizze_40830;\n                int64_t slice_43130 = m_39200;\n                int64_t gtid_40834 = flat_idx_43129;\n                int64_t remnant_43131 = flat_idx_43129 - gtid_40834;\n                \n                if (slt64(flat_idx_43129, m_39200)) {\n                    int64_t tmp_43132 = ((__local int64", "_t *) local_mem_43010)[flat_idx_43129 - block_offset_43024];\n                    \n                    ((__global int64_t *) mem_42389)[gtid_40834] = tmp_43132;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_40830\n    #undef chunk_sizze_42985\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_shortzigpuseq_42730_dim1, 1, 1)\nvoid inner_SMJ_shortzigpuseq_42730(__global int *global_failure, __global unsigned char *tS_mem_42200, __global unsigned char *mem_42207)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42732;\n    int32_t tblock_sizze_42735;\n    int32_t wave_sizze_42734;\n    int32_t block_id_42733;\n    int32_t global_tid_42731;\n    int64_t tid_42730;\n    int16_t x_42152;\n    \n    local_tid_42732 = get_local_id(0);\n    tblock_sizze_42735 = get_local_size(0);\n    wave_sizze_42734 = LOCKSTEP_WIDTH;\n    block_id_42733 = get_tblock_id(0);\n    global_tid_42731 = block_id_42733 * tblock_sizze_42735 + local_tid_42732;\n    tid_42730 = sext_i32_i64(global_tid_42731);\n    x_42152 = ((__global int16_t *) tS_mem_42200)[(int64_t) 0];\n    ((__global int16_t *) mem_42207)[(int64_t) 0] = x_42152;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_shortzigpuseq_42756_dim1, 1, 1)\nvoid inner_SMJ_shortzigpuseq_42756(__global int *global_failure, int64_t tmp_39078, __global unsigned char *tS_mem_42200, __global unsigned char *mem_42210)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42758;\n    int32_t tblock_sizze_42761;\n    int32_t wave_sizze_42760;\n    int32_t block_id_42759;\n    int32_t global_tid_42757;\n    int64_t tid_42756;\n    int16_t x_42156;\n    \n    local_tid_42758 = get_local_id(0);\n    tblock_sizze_42761 = get_local_size(0);\n    wave_sizze_42760 = LOCKSTEP_WIDTH;\n    block_id_42759 = get_tblock_id(0);\n    global_tid_42757 = block_id_42759 * tblock_sizze_42761 + local_tid_42758;\n    tid_42756 = sext_i32_i64(global_tid_42757);\n ",
                                    "   x_42156 = ((__global int16_t *) tS_mem_42200)[tmp_39078];\n    ((__global int16_t *) mem_42210)[(int64_t) 0] = x_42156;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_shortzigpuseq_42772_dim1, 1, 1)\nvoid inner_SMJ_shortzigpuseq_42772(__global int *global_failure, int64_t start_39100, int64_t i_p_m_t_s_39106, __global unsigned char *tR_mem_42199, __global unsigned char *mem_42218, __global unsigned char *mem_42219)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42774;\n    int32_t tblock_sizze_42777;\n    int32_t wave_sizze_42776;\n    int32_t block_id_42775;\n    int32_t global_tid_42773;\n    int64_t tid_42772;\n    int16_t r_max_42160;\n    int16_t r_min_42163;\n    \n    local_tid_42774 = get_local_id(0);\n    tblock_sizze_42777 = get_local_size(0);\n    wave_sizze_42776 = LOCKSTEP_WIDTH;\n    block_id_42775 = get_tblock_id(0);\n    global_tid_42773 = block_id_42775 * tblock_sizze_42777 + local_tid_42774;\n    tid_42772 = sext_i32_i64(global_tid_42773);\n    r_max_42160 = ((__global int16_t *) tR_mem_42199)[i_p_m_t_s_39106];\n    r_min_42163 = ((__global int16_t *) tR_mem_42199)[start_39100];\n    ((__global int16_t *) mem_42218)[(int64_t) 0] = r_max_42160;\n    ((__global int16_t *) mem_42219)[(int64_t) 0] = r_min_42163;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_shortzigpuseq_42778_dim1, 1, 1)\nvoid inner_SMJ_shortzigpuseq_42778(__global int *global_failure, __global unsigned char *mem_42219, __global unsigned char *ext_mem_42220, __global unsigned char *mem_42222)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42780;\n    int32_t tblock_sizze_42783;\n    int32_t wave_sizze_42782;\n    int32_t block_id_42781;\n    int32_t global_tid_42779;\n    int64_t tid_42778;\n    int16_t s_max_42165;\n    int16_t r_min_42166;\n    bool defunc_0_gt_res_42167;\n    \n    local_tid_42780 = get_local_id(0);\n    tblock_sizze_42783 = get_local_size(0);\n    wave_sizze_42782 = LOCKSTEP_WIDTH;\n    block_id_42781 = get_tbl", "ock_id(0);\n    global_tid_42779 = block_id_42781 * tblock_sizze_42783 + local_tid_42780;\n    tid_42778 = sext_i32_i64(global_tid_42779);\n    s_max_42165 = ((__global int16_t *) ext_mem_42220)[(int64_t) 0];\n    r_min_42166 = ((__global int16_t *) mem_42219)[(int64_t) 0];\n    defunc_0_gt_res_42167 = slt16(s_max_42165, r_min_42166);\n    ((__global bool *) mem_42222)[(int64_t) 0] = defunc_0_gt_res_42167;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_shortzigpuseq_42784_dim1, 1, 1)\nvoid inner_SMJ_shortzigpuseq_42784(__global int *global_failure, __global unsigned char *mem_42218, __global unsigned char *ext_mem_42221, __global unsigned char *mem_42223)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42786;\n    int32_t tblock_sizze_42789;\n    int32_t wave_sizze_42788;\n    int32_t block_id_42787;\n    int32_t global_tid_42785;\n    int64_t tid_42784;\n    int16_t r_max_42170;\n    int16_t s_min_42171;\n    bool defunc_0_gt_res_42172;\n    \n    local_tid_42786 = get_local_id(0);\n    tblock_sizze_42789 = get_local_size(0);\n    wave_sizze_42788 = LOCKSTEP_WIDTH;\n    block_id_42787 = get_tblock_id(0);\n    global_tid_42785 = block_id_42787 * tblock_sizze_42789 + local_tid_42786;\n    tid_42784 = sext_i32_i64(global_tid_42785);\n    r_max_42170 = ((__global int16_t *) mem_42218)[(int64_t) 0];\n    s_min_42171 = ((__global int16_t *) ext_mem_42221)[(int64_t) 0];\n    defunc_0_gt_res_42172 = slt16(r_max_42170, s_min_42171);\n    ((__global bool *) mem_42223)[(int64_t) 0] = defunc_0_gt_res_42172;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_shortzigpuseq_43162_dim1, 1, 1)\nvoid inner_SMJ_shortzigpuseq_43162(__global int *global_failure, int64_t m_39210, __global unsigned char *mem_42394, __global unsigned char *mem_42396)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43164;\n    int32_t tblock_sizze_43167;\n    int32_t wave_sizze_43166;\n    int32_t block_id_43165;\n    int32_t global_tid_43163;\n    int64_t tid_", "43162;\n    int64_t x_42174;\n    \n    local_tid_43164 = get_local_id(0);\n    tblock_sizze_43167 = get_local_size(0);\n    wave_sizze_43166 = LOCKSTEP_WIDTH;\n    block_id_43165 = get_tblock_id(0);\n    global_tid_43163 = block_id_43165 * tblock_sizze_43167 + local_tid_43164;\n    tid_43162 = sext_i32_i64(global_tid_43163);\n    x_42174 = ((__global int64_t *) mem_42394)[m_39210];\n    ((__global int64_t *) mem_42396)[(int64_t) 0] = x_42174;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_shortzigpuseq_43168_dim1, 1, 1)\nvoid inner_SMJ_shortzigpuseq_43168(__global int *global_failure, int64_t m_39210, __global unsigned char *mem_42377, __global unsigned char *mem_42399)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43170;\n    int32_t tblock_sizze_43173;\n    int32_t wave_sizze_43172;\n    int32_t block_id_43171;\n    int32_t global_tid_43169;\n    int64_t tid_43168;\n    int64_t x_42178;\n    \n    local_tid_43170 = get_local_id(0);\n    tblock_sizze_43173 = get_local_size(0);\n    wave_sizze_43172 = LOCKSTEP_WIDTH;\n    block_id_43171 = get_tblock_id(0);\n    global_tid_43169 = block_id_43171 * tblock_sizze_43173 + local_tid_43170;\n    tid_43168 = sext_i32_i64(global_tid_43169);\n    x_42178 = ((__global int64_t *) mem_42377)[m_39210];\n    ((__global int64_t *) mem_42399)[(int64_t) 0] = x_42178;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_shortzigpuseq_43174_dim1, 1, 1)\nvoid inner_SMJ_shortzigpuseq_43174(__global int *global_failure, __global unsigned char *ext_mem_42397, __global unsigned char *ext_mem_42400, __global unsigned char *mem_42406)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43176;\n    int32_t tblock_sizze_43179;\n    int32_t wave_sizze_43178;\n    int32_t block_id_43177;\n    int32_t global_tid_43175;\n    int64_t tid_43174;\n    int64_t zp_lhs_42182;\n    int64_t n_pairs_t_res_42183;\n    int64_t n_pairs_t_res_42184;\n    \n    local_tid_43176 = get_local_id(0);\n    tblock_sizze_43179 = get_",
                                    "local_size(0);\n    wave_sizze_43178 = LOCKSTEP_WIDTH;\n    block_id_43177 = get_tblock_id(0);\n    global_tid_43175 = block_id_43177 * tblock_sizze_43179 + local_tid_43176;\n    tid_43174 = sext_i32_i64(global_tid_43175);\n    zp_lhs_42182 = ((__global int64_t *) ext_mem_42397)[(int64_t) 0];\n    n_pairs_t_res_42183 = ((__global int64_t *) ext_mem_42400)[(int64_t) 0];\n    n_pairs_t_res_42184 = add64(zp_lhs_42182, n_pairs_t_res_42183);\n    ((__global int64_t *) mem_42406)[(int64_t) 0] = n_pairs_t_res_42184;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_shortzigpuseq_43221_dim1, 1, 1)\nvoid inner_SMJ_shortzigpuseq_43221(__global int *global_failure, int64_t loopres_39384, __global unsigned char *mem_param_42440, __global unsigned char *mem_param_42443, __global unsigned char *mem_param_42446, __global unsigned char *mem_42453, __global unsigned char *mem_42454, __global unsigned char *mem_42455)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43223;\n    int32_t tblock_sizze_43226;\n    int32_t wave_sizze_43225;\n    int32_t block_id_43224;\n    int32_t global_tid_43222;\n    int64_t tid_43221;\n    int16_t loopres_42186;\n    int64_t loopres_42188;\n    int64_t loopres_42190;\n    \n    local_tid_43223 = get_local_id(0);\n    tblock_sizze_43226 = get_local_size(0);\n    wave_sizze_43225 = LOCKSTEP_WIDTH;\n    block_id_43224 = get_tblock_id(0);\n    global_tid_43222 = block_id_43224 * tblock_sizze_43226 + local_tid_43223;\n    tid_43221 = sext_i32_i64(global_tid_43222);\n    loopres_42186 = ((__global int16_t *) mem_param_42440)[loopres_39384];\n    loopres_42188 = ((__global int64_t *) mem_param_42443)[loopres_39384];\n    loopres_42190 = ((__global int64_t *) mem_param_42446)[loopres_39384];\n    ((__global int16_t *) mem_42453)[(int64_t) 0] = loopres_42186;\n    ((__global int64_t *) mem_42454)[(int64_t) 0] = loopres_42188;\n    ((__global int64_t *) mem_42455)[(int64_t) 0] = loopres_42190;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL\nvoid inner_SMJ_", "shortzireplicate_43228(int64_t loopres_39385, int64_t replicate_n_43227, int64_t virt_num_tblocks_43233, int64_t num_tblocks_43234, __global unsigned char *mem_42453, __global unsigned char *mem_42457)\n{\n    int32_t replicate_ltid_43229;\n    int32_t tblock_sizze_43231;\n    int32_t replicate_gid_43230;\n    int32_t replicate_gtid_43228;\n    int32_t phys_tblock_id_43235;\n    int32_t iterations_43236;\n    \n    replicate_ltid_43229 = get_local_id(0);\n    tblock_sizze_43231 = get_local_size(0);\n    replicate_gid_43230 = get_tblock_id(0);\n    replicate_gtid_43228 = replicate_gid_43230 * tblock_sizze_43231 + replicate_ltid_43229;\n    phys_tblock_id_43235 = get_tblock_id(0);\n    iterations_43236 = sdiv_up32(sext_i64_i32(virt_num_tblocks_43233) - phys_tblock_id_43235, sext_i64_i32(num_tblocks_43234));\n    for (int32_t i_43237 = 0; i_43237 < iterations_43236; i_43237++) {\n        int32_t virt_tblock_id_43238;\n        int64_t global_tid_43239;\n        int64_t slice_43242;\n        int64_t slice_43243;\n        int64_t rep_i_43240;\n        int64_t remnant_43244;\n        int64_t rep_i_43241;\n        int64_t remnant_43245;\n        \n        virt_tblock_id_43238 = phys_tblock_id_43235 + i_43237 * sext_i64_i32(num_tblocks_43234);\n        global_tid_43239 = sext_i32_i64(virt_tblock_id_43238) * sext_i32_i64(tblock_sizze_43231) + sext_i32_i64(replicate_ltid_43229);\n        slice_43242 = (int64_t) 1;\n        slice_43243 = loopres_39385 * slice_43242;\n        rep_i_43240 = squot64(global_tid_43239, slice_43242);\n        remnant_43244 = global_tid_43239 - rep_i_43240 * slice_43242;\n        rep_i_43241 = remnant_43244;\n        remnant_43245 = remnant_43244 - rep_i_43241;\n        if (slt64(global_tid_43239, replicate_n_43227)) {\n            int16_t tmp_43246 = ((__global int16_t *) mem_42453)[rep_i_43241];\n            \n            ((__global int16_t *) mem_42457)[rep_i_43240 + rep_i_43241] = tmp_43246;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:", "\n    return;\n}\nFUTHARK_KERNEL\nvoid inner_SMJ_shortzireplicate_43248(int64_t loopres_39385, int64_t replicate_n_43247, int64_t virt_num_tblocks_43253, int64_t num_tblocks_43254, __global unsigned char *mem_42454, __global unsigned char *mem_42459)\n{\n    int32_t replicate_ltid_43249;\n    int32_t tblock_sizze_43251;\n    int32_t replicate_gid_43250;\n    int32_t replicate_gtid_43248;\n    int32_t phys_tblock_id_43255;\n    int32_t iterations_43256;\n    \n    replicate_ltid_43249 = get_local_id(0);\n    tblock_sizze_43251 = get_local_size(0);\n    replicate_gid_43250 = get_tblock_id(0);\n    replicate_gtid_43248 = replicate_gid_43250 * tblock_sizze_43251 + replicate_ltid_43249;\n    phys_tblock_id_43255 = get_tblock_id(0);\n    iterations_43256 = sdiv_up32(sext_i64_i32(virt_num_tblocks_43253) - phys_tblock_id_43255, sext_i64_i32(num_tblocks_43254));\n    for (int32_t i_43257 = 0; i_43257 < iterations_43256; i_43257++) {\n        int32_t virt_tblock_id_43258;\n        int64_t global_tid_43259;\n        int64_t slice_43262;\n        int64_t slice_43263;\n        int64_t rep_i_43260;\n        int64_t remnant_43264;\n        int64_t rep_i_43261;\n        int64_t remnant_43265;\n        \n        virt_tblock_id_43258 = phys_tblock_id_43255 + i_43257 * sext_i64_i32(num_tblocks_43254);\n        global_tid_43259 = sext_i32_i64(virt_tblock_id_43258) * sext_i32_i64(tblock_sizze_43251) + sext_i32_i64(replicate_ltid_43249);\n        slice_43262 = (int64_t) 1;\n        slice_43263 = loopres_39385 * slice_43262;\n        rep_i_43260 = squot64(global_tid_43259, slice_43262);\n        remnant_43264 = global_tid_43259 - rep_i_43260 * slice_43262;\n        rep_i_43261 = remnant_43264;\n        remnant_43265 = remnant_43264 - rep_i_43261;\n        if (slt64(global_tid_43259, replicate_n_43247)) {\n            int64_t tmp_43266 = ((__global int64_t *) mem_42454)[rep_i_43261];\n            \n            ((__global int64_t *) mem_42459)[rep_i_43260 + rep_i_43261] = tmp_43266;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE ",
                                    "| CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_shortzisegmap_40301_dim1, 1, 1)\nvoid inner_SMJ_shortzisegmap_40301(__global int *global_failure, int64_t nR_25439, int64_t m_39200, int64_t num_tblocks_40306, int64_t ext_42365, int64_t ext_42366, int64_t ext_42367, int64_t ext_42368, int32_t virt_num_tblocks_42987, __global unsigned char *tR_mem_42199, __global unsigned char *ext_mem_42201, __global unsigned char *ext_mem_42369, __global unsigned char *ext_mem_42370, __global unsigned char *mem_42373, __global unsigned char *mem_42375, __global unsigned char *mem_42377, __global unsigned char *mem_42379, __global unsigned char *mem_42381, __global unsigned char *mem_42383)\n{\n    #define segmap_tblock_sizze_40304 (inner_SMJ_shortzisegmap_40301zisegmap_tblock_sizze_40304)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42989;\n    int32_t tblock_sizze_42992;\n    int32_t wave_sizze_42991;\n    int32_t block_id_42990;\n    int32_t global_tid_42988;\n    int64_t phys_tid_40301;\n    int32_t phys_tblock_id_42993;\n    int32_t iterations_42994;\n    \n    local_tid_42989 = get_local_id(0);\n    tblock_sizze_42992 = get_local_size(0);\n    wave_sizze_42991 = LOCKSTEP_WIDTH;\n    block_id_42990 = get_tblock_id(0);\n    global_tid_42988 = block_id_42990 * tblock_sizze_42992 + local_tid_42989;\n    phys_tid_40301 = sext_i32_i64(global_tid_42988);\n    phys_tblock_id_42993 = get_tblock_id(0);\n    iterations_42994 = sdiv_up32(virt_num_tblocks_42987 - phys_tblock_id_42993, sext_i64_i32(num_tblocks_40306));\n    for (int32_t i_42995 = 0; i_42995 < iterations_42994; i_42995++) {\n        int32_t virt_tblock_id_42996;\n        int64_t global_tid_42997;\n        int64_t slice_42998;\n        int64_t write_i_40300;\n        int64_t remnant_42999;\n        \n        virt_tblock_id_42996 = phys_tblock_id_42993 + i_42995 * sext_i64_i32(num_tblocks_40306);\n        global_tid_42997 = sext_i32_i64(virt_tblock_id_42996) * segmap_tblock_sizze_40304 ", "+ sext_i32_i64(local_tid_42989);\n        slice_42998 = nR_25439;\n        write_i_40300 = global_tid_42997;\n        remnant_42999 = global_tid_42997 - write_i_40300;\n        if (slt64(write_i_40300, nR_25439)) {\n            int64_t eta_p_39447;\n            int16_t write_value_39449;\n            int64_t write_value_39450;\n            int64_t write_value_39451;\n            int64_t write_value_39452;\n            bool cond_39453;\n            int64_t lifted_lambda_res_39454;\n            \n            eta_p_39447 = ((__global int64_t *) mem_42375)[write_i_40300];\n            write_value_39449 = ((__global int16_t *) tR_mem_42199)[write_i_40300];\n            write_value_39450 = ((__global int64_t *) ext_mem_42201)[write_i_40300];\n            write_value_39451 = ((__global int64_t *) ext_mem_42369)[ext_42366 + write_i_40300 * ext_42365];\n            write_value_39452 = ((__global int64_t *) ext_mem_42370)[ext_42368 + write_i_40300 * ext_42367];\n            cond_39453 = eta_p_39447 == (int64_t) 1;\n            if (cond_39453) {\n                int64_t eta_p_39448;\n                int64_t lifted_lambda_res_t_res_39514;\n                \n                eta_p_39448 = ((__global int64_t *) mem_42373)[write_i_40300];\n                lifted_lambda_res_t_res_39514 = sub64(eta_p_39448, (int64_t) 1);\n                lifted_lambda_res_39454 = lifted_lambda_res_t_res_39514;\n            } else {\n                lifted_lambda_res_39454 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39454) && slt64(lifted_lambda_res_39454, m_39200)) {\n                ((__global int16_t *) mem_42383)[lifted_lambda_res_39454] = write_value_39449;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39454) && slt64(lifted_lambda_res_39454, m_39200)) {\n                ((__global int64_t *) mem_42381)[lifted_lambda_res_39454] = write_value_39450;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39454) && slt64(lifted_lambda_res_39454, m_39200)) {", "\n                ((__global int64_t *) mem_42379)[lifted_lambda_res_39454] = write_value_39451;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39454) && slt64(lifted_lambda_res_39454, m_39200)) {\n                ((__global int64_t *) mem_42377)[lifted_lambda_res_39454] = write_value_39452;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_40304\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_shortzisegmap_40335_dim1, 1, 1)\nvoid inner_SMJ_shortzisegmap_40335(__global int *global_failure, int64_t m_39200, __global unsigned char *mem_42387, __global unsigned char *mem_42394)\n{\n    #define segmap_tblock_sizze_40331 (inner_SMJ_shortzisegmap_40335zisegmap_tblock_sizze_40331)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43155;\n    int32_t tblock_sizze_43158;\n    int32_t wave_sizze_43157;\n    int32_t block_id_43156;\n    int32_t global_tid_43154;\n    int64_t phys_tid_40335;\n    int64_t global_tid_43159;\n    int64_t slice_43160;\n    int64_t gtid_40334;\n    int64_t remnant_43161;\n    \n    local_tid_43155 = get_local_id(0);\n    tblock_sizze_43158 = get_local_size(0);\n    wave_sizze_43157 = LOCKSTEP_WIDTH;\n    block_id_43156 = get_tblock_id(0);\n    global_tid_43154 = block_id_43156 * tblock_sizze_43158 + local_tid_43155;\n    phys_tid_40335 = sext_i32_i64(global_tid_43154);\n    global_tid_43159 = sext_i32_i64(block_id_43156) * segmap_tblock_sizze_40331 + sext_i32_i64(local_tid_43155);\n    slice_43160 = m_39200;\n    gtid_40334 = global_tid_43159;\n    remnant_43161 = global_tid_43159 - gtid_40334;\n    if (slt64(gtid_40334, m_39200)) {\n        int64_t zv_lhs_40337;\n        int64_t tmp_40338;\n        bool cond_40340;\n        int64_t lifted_lambda_res_40341;\n        \n        zv_lhs_40337 = add64((int64_t) -1, gtid_40334);\n        tmp_40338 = smod64(zv_lhs_40337, m_39200);\n        cond_40340 = gtid_40334 == (int64_t) 0;\n        if (cond_40340) {\n         ",
                                    "   lifted_lambda_res_40341 = (int64_t) 0;\n        } else {\n            int64_t lifted_lambda_res_40339 = ((__global int64_t *) mem_42387)[tmp_40338];\n            \n            lifted_lambda_res_40341 = lifted_lambda_res_40339;\n        }\n        ((__global int64_t *) mem_42394)[gtid_40334] = lifted_lambda_res_40341;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_40331\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_shortzisegmap_40343_dim1, 1, 1)\nvoid inner_SMJ_shortzisegmap_40343(__global int *global_failure, int64_t m_39200, int64_t lower_bound_39283, int64_t min_res_39285, int64_t j_m_i_39286, int64_t num_tblocks_40348, int32_t virt_num_tblocks_43200, __global unsigned char *mem_42379, __global unsigned char *mem_42381, __global unsigned char *mem_42383, __global unsigned char *mem_42394, __global unsigned char *mem_42423, __global unsigned char *mem_42425, __global unsigned char *mem_42427)\n{\n    #define segmap_tblock_sizze_40346 (inner_SMJ_shortzisegmap_40343zisegmap_tblock_sizze_40346)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43202;\n    int32_t tblock_sizze_43205;\n    int32_t wave_sizze_43204;\n    int32_t block_id_43203;\n    int32_t global_tid_43201;\n    int64_t phys_tid_40343;\n    int32_t phys_tblock_id_43206;\n    int32_t iterations_43207;\n    \n    local_tid_43202 = get_local_id(0);\n    tblock_sizze_43205 = get_local_size(0);\n    wave_sizze_43204 = LOCKSTEP_WIDTH;\n    block_id_43203 = get_tblock_id(0);\n    global_tid_43201 = block_id_43203 * tblock_sizze_43205 + local_tid_43202;\n    phys_tid_40343 = sext_i32_i64(global_tid_43201);\n    phys_tblock_id_43206 = get_tblock_id(0);\n    iterations_43207 = sdiv_up32(virt_num_tblocks_43200 - phys_tblock_id_43206, sext_i64_i32(num_tblocks_40348));\n    for (int32_t i_43208 = 0; i_43208 < iterations_43207; i_43208++) {\n        int32_t virt_tblock_id_43209;\n        int64_t global_tid_43210;\n        int64_t slice_43211;\n        int64_t write_i_40342;\n        int64_t remnant_43212;\n        \n ", "       virt_tblock_id_43209 = phys_tblock_id_43206 + i_43208 * sext_i64_i32(num_tblocks_40348);\n        global_tid_43210 = sext_i32_i64(virt_tblock_id_43209) * segmap_tblock_sizze_40346 + sext_i32_i64(local_tid_43202);\n        slice_43211 = m_39200;\n        write_i_40342 = global_tid_43210;\n        remnant_43212 = global_tid_43210 - write_i_40342;\n        if (slt64(write_i_40342, m_39200)) {\n            int64_t eta_p_39484;\n            int16_t write_value_39485;\n            int64_t write_value_39486;\n            int64_t write_value_39487;\n            bool cond_39488;\n            bool cond_t_res_39489;\n            bool x_39490;\n            int64_t lifted_lambda_res_39491;\n            \n            eta_p_39484 = ((__global int64_t *) mem_42394)[write_i_40342];\n            write_value_39485 = ((__global int16_t *) mem_42383)[write_i_40342];\n            write_value_39486 = ((__global int64_t *) mem_42381)[write_i_40342];\n            write_value_39487 = ((__global int64_t *) mem_42379)[write_i_40342];\n            cond_39488 = sle64(lower_bound_39283, eta_p_39484);\n            cond_t_res_39489 = slt64(eta_p_39484, min_res_39285);\n            x_39490 = cond_39488 && cond_t_res_39489;\n            if (x_39490) {\n                int64_t lifted_lambda_res_t_res_39517 = sub64(eta_p_39484, lower_bound_39283);\n                \n                lifted_lambda_res_39491 = lifted_lambda_res_t_res_39517;\n            } else {\n                lifted_lambda_res_39491 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39491) && slt64(lifted_lambda_res_39491, j_m_i_39286)) {\n                ((__global int16_t *) mem_42423)[lifted_lambda_res_39491] = write_value_39485;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39491) && slt64(lifted_lambda_res_39491, j_m_i_39286)) {\n                ((__global int64_t *) mem_42425)[lifted_lambda_res_39491] = write_value_39486;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39491) && s", "lt64(lifted_lambda_res_39491, j_m_i_39286)) {\n                ((__global int64_t *) mem_42427)[lifted_lambda_res_39491] = write_value_39487;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_40346\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_shortzisegmap_40351_dim1, 1, 1)\nvoid inner_SMJ_shortzisegmap_40351(__global int *global_failure, int64_t m_39200, int64_t m_39340, int64_t num_tblocks_40356, int32_t virt_num_tblocks_43182, __global unsigned char *mem_42377, __global unsigned char *mem_42389, __global unsigned char *mem_42391, __global unsigned char *mem_42394, __global unsigned char *mem_42402, __global unsigned char *mem_42404)\n{\n    #define segmap_tblock_sizze_40354 (inner_SMJ_shortzisegmap_40351zisegmap_tblock_sizze_40354)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43184;\n    int32_t tblock_sizze_43187;\n    int32_t wave_sizze_43186;\n    int32_t block_id_43185;\n    int32_t global_tid_43183;\n    int64_t phys_tid_40351;\n    int32_t phys_tblock_id_43188;\n    int32_t iterations_43189;\n    \n    local_tid_43184 = get_local_id(0);\n    tblock_sizze_43187 = get_local_size(0);\n    wave_sizze_43186 = LOCKSTEP_WIDTH;\n    block_id_43185 = get_tblock_id(0);\n    global_tid_43183 = block_id_43185 * tblock_sizze_43187 + local_tid_43184;\n    phys_tid_40351 = sext_i32_i64(global_tid_43183);\n    phys_tblock_id_43188 = get_tblock_id(0);\n    iterations_43189 = sdiv_up32(virt_num_tblocks_43182 - phys_tblock_id_43188, sext_i64_i32(num_tblocks_40356));\n    for (int32_t i_43190 = 0; i_43190 < iterations_43189; i_43190++) {\n        int32_t virt_tblock_id_43191;\n        int64_t global_tid_43192;\n        int64_t slice_43193;\n        int64_t write_i_40350;\n        int64_t remnant_43194;\n        \n        virt_tblock_id_43191 = phys_tblock_id_43188 + i_43190 * sext_i64_i32(num_tblocks_40356);\n        global_tid_43192 = sext_i32_i64(virt_tblock_id_43191) * segmap_tblock_sizze",
                                    "_40354 + sext_i32_i64(local_tid_43184);\n        slice_43193 = m_39200;\n        write_i_40350 = global_tid_43192;\n        remnant_43194 = global_tid_43192 - write_i_40350;\n        if (slt64(write_i_40350, m_39200)) {\n            int64_t eta_p_39424;\n            int64_t write_value_39426;\n            int64_t write_value_39427;\n            bool cond_39428;\n            int64_t lifted_lambda_res_39429;\n            \n            eta_p_39424 = ((__global int64_t *) mem_42391)[write_i_40350];\n            write_value_39426 = ((__global int64_t *) mem_42394)[write_i_40350];\n            write_value_39427 = ((__global int64_t *) mem_42377)[write_i_40350];\n            cond_39428 = eta_p_39424 == (int64_t) 1;\n            if (cond_39428) {\n                int64_t eta_p_39425;\n                int64_t lifted_lambda_res_t_res_39522;\n                \n                eta_p_39425 = ((__global int64_t *) mem_42389)[write_i_40350];\n                lifted_lambda_res_t_res_39522 = sub64(eta_p_39425, (int64_t) 1);\n                lifted_lambda_res_39429 = lifted_lambda_res_t_res_39522;\n            } else {\n                lifted_lambda_res_39429 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39429) && slt64(lifted_lambda_res_39429, m_39340)) {\n                ((__global int64_t *) mem_42404)[lifted_lambda_res_39429] = write_value_39426;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_39429) && slt64(lifted_lambda_res_39429, m_39340)) {\n                ((__global int64_t *) mem_42402)[lifted_lambda_res_39429] = write_value_39427;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_40354\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_shortzisegmap_40373_dim1, 1, 1)\nvoid inner_SMJ_shortzisegmap_40373(__global int *global_failure, int64_t loopres_39384, int64_t loopres_39385, __global unsigned char *mem_42452, __global unsigned char *mem_42455)\n{\n    #define s", "egmap_tblock_sizze_40369 (inner_SMJ_shortzisegmap_40373zisegmap_tblock_sizze_40369)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43269;\n    int32_t tblock_sizze_43272;\n    int32_t wave_sizze_43271;\n    int32_t block_id_43270;\n    int32_t global_tid_43268;\n    int64_t phys_tid_40373;\n    int64_t global_tid_43273;\n    int64_t slice_43274;\n    int64_t gtid_40372;\n    int64_t remnant_43275;\n    \n    local_tid_43269 = get_local_id(0);\n    tblock_sizze_43272 = get_local_size(0);\n    wave_sizze_43271 = LOCKSTEP_WIDTH;\n    block_id_43270 = get_tblock_id(0);\n    global_tid_43268 = block_id_43270 * tblock_sizze_43272 + local_tid_43269;\n    phys_tid_40373 = sext_i32_i64(global_tid_43268);\n    global_tid_43273 = sext_i32_i64(block_id_43270) * segmap_tblock_sizze_40369 + sext_i32_i64(local_tid_43269);\n    slice_43274 = loopres_39385;\n    gtid_40372 = global_tid_43273;\n    remnant_43275 = global_tid_43273 - gtid_40372;\n    if (slt64(gtid_40372, loopres_39385)) {\n        int64_t loopres_42194;\n        int64_t tmp_40375;\n        \n        loopres_42194 = ((__global int64_t *) mem_42455)[(int64_t) 0];\n        tmp_40375 = add64(gtid_40372, loopres_42194);\n        ((__global int64_t *) mem_42452)[loopres_39384 + gtid_40372] = tmp_40375;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_40369\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_shortzisegmap_intrablock_41423_dim1, 1, 1)\nvoid inner_SMJ_shortzisegmap_intrablock_41423(__global int *global_failure, int64_t nS_25440, int64_t start_39100, int64_t min_res_39102, int64_t ldim_41426, int64_t num_whole_tiles_41441, int64_t residual_input_41665, unsigned char cond_41666_bits, int64_t binop_x_41682, __global unsigned char *tR_mem_42199, __global unsigned char *tS_mem_42200, __global unsigned char *ext_mem_42224, __global unsigned char *mem_42344, __global unsigned char *mem_42346)\n{\n    bool cond_41666 = cond_41666_bits;\n    \n    #define tile_sizze_41425 (inner_SMJ_shortzisegmap_intrablock_41423zitile_sizze_4", "1425)\n    #define bytes_42306 (inner_SMJ_shortzisegmap_intrablock_41423zibytes_42306)\n    #define bytes_42308 (inner_SMJ_shortzisegmap_intrablock_41423zibytes_42308)\n    \n    volatile __local unsigned char *color_42702_backing_2 = &shared_mem[0];\n    const int64_t color_42702_backing_2_offset = 0 + (bytes_42306 + srem64((int64_t) 8 - srem64(bytes_42306, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_42701_backing_1 = &shared_mem[color_42702_backing_2_offset];\n    const int64_t color_42701_backing_1_offset = color_42702_backing_2_offset + (bytes_42308 + srem64((int64_t) 8 - srem64(bytes_42308, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_42700_backing_0 = &shared_mem[color_42701_backing_1_offset];\n    const int64_t color_42700_backing_0_offset = color_42701_backing_1_offset + (bytes_42306 + srem64((int64_t) 8 - srem64(bytes_42306, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42793;\n    int32_t tblock_sizze_42796;\n    int32_t wave_sizze_42795;\n    int32_t block_id_42794;\n    int32_t global_tid_42792;\n    int64_t gid_flat_41423;\n    int64_t slice_42798;\n    int64_t ltid_pre_42797;\n    int64_t remnant_42799;\n    int64_t slice_42800;\n    int64_t gid_41422;\n    int64_t remnant_42801;\n    __local unsigned char *color_42700;\n    __local unsigned char *color_42701;\n    __local unsigned char *color_42702;\n    int64_t binop_x_41433;\n    int16_t mem_42290[1];\n    int64_t ltid_flat_41428;\n    int64_t ltid_41427;\n    int64_t gtid_41434;\n    bool cond_41435;\n    int16_t pre_41436;\n    int64_t mem_42294[1];\n    int16_t mem_42298[1];\n    int64_t mem_42302[1];\n    int64_t ltid_flat_41443;\n    int64_t ltid_41442;\n    int64_t gtid_41453;\n    bool cond_41454;\n    int64_t neutral_41455;\n    int16_t neutral_41456;\n    int64_t ext_mem_42326[1];\n    int16_t ext_mem_42325[1];\n    int64_t ext_mem_42324[1];\n    int64_t mem_param_42303[1];\n    int16_t mem_param_42304[1];\n    int64_t m",
                                    "em_param_42305[1];\n    int64_t mem_42336[1];\n    int64_t mem_42340[1];\n    int64_t ext_mem_42342[1];\n    int64_t ext_mem_42341[1];\n    \n    local_tid_42793 = get_local_id(0);\n    tblock_sizze_42796 = get_local_size(0);\n    wave_sizze_42795 = LOCKSTEP_WIDTH;\n    block_id_42794 = get_tblock_id(0);\n    global_tid_42792 = block_id_42794 * tblock_sizze_42796 + local_tid_42793;\n    gid_flat_41423 = sext_i32_i64(block_id_42794);\n    slice_42798 = tile_sizze_41425;\n    ltid_pre_42797 = sext_i32_i64(local_tid_42793);\n    remnant_42799 = sext_i32_i64(local_tid_42793) - ltid_pre_42797;\n    slice_42800 = ldim_41426;\n    gid_41422 = sext_i32_i64(block_id_42794);\n    remnant_42801 = sext_i32_i64(block_id_42794) - gid_41422;\n    color_42700 = (__local unsigned char *) color_42700_backing_0;\n    color_42701 = (__local unsigned char *) color_42701_backing_1;\n    color_42702 = (__local unsigned char *) color_42702_backing_2;\n    binop_x_41433 = gid_41422 * tile_sizze_41425;\n    ltid_flat_41428 = sext_i32_i64(local_tid_42793);\n    ltid_41427 = sext_i32_i64(sext_i64_i32(ltid_pre_42797));\n    gtid_41434 = ltid_41427 + binop_x_41433;\n    cond_41435 = slt64(gtid_41434, min_res_39102);\n    if (cond_41435) {\n        int64_t slice_41437;\n        int16_t eta_p_41438;\n        \n        slice_41437 = start_39100 + gtid_41434;\n        eta_p_41438 = ((__global int16_t *) tR_mem_42199)[slice_41437];\n        pre_41436 = eta_p_41438;\n    } else {\n        pre_41436 = (int16_t) 0;\n    }\n    mem_42290[(int64_t) 0] = pre_41436;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    ltid_flat_41443 = sext_i32_i64(local_tid_42793);\n    ltid_41442 = sext_i32_i64(sext_i64_i32(ltid_pre_42797));\n    gtid_41453 = binop_x_41433 + ltid_41442;\n    cond_41454 = slt64(gtid_41453, min_res_39102);\n    if (cond_41454) {\n        neutral_41455 = (int64_t) -1;\n    } else {\n        neutral_41455 = (int64_t) 0;\n    }\n    if (cond_41454) {\n        int16_t eta_p_41458 = mem_42290[(int64_t) 0];\n        \n        neutral_41456 = eta_p_41458;\n   ", " } else {\n        neutral_41456 = (int16_t) 0;\n    }\n    mem_42294[(int64_t) 0] = neutral_41455;\n    mem_42298[(int64_t) 0] = neutral_41456;\n    mem_42302[(int64_t) 0] = (int64_t) 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    for (int32_t i_3 = 0; i_3 < 1; i_3++)\n        mem_param_42303[i_3] = mem_42294[i_3];\n    for (int32_t i_4 = 0; i_4 < 1; i_4++)\n        mem_param_42304[i_4] = mem_42298[i_4];\n    for (int32_t i_5 = 0; i_5 < 1; i_5++)\n        mem_param_42305[i_5] = mem_42302[i_5];\n    for (int64_t tile_id_41468 = 0; tile_id_41468 < num_whole_tiles_41441; tile_id_41468++) {\n        int64_t binop_x_41567;\n        int64_t ltid_flat_41566;\n        int64_t ltid_41565;\n        int64_t j_41568;\n        bool cond_41572;\n        int64_t pre1d_41575;\n        int64_t pre1d_41573;\n        int16_t pre1d_41574;\n        int64_t mem_42315[1];\n        int16_t mem_42319[1];\n        int64_t mem_42323[1];\n        int64_t ltid_flat_41586;\n        int64_t ltid_41585;\n        int64_t gtid_41588;\n        int64_t acc_41590;\n        int16_t acc_41591;\n        int64_t acc_41592;\n        bool cond_41593;\n        int64_t acc_41594;\n        int16_t acc_41595;\n        int64_t acc_41596;\n        int64_t mem_param_tmp_42802[1];\n        int16_t mem_param_tmp_42803[1];\n        int64_t mem_param_tmp_42804[1];\n        \n        binop_x_41567 = tile_sizze_41425 * tile_id_41468;\n        ltid_flat_41566 = sext_i32_i64(local_tid_42793);\n        ltid_41565 = sext_i32_i64(sext_i64_i32(ltid_pre_42797));\n        j_41568 = ltid_41565 + binop_x_41567;\n        cond_41572 = slt64(j_41568, nS_25440);\n        pre1d_41575 = btoi_bool_i64(cond_41572);\n        if (cond_41572) {\n            int64_t tile_elem_41576;\n            int16_t tile_elem_41577;\n            \n            tile_elem_41576 = ((__global int64_t *) ext_mem_42224)[j_41568];\n            tile_elem_41577 = ((__global int16_t *) tS_mem_42200)[j_41568];\n            pre1d_41573 = tile_elem_41576;\n            pre1d_41574 = tile_el", "em_41577;\n        } else {\n            pre1d_41573 = (int64_t) 0;\n            pre1d_41574 = (int16_t) 0;\n        }\n        ((__local int64_t *) color_42702)[ltid_41565] = pre1d_41573;\n        ((__local int16_t *) color_42701)[ltid_41565] = pre1d_41574;\n        ((__local int64_t *) color_42700)[ltid_41565] = pre1d_41575;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_41586 = sext_i32_i64(local_tid_42793);\n        ltid_41585 = sext_i32_i64(sext_i64_i32(ltid_pre_42797));\n        gtid_41588 = binop_x_41433 + ltid_41585;\n        acc_41590 = mem_param_42303[(int64_t) 0];\n        acc_41591 = mem_param_42304[(int64_t) 0];\n        acc_41592 = mem_param_42305[(int64_t) 0];\n        cond_41593 = slt64(gtid_41588, min_res_39102);\n        if (cond_41593) {\n            int16_t eta_p_41589;\n            int64_t x_41597;\n            int16_t x_41598;\n            int64_t x_41599;\n            int64_t redout_42136;\n            int16_t redout_42137;\n            int64_t redout_42138;\n            \n            eta_p_41589 = mem_42290[(int64_t) 0];\n            redout_42136 = acc_41590;\n            redout_42137 = acc_41591;\n            redout_42138 = acc_41592;\n            for (int64_t i_42139 = 0; i_42139 < tile_sizze_41425; i_42139++) {\n                int64_t x_41600;\n                int16_t x_41601;\n                bool defunc_0_neq_res_41609;\n                bool defunc_0_neq_res_41610;\n                bool cond_f_res_41611;\n                bool y_41612;\n                bool cond_41613;\n                bool defunc_0_neq_res_41614;\n                bool defunc_0_neq_res_41615;\n                bool cond_t_res_f_res_41616;\n                bool y_41617;\n                bool cond_t_res_41618;\n                bool x_41619;\n                int64_t defunc_0_op_res_41620;\n                int16_t defunc_0_op_res_41621;\n                int64_t defunc_0_op_res_41622;\n                int64_t redout_tmp_42808;\n                int16_t redout_tmp_42809;\n                int64_t redout_tmp_42810;\n ",
                                    "               \n                x_41600 = ((__local int64_t *) color_42702)[i_42139];\n                x_41601 = ((__local int16_t *) color_42701)[i_42139];\n                defunc_0_neq_res_41609 = redout_42137 == eta_p_41589;\n                defunc_0_neq_res_41610 = !defunc_0_neq_res_41609;\n                cond_f_res_41611 = slt64(redout_42136, (int64_t) 0);\n                y_41612 = defunc_0_neq_res_41609 && cond_f_res_41611;\n                cond_41613 = defunc_0_neq_res_41610 || y_41612;\n                defunc_0_neq_res_41614 = x_41601 == eta_p_41589;\n                defunc_0_neq_res_41615 = !defunc_0_neq_res_41614;\n                cond_t_res_f_res_41616 = slt64(x_41600, (int64_t) 0);\n                y_41617 = defunc_0_neq_res_41614 && cond_t_res_f_res_41616;\n                cond_t_res_41618 = defunc_0_neq_res_41615 || y_41617;\n                x_41619 = cond_41613 && cond_t_res_41618;\n                if (x_41619) {\n                    defunc_0_op_res_41620 = (int64_t) -1;\n                    defunc_0_op_res_41621 = eta_p_41589;\n                    defunc_0_op_res_41622 = (int64_t) 0;\n                } else {\n                    int64_t x_41602;\n                    int64_t defunc_0_op_res_f_res_41623;\n                    int16_t defunc_0_op_res_f_res_41624;\n                    int64_t defunc_0_op_res_f_res_41625;\n                    \n                    x_41602 = ((__local int64_t *) color_42700)[i_42139];\n                    if (cond_41613) {\n                        defunc_0_op_res_f_res_41623 = x_41600;\n                        defunc_0_op_res_f_res_41624 = x_41601;\n                        defunc_0_op_res_f_res_41625 = x_41602;\n                    } else {\n                        int16_t defunc_0_op_res_f_res_f_res_41626;\n                        int64_t defunc_0_op_res_f_res_f_res_41627;\n                        int64_t defunc_0_op_res_f_res_f_res_41628;\n                        \n                        if (cond_t_res_41618) {\n                            defunc_0_op", "_res_f_res_f_res_41626 = redout_42137;\n                        } else {\n                            defunc_0_op_res_f_res_f_res_41626 = eta_p_41589;\n                        }\n                        if (cond_t_res_41618) {\n                            defunc_0_op_res_f_res_f_res_41627 = redout_42136;\n                            defunc_0_op_res_f_res_f_res_41628 = redout_42138;\n                        } else {\n                            int64_t min_res_41629;\n                            int64_t tmp_41630;\n                            \n                            min_res_41629 = smin64(x_41600, redout_42136);\n                            tmp_41630 = add64(x_41602, redout_42138);\n                            defunc_0_op_res_f_res_f_res_41627 = min_res_41629;\n                            defunc_0_op_res_f_res_f_res_41628 = tmp_41630;\n                        }\n                        defunc_0_op_res_f_res_41623 = defunc_0_op_res_f_res_f_res_41627;\n                        defunc_0_op_res_f_res_41624 = defunc_0_op_res_f_res_f_res_41626;\n                        defunc_0_op_res_f_res_41625 = defunc_0_op_res_f_res_f_res_41628;\n                    }\n                    defunc_0_op_res_41620 = defunc_0_op_res_f_res_41623;\n                    defunc_0_op_res_41621 = defunc_0_op_res_f_res_41624;\n                    defunc_0_op_res_41622 = defunc_0_op_res_f_res_41625;\n                }\n                redout_tmp_42808 = defunc_0_op_res_41620;\n                redout_tmp_42809 = defunc_0_op_res_41621;\n                redout_tmp_42810 = defunc_0_op_res_41622;\n                redout_42136 = redout_tmp_42808;\n                redout_42137 = redout_tmp_42809;\n                redout_42138 = redout_tmp_42810;\n            }\n            x_41597 = redout_42136;\n            x_41598 = redout_42137;\n            x_41599 = redout_42138;\n            acc_41594 = x_41597;\n            acc_41595 = x_41598;\n            acc_41596 = x_41599;\n        } else {\n            acc_41594 = acc_41590;\n            acc_", "41595 = acc_41591;\n            acc_41596 = acc_41592;\n        }\n        mem_42315[(int64_t) 0] = acc_41594;\n        mem_42319[(int64_t) 0] = acc_41595;\n        mem_42323[(int64_t) 0] = acc_41596;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_6 = 0; i_6 < 1; i_6++)\n            mem_param_tmp_42802[i_6] = mem_42315[i_6];\n        for (int32_t i_7 = 0; i_7 < 1; i_7++)\n            mem_param_tmp_42803[i_7] = mem_42319[i_7];\n        for (int32_t i_8 = 0; i_8 < 1; i_8++)\n            mem_param_tmp_42804[i_8] = mem_42323[i_8];\n        for (int32_t i_9 = 0; i_9 < 1; i_9++)\n            mem_param_42303[i_9] = mem_param_tmp_42802[i_9];\n        for (int32_t i_10 = 0; i_10 < 1; i_10++)\n            mem_param_42304[i_10] = mem_param_tmp_42803[i_10];\n        for (int32_t i_11 = 0; i_11 < 1; i_11++)\n            mem_param_42305[i_11] = mem_param_tmp_42804[i_11];\n    }\n    for (int32_t i_12 = 0; i_12 < 1; i_12++)\n        ext_mem_42326[i_12] = mem_param_42303[i_12];\n    for (int32_t i_13 = 0; i_13 < 1; i_13++)\n        ext_mem_42325[i_13] = mem_param_42304[i_13];\n    for (int32_t i_14 = 0; i_14 < 1; i_14++)\n        ext_mem_42324[i_14] = mem_param_42305[i_14];\n    barrier(CLK_LOCAL_MEM_FENCE);\n    if (cond_41666) {\n        for (int32_t i_15 = 0; i_15 < 1; i_15++)\n            ext_mem_42342[i_15] = ext_mem_42326[i_15];\n        for (int32_t i_16 = 0; i_16 < 1; i_16++)\n            ext_mem_42341[i_16] = ext_mem_42324[i_16];\n    } else {\n        int64_t ltid_flat_41668;\n        int64_t ltid_41667;\n        int64_t j_41683;\n        bool cond_41687;\n        int64_t pre1d_41690;\n        int64_t pre1d_41688;\n        int16_t pre1d_41689;\n        int64_t ltid_flat_41704;\n        int64_t ltid_41703;\n        int64_t gtid_41717;\n        int64_t acc_41719;\n        int64_t acc_41721;\n        bool cond_41722;\n        int64_t acc_41723;\n        int64_t acc_41725;\n        \n        ltid_flat_41668 = sext_i32_i64(local_tid_42793);\n        ltid_41667 = sext_i32_i64(sext_i64_i32(ltid_pre_42797));\n    ",
                                    "    j_41683 = ltid_41667 + binop_x_41682;\n        cond_41687 = slt64(j_41683, nS_25440);\n        pre1d_41690 = btoi_bool_i64(cond_41687);\n        if (cond_41687) {\n            int64_t tile_elem_41691;\n            int16_t tile_elem_41692;\n            \n            tile_elem_41691 = ((__global int64_t *) ext_mem_42224)[j_41683];\n            tile_elem_41692 = ((__global int16_t *) tS_mem_42200)[j_41683];\n            pre1d_41688 = tile_elem_41691;\n            pre1d_41689 = tile_elem_41692;\n        } else {\n            pre1d_41688 = (int64_t) 0;\n            pre1d_41689 = (int16_t) 0;\n        }\n        ((__local int64_t *) color_42702)[ltid_41667] = pre1d_41688;\n        ((__local int16_t *) color_42701)[ltid_41667] = pre1d_41689;\n        ((__local int64_t *) color_42700)[ltid_41667] = pre1d_41690;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_41704 = sext_i32_i64(local_tid_42793);\n        ltid_41703 = sext_i32_i64(sext_i64_i32(ltid_pre_42797));\n        gtid_41717 = binop_x_41433 + ltid_41703;\n        acc_41719 = ext_mem_42326[(int64_t) 0];\n        acc_41721 = ext_mem_42324[(int64_t) 0];\n        cond_41722 = slt64(gtid_41717, min_res_39102);\n        if (cond_41722) {\n            int16_t eta_p_41718;\n            int16_t acc_41720;\n            int64_t x_41726;\n            int16_t x_41727;\n            int64_t x_41728;\n            int64_t redout_42140;\n            int16_t redout_42141;\n            int64_t redout_42142;\n            \n            eta_p_41718 = mem_42290[(int64_t) 0];\n            acc_41720 = ext_mem_42325[(int64_t) 0];\n            redout_42140 = acc_41719;\n            redout_42141 = acc_41720;\n            redout_42142 = acc_41721;\n            for (int64_t i_42143 = 0; i_42143 < residual_input_41665; i_42143++) {\n                int64_t x_41729;\n                int16_t x_41730;\n                bool defunc_0_neq_res_41738;\n                bool defunc_0_neq_res_41739;\n                bool cond_f_res_41740;\n                bool y_41741;\n                bool c", "ond_41742;\n                bool defunc_0_neq_res_41743;\n                bool defunc_0_neq_res_41744;\n                bool cond_t_res_f_res_41745;\n                bool y_41746;\n                bool cond_t_res_41747;\n                bool x_41748;\n                int64_t defunc_0_op_res_41749;\n                int16_t defunc_0_op_res_41750;\n                int64_t defunc_0_op_res_41751;\n                int64_t redout_tmp_42811;\n                int16_t redout_tmp_42812;\n                int64_t redout_tmp_42813;\n                \n                x_41729 = ((__local int64_t *) color_42702)[i_42143];\n                x_41730 = ((__local int16_t *) color_42701)[i_42143];\n                defunc_0_neq_res_41738 = redout_42141 == eta_p_41718;\n                defunc_0_neq_res_41739 = !defunc_0_neq_res_41738;\n                cond_f_res_41740 = slt64(redout_42140, (int64_t) 0);\n                y_41741 = defunc_0_neq_res_41738 && cond_f_res_41740;\n                cond_41742 = defunc_0_neq_res_41739 || y_41741;\n                defunc_0_neq_res_41743 = x_41730 == eta_p_41718;\n                defunc_0_neq_res_41744 = !defunc_0_neq_res_41743;\n                cond_t_res_f_res_41745 = slt64(x_41729, (int64_t) 0);\n                y_41746 = defunc_0_neq_res_41743 && cond_t_res_f_res_41745;\n                cond_t_res_41747 = defunc_0_neq_res_41744 || y_41746;\n                x_41748 = cond_41742 && cond_t_res_41747;\n                if (x_41748) {\n                    defunc_0_op_res_41749 = (int64_t) -1;\n                    defunc_0_op_res_41750 = eta_p_41718;\n                    defunc_0_op_res_41751 = (int64_t) 0;\n                } else {\n                    int64_t x_41731;\n                    int64_t defunc_0_op_res_f_res_41752;\n                    int16_t defunc_0_op_res_f_res_41753;\n                    int64_t defunc_0_op_res_f_res_41754;\n                    \n                    x_41731 = ((__local int64_t *) color_42700)[i_42143];\n                    if (cond_41742) {\n                  ", "      defunc_0_op_res_f_res_41752 = x_41729;\n                        defunc_0_op_res_f_res_41753 = x_41730;\n                        defunc_0_op_res_f_res_41754 = x_41731;\n                    } else {\n                        int16_t defunc_0_op_res_f_res_f_res_41755;\n                        int64_t defunc_0_op_res_f_res_f_res_41756;\n                        int64_t defunc_0_op_res_f_res_f_res_41757;\n                        \n                        if (cond_t_res_41747) {\n                            defunc_0_op_res_f_res_f_res_41755 = redout_42141;\n                        } else {\n                            defunc_0_op_res_f_res_f_res_41755 = eta_p_41718;\n                        }\n                        if (cond_t_res_41747) {\n                            defunc_0_op_res_f_res_f_res_41756 = redout_42140;\n                            defunc_0_op_res_f_res_f_res_41757 = redout_42142;\n                        } else {\n                            int64_t min_res_41758;\n                            int64_t tmp_41759;\n                            \n                            min_res_41758 = smin64(x_41729, redout_42140);\n                            tmp_41759 = add64(x_41731, redout_42142);\n                            defunc_0_op_res_f_res_f_res_41756 = min_res_41758;\n                            defunc_0_op_res_f_res_f_res_41757 = tmp_41759;\n                        }\n                        defunc_0_op_res_f_res_41752 = defunc_0_op_res_f_res_f_res_41756;\n                        defunc_0_op_res_f_res_41753 = defunc_0_op_res_f_res_f_res_41755;\n                        defunc_0_op_res_f_res_41754 = defunc_0_op_res_f_res_f_res_41757;\n                    }\n                    defunc_0_op_res_41749 = defunc_0_op_res_f_res_41752;\n                    defunc_0_op_res_41750 = defunc_0_op_res_f_res_41753;\n                    defunc_0_op_res_41751 = defunc_0_op_res_f_res_41754;\n                }\n                redout_tmp_42811 = defunc_0_op_res_41749;\n                redout_tmp_42812 = defu",
                                    "nc_0_op_res_41750;\n                redout_tmp_42813 = defunc_0_op_res_41751;\n                redout_42140 = redout_tmp_42811;\n                redout_42141 = redout_tmp_42812;\n                redout_42142 = redout_tmp_42813;\n            }\n            x_41726 = redout_42140;\n            x_41727 = redout_42141;\n            x_41728 = redout_42142;\n            acc_41723 = x_41726;\n            acc_41725 = x_41728;\n        } else {\n            acc_41723 = acc_41719;\n            acc_41725 = acc_41721;\n        }\n        mem_42336[(int64_t) 0] = acc_41723;\n        mem_42340[(int64_t) 0] = acc_41725;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_17 = 0; i_17 < 1; i_17++)\n            ext_mem_42342[i_17] = mem_42336[i_17];\n        for (int32_t i_18 = 0; i_18 < 1; i_18++)\n            ext_mem_42341[i_18] = mem_42340[i_18];\n    }\n    if (slt64(sext_i32_i64(local_tid_42793) + tile_sizze_41425 * sext_i32_i64(block_id_42794), min_res_39102)) {\n        int64_t tmp_42814 = ext_mem_42342[(int64_t) 0];\n        \n        ((__global int64_t *) mem_42344)[sext_i32_i64(local_tid_42793) + tile_sizze_41425 * sext_i32_i64(block_id_42794)] = tmp_42814;\n    }\n    if (slt64(sext_i32_i64(local_tid_42793) + tile_sizze_41425 * sext_i32_i64(block_id_42794), min_res_39102)) {\n        int64_t tmp_42815 = ext_mem_42341[(int64_t) 0];\n        \n        ((__global int64_t *) mem_42346)[sext_i32_i64(local_tid_42793) + tile_sizze_41425 * sext_i32_i64(block_id_42794)] = tmp_42815;\n    }\n    \n  error_8:\n    return;\n    #undef tile_sizze_41425\n    #undef bytes_42306\n    #undef bytes_42308\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_shortzisegmap_intrablock_41778_dim1, 1, 1)\nvoid inner_SMJ_shortzisegmap_intrablock_41778(__global int *global_failure, int64_t nS_25440, int64_t start_39100, int64_t min_res_39102, int64_t ldim_41781, int64_t num_whole_tiles_41796, int64_t residual_input_42020, unsigned char cond_42021_bits, int64_t binop_x_42037, __global unsigned char *tR_mem_42199, __global unsigned char *tS_mem_4", "2200, __global unsigned char *ext_mem_42224, __global unsigned char *mem_42283, __global unsigned char *mem_42285)\n{\n    bool cond_42021 = cond_42021_bits;\n    \n    #define tile_sizze_41780 (inner_SMJ_shortzisegmap_intrablock_41778zitile_sizze_41780)\n    #define bytes_42245 (inner_SMJ_shortzisegmap_intrablock_41778zibytes_42245)\n    #define bytes_42247 (inner_SMJ_shortzisegmap_intrablock_41778zibytes_42247)\n    \n    volatile __local unsigned char *color_42705_backing_2 = &shared_mem[0];\n    const int64_t color_42705_backing_2_offset = 0 + (bytes_42245 + srem64((int64_t) 8 - srem64(bytes_42245, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_42704_backing_1 = &shared_mem[color_42705_backing_2_offset];\n    const int64_t color_42704_backing_1_offset = color_42705_backing_2_offset + (bytes_42247 + srem64((int64_t) 8 - srem64(bytes_42247, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_42703_backing_0 = &shared_mem[color_42704_backing_1_offset];\n    const int64_t color_42703_backing_0_offset = color_42704_backing_1_offset + (bytes_42245 + srem64((int64_t) 8 - srem64(bytes_42245, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42819;\n    int32_t tblock_sizze_42822;\n    int32_t wave_sizze_42821;\n    int32_t block_id_42820;\n    int32_t global_tid_42818;\n    int64_t gid_flat_41778;\n    int64_t slice_42824;\n    int64_t ltid_pre_42823;\n    int64_t remnant_42825;\n    int64_t slice_42826;\n    int64_t gid_41777;\n    int64_t remnant_42827;\n    __local unsigned char *color_42703;\n    __local unsigned char *color_42704;\n    __local unsigned char *color_42705;\n    int64_t binop_x_41788;\n    int16_t mem_42229[1];\n    int64_t ltid_flat_41783;\n    int64_t ltid_41782;\n    int64_t gtid_41789;\n    bool cond_41790;\n    int16_t pre_41791;\n    int64_t mem_42233[1];\n    int16_t mem_42237[1];\n    int64_t mem_42241[1];\n    int64_t ltid_flat_41798;\n    int64_t ltid_41797;\n    int64_t gtid_4180", "8;\n    bool cond_41809;\n    int64_t neutral_41810;\n    int16_t neutral_41811;\n    int64_t ext_mem_42265[1];\n    int16_t ext_mem_42264[1];\n    int64_t ext_mem_42263[1];\n    int64_t mem_param_42242[1];\n    int16_t mem_param_42243[1];\n    int64_t mem_param_42244[1];\n    int64_t mem_42275[1];\n    int64_t mem_42279[1];\n    int64_t ext_mem_42281[1];\n    int64_t ext_mem_42280[1];\n    \n    local_tid_42819 = get_local_id(0);\n    tblock_sizze_42822 = get_local_size(0);\n    wave_sizze_42821 = LOCKSTEP_WIDTH;\n    block_id_42820 = get_tblock_id(0);\n    global_tid_42818 = block_id_42820 * tblock_sizze_42822 + local_tid_42819;\n    gid_flat_41778 = sext_i32_i64(block_id_42820);\n    slice_42824 = tile_sizze_41780;\n    ltid_pre_42823 = sext_i32_i64(local_tid_42819);\n    remnant_42825 = sext_i32_i64(local_tid_42819) - ltid_pre_42823;\n    slice_42826 = ldim_41781;\n    gid_41777 = sext_i32_i64(block_id_42820);\n    remnant_42827 = sext_i32_i64(block_id_42820) - gid_41777;\n    color_42703 = (__local unsigned char *) color_42703_backing_0;\n    color_42704 = (__local unsigned char *) color_42704_backing_1;\n    color_42705 = (__local unsigned char *) color_42705_backing_2;\n    binop_x_41788 = gid_41777 * tile_sizze_41780;\n    ltid_flat_41783 = sext_i32_i64(local_tid_42819);\n    ltid_41782 = sext_i32_i64(sext_i64_i32(ltid_pre_42823));\n    gtid_41789 = ltid_41782 + binop_x_41788;\n    cond_41790 = slt64(gtid_41789, min_res_39102);\n    if (cond_41790) {\n        int64_t slice_41792;\n        int16_t eta_p_41793;\n        \n        slice_41792 = start_39100 + gtid_41789;\n        eta_p_41793 = ((__global int16_t *) tR_mem_42199)[slice_41792];\n        pre_41791 = eta_p_41793;\n    } else {\n        pre_41791 = (int16_t) 0;\n    }\n    mem_42229[(int64_t) 0] = pre_41791;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    ltid_flat_41798 = sext_i32_i64(local_tid_42819);\n    ltid_41797 = sext_i32_i64(sext_i64_i32(ltid_pre_42823));\n    gtid_41808 = binop_x_41788 + ltid_41797;\n    cond_41809 = slt64(gtid_41808, min_res_3910",
                                    "2);\n    if (cond_41809) {\n        neutral_41810 = (int64_t) -1;\n    } else {\n        neutral_41810 = (int64_t) 0;\n    }\n    if (cond_41809) {\n        int16_t eta_p_41813 = mem_42229[(int64_t) 0];\n        \n        neutral_41811 = eta_p_41813;\n    } else {\n        neutral_41811 = (int16_t) 0;\n    }\n    mem_42233[(int64_t) 0] = neutral_41810;\n    mem_42237[(int64_t) 0] = neutral_41811;\n    mem_42241[(int64_t) 0] = (int64_t) 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    for (int32_t i_3 = 0; i_3 < 1; i_3++)\n        mem_param_42242[i_3] = mem_42233[i_3];\n    for (int32_t i_4 = 0; i_4 < 1; i_4++)\n        mem_param_42243[i_4] = mem_42237[i_4];\n    for (int32_t i_5 = 0; i_5 < 1; i_5++)\n        mem_param_42244[i_5] = mem_42241[i_5];\n    for (int64_t tile_id_41823 = 0; tile_id_41823 < num_whole_tiles_41796; tile_id_41823++) {\n        int64_t binop_x_41922;\n        int64_t ltid_flat_41921;\n        int64_t ltid_41920;\n        int64_t j_41923;\n        bool cond_41927;\n        int64_t pre1d_41930;\n        int64_t pre1d_41928;\n        int16_t pre1d_41929;\n        int64_t mem_42254[1];\n        int16_t mem_42258[1];\n        int64_t mem_42262[1];\n        int64_t ltid_flat_41941;\n        int64_t ltid_41940;\n        int64_t gtid_41943;\n        int64_t acc_41945;\n        int16_t acc_41946;\n        int64_t acc_41947;\n        bool cond_41948;\n        int64_t acc_41949;\n        int16_t acc_41950;\n        int64_t acc_41951;\n        int64_t mem_param_tmp_42828[1];\n        int16_t mem_param_tmp_42829[1];\n        int64_t mem_param_tmp_42830[1];\n        \n        binop_x_41922 = tile_sizze_41780 * tile_id_41823;\n        ltid_flat_41921 = sext_i32_i64(local_tid_42819);\n        ltid_41920 = sext_i32_i64(sext_i64_i32(ltid_pre_42823));\n        j_41923 = ltid_41920 + binop_x_41922;\n        cond_41927 = slt64(j_41923, nS_25440);\n        pre1d_41930 = btoi_bool_i64(cond_41927);\n        if (cond_41927) {\n            int64_t tile_elem_41931;\n            int16_t tile_elem_4193", "2;\n            \n            tile_elem_41931 = ((__global int64_t *) ext_mem_42224)[j_41923];\n            tile_elem_41932 = ((__global int16_t *) tS_mem_42200)[j_41923];\n            pre1d_41928 = tile_elem_41931;\n            pre1d_41929 = tile_elem_41932;\n        } else {\n            pre1d_41928 = (int64_t) 0;\n            pre1d_41929 = (int16_t) 0;\n        }\n        ((__local int64_t *) color_42705)[ltid_41920] = pre1d_41928;\n        ((__local int16_t *) color_42704)[ltid_41920] = pre1d_41929;\n        ((__local int64_t *) color_42703)[ltid_41920] = pre1d_41930;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_41941 = sext_i32_i64(local_tid_42819);\n        ltid_41940 = sext_i32_i64(sext_i64_i32(ltid_pre_42823));\n        gtid_41943 = binop_x_41788 + ltid_41940;\n        acc_41945 = mem_param_42242[(int64_t) 0];\n        acc_41946 = mem_param_42243[(int64_t) 0];\n        acc_41947 = mem_param_42244[(int64_t) 0];\n        cond_41948 = slt64(gtid_41943, min_res_39102);\n        if (cond_41948) {\n            int16_t eta_p_41944;\n            int64_t x_41952;\n            int16_t x_41953;\n            int64_t x_41954;\n            int64_t redout_42144;\n            int16_t redout_42145;\n            int64_t redout_42146;\n            \n            eta_p_41944 = mem_42229[(int64_t) 0];\n            redout_42144 = acc_41945;\n            redout_42145 = acc_41946;\n            redout_42146 = acc_41947;\n            for (int64_t i_42147 = 0; i_42147 < tile_sizze_41780; i_42147++) {\n                int64_t x_41955;\n                int16_t x_41956;\n                bool defunc_0_neq_res_41964;\n                bool defunc_0_neq_res_41965;\n                bool cond_f_res_41966;\n                bool y_41967;\n                bool cond_41968;\n                bool defunc_0_neq_res_41969;\n                bool defunc_0_neq_res_41970;\n                bool cond_t_res_f_res_41971;\n                bool y_41972;\n                bool cond_t_res_41973;\n                bool x_41974;\n                int64_t", " defunc_0_op_res_41975;\n                int16_t defunc_0_op_res_41976;\n                int64_t defunc_0_op_res_41977;\n                int64_t redout_tmp_42834;\n                int16_t redout_tmp_42835;\n                int64_t redout_tmp_42836;\n                \n                x_41955 = ((__local int64_t *) color_42705)[i_42147];\n                x_41956 = ((__local int16_t *) color_42704)[i_42147];\n                defunc_0_neq_res_41964 = redout_42145 == eta_p_41944;\n                defunc_0_neq_res_41965 = !defunc_0_neq_res_41964;\n                cond_f_res_41966 = slt64(redout_42144, (int64_t) 0);\n                y_41967 = defunc_0_neq_res_41964 && cond_f_res_41966;\n                cond_41968 = defunc_0_neq_res_41965 || y_41967;\n                defunc_0_neq_res_41969 = x_41956 == eta_p_41944;\n                defunc_0_neq_res_41970 = !defunc_0_neq_res_41969;\n                cond_t_res_f_res_41971 = slt64(x_41955, (int64_t) 0);\n                y_41972 = defunc_0_neq_res_41969 && cond_t_res_f_res_41971;\n                cond_t_res_41973 = defunc_0_neq_res_41970 || y_41972;\n                x_41974 = cond_41968 && cond_t_res_41973;\n                if (x_41974) {\n                    defunc_0_op_res_41975 = (int64_t) -1;\n                    defunc_0_op_res_41976 = eta_p_41944;\n                    defunc_0_op_res_41977 = (int64_t) 0;\n                } else {\n                    int64_t x_41957;\n                    int64_t defunc_0_op_res_f_res_41978;\n                    int16_t defunc_0_op_res_f_res_41979;\n                    int64_t defunc_0_op_res_f_res_41980;\n                    \n                    x_41957 = ((__local int64_t *) color_42703)[i_42147];\n                    if (cond_41968) {\n                        defunc_0_op_res_f_res_41978 = x_41955;\n                        defunc_0_op_res_f_res_41979 = x_41956;\n                        defunc_0_op_res_f_res_41980 = x_41957;\n                    } else {\n                        int16_t defunc_0_op_res_f_res_f_res_41981;\n ",
                                    "                       int64_t defunc_0_op_res_f_res_f_res_41982;\n                        int64_t defunc_0_op_res_f_res_f_res_41983;\n                        \n                        if (cond_t_res_41973) {\n                            defunc_0_op_res_f_res_f_res_41981 = redout_42145;\n                        } else {\n                            defunc_0_op_res_f_res_f_res_41981 = eta_p_41944;\n                        }\n                        if (cond_t_res_41973) {\n                            defunc_0_op_res_f_res_f_res_41982 = redout_42144;\n                            defunc_0_op_res_f_res_f_res_41983 = redout_42146;\n                        } else {\n                            int64_t min_res_41984;\n                            int64_t tmp_41985;\n                            \n                            min_res_41984 = smin64(x_41955, redout_42144);\n                            tmp_41985 = add64(x_41957, redout_42146);\n                            defunc_0_op_res_f_res_f_res_41982 = min_res_41984;\n                            defunc_0_op_res_f_res_f_res_41983 = tmp_41985;\n                        }\n                        defunc_0_op_res_f_res_41978 = defunc_0_op_res_f_res_f_res_41982;\n                        defunc_0_op_res_f_res_41979 = defunc_0_op_res_f_res_f_res_41981;\n                        defunc_0_op_res_f_res_41980 = defunc_0_op_res_f_res_f_res_41983;\n                    }\n                    defunc_0_op_res_41975 = defunc_0_op_res_f_res_41978;\n                    defunc_0_op_res_41976 = defunc_0_op_res_f_res_41979;\n                    defunc_0_op_res_41977 = defunc_0_op_res_f_res_41980;\n                }\n                redout_tmp_42834 = defunc_0_op_res_41975;\n                redout_tmp_42835 = defunc_0_op_res_41976;\n                redout_tmp_42836 = defunc_0_op_res_41977;\n                redout_42144 = redout_tmp_42834;\n                redout_42145 = redout_tmp_42835;\n                redout_42146 = redout_tmp_42836;\n            }\n            x_41952 = redout_4", "2144;\n            x_41953 = redout_42145;\n            x_41954 = redout_42146;\n            acc_41949 = x_41952;\n            acc_41950 = x_41953;\n            acc_41951 = x_41954;\n        } else {\n            acc_41949 = acc_41945;\n            acc_41950 = acc_41946;\n            acc_41951 = acc_41947;\n        }\n        mem_42254[(int64_t) 0] = acc_41949;\n        mem_42258[(int64_t) 0] = acc_41950;\n        mem_42262[(int64_t) 0] = acc_41951;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_6 = 0; i_6 < 1; i_6++)\n            mem_param_tmp_42828[i_6] = mem_42254[i_6];\n        for (int32_t i_7 = 0; i_7 < 1; i_7++)\n            mem_param_tmp_42829[i_7] = mem_42258[i_7];\n        for (int32_t i_8 = 0; i_8 < 1; i_8++)\n            mem_param_tmp_42830[i_8] = mem_42262[i_8];\n        for (int32_t i_9 = 0; i_9 < 1; i_9++)\n            mem_param_42242[i_9] = mem_param_tmp_42828[i_9];\n        for (int32_t i_10 = 0; i_10 < 1; i_10++)\n            mem_param_42243[i_10] = mem_param_tmp_42829[i_10];\n        for (int32_t i_11 = 0; i_11 < 1; i_11++)\n            mem_param_42244[i_11] = mem_param_tmp_42830[i_11];\n    }\n    for (int32_t i_12 = 0; i_12 < 1; i_12++)\n        ext_mem_42265[i_12] = mem_param_42242[i_12];\n    for (int32_t i_13 = 0; i_13 < 1; i_13++)\n        ext_mem_42264[i_13] = mem_param_42243[i_13];\n    for (int32_t i_14 = 0; i_14 < 1; i_14++)\n        ext_mem_42263[i_14] = mem_param_42244[i_14];\n    barrier(CLK_LOCAL_MEM_FENCE);\n    if (cond_42021) {\n        for (int32_t i_15 = 0; i_15 < 1; i_15++)\n            ext_mem_42281[i_15] = ext_mem_42265[i_15];\n        for (int32_t i_16 = 0; i_16 < 1; i_16++)\n            ext_mem_42280[i_16] = ext_mem_42263[i_16];\n    } else {\n        int64_t ltid_flat_42023;\n        int64_t ltid_42022;\n        int64_t j_42038;\n        bool cond_42042;\n        int64_t pre1d_42045;\n        int64_t pre1d_42043;\n        int16_t pre1d_42044;\n        int64_t ltid_flat_42059;\n        int64_t ltid_42058;\n        int64_t gtid_42072;\n        int64_t acc_420", "74;\n        int64_t acc_42076;\n        bool cond_42077;\n        int64_t acc_42078;\n        int64_t acc_42080;\n        \n        ltid_flat_42023 = sext_i32_i64(local_tid_42819);\n        ltid_42022 = sext_i32_i64(sext_i64_i32(ltid_pre_42823));\n        j_42038 = ltid_42022 + binop_x_42037;\n        cond_42042 = slt64(j_42038, nS_25440);\n        pre1d_42045 = btoi_bool_i64(cond_42042);\n        if (cond_42042) {\n            int64_t tile_elem_42046;\n            int16_t tile_elem_42047;\n            \n            tile_elem_42046 = ((__global int64_t *) ext_mem_42224)[j_42038];\n            tile_elem_42047 = ((__global int16_t *) tS_mem_42200)[j_42038];\n            pre1d_42043 = tile_elem_42046;\n            pre1d_42044 = tile_elem_42047;\n        } else {\n            pre1d_42043 = (int64_t) 0;\n            pre1d_42044 = (int16_t) 0;\n        }\n        ((__local int64_t *) color_42705)[ltid_42022] = pre1d_42043;\n        ((__local int16_t *) color_42704)[ltid_42022] = pre1d_42044;\n        ((__local int64_t *) color_42703)[ltid_42022] = pre1d_42045;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_42059 = sext_i32_i64(local_tid_42819);\n        ltid_42058 = sext_i32_i64(sext_i64_i32(ltid_pre_42823));\n        gtid_42072 = binop_x_41788 + ltid_42058;\n        acc_42074 = ext_mem_42265[(int64_t) 0];\n        acc_42076 = ext_mem_42263[(int64_t) 0];\n        cond_42077 = slt64(gtid_42072, min_res_39102);\n        if (cond_42077) {\n            int16_t eta_p_42073;\n            int16_t acc_42075;\n            int64_t x_42081;\n            int16_t x_42082;\n            int64_t x_42083;\n            int64_t redout_42148;\n            int16_t redout_42149;\n            int64_t redout_42150;\n            \n            eta_p_42073 = mem_42229[(int64_t) 0];\n            acc_42075 = ext_mem_42264[(int64_t) 0];\n            redout_42148 = acc_42074;\n            redout_42149 = acc_42075;\n            redout_42150 = acc_42076;\n            for (int64_t i_42151 = 0; i_42151 < residual_input_42020; i_42151++) {\n  ",
                                    "              int64_t x_42084;\n                int16_t x_42085;\n                bool defunc_0_neq_res_42093;\n                bool defunc_0_neq_res_42094;\n                bool cond_f_res_42095;\n                bool y_42096;\n                bool cond_42097;\n                bool defunc_0_neq_res_42098;\n                bool defunc_0_neq_res_42099;\n                bool cond_t_res_f_res_42100;\n                bool y_42101;\n                bool cond_t_res_42102;\n                bool x_42103;\n                int64_t defunc_0_op_res_42104;\n                int16_t defunc_0_op_res_42105;\n                int64_t defunc_0_op_res_42106;\n                int64_t redout_tmp_42837;\n                int16_t redout_tmp_42838;\n                int64_t redout_tmp_42839;\n                \n                x_42084 = ((__local int64_t *) color_42705)[i_42151];\n                x_42085 = ((__local int16_t *) color_42704)[i_42151];\n                defunc_0_neq_res_42093 = redout_42149 == eta_p_42073;\n                defunc_0_neq_res_42094 = !defunc_0_neq_res_42093;\n                cond_f_res_42095 = slt64(redout_42148, (int64_t) 0);\n                y_42096 = defunc_0_neq_res_42093 && cond_f_res_42095;\n                cond_42097 = defunc_0_neq_res_42094 || y_42096;\n                defunc_0_neq_res_42098 = x_42085 == eta_p_42073;\n                defunc_0_neq_res_42099 = !defunc_0_neq_res_42098;\n                cond_t_res_f_res_42100 = slt64(x_42084, (int64_t) 0);\n                y_42101 = defunc_0_neq_res_42098 && cond_t_res_f_res_42100;\n                cond_t_res_42102 = defunc_0_neq_res_42099 || y_42101;\n                x_42103 = cond_42097 && cond_t_res_42102;\n                if (x_42103) {\n                    defunc_0_op_res_42104 = (int64_t) -1;\n                    defunc_0_op_res_42105 = eta_p_42073;\n                    defunc_0_op_res_42106 = (int64_t) 0;\n                } else {\n                    int64_t x_42086;\n                    int64_t defunc_0_op_res_f_res_42107;\n                    ", "int16_t defunc_0_op_res_f_res_42108;\n                    int64_t defunc_0_op_res_f_res_42109;\n                    \n                    x_42086 = ((__local int64_t *) color_42703)[i_42151];\n                    if (cond_42097) {\n                        defunc_0_op_res_f_res_42107 = x_42084;\n                        defunc_0_op_res_f_res_42108 = x_42085;\n                        defunc_0_op_res_f_res_42109 = x_42086;\n                    } else {\n                        int16_t defunc_0_op_res_f_res_f_res_42110;\n                        int64_t defunc_0_op_res_f_res_f_res_42111;\n                        int64_t defunc_0_op_res_f_res_f_res_42112;\n                        \n                        if (cond_t_res_42102) {\n                            defunc_0_op_res_f_res_f_res_42110 = redout_42149;\n                        } else {\n                            defunc_0_op_res_f_res_f_res_42110 = eta_p_42073;\n                        }\n                        if (cond_t_res_42102) {\n                            defunc_0_op_res_f_res_f_res_42111 = redout_42148;\n                            defunc_0_op_res_f_res_f_res_42112 = redout_42150;\n                        } else {\n                            int64_t min_res_42113;\n                            int64_t tmp_42114;\n                            \n                            min_res_42113 = smin64(x_42084, redout_42148);\n                            tmp_42114 = add64(x_42086, redout_42150);\n                            defunc_0_op_res_f_res_f_res_42111 = min_res_42113;\n                            defunc_0_op_res_f_res_f_res_42112 = tmp_42114;\n                        }\n                        defunc_0_op_res_f_res_42107 = defunc_0_op_res_f_res_f_res_42111;\n                        defunc_0_op_res_f_res_42108 = defunc_0_op_res_f_res_f_res_42110;\n                        defunc_0_op_res_f_res_42109 = defunc_0_op_res_f_res_f_res_42112;\n                    }\n                    defunc_0_op_res_42104 = defunc_0_op_res_f_res_42107;\n                ", "    defunc_0_op_res_42105 = defunc_0_op_res_f_res_42108;\n                    defunc_0_op_res_42106 = defunc_0_op_res_f_res_42109;\n                }\n                redout_tmp_42837 = defunc_0_op_res_42104;\n                redout_tmp_42838 = defunc_0_op_res_42105;\n                redout_tmp_42839 = defunc_0_op_res_42106;\n                redout_42148 = redout_tmp_42837;\n                redout_42149 = redout_tmp_42838;\n                redout_42150 = redout_tmp_42839;\n            }\n            x_42081 = redout_42148;\n            x_42082 = redout_42149;\n            x_42083 = redout_42150;\n            acc_42078 = x_42081;\n            acc_42080 = x_42083;\n        } else {\n            acc_42078 = acc_42074;\n            acc_42080 = acc_42076;\n        }\n        mem_42275[(int64_t) 0] = acc_42078;\n        mem_42279[(int64_t) 0] = acc_42080;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_17 = 0; i_17 < 1; i_17++)\n            ext_mem_42281[i_17] = mem_42275[i_17];\n        for (int32_t i_18 = 0; i_18 < 1; i_18++)\n            ext_mem_42280[i_18] = mem_42279[i_18];\n    }\n    if (slt64(sext_i32_i64(local_tid_42819) + tile_sizze_41780 * sext_i32_i64(block_id_42820), min_res_39102)) {\n        int64_t tmp_42840 = ext_mem_42281[(int64_t) 0];\n        \n        ((__global int64_t *) mem_42283)[sext_i32_i64(local_tid_42819) + tile_sizze_41780 * sext_i32_i64(block_id_42820)] = tmp_42840;\n    }\n    if (slt64(sext_i32_i64(local_tid_42819) + tile_sizze_41780 * sext_i32_i64(block_id_42820), min_res_39102)) {\n        int64_t tmp_42841 = ext_mem_42280[(int64_t) 0];\n        \n        ((__global int64_t *) mem_42285)[sext_i32_i64(local_tid_42819) + tile_sizze_41780 * sext_i32_i64(block_id_42820)] = tmp_42841;\n    }\n    \n  error_8:\n    return;\n    #undef tile_sizze_41780\n    #undef bytes_42245\n    #undef bytes_42247\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_shortzisegscan_40299_dim1, 1, 1)\nvoid inner_SMJ_shortzisegscan_40299(__global int *global_failure, int64_t nR_25439, int64_t num_tblocks_4029",
                                    "6, int64_t ext_42367, int64_t ext_42368, int64_t num_virt_blocks_42849, int64_t num_virt_threads_42850, __global unsigned char *ext_mem_42370, __global unsigned char *mem_42373, __global unsigned char *mem_42375, __global unsigned char *status_flags_mem_42851, __global unsigned char *aggregates_mem_42873, __global unsigned char *incprefixes_mem_42875, __global unsigned char *global_dynid_mem_42877)\n{\n    #define segscan_tblock_sizze_40294 (inner_SMJ_shortzisegscan_40299zisegscan_tblock_sizze_40294)\n    #define chunk_sizze_42848 (inner_SMJ_shortzisegscan_40299zichunk_sizze_42848)\n    \n    volatile __local unsigned char *local_mem_42907_backing_0 = &shared_mem[0];\n    const int64_t local_mem_42907_backing_0_offset = 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_40294), chunk_sizze_42848 * segscan_tblock_sizze_40294 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_40294), chunk_sizze_42848 * segscan_tblock_sizze_40294 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42900;\n    int32_t tblock_sizze_42903;\n    int32_t wave_sizze_42902;\n    int32_t block_id_42901;\n    int32_t global_tid_42899;\n    int64_t phys_tid_40299;\n    int32_t chunk_sizze_32b_42904;\n    int64_t byte_offsets_42905;\n    int64_t warp_byte_offset_42906;\n    __local unsigned char *local_mem_42907;\n    int64_t trans_arr_len_42908;\n    int64_t phys_block_id_42914;\n    int64_t virtloop_bound_42915;\n    \n    local_tid_42900 = get_local_id(0);\n    tblock_sizze_42903 = get_local_size(0);\n    wave_sizze_42902 = LOCKSTEP_WIDTH;\n    block_id_42901 = get_tblock_id(0);\n    global_tid_42899 = block_id_42901 * tblock_sizze_42903 + local_tid_42900;\n    phys_tid_40299 = sext_i32_i64(global_tid_42899);\n    chunk_sizze_32b_42904 = sext_i64_i32(chunk_sizze_42848);\n    byte_offsets_42905 = segscan_tblock_sizze_40294 * (int64_t) 8;\n    warp_byte_offset_42906 = (int64_t)", " 288;\n    // Allocate reusable shared memory\n    { }\n    local_mem_42907 = (__local unsigned char *) local_mem_42907_backing_0;\n    trans_arr_len_42908 = chunk_sizze_42848 * segscan_tblock_sizze_40294;\n    phys_block_id_42914 = get_tblock_id(0);\n    virtloop_bound_42915 = sdiv_up64(num_virt_blocks_42849 - phys_block_id_42914, num_tblocks_40296);\n    for (int64_t virtloop_i_42916 = 0; virtloop_i_42916 < virtloop_bound_42915; virtloop_i_42916++) {\n        int64_t dynamic_id_42917;\n        int64_t block_offset_42918;\n        int64_t sgm_idx_42919;\n        int32_t boundary_42920;\n        int32_t segsizze_compact_42921;\n        int64_t private_mem_42922[chunk_sizze_42848];\n        int64_t thd_offset_42924;\n        int64_t acc_42940;\n        int64_t prefix_42950;\n        bool block_new_sgm_42951;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_42900 == 0) {\n                dynamic_id_42917 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_42877)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_42907)[(int64_t) 0] = dynamic_id_42917;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_42917 == num_virt_blocks_42849 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_42877)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_42917 = ((__local int32_t *) local_mem_42907)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_42918 = dynamic_id_42917 * chunk_sizze_42848 * segscan_tblock_sizze_40294;\n        sgm_idx_42919 = smod64(block_offset_42918, nR_25439);\n        boundary_42920 = sext_i64_i32(smin64(chunk_sizze_42848 * segscan_tblock_sizze_40294, nR_25439 - sgm_idx_42919)", ");\n        segsizze_compact_42921 = sext_i64_i32(smin64(chunk_sizze_42848 * segscan_tblock_sizze_40294, nR_25439));\n        thd_offset_42924 = block_offset_42918 + sext_i32_i64(local_tid_42900);\n        // Load and map\n        {\n            for (int64_t i_42925 = 0; i_42925 < chunk_sizze_42848; i_42925++) {\n                int64_t virt_tid_42926 = thd_offset_42924 + i_42925 * segscan_tblock_sizze_40294;\n                int64_t slice_42927 = nR_25439;\n                int64_t gtid_40298 = virt_tid_42926;\n                int64_t remnant_42928 = virt_tid_42926 - gtid_40298;\n                \n                if (slt64(virt_tid_42926, nR_25439)) {\n                    int64_t eta_p_39458 = ((__global int64_t *) ext_mem_42370)[ext_42368 + gtid_40298 * ext_42367];\n                    bool lifted_lambda_res_39459 = slt64((int64_t) 0, eta_p_39458);\n                    int64_t defunc_0_f_res_39460 = btoi_bool_i64(lifted_lambda_res_39459);\n                    \n                    ((__global int64_t *) mem_42375)[gtid_40298] = defunc_0_f_res_39460;\n                    private_mem_42922[i_42925] = defunc_0_f_res_39460;\n                } else {\n                    private_mem_42922[i_42925] = (int64_t) 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_42929 = 0; i_42929 < chunk_sizze_42848; i_42929++) {\n                int64_t sharedIdx_42930 = sext_i32_i64(local_tid_42900) + i_42929 * segscan_tblock_sizze_40294;\n                int64_t tmp_42931 = private_mem_42922[i_42929];\n                \n                ((__local int64_t *) local_mem_42907)[sharedIdx_42930] = tmp_42931;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_42932 = 0; i_42932 < chunk_sizze_42848; i_42932++) {\n                int64_t sharedIdx_42933 = sext_i32_i64(local_tid_42900) * chunk_sizze_42848 + i_42932;\n                int64_t tmp_42934 = ((__local int64_t *) local_mem_42907)",
                                    "[sharedIdx_42933];\n                \n                private_mem_42922[i_42932] = tmp_42934;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_42935 = 0; i_42935 < chunk_sizze_42848 - (int64_t) 1; i_42935++) {\n                int64_t eta_p_39187;\n                int64_t eta_p_39188;\n                \n                eta_p_39187 = private_mem_42922[i_42935];\n                eta_p_39188 = private_mem_42922[i_42935 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_39189 = add64(eta_p_39187, eta_p_39188);\n                \n                private_mem_42922[i_42935 + (int64_t) 1] = defunc_0_op_res_39189;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_42936 = private_mem_42922[chunk_sizze_42848 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_42907)[sext_i32_i64(local_tid_42900)] = tmp_42936;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_42937;\n            int64_t eta_p_42938;\n            int64_t eta_p_42941;\n            int64_t eta_p_42942;\n            bool ltid_in_bounds_42944 = slt64(sext_i32_i64(local_tid_42900), num_virt_threads_42850);\n            int32_t skip_threads_42945;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_42944) {\n                    eta_p_42938 = ((volatile __local int64_t *) local_mem_42907)[sext_i32_i64(local_tid_42900)];\n                    if ((local_tid_42900 - squot32(local_tid_42900, 32) * 32) == 0) {\n                        eta_p_42937 = eta_p_42938;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_42945 = 1;\n                while (slt32(skip_threads_42945, 32)) {\n                    bool thread_active_42946 = sle32(skip_", "threads_42945, local_tid_42900 - squot32(local_tid_42900, 32) * 32) && ltid_in_bounds_42944;\n                    \n                    if (thread_active_42946) {\n                        // read operands\n                        {\n                            eta_p_42937 = ((volatile __local int64_t *) local_mem_42907)[sext_i32_i64(local_tid_42900) - sext_i32_i64(skip_threads_42945)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_42946) {\n                            int64_t defunc_0_op_res_42939 = add64(eta_p_42937, eta_p_42938);\n                            \n                            eta_p_42937 = defunc_0_op_res_42939;\n                        }\n                    }\n                    if (sle32(wave_sizze_42902, skip_threads_42945)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_42946) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_42907)[sext_i32_i64(local_tid_42900)] = eta_p_42937;\n                            eta_p_42938 = eta_p_42937;\n                        }\n                    }\n                    if (sle32(wave_sizze_42902, skip_threads_42945)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_42945 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_42900 - squot32(local_tid_42900, 32) * 32) == 31 && ltid_in_bounds_42944) {\n                    ((volatile __local int64_t *) local_mem_42907)[sext_i32_i64(squot32(local_tid_42900, 32))] = eta_p_42937;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-i", "n for block 'i+1'\n            {\n                int32_t skip_threads_42947;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_42900, 32) == 0 && ltid_in_bounds_42944) {\n                        eta_p_42942 = ((volatile __local int64_t *) local_mem_42907)[sext_i32_i64(local_tid_42900)];\n                        if ((local_tid_42900 - squot32(local_tid_42900, 32) * 32) == 0) {\n                            eta_p_42941 = eta_p_42942;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_42947 = 1;\n                    while (slt32(skip_threads_42947, 32)) {\n                        bool thread_active_42948 = sle32(skip_threads_42947, local_tid_42900 - squot32(local_tid_42900, 32) * 32) && (squot32(local_tid_42900, 32) == 0 && ltid_in_bounds_42944);\n                        \n                        if (thread_active_42948) {\n                            // read operands\n                            {\n                                eta_p_42941 = ((volatile __local int64_t *) local_mem_42907)[sext_i32_i64(local_tid_42900) - sext_i32_i64(skip_threads_42947)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_42948) {\n                                int64_t defunc_0_op_res_42943 = add64(eta_p_42941, eta_p_42942);\n                                \n                                eta_p_42941 = defunc_0_op_res_42943;\n                            }\n                        }\n                        if (sle32(wave_sizze_42902, skip_threads_42947)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_42948) {\n                            // write result\n                            {\n                ",
                                    "                ((volatile __local int64_t *) local_mem_42907)[sext_i32_i64(local_tid_42900)] = eta_p_42941;\n                                eta_p_42942 = eta_p_42941;\n                            }\n                        }\n                        if (sle32(wave_sizze_42902, skip_threads_42947)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_42947 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_42949 = squot32(local_tid_42900, 32) == 0 || !ltid_in_bounds_42944;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_42949) {\n                        eta_p_42938 = eta_p_42937;\n                        eta_p_42937 = ((__local int64_t *) local_mem_42907)[sext_i32_i64(squot32(local_tid_42900, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_42949) {\n                        int64_t defunc_0_op_res_42939 = add64(eta_p_42937, eta_p_42938);\n                        \n                        eta_p_42937 = defunc_0_op_res_42939;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_42949) {\n                        ((__local int64_t *) local_mem_42907)[sext_i32_i64(local_tid_42900)] = eta_p_42937;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_42900, 32) == 0 && ltid_in_bounds_42944) {\n                    ((__local int64_t *) local_mem_42907)[sext_i32_i64(local_tid_42900)] = eta_p_42938;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n      ", "      barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_42900 == 0) {\n                acc_42940 = ((__local int64_t *) local_mem_42907)[segscan_tblock_sizze_40294 - (int64_t) 1];\n            } else {\n                acc_42940 = ((__local int64_t *) local_mem_42907)[sext_i32_i64(local_tid_42900) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_42950 = (int64_t) 0;\n        block_new_sgm_42951 = sgm_idx_42919 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_42951 && local_tid_42900 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_42875)[dynamic_id_42917] = acc_42940;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_42851)[dynamic_id_42917] = (int8_t) 2;\n                acc_42940 = (int64_t) 0;\n            }\n            if (!block_new_sgm_42951 && slt32(local_tid_42900, wave_sizze_42902)) {\n                if (local_tid_42900 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_42873)[dynamic_id_42917] = acc_42940;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_42851)[dynamic_id_42917] = (int8_t) 1;\n                    \n                    int8_t tmp_42952 = ((volatile __global int8_t *) status_flags_mem_42851)[dynamic_id_42917 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_42907)[(int64_t) 0] = tmp_42952;\n                }\n                mem_fence_local();\n                \n                int8_t status_42953 = ((__local int8_t *) local_mem_42907)[(int64_t) 0];\n                \n                if (status_42953 == (int8_t) 2) {\n                    if (local_tid_42900 == 0) {\n                        prefix_42950 = ((volatile __global int64_t *) incprefixes_mem_42875)[dynamic_id_42917 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_4", "2954 = sext_i64_i32(dynamic_id_42917 - sext_i32_i64(wave_sizze_42902));\n                    \n                    while (slt32(wave_sizze_42902 * -1, readOffset_42954)) {\n                        int32_t read_i_42955 = readOffset_42954 + local_tid_42900;\n                        int64_t aggr_42956 = (int64_t) 0;\n                        int8_t flag_42957 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_42955)) {\n                            flag_42957 = ((volatile __global int8_t *) status_flags_mem_42851)[sext_i32_i64(read_i_42955)];\n                            if (flag_42957 == (int8_t) 2) {\n                                aggr_42956 = ((volatile __global int64_t *) incprefixes_mem_42875)[sext_i32_i64(read_i_42955)];\n                            } else if (flag_42957 == (int8_t) 1) {\n                                aggr_42956 = ((volatile __global int64_t *) aggregates_mem_42873)[sext_i32_i64(read_i_42955)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_42907)[(int64_t) 4 + sext_i32_i64(local_tid_42900)] = aggr_42956;\n                        ((__local int8_t *) local_mem_42907)[sext_i32_i64(local_tid_42900)] = flag_42957;\n                        flag_42957 = ((__local int8_t *) local_mem_42907)[sext_i32_i64(wave_sizze_42902) - (int64_t) 1];\n                        if (slt8(flag_42957, (int8_t) 2)) {\n                            int8_t flg_x_42961;\n                            int8_t flg_y_42962;\n                            int64_t eta_p_42958;\n                            int64_t eta_p_42959;\n                            int32_t skip_threads_42963;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_42962 = ((volatile __local int8_t *) local_mem_42907)[sext_i32_i64(local_tid_42900)];\n                                eta_p_42959 = ((volatile __local int64_t *) local_mem_42907",
                                    ")[(int64_t) 4 + sext_i32_i64(local_tid_42900)];\n                                if ((local_tid_42900 - squot32(local_tid_42900, 32) * 32) == 0) {\n                                    eta_p_42958 = eta_p_42959;\n                                    flg_x_42961 = flg_y_42962;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_42963 = 1;\n                                while (slt32(skip_threads_42963, 32)) {\n                                    if (sle32(skip_threads_42963, local_tid_42900 - squot32(local_tid_42900, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_42961 = ((volatile __local int8_t *) local_mem_42907)[sext_i32_i64(local_tid_42900) - sext_i32_i64(skip_threads_42963)];\n                                            eta_p_42958 = ((volatile __local int64_t *) local_mem_42907)[(int64_t) 4 + (sext_i32_i64(local_tid_42900) - sext_i32_i64(skip_threads_42963))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_42962 == (int8_t) 2 || flg_y_42962 == (int8_t) 0) {\n                                                flg_x_42961 = flg_y_42962;\n                                                eta_p_42958 = eta_p_42959;\n                                            } else {\n                                                int64_t defunc_0_op_res_42960 = add64(eta_p_42958, eta_p_42959);\n                                                \n                                                eta_p_42958 = defunc_0_op_res_42960;\n                                            }\n                                        }\n                                        // write result\n     ", "                                   {\n                                            ((volatile __local int8_t *) local_mem_42907)[sext_i32_i64(local_tid_42900)] = flg_x_42961;\n                                            flg_y_42962 = flg_x_42961;\n                                            ((volatile __local int64_t *) local_mem_42907)[(int64_t) 4 + sext_i32_i64(local_tid_42900)] = eta_p_42958;\n                                            eta_p_42959 = eta_p_42958;\n                                        }\n                                    }\n                                    skip_threads_42963 *= 2;\n                                }\n                            }\n                        }\n                        flag_42957 = ((__local int8_t *) local_mem_42907)[sext_i32_i64(wave_sizze_42902) - (int64_t) 1];\n                        aggr_42956 = ((__local int64_t *) local_mem_42907)[(int64_t) 4 + (sext_i32_i64(wave_sizze_42902) - (int64_t) 1)];\n                        if (flag_42957 == (int8_t) 2) {\n                            readOffset_42954 = wave_sizze_42902 * -1;\n                        } else if (flag_42957 == (int8_t) 1) {\n                            readOffset_42954 -= wave_sizze_42902;\n                        }\n                        if (slt8((int8_t) 0, flag_42957)) {\n                            int64_t eta_p_42964 = aggr_42956;\n                            int64_t eta_p_42965 = prefix_42950;\n                            int64_t defunc_0_op_res_42966 = add64(eta_p_42964, eta_p_42965);\n                            \n                            prefix_42950 = defunc_0_op_res_42966;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_42900 == 0) {\n                    if (boundary_42920 == sext_i64_i32(segscan_tblock_sizze_40294 * chunk_sizze_42848)) {\n                        int64_t eta_p_42967 = prefix_42950;\n                        int64_t eta_p_42968 = acc_42940;\n             ", "           int64_t defunc_0_op_res_42969 = add64(eta_p_42967, eta_p_42968);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_42875)[dynamic_id_42917] = defunc_0_op_res_42969;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_42851)[dynamic_id_42917] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_42907)[(int64_t) 4] = prefix_42950;\n                    acc_42940 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_42917 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_42950 = ((__local int64_t *) local_mem_42907)[(int64_t) 4];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_42970;\n            int64_t eta_p_42971;\n            int64_t eta_p_42973 = prefix_42950;\n            int64_t eta_p_42974 = acc_42940;\n            \n            if (slt32(local_tid_42900 * chunk_sizze_32b_42904, boundary_42920) && !block_new_sgm_42951) {\n                int64_t defunc_0_op_res_42975 = add64(eta_p_42973, eta_p_42974);\n                \n                eta_p_42970 = defunc_0_op_res_42975;\n            } else {\n                eta_p_42970 = acc_42940;\n            }\n            \n            int32_t stopping_point_42976 = segsizze_compact_42921 - srem32(local_tid_42900 * chunk_sizze_32b_42904 - 1 + segsizze_compact_42921 - boundary_42920, segsizze_compact_42921);\n            \n            for (int64_t i_42977 = 0; i_42977 < chunk_sizze_42848; i_42977++) {\n                if (slt32(sext_i64_i32(i_42977), stopping_point_42976 - 1)) {\n                    eta_p_42971 = private_mem_42922[i_42977];\n                    \n                    int64_t defunc_0_op_res_42972 = add64(eta_p_42970, eta_p_42971);\n                    \n                    private_mem_42922[i_42977] = defunc_0_op_res_42972;\n        ",
                                    "        }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_42978 = 0; i_42978 < chunk_sizze_42848; i_42978++) {\n                int64_t sharedIdx_42979 = sext_i32_i64(local_tid_42900) * chunk_sizze_42848 + i_42978;\n                int64_t tmp_42980 = private_mem_42922[i_42978];\n                \n                ((__local int64_t *) local_mem_42907)[sharedIdx_42979] = tmp_42980;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_42981 = 0; i_42981 < chunk_sizze_42848; i_42981++) {\n                int64_t flat_idx_42982 = thd_offset_42924 + i_42981 * segscan_tblock_sizze_40294;\n                int64_t slice_42983 = nR_25439;\n                int64_t gtid_40298 = flat_idx_42982;\n                int64_t remnant_42984 = flat_idx_42982 - gtid_40298;\n                \n                if (slt64(flat_idx_42982, nR_25439)) {\n                    int64_t tmp_42985 = ((__local int64_t *) local_mem_42907)[flat_idx_42982 - block_offset_42918];\n                    \n                    ((__global int64_t *) mem_42373)[gtid_40298] = tmp_42985;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_40294\n    #undef chunk_sizze_42848\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_shortzisegscan_40315_dim1, 1, 1)\nvoid inner_SMJ_shortzisegscan_40315(__global int *global_failure, int64_t m_39200, int64_t num_tblocks_40312, int64_t num_virt_blocks_43006, int64_t num_virt_threads_43007, __global unsigned char *mem_42377, __global unsigned char *mem_42387, __global unsigned char *mem_42389, __global unsigned char *mem_42391, __global unsigned char *status_flags_mem_43008, __global unsigned char *aggregates_mem_43010, __global unsigned char *incprefixes_mem_43012, __global unsigned char *aggregates_mem_43014, __global unsigned char *incprefixes_mem_43016, __global unsigned char *global_dyni", "d_mem_43018)\n{\n    #define segscan_tblock_sizze_40310 (inner_SMJ_shortzisegscan_40315zisegscan_tblock_sizze_40310)\n    #define chunk_sizze_43005 (inner_SMJ_shortzisegscan_40315zichunk_sizze_43005)\n    \n    volatile __local unsigned char *local_mem_43030_backing_0 = &shared_mem[0];\n    const int64_t local_mem_43030_backing_0_offset = 0 + (smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_40310, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_40310), smax64(chunk_sizze_43005 * segscan_tblock_sizze_40310 * (int64_t) 8, chunk_sizze_43005 * segscan_tblock_sizze_40310 * (int64_t) 8)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_40310, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_40310), smax64(chunk_sizze_43005 * segscan_tblock_sizze_40310 * (int64_t) 8, chunk_sizze_43005 * segscan_tblock_sizze_40310 * (int64_t) 8)), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_43021;\n    int32_t tblock_sizze_43024;\n    int32_t wave_sizze_43023;\n    int32_t block_id_43022;\n    int32_t global_tid_43020;\n    int64_t phys_tid_40315;\n    int32_t chunk_sizze_32b_43025;\n    int64_t byte_offsets_43026;\n    int64_t byte_offsets_43027;\n    int64_t warp_byte_offset_43028;\n    int64_t warp_byte_offset_43029;\n    __local unsigned char *local_mem_43030;\n    int64_t trans_arr_len_43031;\n    int64_t phys_block_id_43040;\n    int64_t virtloop_bound_43041;\n    \n    local_tid_43021 = get_local_id(0);\n    tblock_sizze_43024 = get_local_size(0);\n    wave_sizze_43023 = LOCKSTEP_WIDTH;\n    block_id_43022 = get_tblock_id(0);\n    global_tid_43020 = block_id_43022 * tblock_sizze_43024 + local_tid_43021;\n    phys_tid_40315 = sext_i32_i64(global_tid_43020);\n    chunk_sizze_32b_43025 = sext_i64_i32(chunk_sizze_43005);\n    byte_offsets_43026 = segscan_tblock_sizze_40310 * (int64_t) 8;\n    byte_offsets_43027 = sdiv_up64(byte_offsets_43026, (i", "nt64_t) 8) * (int64_t) 8 + segscan_tblock_sizze_40310 * (int64_t) 8;\n    warp_byte_offset_43028 = (int64_t) 288;\n    warp_byte_offset_43029 = sdiv_up64(warp_byte_offset_43028, (int64_t) 8) * (int64_t) 8 + (int64_t) 256;\n    // Allocate reusable shared memory\n    { }\n    local_mem_43030 = (__local unsigned char *) local_mem_43030_backing_0;\n    trans_arr_len_43031 = chunk_sizze_43005 * segscan_tblock_sizze_40310;\n    phys_block_id_43040 = get_tblock_id(0);\n    virtloop_bound_43041 = sdiv_up64(num_virt_blocks_43006 - phys_block_id_43040, num_tblocks_40312);\n    for (int64_t virtloop_i_43042 = 0; virtloop_i_43042 < virtloop_bound_43041; virtloop_i_43042++) {\n        int64_t dynamic_id_43043;\n        int64_t block_offset_43044;\n        int64_t sgm_idx_43045;\n        int32_t boundary_43046;\n        int32_t segsizze_compact_43047;\n        int64_t private_mem_43048[chunk_sizze_43005];\n        int64_t private_mem_43050[chunk_sizze_43005];\n        int64_t thd_offset_43052;\n        int64_t acc_43078;\n        int64_t acc_43079;\n        int64_t prefix_43092;\n        int64_t prefix_43093;\n        bool block_new_sgm_43094;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_43021 == 0) {\n                dynamic_id_43043 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_43018)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_43030)[(int64_t) 0] = dynamic_id_43043;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_43043 == num_virt_blocks_43006 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_43018)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_43043 = ((__local int32_t *) local_mem_43030)[(in",
                                    "t64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_43044 = dynamic_id_43043 * chunk_sizze_43005 * segscan_tblock_sizze_40310;\n        sgm_idx_43045 = smod64(block_offset_43044, m_39200);\n        boundary_43046 = sext_i64_i32(smin64(chunk_sizze_43005 * segscan_tblock_sizze_40310, m_39200 - sgm_idx_43045));\n        segsizze_compact_43047 = sext_i64_i32(smin64(chunk_sizze_43005 * segscan_tblock_sizze_40310, m_39200));\n        thd_offset_43052 = block_offset_43044 + sext_i32_i64(local_tid_43021);\n        // Load and map\n        {\n            for (int64_t i_43053 = 0; i_43053 < chunk_sizze_43005; i_43053++) {\n                int64_t virt_tid_43054 = thd_offset_43052 + i_43053 * segscan_tblock_sizze_40310;\n                int64_t slice_43055 = m_39200;\n                int64_t gtid_40314 = virt_tid_43054;\n                int64_t remnant_43056 = virt_tid_43054 - gtid_40314;\n                \n                if (slt64(virt_tid_43054, m_39200)) {\n                    int64_t x_39463 = ((__global int64_t *) mem_42377)[gtid_40314];\n                    bool lifted_lambda_res_39465 = slt64((int64_t) 1, x_39463);\n                    int64_t defunc_0_f_res_39466 = btoi_bool_i64(lifted_lambda_res_39465);\n                    \n                    ((__global int64_t *) mem_42391)[gtid_40314] = defunc_0_f_res_39466;\n                    private_mem_43048[i_43053] = x_39463;\n                    private_mem_43050[i_43053] = defunc_0_f_res_39466;\n                } else {\n                    private_mem_43048[i_43053] = (int64_t) 0;\n                    private_mem_43050[i_43053] = (int64_t) 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_43057 = 0; i_43057 < chunk_sizze_43005; i_43057++) {\n                int64_t sharedIdx_43058 = sext_i32_i64(local_tid_43021) + i_43057 * segscan_tblock_sizze_40310;\n                int64_t tmp_43059 = private_mem_43048[i_43057];\n         ", "       \n                ((__local int64_t *) local_mem_43030)[sharedIdx_43058] = tmp_43059;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_43060 = 0; i_43060 < chunk_sizze_43005; i_43060++) {\n                int64_t sharedIdx_43061 = sext_i32_i64(local_tid_43021) * chunk_sizze_43005 + i_43060;\n                int64_t tmp_43062 = ((__local int64_t *) local_mem_43030)[sharedIdx_43061];\n                \n                private_mem_43048[i_43060] = tmp_43062;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_43063 = 0; i_43063 < chunk_sizze_43005; i_43063++) {\n                int64_t sharedIdx_43064 = sext_i32_i64(local_tid_43021) + i_43063 * segscan_tblock_sizze_40310;\n                int64_t tmp_43065 = private_mem_43050[i_43063];\n                \n                ((__local int64_t *) local_mem_43030)[sharedIdx_43064] = tmp_43065;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_43066 = 0; i_43066 < chunk_sizze_43005; i_43066++) {\n                int64_t sharedIdx_43067 = sext_i32_i64(local_tid_43021) * chunk_sizze_43005 + i_43066;\n                int64_t tmp_43068 = ((__local int64_t *) local_mem_43030)[sharedIdx_43067];\n                \n                private_mem_43050[i_43066] = tmp_43068;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_43069 = 0; i_43069 < chunk_sizze_43005 - (int64_t) 1; i_43069++) {\n                int64_t eta_p_39237;\n                int64_t eta_p_39238;\n                \n                eta_p_39237 = private_mem_43048[i_43069];\n                eta_p_39238 = private_mem_43048[i_43069 + (int64_t) 1];\n                \n                int64_t eta_p_39330;\n                int64_t eta_p_39331;\n                \n                eta_p_39330 = private_mem_43050[i_43069];\n                eta_p_39331 = private_mem_43050[i_43069 + (int64_t) 1];\n                \n              ", "  int64_t lifted_lambda_res_39239 = add64(eta_p_39237, eta_p_39238);\n                int64_t defunc_0_op_res_39332 = add64(eta_p_39330, eta_p_39331);\n                \n                private_mem_43048[i_43069 + (int64_t) 1] = lifted_lambda_res_39239;\n                private_mem_43050[i_43069 + (int64_t) 1] = defunc_0_op_res_39332;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_43070 = private_mem_43048[chunk_sizze_43005 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_43030)[sext_i32_i64(local_tid_43021)] = tmp_43070;\n            \n            int64_t tmp_43071 = private_mem_43050[chunk_sizze_43005 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + sext_i32_i64(local_tid_43021)] = tmp_43071;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_43072;\n            int64_t eta_p_43073;\n            int64_t eta_p_43074;\n            int64_t eta_p_43075;\n            int64_t eta_p_43080;\n            int64_t eta_p_43081;\n            int64_t eta_p_43082;\n            int64_t eta_p_43083;\n            bool ltid_in_bounds_43086 = slt64(sext_i32_i64(local_tid_43021), num_virt_threads_43007);\n            int32_t skip_threads_43087;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_43086) {\n                    eta_p_43074 = ((volatile __local int64_t *) local_mem_43030)[sext_i32_i64(local_tid_43021)];\n                    eta_p_43075 = ((volatile __local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + sext_i32_i64(local_tid_43021)];\n                    if ((local_tid_43021 - squot32(local_tid_43021, 32) * 32) == 0) {\n                        eta_p_43072 = eta_p_43074;\n                        eta_p_43073 = eta_p_43075;\n                    }\n                }\n            }\n            // i",
                                    "n-block scan (hopefully no barriers needed)\n            {\n                skip_threads_43087 = 1;\n                while (slt32(skip_threads_43087, 32)) {\n                    bool thread_active_43088 = sle32(skip_threads_43087, local_tid_43021 - squot32(local_tid_43021, 32) * 32) && ltid_in_bounds_43086;\n                    \n                    if (thread_active_43088) {\n                        // read operands\n                        {\n                            eta_p_43072 = ((volatile __local int64_t *) local_mem_43030)[sext_i32_i64(local_tid_43021) - sext_i32_i64(skip_threads_43087)];\n                            eta_p_43073 = ((volatile __local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + (sext_i32_i64(local_tid_43021) - sext_i32_i64(skip_threads_43087))];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_43088) {\n                            int64_t lifted_lambda_res_43076 = add64(eta_p_43072, eta_p_43074);\n                            int64_t defunc_0_op_res_43077 = add64(eta_p_43073, eta_p_43075);\n                            \n                            eta_p_43072 = lifted_lambda_res_43076;\n                            eta_p_43073 = defunc_0_op_res_43077;\n                        }\n                    }\n                    if (sle32(wave_sizze_43023, skip_threads_43087)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_43088) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_43030)[sext_i32_i64(local_tid_43021)] = eta_p_43072;\n                            eta_p_43074 = eta_p_43072;\n                            ((volatile __local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + sext_i32_i64(local_tid_43021)] = eta_p_43073;\n                            eta_p_43075 = et", "a_p_43073;\n                        }\n                    }\n                    if (sle32(wave_sizze_43023, skip_threads_43087)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_43087 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_43021 - squot32(local_tid_43021, 32) * 32) == 31 && ltid_in_bounds_43086) {\n                    ((volatile __local int64_t *) local_mem_43030)[sext_i32_i64(squot32(local_tid_43021, 32))] = eta_p_43072;\n                    ((volatile __local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + sext_i32_i64(squot32(local_tid_43021, 32))] = eta_p_43073;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_43089;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_43021, 32) == 0 && ltid_in_bounds_43086) {\n                        eta_p_43082 = ((volatile __local int64_t *) local_mem_43030)[sext_i32_i64(local_tid_43021)];\n                        eta_p_43083 = ((volatile __local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + sext_i32_i64(local_tid_43021)];\n                        if ((local_tid_43021 - squot32(local_tid_43021, 32) * 32) == 0) {\n                            eta_p_43080 = eta_p_43082;\n                            eta_p_43081 = eta_p_43083;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_43089 = 1;\n                    while (slt32(skip_threads_43089, 32)) {\n                        bool thread_active_43090 = sle32(skip_th", "reads_43089, local_tid_43021 - squot32(local_tid_43021, 32) * 32) && (squot32(local_tid_43021, 32) == 0 && ltid_in_bounds_43086);\n                        \n                        if (thread_active_43090) {\n                            // read operands\n                            {\n                                eta_p_43080 = ((volatile __local int64_t *) local_mem_43030)[sext_i32_i64(local_tid_43021) - sext_i32_i64(skip_threads_43089)];\n                                eta_p_43081 = ((volatile __local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + (sext_i32_i64(local_tid_43021) - sext_i32_i64(skip_threads_43089))];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_43090) {\n                                int64_t lifted_lambda_res_43084 = add64(eta_p_43080, eta_p_43082);\n                                int64_t defunc_0_op_res_43085 = add64(eta_p_43081, eta_p_43083);\n                                \n                                eta_p_43080 = lifted_lambda_res_43084;\n                                eta_p_43081 = defunc_0_op_res_43085;\n                            }\n                        }\n                        if (sle32(wave_sizze_43023, skip_threads_43089)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_43090) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_43030)[sext_i32_i64(local_tid_43021)] = eta_p_43080;\n                                eta_p_43082 = eta_p_43080;\n                                ((volatile __local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + sext_i32_i64(local_tid_43021)] = eta_p_43081;\n                                eta_p_43083 = eta_p_43081;\n                            }\n                      ",
                                    "  }\n                        if (sle32(wave_sizze_43023, skip_threads_43089)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_43089 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_43091 = squot32(local_tid_43021, 32) == 0 || !ltid_in_bounds_43086;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_43091) {\n                        eta_p_43074 = eta_p_43072;\n                        eta_p_43075 = eta_p_43073;\n                        eta_p_43072 = ((__local int64_t *) local_mem_43030)[sext_i32_i64(squot32(local_tid_43021, 32)) - (int64_t) 1];\n                        eta_p_43073 = ((__local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + (sext_i32_i64(squot32(local_tid_43021, 32)) - (int64_t) 1)];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_43091) {\n                        int64_t lifted_lambda_res_43076 = add64(eta_p_43072, eta_p_43074);\n                        int64_t defunc_0_op_res_43077 = add64(eta_p_43073, eta_p_43075);\n                        \n                        eta_p_43072 = lifted_lambda_res_43076;\n                        eta_p_43073 = defunc_0_op_res_43077;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_43091) {\n                        ((__local int64_t *) local_mem_43030)[sext_i32_i64(local_tid_43021)] = eta_p_43072;\n                        ((__local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + sext_i32_i64(local_tid_43021)] = eta_p_43073;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // re", "store correct values for first block\n            {\n                if (squot32(local_tid_43021, 32) == 0 && ltid_in_bounds_43086) {\n                    ((__local int64_t *) local_mem_43030)[sext_i32_i64(local_tid_43021)] = eta_p_43074;\n                    ((__local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + sext_i32_i64(local_tid_43021)] = eta_p_43075;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_43021 == 0) {\n                acc_43078 = ((__local int64_t *) local_mem_43030)[segscan_tblock_sizze_40310 - (int64_t) 1];\n                acc_43079 = ((__local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + (segscan_tblock_sizze_40310 - (int64_t) 1)];\n            } else {\n                acc_43078 = ((__local int64_t *) local_mem_43030)[sext_i32_i64(local_tid_43021) - (int64_t) 1];\n                acc_43079 = ((__local int64_t *) local_mem_43030)[squot64(byte_offsets_43026, (int64_t) 8) + (sext_i32_i64(local_tid_43021) - (int64_t) 1)];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_43092 = (int64_t) 0;\n        prefix_43093 = (int64_t) 0;\n        block_new_sgm_43094 = sgm_idx_43045 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_43094 && local_tid_43021 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_43012)[dynamic_id_43043] = acc_43078;\n                ((volatile __global int64_t *) incprefixes_mem_43016)[dynamic_id_43043] = acc_43079;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_43008)[dynamic_id_43043] = (int8_t) 2;\n                acc_43078 = (int64_t) 0;\n                acc_43079 = (int64_t) 0;\n            }\n            if (!block_new_sgm_43094 && slt32(local_tid_43021, wave_sizze_43023)) {\n                if (local_tid_43021 == 0) {\n                    ((volatile __global int64", "_t *) aggregates_mem_43010)[dynamic_id_43043] = acc_43078;\n                    ((volatile __global int64_t *) aggregates_mem_43014)[dynamic_id_43043] = acc_43079;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_43008)[dynamic_id_43043] = (int8_t) 1;\n                    \n                    int8_t tmp_43095 = ((volatile __global int8_t *) status_flags_mem_43008)[dynamic_id_43043 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_43030)[(int64_t) 0] = tmp_43095;\n                }\n                mem_fence_local();\n                \n                int8_t status_43096 = ((__local int8_t *) local_mem_43030)[(int64_t) 0];\n                \n                if (status_43096 == (int8_t) 2) {\n                    if (local_tid_43021 == 0) {\n                        prefix_43092 = ((volatile __global int64_t *) incprefixes_mem_43012)[dynamic_id_43043 - (int64_t) 1];\n                        prefix_43093 = ((volatile __global int64_t *) incprefixes_mem_43016)[dynamic_id_43043 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_43097 = sext_i64_i32(dynamic_id_43043 - sext_i32_i64(wave_sizze_43023));\n                    \n                    while (slt32(wave_sizze_43023 * -1, readOffset_43097)) {\n                        int32_t read_i_43098 = readOffset_43097 + local_tid_43021;\n                        int64_t aggr_43099 = (int64_t) 0;\n                        int64_t aggr_43100 = (int64_t) 0;\n                        int8_t flag_43101 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_43098)) {\n                            flag_43101 = ((volatile __global int8_t *) status_flags_mem_43008)[sext_i32_i64(read_i_43098)];\n                            if (flag_43101 == (int8_t) 2) {\n                                aggr_43099 = ((volatile __global int64_t *) incprefixes_mem_43012)[sext_i32_i64(read_i_43098)];\n  ",
                                    "                              aggr_43100 = ((volatile __global int64_t *) incprefixes_mem_43016)[sext_i32_i64(read_i_43098)];\n                            } else if (flag_43101 == (int8_t) 1) {\n                                aggr_43099 = ((volatile __global int64_t *) aggregates_mem_43010)[sext_i32_i64(read_i_43098)];\n                                aggr_43100 = ((volatile __global int64_t *) aggregates_mem_43014)[sext_i32_i64(read_i_43098)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_43030)[(int64_t) 4 + sext_i32_i64(local_tid_43021)] = aggr_43099;\n                        ((__local int64_t *) local_mem_43030)[squot64(warp_byte_offset_43028, (int64_t) 8) + sext_i32_i64(local_tid_43021)] = aggr_43100;\n                        ((__local int8_t *) local_mem_43030)[sext_i32_i64(local_tid_43021)] = flag_43101;\n                        flag_43101 = ((__local int8_t *) local_mem_43030)[sext_i32_i64(wave_sizze_43023) - (int64_t) 1];\n                        if (slt8(flag_43101, (int8_t) 2)) {\n                            int8_t flg_x_43108;\n                            int8_t flg_y_43109;\n                            int64_t eta_p_43102;\n                            int64_t eta_p_43103;\n                            int64_t eta_p_43104;\n                            int64_t eta_p_43105;\n                            int32_t skip_threads_43110;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_43109 = ((volatile __local int8_t *) local_mem_43030)[sext_i32_i64(local_tid_43021)];\n                                eta_p_43104 = ((volatile __local int64_t *) local_mem_43030)[(int64_t) 4 + sext_i32_i64(local_tid_43021)];\n                                eta_p_43105 = ((volatile __local int64_t *) local_mem_43030)[squot64(warp_byte_offset_43028, (int64_t) 8) + sext_i32_i64(local_tid_43021)];\n                                i", "f ((local_tid_43021 - squot32(local_tid_43021, 32) * 32) == 0) {\n                                    eta_p_43102 = eta_p_43104;\n                                    eta_p_43103 = eta_p_43105;\n                                    flg_x_43108 = flg_y_43109;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_43110 = 1;\n                                while (slt32(skip_threads_43110, 32)) {\n                                    if (sle32(skip_threads_43110, local_tid_43021 - squot32(local_tid_43021, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_43108 = ((volatile __local int8_t *) local_mem_43030)[sext_i32_i64(local_tid_43021) - sext_i32_i64(skip_threads_43110)];\n                                            eta_p_43102 = ((volatile __local int64_t *) local_mem_43030)[(int64_t) 4 + (sext_i32_i64(local_tid_43021) - sext_i32_i64(skip_threads_43110))];\n                                            eta_p_43103 = ((volatile __local int64_t *) local_mem_43030)[squot64(warp_byte_offset_43028, (int64_t) 8) + (sext_i32_i64(local_tid_43021) - sext_i32_i64(skip_threads_43110))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_43109 == (int8_t) 2 || flg_y_43109 == (int8_t) 0) {\n                                                flg_x_43108 = flg_y_43109;\n                                                eta_p_43102 = eta_p_43104;\n                                                eta_p_43103 = eta_p_43105;\n                                            } else {\n                                                int64_t lifted_lambda_res_43106 = add64(eta_p_43102, eta_p_43104);\n   ", "                                             int64_t defunc_0_op_res_43107 = add64(eta_p_43103, eta_p_43105);\n                                                \n                                                eta_p_43102 = lifted_lambda_res_43106;\n                                                eta_p_43103 = defunc_0_op_res_43107;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_43030)[sext_i32_i64(local_tid_43021)] = flg_x_43108;\n                                            flg_y_43109 = flg_x_43108;\n                                            ((volatile __local int64_t *) local_mem_43030)[(int64_t) 4 + sext_i32_i64(local_tid_43021)] = eta_p_43102;\n                                            eta_p_43104 = eta_p_43102;\n                                            ((volatile __local int64_t *) local_mem_43030)[squot64(warp_byte_offset_43028, (int64_t) 8) + sext_i32_i64(local_tid_43021)] = eta_p_43103;\n                                            eta_p_43105 = eta_p_43103;\n                                        }\n                                    }\n                                    skip_threads_43110 *= 2;\n                                }\n                            }\n                        }\n                        flag_43101 = ((__local int8_t *) local_mem_43030)[sext_i32_i64(wave_sizze_43023) - (int64_t) 1];\n                        aggr_43099 = ((__local int64_t *) local_mem_43030)[(int64_t) 4 + (sext_i32_i64(wave_sizze_43023) - (int64_t) 1)];\n                        aggr_43100 = ((__local int64_t *) local_mem_43030)[squot64(warp_byte_offset_43028, (int64_t) 8) + (sext_i32_i64(wave_sizze_43023) - (int64_t) 1)];\n                        if (flag_43101 == (int8_t) 2) {\n                            readOffset_43097 = wave_sizze_43023 * -1;\n            ",
                                    "            } else if (flag_43101 == (int8_t) 1) {\n                            readOffset_43097 -= wave_sizze_43023;\n                        }\n                        if (slt8((int8_t) 0, flag_43101)) {\n                            int64_t eta_p_43111 = aggr_43099;\n                            int64_t eta_p_43112 = aggr_43100;\n                            int64_t eta_p_43113 = prefix_43092;\n                            int64_t eta_p_43114 = prefix_43093;\n                            int64_t lifted_lambda_res_43115 = add64(eta_p_43111, eta_p_43113);\n                            int64_t defunc_0_op_res_43116 = add64(eta_p_43112, eta_p_43114);\n                            \n                            prefix_43092 = lifted_lambda_res_43115;\n                            prefix_43093 = defunc_0_op_res_43116;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_43021 == 0) {\n                    if (boundary_43046 == sext_i64_i32(segscan_tblock_sizze_40310 * chunk_sizze_43005)) {\n                        int64_t eta_p_43117 = prefix_43092;\n                        int64_t eta_p_43118 = prefix_43093;\n                        int64_t eta_p_43119 = acc_43078;\n                        int64_t eta_p_43120 = acc_43079;\n                        int64_t lifted_lambda_res_43121 = add64(eta_p_43117, eta_p_43119);\n                        int64_t defunc_0_op_res_43122 = add64(eta_p_43118, eta_p_43120);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_43012)[dynamic_id_43043] = lifted_lambda_res_43121;\n                        ((volatile __global int64_t *) incprefixes_mem_43016)[dynamic_id_43043] = defunc_0_op_res_43122;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_43008)[dynamic_id_43043] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_43030)[(int64_t) 4] = pre", "fix_43092;\n                    ((__local int64_t *) local_mem_43030)[squot64(warp_byte_offset_43028, (int64_t) 8)] = prefix_43093;\n                    acc_43078 = (int64_t) 0;\n                    acc_43079 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_43043 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_43092 = ((__local int64_t *) local_mem_43030)[(int64_t) 4];\n                prefix_43093 = ((__local int64_t *) local_mem_43030)[squot64(warp_byte_offset_43028, (int64_t) 8)];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_43123;\n            int64_t eta_p_43125;\n            int64_t eta_p_43129 = prefix_43092;\n            int64_t eta_p_43131 = acc_43078;\n            int64_t eta_p_43124;\n            int64_t eta_p_43126;\n            int64_t eta_p_43130 = prefix_43093;\n            int64_t eta_p_43132 = acc_43079;\n            \n            if (slt32(local_tid_43021 * chunk_sizze_32b_43025, boundary_43046) && !block_new_sgm_43094) {\n                int64_t lifted_lambda_res_43133 = add64(eta_p_43129, eta_p_43131);\n                int64_t defunc_0_op_res_43134 = add64(eta_p_43130, eta_p_43132);\n                \n                eta_p_43123 = lifted_lambda_res_43133;\n                eta_p_43124 = defunc_0_op_res_43134;\n            } else {\n                eta_p_43123 = acc_43078;\n                eta_p_43124 = acc_43079;\n            }\n            \n            int32_t stopping_point_43135 = segsizze_compact_43047 - srem32(local_tid_43021 * chunk_sizze_32b_43025 - 1 + segsizze_compact_43047 - boundary_43046, segsizze_compact_43047);\n            \n            for (int64_t i_43136 = 0; i_43136 < chunk_sizze_43005; i_43136++) {\n                if (slt32(sext_i64_i32(i_43136), stopping_point_43135 - 1)) {\n                    eta_p_43125 = private_mem_43048[i_43136];\n                    eta_p_43126 = private_mem_43050[i_43136];\n", "                    \n                    int64_t lifted_lambda_res_43127 = add64(eta_p_43123, eta_p_43125);\n                    int64_t defunc_0_op_res_43128 = add64(eta_p_43124, eta_p_43126);\n                    \n                    private_mem_43048[i_43136] = lifted_lambda_res_43127;\n                    private_mem_43050[i_43136] = defunc_0_op_res_43128;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_43137 = 0; i_43137 < chunk_sizze_43005; i_43137++) {\n                int64_t sharedIdx_43138 = sext_i32_i64(local_tid_43021) * chunk_sizze_43005 + i_43137;\n                int64_t tmp_43139 = private_mem_43048[i_43137];\n                \n                ((__local int64_t *) local_mem_43030)[sharedIdx_43138] = tmp_43139;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_43140 = 0; i_43140 < chunk_sizze_43005; i_43140++) {\n                int64_t flat_idx_43141 = thd_offset_43052 + i_43140 * segscan_tblock_sizze_40310;\n                int64_t slice_43142 = m_39200;\n                int64_t gtid_40314 = flat_idx_43141;\n                int64_t remnant_43143 = flat_idx_43141 - gtid_40314;\n                \n                if (slt64(flat_idx_43141, m_39200)) {\n                    int64_t tmp_43144 = ((__local int64_t *) local_mem_43030)[flat_idx_43141 - block_offset_43044];\n                    \n                    ((__global int64_t *) mem_42387)[gtid_40314] = tmp_43144;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_43145 = 0; i_43145 < chunk_sizze_43005; i_43145++) {\n                int64_t sharedIdx_43146 = sext_i32_i64(local_tid_43021) * chunk_sizze_43005 + i_43145;\n                int64_t tmp_43147 = private_mem_43050[i_43145];\n                \n                ((__local int64_t *) local_mem_43030)[sharedIdx_43146] = tmp_43147;\n            }\n            barrier(CLK_LOCAL_M",
                                    "EM_FENCE);\n            for (int64_t i_43148 = 0; i_43148 < chunk_sizze_43005; i_43148++) {\n                int64_t flat_idx_43149 = thd_offset_43052 + i_43148 * segscan_tblock_sizze_40310;\n                int64_t slice_43150 = m_39200;\n                int64_t gtid_40314 = flat_idx_43149;\n                int64_t remnant_43151 = flat_idx_43149 - gtid_40314;\n                \n                if (slt64(flat_idx_43149, m_39200)) {\n                    int64_t tmp_43152 = ((__local int64_t *) local_mem_43030)[flat_idx_43149 - block_offset_43044];\n                    \n                    ((__global int64_t *) mem_42389)[gtid_40314] = tmp_43152;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_40310\n    #undef chunk_sizze_43005\n}\nFUTHARK_KERNEL_SIZED(max_idxzisegred_nonseg_39555_dim1, 1, 1)\nvoid max_idxzisegred_nonseg_39555(__global int *global_failure, int64_t nz2080U_37756, int64_t num_tblocks_39550, int64_t num_threads_42733, __global unsigned char *eta_p_mem_42199, __global unsigned char *mem_42201, __global unsigned char *counters_mem_42709, __global unsigned char *segred_tmp_mem_42731)\n{\n    #define segred_tblock_sizze_39548 (max_idxzisegred_nonseg_39555zisegred_tblock_sizze_39548)\n    #define chunk_sizze_42708 (max_idxzisegred_nonseg_39555zichunk_sizze_42708)\n    \n    volatile __local unsigned char *sync_arr_mem_42741_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_42741_backing_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i64_mem_42739_backing_0 = &shared_mem[sync_arr_mem_42741_backing_1_offset];\n    const int64_t red_arr_i64_mem_42739_backing_0_offset = sync_arr_mem_42741_backing_1_offset + ((int64_t) 8 * segred_tblock_sizze_39548 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_39548, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42735;\n    int32_t tblock_sizze_427", "38;\n    int32_t wave_sizze_42737;\n    int32_t block_id_42736;\n    int32_t global_tid_42734;\n    int64_t phys_tid_39555;\n    __local unsigned char *red_arr_i64_mem_42739;\n    __local unsigned char *sync_arr_mem_42741;\n    int64_t dummy_39553;\n    int64_t gtid_39554;\n    int64_t q_42743;\n    int64_t eta_p_block_res_acc_42744;\n    int64_t eta_p_38112;\n    int64_t eta_p_38113;\n    int64_t tblock_id_in_segment_42748;\n    int64_t block_base_offset_42749;\n    int32_t offset_42752;\n    int32_t skip_waves_42753;\n    int64_t eta_p_42745;\n    int64_t eta_p_42746;\n    int32_t old_counter_42754;\n    bool is_last_block_42755;\n    \n    local_tid_42735 = get_local_id(0);\n    tblock_sizze_42738 = get_local_size(0);\n    wave_sizze_42737 = LOCKSTEP_WIDTH;\n    block_id_42736 = get_tblock_id(0);\n    global_tid_42734 = block_id_42736 * tblock_sizze_42738 + local_tid_42735;\n    phys_tid_39555 = sext_i32_i64(global_tid_42734);\n    red_arr_i64_mem_42739 = (__local unsigned char *) red_arr_i64_mem_42739_backing_0;\n    sync_arr_mem_42741 = (__local unsigned char *) sync_arr_mem_42741_backing_1;\n    dummy_39553 = (int64_t) 0;\n    gtid_39554 = (int64_t) 0;\n    q_42743 = sdiv_up64(nz2080U_37756, sext_i32_i64(sext_i64_i32(segred_tblock_sizze_39548 * num_tblocks_39550)) * chunk_sizze_42708);\n    // ne-initialise the outer (per-block) accumulator(s)\n    {\n        eta_p_block_res_acc_42744 = (int64_t) -9223372036854775808;\n    }\n    tblock_id_in_segment_42748 = squot64(phys_tid_39555, segred_tblock_sizze_39548);\n    block_base_offset_42749 = tblock_id_in_segment_42748 * q_42743 * segred_tblock_sizze_39548;\n    for (int64_t i_42750 = 0; i_42750 < q_42743; i_42750++) {\n        int64_t block_offset_42751 = block_base_offset_42749 + i_42750 * segred_tblock_sizze_39548;\n        \n        gtid_39554 = phys_tid_39555 + num_threads_42733 * i_42750;\n        if (slt64(gtid_39554, nz2080U_37756)) {\n            // apply map function(s)\n            {\n                // apply map function\n                {\n       ", "             int64_t x_38111 = ((__global int64_t *) eta_p_mem_42199)[gtid_39554];\n                    \n                    // load accumulator(s)\n                    {\n                        eta_p_38112 = eta_p_block_res_acc_42744;\n                    }\n                    // load next value(s)\n                    {\n                        eta_p_38113 = x_38111;\n                    }\n                    // apply reduction operator(s)\n                    {\n                        int64_t max_res_38114 = smax64(eta_p_38112, eta_p_38113);\n                        \n                        // store in accumulator(s)\n                        {\n                            eta_p_block_res_acc_42744 = max_res_38114;\n                        }\n                    }\n                }\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // store accs. prims go in lmem; non-prims in params (in global mem)\n    {\n        ((__local int64_t *) red_arr_i64_mem_42739)[sext_i32_i64(local_tid_42735)] = eta_p_block_res_acc_42744;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    skip_waves_42753 = 1;\n    offset_42752 = 0;\n    // participating threads read initial accumulator\n    {\n        if (slt32(local_tid_42735, sext_i64_i32(segred_tblock_sizze_39548))) {\n            eta_p_42745 = ((__local int64_t *) red_arr_i64_mem_42739)[sext_i32_i64(local_tid_42735 + offset_42752)];\n        }\n    }\n    offset_42752 = 1;\n    while (slt32(offset_42752, wave_sizze_42737)) {\n        if (slt32(local_tid_42735 + offset_42752, sext_i64_i32(segred_tblock_sizze_39548)) && ((local_tid_42735 - squot32(local_tid_42735, wave_sizze_42737) * wave_sizze_42737) & (2 * offset_42752 - 1)) == 0) {\n            // read array element\n            {\n                eta_p_42746 = ((volatile __local int64_t *) red_arr_i64_mem_42739)[sext_i32_i64(local_tid_42735 + offset_42752)];\n            }\n            // apply reduction operation\n            {\n                int64_t max_res_42747 = smax64(eta_p_42745, eta_p_4274",
                                    "6);\n                \n                eta_p_42745 = max_res_42747;\n            }\n            // write result of operation\n            {\n                ((volatile __local int64_t *) red_arr_i64_mem_42739)[sext_i32_i64(local_tid_42735)] = eta_p_42745;\n            }\n        }\n        offset_42752 *= 2;\n    }\n    while (slt32(skip_waves_42753, squot32(sext_i64_i32(segred_tblock_sizze_39548) + wave_sizze_42737 - 1, wave_sizze_42737))) {\n        barrier(CLK_LOCAL_MEM_FENCE);\n        offset_42752 = skip_waves_42753 * wave_sizze_42737;\n        if (slt32(local_tid_42735 + offset_42752, sext_i64_i32(segred_tblock_sizze_39548)) && ((local_tid_42735 - squot32(local_tid_42735, wave_sizze_42737) * wave_sizze_42737) == 0 && (squot32(local_tid_42735, wave_sizze_42737) & (2 * skip_waves_42753 - 1)) == 0)) {\n            // read array element\n            {\n                eta_p_42746 = ((__local int64_t *) red_arr_i64_mem_42739)[sext_i32_i64(local_tid_42735 + offset_42752)];\n            }\n            // apply reduction operation\n            {\n                int64_t max_res_42747 = smax64(eta_p_42745, eta_p_42746);\n                \n                eta_p_42745 = max_res_42747;\n            }\n            // write result of operation\n            {\n                ((__local int64_t *) red_arr_i64_mem_42739)[sext_i32_i64(local_tid_42735)] = eta_p_42745;\n            }\n        }\n        skip_waves_42753 *= 2;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // thread 0 updates per-block acc(s); rest reset to ne\n    {\n        if (sext_i32_i64(local_tid_42735) == (int64_t) 0) {\n            eta_p_block_res_acc_42744 = eta_p_42745;\n        } else {\n            eta_p_block_res_acc_42744 = (int64_t) -9223372036854775808;\n        }\n    }\n    // first thread in block saves block result to global memory\n    {\n        if (local_tid_42735 == 0) {\n            ((__global int64_t *) segred_tmp_mem_42731)[sext_i32_i64(block_id_42736)] = eta_p_block_res_acc_42744;\n            mem", "_fence_global();\n            old_counter_42754 = atomic_add_i32_global(&((volatile __global int *) counters_mem_42709)[(int64_t) 0], (int) 1);\n            ((__local bool *) sync_arr_mem_42741)[(int64_t) 0] = old_counter_42754 == sext_i64_i32(num_tblocks_39550 - (int64_t) 1);\n        }\n    }\n    barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    is_last_block_42755 = ((__local bool *) sync_arr_mem_42741)[(int64_t) 0];\n    if (is_last_block_42755) {\n        if (local_tid_42735 == 0) {\n            old_counter_42754 = atomic_add_i32_global(&((volatile __global int *) counters_mem_42709)[(int64_t) 0], (int) sext_i64_i32((int64_t) 0 - num_tblocks_39550));\n        }\n        // read in the per-block-results\n        {\n            int64_t read_per_thread_42756 = sdiv_up64(num_tblocks_39550, segred_tblock_sizze_39548);\n            \n            eta_p_38112 = (int64_t) -9223372036854775808;\n            for (int64_t i_42757 = 0; i_42757 < read_per_thread_42756; i_42757++) {\n                int64_t block_res_id_42758 = sext_i32_i64(local_tid_42735) * read_per_thread_42756 + i_42757;\n                int64_t index_of_block_res_42759 = block_res_id_42758;\n                \n                if (slt64(block_res_id_42758, num_tblocks_39550)) {\n                    eta_p_38113 = ((__global int64_t *) segred_tmp_mem_42731)[index_of_block_res_42759];\n                    \n                    int64_t max_res_38114 = smax64(eta_p_38112, eta_p_38113);\n                    \n                    eta_p_38112 = max_res_38114;\n                }\n            }\n        }\n        ((__local int64_t *) red_arr_i64_mem_42739)[sext_i32_i64(local_tid_42735)] = eta_p_38112;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // reduce the per-block results\n        {\n            int32_t offset_42760;\n            int32_t skip_waves_42761 = 1;\n            int64_t eta_p_42745;\n            int64_t eta_p_42746;\n            \n            offset_42760 = 0;\n            // participating threads read initial accumulator\n    ", "        {\n                if (slt32(local_tid_42735, sext_i64_i32(segred_tblock_sizze_39548))) {\n                    eta_p_42745 = ((__local int64_t *) red_arr_i64_mem_42739)[sext_i32_i64(local_tid_42735 + offset_42760)];\n                }\n            }\n            offset_42760 = 1;\n            while (slt32(offset_42760, wave_sizze_42737)) {\n                if (slt32(local_tid_42735 + offset_42760, sext_i64_i32(segred_tblock_sizze_39548)) && ((local_tid_42735 - squot32(local_tid_42735, wave_sizze_42737) * wave_sizze_42737) & (2 * offset_42760 - 1)) == 0) {\n                    // read array element\n                    {\n                        eta_p_42746 = ((volatile __local int64_t *) red_arr_i64_mem_42739)[sext_i32_i64(local_tid_42735 + offset_42760)];\n                    }\n                    // apply reduction operation\n                    {\n                        int64_t max_res_42747 = smax64(eta_p_42745, eta_p_42746);\n                        \n                        eta_p_42745 = max_res_42747;\n                    }\n                    // write result of operation\n                    {\n                        ((volatile __local int64_t *) red_arr_i64_mem_42739)[sext_i32_i64(local_tid_42735)] = eta_p_42745;\n                    }\n                }\n                offset_42760 *= 2;\n            }\n            while (slt32(skip_waves_42761, squot32(sext_i64_i32(segred_tblock_sizze_39548) + wave_sizze_42737 - 1, wave_sizze_42737))) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                offset_42760 = skip_waves_42761 * wave_sizze_42737;\n                if (slt32(local_tid_42735 + offset_42760, sext_i64_i32(segred_tblock_sizze_39548)) && ((local_tid_42735 - squot32(local_tid_42735, wave_sizze_42737) * wave_sizze_42737) == 0 && (squot32(local_tid_42735, wave_sizze_42737) & (2 * skip_waves_42761 - 1)) == 0)) {\n                    // read array element\n                    {\n                        eta_p_42746 = ((__local int64_t *) red_arr_i64_mem_42739)[sext",
                                    "_i32_i64(local_tid_42735 + offset_42760)];\n                    }\n                    // apply reduction operation\n                    {\n                        int64_t max_res_42747 = smax64(eta_p_42745, eta_p_42746);\n                        \n                        eta_p_42745 = max_res_42747;\n                    }\n                    // write result of operation\n                    {\n                        ((__local int64_t *) red_arr_i64_mem_42739)[sext_i32_i64(local_tid_42735)] = eta_p_42745;\n                    }\n                }\n                skip_waves_42761 *= 2;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // and back to memory with the final result\n            {\n                if (local_tid_42735 == 0) {\n                    ((__global int64_t *) mem_42201)[(int64_t) 0] = eta_p_42745;\n                }\n            }\n        }\n    }\n    \n  error_5:\n    return;\n    #undef segred_tblock_sizze_39548\n    #undef chunk_sizze_42708\n}\nFUTHARK_KERNEL_SIZED(min_idxzisegred_nonseg_39545_dim1, 1, 1)\nvoid min_idxzisegred_nonseg_39545(__global int *global_failure, int64_t nz2080U_37716, int64_t num_tblocks_39540, int64_t num_threads_42733, __global unsigned char *eta_p_mem_42199, __global unsigned char *mem_42201, __global unsigned char *counters_mem_42709, __global unsigned char *segred_tmp_mem_42731)\n{\n    #define segred_tblock_sizze_39538 (min_idxzisegred_nonseg_39545zisegred_tblock_sizze_39538)\n    #define chunk_sizze_42708 (min_idxzisegred_nonseg_39545zichunk_sizze_42708)\n    \n    volatile __local unsigned char *sync_arr_mem_42741_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_42741_backing_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i64_mem_42739_backing_0 = &shared_mem[sync_arr_mem_42741_backing_1_offset];\n    const int64_t red_arr_i64_mem_42739_backing_0_offset = sync_arr_mem_42741_backing_1_offset + ((int64_t) 8 * segred_tblock_sizze_39538 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_395", "38, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_42735;\n    int32_t tblock_sizze_42738;\n    int32_t wave_sizze_42737;\n    int32_t block_id_42736;\n    int32_t global_tid_42734;\n    int64_t phys_tid_39545;\n    __local unsigned char *red_arr_i64_mem_42739;\n    __local unsigned char *sync_arr_mem_42741;\n    int64_t dummy_39543;\n    int64_t gtid_39544;\n    int64_t q_42743;\n    int64_t eta_p_block_res_acc_42744;\n    int64_t eta_p_38112;\n    int64_t eta_p_38113;\n    int64_t tblock_id_in_segment_42748;\n    int64_t block_base_offset_42749;\n    int32_t offset_42752;\n    int32_t skip_waves_42753;\n    int64_t eta_p_42745;\n    int64_t eta_p_42746;\n    int32_t old_counter_42754;\n    bool is_last_block_42755;\n    \n    local_tid_42735 = get_local_id(0);\n    tblock_sizze_42738 = get_local_size(0);\n    wave_sizze_42737 = LOCKSTEP_WIDTH;\n    block_id_42736 = get_tblock_id(0);\n    global_tid_42734 = block_id_42736 * tblock_sizze_42738 + local_tid_42735;\n    phys_tid_39545 = sext_i32_i64(global_tid_42734);\n    red_arr_i64_mem_42739 = (__local unsigned char *) red_arr_i64_mem_42739_backing_0;\n    sync_arr_mem_42741 = (__local unsigned char *) sync_arr_mem_42741_backing_1;\n    dummy_39543 = (int64_t) 0;\n    gtid_39544 = (int64_t) 0;\n    q_42743 = sdiv_up64(nz2080U_37716, sext_i32_i64(sext_i64_i32(segred_tblock_sizze_39538 * num_tblocks_39540)) * chunk_sizze_42708);\n    // ne-initialise the outer (per-block) accumulator(s)\n    {\n        eta_p_block_res_acc_42744 = (int64_t) 9223372036854775807;\n    }\n    tblock_id_in_segment_42748 = squot64(phys_tid_39545, segred_tblock_sizze_39538);\n    block_base_offset_42749 = tblock_id_in_segment_42748 * q_42743 * segred_tblock_sizze_39538;\n    for (int64_t i_42750 = 0; i_42750 < q_42743; i_42750++) {\n        int64_t block_offset_42751 = block_base_offset_42749 + i_42750 * segred_tblock_sizze_39538;\n        \n        gtid_39544 = phys_tid_39545 + num_threads_42733 * i_42750;\n        if (slt64", "(gtid_39544, nz2080U_37716)) {\n            // apply map function(s)\n            {\n                // apply map function\n                {\n                    int64_t x_38111 = ((__global int64_t *) eta_p_mem_42199)[gtid_39544];\n                    \n                    // load accumulator(s)\n                    {\n                        eta_p_38112 = eta_p_block_res_acc_42744;\n                    }\n                    // load next value(s)\n                    {\n                        eta_p_38113 = x_38111;\n                    }\n                    // apply reduction operator(s)\n                    {\n                        int64_t min_res_38114 = smin64(eta_p_38112, eta_p_38113);\n                        \n                        // store in accumulator(s)\n                        {\n                            eta_p_block_res_acc_42744 = min_res_38114;\n                        }\n                    }\n                }\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // store accs. prims go in lmem; non-prims in params (in global mem)\n    {\n        ((__local int64_t *) red_arr_i64_mem_42739)[sext_i32_i64(local_tid_42735)] = eta_p_block_res_acc_42744;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    skip_waves_42753 = 1;\n    offset_42752 = 0;\n    // participating threads read initial accumulator\n    {\n        if (slt32(local_tid_42735, sext_i64_i32(segred_tblock_sizze_39538))) {\n            eta_p_42745 = ((__local int64_t *) red_arr_i64_mem_42739)[sext_i32_i64(local_tid_42735 + offset_42752)];\n        }\n    }\n    offset_42752 = 1;\n    while (slt32(offset_42752, wave_sizze_42737)) {\n        if (slt32(local_tid_42735 + offset_42752, sext_i64_i32(segred_tblock_sizze_39538)) && ((local_tid_42735 - squot32(local_tid_42735, wave_sizze_42737) * wave_sizze_42737) & (2 * offset_42752 - 1)) == 0) {\n            // read array element\n            {\n                eta_p_42746 = ((volatile __local int64_t *) red_arr_i64_mem_42739)[sext_i32_i64(local_tid_42735 + offset_427",
                                    "52)];\n            }\n            // apply reduction operation\n            {\n                int64_t min_res_42747 = smin64(eta_p_42745, eta_p_42746);\n                \n                eta_p_42745 = min_res_42747;\n            }\n            // write result of operation\n            {\n                ((volatile __local int64_t *) red_arr_i64_mem_42739)[sext_i32_i64(local_tid_42735)] = eta_p_42745;\n            }\n        }\n        offset_42752 *= 2;\n    }\n    while (slt32(skip_waves_42753, squot32(sext_i64_i32(segred_tblock_sizze_39538) + wave_sizze_42737 - 1, wave_sizze_42737))) {\n        barrier(CLK_LOCAL_MEM_FENCE);\n        offset_42752 = skip_waves_42753 * wave_sizze_42737;\n        if (slt32(local_tid_42735 + offset_42752, sext_i64_i32(segred_tblock_sizze_39538)) && ((local_tid_42735 - squot32(local_tid_42735, wave_sizze_42737) * wave_sizze_42737) == 0 && (squot32(local_tid_42735, wave_sizze_42737) & (2 * skip_waves_42753 - 1)) == 0)) {\n            // read array element\n            {\n                eta_p_42746 = ((__local int64_t *) red_arr_i64_mem_42739)[sext_i32_i64(local_tid_42735 + offset_42752)];\n            }\n            // apply reduction operation\n            {\n                int64_t min_res_42747 = smin64(eta_p_42745, eta_p_42746);\n                \n                eta_p_42745 = min_res_42747;\n            }\n            // write result of operation\n            {\n                ((__local int64_t *) red_arr_i64_mem_42739)[sext_i32_i64(local_tid_42735)] = eta_p_42745;\n            }\n        }\n        skip_waves_42753 *= 2;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // thread 0 updates per-block acc(s); rest reset to ne\n    {\n        if (sext_i32_i64(local_tid_42735) == (int64_t) 0) {\n            eta_p_block_res_acc_42744 = eta_p_42745;\n        } else {\n            eta_p_block_res_acc_42744 = (int64_t) 9223372036854775807;\n        }\n    }\n    // first thread in block saves block result to global memory\n    {\n        if (local_tid_", "42735 == 0) {\n            ((__global int64_t *) segred_tmp_mem_42731)[sext_i32_i64(block_id_42736)] = eta_p_block_res_acc_42744;\n            mem_fence_global();\n            old_counter_42754 = atomic_add_i32_global(&((volatile __global int *) counters_mem_42709)[(int64_t) 0], (int) 1);\n            ((__local bool *) sync_arr_mem_42741)[(int64_t) 0] = old_counter_42754 == sext_i64_i32(num_tblocks_39540 - (int64_t) 1);\n        }\n    }\n    barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    is_last_block_42755 = ((__local bool *) sync_arr_mem_42741)[(int64_t) 0];\n    if (is_last_block_42755) {\n        if (local_tid_42735 == 0) {\n            old_counter_42754 = atomic_add_i32_global(&((volatile __global int *) counters_mem_42709)[(int64_t) 0], (int) sext_i64_i32((int64_t) 0 - num_tblocks_39540));\n        }\n        // read in the per-block-results\n        {\n            int64_t read_per_thread_42756 = sdiv_up64(num_tblocks_39540, segred_tblock_sizze_39538);\n            \n            eta_p_38112 = (int64_t) 9223372036854775807;\n            for (int64_t i_42757 = 0; i_42757 < read_per_thread_42756; i_42757++) {\n                int64_t block_res_id_42758 = sext_i32_i64(local_tid_42735) * read_per_thread_42756 + i_42757;\n                int64_t index_of_block_res_42759 = block_res_id_42758;\n                \n                if (slt64(block_res_id_42758, num_tblocks_39540)) {\n                    eta_p_38113 = ((__global int64_t *) segred_tmp_mem_42731)[index_of_block_res_42759];\n                    \n                    int64_t min_res_38114 = smin64(eta_p_38112, eta_p_38113);\n                    \n                    eta_p_38112 = min_res_38114;\n                }\n            }\n        }\n        ((__local int64_t *) red_arr_i64_mem_42739)[sext_i32_i64(local_tid_42735)] = eta_p_38112;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // reduce the per-block results\n        {\n            int32_t offset_42760;\n            int32_t skip_waves_42761 = 1;\n            int64_t eta_p_42745;", "\n            int64_t eta_p_42746;\n            \n            offset_42760 = 0;\n            // participating threads read initial accumulator\n            {\n                if (slt32(local_tid_42735, sext_i64_i32(segred_tblock_sizze_39538))) {\n                    eta_p_42745 = ((__local int64_t *) red_arr_i64_mem_42739)[sext_i32_i64(local_tid_42735 + offset_42760)];\n                }\n            }\n            offset_42760 = 1;\n            while (slt32(offset_42760, wave_sizze_42737)) {\n                if (slt32(local_tid_42735 + offset_42760, sext_i64_i32(segred_tblock_sizze_39538)) && ((local_tid_42735 - squot32(local_tid_42735, wave_sizze_42737) * wave_sizze_42737) & (2 * offset_42760 - 1)) == 0) {\n                    // read array element\n                    {\n                        eta_p_42746 = ((volatile __local int64_t *) red_arr_i64_mem_42739)[sext_i32_i64(local_tid_42735 + offset_42760)];\n                    }\n                    // apply reduction operation\n                    {\n                        int64_t min_res_42747 = smin64(eta_p_42745, eta_p_42746);\n                        \n                        eta_p_42745 = min_res_42747;\n                    }\n                    // write result of operation\n                    {\n                        ((volatile __local int64_t *) red_arr_i64_mem_42739)[sext_i32_i64(local_tid_42735)] = eta_p_42745;\n                    }\n                }\n                offset_42760 *= 2;\n            }\n            while (slt32(skip_waves_42761, squot32(sext_i64_i32(segred_tblock_sizze_39538) + wave_sizze_42737 - 1, wave_sizze_42737))) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                offset_42760 = skip_waves_42761 * wave_sizze_42737;\n                if (slt32(local_tid_42735 + offset_42760, sext_i64_i32(segred_tblock_sizze_39538)) && ((local_tid_42735 - squot32(local_tid_42735, wave_sizze_42737) * wave_sizze_42737) == 0 && (squot32(local_tid_42735, wave_sizze_42737) & (2 * skip_waves_42761 - 1)) == 0)) {\n       ", "             // read array element\n                    {\n                        eta_p_42746 = ((__local int64_t *) red_arr_i64_mem_42739)[sext_i32_i64(local_tid_42735 + offset_42760)];\n                    }\n                    // apply reduction operation\n                    {\n                        int64_t min_res_42747 = smin64(eta_p_42745, eta_p_42746);\n                        \n                        eta_p_42745 = min_res_42747;\n                    }\n                    // write result of operation\n                    {\n                        ((__local int64_t *) red_arr_i64_mem_42739)[sext_i32_i64(local_tid_42735)] = eta_p_42745;\n                    }\n                }\n                skip_waves_42761 *= 2;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // and back to memory with the final result\n            {\n                if (local_tid_42735 == 0) {\n                    ((__global int64_t *) mem_42201)[(int64_t) 0] = eta_p_42745;\n                }\n            }\n        }\n    }\n    \n  error_5:\n    return;\n    #undef segred_tblock_sizze_39538\n    #undef chunk_sizze_42708\n}\n", NULL};
// Start of gpu_prototypes.h

// Constants used for transpositions.  In principle these should be configurable.
#define TR_BLOCK_DIM 16
#define TR_TILE_DIM (TR_BLOCK_DIM*2)
#define TR_ELEMS_PER_THREAD 8

// Config stuff included in every GPU backend.
struct gpu_config {
  size_t default_block_size;
  size_t default_grid_size;
  size_t default_tile_size;
  size_t default_reg_tile_size;
  size_t default_cache;
  size_t default_shared_memory;
  size_t default_registers;
  size_t default_threshold;

  int default_block_size_changed;
  int default_grid_size_changed;
  int default_tile_size_changed;
};

// The following are dummy sizes that mean the concrete defaults
// will be set during initialisation via hardware-inspection-based
// heuristics.
struct gpu_config gpu_config_initial = {
  0
};

// Must be defined by the user.
static int gpu_macros(struct futhark_context *ctx, char*** names, int64_t** values);

static void gpu_init_log(struct futhark_context *ctx);
struct builtin_kernels* init_builtin_kernels(struct futhark_context* ctx);
void free_builtin_kernels(struct futhark_context* ctx, struct builtin_kernels* kernels);
static int gpu_free_all(struct futhark_context *ctx);

// End of gpu_prototypes.h

// Start of backends/cuda.h.

// Forward declarations.
// Invoked by setup_opencl() after the platform and device has been
// found, but before the program is loaded.  Its intended use is to
// tune constants based on the selected platform and device.
static void set_tuning_params(struct futhark_context* ctx);
static char* get_failure_msg(int failure_idx, int64_t args[]);

#define CUDA_SUCCEED_FATAL(x) cuda_api_succeed_fatal(x, #x, __FILE__, __LINE__)
#define CUDA_SUCCEED_NONFATAL(x) cuda_api_succeed_nonfatal(x, #x, __FILE__, __LINE__)
#define NVRTC_SUCCEED_FATAL(x) nvrtc_api_succeed_fatal(x, #x, __FILE__, __LINE__)
#define NVRTC_SUCCEED_NONFATAL(x) nvrtc_api_succeed_nonfatal(x, #x, __FILE__, __LINE__)
// Take care not to override an existing error.
#define CUDA_SUCCEED_OR_RETURN(e) {             \
    char *serror = CUDA_SUCCEED_NONFATAL(e);    \
    if (serror) {                               \
      if (!ctx->error) {                        \
        ctx->error = serror;                    \
      } else {                                  \
        free(serror);                           \
      }                                         \
      return bad;                               \
    }                                           \
  }

// CUDA_SUCCEED_OR_RETURN returns the value of the variable 'bad' in
// scope.  By default, it will be this one.  Create a local variable
// of some other type if needed.  This is a bit of a hack, but it
// saves effort in the code generator.
static const int bad = 1;

static inline void cuda_api_succeed_fatal(CUresult res, const char *call,
                                          const char *file, int line) {
  if (res != CUDA_SUCCESS) {
    const char *err_str;
    cuGetErrorString(res, &err_str);
    if (err_str == NULL) { err_str = "Unknown"; }
    futhark_panic(-1, "%s:%d: CUDA call\n  %s\nfailed with error code %d (%s)\n",
                  file, line, call, res, err_str);
  }
}

static char* cuda_api_succeed_nonfatal(CUresult res, const char *call,
                                       const char *file, int line) {
  if (res != CUDA_SUCCESS) {
    const char *err_str;
    cuGetErrorString(res, &err_str);
    if (err_str == NULL) { err_str = "Unknown"; }
    return msgprintf("%s:%d: CUDA call\n  %s\nfailed with error code %d (%s)\n",
                     file, line, call, res, err_str);
  } else {
    return NULL;
  }
}

static inline void nvrtc_api_succeed_fatal(nvrtcResult res, const char *call,
                                           const char *file, int line) {
  if (res != NVRTC_SUCCESS) {
    const char *err_str = nvrtcGetErrorString(res);
    futhark_panic(-1, "%s:%d: NVRTC call\n  %s\nfailed with error code %d (%s)\n",
                  file, line, call, res, err_str);
  }
}

static char* nvrtc_api_succeed_nonfatal(nvrtcResult res, const char *call,
                                        const char *file, int line) {
  if (res != NVRTC_SUCCESS) {
    const char *err_str = nvrtcGetErrorString(res);
    return msgprintf("%s:%d: NVRTC call\n  %s\nfailed with error code %d (%s)\n",
                     file, line, call, res, err_str);
  } else {
    return NULL;
  }
}

struct futhark_context_config {
  int in_use;
  int debugging;
  int profiling;
  int logging;
  char* cache_fname;
  int num_tuning_params;
  int64_t *tuning_params;
  const char** tuning_param_names;
  const char** tuning_param_vars;
  const char** tuning_param_classes;
  // Uniform fields above.

  char* program;
  int num_nvrtc_opts;
  char* *nvrtc_opts;

  char* preferred_device;
  int preferred_device_num;

  int unified_memory;

  char* dump_ptx_to;
  char* load_ptx_from;

  struct gpu_config gpu;
};

static void backend_context_config_setup(struct futhark_context_config *cfg) {
  cfg->num_nvrtc_opts = 0;
  cfg->nvrtc_opts = (char**) malloc(sizeof(char*));
  cfg->nvrtc_opts[0] = NULL;

  cfg->program = strconcat(gpu_program);

  cfg->preferred_device_num = 0;
  cfg->preferred_device = strdup("");

  cfg->dump_ptx_to = NULL;
  cfg->load_ptx_from = NULL;

  cfg->unified_memory = 2;

  cfg->gpu = gpu_config_initial;
  cfg->gpu.default_block_size = 256;
  cfg->gpu.default_tile_size = 32;
  cfg->gpu.default_reg_tile_size = 2;
  cfg->gpu.default_threshold = 32*1024;
}

static void backend_context_config_teardown(struct futhark_context_config* cfg) {
  for (int i = 0; i < cfg->num_nvrtc_opts; i++) {
    free(cfg->nvrtc_opts[i]);
  }
  free(cfg->nvrtc_opts);
  free(cfg->dump_ptx_to);
  free(cfg->load_ptx_from);
  free(cfg->preferred_device);
  free(cfg->program);
}

void futhark_context_config_add_nvrtc_option(struct futhark_context_config *cfg, const char *opt) {
  cfg->nvrtc_opts[cfg->num_nvrtc_opts] = strdup(opt);
  cfg->num_nvrtc_opts++;
  cfg->nvrtc_opts = (char **) realloc(cfg->nvrtc_opts, (cfg->num_nvrtc_opts + 1) * sizeof(char *));
  cfg->nvrtc_opts[cfg->num_nvrtc_opts] = NULL;
}

void futhark_context_config_set_device(struct futhark_context_config *cfg, const char *s) {
  int x = 0;
  if (*s == '#') {
    s++;
    while (isdigit(*s)) {
      x = x * 10 + (*s++)-'0';
    }
    // Skip trailing spaces.
    while (isspace(*s)) {
      s++;
    }
  }
  free(cfg->preferred_device);
  cfg->preferred_device = strdup(s);
  cfg->preferred_device_num = x;
}

const char* futhark_context_config_get_program(struct futhark_context_config *cfg) {
  return cfg->program;
}

void futhark_context_config_set_program(struct futhark_context_config *cfg, const char *s) {
  free(cfg->program);
  cfg->program = strdup(s);
}

void futhark_context_config_dump_ptx_to(struct futhark_context_config *cfg, const char *path) {
  free(cfg->dump_ptx_to);
  cfg->dump_ptx_to = strdup(path);
}

void futhark_context_config_load_ptx_from(struct futhark_context_config *cfg, const char *path) {
  free(cfg->load_ptx_from);
  cfg->load_ptx_from = strdup(path);
}

void futhark_context_config_set_unified_memory(struct futhark_context_config* cfg, int flag) {
  cfg->unified_memory = flag;
}

// A record of something that happened.
struct profiling_record {
  cudaEvent_t *events; // Points to two events.
  const char *name;
};

struct futhark_context {
  struct futhark_context_config* cfg;
  int detail_memory;
  int debugging;
  int profiling;
  int profiling_paused;
  int logging;
  lock_t lock;
  char *error;
  lock_t error_lock;
  FILE *log;
  struct constants *constants;
  struct free_list free_list;
  struct event_list event_list;
  int64_t peak_mem_usage_default;
  int64_t cur_mem_usage_default;
  struct program* program;
  bool program_initialised;
  // Uniform fields above.

  CUdeviceptr global_failure;
  CUdeviceptr global_failure_args;
  struct tuning_params tuning_params;
  // True if a potentially failing kernel has been enqueued.
  int32_t failure_is_an_option;
  int total_runs;
  long int total_runtime;
  int64_t peak_mem_usage_device;
  int64_t cur_mem_usage_device;

  CUdevice dev;
  CUcontext cu_ctx;
  CUmodule module;
  CUstream stream;

  struct free_list gpu_free_list;

  size_t max_thread_block_size;
  size_t max_grid_size;
  size_t max_tile_size;
  size_t max_threshold;
  size_t max_shared_memory;
  size_t max_bespoke;
  size_t max_registers;
  size_t max_cache;

  size_t lockstep_width;

  struct builtin_kernels* kernels;
};

#define CU_DEV_ATTR(x) (CU_DEVICE_ATTRIBUTE_##x)
#define device_query(dev,attrib) _device_query(dev, CU_DEV_ATTR(attrib))
static int _device_query(CUdevice dev, CUdevice_attribute attrib) {
  int val;
  CUDA_SUCCEED_FATAL(cuDeviceGetAttribute(&val, attrib, dev));
  return val;
}

#define CU_FUN_ATTR(x) (CU_FUNC_ATTRIBUTE_##x)
#define function_query(fn,attrib) _function_query(dev, CU_FUN_ATTR(attrib))
static int _function_query(CUfunction dev, CUfunction_attribute attrib) {
  int val;
  CUDA_SUCCEED_FATAL(cuFuncGetAttribute(&val, attrib, dev));
  return val;
}

static int cuda_device_setup(struct futhark_context *ctx) {
  struct futhark_context_config *cfg = ctx->cfg;
  char name[256];
  int count, chosen = -1, best_cc = -1;
  int cc_major_best = 0, cc_minor_best = 0;
  int cc_major = 0, cc_minor = 0;
  CUdevice dev;

  CUDA_SUCCEED_FATAL(cuDeviceGetCount(&count));
  if (count == 0) { return 1; }

  int num_device_matches = 0;

  // XXX: Current device selection policy is to choose the device with the
  // highest compute capability (if no preferred device is set).
  // This should maybe be changed, since greater compute capability is not
  // necessarily an indicator of better performance.
  for (int i = 0; i < count; i++) {
    CUDA_SUCCEED_FATAL(cuDeviceGet(&dev, i));

    cc_major = device_query(dev, COMPUTE_CAPABILITY_MAJOR);
    cc_minor = device_query(dev, COMPUTE_CAPABILITY_MINOR);

    CUDA_SUCCEED_FATAL(cuDeviceGetName(name, sizeof(name) - 1, dev));
    name[sizeof(name) - 1] = 0;

    if (cfg->logging) {
      fprintf(ctx->log, "Device #%d: name=\"%s\", compute capability=%d.%d\n",
              i, name, cc_major, cc_minor);
    }

    if (device_query(dev, COMPUTE_MODE) == CU_COMPUTEMODE_PROHIBITED) {
      if (cfg->logging) {
        fprintf(ctx->log, "Device #%d is compute-prohibited, ignoring\n", i);
      }
      continue;
    }

    if (best_cc == -1 || cc_major > cc_major_best ||
        (cc_major == cc_major_best && cc_minor > cc_minor_best)) {
      best_cc = i;
      cc_major_best = cc_major;
      cc_minor_best = cc_minor;
    }

    if (strstr(name, cfg->preferred_device) != NULL &&
        num_device_matches++ == cfg->preferred_device_num) {
      chosen = i;
      break;
    }
  }

  if (chosen == -1) { chosen = best_cc; }
  if (chosen == -1) { return 1; }

  if (cfg->logging) {
    fprintf(ctx->log, "Using device #%d\n", chosen);
  }

  CUDA_SUCCEED_FATAL(cuDeviceGet(&ctx->dev, chosen));
  return 0;
}

static const char *cuda_nvrtc_get_arch(CUdevice dev) {
  static struct {
    int major;
    int minor;
    const char *arch_str;
  } const x[] = {
    { 3, 0, "compute_30" },
    { 3, 2, "compute_32" },
    { 3, 5, "compute_35" },
    { 3, 7, "compute_37" },
    { 5, 0, "compute_50" },
    { 5, 2, "compute_52" },
    { 5, 3, "compute_53" },
    { 6, 0, "compute_60" },
    { 6, 1, "compute_61" },
    { 6, 2, "compute_62" },
    { 7, 0, "compute_70" },
    { 7, 2, "compute_72" },
    { 7, 5, "compute_75" },
    { 8, 0, "compute_80" },
    { 8, 6, "compute_80" },
    { 8, 7, "compute_80" }
  };

  int major = device_query(dev, COMPUTE_CAPABILITY_MAJOR);
  int minor = device_query(dev, COMPUTE_CAPABILITY_MINOR);

  int chosen = -1;
  int num_archs = sizeof(x)/sizeof(x[0]);
  for (int i = 0; i < num_archs; i++) {
    if (x[i].major < major || (x[i].major == major && x[i].minor <= minor)) {
      chosen = i;
    } else {
      break;
    }
  }

  if (chosen == -1) {
    futhark_panic(-1, "Unsupported compute capability %d.%d\n", major, minor);
  }

  if (x[chosen].major != major || x[chosen].minor != minor) {
    fprintf(stderr,
            "Warning: device compute capability is %d.%d, but newest supported by Futhark is %d.%d.\n",
            major, minor, x[chosen].major, x[chosen].minor);
  }

  return x[chosen].arch_str;
}

static void cuda_nvrtc_mk_build_options(struct futhark_context *ctx, const char *extra_opts[],
                                        char*** opts_out, size_t *n_opts) {
  int arch_set = 0, num_extra_opts;
  struct futhark_context_config *cfg = ctx->cfg;

  char** macro_names;
  int64_t* macro_vals;
  int num_macros = gpu_macros(ctx, &macro_names, &macro_vals);

  // nvrtc cannot handle multiple -arch options.  Hence, if one of the
  // extra_opts is -arch, we have to be careful not to do our usual
  // automatic generation.
  for (num_extra_opts = 0; extra_opts[num_extra_opts] != NULL; num_extra_opts++) {
    if (strstr(extra_opts[num_extra_opts], "-arch")
        == extra_opts[num_extra_opts] ||
        strstr(extra_opts[num_extra_opts], "--gpu-architecture")
        == extra_opts[num_extra_opts]) {
      arch_set = 1;
    }
  }

  size_t i = 0, n_opts_alloc = 20 + num_macros + num_extra_opts + cfg->num_tuning_params;
  char **opts = (char**) malloc(n_opts_alloc * sizeof(char *));
  if (!arch_set) {
    opts[i++] = strdup("-arch");
    opts[i++] = strdup(cuda_nvrtc_get_arch(ctx->dev));
  }
  opts[i++] = strdup("-default-device");
  if (cfg->debugging) {
    opts[i++] = strdup("-G");
    opts[i++] = strdup("-lineinfo");
  } else {
    opts[i++] = strdup("--disable-warnings");
  }
  opts[i++] = msgprintf("-D%s=%d",
                        "max_thread_block_size",
                        (int)ctx->max_thread_block_size);
  opts[i++] = msgprintf("-D%s=%d",
                        "max_shared_memory",
                        (int)ctx->max_shared_memory);
  opts[i++] = msgprintf("-D%s=%d",
                        "max_registers",
                        (int)ctx->max_registers);

  for (int j = 0; j < num_macros; j++) {
    opts[i++] = msgprintf("-D%s=%zu", macro_names[j], macro_vals[j]);
  }

  for (int j = 0; j < cfg->num_tuning_params; j++) {
    opts[i++] = msgprintf("-D%s=%zu", cfg->tuning_param_vars[j],
                          cfg->tuning_params[j]);
  }
  opts[i++] = msgprintf("-DLOCKSTEP_WIDTH=%zu", ctx->lockstep_width);
  opts[i++] = msgprintf("-DMAX_THREADS_PER_BLOCK=%zu", ctx->max_thread_block_size);

  // Time for the best lines of the code in the entire compiler.
  if (getenv("CUDA_HOME") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_HOME"));
  }
  if (getenv("CUDA_ROOT") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_ROOT"));
  }
  if (getenv("CUDA_PATH") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_PATH"));
  }
  opts[i++] = msgprintf("-I/usr/local/cuda/include");
  opts[i++] = msgprintf("-I/usr/include");

  for (int j = 0; extra_opts[j] != NULL; j++) {
    opts[i++] = strdup(extra_opts[j]);
  }

  opts[i++] = msgprintf("-DTR_BLOCK_DIM=%d", TR_BLOCK_DIM);
  opts[i++] = msgprintf("-DTR_TILE_DIM=%d", TR_TILE_DIM);
  opts[i++] = msgprintf("-DTR_ELEMS_PER_THREAD=%d", TR_ELEMS_PER_THREAD);

  free(macro_names);
  free(macro_vals);

  *n_opts = i;
  *opts_out = opts;
}

static char* cuda_nvrtc_build(const char *src, const char *opts[], size_t n_opts,
                              char **ptx) {
  nvrtcProgram prog;
  char *problem = NULL;

  problem = NVRTC_SUCCEED_NONFATAL(nvrtcCreateProgram(&prog, src, "futhark-cuda", 0, NULL, NULL));

  if (problem) {
    return problem;
  }

  nvrtcResult res = nvrtcCompileProgram(prog, n_opts, opts);
  if (res != NVRTC_SUCCESS) {
    size_t log_size;
    if (nvrtcGetProgramLogSize(prog, &log_size) == NVRTC_SUCCESS) {
      char *log = (char*) malloc(log_size);
      if (nvrtcGetProgramLog(prog, log) == NVRTC_SUCCESS) {
        problem = msgprintf("NVRTC compilation failed.\n\n%s\n", log);
      } else {
        problem = msgprintf("Could not retrieve compilation log\n");
      }
      free(log);
    }
    return problem;
  }

  size_t ptx_size;
  NVRTC_SUCCEED_FATAL(nvrtcGetPTXSize(prog, &ptx_size));
  *ptx = (char*) malloc(ptx_size);
  NVRTC_SUCCEED_FATAL(nvrtcGetPTX(prog, *ptx));

  NVRTC_SUCCEED_FATAL(nvrtcDestroyProgram(&prog));

  return NULL;
}

static void cuda_load_ptx_from_cache(struct futhark_context_config *cfg,
                                     const char *src,
                                     const char *opts[], size_t n_opts,
                                     struct cache_hash *h, const char *cache_fname,
                                     char **ptx) {
  if (cfg->logging) {
    fprintf(stderr, "Restoring cache from from %s...\n", cache_fname);
  }
  cache_hash_init(h);
  for (size_t i = 0; i < n_opts; i++) {
    cache_hash(h, opts[i], strlen(opts[i]));
  }
  cache_hash(h, src, strlen(src));
  size_t ptxsize;
  errno = 0;
  if (cache_restore(cache_fname, h, (unsigned char**)ptx, &ptxsize) != 0) {
    if (cfg->logging) {
      fprintf(stderr, "Failed to restore cache (errno: %s)\n", strerror(errno));
    }
  }
}

static void cuda_size_setup(struct futhark_context *ctx)
{
  struct futhark_context_config *cfg = ctx->cfg;
  if (cfg->gpu.default_block_size > ctx->max_thread_block_size) {
    if (cfg->gpu.default_block_size_changed) {
      fprintf(stderr,
              "Note: Device limits default block size to %zu (down from %zu).\n",
              ctx->max_thread_block_size, cfg->gpu.default_block_size);
    }
    cfg->gpu.default_block_size = ctx->max_thread_block_size;
  }
  if (cfg->gpu.default_grid_size > ctx->max_grid_size) {
    if (cfg->gpu.default_grid_size_changed) {
      fprintf(stderr,
              "Note: Device limits default grid size to %zu (down from %zu).\n",
              ctx->max_grid_size, cfg->gpu.default_grid_size);
    }
    cfg->gpu.default_grid_size = ctx->max_grid_size;
  }
  if (cfg->gpu.default_tile_size > ctx->max_tile_size) {
    if (cfg->gpu.default_tile_size_changed) {
      fprintf(stderr,
              "Note: Device limits default tile size to %zu (down from %zu).\n",
              ctx->max_tile_size, cfg->gpu.default_tile_size);
    }
    cfg->gpu.default_tile_size = ctx->max_tile_size;
  }

  if (!cfg->gpu.default_grid_size_changed) {
    cfg->gpu.default_grid_size =
      (device_query(ctx->dev, MULTIPROCESSOR_COUNT) *
       device_query(ctx->dev, MAX_THREADS_PER_MULTIPROCESSOR))
      / cfg->gpu.default_block_size;
  }

  for (int i = 0; i < cfg->num_tuning_params; i++) {
    const char *size_class = cfg->tuning_param_classes[i];
    int64_t *size_value = &cfg->tuning_params[i];
    const char* size_name = cfg->tuning_param_names[i];
    int64_t max_value = 0, default_value = 0;

    if (strstr(size_class, "thread_block_size") == size_class) {
      max_value = ctx->max_thread_block_size;
      default_value = cfg->gpu.default_block_size;
    } else if (strstr(size_class, "grid_size") == size_class) {
      max_value = ctx->max_grid_size;
      default_value = cfg->gpu.default_grid_size;
      // XXX: as a quick and dirty hack, use twice as many threads for
      // histograms by default.  We really should just be smarter
      // about sizes somehow.
      if (strstr(size_name, ".seghist_") != NULL) {
        default_value *= 2;
      }
    } else if (strstr(size_class, "tile_size") == size_class) {
      max_value = ctx->max_tile_size;
      default_value = cfg->gpu.default_tile_size;
    } else if (strstr(size_class, "reg_tile_size") == size_class) {
      max_value = 0; // No limit.
      default_value = cfg->gpu.default_reg_tile_size;
    } else if (strstr(size_class, "shared_memory") == size_class) {
      max_value = ctx->max_shared_memory;
      default_value = ctx->max_shared_memory;
    } else if (strstr(size_class, "cache") == size_class) {
      max_value = ctx->max_cache;
      default_value = ctx->max_cache;
    } else if (strstr(size_class, "threshold") == size_class) {
      // Threshold can be as large as it takes.
      default_value = cfg->gpu.default_threshold;
    } else {
      // Bespoke sizes have no limit or default.
    }

    if (*size_value == 0) {
      *size_value = default_value;
    } else if (max_value > 0 && *size_value > max_value) {
      fprintf(stderr, "Note: Device limits %s to %zu (down from %zu)\n",
              size_name, max_value, *size_value);
      *size_value = max_value;
    }
  }
}

static char* cuda_module_setup(struct futhark_context *ctx,
                               const char *src,
                               const char *extra_opts[],
                               const char* cache_fname) {
  char *ptx = NULL;
  struct futhark_context_config *cfg = ctx->cfg;

  if (cfg->load_ptx_from) {
    ptx = slurp_file(cfg->load_ptx_from, NULL);
  }

  char **opts;
  size_t n_opts;
  cuda_nvrtc_mk_build_options(ctx, extra_opts, &opts, &n_opts);

  if (cfg->logging) {
    fprintf(stderr, "NVRTC compile options:\n");
    for (size_t j = 0; j < n_opts; j++) {
      fprintf(stderr, "\t%s\n", opts[j]);
    }
    fprintf(stderr, "\n");
  }

  struct cache_hash h;
  int loaded_ptx_from_cache = 0;
  if (cache_fname != NULL) {
    cuda_load_ptx_from_cache(cfg, src, (const char**)opts, n_opts, &h, cache_fname, &ptx);

    if (ptx != NULL) {
      if (cfg->logging) {
        fprintf(stderr, "Restored PTX from cache; now loading module...\n");
      }
      if (cuModuleLoadData(&ctx->module, ptx) == CUDA_SUCCESS) {
        if (cfg->logging) {
          fprintf(stderr, "Success!\n");
        }
        loaded_ptx_from_cache = 1;
      } else {
        if (cfg->logging) {
          fprintf(stderr, "Failed!\n");
        }
        free(ptx);
        ptx = NULL;
      }
    }
  }

  if (ptx == NULL) {
    char* problem = cuda_nvrtc_build(src, (const char**)opts, n_opts, &ptx);
    if (problem != NULL) {
      return problem;
    }
  }

  if (cfg->dump_ptx_to != NULL) {
    dump_file(cfg->dump_ptx_to, ptx, strlen(ptx));
  }

  if (!loaded_ptx_from_cache) {
    CUDA_SUCCEED_FATAL(cuModuleLoadData(&ctx->module, ptx));
  }

  if (cache_fname != NULL && !loaded_ptx_from_cache) {
    if (cfg->logging) {
      fprintf(stderr, "Caching PTX in %s...\n", cache_fname);
    }
    errno = 0;
    if (cache_store(cache_fname, &h, (const unsigned char*)ptx, strlen(ptx)) != 0) {
      fprintf(stderr, "Failed to cache PTX: %s\n", strerror(errno));
    }
  }

  for (size_t i = 0; i < n_opts; i++) {
    free((char *)opts[i]);
  }
  free(opts);
  free(ptx);

  return NULL;
}

struct cuda_event {
  cudaEvent_t start;
  cudaEvent_t end;
};

static struct cuda_event* cuda_event_new(struct futhark_context* ctx) {
  if (ctx->profiling && !ctx->profiling_paused) {
    struct cuda_event* e = malloc(sizeof(struct cuda_event));
    cudaEventCreate(&e->start);
    cudaEventCreate(&e->end);
    return e;
  } else {
    return NULL;
  }
}

static int cuda_event_report(struct str_builder* sb, struct cuda_event* e) {
  float ms;
  CUresult err;
  if ((err = cuEventElapsedTime(&ms, e->start, e->end)) != CUDA_SUCCESS) {
    return err;
  }

  // CUDA provides milisecond resolution, but we want microseconds.
  str_builder(sb, ",\"duration\":%f", ms*1000);

  if ((err = cuEventDestroy(e->start)) != CUDA_SUCCESS) {
    return 1;
  }

  if ((err = cuEventDestroy(e->end)) != CUDA_SUCCESS) {
    return 1;
  }

  free(e);

  return 0;
}

int futhark_context_sync(struct futhark_context* ctx) {
  CUDA_SUCCEED_OR_RETURN(cuCtxPushCurrent(ctx->cu_ctx));
  CUDA_SUCCEED_OR_RETURN(cuCtxSynchronize());
  if (ctx->failure_is_an_option) {
    // Check for any delayed error.
    int32_t failure_idx;
    CUDA_SUCCEED_OR_RETURN(
                           cuMemcpyDtoH(&failure_idx,
                                        ctx->global_failure,
                                        sizeof(int32_t)));
    ctx->failure_is_an_option = 0;

    if (failure_idx >= 0) {
      // We have to clear global_failure so that the next entry point
      // is not considered a failure from the start.
      int32_t no_failure = -1;
      CUDA_SUCCEED_OR_RETURN(
                             cuMemcpyHtoD(ctx->global_failure,
                                          &no_failure,
                                          sizeof(int32_t)));

      int64_t args[max_failure_args+1];
      CUDA_SUCCEED_OR_RETURN(
                             cuMemcpyDtoH(&args,
                                          ctx->global_failure_args,
                                          sizeof(args)));

      ctx->error = get_failure_msg(failure_idx, args);

      return FUTHARK_PROGRAM_ERROR;
    }
  }

  CUDA_SUCCEED_OR_RETURN(cuCtxPopCurrent(&ctx->cu_ctx));
  return 0;
}

struct builtin_kernels* init_builtin_kernels(struct futhark_context* ctx);
void free_builtin_kernels(struct futhark_context* ctx, struct builtin_kernels* kernels);

int backend_context_setup(struct futhark_context* ctx) {
  ctx->failure_is_an_option = 0;
  ctx->total_runs = 0;
  ctx->total_runtime = 0;
  ctx->peak_mem_usage_device = 0;
  ctx->cur_mem_usage_device = 0;
  ctx->kernels = NULL;

  CUDA_SUCCEED_FATAL(cuInit(0));
  if (cuda_device_setup(ctx) != 0) {
    futhark_panic(-1, "No suitable CUDA device found.\n");
  }
  CUDA_SUCCEED_FATAL(cuCtxCreate(&ctx->cu_ctx, 0, ctx->dev));

  free_list_init(&ctx->gpu_free_list);

  if (ctx->cfg->unified_memory == 2) {
    ctx->cfg->unified_memory = device_query(ctx->dev, MANAGED_MEMORY);
  }

  if (ctx->cfg->logging) {
    if (ctx->cfg->unified_memory) {
      fprintf(ctx->log, "Using managed memory\n");
    } else {
      fprintf(ctx->log, "Using unmanaged memory\n");
    }
  }

  ctx->max_thread_block_size = device_query(ctx->dev, MAX_THREADS_PER_BLOCK);
  ctx->max_grid_size = device_query(ctx->dev, MAX_GRID_DIM_X);
  ctx->max_tile_size = sqrt(ctx->max_thread_block_size);
  ctx->max_threshold = 1U<<31; // No limit.
  ctx->max_bespoke = 1U<<31; // No limit.

  if (ctx->cfg->gpu.default_registers != 0) {
    ctx->max_registers = ctx->cfg->gpu.default_registers;
  } else {
    ctx->max_registers = device_query(ctx->dev, MAX_REGISTERS_PER_BLOCK);
  }

  if (ctx->cfg->gpu.default_shared_memory != 0) {
    ctx->max_shared_memory = ctx->cfg->gpu.default_shared_memory;
  } else {
    // MAX_SHARED_MEMORY_PER_BLOCK gives bogus numbers (48KiB); probably
    // for backwards compatibility.  Add _OPTIN and you seem to get the
    // right number.
    ctx->max_shared_memory = device_query(ctx->dev, MAX_SHARED_MEMORY_PER_BLOCK_OPTIN);
#if CUDART_VERSION >= 12000
    ctx->max_shared_memory -= device_query(ctx->dev, RESERVED_SHARED_MEMORY_PER_BLOCK);
#endif
  }

  if (ctx->cfg->gpu.default_cache != 0) {
    ctx->max_cache = ctx->cfg->gpu.default_cache;
  } else {
    ctx->max_cache = device_query(ctx->dev, L2_CACHE_SIZE);
  }

  ctx->lockstep_width = device_query(ctx->dev, WARP_SIZE);
  CUDA_SUCCEED_FATAL(cuStreamCreate(&ctx->stream, CU_STREAM_DEFAULT));
  cuda_size_setup(ctx);

  gpu_init_log(ctx);

  ctx->error = cuda_module_setup(ctx,
                                 ctx->cfg->program,
                                 (const char**)ctx->cfg->nvrtc_opts,
                                 ctx->cfg->cache_fname);

  if (ctx->error != NULL) {
    futhark_panic(1, "During CUDA initialisation:\n%s\n", ctx->error);
  }

  int32_t no_error = -1;
  CUDA_SUCCEED_FATAL(cuMemAlloc(&ctx->global_failure, sizeof(no_error)));
  CUDA_SUCCEED_FATAL(cuMemcpyHtoD(ctx->global_failure, &no_error, sizeof(no_error)));
  // The +1 is to avoid zero-byte allocations.
  CUDA_SUCCEED_FATAL(cuMemAlloc(&ctx->global_failure_args, sizeof(int64_t)*(max_failure_args+1)));

  if ((ctx->kernels = init_builtin_kernels(ctx)) == NULL) {
    return 1;
  }

  return 0;
}

void backend_context_teardown(struct futhark_context* ctx) {
  if (ctx->kernels != NULL) {
    free_builtin_kernels(ctx, ctx->kernels);
    cuMemFree(ctx->global_failure);
    cuMemFree(ctx->global_failure_args);
    CUDA_SUCCEED_FATAL(gpu_free_all(ctx));
    CUDA_SUCCEED_FATAL(cuStreamDestroy(ctx->stream));
    CUDA_SUCCEED_FATAL(cuModuleUnload(ctx->module));
    CUDA_SUCCEED_FATAL(cuCtxDestroy(ctx->cu_ctx));
  }
  free_list_destroy(&ctx->gpu_free_list);
}

// GPU ABSTRACTION LAYER

// Types.

typedef CUfunction gpu_kernel;
typedef CUdeviceptr gpu_mem;

static void gpu_create_kernel(struct futhark_context *ctx,
                              gpu_kernel* kernel,
                              const char* name) {
  if (ctx->debugging) {
    fprintf(ctx->log, "Creating kernel %s.\n", name);
  }
  CUDA_SUCCEED_FATAL(cuModuleGetFunction(kernel, ctx->module, name));
  // Unless the below is set, the kernel is limited to 48KiB of memory.
  CUDA_SUCCEED_FATAL(cuFuncSetAttribute(*kernel,
                                        cudaFuncAttributeMaxDynamicSharedMemorySize,
                                        ctx->max_shared_memory));
}

static void gpu_free_kernel(struct futhark_context *ctx,
                            gpu_kernel kernel) {
  (void)ctx;
  (void)kernel;
}

static int gpu_scalar_to_device(struct futhark_context* ctx,
                                gpu_mem dst, size_t offset, size_t size,
                                void *src) {
  struct cuda_event *event = cuda_event_new(ctx);
  if (event != NULL) {
    add_event(ctx,
              "copy_scalar_to_dev",
              strdup(""),
              event,
              (event_report_fn)cuda_event_report);
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
  }
  CUDA_SUCCEED_OR_RETURN(cuMemcpyHtoD(dst + offset, src, size));
  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }
  return FUTHARK_SUCCESS;
}

static int gpu_scalar_from_device(struct futhark_context* ctx,
                                  void *dst,
                                  gpu_mem src, size_t offset, size_t size) {
  struct cuda_event *event = cuda_event_new(ctx);
  if (event != NULL) {
    add_event(ctx,
              "copy_scalar_from_dev",
              strdup(""),
              event,
              (event_report_fn)cuda_event_report);
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
  }
  CUDA_SUCCEED_OR_RETURN(cuMemcpyDtoH(dst, src + offset, size));
  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }
  return FUTHARK_SUCCESS;
}

static int gpu_memcpy(struct futhark_context* ctx,
                      gpu_mem dst, int64_t dst_offset,
                      gpu_mem src, int64_t src_offset,
                      int64_t nbytes) {
  struct cuda_event *event = cuda_event_new(ctx);
  if (event != NULL) {
    add_event(ctx,
              "copy_dev_to_dev",
              strdup(""),
              event,
              (event_report_fn)cuda_event_report);
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
  }
  CUDA_SUCCEED_OR_RETURN(cuMemcpyAsync(dst+dst_offset, src+src_offset, nbytes, ctx->stream));
  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }
  return FUTHARK_SUCCESS;
}

static int memcpy_host2gpu(struct futhark_context* ctx, bool sync,
                           gpu_mem dst, int64_t dst_offset,
                           const unsigned char* src, int64_t src_offset,
                           int64_t nbytes) {
  if (nbytes > 0) {
    struct cuda_event *event = cuda_event_new(ctx);
    if (event != NULL) {
      add_event(ctx,
                "copy_host_to_dev",
                strdup(""),
                event,
                (event_report_fn)cuda_event_report);
      CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
    }
    if (sync) {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyHtoD(dst + dst_offset, src + src_offset, nbytes));
    } else {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyHtoDAsync(dst + dst_offset, src + src_offset, nbytes, ctx->stream));
    }
    if (event != NULL) {
      CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
    }
  }
  return FUTHARK_SUCCESS;
}

static int memcpy_gpu2host(struct futhark_context* ctx, bool sync,
                           unsigned char* dst, int64_t dst_offset,
                           gpu_mem src, int64_t src_offset,
                           int64_t nbytes) {
  if (nbytes > 0) {
    struct cuda_event *event = cuda_event_new(ctx);
    if (event != NULL) {
      add_event(ctx,
                "copy_dev_to_host",
                strdup(""),
                event,
                (event_report_fn)cuda_event_report);
      CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
    }
    if (sync) {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyDtoH(dst + dst_offset, src + src_offset, nbytes));
    } else {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyDtoHAsync(dst + dst_offset, src + src_offset, nbytes, ctx->stream));
    }
    if (event != NULL) {
      CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
    }
    if (sync &&
        ctx->failure_is_an_option &&
        futhark_context_sync(ctx) != 0) {
      return 1;
    }
  }
  return FUTHARK_SUCCESS;
}

static int gpu_launch_kernel(struct futhark_context* ctx,
                             gpu_kernel kernel, const char *name,
                             const int32_t grid[3],
                             const int32_t block[3],
                             unsigned int shared_mem_bytes,
                             int num_args,
                             void* args[num_args],
                             size_t args_sizes[num_args]) {
  (void) args_sizes;

  if (shared_mem_bytes > ctx->max_shared_memory) {
    set_error(ctx, msgprintf("Kernel %s with %d bytes of memory exceeds device limit of %d\n",
                             name, shared_mem_bytes, (int)ctx->max_shared_memory));
    return 1;
  }

  int64_t time_start = 0, time_end = 0;
  if (ctx->debugging) {
    time_start = get_wall_time();
  }

  struct cuda_event *event = cuda_event_new(ctx);

  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
    add_event(ctx,
              name,
              msgprintf("Kernel %s with\n"
                        "  grid=(%d,%d,%d)\n"
                        "  block=(%d,%d,%d)\n"
                        "  shared memory=%d",
                        name,
                        grid[0], grid[1], grid[2],
                        block[0], block[1], block[2],
                        shared_mem_bytes),
              event,
              (event_report_fn)cuda_event_report);
  }

  CUDA_SUCCEED_OR_RETURN
    (cuLaunchKernel(kernel,
                    grid[0], grid[1], grid[2],
                    block[0], block[1], block[2],
                    shared_mem_bytes, ctx->stream,
                    args, NULL));

  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }

  if (ctx->debugging) {
    CUDA_SUCCEED_FATAL(cuCtxSynchronize());
    time_end = get_wall_time();
    long int time_diff = time_end - time_start;
    fprintf(ctx->log, "  runtime: %ldus\n", time_diff);
  }
  if (ctx->logging) {
    fprintf(ctx->log, "\n");
  }

  return FUTHARK_SUCCESS;
}

static int gpu_alloc_actual(struct futhark_context *ctx, size_t size, gpu_mem *mem_out) {
  CUresult res;
  if (ctx->cfg->unified_memory) {
    res = cuMemAllocManaged(mem_out, size, CU_MEM_ATTACH_GLOBAL);
  } else {
    res = cuMemAlloc(mem_out, size);
  }

  if (res == CUDA_ERROR_OUT_OF_MEMORY) {
    return FUTHARK_OUT_OF_MEMORY;
  }

  CUDA_SUCCEED_OR_RETURN(res);
  return FUTHARK_SUCCESS;
}

static int gpu_free_actual(struct futhark_context *ctx, gpu_mem mem) {
  (void)ctx;
  CUDA_SUCCEED_OR_RETURN(cuMemFree(mem));
  return FUTHARK_SUCCESS;
}

// End of backends/cuda.h.

// Start of gpu.h

// Generic functions that use our tiny GPU abstraction layer.  The
// entire context must be defined before this header is included.  In
// particular we expect the following functions to be available:

static int gpu_free_actual(struct futhark_context *ctx, gpu_mem mem);
static int gpu_alloc_actual(struct futhark_context *ctx, size_t size, gpu_mem *mem_out);
int gpu_launch_kernel(struct futhark_context* ctx,
                      gpu_kernel kernel, const char *name,
                      const int32_t grid[3],
                      const int32_t block[3],
                      unsigned int shared_mem_bytes,
                      int num_args,
                      void* args[num_args],
                      size_t args_sizes[num_args]);
int gpu_memcpy(struct futhark_context* ctx,
               gpu_mem dst, int64_t dst_offset,
               gpu_mem src, int64_t src_offset,
               int64_t nbytes);
int gpu_scalar_from_device(struct futhark_context* ctx,
                           void *dst,
                           gpu_mem src, size_t offset, size_t size);
int gpu_scalar_to_device(struct futhark_context* ctx,
                         gpu_mem dst, size_t offset, size_t size,
                         void *src);
void gpu_create_kernel(struct futhark_context *ctx,
                       gpu_kernel* kernel,
                       const char* name);

static void gpu_init_log(struct futhark_context *ctx) {
  if (ctx->cfg->logging) {
    fprintf(ctx->log, "Default block size: %ld\n", (long)ctx->cfg->gpu.default_block_size);
    fprintf(ctx->log, "Default grid size: %ld\n", (long)ctx->cfg->gpu.default_grid_size);
    fprintf(ctx->log, "Default tile size: %ld\n", (long)ctx->cfg->gpu.default_tile_size);
    fprintf(ctx->log, "Default register tile size: %ld\n", (long)ctx->cfg->gpu.default_reg_tile_size);
    fprintf(ctx->log, "Default cache: %ld\n", (long)ctx->cfg->gpu.default_cache);
    fprintf(ctx->log, "Default registers: %ld\n", (long)ctx->cfg->gpu.default_registers);
    fprintf(ctx->log, "Default threshold: %ld\n", (long)ctx->cfg->gpu.default_threshold);
    fprintf(ctx->log, "Max thread block size: %ld\n", (long)ctx->max_thread_block_size);
    fprintf(ctx->log, "Max grid size: %ld\n", (long)ctx->max_grid_size);
    fprintf(ctx->log, "Max tile size: %ld\n", (long)ctx->max_tile_size);
    fprintf(ctx->log, "Max threshold: %ld\n", (long)ctx->max_threshold);
    fprintf(ctx->log, "Max shared memory: %ld\n", (long)ctx->max_shared_memory);
    fprintf(ctx->log, "Max registers: %ld\n", (long)ctx->max_registers);
    fprintf(ctx->log, "Max cache: %ld\n", (long)ctx->max_cache);
    fprintf(ctx->log, "Lockstep width: %ld\n", (long)ctx->lockstep_width);
  }
}

// Generic GPU command line options.

void futhark_context_config_set_default_thread_block_size(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_block_size = size;
  cfg->gpu.default_block_size_changed = 1;
}

void futhark_context_config_set_default_group_size(struct futhark_context_config *cfg, int size) {
  futhark_context_config_set_default_thread_block_size(cfg, size);
}

void futhark_context_config_set_default_grid_size(struct futhark_context_config *cfg, int num) {
  cfg->gpu.default_grid_size = num;
  cfg->gpu.default_grid_size_changed = 1;
}

void futhark_context_config_set_default_num_groups(struct futhark_context_config *cfg, int num) {
  futhark_context_config_set_default_grid_size(cfg, num);
}

void futhark_context_config_set_default_tile_size(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_tile_size = size;
  cfg->gpu.default_tile_size_changed = 1;
}

void futhark_context_config_set_default_reg_tile_size(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_reg_tile_size = size;
}

void futhark_context_config_set_default_cache(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_cache = size;
}

void futhark_context_config_set_default_registers(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_registers = size;
}

void futhark_context_config_set_default_threshold(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_threshold = size;
}

int futhark_context_config_set_tuning_param(struct futhark_context_config *cfg,
                                            const char *param_name,
                                            size_t new_value) {
  for (int i = 0; i < cfg->num_tuning_params; i++) {
    if (strcmp(param_name, cfg->tuning_param_names[i]) == 0) {
      cfg->tuning_params[i] = new_value;
      return 0;
    }
  }
  if (strcmp(param_name, "default_thread_block_size") == 0 ||
      strcmp(param_name, "default_group_size") == 0) {
    cfg->gpu.default_block_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_grid_size") == 0 ||
      strcmp(param_name, "default_num_groups") == 0) {
    cfg->gpu.default_grid_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_threshold") == 0) {
    cfg->gpu.default_threshold = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_tile_size") == 0) {
    cfg->gpu.default_tile_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_reg_tile_size") == 0) {
    cfg->gpu.default_reg_tile_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_cache") == 0) {
    cfg->gpu.default_cache = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_shared_memory") == 0) {
    cfg->gpu.default_shared_memory = new_value;
    return 0;
  }

  return 1;
}

// End of GPU command line optiopns.

// Max number of thead blocks we allow along the second or third
// dimension for transpositions.
#define MAX_TR_THREAD_BLOCKS 65535

struct builtin_kernels {
  // We have a lot of ways to transpose arrays.
  gpu_kernel map_transpose_1b;
  gpu_kernel map_transpose_1b_low_height;
  gpu_kernel map_transpose_1b_low_width;
  gpu_kernel map_transpose_1b_small;
  gpu_kernel map_transpose_1b_large;
  gpu_kernel map_transpose_2b;
  gpu_kernel map_transpose_2b_low_height;
  gpu_kernel map_transpose_2b_low_width;
  gpu_kernel map_transpose_2b_small;
  gpu_kernel map_transpose_2b_large;
  gpu_kernel map_transpose_4b;
  gpu_kernel map_transpose_4b_low_height;
  gpu_kernel map_transpose_4b_low_width;
  gpu_kernel map_transpose_4b_small;
  gpu_kernel map_transpose_4b_large;
  gpu_kernel map_transpose_8b;
  gpu_kernel map_transpose_8b_low_height;
  gpu_kernel map_transpose_8b_low_width;
  gpu_kernel map_transpose_8b_small;
  gpu_kernel map_transpose_8b_large;

  // And a few ways of copying.
  gpu_kernel lmad_copy_1b;
  gpu_kernel lmad_copy_2b;
  gpu_kernel lmad_copy_4b;
  gpu_kernel lmad_copy_8b;
};

struct builtin_kernels* init_builtin_kernels(struct futhark_context* ctx) {
  struct builtin_kernels *kernels = malloc(sizeof(struct builtin_kernels));
  gpu_create_kernel(ctx, &kernels->map_transpose_1b, "map_transpose_1b");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_large, "map_transpose_1b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_low_height, "map_transpose_1b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_low_width, "map_transpose_1b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_small, "map_transpose_1b_small");

  gpu_create_kernel(ctx, &kernels->map_transpose_2b, "map_transpose_2b");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_large, "map_transpose_2b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_low_height, "map_transpose_2b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_low_width, "map_transpose_2b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_small, "map_transpose_2b_small");

  gpu_create_kernel(ctx, &kernels->map_transpose_4b, "map_transpose_4b");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_large, "map_transpose_4b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_low_height, "map_transpose_4b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_low_width, "map_transpose_4b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_small, "map_transpose_4b_small");

  gpu_create_kernel(ctx, &kernels->map_transpose_8b, "map_transpose_8b");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_large, "map_transpose_8b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_low_height, "map_transpose_8b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_low_width, "map_transpose_8b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_small, "map_transpose_8b_small");

  gpu_create_kernel(ctx, &kernels->lmad_copy_1b, "lmad_copy_1b");
  gpu_create_kernel(ctx, &kernels->lmad_copy_2b, "lmad_copy_2b");
  gpu_create_kernel(ctx, &kernels->lmad_copy_4b, "lmad_copy_4b");
  gpu_create_kernel(ctx, &kernels->lmad_copy_8b, "lmad_copy_8b");

  return kernels;
}

void free_builtin_kernels(struct futhark_context* ctx, struct builtin_kernels* kernels) {
  gpu_free_kernel(ctx, kernels->map_transpose_1b);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_small);

  gpu_free_kernel(ctx, kernels->map_transpose_2b);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_small);

  gpu_free_kernel(ctx, kernels->map_transpose_4b);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_small);

  gpu_free_kernel(ctx, kernels->map_transpose_8b);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_small);

  gpu_free_kernel(ctx, kernels->lmad_copy_1b);
  gpu_free_kernel(ctx, kernels->lmad_copy_2b);
  gpu_free_kernel(ctx, kernels->lmad_copy_4b);
  gpu_free_kernel(ctx, kernels->lmad_copy_8b);

  free(kernels);
}

static int gpu_alloc(struct futhark_context *ctx, FILE *log,
                     size_t min_size, const char *tag,
                     gpu_mem *mem_out, size_t *size_out) {
  if (min_size < sizeof(int)) {
    min_size = sizeof(int);
  }

  gpu_mem* memptr;
  if (free_list_find(&ctx->gpu_free_list, min_size, tag, size_out, (fl_mem*)&memptr) == 0) {
    // Successfully found a free block.  Is it big enough?
    if (*size_out >= min_size) {
      if (ctx->cfg->debugging) {
        fprintf(log, "No need to allocate: Found a block in the free list.\n");
      }
      *mem_out = *memptr;
      free(memptr);
      return FUTHARK_SUCCESS;
    } else {
      if (ctx->cfg->debugging) {
        fprintf(log, "Found a free block, but it was too small.\n");
      }
      int error = gpu_free_actual(ctx, *memptr);
      free(memptr);
      if (error != FUTHARK_SUCCESS) {
        return error;
      }
    }
  }

  *size_out = min_size;

  // We have to allocate a new block from the driver.  If the
  // allocation does not succeed, then we might be in an out-of-memory
  // situation.  We now start freeing things from the free list until
  // we think we have freed enough that the allocation will succeed.
  // Since we don't know how far the allocation is from fitting, we
  // have to check after every deallocation.  This might be pretty
  // expensive.  Let's hope that this case is hit rarely.

  if (ctx->cfg->debugging) {
    fprintf(log, "Actually allocating the desired block.\n");
  }

  int error = gpu_alloc_actual(ctx, min_size, mem_out);

  while (error == FUTHARK_OUT_OF_MEMORY) {
    if (ctx->cfg->debugging) {
      fprintf(log, "Out of GPU memory: releasing entry from the free list...\n");
    }
    gpu_mem* memptr;
    if (free_list_first(&ctx->gpu_free_list, (fl_mem*)&memptr) == 0) {
      gpu_mem mem = *memptr;
      free(memptr);
      error = gpu_free_actual(ctx, mem);
      if (error != FUTHARK_SUCCESS) {
        return error;
      }
    } else {
      break;
    }
    error = gpu_alloc_actual(ctx, min_size, mem_out);
  }

  return error;
}

static int gpu_free(struct futhark_context *ctx,
                    gpu_mem mem, size_t size, const char *tag) {
  gpu_mem* memptr = malloc(sizeof(gpu_mem));
  *memptr = mem;
  free_list_insert(&ctx->gpu_free_list, size, (fl_mem)memptr, tag);
  return FUTHARK_SUCCESS;
}

static int gpu_free_all(struct futhark_context *ctx) {
  free_list_pack(&ctx->gpu_free_list);
  gpu_mem* memptr;
  while (free_list_first(&ctx->gpu_free_list, (fl_mem*)&memptr) == 0) {
    gpu_mem mem = *memptr;
    free(memptr);
    int error = gpu_free_actual(ctx, mem);
    if (error != FUTHARK_SUCCESS) {
      return error;
    }
  }

  return FUTHARK_SUCCESS;
}

static int gpu_map_transpose(struct futhark_context* ctx,
                             gpu_kernel kernel_default,
                             gpu_kernel kernel_low_height,
                             gpu_kernel kernel_low_width,
                             gpu_kernel kernel_small,
                             gpu_kernel kernel_large,
                             const char *name, size_t elem_size,
                             gpu_mem dst, int64_t dst_offset,
                             gpu_mem src, int64_t src_offset,
                             int64_t k, int64_t n, int64_t m) {
  int64_t mulx = TR_BLOCK_DIM / n;
  int64_t muly = TR_BLOCK_DIM / m;
  int32_t mulx32 = mulx;
  int32_t muly32 = muly;
  int32_t k32 = k;
  int32_t n32 = n;
  int32_t m32 = m;

  gpu_kernel kernel = kernel_default;
  int32_t grid[3];
  int32_t block[3];

  void* args[11];
  size_t args_sizes[11] = {
    sizeof(gpu_mem), sizeof(int64_t),
    sizeof(gpu_mem), sizeof(int64_t),
    sizeof(int32_t),
    sizeof(int32_t),
    sizeof(int32_t),
    sizeof(int32_t),
    sizeof(int32_t)
  };

  args[0] = &dst;
  args[1] = &dst_offset;
  args[2] = &src;
  args[3] = &src_offset;
  args[7] = &mulx;
  args[8] = &muly;

  if (dst_offset + k * n * m <= 2147483647L &&
      src_offset + k * n * m <= 2147483647L) {
    if (m <= TR_BLOCK_DIM/2 && n <= TR_BLOCK_DIM/2) {
      if (ctx->logging) { fprintf(ctx->log, "Using small kernel\n"); }
      kernel = kernel_small;
      grid[0] = ((k * n * m) + (TR_BLOCK_DIM*TR_BLOCK_DIM) - 1) / (TR_BLOCK_DIM*TR_BLOCK_DIM);
      grid[1] = 1;
      grid[2] = 1;
      block[0] = TR_BLOCK_DIM*TR_BLOCK_DIM;
      block[1] = 1;
      block[2] = 1;
    } else if (m <= TR_BLOCK_DIM/2 && TR_BLOCK_DIM < n) {
      if (ctx->logging) { fprintf(ctx->log, "Using low-width kernel\n"); }
      kernel = kernel_low_width;
      int64_t x_elems = m;
      int64_t y_elems = (n + muly - 1) / muly;
      grid[0] = (x_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[1] = (y_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[2] = k;
      block[0] = TR_BLOCK_DIM;
      block[1] = TR_BLOCK_DIM;
      block[2] = 1;
    } else if (n <= TR_BLOCK_DIM/2 && TR_BLOCK_DIM < m) {
      if (ctx->logging) { fprintf(ctx->log, "Using low-height kernel\n"); }
      kernel = kernel_low_height;
      int64_t x_elems = (m + mulx - 1) / mulx;
      int64_t y_elems = n;
      grid[0] = (x_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[1] = (y_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[2] = k;
      block[0] = TR_BLOCK_DIM;
      block[1] = TR_BLOCK_DIM;
      block[2] = 1;
    } else {
      if (ctx->logging) { fprintf(ctx->log, "Using default kernel\n"); }
      kernel = kernel_default;
      grid[0] = (m+TR_TILE_DIM-1)/TR_TILE_DIM;
      grid[1] = (n+TR_TILE_DIM-1)/TR_TILE_DIM;
      grid[2] = k;
      block[0] = TR_TILE_DIM;
      block[1] = TR_TILE_DIM/TR_ELEMS_PER_THREAD;
      block[2] = 1;
    }
    args[4] = &k32;
    args[5] = &m32;
    args[6] = &n32;
    args[7] = &mulx32;
    args[8] = &muly32;
  } else {
    if (ctx->logging) { fprintf(ctx->log, "Using large kernel\n"); }
    kernel = kernel_large;
    grid[0] = (m+TR_TILE_DIM-1)/TR_TILE_DIM;
    grid[1] = (n+TR_TILE_DIM-1)/TR_TILE_DIM;
    grid[2] = k;
    block[0] = TR_TILE_DIM;
    block[1] = TR_TILE_DIM/TR_ELEMS_PER_THREAD;
    block[2] = 1;
    args[4] = &k;
    args[5] = &m;
    args[6] = &n;
    args[7] = &mulx;
    args[8] = &muly;
    args_sizes[4] = sizeof(int64_t);
    args_sizes[5] = sizeof(int64_t);
    args_sizes[6] = sizeof(int64_t);
    args_sizes[7] = sizeof(int64_t);
    args_sizes[8] = sizeof(int64_t);
  }

  // Cap the number of thead blocks we launch and figure out how many
  // repeats we need alongside each dimension.
  int32_t repeat_1 = grid[1] / MAX_TR_THREAD_BLOCKS;
  int32_t repeat_2 = grid[2] / MAX_TR_THREAD_BLOCKS;
  grid[1] = repeat_1 > 0 ? MAX_TR_THREAD_BLOCKS : grid[1];
  grid[2] = repeat_2 > 0 ? MAX_TR_THREAD_BLOCKS : grid[2];
  args[9] = &repeat_1;
  args[10] = &repeat_2;
  args_sizes[9] = sizeof(repeat_1);
  args_sizes[10] = sizeof(repeat_2);

  if (ctx->logging) {
    fprintf(ctx->log, "\n");
  }

  return gpu_launch_kernel(ctx, kernel, name, grid, block,
                           TR_TILE_DIM*(TR_TILE_DIM+1)*elem_size,
                           sizeof(args)/sizeof(args[0]), args, args_sizes);
}

#define GEN_MAP_TRANSPOSE_GPU2GPU(NAME, ELEM_TYPE)                      \
  static int map_transpose_gpu2gpu_##NAME                               \
  (struct futhark_context* ctx,                                         \
   gpu_mem dst, int64_t dst_offset,                                     \
   gpu_mem src, int64_t src_offset,                                     \
   int64_t k, int64_t m, int64_t n)                                     \
  {                                                                     \
    return                                                              \
      gpu_map_transpose                                                 \
      (ctx,                                                             \
       ctx->kernels->map_transpose_##NAME,                              \
       ctx->kernels->map_transpose_##NAME##_low_height,                 \
       ctx->kernels->map_transpose_##NAME##_low_width,                  \
       ctx->kernels->map_transpose_##NAME##_small,                      \
       ctx->kernels->map_transpose_##NAME##_large,                      \
       "map_transpose_" #NAME, sizeof(ELEM_TYPE),                       \
       dst, dst_offset, src, src_offset,                                \
       k, n, m);                                                        \
  }

static int gpu_lmad_copy(struct futhark_context* ctx,
                         gpu_kernel kernel, int r,
                         gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],
                         gpu_mem src, int64_t src_offset, int64_t src_strides[r],
                         int64_t shape[r]) {
  if (r > 8) {
    set_error(ctx, strdup("Futhark runtime limitation:\nCannot copy array of greater than rank 8.\n"));
    return 1;
  }

  int64_t n = 1;
  for (int i = 0; i < r; i++) { n *= shape[i]; }

  void* args[6+(8*3)];
  size_t args_sizes[6+(8*3)];

  args[0] = &dst;
  args_sizes[0] = sizeof(gpu_mem);
  args[1] = &dst_offset;
  args_sizes[1] = sizeof(dst_offset);
  args[2] = &src;
  args_sizes[2] = sizeof(gpu_mem);
  args[3] = &src_offset;
  args_sizes[3] = sizeof(src_offset);
  args[4] = &n;
  args_sizes[4] = sizeof(n);
  args[5] = &r;
  args_sizes[5] = sizeof(r);

  int64_t zero = 0;

  for (int i = 0; i < 8; i++) {
    args_sizes[6+i*3] = sizeof(int64_t);
    args_sizes[6+i*3+1] = sizeof(int64_t);
    args_sizes[6+i*3+2] = sizeof(int64_t);
    if (i < r) {
      args[6+i*3] = &shape[i];
      args[6+i*3+1] = &dst_strides[i];
      args[6+i*3+2] = &src_strides[i];
    } else {
      args[6+i*3] = &zero;
      args[6+i*3+1] = &zero;
      args[6+i*3+2] = &zero;
    }
  }
  const size_t w = 256; // XXX: hardcoded thread block size.

  return gpu_launch_kernel(ctx, kernel, "copy_lmad_dev_to_dev",
                           (const int32_t[3]) {(n+w-1)/w,1,1},
                           (const int32_t[3]) {w,1,1},
                           0, 6+(8*3), args, args_sizes);
}

#define GEN_LMAD_COPY_ELEMENTS_GPU2GPU(NAME, ELEM_TYPE)                 \
  static int lmad_copy_elements_gpu2gpu_##NAME                          \
  (struct futhark_context* ctx,                                         \
   int r,                                                               \
   gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],             \
   gpu_mem src, int64_t src_offset, int64_t src_strides[r],             \
   int64_t shape[r]) {                                                  \
    return gpu_lmad_copy(ctx, ctx->kernels->lmad_copy_##NAME, r,        \
                         dst, dst_offset, dst_strides,                  \
                         src, src_offset, src_strides,                  \
                         shape);                                        \
  }                                                                     \

#define GEN_LMAD_COPY_GPU2GPU(NAME, ELEM_TYPE)                          \
  static int lmad_copy_gpu2gpu_##NAME                                   \
  (struct futhark_context* ctx,                                         \
   int r,                                                               \
   gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],             \
   gpu_mem src, int64_t src_offset, int64_t src_strides[r],             \
   int64_t shape[r]) {                                                  \
    log_copy(ctx, "GPU to GPU", r, dst_offset, dst_strides,             \
             src_offset, src_strides, shape);                           \
    int64_t size = 1;                                                   \
    for (int i = 0; i < r; i++) { size *= shape[i]; }                   \
    if (size == 0) { return FUTHARK_SUCCESS; }                          \
    int64_t k, n, m;                                                    \
    if (lmad_map_tr(&k, &n, &m,                                         \
                       r, dst_strides, src_strides, shape)) {           \
      log_transpose(ctx, k, n, m);                                      \
      return map_transpose_gpu2gpu_##NAME                               \
        (ctx, dst, dst_offset, src, src_offset, k, n, m);               \
    } else if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {   \
      if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}        \
      return gpu_memcpy(ctx,                                            \
                        dst, dst_offset*sizeof(ELEM_TYPE),              \
                        src, src_offset*sizeof(ELEM_TYPE),              \
                        size * sizeof(ELEM_TYPE));                      \
    } else {                                                            \
      if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}     \
      return lmad_copy_elements_gpu2gpu_##NAME                          \
        (ctx, r,                                                        \
         dst, dst_offset, dst_strides,                                  \
         src, src_offset, src_strides,                                  \
         shape);                                                        \
    }                                                                   \
  }

static int
lmad_copy_elements_host2gpu(struct futhark_context *ctx, size_t elem_size,
                            int r,
                            gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],
                            unsigned char* src, int64_t src_offset, int64_t src_strides[r],
                            int64_t shape[r]) {
  (void)ctx; (void)elem_size; (void)r;
  (void)dst; (void)dst_offset; (void)dst_strides;
  (void)src; (void)src_offset; (void)src_strides;
  (void)shape;
  set_error(ctx, strdup("Futhark runtime limitation:\nCannot copy unstructured array from host to GPU.\n"));
  return 1;
}

static int
lmad_copy_elements_gpu2host (struct futhark_context *ctx, size_t elem_size,
                             int r,
                             unsigned char* dst, int64_t dst_offset, int64_t dst_strides[r],
                             gpu_mem src, int64_t src_offset, int64_t src_strides[r],
                             int64_t shape[r]) {
  (void)ctx; (void)elem_size; (void)r;
  (void)dst; (void)dst_offset; (void)dst_strides;
  (void)src; (void)src_offset; (void)src_strides;
  (void)shape;
  set_error(ctx, strdup("Futhark runtime limitation:\nCannot copy unstructured array from GPU to host.\n"));
  return 1;
}

#define GEN_LMAD_COPY_ELEMENTS_HOSTGPU(NAME, ELEM_TYPE)                 \
  static int lmad_copy_elements_gpu2gpu_##NAME                          \
  (struct futhark_context* ctx,                                         \
   int r,                                                               \
   gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],             \
   gpu_mem src, int64_t src_offset, int64_t src_strides[r],             \
   int64_t shape[r]) {                                                  \
    return (ctx, ctx->kernels->lmad_copy_##NAME, r,                     \
                         dst, dst_offset, dst_strides,                  \
                         src, src_offset, src_strides,                  \
                         shape);                                        \
  }                                                                     \


static int lmad_copy_host2gpu(struct futhark_context* ctx, size_t elem_size, bool sync,
                              int r,
                              gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],
                              unsigned char* src, int64_t src_offset, int64_t src_strides[r],
                              int64_t shape[r]) {
  log_copy(ctx, "Host to GPU", r, dst_offset, dst_strides,
           src_offset, src_strides, shape);
  int64_t size = elem_size;
  for (int i = 0; i < r; i++) { size *= shape[i]; }
  if (size == 0) { return FUTHARK_SUCCESS; }
  int64_t k, n, m;
  if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {
    if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}
    return memcpy_host2gpu(ctx, sync,
                           dst, dst_offset*elem_size,
                           src, src_offset*elem_size,
                           size);
  } else {
    if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}
    int error;
    error = lmad_copy_elements_host2gpu
      (ctx, elem_size, r,
       dst, dst_offset, dst_strides,
       src, src_offset, src_strides,
       shape);
    if (error == 0 && sync) {
      error = futhark_context_sync(ctx);
    }
    return error;
  }
}

static int lmad_copy_gpu2host(struct futhark_context* ctx, size_t elem_size, bool sync,
                              int r,
                              unsigned char* dst, int64_t dst_offset, int64_t dst_strides[r],
                              gpu_mem src, int64_t src_offset, int64_t src_strides[r],
                              int64_t shape[r]) {
  log_copy(ctx, "Host to GPU", r, dst_offset, dst_strides,
           src_offset, src_strides, shape);
  int64_t size = elem_size;
  for (int i = 0; i < r; i++) { size *= shape[i]; }
  if (size == 0) { return FUTHARK_SUCCESS; }
  int64_t k, n, m;
  if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {
    if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}
    return memcpy_gpu2host(ctx, sync,
                           dst, dst_offset*elem_size,
                           src, src_offset*elem_size,
                           size);
  } else {
    if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}
    int error;
    error = lmad_copy_elements_gpu2host
      (ctx, elem_size, r,
       dst, dst_offset, dst_strides,
       src, src_offset, src_strides,
       shape);
    if (error == 0 && sync) {
      error = futhark_context_sync(ctx);
    }
    return error;
  }
}

GEN_MAP_TRANSPOSE_GPU2GPU(1b, uint8_t)
GEN_MAP_TRANSPOSE_GPU2GPU(2b, uint16_t)
GEN_MAP_TRANSPOSE_GPU2GPU(4b, uint32_t)
GEN_MAP_TRANSPOSE_GPU2GPU(8b, uint64_t)

GEN_LMAD_COPY_ELEMENTS_GPU2GPU(1b, uint8_t)
GEN_LMAD_COPY_ELEMENTS_GPU2GPU(2b, uint16_t)
GEN_LMAD_COPY_ELEMENTS_GPU2GPU(4b, uint32_t)
GEN_LMAD_COPY_ELEMENTS_GPU2GPU(8b, uint64_t)

GEN_LMAD_COPY_GPU2GPU(1b, uint8_t)
GEN_LMAD_COPY_GPU2GPU(2b, uint16_t)
GEN_LMAD_COPY_GPU2GPU(4b, uint32_t)
GEN_LMAD_COPY_GPU2GPU(8b, uint64_t)

// End of gpu.h

static int gpu_macros(struct futhark_context *ctx, char ***names_out, int64_t **values_out)
{
    int num_macros = 207;
    char **names = malloc(num_macros * sizeof(char *));
    int64_t *values = malloc(num_macros * sizeof(int64_t));
    
    {
        names[0] = "min_idxzisegred_nonseg_39545_dim1";
        values[0] = *ctx->tuning_params.min_idxzisegred_tblock_sizze_39537;
    }
    {
        names[1] = "min_idxzisegred_nonseg_39545zisegred_tblock_sizze_39538";
        values[1] = *ctx->tuning_params.min_idxzisegred_tblock_sizze_39537;
    }
    {
        names[2] = "min_idxzisegred_nonseg_39545zichunk_sizze_42708";
        values[2] = (int64_t) 1;
    }
    {
        names[3] = "max_idxzisegred_nonseg_39555_dim1";
        values[3] = *ctx->tuning_params.max_idxzisegred_tblock_sizze_39547;
    }
    {
        names[4] = "max_idxzisegred_nonseg_39555zisegred_tblock_sizze_39548";
        values[4] = *ctx->tuning_params.max_idxzisegred_tblock_sizze_39547;
    }
    {
        names[5] = "max_idxzisegred_nonseg_39555zichunk_sizze_42708";
        values[5] = (int64_t) 1;
    }
    {
        names[6] = "inner_SMJ_shortzisegmap_40373_dim1";
        values[6] = *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_40361;
    }
    {
        names[7] = "inner_SMJ_shortzisegmap_40373zisegmap_tblock_sizze_40369";
        values[7] = *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_40361;
    }
    {
        names[8] = "inner_SMJ_shortzigpuseq_43221_dim1";
        values[8] = (int64_t) 1;
    }
    {
        names[9] = "inner_SMJ_shortzisegmap_40343_dim1";
        values[9] = *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_40345;
    }
    {
        names[10] = "inner_SMJ_shortzisegmap_40343zisegmap_tblock_sizze_40346";
        values[10] = *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_40345;
    }
    {
        names[11] = "inner_SMJ_shortzisegmap_40351_dim1";
        values[11] = *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_40353;
    }
    {
        names[12] = "inner_SMJ_shortzisegmap_40351zisegmap_tblock_sizze_40354";
        values[12] = *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_40353;
    }
    {
        names[13] = "inner_SMJ_shortzigpuseq_43174_dim1";
        values[13] = (int64_t) 1;
    }
    {
        names[14] = "inner_SMJ_shortzigpuseq_43168_dim1";
        values[14] = (int64_t) 1;
    }
    {
        names[15] = "inner_SMJ_shortzigpuseq_43162_dim1";
        values[15] = (int64_t) 1;
    }
    {
        names[16] = "inner_SMJ_shortzisegmap_40335_dim1";
        values[16] = *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_40319;
    }
    {
        names[17] = "inner_SMJ_shortzisegmap_40335zisegmap_tblock_sizze_40331";
        values[17] = *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_40319;
    }
    {
        names[18] = "inner_SMJ_shortzisegscan_40315_dim1";
        values[18] = *ctx->tuning_params.inner_SMJ_shortzisegscan_tblock_sizze_40309;
    }
    {
        names[19] = "inner_SMJ_shortzisegscan_40315zisegscan_tblock_sizze_40310";
        values[19] = *ctx->tuning_params.inner_SMJ_shortzisegscan_tblock_sizze_40309;
    }
    {
        names[20] = "inner_SMJ_shortzisegscan_40315zichunk_sizze_43005";
        values[20] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[21] = "inner_SMJ_shortzisegmap_40301_dim1";
        values[21] = *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_40303;
    }
    {
        names[22] = "inner_SMJ_shortzisegmap_40301zisegmap_tblock_sizze_40304";
        values[22] = *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_40303;
    }
    {
        names[23] = "inner_SMJ_shortzisegscan_40299_dim1";
        values[23] = *ctx->tuning_params.inner_SMJ_shortzisegscan_tblock_sizze_40293;
    }
    {
        names[24] = "inner_SMJ_shortzisegscan_40299zisegscan_tblock_sizze_40294";
        values[24] = *ctx->tuning_params.inner_SMJ_shortzisegscan_tblock_sizze_40293;
    }
    {
        names[25] = "inner_SMJ_shortzisegscan_40299zichunk_sizze_42848";
        values[25] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[26] = "inner_SMJ_shortzisegmap_intrablock_41778_dim1";
        values[26] = *ctx->tuning_params.inner_SMJ_shortzitile_sizze_41779;
    }
    {
        names[27] = "inner_SMJ_shortzisegmap_intrablock_41778zitile_sizze_41780";
        values[27] = *ctx->tuning_params.inner_SMJ_shortzitile_sizze_41779;
    }
    {
        names[28] = "inner_SMJ_shortzisegmap_intrablock_41778zibytes_42245";
        values[28] = (int64_t) 8 * *ctx->tuning_params.inner_SMJ_shortzitile_sizze_41779;
    }
    {
        names[29] = "inner_SMJ_shortzisegmap_intrablock_41778zibytes_42247";
        values[29] = (int64_t) 2 * *ctx->tuning_params.inner_SMJ_shortzitile_sizze_41779;
    }
    {
        names[30] = "inner_SMJ_shortzisegmap_intrablock_41423_dim1";
        values[30] = *ctx->tuning_params.inner_SMJ_shortzitile_sizze_41424;
    }
    {
        names[31] = "inner_SMJ_shortzisegmap_intrablock_41423zitile_sizze_41425";
        values[31] = *ctx->tuning_params.inner_SMJ_shortzitile_sizze_41424;
    }
    {
        names[32] = "inner_SMJ_shortzisegmap_intrablock_41423zibytes_42306";
        values[32] = (int64_t) 8 * *ctx->tuning_params.inner_SMJ_shortzitile_sizze_41424;
    }
    {
        names[33] = "inner_SMJ_shortzisegmap_intrablock_41423zibytes_42308";
        values[33] = (int64_t) 2 * *ctx->tuning_params.inner_SMJ_shortzitile_sizze_41424;
    }
    {
        names[34] = "inner_SMJ_shortzigpuseq_42784_dim1";
        values[34] = (int64_t) 1;
    }
    {
        names[35] = "inner_SMJ_shortzigpuseq_42778_dim1";
        values[35] = (int64_t) 1;
    }
    {
        names[36] = "inner_SMJ_shortzigpuseq_42772_dim1";
        values[36] = (int64_t) 1;
    }
    {
        names[37] = "inner_SMJ_shortzigpuseq_42756_dim1";
        values[37] = (int64_t) 1;
    }
    {
        names[38] = "inner_SMJ_shortzigpuseq_42730_dim1";
        values[38] = (int64_t) 1;
    }
    {
        names[39] = "inner_SMJ_longzisegmap_40893_dim1";
        values[39] = *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_40881;
    }
    {
        names[40] = "inner_SMJ_longzisegmap_40893zisegmap_tblock_sizze_40889";
        values[40] = *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_40881;
    }
    {
        names[41] = "inner_SMJ_longzigpuseq_43201_dim1";
        values[41] = (int64_t) 1;
    }
    {
        names[42] = "inner_SMJ_longzisegmap_40863_dim1";
        values[42] = *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_40865;
    }
    {
        names[43] = "inner_SMJ_longzisegmap_40863zisegmap_tblock_sizze_40866";
        values[43] = *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_40865;
    }
    {
        names[44] = "inner_SMJ_longzisegmap_40871_dim1";
        values[44] = *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_40873;
    }
    {
        names[45] = "inner_SMJ_longzisegmap_40871zisegmap_tblock_sizze_40874";
        values[45] = *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_40873;
    }
    {
        names[46] = "inner_SMJ_longzigpuseq_43154_dim1";
        values[46] = (int64_t) 1;
    }
    {
        names[47] = "inner_SMJ_longzigpuseq_43148_dim1";
        values[47] = (int64_t) 1;
    }
    {
        names[48] = "inner_SMJ_longzigpuseq_43142_dim1";
        values[48] = (int64_t) 1;
    }
    {
        names[49] = "inner_SMJ_longzisegmap_40855_dim1";
        values[49] = *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_40839;
    }
    {
        names[50] = "inner_SMJ_longzisegmap_40855zisegmap_tblock_sizze_40851";
        values[50] = *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_40839;
    }
    {
        names[51] = "inner_SMJ_longzisegscan_40835_dim1";
        values[51] = *ctx->tuning_params.inner_SMJ_longzisegscan_tblock_sizze_40829;
    }
    {
        names[52] = "inner_SMJ_longzisegscan_40835zisegscan_tblock_sizze_40830";
        values[52] = *ctx->tuning_params.inner_SMJ_longzisegscan_tblock_sizze_40829;
    }
    {
        names[53] = "inner_SMJ_longzisegscan_40835zichunk_sizze_42985";
        values[53] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[54] = "inner_SMJ_longzisegmap_40821_dim1";
        values[54] = *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_40823;
    }
    {
        names[55] = "inner_SMJ_longzisegmap_40821zisegmap_tblock_sizze_40824";
        values[55] = *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_40823;
    }
    {
        names[56] = "inner_SMJ_longzisegscan_40819_dim1";
        values[56] = *ctx->tuning_params.inner_SMJ_longzisegscan_tblock_sizze_40813;
    }
    {
        names[57] = "inner_SMJ_longzisegscan_40819zisegscan_tblock_sizze_40814";
        values[57] = *ctx->tuning_params.inner_SMJ_longzisegscan_tblock_sizze_40813;
    }
    {
        names[58] = "inner_SMJ_longzisegscan_40819zichunk_sizze_42828";
        values[58] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[59] = "inner_SMJ_longzisegmap_intrablock_41778_dim1";
        values[59] = *ctx->tuning_params.inner_SMJ_longzitile_sizze_41779;
    }
    {
        names[60] = "inner_SMJ_longzisegmap_intrablock_41778zitile_sizze_41780";
        values[60] = *ctx->tuning_params.inner_SMJ_longzitile_sizze_41779;
    }
    {
        names[61] = "inner_SMJ_longzisegmap_intrablock_41778zibytes_42245";
        values[61] = (int64_t) 8 * *ctx->tuning_params.inner_SMJ_longzitile_sizze_41779;
    }
    {
        names[62] = "inner_SMJ_longzisegmap_intrablock_41423_dim1";
        values[62] = *ctx->tuning_params.inner_SMJ_longzitile_sizze_41424;
    }
    {
        names[63] = "inner_SMJ_longzisegmap_intrablock_41423zitile_sizze_41425";
        values[63] = *ctx->tuning_params.inner_SMJ_longzitile_sizze_41424;
    }
    {
        names[64] = "inner_SMJ_longzisegmap_intrablock_41423zibytes_42306";
        values[64] = (int64_t) 8 * *ctx->tuning_params.inner_SMJ_longzitile_sizze_41424;
    }
    {
        names[65] = "inner_SMJ_longzigpuseq_42764_dim1";
        values[65] = (int64_t) 1;
    }
    {
        names[66] = "inner_SMJ_longzigpuseq_42758_dim1";
        values[66] = (int64_t) 1;
    }
    {
        names[67] = "inner_SMJ_longzigpuseq_42752_dim1";
        values[67] = (int64_t) 1;
    }
    {
        names[68] = "inner_SMJ_longzigpuseq_42736_dim1";
        values[68] = (int64_t) 1;
    }
    {
        names[69] = "inner_SMJ_longzigpuseq_42730_dim1";
        values[69] = (int64_t) 1;
    }
    {
        names[70] = "inner_SMJ_intzisegmap_40633_dim1";
        values[70] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_40621;
    }
    {
        names[71] = "inner_SMJ_intzisegmap_40633zisegmap_tblock_sizze_40629";
        values[71] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_40621;
    }
    {
        names[72] = "inner_SMJ_intzigpuseq_43201_dim1";
        values[72] = (int64_t) 1;
    }
    {
        names[73] = "inner_SMJ_intzisegmap_40603_dim1";
        values[73] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_40605;
    }
    {
        names[74] = "inner_SMJ_intzisegmap_40603zisegmap_tblock_sizze_40606";
        values[74] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_40605;
    }
    {
        names[75] = "inner_SMJ_intzisegmap_40611_dim1";
        values[75] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_40613;
    }
    {
        names[76] = "inner_SMJ_intzisegmap_40611zisegmap_tblock_sizze_40614";
        values[76] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_40613;
    }
    {
        names[77] = "inner_SMJ_intzigpuseq_43154_dim1";
        values[77] = (int64_t) 1;
    }
    {
        names[78] = "inner_SMJ_intzigpuseq_43148_dim1";
        values[78] = (int64_t) 1;
    }
    {
        names[79] = "inner_SMJ_intzigpuseq_43142_dim1";
        values[79] = (int64_t) 1;
    }
    {
        names[80] = "inner_SMJ_intzisegmap_40595_dim1";
        values[80] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_40579;
    }
    {
        names[81] = "inner_SMJ_intzisegmap_40595zisegmap_tblock_sizze_40591";
        values[81] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_40579;
    }
    {
        names[82] = "inner_SMJ_intzisegscan_40575_dim1";
        values[82] = *ctx->tuning_params.inner_SMJ_intzisegscan_tblock_sizze_40569;
    }
    {
        names[83] = "inner_SMJ_intzisegscan_40575zisegscan_tblock_sizze_40570";
        values[83] = *ctx->tuning_params.inner_SMJ_intzisegscan_tblock_sizze_40569;
    }
    {
        names[84] = "inner_SMJ_intzisegscan_40575zichunk_sizze_42985";
        values[84] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[85] = "inner_SMJ_intzisegmap_40561_dim1";
        values[85] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_40563;
    }
    {
        names[86] = "inner_SMJ_intzisegmap_40561zisegmap_tblock_sizze_40564";
        values[86] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_40563;
    }
    {
        names[87] = "inner_SMJ_intzisegscan_40559_dim1";
        values[87] = *ctx->tuning_params.inner_SMJ_intzisegscan_tblock_sizze_40553;
    }
    {
        names[88] = "inner_SMJ_intzisegscan_40559zisegscan_tblock_sizze_40554";
        values[88] = *ctx->tuning_params.inner_SMJ_intzisegscan_tblock_sizze_40553;
    }
    {
        names[89] = "inner_SMJ_intzisegscan_40559zichunk_sizze_42848";
        values[89] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[90] = "inner_SMJ_intzisegmap_intrablock_41778_dim1";
        values[90] = *ctx->tuning_params.inner_SMJ_intzitile_sizze_41779;
    }
    {
        names[91] = "inner_SMJ_intzisegmap_intrablock_41778zitile_sizze_41780";
        values[91] = *ctx->tuning_params.inner_SMJ_intzitile_sizze_41779;
    }
    {
        names[92] = "inner_SMJ_intzisegmap_intrablock_41778zibytes_42245";
        values[92] = (int64_t) 8 * *ctx->tuning_params.inner_SMJ_intzitile_sizze_41779;
    }
    {
        names[93] = "inner_SMJ_intzisegmap_intrablock_41778zibytes_42247";
        values[93] = (int64_t) 4 * *ctx->tuning_params.inner_SMJ_intzitile_sizze_41779;
    }
    {
        names[94] = "inner_SMJ_intzisegmap_intrablock_41423_dim1";
        values[94] = *ctx->tuning_params.inner_SMJ_intzitile_sizze_41424;
    }
    {
        names[95] = "inner_SMJ_intzisegmap_intrablock_41423zitile_sizze_41425";
        values[95] = *ctx->tuning_params.inner_SMJ_intzitile_sizze_41424;
    }
    {
        names[96] = "inner_SMJ_intzisegmap_intrablock_41423zibytes_42306";
        values[96] = (int64_t) 8 * *ctx->tuning_params.inner_SMJ_intzitile_sizze_41424;
    }
    {
        names[97] = "inner_SMJ_intzisegmap_intrablock_41423zibytes_42308";
        values[97] = (int64_t) 4 * *ctx->tuning_params.inner_SMJ_intzitile_sizze_41424;
    }
    {
        names[98] = "inner_SMJ_intzigpuseq_42784_dim1";
        values[98] = (int64_t) 1;
    }
    {
        names[99] = "inner_SMJ_intzigpuseq_42778_dim1";
        values[99] = (int64_t) 1;
    }
    {
        names[100] = "inner_SMJ_intzigpuseq_42772_dim1";
        values[100] = (int64_t) 1;
    }
    {
        names[101] = "inner_SMJ_intzigpuseq_42756_dim1";
        values[101] = (int64_t) 1;
    }
    {
        names[102] = "inner_SMJ_intzigpuseq_42730_dim1";
        values[102] = (int64_t) 1;
    }
    {
        names[103] = "inner_SMJ_floatzisegmap_41153_dim1";
        values[103] = *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_41141;
    }
    {
        names[104] = "inner_SMJ_floatzisegmap_41153zisegmap_tblock_sizze_41149";
        values[104] = *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_41141;
    }
    {
        names[105] = "inner_SMJ_floatzigpuseq_43221_dim1";
        values[105] = (int64_t) 1;
    }
    {
        names[106] = "inner_SMJ_floatzisegmap_41123_dim1";
        values[106] = *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_41125;
    }
    {
        names[107] = "inner_SMJ_floatzisegmap_41123zisegmap_tblock_sizze_41126";
        values[107] = *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_41125;
    }
    {
        names[108] = "inner_SMJ_floatzisegmap_41131_dim1";
        values[108] = *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_41133;
    }
    {
        names[109] = "inner_SMJ_floatzisegmap_41131zisegmap_tblock_sizze_41134";
        values[109] = *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_41133;
    }
    {
        names[110] = "inner_SMJ_floatzigpuseq_43174_dim1";
        values[110] = (int64_t) 1;
    }
    {
        names[111] = "inner_SMJ_floatzigpuseq_43168_dim1";
        values[111] = (int64_t) 1;
    }
    {
        names[112] = "inner_SMJ_floatzigpuseq_43162_dim1";
        values[112] = (int64_t) 1;
    }
    {
        names[113] = "inner_SMJ_floatzisegmap_41115_dim1";
        values[113] = *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_41099;
    }
    {
        names[114] = "inner_SMJ_floatzisegmap_41115zisegmap_tblock_sizze_41111";
        values[114] = *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_41099;
    }
    {
        names[115] = "inner_SMJ_floatzisegscan_41095_dim1";
        values[115] = *ctx->tuning_params.inner_SMJ_floatzisegscan_tblock_sizze_41089;
    }
    {
        names[116] = "inner_SMJ_floatzisegscan_41095zisegscan_tblock_sizze_41090";
        values[116] = *ctx->tuning_params.inner_SMJ_floatzisegscan_tblock_sizze_41089;
    }
    {
        names[117] = "inner_SMJ_floatzisegscan_41095zichunk_sizze_43005";
        values[117] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[118] = "inner_SMJ_floatzisegmap_41081_dim1";
        values[118] = *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_41083;
    }
    {
        names[119] = "inner_SMJ_floatzisegmap_41081zisegmap_tblock_sizze_41084";
        values[119] = *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_41083;
    }
    {
        names[120] = "inner_SMJ_floatzisegscan_41079_dim1";
        values[120] = *ctx->tuning_params.inner_SMJ_floatzisegscan_tblock_sizze_41073;
    }
    {
        names[121] = "inner_SMJ_floatzisegscan_41079zisegscan_tblock_sizze_41074";
        values[121] = *ctx->tuning_params.inner_SMJ_floatzisegscan_tblock_sizze_41073;
    }
    {
        names[122] = "inner_SMJ_floatzisegscan_41079zichunk_sizze_42848";
        values[122] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[123] = "inner_SMJ_floatzisegmap_intrablock_41778_dim1";
        values[123] = *ctx->tuning_params.inner_SMJ_floatzitile_sizze_41779;
    }
    {
        names[124] = "inner_SMJ_floatzisegmap_intrablock_41778zitile_sizze_41780";
        values[124] = *ctx->tuning_params.inner_SMJ_floatzitile_sizze_41779;
    }
    {
        names[125] = "inner_SMJ_floatzisegmap_intrablock_41778zibytes_42245";
        values[125] = (int64_t) 8 * *ctx->tuning_params.inner_SMJ_floatzitile_sizze_41779;
    }
    {
        names[126] = "inner_SMJ_floatzisegmap_intrablock_41778zibytes_42247";
        values[126] = (int64_t) 4 * *ctx->tuning_params.inner_SMJ_floatzitile_sizze_41779;
    }
    {
        names[127] = "inner_SMJ_floatzisegmap_intrablock_41423_dim1";
        values[127] = *ctx->tuning_params.inner_SMJ_floatzitile_sizze_41424;
    }
    {
        names[128] = "inner_SMJ_floatzisegmap_intrablock_41423zitile_sizze_41425";
        values[128] = *ctx->tuning_params.inner_SMJ_floatzitile_sizze_41424;
    }
    {
        names[129] = "inner_SMJ_floatzisegmap_intrablock_41423zibytes_42306";
        values[129] = (int64_t) 8 * *ctx->tuning_params.inner_SMJ_floatzitile_sizze_41424;
    }
    {
        names[130] = "inner_SMJ_floatzisegmap_intrablock_41423zibytes_42308";
        values[130] = (int64_t) 4 * *ctx->tuning_params.inner_SMJ_floatzitile_sizze_41424;
    }
    {
        names[131] = "inner_SMJ_floatzigpuseq_42784_dim1";
        values[131] = (int64_t) 1;
    }
    {
        names[132] = "inner_SMJ_floatzigpuseq_42778_dim1";
        values[132] = (int64_t) 1;
    }
    {
        names[133] = "inner_SMJ_floatzigpuseq_42772_dim1";
        values[133] = (int64_t) 1;
    }
    {
        names[134] = "inner_SMJ_floatzigpuseq_42756_dim1";
        values[134] = (int64_t) 1;
    }
    {
        names[135] = "inner_SMJ_floatzigpuseq_42730_dim1";
        values[135] = (int64_t) 1;
    }
    {
        names[136] = "inner_SMJ_doublezisegmap_41413_dim1";
        values[136] = *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_41401;
    }
    {
        names[137] = "inner_SMJ_doublezisegmap_41413zisegmap_tblock_sizze_41409";
        values[137] = *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_41401;
    }
    {
        names[138] = "inner_SMJ_doublezigpuseq_43221_dim1";
        values[138] = (int64_t) 1;
    }
    {
        names[139] = "inner_SMJ_doublezisegmap_41383_dim1";
        values[139] = *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_41385;
    }
    {
        names[140] = "inner_SMJ_doublezisegmap_41383zisegmap_tblock_sizze_41386";
        values[140] = *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_41385;
    }
    {
        names[141] = "inner_SMJ_doublezisegmap_41391_dim1";
        values[141] = *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_41393;
    }
    {
        names[142] = "inner_SMJ_doublezisegmap_41391zisegmap_tblock_sizze_41394";
        values[142] = *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_41393;
    }
    {
        names[143] = "inner_SMJ_doublezigpuseq_43174_dim1";
        values[143] = (int64_t) 1;
    }
    {
        names[144] = "inner_SMJ_doublezigpuseq_43168_dim1";
        values[144] = (int64_t) 1;
    }
    {
        names[145] = "inner_SMJ_doublezigpuseq_43162_dim1";
        values[145] = (int64_t) 1;
    }
    {
        names[146] = "inner_SMJ_doublezisegmap_41375_dim1";
        values[146] = *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_41359;
    }
    {
        names[147] = "inner_SMJ_doublezisegmap_41375zisegmap_tblock_sizze_41371";
        values[147] = *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_41359;
    }
    {
        names[148] = "inner_SMJ_doublezisegscan_41355_dim1";
        values[148] = *ctx->tuning_params.inner_SMJ_doublezisegscan_tblock_sizze_41349;
    }
    {
        names[149] = "inner_SMJ_doublezisegscan_41355zisegscan_tblock_sizze_41350";
        values[149] = *ctx->tuning_params.inner_SMJ_doublezisegscan_tblock_sizze_41349;
    }
    {
        names[150] = "inner_SMJ_doublezisegscan_41355zichunk_sizze_43005";
        values[150] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[151] = "inner_SMJ_doublezisegmap_41341_dim1";
        values[151] = *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_41343;
    }
    {
        names[152] = "inner_SMJ_doublezisegmap_41341zisegmap_tblock_sizze_41344";
        values[152] = *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_41343;
    }
    {
        names[153] = "inner_SMJ_doublezisegscan_41339_dim1";
        values[153] = *ctx->tuning_params.inner_SMJ_doublezisegscan_tblock_sizze_41333;
    }
    {
        names[154] = "inner_SMJ_doublezisegscan_41339zisegscan_tblock_sizze_41334";
        values[154] = *ctx->tuning_params.inner_SMJ_doublezisegscan_tblock_sizze_41333;
    }
    {
        names[155] = "inner_SMJ_doublezisegscan_41339zichunk_sizze_42848";
        values[155] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[156] = "inner_SMJ_doublezisegmap_intrablock_41778_dim1";
        values[156] = *ctx->tuning_params.inner_SMJ_doublezitile_sizze_41779;
    }
    {
        names[157] = "inner_SMJ_doublezisegmap_intrablock_41778zitile_sizze_41780";
        values[157] = *ctx->tuning_params.inner_SMJ_doublezitile_sizze_41779;
    }
    {
        names[158] = "inner_SMJ_doublezisegmap_intrablock_41778zibytes_42245";
        values[158] = (int64_t) 8 * *ctx->tuning_params.inner_SMJ_doublezitile_sizze_41779;
    }
    {
        names[159] = "inner_SMJ_doublezisegmap_intrablock_41423_dim1";
        values[159] = *ctx->tuning_params.inner_SMJ_doublezitile_sizze_41424;
    }
    {
        names[160] = "inner_SMJ_doublezisegmap_intrablock_41423zitile_sizze_41425";
        values[160] = *ctx->tuning_params.inner_SMJ_doublezitile_sizze_41424;
    }
    {
        names[161] = "inner_SMJ_doublezisegmap_intrablock_41423zibytes_42306";
        values[161] = (int64_t) 8 * *ctx->tuning_params.inner_SMJ_doublezitile_sizze_41424;
    }
    {
        names[162] = "inner_SMJ_doublezigpuseq_42784_dim1";
        values[162] = (int64_t) 1;
    }
    {
        names[163] = "inner_SMJ_doublezigpuseq_42778_dim1";
        values[163] = (int64_t) 1;
    }
    {
        names[164] = "inner_SMJ_doublezigpuseq_42772_dim1";
        values[164] = (int64_t) 1;
    }
    {
        names[165] = "inner_SMJ_doublezigpuseq_42756_dim1";
        values[165] = (int64_t) 1;
    }
    {
        names[166] = "inner_SMJ_doublezigpuseq_42730_dim1";
        values[166] = (int64_t) 1;
    }
    {
        names[167] = "gather_payloads_short_GFURzisegmap_39879_dim1";
        values[167] = *ctx->tuning_params.gather_payloads_short_GFURzisegmap_tblock_sizze_39857;
    }
    {
        names[168] = "gather_payloads_short_GFURzisegmap_39879zisegmap_tblock_sizze_39875";
        values[168] = *ctx->tuning_params.gather_payloads_short_GFURzisegmap_tblock_sizze_39857;
    }
    {
        names[169] = "gather_payloads_short_GFURzisegmap_39851_dim1";
        values[169] = *ctx->tuning_params.gather_payloads_short_GFURzisegmap_tblock_sizze_39839;
    }
    {
        names[170] = "gather_payloads_short_GFURzisegmap_39851zisegmap_tblock_sizze_39847";
        values[170] = *ctx->tuning_params.gather_payloads_short_GFURzisegmap_tblock_sizze_39839;
    }
    {
        names[171] = "gather_payloads_shortzisegmap_39599_dim1";
        values[171] = *ctx->tuning_params.gather_payloads_shortzisegmap_tblock_sizze_39577;
    }
    {
        names[172] = "gather_payloads_shortzisegmap_39599zisegmap_tblock_sizze_39595";
        values[172] = *ctx->tuning_params.gather_payloads_shortzisegmap_tblock_sizze_39577;
    }
    {
        names[173] = "gather_payloads_shortzisegmap_39571_dim1";
        values[173] = *ctx->tuning_params.gather_payloads_shortzisegmap_tblock_sizze_39559;
    }
    {
        names[174] = "gather_payloads_shortzisegmap_39571zisegmap_tblock_sizze_39567";
        values[174] = *ctx->tuning_params.gather_payloads_shortzisegmap_tblock_sizze_39559;
    }
    {
        names[175] = "gather_payloads_long_GFURzisegmap_39991_dim1";
        values[175] = *ctx->tuning_params.gather_payloads_long_GFURzisegmap_tblock_sizze_39969;
    }
    {
        names[176] = "gather_payloads_long_GFURzisegmap_39991zisegmap_tblock_sizze_39987";
        values[176] = *ctx->tuning_params.gather_payloads_long_GFURzisegmap_tblock_sizze_39969;
    }
    {
        names[177] = "gather_payloads_long_GFURzisegmap_39963_dim1";
        values[177] = *ctx->tuning_params.gather_payloads_long_GFURzisegmap_tblock_sizze_39951;
    }
    {
        names[178] = "gather_payloads_long_GFURzisegmap_39963zisegmap_tblock_sizze_39959";
        values[178] = *ctx->tuning_params.gather_payloads_long_GFURzisegmap_tblock_sizze_39951;
    }
    {
        names[179] = "gather_payloads_longzisegmap_39711_dim1";
        values[179] = *ctx->tuning_params.gather_payloads_longzisegmap_tblock_sizze_39689;
    }
    {
        names[180] = "gather_payloads_longzisegmap_39711zisegmap_tblock_sizze_39707";
        values[180] = *ctx->tuning_params.gather_payloads_longzisegmap_tblock_sizze_39689;
    }
    {
        names[181] = "gather_payloads_longzisegmap_39683_dim1";
        values[181] = *ctx->tuning_params.gather_payloads_longzisegmap_tblock_sizze_39671;
    }
    {
        names[182] = "gather_payloads_longzisegmap_39683zisegmap_tblock_sizze_39679";
        values[182] = *ctx->tuning_params.gather_payloads_longzisegmap_tblock_sizze_39671;
    }
    {
        names[183] = "gather_payloads_int_GFURzisegmap_39935_dim1";
        values[183] = *ctx->tuning_params.gather_payloads_int_GFURzisegmap_tblock_sizze_39913;
    }
    {
        names[184] = "gather_payloads_int_GFURzisegmap_39935zisegmap_tblock_sizze_39931";
        values[184] = *ctx->tuning_params.gather_payloads_int_GFURzisegmap_tblock_sizze_39913;
    }
    {
        names[185] = "gather_payloads_int_GFURzisegmap_39907_dim1";
        values[185] = *ctx->tuning_params.gather_payloads_int_GFURzisegmap_tblock_sizze_39895;
    }
    {
        names[186] = "gather_payloads_int_GFURzisegmap_39907zisegmap_tblock_sizze_39903";
        values[186] = *ctx->tuning_params.gather_payloads_int_GFURzisegmap_tblock_sizze_39895;
    }
    {
        names[187] = "gather_payloads_intzisegmap_39655_dim1";
        values[187] = *ctx->tuning_params.gather_payloads_intzisegmap_tblock_sizze_39633;
    }
    {
        names[188] = "gather_payloads_intzisegmap_39655zisegmap_tblock_sizze_39651";
        values[188] = *ctx->tuning_params.gather_payloads_intzisegmap_tblock_sizze_39633;
    }
    {
        names[189] = "gather_payloads_intzisegmap_39627_dim1";
        values[189] = *ctx->tuning_params.gather_payloads_intzisegmap_tblock_sizze_39615;
    }
    {
        names[190] = "gather_payloads_intzisegmap_39627zisegmap_tblock_sizze_39623";
        values[190] = *ctx->tuning_params.gather_payloads_intzisegmap_tblock_sizze_39615;
    }
    {
        names[191] = "gather_payloads_float_GFURzisegmap_40047_dim1";
        values[191] = *ctx->tuning_params.gather_payloads_float_GFURzisegmap_tblock_sizze_40025;
    }
    {
        names[192] = "gather_payloads_float_GFURzisegmap_40047zisegmap_tblock_sizze_40043";
        values[192] = *ctx->tuning_params.gather_payloads_float_GFURzisegmap_tblock_sizze_40025;
    }
    {
        names[193] = "gather_payloads_float_GFURzisegmap_40019_dim1";
        values[193] = *ctx->tuning_params.gather_payloads_float_GFURzisegmap_tblock_sizze_40007;
    }
    {
        names[194] = "gather_payloads_float_GFURzisegmap_40019zisegmap_tblock_sizze_40015";
        values[194] = *ctx->tuning_params.gather_payloads_float_GFURzisegmap_tblock_sizze_40007;
    }
    {
        names[195] = "gather_payloads_floatzisegmap_39767_dim1";
        values[195] = *ctx->tuning_params.gather_payloads_floatzisegmap_tblock_sizze_39745;
    }
    {
        names[196] = "gather_payloads_floatzisegmap_39767zisegmap_tblock_sizze_39763";
        values[196] = *ctx->tuning_params.gather_payloads_floatzisegmap_tblock_sizze_39745;
    }
    {
        names[197] = "gather_payloads_floatzisegmap_39739_dim1";
        values[197] = *ctx->tuning_params.gather_payloads_floatzisegmap_tblock_sizze_39727;
    }
    {
        names[198] = "gather_payloads_floatzisegmap_39739zisegmap_tblock_sizze_39735";
        values[198] = *ctx->tuning_params.gather_payloads_floatzisegmap_tblock_sizze_39727;
    }
    {
        names[199] = "gather_payloads_double_GFURzisegmap_40103_dim1";
        values[199] = *ctx->tuning_params.gather_payloads_double_GFURzisegmap_tblock_sizze_40081;
    }
    {
        names[200] = "gather_payloads_double_GFURzisegmap_40103zisegmap_tblock_sizze_40099";
        values[200] = *ctx->tuning_params.gather_payloads_double_GFURzisegmap_tblock_sizze_40081;
    }
    {
        names[201] = "gather_payloads_double_GFURzisegmap_40075_dim1";
        values[201] = *ctx->tuning_params.gather_payloads_double_GFURzisegmap_tblock_sizze_40063;
    }
    {
        names[202] = "gather_payloads_double_GFURzisegmap_40075zisegmap_tblock_sizze_40071";
        values[202] = *ctx->tuning_params.gather_payloads_double_GFURzisegmap_tblock_sizze_40063;
    }
    {
        names[203] = "gather_payloads_doublezisegmap_39823_dim1";
        values[203] = *ctx->tuning_params.gather_payloads_doublezisegmap_tblock_sizze_39801;
    }
    {
        names[204] = "gather_payloads_doublezisegmap_39823zisegmap_tblock_sizze_39819";
        values[204] = *ctx->tuning_params.gather_payloads_doublezisegmap_tblock_sizze_39801;
    }
    {
        names[205] = "gather_payloads_doublezisegmap_39795_dim1";
        values[205] = *ctx->tuning_params.gather_payloads_doublezisegmap_tblock_sizze_39783;
    }
    {
        names[206] = "gather_payloads_doublezisegmap_39795zisegmap_tblock_sizze_39791";
        values[206] = *ctx->tuning_params.gather_payloads_doublezisegmap_tblock_sizze_39783;
    }
    *names_out = names;
    *values_out = values;
    return num_macros;
}
static char *get_failure_msg(int failure_idx, int64_t args[])
{
    (void) args;
    switch (failure_idx) {
        
      case 0:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:34:16-37\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftbasics.fut:32:30-36:6\n   #3  ftSMJ.fut:432:5-41\n   #4  ftSMJ.fut:431:1-432:41\n", args[0], args[1]);
            break;
        }
        
      case 1:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:52:16-37\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftbasics.fut:50:30-54:6\n   #3  ftSMJ.fut:460:5-50\n   #4  ftSMJ.fut:459:1-460:50\n", args[0], args[1]);
            break;
        }
        
      case 2:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:34:16-37\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftbasics.fut:32:30-36:6\n   #3  ftSMJ.fut:429:5-41\n   #4  ftSMJ.fut:428:1-429:41\n", args[0], args[1]);
            break;
        }
        
      case 3:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:52:16-37\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftbasics.fut:50:30-54:6\n   #3  ftSMJ.fut:457:5-50\n   #4  ftSMJ.fut:456:1-457:50\n", args[0], args[1]);
            break;
        }
        
      case 4:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:34:16-37\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftbasics.fut:32:30-36:6\n   #3  ftSMJ.fut:423:5-41\n   #4  ftSMJ.fut:422:1-423:41\n", args[0], args[1]);
            break;
        }
        
      case 5:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:52:16-37\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftbasics.fut:50:30-54:6\n   #3  ftSMJ.fut:451:5-50\n   #4  ftSMJ.fut:450:1-451:50\n", args[0], args[1]);
            break;
        }
        
      case 6:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:34:16-37\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftbasics.fut:32:30-36:6\n   #3  ftSMJ.fut:426:5-41\n   #4  ftSMJ.fut:425:1-426:41\n", args[0], args[1]);
            break;
        }
        
      case 7:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:52:16-37\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftbasics.fut:50:30-54:6\n   #3  ftSMJ.fut:454:5-50\n   #4  ftSMJ.fut:453:1-454:50\n", args[0], args[1]);
            break;
        }
        
      case 8:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:34:16-37\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftbasics.fut:32:30-36:6\n   #3  ftSMJ.fut:420:5-41\n   #4  ftSMJ.fut:419:1-420:41\n", args[0], args[1]);
            break;
        }
        
      case 9:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:52:16-37\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftbasics.fut:50:30-54:6\n   #3  ftSMJ.fut:448:5-50\n   #4  ftSMJ.fut:447:1-448:50\n", args[0], args[1]);
            break;
        }
    }
    return strdup("Unknown error.  This is a compiler bug.");
}
struct program {
    int dummy;
    gpu_kernel builtinzhiota_i64ziiota_i64_42712;
    gpu_kernel builtinzhreplicate_f32zireplicate_42741;
    gpu_kernel builtinzhreplicate_f64zireplicate_42741;
    gpu_kernel builtinzhreplicate_i16zireplicate_42741;
    gpu_kernel builtinzhreplicate_i32zireplicate_42884;
    gpu_kernel builtinzhreplicate_i64zireplicate_42715;
    gpu_kernel builtinzhreplicate_i8zireplicate_42858;
    gpu_kernel gather_payloads_doublezisegmap_39795;
    gpu_kernel gather_payloads_doublezisegmap_39823;
    gpu_kernel gather_payloads_double_GFURzisegmap_40075;
    gpu_kernel gather_payloads_double_GFURzisegmap_40103;
    gpu_kernel gather_payloads_floatzisegmap_39739;
    gpu_kernel gather_payloads_floatzisegmap_39767;
    gpu_kernel gather_payloads_float_GFURzisegmap_40019;
    gpu_kernel gather_payloads_float_GFURzisegmap_40047;
    gpu_kernel gather_payloads_intzisegmap_39627;
    gpu_kernel gather_payloads_intzisegmap_39655;
    gpu_kernel gather_payloads_int_GFURzisegmap_39907;
    gpu_kernel gather_payloads_int_GFURzisegmap_39935;
    gpu_kernel gather_payloads_longzisegmap_39683;
    gpu_kernel gather_payloads_longzisegmap_39711;
    gpu_kernel gather_payloads_long_GFURzisegmap_39963;
    gpu_kernel gather_payloads_long_GFURzisegmap_39991;
    gpu_kernel gather_payloads_shortzisegmap_39571;
    gpu_kernel gather_payloads_shortzisegmap_39599;
    gpu_kernel gather_payloads_short_GFURzisegmap_39851;
    gpu_kernel gather_payloads_short_GFURzisegmap_39879;
    gpu_kernel inner_SMJ_doublezigpuseq_42730;
    gpu_kernel inner_SMJ_doublezigpuseq_42756;
    gpu_kernel inner_SMJ_doublezigpuseq_42772;
    gpu_kernel inner_SMJ_doublezigpuseq_42778;
    gpu_kernel inner_SMJ_doublezigpuseq_42784;
    gpu_kernel inner_SMJ_doublezigpuseq_43162;
    gpu_kernel inner_SMJ_doublezigpuseq_43168;
    gpu_kernel inner_SMJ_doublezigpuseq_43174;
    gpu_kernel inner_SMJ_doublezigpuseq_43221;
    gpu_kernel inner_SMJ_doublezireplicate_43228;
    gpu_kernel inner_SMJ_doublezireplicate_43248;
    gpu_kernel inner_SMJ_doublezisegmap_41341;
    gpu_kernel inner_SMJ_doublezisegmap_41375;
    gpu_kernel inner_SMJ_doublezisegmap_41383;
    gpu_kernel inner_SMJ_doublezisegmap_41391;
    gpu_kernel inner_SMJ_doublezisegmap_41413;
    gpu_kernel inner_SMJ_doublezisegmap_intrablock_41423;
    gpu_kernel inner_SMJ_doublezisegmap_intrablock_41778;
    gpu_kernel inner_SMJ_doublezisegscan_41339;
    gpu_kernel inner_SMJ_doublezisegscan_41355;
    gpu_kernel inner_SMJ_floatzigpuseq_42730;
    gpu_kernel inner_SMJ_floatzigpuseq_42756;
    gpu_kernel inner_SMJ_floatzigpuseq_42772;
    gpu_kernel inner_SMJ_floatzigpuseq_42778;
    gpu_kernel inner_SMJ_floatzigpuseq_42784;
    gpu_kernel inner_SMJ_floatzigpuseq_43162;
    gpu_kernel inner_SMJ_floatzigpuseq_43168;
    gpu_kernel inner_SMJ_floatzigpuseq_43174;
    gpu_kernel inner_SMJ_floatzigpuseq_43221;
    gpu_kernel inner_SMJ_floatzireplicate_43228;
    gpu_kernel inner_SMJ_floatzireplicate_43248;
    gpu_kernel inner_SMJ_floatzisegmap_41081;
    gpu_kernel inner_SMJ_floatzisegmap_41115;
    gpu_kernel inner_SMJ_floatzisegmap_41123;
    gpu_kernel inner_SMJ_floatzisegmap_41131;
    gpu_kernel inner_SMJ_floatzisegmap_41153;
    gpu_kernel inner_SMJ_floatzisegmap_intrablock_41423;
    gpu_kernel inner_SMJ_floatzisegmap_intrablock_41778;
    gpu_kernel inner_SMJ_floatzisegscan_41079;
    gpu_kernel inner_SMJ_floatzisegscan_41095;
    gpu_kernel inner_SMJ_intzigpuseq_42730;
    gpu_kernel inner_SMJ_intzigpuseq_42756;
    gpu_kernel inner_SMJ_intzigpuseq_42772;
    gpu_kernel inner_SMJ_intzigpuseq_42778;
    gpu_kernel inner_SMJ_intzigpuseq_42784;
    gpu_kernel inner_SMJ_intzigpuseq_43142;
    gpu_kernel inner_SMJ_intzigpuseq_43148;
    gpu_kernel inner_SMJ_intzigpuseq_43154;
    gpu_kernel inner_SMJ_intzigpuseq_43201;
    gpu_kernel inner_SMJ_intzireplicate_43208;
    gpu_kernel inner_SMJ_intzireplicate_43228;
    gpu_kernel inner_SMJ_intzisegmap_40561;
    gpu_kernel inner_SMJ_intzisegmap_40595;
    gpu_kernel inner_SMJ_intzisegmap_40603;
    gpu_kernel inner_SMJ_intzisegmap_40611;
    gpu_kernel inner_SMJ_intzisegmap_40633;
    gpu_kernel inner_SMJ_intzisegmap_intrablock_41423;
    gpu_kernel inner_SMJ_intzisegmap_intrablock_41778;
    gpu_kernel inner_SMJ_intzisegscan_40559;
    gpu_kernel inner_SMJ_intzisegscan_40575;
    gpu_kernel inner_SMJ_longzigpuseq_42730;
    gpu_kernel inner_SMJ_longzigpuseq_42736;
    gpu_kernel inner_SMJ_longzigpuseq_42752;
    gpu_kernel inner_SMJ_longzigpuseq_42758;
    gpu_kernel inner_SMJ_longzigpuseq_42764;
    gpu_kernel inner_SMJ_longzigpuseq_43142;
    gpu_kernel inner_SMJ_longzigpuseq_43148;
    gpu_kernel inner_SMJ_longzigpuseq_43154;
    gpu_kernel inner_SMJ_longzigpuseq_43201;
    gpu_kernel inner_SMJ_longzireplicate_43208;
    gpu_kernel inner_SMJ_longzireplicate_43228;
    gpu_kernel inner_SMJ_longzisegmap_40821;
    gpu_kernel inner_SMJ_longzisegmap_40855;
    gpu_kernel inner_SMJ_longzisegmap_40863;
    gpu_kernel inner_SMJ_longzisegmap_40871;
    gpu_kernel inner_SMJ_longzisegmap_40893;
    gpu_kernel inner_SMJ_longzisegmap_intrablock_41423;
    gpu_kernel inner_SMJ_longzisegmap_intrablock_41778;
    gpu_kernel inner_SMJ_longzisegscan_40819;
    gpu_kernel inner_SMJ_longzisegscan_40835;
    gpu_kernel inner_SMJ_shortzigpuseq_42730;
    gpu_kernel inner_SMJ_shortzigpuseq_42756;
    gpu_kernel inner_SMJ_shortzigpuseq_42772;
    gpu_kernel inner_SMJ_shortzigpuseq_42778;
    gpu_kernel inner_SMJ_shortzigpuseq_42784;
    gpu_kernel inner_SMJ_shortzigpuseq_43162;
    gpu_kernel inner_SMJ_shortzigpuseq_43168;
    gpu_kernel inner_SMJ_shortzigpuseq_43174;
    gpu_kernel inner_SMJ_shortzigpuseq_43221;
    gpu_kernel inner_SMJ_shortzireplicate_43228;
    gpu_kernel inner_SMJ_shortzireplicate_43248;
    gpu_kernel inner_SMJ_shortzisegmap_40301;
    gpu_kernel inner_SMJ_shortzisegmap_40335;
    gpu_kernel inner_SMJ_shortzisegmap_40343;
    gpu_kernel inner_SMJ_shortzisegmap_40351;
    gpu_kernel inner_SMJ_shortzisegmap_40373;
    gpu_kernel inner_SMJ_shortzisegmap_intrablock_41423;
    gpu_kernel inner_SMJ_shortzisegmap_intrablock_41778;
    gpu_kernel inner_SMJ_shortzisegscan_40299;
    gpu_kernel inner_SMJ_shortzisegscan_40315;
    gpu_kernel max_idxzisegred_nonseg_39555;
    gpu_kernel min_idxzisegred_nonseg_39545;
};
static void setup_program(struct futhark_context *ctx)
{
    (void) ctx;
    
    int error = 0;
    
    (void) error;
    ctx->program = malloc(sizeof(struct program));
    gpu_create_kernel(ctx, &ctx->program->builtinzhiota_i64ziiota_i64_42712, "builtinzhiota_i64ziiota_i64_42712");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_f32zireplicate_42741, "builtinzhreplicate_f32zireplicate_42741");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_f64zireplicate_42741, "builtinzhreplicate_f64zireplicate_42741");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_i16zireplicate_42741, "builtinzhreplicate_i16zireplicate_42741");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_i32zireplicate_42884, "builtinzhreplicate_i32zireplicate_42884");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_i64zireplicate_42715, "builtinzhreplicate_i64zireplicate_42715");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_i8zireplicate_42858, "builtinzhreplicate_i8zireplicate_42858");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_doublezisegmap_39795, "gather_payloads_doublezisegmap_39795");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_doublezisegmap_39823, "gather_payloads_doublezisegmap_39823");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_double_GFURzisegmap_40075, "gather_payloads_double_GFURzisegmap_40075");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_double_GFURzisegmap_40103, "gather_payloads_double_GFURzisegmap_40103");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_floatzisegmap_39739, "gather_payloads_floatzisegmap_39739");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_floatzisegmap_39767, "gather_payloads_floatzisegmap_39767");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_float_GFURzisegmap_40019, "gather_payloads_float_GFURzisegmap_40019");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_float_GFURzisegmap_40047, "gather_payloads_float_GFURzisegmap_40047");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_intzisegmap_39627, "gather_payloads_intzisegmap_39627");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_intzisegmap_39655, "gather_payloads_intzisegmap_39655");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_int_GFURzisegmap_39907, "gather_payloads_int_GFURzisegmap_39907");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_int_GFURzisegmap_39935, "gather_payloads_int_GFURzisegmap_39935");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_longzisegmap_39683, "gather_payloads_longzisegmap_39683");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_longzisegmap_39711, "gather_payloads_longzisegmap_39711");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_long_GFURzisegmap_39963, "gather_payloads_long_GFURzisegmap_39963");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_long_GFURzisegmap_39991, "gather_payloads_long_GFURzisegmap_39991");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_shortzisegmap_39571, "gather_payloads_shortzisegmap_39571");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_shortzisegmap_39599, "gather_payloads_shortzisegmap_39599");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_short_GFURzisegmap_39851, "gather_payloads_short_GFURzisegmap_39851");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_short_GFURzisegmap_39879, "gather_payloads_short_GFURzisegmap_39879");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_doublezigpuseq_42730, "inner_SMJ_doublezigpuseq_42730");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_doublezigpuseq_42756, "inner_SMJ_doublezigpuseq_42756");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_doublezigpuseq_42772, "inner_SMJ_doublezigpuseq_42772");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_doublezigpuseq_42778, "inner_SMJ_doublezigpuseq_42778");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_doublezigpuseq_42784, "inner_SMJ_doublezigpuseq_42784");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_doublezigpuseq_43162, "inner_SMJ_doublezigpuseq_43162");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_doublezigpuseq_43168, "inner_SMJ_doublezigpuseq_43168");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_doublezigpuseq_43174, "inner_SMJ_doublezigpuseq_43174");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_doublezigpuseq_43221, "inner_SMJ_doublezigpuseq_43221");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_doublezireplicate_43228, "inner_SMJ_doublezireplicate_43228");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_doublezireplicate_43248, "inner_SMJ_doublezireplicate_43248");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_doublezisegmap_41341, "inner_SMJ_doublezisegmap_41341");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_doublezisegmap_41375, "inner_SMJ_doublezisegmap_41375");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_doublezisegmap_41383, "inner_SMJ_doublezisegmap_41383");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_doublezisegmap_41391, "inner_SMJ_doublezisegmap_41391");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_doublezisegmap_41413, "inner_SMJ_doublezisegmap_41413");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_doublezisegmap_intrablock_41423, "inner_SMJ_doublezisegmap_intrablock_41423");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_doublezisegmap_intrablock_41778, "inner_SMJ_doublezisegmap_intrablock_41778");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_doublezisegscan_41339, "inner_SMJ_doublezisegscan_41339");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_doublezisegscan_41355, "inner_SMJ_doublezisegscan_41355");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_floatzigpuseq_42730, "inner_SMJ_floatzigpuseq_42730");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_floatzigpuseq_42756, "inner_SMJ_floatzigpuseq_42756");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_floatzigpuseq_42772, "inner_SMJ_floatzigpuseq_42772");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_floatzigpuseq_42778, "inner_SMJ_floatzigpuseq_42778");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_floatzigpuseq_42784, "inner_SMJ_floatzigpuseq_42784");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_floatzigpuseq_43162, "inner_SMJ_floatzigpuseq_43162");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_floatzigpuseq_43168, "inner_SMJ_floatzigpuseq_43168");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_floatzigpuseq_43174, "inner_SMJ_floatzigpuseq_43174");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_floatzigpuseq_43221, "inner_SMJ_floatzigpuseq_43221");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_floatzireplicate_43228, "inner_SMJ_floatzireplicate_43228");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_floatzireplicate_43248, "inner_SMJ_floatzireplicate_43248");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_floatzisegmap_41081, "inner_SMJ_floatzisegmap_41081");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_floatzisegmap_41115, "inner_SMJ_floatzisegmap_41115");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_floatzisegmap_41123, "inner_SMJ_floatzisegmap_41123");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_floatzisegmap_41131, "inner_SMJ_floatzisegmap_41131");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_floatzisegmap_41153, "inner_SMJ_floatzisegmap_41153");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_floatzisegmap_intrablock_41423, "inner_SMJ_floatzisegmap_intrablock_41423");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_floatzisegmap_intrablock_41778, "inner_SMJ_floatzisegmap_intrablock_41778");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_floatzisegscan_41079, "inner_SMJ_floatzisegscan_41079");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_floatzisegscan_41095, "inner_SMJ_floatzisegscan_41095");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzigpuseq_42730, "inner_SMJ_intzigpuseq_42730");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzigpuseq_42756, "inner_SMJ_intzigpuseq_42756");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzigpuseq_42772, "inner_SMJ_intzigpuseq_42772");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzigpuseq_42778, "inner_SMJ_intzigpuseq_42778");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzigpuseq_42784, "inner_SMJ_intzigpuseq_42784");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzigpuseq_43142, "inner_SMJ_intzigpuseq_43142");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzigpuseq_43148, "inner_SMJ_intzigpuseq_43148");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzigpuseq_43154, "inner_SMJ_intzigpuseq_43154");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzigpuseq_43201, "inner_SMJ_intzigpuseq_43201");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzireplicate_43208, "inner_SMJ_intzireplicate_43208");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzireplicate_43228, "inner_SMJ_intzireplicate_43228");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzisegmap_40561, "inner_SMJ_intzisegmap_40561");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzisegmap_40595, "inner_SMJ_intzisegmap_40595");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzisegmap_40603, "inner_SMJ_intzisegmap_40603");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzisegmap_40611, "inner_SMJ_intzisegmap_40611");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzisegmap_40633, "inner_SMJ_intzisegmap_40633");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzisegmap_intrablock_41423, "inner_SMJ_intzisegmap_intrablock_41423");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzisegmap_intrablock_41778, "inner_SMJ_intzisegmap_intrablock_41778");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzisegscan_40559, "inner_SMJ_intzisegscan_40559");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzisegscan_40575, "inner_SMJ_intzisegscan_40575");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_longzigpuseq_42730, "inner_SMJ_longzigpuseq_42730");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_longzigpuseq_42736, "inner_SMJ_longzigpuseq_42736");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_longzigpuseq_42752, "inner_SMJ_longzigpuseq_42752");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_longzigpuseq_42758, "inner_SMJ_longzigpuseq_42758");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_longzigpuseq_42764, "inner_SMJ_longzigpuseq_42764");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_longzigpuseq_43142, "inner_SMJ_longzigpuseq_43142");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_longzigpuseq_43148, "inner_SMJ_longzigpuseq_43148");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_longzigpuseq_43154, "inner_SMJ_longzigpuseq_43154");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_longzigpuseq_43201, "inner_SMJ_longzigpuseq_43201");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_longzireplicate_43208, "inner_SMJ_longzireplicate_43208");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_longzireplicate_43228, "inner_SMJ_longzireplicate_43228");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_longzisegmap_40821, "inner_SMJ_longzisegmap_40821");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_longzisegmap_40855, "inner_SMJ_longzisegmap_40855");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_longzisegmap_40863, "inner_SMJ_longzisegmap_40863");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_longzisegmap_40871, "inner_SMJ_longzisegmap_40871");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_longzisegmap_40893, "inner_SMJ_longzisegmap_40893");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_longzisegmap_intrablock_41423, "inner_SMJ_longzisegmap_intrablock_41423");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_longzisegmap_intrablock_41778, "inner_SMJ_longzisegmap_intrablock_41778");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_longzisegscan_40819, "inner_SMJ_longzisegscan_40819");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_longzisegscan_40835, "inner_SMJ_longzisegscan_40835");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_shortzigpuseq_42730, "inner_SMJ_shortzigpuseq_42730");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_shortzigpuseq_42756, "inner_SMJ_shortzigpuseq_42756");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_shortzigpuseq_42772, "inner_SMJ_shortzigpuseq_42772");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_shortzigpuseq_42778, "inner_SMJ_shortzigpuseq_42778");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_shortzigpuseq_42784, "inner_SMJ_shortzigpuseq_42784");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_shortzigpuseq_43162, "inner_SMJ_shortzigpuseq_43162");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_shortzigpuseq_43168, "inner_SMJ_shortzigpuseq_43168");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_shortzigpuseq_43174, "inner_SMJ_shortzigpuseq_43174");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_shortzigpuseq_43221, "inner_SMJ_shortzigpuseq_43221");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_shortzireplicate_43228, "inner_SMJ_shortzireplicate_43228");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_shortzireplicate_43248, "inner_SMJ_shortzireplicate_43248");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_shortzisegmap_40301, "inner_SMJ_shortzisegmap_40301");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_shortzisegmap_40335, "inner_SMJ_shortzisegmap_40335");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_shortzisegmap_40343, "inner_SMJ_shortzisegmap_40343");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_shortzisegmap_40351, "inner_SMJ_shortzisegmap_40351");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_shortzisegmap_40373, "inner_SMJ_shortzisegmap_40373");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_shortzisegmap_intrablock_41423, "inner_SMJ_shortzisegmap_intrablock_41423");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_shortzisegmap_intrablock_41778, "inner_SMJ_shortzisegmap_intrablock_41778");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_shortzisegscan_40299, "inner_SMJ_shortzisegscan_40299");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_shortzisegscan_40315, "inner_SMJ_shortzisegscan_40315");
    gpu_create_kernel(ctx, &ctx->program->max_idxzisegred_nonseg_39555, "max_idxzisegred_nonseg_39555");
    gpu_create_kernel(ctx, &ctx->program->min_idxzisegred_nonseg_39545, "min_idxzisegred_nonseg_39545");
}
static void teardown_program(struct futhark_context *ctx)
{
    (void) ctx;
    
    int error = 0;
    
    (void) error;
    gpu_free_kernel(ctx, ctx->program->builtinzhiota_i64ziiota_i64_42712);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_f32zireplicate_42741);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_f64zireplicate_42741);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_i16zireplicate_42741);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_i32zireplicate_42884);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_i64zireplicate_42715);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_i8zireplicate_42858);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_doublezisegmap_39795);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_doublezisegmap_39823);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_double_GFURzisegmap_40075);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_double_GFURzisegmap_40103);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_floatzisegmap_39739);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_floatzisegmap_39767);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_float_GFURzisegmap_40019);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_float_GFURzisegmap_40047);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_intzisegmap_39627);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_intzisegmap_39655);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_int_GFURzisegmap_39907);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_int_GFURzisegmap_39935);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_longzisegmap_39683);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_longzisegmap_39711);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_long_GFURzisegmap_39963);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_long_GFURzisegmap_39991);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_shortzisegmap_39571);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_shortzisegmap_39599);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_short_GFURzisegmap_39851);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_short_GFURzisegmap_39879);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_doublezigpuseq_42730);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_doublezigpuseq_42756);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_doublezigpuseq_42772);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_doublezigpuseq_42778);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_doublezigpuseq_42784);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_doublezigpuseq_43162);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_doublezigpuseq_43168);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_doublezigpuseq_43174);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_doublezigpuseq_43221);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_doublezireplicate_43228);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_doublezireplicate_43248);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_doublezisegmap_41341);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_doublezisegmap_41375);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_doublezisegmap_41383);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_doublezisegmap_41391);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_doublezisegmap_41413);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_doublezisegmap_intrablock_41423);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_doublezisegmap_intrablock_41778);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_doublezisegscan_41339);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_doublezisegscan_41355);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_floatzigpuseq_42730);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_floatzigpuseq_42756);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_floatzigpuseq_42772);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_floatzigpuseq_42778);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_floatzigpuseq_42784);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_floatzigpuseq_43162);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_floatzigpuseq_43168);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_floatzigpuseq_43174);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_floatzigpuseq_43221);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_floatzireplicate_43228);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_floatzireplicate_43248);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_floatzisegmap_41081);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_floatzisegmap_41115);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_floatzisegmap_41123);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_floatzisegmap_41131);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_floatzisegmap_41153);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_floatzisegmap_intrablock_41423);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_floatzisegmap_intrablock_41778);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_floatzisegscan_41079);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_floatzisegscan_41095);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_42730);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_42756);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_42772);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_42778);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_42784);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_43142);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_43148);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_43154);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_43201);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzireplicate_43208);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzireplicate_43228);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_40561);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_40595);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_40603);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_40611);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_40633);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_intrablock_41423);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_intrablock_41778);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzisegscan_40559);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzisegscan_40575);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_longzigpuseq_42730);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_longzigpuseq_42736);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_longzigpuseq_42752);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_longzigpuseq_42758);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_longzigpuseq_42764);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_longzigpuseq_43142);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_longzigpuseq_43148);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_longzigpuseq_43154);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_longzigpuseq_43201);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_longzireplicate_43208);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_longzireplicate_43228);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_longzisegmap_40821);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_longzisegmap_40855);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_longzisegmap_40863);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_longzisegmap_40871);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_longzisegmap_40893);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_longzisegmap_intrablock_41423);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_longzisegmap_intrablock_41778);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_longzisegscan_40819);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_longzisegscan_40835);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_shortzigpuseq_42730);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_shortzigpuseq_42756);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_shortzigpuseq_42772);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_shortzigpuseq_42778);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_shortzigpuseq_42784);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_shortzigpuseq_43162);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_shortzigpuseq_43168);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_shortzigpuseq_43174);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_shortzigpuseq_43221);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_shortzireplicate_43228);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_shortzireplicate_43248);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_shortzisegmap_40301);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_shortzisegmap_40335);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_shortzisegmap_40343);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_shortzisegmap_40351);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_shortzisegmap_40373);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_shortzisegmap_intrablock_41423);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_shortzisegmap_intrablock_41778);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_shortzisegscan_40299);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_shortzisegscan_40315);
    gpu_free_kernel(ctx, ctx->program->max_idxzisegred_nonseg_39555);
    gpu_free_kernel(ctx, ctx->program->min_idxzisegred_nonseg_39545);
    free(ctx->program);
}
static void set_tuning_params(struct futhark_context *ctx)
{
    (void) ctx;
    ctx->tuning_params.builtinzhiota_i64zitblock_sizze_42716 = &ctx->cfg->tuning_params[0];
    ctx->tuning_params.builtinzhreplicate_f32zitblock_sizze_42745 = &ctx->cfg->tuning_params[1];
    ctx->tuning_params.builtinzhreplicate_f64zitblock_sizze_42745 = &ctx->cfg->tuning_params[2];
    ctx->tuning_params.builtinzhreplicate_i16zitblock_sizze_42745 = &ctx->cfg->tuning_params[3];
    ctx->tuning_params.builtinzhreplicate_i32zitblock_sizze_42888 = &ctx->cfg->tuning_params[4];
    ctx->tuning_params.builtinzhreplicate_i64zitblock_sizze_42719 = &ctx->cfg->tuning_params[5];
    ctx->tuning_params.builtinzhreplicate_i8zitblock_sizze_42862 = &ctx->cfg->tuning_params[6];
    ctx->tuning_params.gather_payloads_doublezisegmap_tblock_sizze_39783 = &ctx->cfg->tuning_params[7];
    ctx->tuning_params.gather_payloads_doublezisegmap_tblock_sizze_39801 = &ctx->cfg->tuning_params[8];
    ctx->tuning_params.gather_payloads_double_GFURzisegmap_tblock_sizze_40063 = &ctx->cfg->tuning_params[9];
    ctx->tuning_params.gather_payloads_double_GFURzisegmap_tblock_sizze_40081 = &ctx->cfg->tuning_params[10];
    ctx->tuning_params.gather_payloads_floatzisegmap_tblock_sizze_39727 = &ctx->cfg->tuning_params[11];
    ctx->tuning_params.gather_payloads_floatzisegmap_tblock_sizze_39745 = &ctx->cfg->tuning_params[12];
    ctx->tuning_params.gather_payloads_float_GFURzisegmap_tblock_sizze_40007 = &ctx->cfg->tuning_params[13];
    ctx->tuning_params.gather_payloads_float_GFURzisegmap_tblock_sizze_40025 = &ctx->cfg->tuning_params[14];
    ctx->tuning_params.gather_payloads_intzisegmap_tblock_sizze_39615 = &ctx->cfg->tuning_params[15];
    ctx->tuning_params.gather_payloads_intzisegmap_tblock_sizze_39633 = &ctx->cfg->tuning_params[16];
    ctx->tuning_params.gather_payloads_int_GFURzisegmap_tblock_sizze_39895 = &ctx->cfg->tuning_params[17];
    ctx->tuning_params.gather_payloads_int_GFURzisegmap_tblock_sizze_39913 = &ctx->cfg->tuning_params[18];
    ctx->tuning_params.gather_payloads_longzisegmap_tblock_sizze_39671 = &ctx->cfg->tuning_params[19];
    ctx->tuning_params.gather_payloads_longzisegmap_tblock_sizze_39689 = &ctx->cfg->tuning_params[20];
    ctx->tuning_params.gather_payloads_long_GFURzisegmap_tblock_sizze_39951 = &ctx->cfg->tuning_params[21];
    ctx->tuning_params.gather_payloads_long_GFURzisegmap_tblock_sizze_39969 = &ctx->cfg->tuning_params[22];
    ctx->tuning_params.gather_payloads_shortzisegmap_tblock_sizze_39559 = &ctx->cfg->tuning_params[23];
    ctx->tuning_params.gather_payloads_shortzisegmap_tblock_sizze_39577 = &ctx->cfg->tuning_params[24];
    ctx->tuning_params.gather_payloads_short_GFURzisegmap_tblock_sizze_39839 = &ctx->cfg->tuning_params[25];
    ctx->tuning_params.gather_payloads_short_GFURzisegmap_tblock_sizze_39857 = &ctx->cfg->tuning_params[26];
    ctx->tuning_params.inner_SMJ_doublezisegmap_num_tblocks_41345 = &ctx->cfg->tuning_params[27];
    ctx->tuning_params.inner_SMJ_doublezisegmap_num_tblocks_41387 = &ctx->cfg->tuning_params[28];
    ctx->tuning_params.inner_SMJ_doublezisegmap_num_tblocks_41395 = &ctx->cfg->tuning_params[29];
    ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_41343 = &ctx->cfg->tuning_params[30];
    ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_41359 = &ctx->cfg->tuning_params[31];
    ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_41385 = &ctx->cfg->tuning_params[32];
    ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_41393 = &ctx->cfg->tuning_params[33];
    ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_41401 = &ctx->cfg->tuning_params[34];
    ctx->tuning_params.inner_SMJ_doublezisegscan_num_tblocks_41335 = &ctx->cfg->tuning_params[35];
    ctx->tuning_params.inner_SMJ_doublezisegscan_num_tblocks_41351 = &ctx->cfg->tuning_params[36];
    ctx->tuning_params.inner_SMJ_doublezisegscan_tblock_sizze_41333 = &ctx->cfg->tuning_params[37];
    ctx->tuning_params.inner_SMJ_doublezisegscan_tblock_sizze_41349 = &ctx->cfg->tuning_params[38];
    ctx->tuning_params.inner_SMJ_doublezisuff_outer_par_0 = &ctx->cfg->tuning_params[39];
    ctx->tuning_params.inner_SMJ_doublezitblock_sizze_43232 = &ctx->cfg->tuning_params[40];
    ctx->tuning_params.inner_SMJ_doublezitblock_sizze_43252 = &ctx->cfg->tuning_params[41];
    ctx->tuning_params.inner_SMJ_doublezitile_sizze_41424 = &ctx->cfg->tuning_params[42];
    ctx->tuning_params.inner_SMJ_doublezitile_sizze_41779 = &ctx->cfg->tuning_params[43];
    ctx->tuning_params.inner_SMJ_floatzisegmap_num_tblocks_41085 = &ctx->cfg->tuning_params[44];
    ctx->tuning_params.inner_SMJ_floatzisegmap_num_tblocks_41127 = &ctx->cfg->tuning_params[45];
    ctx->tuning_params.inner_SMJ_floatzisegmap_num_tblocks_41135 = &ctx->cfg->tuning_params[46];
    ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_41083 = &ctx->cfg->tuning_params[47];
    ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_41099 = &ctx->cfg->tuning_params[48];
    ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_41125 = &ctx->cfg->tuning_params[49];
    ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_41133 = &ctx->cfg->tuning_params[50];
    ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_41141 = &ctx->cfg->tuning_params[51];
    ctx->tuning_params.inner_SMJ_floatzisegscan_num_tblocks_41075 = &ctx->cfg->tuning_params[52];
    ctx->tuning_params.inner_SMJ_floatzisegscan_num_tblocks_41091 = &ctx->cfg->tuning_params[53];
    ctx->tuning_params.inner_SMJ_floatzisegscan_tblock_sizze_41073 = &ctx->cfg->tuning_params[54];
    ctx->tuning_params.inner_SMJ_floatzisegscan_tblock_sizze_41089 = &ctx->cfg->tuning_params[55];
    ctx->tuning_params.inner_SMJ_floatzisuff_outer_par_0 = &ctx->cfg->tuning_params[56];
    ctx->tuning_params.inner_SMJ_floatzitblock_sizze_43232 = &ctx->cfg->tuning_params[57];
    ctx->tuning_params.inner_SMJ_floatzitblock_sizze_43252 = &ctx->cfg->tuning_params[58];
    ctx->tuning_params.inner_SMJ_floatzitile_sizze_41424 = &ctx->cfg->tuning_params[59];
    ctx->tuning_params.inner_SMJ_floatzitile_sizze_41779 = &ctx->cfg->tuning_params[60];
    ctx->tuning_params.inner_SMJ_intzisegmap_num_tblocks_40565 = &ctx->cfg->tuning_params[61];
    ctx->tuning_params.inner_SMJ_intzisegmap_num_tblocks_40607 = &ctx->cfg->tuning_params[62];
    ctx->tuning_params.inner_SMJ_intzisegmap_num_tblocks_40615 = &ctx->cfg->tuning_params[63];
    ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_40563 = &ctx->cfg->tuning_params[64];
    ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_40579 = &ctx->cfg->tuning_params[65];
    ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_40605 = &ctx->cfg->tuning_params[66];
    ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_40613 = &ctx->cfg->tuning_params[67];
    ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_40621 = &ctx->cfg->tuning_params[68];
    ctx->tuning_params.inner_SMJ_intzisegscan_num_tblocks_40555 = &ctx->cfg->tuning_params[69];
    ctx->tuning_params.inner_SMJ_intzisegscan_num_tblocks_40571 = &ctx->cfg->tuning_params[70];
    ctx->tuning_params.inner_SMJ_intzisegscan_tblock_sizze_40553 = &ctx->cfg->tuning_params[71];
    ctx->tuning_params.inner_SMJ_intzisegscan_tblock_sizze_40569 = &ctx->cfg->tuning_params[72];
    ctx->tuning_params.inner_SMJ_intzisuff_outer_par_0 = &ctx->cfg->tuning_params[73];
    ctx->tuning_params.inner_SMJ_intzitblock_sizze_43212 = &ctx->cfg->tuning_params[74];
    ctx->tuning_params.inner_SMJ_intzitblock_sizze_43232 = &ctx->cfg->tuning_params[75];
    ctx->tuning_params.inner_SMJ_intzitile_sizze_41424 = &ctx->cfg->tuning_params[76];
    ctx->tuning_params.inner_SMJ_intzitile_sizze_41779 = &ctx->cfg->tuning_params[77];
    ctx->tuning_params.inner_SMJ_longzisegmap_num_tblocks_40825 = &ctx->cfg->tuning_params[78];
    ctx->tuning_params.inner_SMJ_longzisegmap_num_tblocks_40867 = &ctx->cfg->tuning_params[79];
    ctx->tuning_params.inner_SMJ_longzisegmap_num_tblocks_40875 = &ctx->cfg->tuning_params[80];
    ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_40823 = &ctx->cfg->tuning_params[81];
    ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_40839 = &ctx->cfg->tuning_params[82];
    ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_40865 = &ctx->cfg->tuning_params[83];
    ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_40873 = &ctx->cfg->tuning_params[84];
    ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_40881 = &ctx->cfg->tuning_params[85];
    ctx->tuning_params.inner_SMJ_longzisegscan_num_tblocks_40815 = &ctx->cfg->tuning_params[86];
    ctx->tuning_params.inner_SMJ_longzisegscan_num_tblocks_40831 = &ctx->cfg->tuning_params[87];
    ctx->tuning_params.inner_SMJ_longzisegscan_tblock_sizze_40813 = &ctx->cfg->tuning_params[88];
    ctx->tuning_params.inner_SMJ_longzisegscan_tblock_sizze_40829 = &ctx->cfg->tuning_params[89];
    ctx->tuning_params.inner_SMJ_longzisuff_outer_par_0 = &ctx->cfg->tuning_params[90];
    ctx->tuning_params.inner_SMJ_longzitblock_sizze_43212 = &ctx->cfg->tuning_params[91];
    ctx->tuning_params.inner_SMJ_longzitblock_sizze_43232 = &ctx->cfg->tuning_params[92];
    ctx->tuning_params.inner_SMJ_longzitile_sizze_41424 = &ctx->cfg->tuning_params[93];
    ctx->tuning_params.inner_SMJ_longzitile_sizze_41779 = &ctx->cfg->tuning_params[94];
    ctx->tuning_params.inner_SMJ_shortzisegmap_num_tblocks_40305 = &ctx->cfg->tuning_params[95];
    ctx->tuning_params.inner_SMJ_shortzisegmap_num_tblocks_40347 = &ctx->cfg->tuning_params[96];
    ctx->tuning_params.inner_SMJ_shortzisegmap_num_tblocks_40355 = &ctx->cfg->tuning_params[97];
    ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_40303 = &ctx->cfg->tuning_params[98];
    ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_40319 = &ctx->cfg->tuning_params[99];
    ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_40345 = &ctx->cfg->tuning_params[100];
    ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_40353 = &ctx->cfg->tuning_params[101];
    ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_40361 = &ctx->cfg->tuning_params[102];
    ctx->tuning_params.inner_SMJ_shortzisegscan_num_tblocks_40295 = &ctx->cfg->tuning_params[103];
    ctx->tuning_params.inner_SMJ_shortzisegscan_num_tblocks_40311 = &ctx->cfg->tuning_params[104];
    ctx->tuning_params.inner_SMJ_shortzisegscan_tblock_sizze_40293 = &ctx->cfg->tuning_params[105];
    ctx->tuning_params.inner_SMJ_shortzisegscan_tblock_sizze_40309 = &ctx->cfg->tuning_params[106];
    ctx->tuning_params.inner_SMJ_shortzisuff_outer_par_0 = &ctx->cfg->tuning_params[107];
    ctx->tuning_params.inner_SMJ_shortzitblock_sizze_43232 = &ctx->cfg->tuning_params[108];
    ctx->tuning_params.inner_SMJ_shortzitblock_sizze_43252 = &ctx->cfg->tuning_params[109];
    ctx->tuning_params.inner_SMJ_shortzitile_sizze_41424 = &ctx->cfg->tuning_params[110];
    ctx->tuning_params.inner_SMJ_shortzitile_sizze_41779 = &ctx->cfg->tuning_params[111];
    ctx->tuning_params.max_idxzisegred_num_tblocks_39549 = &ctx->cfg->tuning_params[112];
    ctx->tuning_params.max_idxzisegred_tblock_sizze_39547 = &ctx->cfg->tuning_params[113];
    ctx->tuning_params.min_idxzisegred_num_tblocks_39539 = &ctx->cfg->tuning_params[114];
    ctx->tuning_params.min_idxzisegred_tblock_sizze_39537 = &ctx->cfg->tuning_params[115];
}
int memblock_unref_device(struct futhark_context *ctx, struct memblock_device *block, const char *desc)
{
    if (block->references != NULL) {
        *block->references -= 1;
        if (ctx->detail_memory)
            fprintf(ctx->log, "Unreferencing block %s (allocated as %s) in %s: %d references remaining.\n", desc, block->desc, "space 'device'", *block->references);
        if (*block->references == 0) {
            ctx->cur_mem_usage_device -= block->size;
            (void) gpu_free(ctx, block->mem, block->size, desc);
            free(block->references);
            if (ctx->detail_memory)
                fprintf(ctx->log, "%lld bytes freed (now allocated: %lld bytes)\n", (long long) block->size, (long long) ctx->cur_mem_usage_device);
        }
        block->references = NULL;
    }
    return 0;
}
int memblock_alloc_device(struct futhark_context *ctx, struct memblock_device *block, int64_t size, const char *desc)
{
    if (size < 0)
        futhark_panic(1, "Negative allocation of %lld bytes attempted for %s in %s.\n", (long long) size, desc, "space 'device'", ctx->cur_mem_usage_device);
    
    int ret = memblock_unref_device(ctx, block, desc);
    
    if (ret != FUTHARK_SUCCESS)
        return ret;
    if (ctx->detail_memory)
        fprintf(ctx->log, "Allocating %lld bytes for %s in %s (currently allocated: %lld bytes).\n", (long long) size, desc, "space 'device'", (long long) ctx->cur_mem_usage_device);
    (void) gpu_alloc(ctx, ctx->log, (size_t) size, desc, &block->mem, (size_t *) &size);
    if (ctx->error == NULL) {
        block->references = (int *) malloc(sizeof(int));
        *block->references = 1;
        block->size = size;
        block->desc = desc;
        
        long long new_usage = ctx->cur_mem_usage_device + size;
        
        if (ctx->detail_memory)
            fprintf(ctx->log, "Received block of %lld bytes; now allocated: %lld bytes", (long long) block->size, new_usage);
        ctx->cur_mem_usage_device = new_usage;
        if (new_usage > ctx->peak_mem_usage_device) {
            ctx->peak_mem_usage_device = new_usage;
            if (ctx->detail_memory)
                fprintf(ctx->log, " (new peak).\n");
        } else if (ctx->detail_memory)
            fprintf(ctx->log, ".\n");
        return FUTHARK_SUCCESS;
    } else {
        // We are naively assuming that any memory allocation error is due to OOM.
        lock_lock(&ctx->error_lock);
        
        char *old_error = ctx->error;
        
        ctx->error = msgprintf("Failed to allocate memory in %s.\nAttempted allocation: %12lld bytes\nCurrently allocated:  %12lld bytes\n%s", "space 'device'", (long long) size, (long long) ctx->cur_mem_usage_device, old_error);
        free(old_error);
        lock_unlock(&ctx->error_lock);
        return FUTHARK_OUT_OF_MEMORY;
    }
}
int memblock_set_device(struct futhark_context *ctx, struct memblock_device *lhs, struct memblock_device *rhs, const char *lhs_desc)
{
    int ret = memblock_unref_device(ctx, lhs, lhs_desc);
    
    if (rhs->references != NULL)
        (*rhs->references)++;
    *lhs = *rhs;
    return ret;
}
int memblock_unref(struct futhark_context *ctx, struct memblock *block, const char *desc)
{
    if (block->references != NULL) {
        *block->references -= 1;
        if (ctx->detail_memory)
            fprintf(ctx->log, "Unreferencing block %s (allocated as %s) in %s: %d references remaining.\n", desc, block->desc, "default space", *block->references);
        if (*block->references == 0) {
            ctx->cur_mem_usage_default -= block->size;
            host_free(ctx, (size_t) block->size, desc, (void *) block->mem);
            free(block->references);
            if (ctx->detail_memory)
                fprintf(ctx->log, "%lld bytes freed (now allocated: %lld bytes)\n", (long long) block->size, (long long) ctx->cur_mem_usage_default);
        }
        block->references = NULL;
    }
    return 0;
}
int memblock_alloc(struct futhark_context *ctx, struct memblock *block, int64_t size, const char *desc)
{
    if (size < 0)
        futhark_panic(1, "Negative allocation of %lld bytes attempted for %s in %s.\n", (long long) size, desc, "default space", ctx->cur_mem_usage_default);
    
    int ret = memblock_unref(ctx, block, desc);
    
    if (ret != FUTHARK_SUCCESS)
        return ret;
    if (ctx->detail_memory)
        fprintf(ctx->log, "Allocating %lld bytes for %s in %s (currently allocated: %lld bytes).\n", (long long) size, desc, "default space", (long long) ctx->cur_mem_usage_default);
    host_alloc(ctx, (size_t) size, desc, (size_t *) &size, (void *) &block->mem);
    if (ctx->error == NULL) {
        block->references = (int *) malloc(sizeof(int));
        *block->references = 1;
        block->size = size;
        block->desc = desc;
        
        long long new_usage = ctx->cur_mem_usage_default + size;
        
        if (ctx->detail_memory)
            fprintf(ctx->log, "Received block of %lld bytes; now allocated: %lld bytes", (long long) block->size, new_usage);
        ctx->cur_mem_usage_default = new_usage;
        if (new_usage > ctx->peak_mem_usage_default) {
            ctx->peak_mem_usage_default = new_usage;
            if (ctx->detail_memory)
                fprintf(ctx->log, " (new peak).\n");
        } else if (ctx->detail_memory)
            fprintf(ctx->log, ".\n");
        return FUTHARK_SUCCESS;
    } else {
        // We are naively assuming that any memory allocation error is due to OOM.
        lock_lock(&ctx->error_lock);
        
        char *old_error = ctx->error;
        
        ctx->error = msgprintf("Failed to allocate memory in %s.\nAttempted allocation: %12lld bytes\nCurrently allocated:  %12lld bytes\n%s", "default space", (long long) size, (long long) ctx->cur_mem_usage_default, old_error);
        free(old_error);
        lock_unlock(&ctx->error_lock);
        return FUTHARK_OUT_OF_MEMORY;
    }
}
int memblock_set(struct futhark_context *ctx, struct memblock *lhs, struct memblock *rhs, const char *lhs_desc)
{
    int ret = memblock_unref(ctx, lhs, lhs_desc);
    
    if (rhs->references != NULL)
        (*rhs->references)++;
    *lhs = *rhs;
    return ret;
}
char *futhark_context_report(struct futhark_context *ctx)
{
    if (futhark_context_sync(ctx) != 0)
        return NULL;
    
    struct str_builder builder;
    
    str_builder_init(&builder);
    str_builder_char(&builder, '{');
    str_builder_str(&builder, "\"memory\":{");
    str_builder(&builder, "\"space 'device'\": %lld", (long long) ctx->peak_mem_usage_device);
    str_builder_char(&builder, ',');
    str_builder(&builder, "\"default space\": %lld", (long long) ctx->peak_mem_usage_default);
    str_builder_str(&builder, "},\"events\":[");
    if (report_events_in_list(&ctx->event_list, &builder) != 0) {
        free(builder.str);
        return NULL;
    } else {
        str_builder_str(&builder, "]}");
        return builder.str;
    }
}
int futhark_context_clear_caches(struct futhark_context *ctx)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    ctx->peak_mem_usage_device = 0;
    ctx->peak_mem_usage_default = 0;
    if (ctx->error == NULL)
        gpu_free_all(ctx);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ctx->error != NULL;
}

// Start of context.h

// Internal functions.

static void set_error(struct futhark_context* ctx, char *error) {
  lock_lock(&ctx->error_lock);
  if (ctx->error == NULL) {
    ctx->error = error;
  } else {
    free(error);
  }
  lock_unlock(&ctx->error_lock);
}

// XXX: should be static, but used in ispc_util.h
void lexical_realloc_error(struct futhark_context* ctx, size_t new_size) {
  set_error(ctx,
            msgprintf("Failed to allocate memory.\nAttempted allocation: %12lld bytes\n",
                      (long long) new_size));
}

static int lexical_realloc(struct futhark_context *ctx,
                           unsigned char **ptr,
                           int64_t *old_size,
                           int64_t new_size) {
  unsigned char *new = realloc(*ptr, (size_t)new_size);
  if (new == NULL) {
    lexical_realloc_error(ctx, new_size);
    return FUTHARK_OUT_OF_MEMORY;
  } else {
    *ptr = new;
    *old_size = new_size;
    return FUTHARK_SUCCESS;
  }
}

static void free_all_in_free_list(struct futhark_context* ctx) {
  fl_mem mem;
  free_list_pack(&ctx->free_list);
  while (free_list_first(&ctx->free_list, (fl_mem*)&mem) == 0) {
    free((void*)mem);
  }
}

static int is_small_alloc(size_t size) {
  return size < 1024*1024;
}

static void host_alloc(struct futhark_context* ctx,
                       size_t size, const char* tag, size_t* size_out, void** mem_out) {
  if (is_small_alloc(size) || free_list_find(&ctx->free_list, size, tag, size_out, (fl_mem*)mem_out) != 0) {
    *size_out = size;
    *mem_out = malloc(size);
  }
}

static void host_free(struct futhark_context* ctx,
                      size_t size, const char* tag, void* mem) {
  // Small allocations are handled by malloc()s own free list.  The
  // threshold here is kind of arbitrary, but seems to work OK.
  // Larger allocations are mmap()ed/munmapped() every time, which is
  // very slow, and Futhark programs tend to use a few very large
  // allocations.
  if (is_small_alloc(size)) {
    free(mem);
  } else {
    free_list_insert(&ctx->free_list, size, (fl_mem)mem, tag);
  }
}

static void add_event(struct futhark_context* ctx,
                      const char* name,
                      char* description,
                      void* data,
                      event_report_fn f) {
  if (ctx->logging) {
    fprintf(ctx->log, "Event: %s\n%s\n", name, description);
  }
  add_event_to_list(&ctx->event_list, name, description, data, f);
}

char *futhark_context_get_error(struct futhark_context *ctx) {
  char *error = ctx->error;
  ctx->error = NULL;
  return error;
}

void futhark_context_config_set_debugging(struct futhark_context_config *cfg, int flag) {
    cfg->profiling = cfg->logging = cfg->debugging = flag;
}

void futhark_context_config_set_profiling(struct futhark_context_config *cfg, int flag) {
    cfg->profiling = flag;
}

void futhark_context_config_set_logging(struct futhark_context_config *cfg, int flag) {
    cfg->logging = flag;
}

void futhark_context_config_set_cache_file(struct futhark_context_config *cfg, const char *f) {
  cfg->cache_fname = strdup(f);
}

int futhark_get_tuning_param_count(void) {
  return num_tuning_params;
}

const char *futhark_get_tuning_param_name(int i) {
  return tuning_param_names[i];
}

const char *futhark_get_tuning_param_class(int i) {
    return tuning_param_classes[i];
}

void futhark_context_set_logging_file(struct futhark_context *ctx, FILE *f){
  ctx->log = f;
}

void futhark_context_pause_profiling(struct futhark_context *ctx) {
  ctx->profiling_paused = 1;
}

void futhark_context_unpause_profiling(struct futhark_context *ctx) {
  ctx->profiling_paused = 0;
}

struct futhark_context_config* futhark_context_config_new(void) {
  struct futhark_context_config* cfg = malloc(sizeof(struct futhark_context_config));
  if (cfg == NULL) {
    return NULL;
  }
  cfg->in_use = 0;
  cfg->debugging = 0;
  cfg->profiling = 0;
  cfg->logging = 0;
  cfg->cache_fname = NULL;
  cfg->num_tuning_params = num_tuning_params;
  cfg->tuning_params = malloc(cfg->num_tuning_params * sizeof(int64_t));
  memcpy(cfg->tuning_params, tuning_param_defaults,
         cfg->num_tuning_params * sizeof(int64_t));
  cfg->tuning_param_names = tuning_param_names;
  cfg->tuning_param_vars = tuning_param_vars;
  cfg->tuning_param_classes = tuning_param_classes;
  backend_context_config_setup(cfg);
  return cfg;
}

void futhark_context_config_free(struct futhark_context_config* cfg) {
  assert(!cfg->in_use);
  backend_context_config_teardown(cfg);
  free(cfg->cache_fname);
  free(cfg->tuning_params);
  free(cfg);
}

struct futhark_context* futhark_context_new(struct futhark_context_config* cfg) {
  struct futhark_context* ctx = malloc(sizeof(struct futhark_context));
  if (ctx == NULL) {
    return NULL;
  }
  assert(!cfg->in_use);
  ctx->cfg = cfg;
  ctx->cfg->in_use = 1;
  ctx->program_initialised = false;
  create_lock(&ctx->error_lock);
  create_lock(&ctx->lock);
  free_list_init(&ctx->free_list);
  event_list_init(&ctx->event_list);
  ctx->peak_mem_usage_default = 0;
  ctx->cur_mem_usage_default = 0;
  ctx->constants = malloc(sizeof(struct constants));
  ctx->debugging = cfg->debugging;
  ctx->logging = cfg->logging;
  ctx->detail_memory = cfg->logging;
  ctx->profiling = cfg->profiling;
  ctx->profiling_paused = 0;
  ctx->error = NULL;
  ctx->log = stderr;
  set_tuning_params(ctx);
  if (backend_context_setup(ctx) == 0) {
    setup_program(ctx);
    init_constants(ctx);
    ctx->program_initialised = true;
    (void)futhark_context_clear_caches(ctx);
    (void)futhark_context_sync(ctx);
  }
  return ctx;
}

void futhark_context_free(struct futhark_context* ctx) {
  if (ctx->program_initialised) {
    free_constants(ctx);
    teardown_program(ctx);
  }
  backend_context_teardown(ctx);
  free_all_in_free_list(ctx);
  free_list_destroy(&ctx->free_list);
  event_list_free(&ctx->event_list);
  free(ctx->constants);
  free(ctx->error);
  free_lock(&ctx->lock);
  free_lock(&ctx->error_lock);
  ctx->cfg->in_use = 0;
  free(ctx);
}

// End of context.h

// Start of copy.h

// Cache-oblivious map-transpose function.
#define GEN_MAP_TRANSPOSE(NAME, ELEM_TYPE)                              \
  static void map_transpose_##NAME                                      \
  (ELEM_TYPE* dst, ELEM_TYPE* src,                                      \
   int64_t k, int64_t m, int64_t n,                                     \
   int64_t cb, int64_t ce, int64_t rb, int64_t re)                      \
  {                                                                     \
  int32_t r = re - rb;                                                  \
  int32_t c = ce - cb;                                                  \
  if (k == 1) {                                                         \
    if (r <= 64 && c <= 64) {                                           \
      for (int64_t j = 0; j < c; j++) {                                 \
        for (int64_t i = 0; i < r; i++) {                               \
          dst[(j + cb) * n + (i + rb)] = src[(i + rb) * m + (j + cb)];  \
        }                                                               \
      }                                                                 \
    } else if (c <= r) {                                                \
      map_transpose_##NAME(dst, src, k, m, n, cb, ce, rb, rb + r/2);    \
      map_transpose_##NAME(dst, src, k, m, n, cb, ce, rb + r/2, re);    \
    } else {                                                            \
      map_transpose_##NAME(dst, src, k, m, n, cb, cb + c/2, rb, re);    \
      map_transpose_##NAME(dst, src, k, m, n, cb + c/2, ce, rb, re);    \
    }                                                                   \
  } else {                                                              \
  for (int64_t i = 0; i < k; i++) {                                     \
    map_transpose_##NAME(dst + i * m * n, src + i * m * n, 1, m, n, cb, ce, rb, re); \
  }\
} \
}

// Straightforward LMAD copy function.
#define GEN_LMAD_COPY_ELEMENTS(NAME, ELEM_TYPE)                         \
  static void lmad_copy_elements_##NAME(int r,                          \
                                        ELEM_TYPE* dst, int64_t dst_strides[r], \
                                        ELEM_TYPE *src, int64_t src_strides[r], \
                                        int64_t shape[r]) {             \
    if (r == 1) {                                                       \
      for (int i = 0; i < shape[0]; i++) {                              \
        dst[i*dst_strides[0]] = src[i*src_strides[0]];                  \
      }                                                                 \
    } else if (r > 1) {                                                 \
      for (int i = 0; i < shape[0]; i++) {                              \
        lmad_copy_elements_##NAME(r-1,                                  \
                                  dst+i*dst_strides[0], dst_strides+1,  \
                                  src+i*src_strides[0], src_strides+1,  \
                                  shape+1);                             \
      }                                                                 \
    }                                                                   \
  }                                                                     \

// Check whether this LMAD can be seen as a transposed 2D array.  This
// is done by checking every possible splitting point.
static bool lmad_is_tr(int64_t *n_out, int64_t *m_out,
                       int r,
                       const int64_t strides[r],
                       const int64_t shape[r]) {
  for (int i = 1; i < r; i++) {
    int n = 1, m = 1;
    bool ok = true;
    int64_t expected = 1;
    // Check strides before 'i'.
    for (int j = i-1; j >= 0; j--) {
      ok = ok && strides[j] == expected;
      expected *= shape[j];
      n *= shape[j];
    }
    // Check strides after 'i'.
    for (int j = r-1; j >= i; j--) {
      ok = ok && strides[j] == expected;
      expected *= shape[j];
      m *= shape[j];
    }
    if (ok) {
      *n_out = n;
      *m_out = m;
      return true;
    }
  }
  return false;
}

// This function determines whether the a 'dst' LMAD is row-major and
// 'src' LMAD is column-major.  Both LMADs are for arrays of the same
// shape.  Both LMADs are allowed to have additional dimensions "on
// top".  Essentially, this function determines whether a copy from
// 'src' to 'dst' is a "map(transpose)" that we know how to implement
// efficiently.  The LMADs can have arbitrary rank, and the main
// challenge here is checking whether the src LMAD actually
// corresponds to a 2D column-major layout by morally collapsing
// dimensions.  There is a lot of looping here, but the actual trip
// count is going to be very low in practice.
//
// Returns true if this is indeed a map(transpose), and writes the
// number of arrays, and moral array size to appropriate output
// parameters.
static bool lmad_map_tr(int64_t *num_arrays_out, int64_t *n_out, int64_t *m_out,
                        int r,
                        const int64_t dst_strides[r],
                        const int64_t src_strides[r],
                        const int64_t shape[r]) {
  int64_t rowmajor_strides[r];
  rowmajor_strides[r-1] = 1;

  for (int i = r-2; i >= 0; i--) {
    rowmajor_strides[i] = rowmajor_strides[i+1] * shape[i+1];
  }

  // map_r will be the number of mapped dimensions on top.
  int map_r = 0;
  int64_t num_arrays = 1;
  for (int i = 0; i < r; i++) {
    if (dst_strides[i] != rowmajor_strides[i] ||
        src_strides[i] != rowmajor_strides[i]) {
      break;
    } else {
      num_arrays *= shape[i];
      map_r++;
    }
  }

  *num_arrays_out = num_arrays;

  if (r==map_r) {
    return false;
  }

  if (memcmp(&rowmajor_strides[map_r],
             &dst_strides[map_r],
             sizeof(int64_t)*(r-map_r)) == 0) {
    return lmad_is_tr(n_out, m_out, r-map_r, src_strides+map_r, shape+map_r);
  } else if (memcmp(&rowmajor_strides[map_r],
                    &src_strides[map_r],
                    sizeof(int64_t)*(r-map_r)) == 0) {
    return lmad_is_tr(m_out, n_out, r-map_r, dst_strides+map_r, shape+map_r);
  }
  return false;
}

// Check if the strides correspond to row-major strides of *any*
// permutation of the shape.  This is done by recursive search with
// backtracking.  This is worst-case exponential, but hopefully the
// arrays we encounter do not have that many dimensions.
static bool lmad_contiguous_search(int checked, int64_t expected,
                                   int r,
                                   int64_t strides[r], int64_t shape[r], bool used[r]) {
  for (int i = 0; i < r; i++) {
    for (int j = 0; j < r; j++) {
      if (!used[j] && strides[j] == expected && strides[j] >= 0) {
        used[j] = true;
        if (checked+1 == r ||
            lmad_contiguous_search(checked+1, expected * shape[j], r, strides, shape, used)) {
          return true;
        }
        used[j] = false;
      }
    }
  }
  return false;
}

// Does this LMAD correspond to an array with positive strides and no
// holes?
static bool lmad_contiguous(int r, int64_t strides[r], int64_t shape[r]) {
  bool used[r];
  for (int i = 0; i < r; i++) {
    used[i] = false;
  }
  return lmad_contiguous_search(0, 1, r, strides, shape, used);
}

// Does this copy correspond to something that could be done with a
// memcpy()-like operation?  I.e. do the LMADs actually represent the
// same in-memory layout and are they contiguous?
static bool lmad_memcpyable(int r,
                            int64_t dst_strides[r], int64_t src_strides[r], int64_t shape[r]) {
  if (!lmad_contiguous(r, dst_strides, shape)) {
    return false;
  }
  for (int i = 0; i < r; i++) {
    if (dst_strides[i] != src_strides[i] && shape[i] != 1) {
      return false;
    }
  }
  return true;
}


static void log_copy(struct futhark_context* ctx,
                     const char *kind, int r,
                     int64_t dst_offset, int64_t dst_strides[r],
                     int64_t src_offset, int64_t src_strides[r],
                     int64_t shape[r]) {
  if (ctx->logging) {
    fprintf(ctx->log, "\n# Copy %s\n", kind);
    fprintf(ctx->log, "Shape: ");
    for (int i = 0; i < r; i++) { fprintf(ctx->log, "[%ld]", (long int)shape[i]); }
    fprintf(ctx->log, "\n");
    fprintf(ctx->log, "Dst offset: %ld\n", (long int)dst_offset);
    fprintf(ctx->log, "Dst strides:");
    for (int i = 0; i < r; i++) { fprintf(ctx->log, " %ld", (long int)dst_strides[i]); }
    fprintf(ctx->log, "\n");
    fprintf(ctx->log, "Src offset: %ld\n", (long int)src_offset);
    fprintf(ctx->log, "Src strides:");
    for (int i = 0; i < r; i++) { fprintf(ctx->log, " %ld", (long int)src_strides[i]); }
    fprintf(ctx->log, "\n");
  }
}

static void log_transpose(struct futhark_context* ctx,
                          int64_t k, int64_t n, int64_t m) {
  if (ctx->logging) {
    fprintf(ctx->log, "## Transpose\n");
    fprintf(ctx->log, "Arrays     : %ld\n", (long int)k);
    fprintf(ctx->log, "X elements : %ld\n", (long int)m);
    fprintf(ctx->log, "Y elements : %ld\n", (long int)n);
    fprintf(ctx->log, "\n");
  }
}

#define GEN_LMAD_COPY(NAME, ELEM_TYPE)                                  \
  static void lmad_copy_##NAME                                          \
  (struct futhark_context *ctx, int r,                                  \
   ELEM_TYPE* dst, int64_t dst_offset, int64_t dst_strides[r],          \
   ELEM_TYPE *src, int64_t src_offset, int64_t src_strides[r],          \
   int64_t shape[r]) {                                                  \
    log_copy(ctx, "CPU to CPU", r, dst_offset, dst_strides,             \
             src_offset, src_strides, shape);                           \
    int64_t size = 1;                                                   \
    for (int i = 0; i < r; i++) { size *= shape[i]; }                   \
    if (size == 0) { return; }                                          \
    int64_t k, n, m;                                                    \
    if (lmad_map_tr(&k, &n, &m,                                         \
                    r, dst_strides, src_strides, shape)) {              \
      log_transpose(ctx, k, n, m);                                      \
      map_transpose_##NAME                                              \
        (dst+dst_offset, src+src_offset, k, n, m, 0, n, 0, m);          \
    } else if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {   \
      if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}          \
      memcpy(dst+dst_offset, src+src_offset, size*sizeof(*dst));        \
    } else {                                                            \
      if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}       \
      lmad_copy_elements_##NAME                                         \
        (r,                                                             \
         dst+dst_offset, dst_strides,                                   \
         src+src_offset, src_strides, shape);                           \
    }                                                                   \
  }

GEN_MAP_TRANSPOSE(1b, uint8_t)
GEN_MAP_TRANSPOSE(2b, uint16_t)
GEN_MAP_TRANSPOSE(4b, uint32_t)
GEN_MAP_TRANSPOSE(8b, uint64_t)

GEN_LMAD_COPY_ELEMENTS(1b, uint8_t)
GEN_LMAD_COPY_ELEMENTS(2b, uint16_t)
GEN_LMAD_COPY_ELEMENTS(4b, uint32_t)
GEN_LMAD_COPY_ELEMENTS(8b, uint64_t)

GEN_LMAD_COPY(1b, uint8_t)
GEN_LMAD_COPY(2b, uint16_t)
GEN_LMAD_COPY(4b, uint32_t)
GEN_LMAD_COPY(8b, uint64_t)

// End of copy.h

#define FUTHARK_FUN_ATTR static

FUTHARK_FUN_ATTR int futrts_builtinzhiota_i64(struct futhark_context *ctx, struct memblock_device mem_42707, int64_t n_42708, int64_t x_42709, int64_t s_42710);
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_f32(struct futhark_context *ctx, struct memblock_device mem_42736, int64_t num_elems_42737, float val_42738);
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_f64(struct futhark_context *ctx, struct memblock_device mem_42736, int64_t num_elems_42737, double val_42738);
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i16(struct futhark_context *ctx, struct memblock_device mem_42736, int64_t num_elems_42737, int16_t val_42738);
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i32(struct futhark_context *ctx, struct memblock_device mem_42879, int64_t num_elems_42880, int32_t val_42881);
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i64(struct futhark_context *ctx, struct memblock_device mem_42710, int64_t num_elems_42711, int64_t val_42712);
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i8(struct futhark_context *ctx, struct memblock_device mem_42853, int64_t num_elems_42854, int8_t val_42855);
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_double(struct futhark_context *ctx, struct memblock_device *mem_out_p_43276, struct memblock_device is_mem_42199, struct memblock_device ys_mem_42200, int64_t niz2084U_36170, int64_t dz2083U_36171, int64_t incr_36172, int64_t psizze_36173);
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_double_GFUR(struct futhark_context *ctx, struct memblock_device *mem_out_p_43277, struct memblock_device preVals_mem_42199, struct memblock_device is_mem_42200, struct memblock_device ys_mem_42201, int64_t ni_37677, int64_t n_37678, int64_t incr_37679, int64_t psizze_37680);
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_float(struct futhark_context *ctx, struct memblock_device *mem_out_p_43278, struct memblock_device is_mem_42199, struct memblock_device ys_mem_42200, int64_t niz2084U_35830, int64_t dz2083U_35831, int64_t incr_35832, int64_t psizze_35833);
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_float_GFUR(struct futhark_context *ctx, struct memblock_device *mem_out_p_43279, struct memblock_device preVals_mem_42199, struct memblock_device is_mem_42200, struct memblock_device ys_mem_42201, int64_t ni_37376, int64_t n_37377, int64_t incr_37378, int64_t psizze_37379);
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_int(struct futhark_context *ctx, struct memblock_device *mem_out_p_43280, struct memblock_device is_mem_42199, struct memblock_device ys_mem_42200, int64_t niz2084U_35181, int64_t dz2083U_35182, int64_t incr_35183, int64_t psizze_35184);
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_int_GFUR(struct futhark_context *ctx, struct memblock_device *mem_out_p_43281, struct memblock_device preVals_mem_42199, struct memblock_device is_mem_42200, struct memblock_device ys_mem_42201, int64_t ni_36774, int64_t n_36775, int64_t incr_36776, int64_t psizze_36777);
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_long(struct futhark_context *ctx, struct memblock_device *mem_out_p_43282, struct memblock_device is_mem_42199, struct memblock_device ys_mem_42200, int64_t niz2084U_35490, int64_t dz2083U_35491, int64_t incr_35492, int64_t psizze_35493);
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_long_GFUR(struct futhark_context *ctx, struct memblock_device *mem_out_p_43283, struct memblock_device preVals_mem_42199, struct memblock_device is_mem_42200, struct memblock_device ys_mem_42201, int64_t ni_37075, int64_t n_37076, int64_t incr_37077, int64_t psizze_37078);
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_short(struct futhark_context *ctx, struct memblock_device *mem_out_p_43284, struct memblock_device is_mem_42199, struct memblock_device ys_mem_42200, int64_t niz2084U_34869, int64_t dz2083U_34870, int64_t incr_34871, int64_t psizze_34872);
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_short_GFUR(struct futhark_context *ctx, struct memblock_device *mem_out_p_43285, struct memblock_device preVals_mem_42199, struct memblock_device is_mem_42200, struct memblock_device ys_mem_42201, int64_t ni_36473, int64_t n_36474, int64_t incr_36475, int64_t psizze_36476);
FUTHARK_FUN_ATTR int futrts_entry_inner_SMJ_double(struct futhark_context *ctx, struct memblock_device *mem_out_p_43286, struct memblock_device *mem_out_p_43287, struct memblock_device *mem_out_p_43288, int64_t *out_prim_out_43289, struct memblock_device tR_mem_42199, struct memblock_device tS_mem_42200, int64_t nR_34519, int64_t nS_34520, int64_t offset_R_34523, int64_t offset_S_34524, int64_t partitionsPerWindow_34525, int64_t numberOfWindows_34526, int64_t extParallelism_34527, int64_t scatter_psizze_34528);
FUTHARK_FUN_ATTR int futrts_entry_inner_SMJ_float(struct futhark_context *ctx, struct memblock_device *mem_out_p_43297, struct memblock_device *mem_out_p_43298, struct memblock_device *mem_out_p_43299, int64_t *out_prim_out_43300, struct memblock_device tR_mem_42199, struct memblock_device tS_mem_42200, int64_t nR_32229, int64_t nS_32230, int64_t offset_R_32233, int64_t offset_S_32234, int64_t partitionsPerWindow_32235, int64_t numberOfWindows_32236, int64_t extParallelism_32237, int64_t scatter_psizze_32238);
FUTHARK_FUN_ATTR int futrts_entry_inner_SMJ_int(struct futhark_context *ctx, struct memblock_device *mem_out_p_43308, struct memblock_device *mem_out_p_43309, struct memblock_device *mem_out_p_43310, int64_t *out_prim_out_43311, struct memblock_device tR_mem_42199, struct memblock_device tS_mem_42200, int64_t nR_27729, int64_t nS_27730, int64_t offset_R_27733, int64_t offset_S_27734, int64_t partitionsPerWindow_27735, int64_t numberOfWindows_27736, int64_t extParallelism_27737, int64_t scatter_psizze_27738);
FUTHARK_FUN_ATTR int futrts_entry_inner_SMJ_long(struct futhark_context *ctx, struct memblock_device *mem_out_p_43319, struct memblock_device *mem_out_p_43320, struct memblock_device *mem_out_p_43321, int64_t *out_prim_out_43322, struct memblock_device tR_mem_42199, struct memblock_device tS_mem_42200, int64_t nR_29939, int64_t nS_29940, int64_t offset_R_29943, int64_t offset_S_29944, int64_t partitionsPerWindow_29945, int64_t numberOfWindows_29946, int64_t extParallelism_29947, int64_t scatter_psizze_29948);
FUTHARK_FUN_ATTR int futrts_entry_inner_SMJ_short(struct futhark_context *ctx, struct memblock_device *mem_out_p_43330, struct memblock_device *mem_out_p_43331, struct memblock_device *mem_out_p_43332, int64_t *out_prim_out_43333, struct memblock_device tR_mem_42199, struct memblock_device tS_mem_42200, int64_t nR_25439, int64_t nS_25440, int64_t offset_R_25443, int64_t offset_S_25444, int64_t partitionsPerWindow_25445, int64_t numberOfWindows_25446, int64_t extParallelism_25447, int64_t scatter_psizze_25448);
FUTHARK_FUN_ATTR int futrts_entry_max_idx(struct futhark_context *ctx, int64_t *out_prim_out_43341, struct memblock_device eta_p_mem_42199, int64_t nz2080U_37756);
FUTHARK_FUN_ATTR int futrts_entry_min_idx(struct futhark_context *ctx, int64_t *out_prim_out_43343, struct memblock_device eta_p_mem_42199, int64_t nz2080U_37716);
FUTHARK_FUN_ATTR int futrts_indicesWithIncrement_9601(struct futhark_context *ctx, struct memblock_device *mem_out_p_43345, struct memblock_device xs_mem_42199, int64_t n_22930, int64_t incr_22931);
FUTHARK_FUN_ATTR int futrts_indicesWithIncrement_9701(struct futhark_context *ctx, struct memblock_device *mem_out_p_43346, struct memblock_device xs_mem_42199, int64_t n_25481, int64_t incr_25482);
FUTHARK_FUN_ATTR int futrts_indicesWithIncrement_9775(struct futhark_context *ctx, struct memblock_device *mem_out_p_43347, struct memblock_device xs_mem_42199, int64_t n_27762, int64_t incr_27763);
FUTHARK_FUN_ATTR int futrts_indicesWithIncrement_9844(struct futhark_context *ctx, struct memblock_device *mem_out_p_43348, struct memblock_device xs_mem_42199, int64_t n_29981, int64_t incr_29982);
FUTHARK_FUN_ATTR int futrts_indicesWithIncrement_9920(struct futhark_context *ctx, struct memblock_device *mem_out_p_43349, struct memblock_device xs_mem_42199, int64_t n_32271, int64_t incr_32272);

static int init_constants(struct futhark_context *ctx)
{
    (void) ctx;
    
    int err = 0;
    
    #define counters_mem_42709 (ctx->constants->counters_mem_42709)
    #define global_dynid_mem_42857 (ctx->constants->global_dynid_mem_42857)
    #define global_dynid_mem_42877 (ctx->constants->global_dynid_mem_42877)
    #define global_dynid_mem_42998 (ctx->constants->global_dynid_mem_42998)
    #define global_dynid_mem_43018 (ctx->constants->global_dynid_mem_43018)
    counters_mem_42709.references = NULL;
    global_dynid_mem_42857.references = NULL;
    global_dynid_mem_42877.references = NULL;
    global_dynid_mem_42998.references = NULL;
    global_dynid_mem_43018.references = NULL;
    if (memblock_alloc_device(ctx, &counters_mem_42709, (int64_t) 80, "counters_mem_42709")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_42709, (int64_t) 20, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_42709, (int64_t) 80, "counters_mem_42709")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_42709, (int64_t) 20, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_42877, (int64_t) 4, "global_dynid_mem_42877")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_42877, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_43018, (int64_t) 4, "global_dynid_mem_43018")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_43018, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_42877, (int64_t) 4, "global_dynid_mem_42877")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_42877, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_42998, (int64_t) 4, "global_dynid_mem_42998")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_42998, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_42857, (int64_t) 4, "global_dynid_mem_42857")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_42857, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_42998, (int64_t) 4, "global_dynid_mem_42998")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_42998, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_42877, (int64_t) 4, "global_dynid_mem_42877")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_42877, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_43018, (int64_t) 4, "global_dynid_mem_43018")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_43018, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_42877, (int64_t) 4, "global_dynid_mem_42877")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_42877, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_43018, (int64_t) 4, "global_dynid_mem_43018")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_43018, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    #undef counters_mem_42709
    #undef global_dynid_mem_42857
    #undef global_dynid_mem_42877
    #undef global_dynid_mem_42998
    #undef global_dynid_mem_43018
    
  cleanup:
    return err;
}
static int free_constants(struct futhark_context *ctx)
{
    (void) ctx;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_42709, "ctx->constants->counters_mem_42709") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_42857, "ctx->constants->global_dynid_mem_42857") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_42877, "ctx->constants->global_dynid_mem_42877") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_42998, "ctx->constants->global_dynid_mem_42998") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_43018, "ctx->constants->global_dynid_mem_43018") != 0)
        return 1;
    return 0;
}
static int gpu_kernel_builtinzhiota_i64ziiota_i64_42712(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhiota_i64ziiota_i64_42712, "builtin#iota_i64.iota_i64_42712", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_builtinzhreplicate_f32zireplicate_42741(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, float arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_f32zireplicate_42741, "builtin#replicate_f32.replicate_42741", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_builtinzhreplicate_f64zireplicate_42741(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, double arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_f64zireplicate_42741, "builtin#replicate_f64.replicate_42741", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_builtinzhreplicate_i16zireplicate_42741(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int16_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_i16zireplicate_42741, "builtin#replicate_i16.replicate_42741", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_builtinzhreplicate_i32zireplicate_42884(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int32_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_i32zireplicate_42884, "builtin#replicate_i32.replicate_42884", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_builtinzhreplicate_i64zireplicate_42715(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_i64zireplicate_42715, "builtin#replicate_i64.replicate_42715", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_builtinzhreplicate_i8zireplicate_42858(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int8_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_i8zireplicate_42858, "builtin#replicate_i8.replicate_42858", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_doublezisegmap_39795(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_doublezisegmap_39795, "gather_payloads_double.segmap_39795", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_doublezisegmap_39823(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_doublezisegmap_39823, "gather_payloads_double.segmap_39823", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_double_GFURzisegmap_40075(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_double_GFURzisegmap_40075, "gather_payloads_double_GFUR.segmap_40075", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_double_GFURzisegmap_40103(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_double_GFURzisegmap_40103, "gather_payloads_double_GFUR.segmap_40103", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_floatzisegmap_39739(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_floatzisegmap_39739, "gather_payloads_float.segmap_39739", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_floatzisegmap_39767(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_floatzisegmap_39767, "gather_payloads_float.segmap_39767", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_float_GFURzisegmap_40019(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_float_GFURzisegmap_40019, "gather_payloads_float_GFUR.segmap_40019", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_float_GFURzisegmap_40047(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_float_GFURzisegmap_40047, "gather_payloads_float_GFUR.segmap_40047", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_intzisegmap_39627(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_intzisegmap_39627, "gather_payloads_int.segmap_39627", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_intzisegmap_39655(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_intzisegmap_39655, "gather_payloads_int.segmap_39655", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_int_GFURzisegmap_39907(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_int_GFURzisegmap_39907, "gather_payloads_int_GFUR.segmap_39907", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_int_GFURzisegmap_39935(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_int_GFURzisegmap_39935, "gather_payloads_int_GFUR.segmap_39935", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_longzisegmap_39683(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_longzisegmap_39683, "gather_payloads_long.segmap_39683", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_longzisegmap_39711(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_longzisegmap_39711, "gather_payloads_long.segmap_39711", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_long_GFURzisegmap_39963(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_long_GFURzisegmap_39963, "gather_payloads_long_GFUR.segmap_39963", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_long_GFURzisegmap_39991(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_long_GFURzisegmap_39991, "gather_payloads_long_GFUR.segmap_39991", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_shortzisegmap_39571(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_shortzisegmap_39571, "gather_payloads_short.segmap_39571", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_shortzisegmap_39599(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_shortzisegmap_39599, "gather_payloads_short.segmap_39599", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_short_GFURzisegmap_39851(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_short_GFURzisegmap_39851, "gather_payloads_short_GFUR.segmap_39851", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_short_GFURzisegmap_39879(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_short_GFURzisegmap_39879, "gather_payloads_short_GFUR.segmap_39879", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_doublezigpuseq_42730(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, gpu_mem arg0, gpu_mem arg1)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[3] = {&ctx->global_failure, &arg0, &arg1};
        size_t args_sizes[3] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_doublezigpuseq_42730, "inner_SMJ_double.gpuseq_42730", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 3, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_doublezigpuseq_42756(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_doublezigpuseq_42756, "inner_SMJ_double.gpuseq_42756", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_doublezigpuseq_42772(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4};
        size_t args_sizes[6] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_doublezigpuseq_42772, "inner_SMJ_double.gpuseq_42772", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_doublezigpuseq_42778(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, gpu_mem arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_doublezigpuseq_42778, "inner_SMJ_double.gpuseq_42778", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_doublezigpuseq_42784(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, gpu_mem arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_doublezigpuseq_42784, "inner_SMJ_double.gpuseq_42784", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_doublezisegmap_intrablock_41423(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, bool arg6, int64_t arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_doublezisegmap_intrablock_41423, "inner_SMJ_double.segmap_intrablock_41423", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_doublezisegmap_intrablock_41778(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, bool arg6, int64_t arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_doublezisegmap_intrablock_41778, "inner_SMJ_double.segmap_intrablock_41778", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_doublezisegscan_41339(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_doublezisegscan_41339, "inner_SMJ_double.segscan_41339", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_doublezisegmap_41341(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, int32_t arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14, gpu_mem arg15, gpu_mem arg16, gpu_mem arg17)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[19] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14, &arg15, &arg16, &arg17};
        size_t args_sizes[19] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14), sizeof(arg15), sizeof(arg16), sizeof(arg17)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_doublezisegmap_41341, "inner_SMJ_double.segmap_41341", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 19, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_doublezisegscan_41355(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[15] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13};
        size_t args_sizes[15] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_doublezisegscan_41355, "inner_SMJ_double.segscan_41355", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 15, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_doublezisegmap_41375(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_doublezisegmap_41375, "inner_SMJ_double.segmap_41375", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_doublezigpuseq_43162(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_doublezigpuseq_43162, "inner_SMJ_double.gpuseq_43162", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_doublezigpuseq_43168(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_doublezigpuseq_43168, "inner_SMJ_double.gpuseq_43168", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_doublezigpuseq_43174(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, gpu_mem arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_doublezigpuseq_43174, "inner_SMJ_double.gpuseq_43174", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_doublezisegmap_41391(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_doublezisegmap_41391, "inner_SMJ_double.segmap_41391", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_doublezisegmap_41383(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int32_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_doublezisegmap_41383, "inner_SMJ_double.segmap_41383", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_doublezigpuseq_43221(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_doublezigpuseq_43221, "inner_SMJ_double.gpuseq_43221", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_doublezireplicate_43228(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_doublezireplicate_43228, "inner_SMJ_double.replicate_43228", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_doublezireplicate_43248(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_doublezireplicate_43248, "inner_SMJ_double.replicate_43248", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_doublezisegmap_41413(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_doublezisegmap_41413, "inner_SMJ_double.segmap_41413", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_floatzigpuseq_42730(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, gpu_mem arg0, gpu_mem arg1)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[3] = {&ctx->global_failure, &arg0, &arg1};
        size_t args_sizes[3] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_floatzigpuseq_42730, "inner_SMJ_float.gpuseq_42730", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 3, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_floatzigpuseq_42756(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_floatzigpuseq_42756, "inner_SMJ_float.gpuseq_42756", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_floatzigpuseq_42772(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4};
        size_t args_sizes[6] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_floatzigpuseq_42772, "inner_SMJ_float.gpuseq_42772", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_floatzigpuseq_42778(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, gpu_mem arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_floatzigpuseq_42778, "inner_SMJ_float.gpuseq_42778", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_floatzigpuseq_42784(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, gpu_mem arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_floatzigpuseq_42784, "inner_SMJ_float.gpuseq_42784", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_floatzisegmap_intrablock_41423(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, bool arg6, int64_t arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_floatzisegmap_intrablock_41423, "inner_SMJ_float.segmap_intrablock_41423", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_floatzisegmap_intrablock_41778(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, bool arg6, int64_t arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_floatzisegmap_intrablock_41778, "inner_SMJ_float.segmap_intrablock_41778", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_floatzisegscan_41079(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_floatzisegscan_41079, "inner_SMJ_float.segscan_41079", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_floatzisegmap_41081(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, int32_t arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14, gpu_mem arg15, gpu_mem arg16, gpu_mem arg17)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[19] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14, &arg15, &arg16, &arg17};
        size_t args_sizes[19] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14), sizeof(arg15), sizeof(arg16), sizeof(arg17)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_floatzisegmap_41081, "inner_SMJ_float.segmap_41081", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 19, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_floatzisegscan_41095(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[15] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13};
        size_t args_sizes[15] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_floatzisegscan_41095, "inner_SMJ_float.segscan_41095", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 15, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_floatzisegmap_41115(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_floatzisegmap_41115, "inner_SMJ_float.segmap_41115", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_floatzigpuseq_43162(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_floatzigpuseq_43162, "inner_SMJ_float.gpuseq_43162", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_floatzigpuseq_43168(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_floatzigpuseq_43168, "inner_SMJ_float.gpuseq_43168", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_floatzigpuseq_43174(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, gpu_mem arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_floatzigpuseq_43174, "inner_SMJ_float.gpuseq_43174", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_floatzisegmap_41131(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_floatzisegmap_41131, "inner_SMJ_float.segmap_41131", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_floatzisegmap_41123(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int32_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_floatzisegmap_41123, "inner_SMJ_float.segmap_41123", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_floatzigpuseq_43221(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_floatzigpuseq_43221, "inner_SMJ_float.gpuseq_43221", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_floatzireplicate_43228(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_floatzireplicate_43228, "inner_SMJ_float.replicate_43228", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_floatzireplicate_43248(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_floatzireplicate_43248, "inner_SMJ_float.replicate_43248", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_floatzisegmap_41153(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_floatzisegmap_41153, "inner_SMJ_float.segmap_41153", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzigpuseq_42730(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, gpu_mem arg0, gpu_mem arg1)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[3] = {&ctx->global_failure, &arg0, &arg1};
        size_t args_sizes[3] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_42730, "inner_SMJ_int.gpuseq_42730", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 3, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzigpuseq_42756(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_42756, "inner_SMJ_int.gpuseq_42756", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzigpuseq_42772(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4};
        size_t args_sizes[6] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_42772, "inner_SMJ_int.gpuseq_42772", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzigpuseq_42778(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, gpu_mem arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_42778, "inner_SMJ_int.gpuseq_42778", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzigpuseq_42784(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, gpu_mem arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_42784, "inner_SMJ_int.gpuseq_42784", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzisegmap_intrablock_41423(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, bool arg6, int64_t arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_intrablock_41423, "inner_SMJ_int.segmap_intrablock_41423", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzisegmap_intrablock_41778(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, bool arg6, int64_t arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_intrablock_41778, "inner_SMJ_int.segmap_intrablock_41778", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzisegscan_40559(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzisegscan_40559, "inner_SMJ_int.segscan_40559", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzisegmap_40561(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, int32_t arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14, gpu_mem arg15, gpu_mem arg16, gpu_mem arg17)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[19] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14, &arg15, &arg16, &arg17};
        size_t args_sizes[19] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14), sizeof(arg15), sizeof(arg16), sizeof(arg17)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_40561, "inner_SMJ_int.segmap_40561", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 19, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzisegscan_40575(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[15] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13};
        size_t args_sizes[15] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzisegscan_40575, "inner_SMJ_int.segscan_40575", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 15, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzisegmap_40595(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_40595, "inner_SMJ_int.segmap_40595", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzigpuseq_43142(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_43142, "inner_SMJ_int.gpuseq_43142", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzigpuseq_43148(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_43148, "inner_SMJ_int.gpuseq_43148", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzigpuseq_43154(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, gpu_mem arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_43154, "inner_SMJ_int.gpuseq_43154", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzisegmap_40611(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_40611, "inner_SMJ_int.segmap_40611", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzisegmap_40603(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int32_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_40603, "inner_SMJ_int.segmap_40603", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzigpuseq_43201(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_43201, "inner_SMJ_int.gpuseq_43201", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzireplicate_43208(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzireplicate_43208, "inner_SMJ_int.replicate_43208", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzireplicate_43228(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzireplicate_43228, "inner_SMJ_int.replicate_43228", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzisegmap_40633(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_40633, "inner_SMJ_int.segmap_40633", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_longzigpuseq_42730(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, gpu_mem arg0, gpu_mem arg1)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[3] = {&ctx->global_failure, &arg0, &arg1};
        size_t args_sizes[3] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_longzigpuseq_42730, "inner_SMJ_long.gpuseq_42730", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 3, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_longzigpuseq_42736(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_longzigpuseq_42736, "inner_SMJ_long.gpuseq_42736", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_longzigpuseq_42752(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4};
        size_t args_sizes[6] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_longzigpuseq_42752, "inner_SMJ_long.gpuseq_42752", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_longzigpuseq_42758(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, gpu_mem arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_longzigpuseq_42758, "inner_SMJ_long.gpuseq_42758", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_longzigpuseq_42764(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, gpu_mem arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_longzigpuseq_42764, "inner_SMJ_long.gpuseq_42764", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_longzisegmap_intrablock_41423(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, bool arg6, int64_t arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_longzisegmap_intrablock_41423, "inner_SMJ_long.segmap_intrablock_41423", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_longzisegmap_intrablock_41778(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, bool arg6, int64_t arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_longzisegmap_intrablock_41778, "inner_SMJ_long.segmap_intrablock_41778", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_longzisegscan_40819(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_longzisegscan_40819, "inner_SMJ_long.segscan_40819", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_longzisegmap_40821(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, int32_t arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14, gpu_mem arg15, gpu_mem arg16, gpu_mem arg17)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[19] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14, &arg15, &arg16, &arg17};
        size_t args_sizes[19] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14), sizeof(arg15), sizeof(arg16), sizeof(arg17)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_longzisegmap_40821, "inner_SMJ_long.segmap_40821", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 19, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_longzisegscan_40835(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[15] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13};
        size_t args_sizes[15] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_longzisegscan_40835, "inner_SMJ_long.segscan_40835", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 15, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_longzisegmap_40855(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_longzisegmap_40855, "inner_SMJ_long.segmap_40855", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_longzigpuseq_43142(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_longzigpuseq_43142, "inner_SMJ_long.gpuseq_43142", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_longzigpuseq_43148(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_longzigpuseq_43148, "inner_SMJ_long.gpuseq_43148", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_longzigpuseq_43154(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, gpu_mem arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_longzigpuseq_43154, "inner_SMJ_long.gpuseq_43154", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_longzisegmap_40871(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_longzisegmap_40871, "inner_SMJ_long.segmap_40871", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_longzisegmap_40863(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int32_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_longzisegmap_40863, "inner_SMJ_long.segmap_40863", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_longzigpuseq_43201(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_longzigpuseq_43201, "inner_SMJ_long.gpuseq_43201", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_longzireplicate_43208(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_longzireplicate_43208, "inner_SMJ_long.replicate_43208", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_longzireplicate_43228(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_longzireplicate_43228, "inner_SMJ_long.replicate_43228", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_longzisegmap_40893(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_longzisegmap_40893, "inner_SMJ_long.segmap_40893", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_shortzigpuseq_42730(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, gpu_mem arg0, gpu_mem arg1)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[3] = {&ctx->global_failure, &arg0, &arg1};
        size_t args_sizes[3] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_shortzigpuseq_42730, "inner_SMJ_short.gpuseq_42730", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 3, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_shortzigpuseq_42756(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_shortzigpuseq_42756, "inner_SMJ_short.gpuseq_42756", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_shortzigpuseq_42772(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4};
        size_t args_sizes[6] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_shortzigpuseq_42772, "inner_SMJ_short.gpuseq_42772", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_shortzigpuseq_42778(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, gpu_mem arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_shortzigpuseq_42778, "inner_SMJ_short.gpuseq_42778", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_shortzigpuseq_42784(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, gpu_mem arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_shortzigpuseq_42784, "inner_SMJ_short.gpuseq_42784", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_shortzisegmap_intrablock_41423(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, bool arg6, int64_t arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_shortzisegmap_intrablock_41423, "inner_SMJ_short.segmap_intrablock_41423", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_shortzisegmap_intrablock_41778(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, bool arg6, int64_t arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_shortzisegmap_intrablock_41778, "inner_SMJ_short.segmap_intrablock_41778", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_shortzisegscan_40299(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_shortzisegscan_40299, "inner_SMJ_short.segscan_40299", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_shortzisegmap_40301(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, int32_t arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14, gpu_mem arg15, gpu_mem arg16, gpu_mem arg17)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[19] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14, &arg15, &arg16, &arg17};
        size_t args_sizes[19] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14), sizeof(arg15), sizeof(arg16), sizeof(arg17)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_shortzisegmap_40301, "inner_SMJ_short.segmap_40301", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 19, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_shortzisegscan_40315(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[15] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13};
        size_t args_sizes[15] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_shortzisegscan_40315, "inner_SMJ_short.segscan_40315", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 15, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_shortzisegmap_40335(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_shortzisegmap_40335, "inner_SMJ_short.segmap_40335", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_shortzigpuseq_43162(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_shortzigpuseq_43162, "inner_SMJ_short.gpuseq_43162", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_shortzigpuseq_43168(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_shortzigpuseq_43168, "inner_SMJ_short.gpuseq_43168", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_shortzigpuseq_43174(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, gpu_mem arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_shortzigpuseq_43174, "inner_SMJ_short.gpuseq_43174", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_shortzisegmap_40351(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_shortzisegmap_40351, "inner_SMJ_short.segmap_40351", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_shortzisegmap_40343(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int32_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_shortzisegmap_40343, "inner_SMJ_short.segmap_40343", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_shortzigpuseq_43221(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_shortzigpuseq_43221, "inner_SMJ_short.gpuseq_43221", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_shortzireplicate_43228(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_shortzireplicate_43228, "inner_SMJ_short.replicate_43228", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_shortzireplicate_43248(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_shortzireplicate_43248, "inner_SMJ_short.replicate_43248", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_shortzisegmap_40373(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_shortzisegmap_40373, "inner_SMJ_short.segmap_40373", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_max_idxzisegred_nonseg_39555(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->max_idxzisegred_nonseg_39555, "max_idx.segred_nonseg_39555", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_min_idxzisegred_nonseg_39545(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->min_idxzisegred_nonseg_39545, "min_idx.segred_nonseg_39545", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
struct futhark_i16_1d {
    struct memblock_device mem;
    int64_t shape[1];
};
struct futhark_i16_1d *futhark_new_i16_1d(struct futhark_context *ctx, const int16_t *data, int64_t dim0)
{
    int err = 0;
    struct futhark_i16_1d *bad = NULL;
    struct futhark_i16_1d *arr = (struct futhark_i16_1d *) malloc(sizeof(struct futhark_i16_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * 2, "arr->mem"))
        err = 1;
    arr->shape[0] = dim0;
    err = memcpy_host2gpu(ctx, false, arr->mem.mem, 0, (const unsigned char *) data, 0, (size_t) dim0 * 2);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    if (err != 0) {
        free(arr);
        return bad;
    }
    return arr;
}
struct futhark_i16_1d *futhark_new_raw_i16_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0)
{
    int err = 0;
    struct futhark_i16_1d *bad = NULL;
    struct futhark_i16_1d *arr = (struct futhark_i16_1d *) malloc(sizeof(struct futhark_i16_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    arr->mem.mem = data;
    arr->shape[0] = dim0;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_i16_1d(struct futhark_context *ctx, struct futhark_i16_1d *arr)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_i16_1d(struct futhark_context *ctx, struct futhark_i16_1d *arr, int16_t *data)
{
    int err = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    err = memcpy_gpu2host(ctx, false, (unsigned char *) data, 0, arr->mem.mem, 0, (size_t) arr->shape[0] * 2);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return err;
}
int futhark_index_i16_1d(struct futhark_context *ctx, int16_t *out, struct futhark_i16_1d *arr, int64_t i0)
{
    int err = 0;
    
    if (i0 >= 0 && i0 < arr->shape[0]) {
        lock_lock(&ctx->lock);
        CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
        err = memcpy_gpu2host(ctx, false, (unsigned char *) out, 0, arr->mem.mem, 2 * (i0 * 1), 2);
        CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
        lock_unlock(&ctx->lock);
    } else {
        err = 1;
        set_error(ctx, strdup("Index out of bounds."));
    }
    return err;
}
CUdeviceptr futhark_values_raw_i16_1d(struct futhark_context *ctx, struct futhark_i16_1d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_i16_1d(struct futhark_context *ctx, struct futhark_i16_1d *arr)
{
    (void) ctx;
    return arr->shape;
}
struct futhark_i32_1d {
    struct memblock_device mem;
    int64_t shape[1];
};
struct futhark_i32_1d *futhark_new_i32_1d(struct futhark_context *ctx, const int32_t *data, int64_t dim0)
{
    int err = 0;
    struct futhark_i32_1d *bad = NULL;
    struct futhark_i32_1d *arr = (struct futhark_i32_1d *) malloc(sizeof(struct futhark_i32_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * 4, "arr->mem"))
        err = 1;
    arr->shape[0] = dim0;
    err = memcpy_host2gpu(ctx, false, arr->mem.mem, 0, (const unsigned char *) data, 0, (size_t) dim0 * 4);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    if (err != 0) {
        free(arr);
        return bad;
    }
    return arr;
}
struct futhark_i32_1d *futhark_new_raw_i32_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0)
{
    int err = 0;
    struct futhark_i32_1d *bad = NULL;
    struct futhark_i32_1d *arr = (struct futhark_i32_1d *) malloc(sizeof(struct futhark_i32_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    arr->mem.mem = data;
    arr->shape[0] = dim0;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr, int32_t *data)
{
    int err = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    err = memcpy_gpu2host(ctx, false, (unsigned char *) data, 0, arr->mem.mem, 0, (size_t) arr->shape[0] * 4);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return err;
}
int futhark_index_i32_1d(struct futhark_context *ctx, int32_t *out, struct futhark_i32_1d *arr, int64_t i0)
{
    int err = 0;
    
    if (i0 >= 0 && i0 < arr->shape[0]) {
        lock_lock(&ctx->lock);
        CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
        err = memcpy_gpu2host(ctx, false, (unsigned char *) out, 0, arr->mem.mem, 4 * (i0 * 1), 4);
        CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
        lock_unlock(&ctx->lock);
    } else {
        err = 1;
        set_error(ctx, strdup("Index out of bounds."));
    }
    return err;
}
CUdeviceptr futhark_values_raw_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr)
{
    (void) ctx;
    return arr->shape;
}
struct futhark_i64_1d {
    struct memblock_device mem;
    int64_t shape[1];
};
struct futhark_i64_1d *futhark_new_i64_1d(struct futhark_context *ctx, const int64_t *data, int64_t dim0)
{
    int err = 0;
    struct futhark_i64_1d *bad = NULL;
    struct futhark_i64_1d *arr = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * 8, "arr->mem"))
        err = 1;
    arr->shape[0] = dim0;
    err = memcpy_host2gpu(ctx, false, arr->mem.mem, 0, (const unsigned char *) data, 0, (size_t) dim0 * 8);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    if (err != 0) {
        free(arr);
        return bad;
    }
    return arr;
}
struct futhark_i64_1d *futhark_new_raw_i64_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0)
{
    int err = 0;
    struct futhark_i64_1d *bad = NULL;
    struct futhark_i64_1d *arr = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    arr->mem.mem = data;
    arr->shape[0] = dim0;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr, int64_t *data)
{
    int err = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    err = memcpy_gpu2host(ctx, false, (unsigned char *) data, 0, arr->mem.mem, 0, (size_t) arr->shape[0] * 8);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return err;
}
int futhark_index_i64_1d(struct futhark_context *ctx, int64_t *out, struct futhark_i64_1d *arr, int64_t i0)
{
    int err = 0;
    
    if (i0 >= 0 && i0 < arr->shape[0]) {
        lock_lock(&ctx->lock);
        CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
        err = memcpy_gpu2host(ctx, false, (unsigned char *) out, 0, arr->mem.mem, 8 * (i0 * 1), 8);
        CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
        lock_unlock(&ctx->lock);
    } else {
        err = 1;
        set_error(ctx, strdup("Index out of bounds."));
    }
    return err;
}
CUdeviceptr futhark_values_raw_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr)
{
    (void) ctx;
    return arr->shape;
}
struct futhark_f32_1d {
    struct memblock_device mem;
    int64_t shape[1];
};
struct futhark_f32_1d *futhark_new_f32_1d(struct futhark_context *ctx, const float *data, int64_t dim0)
{
    int err = 0;
    struct futhark_f32_1d *bad = NULL;
    struct futhark_f32_1d *arr = (struct futhark_f32_1d *) malloc(sizeof(struct futhark_f32_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * 4, "arr->mem"))
        err = 1;
    arr->shape[0] = dim0;
    err = memcpy_host2gpu(ctx, false, arr->mem.mem, 0, (const unsigned char *) data, 0, (size_t) dim0 * 4);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    if (err != 0) {
        free(arr);
        return bad;
    }
    return arr;
}
struct futhark_f32_1d *futhark_new_raw_f32_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0)
{
    int err = 0;
    struct futhark_f32_1d *bad = NULL;
    struct futhark_f32_1d *arr = (struct futhark_f32_1d *) malloc(sizeof(struct futhark_f32_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    arr->mem.mem = data;
    arr->shape[0] = dim0;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr, float *data)
{
    int err = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    err = memcpy_gpu2host(ctx, false, (unsigned char *) data, 0, arr->mem.mem, 0, (size_t) arr->shape[0] * 4);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return err;
}
int futhark_index_f32_1d(struct futhark_context *ctx, float *out, struct futhark_f32_1d *arr, int64_t i0)
{
    int err = 0;
    
    if (i0 >= 0 && i0 < arr->shape[0]) {
        lock_lock(&ctx->lock);
        CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
        err = memcpy_gpu2host(ctx, false, (unsigned char *) out, 0, arr->mem.mem, 4 * (i0 * 1), 4);
        CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
        lock_unlock(&ctx->lock);
    } else {
        err = 1;
        set_error(ctx, strdup("Index out of bounds."));
    }
    return err;
}
CUdeviceptr futhark_values_raw_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr)
{
    (void) ctx;
    return arr->shape;
}
struct futhark_f64_1d {
    struct memblock_device mem;
    int64_t shape[1];
};
struct futhark_f64_1d *futhark_new_f64_1d(struct futhark_context *ctx, const double *data, int64_t dim0)
{
    int err = 0;
    struct futhark_f64_1d *bad = NULL;
    struct futhark_f64_1d *arr = (struct futhark_f64_1d *) malloc(sizeof(struct futhark_f64_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * 8, "arr->mem"))
        err = 1;
    arr->shape[0] = dim0;
    err = memcpy_host2gpu(ctx, false, arr->mem.mem, 0, (const unsigned char *) data, 0, (size_t) dim0 * 8);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    if (err != 0) {
        free(arr);
        return bad;
    }
    return arr;
}
struct futhark_f64_1d *futhark_new_raw_f64_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0)
{
    int err = 0;
    struct futhark_f64_1d *bad = NULL;
    struct futhark_f64_1d *arr = (struct futhark_f64_1d *) malloc(sizeof(struct futhark_f64_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    arr->mem.mem = data;
    arr->shape[0] = dim0;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_f64_1d(struct futhark_context *ctx, struct futhark_f64_1d *arr)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_f64_1d(struct futhark_context *ctx, struct futhark_f64_1d *arr, double *data)
{
    int err = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    err = memcpy_gpu2host(ctx, false, (unsigned char *) data, 0, arr->mem.mem, 0, (size_t) arr->shape[0] * 8);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return err;
}
int futhark_index_f64_1d(struct futhark_context *ctx, double *out, struct futhark_f64_1d *arr, int64_t i0)
{
    int err = 0;
    
    if (i0 >= 0 && i0 < arr->shape[0]) {
        lock_lock(&ctx->lock);
        CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
        err = memcpy_gpu2host(ctx, false, (unsigned char *) out, 0, arr->mem.mem, 8 * (i0 * 1), 8);
        CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
        lock_unlock(&ctx->lock);
    } else {
        err = 1;
        set_error(ctx, strdup("Index out of bounds."));
    }
    return err;
}
CUdeviceptr futhark_values_raw_f64_1d(struct futhark_context *ctx, struct futhark_f64_1d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_f64_1d(struct futhark_context *ctx, struct futhark_f64_1d *arr)
{
    (void) ctx;
    return arr->shape;
}
struct futhark_opaque_joinPairs_short {
    struct futhark_i64_1d *v0;
    struct futhark_i64_1d *v1;
    struct futhark_i16_1d *v2;
};
int futhark_project_opaque_joinPairs_short_ix(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_short *obj)
{
    (void) ctx;
    
    struct futhark_i64_1d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_i64_1d));
    memcpy(v, obj->v0, sizeof(struct futhark_i64_1d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_project_opaque_joinPairs_short_iy(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_short *obj)
{
    (void) ctx;
    
    struct futhark_i64_1d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_i64_1d));
    memcpy(v, obj->v1, sizeof(struct futhark_i64_1d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_project_opaque_joinPairs_short_vs(struct futhark_context *ctx, struct futhark_i16_1d **out, const struct futhark_opaque_joinPairs_short *obj)
{
    (void) ctx;
    
    struct futhark_i16_1d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_i16_1d));
    memcpy(v, obj->v2, sizeof(struct futhark_i16_1d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_new_opaque_joinPairs_short(struct futhark_context *ctx, struct futhark_opaque_joinPairs_short **out, const struct futhark_i64_1d *f_ix, const struct futhark_i64_1d *f_iy, const struct futhark_i16_1d *f_vs)
{
    struct futhark_opaque_joinPairs_short *v = malloc(sizeof(struct futhark_opaque_joinPairs_short));
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    {
        v->v0 = malloc(sizeof(struct futhark_i64_1d));
        *v->v0 = *f_ix;
        (void) (*v->v0->mem.references)++;
    }
    {
        v->v1 = malloc(sizeof(struct futhark_i64_1d));
        *v->v1 = *f_iy;
        (void) (*v->v1->mem.references)++;
    }
    {
        v->v2 = malloc(sizeof(struct futhark_i16_1d));
        *v->v2 = *f_vs;
        (void) (*v->v2->mem.references)++;
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return FUTHARK_SUCCESS;
}
int futhark_free_opaque_joinPairs_short(struct futhark_context *ctx, struct futhark_opaque_joinPairs_short *obj)
{
    (void) ctx;
    
    int ret = 0, tmp;
    
    if (obj->v0 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v0)) != 0)
        ret = tmp;
    if (obj->v1 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v1)) != 0)
        ret = tmp;
    if (obj->v2 != NULL && (tmp = futhark_free_i16_1d(ctx, obj->v2)) != 0)
        ret = tmp;
    free(obj);
    return ret;
}
int futhark_store_opaque_joinPairs_short(struct futhark_context *ctx, const struct futhark_opaque_joinPairs_short *obj, void **p, size_t *n)
{
    (void) ctx;
    
    int ret = 0;
    int64_t size_0 = 7 + 1 * sizeof(int64_t) + futhark_shape_i64_1d(ctx, obj->v0)[0] * sizeof(int64_t);
    int64_t size_1 = 7 + 1 * sizeof(int64_t) + futhark_shape_i64_1d(ctx, obj->v1)[0] * sizeof(int64_t);
    int64_t size_2 = 7 + 1 * sizeof(int64_t) + futhark_shape_i16_1d(ctx, obj->v2)[0] * sizeof(int16_t);
    
    *n = size_0 + size_1 + size_2;
    if (p != NULL && *p == NULL)
        *p = malloc(*n);
    if (p != NULL) {
        unsigned char *out = *p;
        
        *out++ = 'b';
        *out++ = 2;
        *out++ = 1;
        memcpy(out, " i64", 4);
        out += 4;
        memcpy(out, futhark_shape_i64_1d(ctx, obj->v0), 1 * sizeof(int64_t));
        out += 1 * sizeof(int64_t);
        ret |= futhark_values_i64_1d(ctx, obj->v0, (void *) out);
        out += futhark_shape_i64_1d(ctx, obj->v0)[0] * sizeof(int64_t);
        *out++ = 'b';
        *out++ = 2;
        *out++ = 1;
        memcpy(out, " i64", 4);
        out += 4;
        memcpy(out, futhark_shape_i64_1d(ctx, obj->v1), 1 * sizeof(int64_t));
        out += 1 * sizeof(int64_t);
        ret |= futhark_values_i64_1d(ctx, obj->v1, (void *) out);
        out += futhark_shape_i64_1d(ctx, obj->v1)[0] * sizeof(int64_t);
        *out++ = 'b';
        *out++ = 2;
        *out++ = 1;
        memcpy(out, " i16", 4);
        out += 4;
        memcpy(out, futhark_shape_i16_1d(ctx, obj->v2), 1 * sizeof(int64_t));
        out += 1 * sizeof(int64_t);
        ret |= futhark_values_i16_1d(ctx, obj->v2, (void *) out);
        out += futhark_shape_i16_1d(ctx, obj->v2)[0] * sizeof(int16_t);
    }
    return ret;
}
struct futhark_opaque_joinPairs_short *futhark_restore_opaque_joinPairs_short(struct futhark_context *ctx, const void *p)
{
    (void) ctx;
    
    int err = 0;
    const unsigned char *src = p;
    struct futhark_opaque_joinPairs_short *obj = malloc(sizeof(struct futhark_opaque_joinPairs_short));
    int64_t shape_0[1] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 1;
    err |= memcmp(src, " i64", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_0, src, 1 * sizeof(int64_t));
        src += 1 * sizeof(int64_t);
    }
    
    const void *data_0 = src;
    
    obj->v0 = NULL;
    src += shape_0[0] * sizeof(int64_t);
    
    int64_t shape_1[1] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 1;
    err |= memcmp(src, " i64", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_1, src, 1 * sizeof(int64_t));
        src += 1 * sizeof(int64_t);
    }
    
    const void *data_1 = src;
    
    obj->v1 = NULL;
    src += shape_1[0] * sizeof(int64_t);
    
    int64_t shape_2[1] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 1;
    err |= memcmp(src, " i16", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_2, src, 1 * sizeof(int64_t));
        src += 1 * sizeof(int64_t);
    }
    
    const void *data_2 = src;
    
    obj->v2 = NULL;
    src += shape_2[0] * sizeof(int16_t);
    if (err == 0) {
        obj->v0 = futhark_new_i64_1d(ctx, data_0, shape_0[0]);
        if (obj->v0 == NULL)
            err = 1;
        obj->v1 = futhark_new_i64_1d(ctx, data_1, shape_1[0]);
        if (obj->v1 == NULL)
            err = 1;
        obj->v2 = futhark_new_i16_1d(ctx, data_2, shape_2[0]);
        if (obj->v2 == NULL)
            err = 1;
    }
    if (err != 0) {
        int ret = 0, tmp;
        
        if (obj->v0 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v0)) != 0)
            ret = tmp;
        if (obj->v1 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v1)) != 0)
            ret = tmp;
        if (obj->v2 != NULL && (tmp = futhark_free_i16_1d(ctx, obj->v2)) != 0)
            ret = tmp;
        free(obj);
        obj = NULL;
    }
    return obj;
}
struct futhark_opaque_joinPairs_int {
    struct futhark_i64_1d *v0;
    struct futhark_i64_1d *v1;
    struct futhark_i32_1d *v2;
};
int futhark_project_opaque_joinPairs_int_ix(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_int *obj)
{
    (void) ctx;
    
    struct futhark_i64_1d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_i64_1d));
    memcpy(v, obj->v0, sizeof(struct futhark_i64_1d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_project_opaque_joinPairs_int_iy(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_int *obj)
{
    (void) ctx;
    
    struct futhark_i64_1d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_i64_1d));
    memcpy(v, obj->v1, sizeof(struct futhark_i64_1d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_project_opaque_joinPairs_int_vs(struct futhark_context *ctx, struct futhark_i32_1d **out, const struct futhark_opaque_joinPairs_int *obj)
{
    (void) ctx;
    
    struct futhark_i32_1d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_i32_1d));
    memcpy(v, obj->v2, sizeof(struct futhark_i32_1d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_new_opaque_joinPairs_int(struct futhark_context *ctx, struct futhark_opaque_joinPairs_int **out, const struct futhark_i64_1d *f_ix, const struct futhark_i64_1d *f_iy, const struct futhark_i32_1d *f_vs)
{
    struct futhark_opaque_joinPairs_int *v = malloc(sizeof(struct futhark_opaque_joinPairs_int));
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    {
        v->v0 = malloc(sizeof(struct futhark_i64_1d));
        *v->v0 = *f_ix;
        (void) (*v->v0->mem.references)++;
    }
    {
        v->v1 = malloc(sizeof(struct futhark_i64_1d));
        *v->v1 = *f_iy;
        (void) (*v->v1->mem.references)++;
    }
    {
        v->v2 = malloc(sizeof(struct futhark_i32_1d));
        *v->v2 = *f_vs;
        (void) (*v->v2->mem.references)++;
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return FUTHARK_SUCCESS;
}
int futhark_free_opaque_joinPairs_int(struct futhark_context *ctx, struct futhark_opaque_joinPairs_int *obj)
{
    (void) ctx;
    
    int ret = 0, tmp;
    
    if (obj->v0 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v0)) != 0)
        ret = tmp;
    if (obj->v1 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v1)) != 0)
        ret = tmp;
    if (obj->v2 != NULL && (tmp = futhark_free_i32_1d(ctx, obj->v2)) != 0)
        ret = tmp;
    free(obj);
    return ret;
}
int futhark_store_opaque_joinPairs_int(struct futhark_context *ctx, const struct futhark_opaque_joinPairs_int *obj, void **p, size_t *n)
{
    (void) ctx;
    
    int ret = 0;
    int64_t size_0 = 7 + 1 * sizeof(int64_t) + futhark_shape_i64_1d(ctx, obj->v0)[0] * sizeof(int64_t);
    int64_t size_1 = 7 + 1 * sizeof(int64_t) + futhark_shape_i64_1d(ctx, obj->v1)[0] * sizeof(int64_t);
    int64_t size_2 = 7 + 1 * sizeof(int64_t) + futhark_shape_i32_1d(ctx, obj->v2)[0] * sizeof(int32_t);
    
    *n = size_0 + size_1 + size_2;
    if (p != NULL && *p == NULL)
        *p = malloc(*n);
    if (p != NULL) {
        unsigned char *out = *p;
        
        *out++ = 'b';
        *out++ = 2;
        *out++ = 1;
        memcpy(out, " i64", 4);
        out += 4;
        memcpy(out, futhark_shape_i64_1d(ctx, obj->v0), 1 * sizeof(int64_t));
        out += 1 * sizeof(int64_t);
        ret |= futhark_values_i64_1d(ctx, obj->v0, (void *) out);
        out += futhark_shape_i64_1d(ctx, obj->v0)[0] * sizeof(int64_t);
        *out++ = 'b';
        *out++ = 2;
        *out++ = 1;
        memcpy(out, " i64", 4);
        out += 4;
        memcpy(out, futhark_shape_i64_1d(ctx, obj->v1), 1 * sizeof(int64_t));
        out += 1 * sizeof(int64_t);
        ret |= futhark_values_i64_1d(ctx, obj->v1, (void *) out);
        out += futhark_shape_i64_1d(ctx, obj->v1)[0] * sizeof(int64_t);
        *out++ = 'b';
        *out++ = 2;
        *out++ = 1;
        memcpy(out, " i32", 4);
        out += 4;
        memcpy(out, futhark_shape_i32_1d(ctx, obj->v2), 1 * sizeof(int64_t));
        out += 1 * sizeof(int64_t);
        ret |= futhark_values_i32_1d(ctx, obj->v2, (void *) out);
        out += futhark_shape_i32_1d(ctx, obj->v2)[0] * sizeof(int32_t);
    }
    return ret;
}
struct futhark_opaque_joinPairs_int *futhark_restore_opaque_joinPairs_int(struct futhark_context *ctx, const void *p)
{
    (void) ctx;
    
    int err = 0;
    const unsigned char *src = p;
    struct futhark_opaque_joinPairs_int *obj = malloc(sizeof(struct futhark_opaque_joinPairs_int));
    int64_t shape_0[1] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 1;
    err |= memcmp(src, " i64", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_0, src, 1 * sizeof(int64_t));
        src += 1 * sizeof(int64_t);
    }
    
    const void *data_0 = src;
    
    obj->v0 = NULL;
    src += shape_0[0] * sizeof(int64_t);
    
    int64_t shape_1[1] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 1;
    err |= memcmp(src, " i64", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_1, src, 1 * sizeof(int64_t));
        src += 1 * sizeof(int64_t);
    }
    
    const void *data_1 = src;
    
    obj->v1 = NULL;
    src += shape_1[0] * sizeof(int64_t);
    
    int64_t shape_2[1] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 1;
    err |= memcmp(src, " i32", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_2, src, 1 * sizeof(int64_t));
        src += 1 * sizeof(int64_t);
    }
    
    const void *data_2 = src;
    
    obj->v2 = NULL;
    src += shape_2[0] * sizeof(int32_t);
    if (err == 0) {
        obj->v0 = futhark_new_i64_1d(ctx, data_0, shape_0[0]);
        if (obj->v0 == NULL)
            err = 1;
        obj->v1 = futhark_new_i64_1d(ctx, data_1, shape_1[0]);
        if (obj->v1 == NULL)
            err = 1;
        obj->v2 = futhark_new_i32_1d(ctx, data_2, shape_2[0]);
        if (obj->v2 == NULL)
            err = 1;
    }
    if (err != 0) {
        int ret = 0, tmp;
        
        if (obj->v0 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v0)) != 0)
            ret = tmp;
        if (obj->v1 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v1)) != 0)
            ret = tmp;
        if (obj->v2 != NULL && (tmp = futhark_free_i32_1d(ctx, obj->v2)) != 0)
            ret = tmp;
        free(obj);
        obj = NULL;
    }
    return obj;
}
struct futhark_opaque_joinPairs_long {
    struct futhark_i64_1d *v0;
    struct futhark_i64_1d *v1;
    struct futhark_i64_1d *v2;
};
int futhark_project_opaque_joinPairs_long_ix(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_long *obj)
{
    (void) ctx;
    
    struct futhark_i64_1d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_i64_1d));
    memcpy(v, obj->v0, sizeof(struct futhark_i64_1d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_project_opaque_joinPairs_long_iy(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_long *obj)
{
    (void) ctx;
    
    struct futhark_i64_1d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_i64_1d));
    memcpy(v, obj->v1, sizeof(struct futhark_i64_1d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_project_opaque_joinPairs_long_vs(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_long *obj)
{
    (void) ctx;
    
    struct futhark_i64_1d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_i64_1d));
    memcpy(v, obj->v2, sizeof(struct futhark_i64_1d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_new_opaque_joinPairs_long(struct futhark_context *ctx, struct futhark_opaque_joinPairs_long **out, const struct futhark_i64_1d *f_ix, const struct futhark_i64_1d *f_iy, const struct futhark_i64_1d *f_vs)
{
    struct futhark_opaque_joinPairs_long *v = malloc(sizeof(struct futhark_opaque_joinPairs_long));
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    {
        v->v0 = malloc(sizeof(struct futhark_i64_1d));
        *v->v0 = *f_ix;
        (void) (*v->v0->mem.references)++;
    }
    {
        v->v1 = malloc(sizeof(struct futhark_i64_1d));
        *v->v1 = *f_iy;
        (void) (*v->v1->mem.references)++;
    }
    {
        v->v2 = malloc(sizeof(struct futhark_i64_1d));
        *v->v2 = *f_vs;
        (void) (*v->v2->mem.references)++;
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return FUTHARK_SUCCESS;
}
int futhark_free_opaque_joinPairs_long(struct futhark_context *ctx, struct futhark_opaque_joinPairs_long *obj)
{
    (void) ctx;
    
    int ret = 0, tmp;
    
    if (obj->v0 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v0)) != 0)
        ret = tmp;
    if (obj->v1 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v1)) != 0)
        ret = tmp;
    if (obj->v2 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v2)) != 0)
        ret = tmp;
    free(obj);
    return ret;
}
int futhark_store_opaque_joinPairs_long(struct futhark_context *ctx, const struct futhark_opaque_joinPairs_long *obj, void **p, size_t *n)
{
    (void) ctx;
    
    int ret = 0;
    int64_t size_0 = 7 + 1 * sizeof(int64_t) + futhark_shape_i64_1d(ctx, obj->v0)[0] * sizeof(int64_t);
    int64_t size_1 = 7 + 1 * sizeof(int64_t) + futhark_shape_i64_1d(ctx, obj->v1)[0] * sizeof(int64_t);
    int64_t size_2 = 7 + 1 * sizeof(int64_t) + futhark_shape_i64_1d(ctx, obj->v2)[0] * sizeof(int64_t);
    
    *n = size_0 + size_1 + size_2;
    if (p != NULL && *p == NULL)
        *p = malloc(*n);
    if (p != NULL) {
        unsigned char *out = *p;
        
        *out++ = 'b';
        *out++ = 2;
        *out++ = 1;
        memcpy(out, " i64", 4);
        out += 4;
        memcpy(out, futhark_shape_i64_1d(ctx, obj->v0), 1 * sizeof(int64_t));
        out += 1 * sizeof(int64_t);
        ret |= futhark_values_i64_1d(ctx, obj->v0, (void *) out);
        out += futhark_shape_i64_1d(ctx, obj->v0)[0] * sizeof(int64_t);
        *out++ = 'b';
        *out++ = 2;
        *out++ = 1;
        memcpy(out, " i64", 4);
        out += 4;
        memcpy(out, futhark_shape_i64_1d(ctx, obj->v1), 1 * sizeof(int64_t));
        out += 1 * sizeof(int64_t);
        ret |= futhark_values_i64_1d(ctx, obj->v1, (void *) out);
        out += futhark_shape_i64_1d(ctx, obj->v1)[0] * sizeof(int64_t);
        *out++ = 'b';
        *out++ = 2;
        *out++ = 1;
        memcpy(out, " i64", 4);
        out += 4;
        memcpy(out, futhark_shape_i64_1d(ctx, obj->v2), 1 * sizeof(int64_t));
        out += 1 * sizeof(int64_t);
        ret |= futhark_values_i64_1d(ctx, obj->v2, (void *) out);
        out += futhark_shape_i64_1d(ctx, obj->v2)[0] * sizeof(int64_t);
    }
    return ret;
}
struct futhark_opaque_joinPairs_long *futhark_restore_opaque_joinPairs_long(struct futhark_context *ctx, const void *p)
{
    (void) ctx;
    
    int err = 0;
    const unsigned char *src = p;
    struct futhark_opaque_joinPairs_long *obj = malloc(sizeof(struct futhark_opaque_joinPairs_long));
    int64_t shape_0[1] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 1;
    err |= memcmp(src, " i64", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_0, src, 1 * sizeof(int64_t));
        src += 1 * sizeof(int64_t);
    }
    
    const void *data_0 = src;
    
    obj->v0 = NULL;
    src += shape_0[0] * sizeof(int64_t);
    
    int64_t shape_1[1] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 1;
    err |= memcmp(src, " i64", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_1, src, 1 * sizeof(int64_t));
        src += 1 * sizeof(int64_t);
    }
    
    const void *data_1 = src;
    
    obj->v1 = NULL;
    src += shape_1[0] * sizeof(int64_t);
    
    int64_t shape_2[1] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 1;
    err |= memcmp(src, " i64", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_2, src, 1 * sizeof(int64_t));
        src += 1 * sizeof(int64_t);
    }
    
    const void *data_2 = src;
    
    obj->v2 = NULL;
    src += shape_2[0] * sizeof(int64_t);
    if (err == 0) {
        obj->v0 = futhark_new_i64_1d(ctx, data_0, shape_0[0]);
        if (obj->v0 == NULL)
            err = 1;
        obj->v1 = futhark_new_i64_1d(ctx, data_1, shape_1[0]);
        if (obj->v1 == NULL)
            err = 1;
        obj->v2 = futhark_new_i64_1d(ctx, data_2, shape_2[0]);
        if (obj->v2 == NULL)
            err = 1;
    }
    if (err != 0) {
        int ret = 0, tmp;
        
        if (obj->v0 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v0)) != 0)
            ret = tmp;
        if (obj->v1 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v1)) != 0)
            ret = tmp;
        if (obj->v2 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v2)) != 0)
            ret = tmp;
        free(obj);
        obj = NULL;
    }
    return obj;
}
struct futhark_opaque_joinPairs_float {
    struct futhark_i64_1d *v0;
    struct futhark_i64_1d *v1;
    struct futhark_f32_1d *v2;
};
int futhark_project_opaque_joinPairs_float_ix(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_float *obj)
{
    (void) ctx;
    
    struct futhark_i64_1d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_i64_1d));
    memcpy(v, obj->v0, sizeof(struct futhark_i64_1d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_project_opaque_joinPairs_float_iy(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_float *obj)
{
    (void) ctx;
    
    struct futhark_i64_1d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_i64_1d));
    memcpy(v, obj->v1, sizeof(struct futhark_i64_1d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_project_opaque_joinPairs_float_vs(struct futhark_context *ctx, struct futhark_f32_1d **out, const struct futhark_opaque_joinPairs_float *obj)
{
    (void) ctx;
    
    struct futhark_f32_1d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_f32_1d));
    memcpy(v, obj->v2, sizeof(struct futhark_f32_1d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_new_opaque_joinPairs_float(struct futhark_context *ctx, struct futhark_opaque_joinPairs_float **out, const struct futhark_i64_1d *f_ix, const struct futhark_i64_1d *f_iy, const struct futhark_f32_1d *f_vs)
{
    struct futhark_opaque_joinPairs_float *v = malloc(sizeof(struct futhark_opaque_joinPairs_float));
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    {
        v->v0 = malloc(sizeof(struct futhark_i64_1d));
        *v->v0 = *f_ix;
        (void) (*v->v0->mem.references)++;
    }
    {
        v->v1 = malloc(sizeof(struct futhark_i64_1d));
        *v->v1 = *f_iy;
        (void) (*v->v1->mem.references)++;
    }
    {
        v->v2 = malloc(sizeof(struct futhark_f32_1d));
        *v->v2 = *f_vs;
        (void) (*v->v2->mem.references)++;
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return FUTHARK_SUCCESS;
}
int futhark_free_opaque_joinPairs_float(struct futhark_context *ctx, struct futhark_opaque_joinPairs_float *obj)
{
    (void) ctx;
    
    int ret = 0, tmp;
    
    if (obj->v0 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v0)) != 0)
        ret = tmp;
    if (obj->v1 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v1)) != 0)
        ret = tmp;
    if (obj->v2 != NULL && (tmp = futhark_free_f32_1d(ctx, obj->v2)) != 0)
        ret = tmp;
    free(obj);
    return ret;
}
int futhark_store_opaque_joinPairs_float(struct futhark_context *ctx, const struct futhark_opaque_joinPairs_float *obj, void **p, size_t *n)
{
    (void) ctx;
    
    int ret = 0;
    int64_t size_0 = 7 + 1 * sizeof(int64_t) + futhark_shape_i64_1d(ctx, obj->v0)[0] * sizeof(int64_t);
    int64_t size_1 = 7 + 1 * sizeof(int64_t) + futhark_shape_i64_1d(ctx, obj->v1)[0] * sizeof(int64_t);
    int64_t size_2 = 7 + 1 * sizeof(int64_t) + futhark_shape_f32_1d(ctx, obj->v2)[0] * sizeof(float);
    
    *n = size_0 + size_1 + size_2;
    if (p != NULL && *p == NULL)
        *p = malloc(*n);
    if (p != NULL) {
        unsigned char *out = *p;
        
        *out++ = 'b';
        *out++ = 2;
        *out++ = 1;
        memcpy(out, " i64", 4);
        out += 4;
        memcpy(out, futhark_shape_i64_1d(ctx, obj->v0), 1 * sizeof(int64_t));
        out += 1 * sizeof(int64_t);
        ret |= futhark_values_i64_1d(ctx, obj->v0, (void *) out);
        out += futhark_shape_i64_1d(ctx, obj->v0)[0] * sizeof(int64_t);
        *out++ = 'b';
        *out++ = 2;
        *out++ = 1;
        memcpy(out, " i64", 4);
        out += 4;
        memcpy(out, futhark_shape_i64_1d(ctx, obj->v1), 1 * sizeof(int64_t));
        out += 1 * sizeof(int64_t);
        ret |= futhark_values_i64_1d(ctx, obj->v1, (void *) out);
        out += futhark_shape_i64_1d(ctx, obj->v1)[0] * sizeof(int64_t);
        *out++ = 'b';
        *out++ = 2;
        *out++ = 1;
        memcpy(out, " f32", 4);
        out += 4;
        memcpy(out, futhark_shape_f32_1d(ctx, obj->v2), 1 * sizeof(int64_t));
        out += 1 * sizeof(int64_t);
        ret |= futhark_values_f32_1d(ctx, obj->v2, (void *) out);
        out += futhark_shape_f32_1d(ctx, obj->v2)[0] * sizeof(float);
    }
    return ret;
}
struct futhark_opaque_joinPairs_float *futhark_restore_opaque_joinPairs_float(struct futhark_context *ctx, const void *p)
{
    (void) ctx;
    
    int err = 0;
    const unsigned char *src = p;
    struct futhark_opaque_joinPairs_float *obj = malloc(sizeof(struct futhark_opaque_joinPairs_float));
    int64_t shape_0[1] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 1;
    err |= memcmp(src, " i64", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_0, src, 1 * sizeof(int64_t));
        src += 1 * sizeof(int64_t);
    }
    
    const void *data_0 = src;
    
    obj->v0 = NULL;
    src += shape_0[0] * sizeof(int64_t);
    
    int64_t shape_1[1] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 1;
    err |= memcmp(src, " i64", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_1, src, 1 * sizeof(int64_t));
        src += 1 * sizeof(int64_t);
    }
    
    const void *data_1 = src;
    
    obj->v1 = NULL;
    src += shape_1[0] * sizeof(int64_t);
    
    int64_t shape_2[1] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 1;
    err |= memcmp(src, " f32", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_2, src, 1 * sizeof(int64_t));
        src += 1 * sizeof(int64_t);
    }
    
    const void *data_2 = src;
    
    obj->v2 = NULL;
    src += shape_2[0] * sizeof(float);
    if (err == 0) {
        obj->v0 = futhark_new_i64_1d(ctx, data_0, shape_0[0]);
        if (obj->v0 == NULL)
            err = 1;
        obj->v1 = futhark_new_i64_1d(ctx, data_1, shape_1[0]);
        if (obj->v1 == NULL)
            err = 1;
        obj->v2 = futhark_new_f32_1d(ctx, data_2, shape_2[0]);
        if (obj->v2 == NULL)
            err = 1;
    }
    if (err != 0) {
        int ret = 0, tmp;
        
        if (obj->v0 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v0)) != 0)
            ret = tmp;
        if (obj->v1 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v1)) != 0)
            ret = tmp;
        if (obj->v2 != NULL && (tmp = futhark_free_f32_1d(ctx, obj->v2)) != 0)
            ret = tmp;
        free(obj);
        obj = NULL;
    }
    return obj;
}
struct futhark_opaque_joinPairs_double {
    struct futhark_i64_1d *v0;
    struct futhark_i64_1d *v1;
    struct futhark_f64_1d *v2;
};
int futhark_project_opaque_joinPairs_double_ix(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_double *obj)
{
    (void) ctx;
    
    struct futhark_i64_1d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_i64_1d));
    memcpy(v, obj->v0, sizeof(struct futhark_i64_1d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_project_opaque_joinPairs_double_iy(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_double *obj)
{
    (void) ctx;
    
    struct futhark_i64_1d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_i64_1d));
    memcpy(v, obj->v1, sizeof(struct futhark_i64_1d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_project_opaque_joinPairs_double_vs(struct futhark_context *ctx, struct futhark_f64_1d **out, const struct futhark_opaque_joinPairs_double *obj)
{
    (void) ctx;
    
    struct futhark_f64_1d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_f64_1d));
    memcpy(v, obj->v2, sizeof(struct futhark_f64_1d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_new_opaque_joinPairs_double(struct futhark_context *ctx, struct futhark_opaque_joinPairs_double **out, const struct futhark_i64_1d *f_ix, const struct futhark_i64_1d *f_iy, const struct futhark_f64_1d *f_vs)
{
    struct futhark_opaque_joinPairs_double *v = malloc(sizeof(struct futhark_opaque_joinPairs_double));
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    {
        v->v0 = malloc(sizeof(struct futhark_i64_1d));
        *v->v0 = *f_ix;
        (void) (*v->v0->mem.references)++;
    }
    {
        v->v1 = malloc(sizeof(struct futhark_i64_1d));
        *v->v1 = *f_iy;
        (void) (*v->v1->mem.references)++;
    }
    {
        v->v2 = malloc(sizeof(struct futhark_f64_1d));
        *v->v2 = *f_vs;
        (void) (*v->v2->mem.references)++;
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return FUTHARK_SUCCESS;
}
int futhark_free_opaque_joinPairs_double(struct futhark_context *ctx, struct futhark_opaque_joinPairs_double *obj)
{
    (void) ctx;
    
    int ret = 0, tmp;
    
    if (obj->v0 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v0)) != 0)
        ret = tmp;
    if (obj->v1 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v1)) != 0)
        ret = tmp;
    if (obj->v2 != NULL && (tmp = futhark_free_f64_1d(ctx, obj->v2)) != 0)
        ret = tmp;
    free(obj);
    return ret;
}
int futhark_store_opaque_joinPairs_double(struct futhark_context *ctx, const struct futhark_opaque_joinPairs_double *obj, void **p, size_t *n)
{
    (void) ctx;
    
    int ret = 0;
    int64_t size_0 = 7 + 1 * sizeof(int64_t) + futhark_shape_i64_1d(ctx, obj->v0)[0] * sizeof(int64_t);
    int64_t size_1 = 7 + 1 * sizeof(int64_t) + futhark_shape_i64_1d(ctx, obj->v1)[0] * sizeof(int64_t);
    int64_t size_2 = 7 + 1 * sizeof(int64_t) + futhark_shape_f64_1d(ctx, obj->v2)[0] * sizeof(double);
    
    *n = size_0 + size_1 + size_2;
    if (p != NULL && *p == NULL)
        *p = malloc(*n);
    if (p != NULL) {
        unsigned char *out = *p;
        
        *out++ = 'b';
        *out++ = 2;
        *out++ = 1;
        memcpy(out, " i64", 4);
        out += 4;
        memcpy(out, futhark_shape_i64_1d(ctx, obj->v0), 1 * sizeof(int64_t));
        out += 1 * sizeof(int64_t);
        ret |= futhark_values_i64_1d(ctx, obj->v0, (void *) out);
        out += futhark_shape_i64_1d(ctx, obj->v0)[0] * sizeof(int64_t);
        *out++ = 'b';
        *out++ = 2;
        *out++ = 1;
        memcpy(out, " i64", 4);
        out += 4;
        memcpy(out, futhark_shape_i64_1d(ctx, obj->v1), 1 * sizeof(int64_t));
        out += 1 * sizeof(int64_t);
        ret |= futhark_values_i64_1d(ctx, obj->v1, (void *) out);
        out += futhark_shape_i64_1d(ctx, obj->v1)[0] * sizeof(int64_t);
        *out++ = 'b';
        *out++ = 2;
        *out++ = 1;
        memcpy(out, " f64", 4);
        out += 4;
        memcpy(out, futhark_shape_f64_1d(ctx, obj->v2), 1 * sizeof(int64_t));
        out += 1 * sizeof(int64_t);
        ret |= futhark_values_f64_1d(ctx, obj->v2, (void *) out);
        out += futhark_shape_f64_1d(ctx, obj->v2)[0] * sizeof(double);
    }
    return ret;
}
struct futhark_opaque_joinPairs_double *futhark_restore_opaque_joinPairs_double(struct futhark_context *ctx, const void *p)
{
    (void) ctx;
    
    int err = 0;
    const unsigned char *src = p;
    struct futhark_opaque_joinPairs_double *obj = malloc(sizeof(struct futhark_opaque_joinPairs_double));
    int64_t shape_0[1] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 1;
    err |= memcmp(src, " i64", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_0, src, 1 * sizeof(int64_t));
        src += 1 * sizeof(int64_t);
    }
    
    const void *data_0 = src;
    
    obj->v0 = NULL;
    src += shape_0[0] * sizeof(int64_t);
    
    int64_t shape_1[1] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 1;
    err |= memcmp(src, " i64", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_1, src, 1 * sizeof(int64_t));
        src += 1 * sizeof(int64_t);
    }
    
    const void *data_1 = src;
    
    obj->v1 = NULL;
    src += shape_1[0] * sizeof(int64_t);
    
    int64_t shape_2[1] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 1;
    err |= memcmp(src, " f64", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_2, src, 1 * sizeof(int64_t));
        src += 1 * sizeof(int64_t);
    }
    
    const void *data_2 = src;
    
    obj->v2 = NULL;
    src += shape_2[0] * sizeof(double);
    if (err == 0) {
        obj->v0 = futhark_new_i64_1d(ctx, data_0, shape_0[0]);
        if (obj->v0 == NULL)
            err = 1;
        obj->v1 = futhark_new_i64_1d(ctx, data_1, shape_1[0]);
        if (obj->v1 == NULL)
            err = 1;
        obj->v2 = futhark_new_f64_1d(ctx, data_2, shape_2[0]);
        if (obj->v2 == NULL)
            err = 1;
    }
    if (err != 0) {
        int ret = 0, tmp;
        
        if (obj->v0 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v0)) != 0)
            ret = tmp;
        if (obj->v1 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v1)) != 0)
            ret = tmp;
        if (obj->v2 != NULL && (tmp = futhark_free_f64_1d(ctx, obj->v2)) != 0)
            ret = tmp;
        free(obj);
        obj = NULL;
    }
    return obj;
}

FUTHARK_FUN_ATTR int futrts_builtinzhiota_i64(struct futhark_context *ctx, struct memblock_device mem_42707, int64_t n_42708, int64_t x_42709, int64_t s_42710)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
    struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
    struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
    struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
    struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
    int64_t tblock_sizze_42716;
    
    tblock_sizze_42716 = *ctx->tuning_params.builtinzhiota_i64zitblock_sizze_42716;
    
    int64_t virt_num_tblocks_42717 = sdiv_up64(n_42708, tblock_sizze_42716);
    int64_t num_tblocks_42718 = smin64(virt_num_tblocks_42717, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhiota_i64ziiota_i64_42712(ctx, num_tblocks_42718, 1, 1, tblock_sizze_42716, 1, 1, (int64_t) 0, n_42708, x_42709, s_42710, virt_num_tblocks_42717, num_tblocks_42718, mem_42707.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_f32(struct futhark_context *ctx, struct memblock_device mem_42736, int64_t num_elems_42737, float val_42738)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
    struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
    struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
    struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
    struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
    int64_t replicate_n_42740 = num_elems_42737;
    int64_t tblock_sizze_42745;
    
    tblock_sizze_42745 = *ctx->tuning_params.builtinzhreplicate_f32zitblock_sizze_42745;
    
    int64_t virt_num_tblocks_42746 = sdiv_up64(replicate_n_42740, tblock_sizze_42745);
    int64_t num_tblocks_42747 = smin64(virt_num_tblocks_42746, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_f32zireplicate_42741(ctx, num_tblocks_42747, 1, 1, tblock_sizze_42745, 1, 1, (int64_t) 0, num_elems_42737, val_42738, replicate_n_42740, virt_num_tblocks_42746, num_tblocks_42747, mem_42736.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_f64(struct futhark_context *ctx, struct memblock_device mem_42736, int64_t num_elems_42737, double val_42738)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
    struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
    struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
    struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
    struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
    int64_t replicate_n_42740 = num_elems_42737;
    int64_t tblock_sizze_42745;
    
    tblock_sizze_42745 = *ctx->tuning_params.builtinzhreplicate_f64zitblock_sizze_42745;
    
    int64_t virt_num_tblocks_42746 = sdiv_up64(replicate_n_42740, tblock_sizze_42745);
    int64_t num_tblocks_42747 = smin64(virt_num_tblocks_42746, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_f64zireplicate_42741(ctx, num_tblocks_42747, 1, 1, tblock_sizze_42745, 1, 1, (int64_t) 0, num_elems_42737, val_42738, replicate_n_42740, virt_num_tblocks_42746, num_tblocks_42747, mem_42736.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i16(struct futhark_context *ctx, struct memblock_device mem_42736, int64_t num_elems_42737, int16_t val_42738)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
    struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
    struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
    struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
    struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
    int64_t replicate_n_42740 = num_elems_42737;
    int64_t tblock_sizze_42745;
    
    tblock_sizze_42745 = *ctx->tuning_params.builtinzhreplicate_i16zitblock_sizze_42745;
    
    int64_t virt_num_tblocks_42746 = sdiv_up64(replicate_n_42740, tblock_sizze_42745);
    int64_t num_tblocks_42747 = smin64(virt_num_tblocks_42746, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_i16zireplicate_42741(ctx, num_tblocks_42747, 1, 1, tblock_sizze_42745, 1, 1, (int64_t) 0, num_elems_42737, val_42738, replicate_n_42740, virt_num_tblocks_42746, num_tblocks_42747, mem_42736.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i32(struct futhark_context *ctx, struct memblock_device mem_42879, int64_t num_elems_42880, int32_t val_42881)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
    struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
    struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
    struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
    struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
    int64_t replicate_n_42883 = num_elems_42880;
    int64_t tblock_sizze_42888;
    
    tblock_sizze_42888 = *ctx->tuning_params.builtinzhreplicate_i32zitblock_sizze_42888;
    
    int64_t virt_num_tblocks_42889 = sdiv_up64(replicate_n_42883, tblock_sizze_42888);
    int64_t num_tblocks_42890 = smin64(virt_num_tblocks_42889, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_i32zireplicate_42884(ctx, num_tblocks_42890, 1, 1, tblock_sizze_42888, 1, 1, (int64_t) 0, num_elems_42880, val_42881, replicate_n_42883, virt_num_tblocks_42889, num_tblocks_42890, mem_42879.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i64(struct futhark_context *ctx, struct memblock_device mem_42710, int64_t num_elems_42711, int64_t val_42712)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
    struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
    struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
    struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
    struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
    int64_t replicate_n_42714 = num_elems_42711;
    int64_t tblock_sizze_42719;
    
    tblock_sizze_42719 = *ctx->tuning_params.builtinzhreplicate_i64zitblock_sizze_42719;
    
    int64_t virt_num_tblocks_42720 = sdiv_up64(replicate_n_42714, tblock_sizze_42719);
    int64_t num_tblocks_42721 = smin64(virt_num_tblocks_42720, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_i64zireplicate_42715(ctx, num_tblocks_42721, 1, 1, tblock_sizze_42719, 1, 1, (int64_t) 0, num_elems_42711, val_42712, replicate_n_42714, virt_num_tblocks_42720, num_tblocks_42721, mem_42710.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i8(struct futhark_context *ctx, struct memblock_device mem_42853, int64_t num_elems_42854, int8_t val_42855)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
    struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
    struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
    struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
    struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
    int64_t replicate_n_42857 = num_elems_42854;
    int64_t tblock_sizze_42862;
    
    tblock_sizze_42862 = *ctx->tuning_params.builtinzhreplicate_i8zitblock_sizze_42862;
    
    int64_t virt_num_tblocks_42863 = sdiv_up64(replicate_n_42857, tblock_sizze_42862);
    int64_t num_tblocks_42864 = smin64(virt_num_tblocks_42863, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_i8zireplicate_42858(ctx, num_tblocks_42864, 1, 1, tblock_sizze_42862, 1, 1, (int64_t) 0, num_elems_42854, val_42855, replicate_n_42857, virt_num_tblocks_42863, num_tblocks_42864, mem_42853.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_double(struct futhark_context *ctx, struct memblock_device *mem_out_p_43276, struct memblock_device is_mem_42199, struct memblock_device ys_mem_42200, int64_t niz2084U_36170, int64_t dz2083U_36171, int64_t incr_36172, int64_t psizze_36173)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_42224;
    
    mem_42224.references = NULL;
    
    struct memblock_device mem_param_tmp_42737;
    
    mem_param_tmp_42737.references = NULL;
    
    struct memblock_device mem_param_tmp_42736;
    
    mem_param_tmp_42736.references = NULL;
    
    struct memblock_device mem_42216;
    
    mem_42216.references = NULL;
    
    struct memblock_device mem_42213;
    
    mem_42213.references = NULL;
    
    struct memblock_device mem_param_42211;
    
    mem_param_42211.references = NULL;
    
    struct memblock_device mem_param_42208;
    
    mem_param_42208.references = NULL;
    
    struct memblock_device ext_mem_42221;
    
    ext_mem_42221.references = NULL;
    
    struct memblock_device ext_mem_42222;
    
    ext_mem_42222.references = NULL;
    
    struct memblock_device mem_42205;
    
    mem_42205.references = NULL;
    
    struct memblock_device mem_42203;
    
    mem_42203.references = NULL;
    
    struct memblock_device mem_out_42706;
    
    mem_out_42706.references = NULL;
    
    struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
    struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
    struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
    struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
    struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
    int64_t bytes_42202 = (int64_t) 8 * niz2084U_36170;
    bool zzero_38179 = psizze_36173 == (int64_t) 0;
    bool nonzzero_38180 = !zzero_38179;
    bool nonzzero_cert_38181;
    
    if (!nonzzero_38180) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftbasics.fut:24:22-28\n   #1  ftSMJ.fut:432:5-41\n   #2  ftSMJ.fut:431:1-432:41\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t segmap_tblock_sizze_39791;
    
    segmap_tblock_sizze_39791 = *ctx->tuning_params.gather_payloads_doublezisegmap_tblock_sizze_39783;
    
    int64_t segmap_usable_groups_39792 = sdiv_up64(niz2084U_36170, segmap_tblock_sizze_39791);
    
    if (memblock_alloc_device(ctx, &mem_42203, bytes_42202, "mem_42203")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_42707 = sext_i64_i32(sdiv_up64(niz2084U_36170, segmap_tblock_sizze_39791));
    
    {
        err = gpu_kernel_gather_payloads_doublezisegmap_39795(ctx, segmap_usable_groups_39792, 1, 1, *ctx->tuning_params.gather_payloads_doublezisegmap_tblock_sizze_39783, 1, 1, (int64_t) 0, niz2084U_36170, incr_36172, is_mem_42199.mem, mem_42203.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t zm_lhs_38177 = add64(dz2083U_36171, psizze_36173);
    int64_t zs_lhs_38178 = sub64(zm_lhs_38177, (int64_t) 1);
    int64_t m_38182 = sdiv64(zs_lhs_38178, psizze_36173);
    
    if (memblock_alloc_device(ctx, &mem_42205, bytes_42202, "mem_42205")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_f64(ctx, mem_42205, niz2084U_36170, 0.0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    bool loop_cond_38184 = slt64((int64_t) 0, m_38182);
    int64_t segmap_tblock_sizze_39819;
    
    segmap_tblock_sizze_39819 = *ctx->tuning_params.gather_payloads_doublezisegmap_tblock_sizze_39801;
    
    int64_t segmap_usable_groups_39820 = sdiv_up_safe64(niz2084U_36170, segmap_tblock_sizze_39819);
    bool partitioned_gather_res_38185;
    int64_t partitioned_gather_res_38188;
    bool loop_while_38189;
    int64_t p_38192;
    
    if (memblock_set_device(ctx, &mem_param_42208, &mem_42203, "mem_42203") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_42211, &mem_42205, "mem_42205") != 0)
        return 1;
    loop_while_38189 = loop_cond_38184;
    p_38192 = (int64_t) 0;
    while (loop_while_38189) {
        int64_t lower_bound_38193 = mul64(psizze_36173, p_38192);
        int64_t min_arg1_38194 = add64(psizze_36173, lower_bound_38193);
        int64_t min_res_38195 = smin64(dz2083U_36171, min_arg1_38194);
        int64_t j_m_i_38196 = sub64(min_res_38195, lower_bound_38193);
        bool empty_slice_38197 = j_m_i_38196 == (int64_t) 0;
        int64_t m_38198 = sub64(j_m_i_38196, (int64_t) 1);
        int64_t i_p_m_t_s_38199 = add64(lower_bound_38193, m_38198);
        bool zzero_leq_i_p_m_t_s_38200 = sle64((int64_t) 0, i_p_m_t_s_38199);
        bool i_p_m_t_s_leq_w_38201 = slt64(i_p_m_t_s_38199, dz2083U_36171);
        bool zzero_lte_i_38202 = sle64((int64_t) 0, lower_bound_38193);
        bool i_lte_j_38203 = sle64(lower_bound_38193, min_res_38195);
        bool y_38204 = i_p_m_t_s_leq_w_38201 && zzero_lte_i_38202;
        bool y_38205 = zzero_leq_i_p_m_t_s_38200 && y_38204;
        bool forwards_ok_38206 = i_lte_j_38203 && y_38205;
        bool ok_or_empty_38207 = empty_slice_38197 || forwards_ok_38206;
        bool index_certs_38208;
        
        if (!ok_or_empty_38207) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) lower_bound_38193, ":", (long long) min_res_38195, "] out of bounds for array of shape [", (long long) dz2083U_36171, "].", "-> #0  ftbasics.fut:31:18-45\n   #1  ftSMJ.fut:432:5-41\n   #2  ftSMJ.fut:431:1-432:41\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_42213, bytes_42202, "mem_42213")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42213.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_42208.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {niz2084U_36170})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_42216, bytes_42202, "mem_42216")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_42742 = sext_i64_i32(sdiv_up64(niz2084U_36170, segmap_tblock_sizze_39819));
        
        {
            err = gpu_kernel_gather_payloads_doublezisegmap_39823(ctx, segmap_usable_groups_39820, 1, 1, *ctx->tuning_params.gather_payloads_doublezisegmap_tblock_sizze_39801, 1, 1, (int64_t) 0, niz2084U_36170, lower_bound_38193, min_res_38195, j_m_i_38196, ys_mem_42200.mem, mem_param_42208.mem, mem_param_42211.mem, mem_42216.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t tmp_38223 = add64((int64_t) 1, p_38192);
        bool loop_cond_38224 = slt64(tmp_38223, m_38182);
        
        if (memblock_set_device(ctx, &mem_param_tmp_42736, &mem_42213, "mem_42213") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_42737, &mem_42216, "mem_42216") != 0)
            return 1;
        
        bool loop_while_tmp_42738 = loop_cond_38224;
        int64_t p_tmp_42741 = tmp_38223;
        
        if (memblock_set_device(ctx, &mem_param_42208, &mem_param_tmp_42736, "mem_param_tmp_42736") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_42211, &mem_param_tmp_42737, "mem_param_tmp_42737") != 0)
            return 1;
        loop_while_38189 = loop_while_tmp_42738;
        p_38192 = p_tmp_42741;
    }
    if (memblock_set_device(ctx, &ext_mem_42222, &mem_param_42208, "mem_param_42208") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_42221, &mem_param_42211, "mem_param_42211") != 0)
        return 1;
    partitioned_gather_res_38185 = loop_while_38189;
    partitioned_gather_res_38188 = p_38192;
    if (memblock_unref_device(ctx, &mem_42203, "mem_42203") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42205, "mem_42205") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_42224, bytes_42202, "mem_42224")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42224.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42221.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {niz2084U_36170})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_42221, "ext_mem_42221") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_42706, &mem_42224, "mem_42224") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_43276, &mem_out_42706, "mem_out_42706") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_42224, "mem_42224") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_42737, "mem_param_tmp_42737") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_42736, "mem_param_tmp_42736") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42216, "mem_42216") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42213, "mem_42213") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42211, "mem_param_42211") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42208, "mem_param_42208") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42221, "ext_mem_42221") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42222, "ext_mem_42222") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42205, "mem_42205") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42203, "mem_42203") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_42706, "mem_out_42706") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_double_GFUR(struct futhark_context *ctx, struct memblock_device *mem_out_p_43277, struct memblock_device preVals_mem_42199, struct memblock_device is_mem_42200, struct memblock_device ys_mem_42201, int64_t ni_37677, int64_t n_37678, int64_t incr_37679, int64_t psizze_37680)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_42223;
    
    mem_42223.references = NULL;
    
    struct memblock_device mem_param_tmp_42717;
    
    mem_param_tmp_42717.references = NULL;
    
    struct memblock_device mem_param_tmp_42716;
    
    mem_param_tmp_42716.references = NULL;
    
    struct memblock_device mem_42215;
    
    mem_42215.references = NULL;
    
    struct memblock_device mem_42212;
    
    mem_42212.references = NULL;
    
    struct memblock_device mem_param_42210;
    
    mem_param_42210.references = NULL;
    
    struct memblock_device mem_param_42207;
    
    mem_param_42207.references = NULL;
    
    struct memblock_device ext_mem_42220;
    
    ext_mem_42220.references = NULL;
    
    struct memblock_device ext_mem_42221;
    
    ext_mem_42221.references = NULL;
    
    struct memblock_device mem_42204;
    
    mem_42204.references = NULL;
    
    struct memblock_device mem_out_42706;
    
    mem_out_42706.references = NULL;
    
    struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
    struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
    struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
    struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
    struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
    int64_t bytes_42203 = (int64_t) 8 * ni_37677;
    bool zzero_38180 = psizze_37680 == (int64_t) 0;
    bool nonzzero_38181 = !zzero_38180;
    bool nonzzero_cert_38182;
    
    if (!nonzzero_38181) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftbasics.fut:43:22-28\n   #1  ftSMJ.fut:460:5-50\n   #2  ftSMJ.fut:459:1-460:50\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t segmap_tblock_sizze_40071;
    
    segmap_tblock_sizze_40071 = *ctx->tuning_params.gather_payloads_double_GFURzisegmap_tblock_sizze_40063;
    
    int64_t segmap_usable_groups_40072 = sdiv_up64(ni_37677, segmap_tblock_sizze_40071);
    
    if (memblock_alloc_device(ctx, &mem_42204, bytes_42203, "mem_42204")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_42707 = sext_i64_i32(sdiv_up64(ni_37677, segmap_tblock_sizze_40071));
    
    {
        err = gpu_kernel_gather_payloads_double_GFURzisegmap_40075(ctx, segmap_usable_groups_40072, 1, 1, *ctx->tuning_params.gather_payloads_double_GFURzisegmap_tblock_sizze_40063, 1, 1, (int64_t) 0, ni_37677, incr_37679, is_mem_42200.mem, mem_42204.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t zm_lhs_38178 = add64(n_37678, psizze_37680);
    int64_t zs_lhs_38179 = sub64(zm_lhs_38178, (int64_t) 1);
    int64_t m_38183 = sdiv64(zs_lhs_38179, psizze_37680);
    bool loop_cond_38184 = slt64((int64_t) 0, m_38183);
    int64_t segmap_tblock_sizze_40099;
    
    segmap_tblock_sizze_40099 = *ctx->tuning_params.gather_payloads_double_GFURzisegmap_tblock_sizze_40081;
    
    int64_t segmap_usable_groups_40100 = sdiv_up_safe64(ni_37677, segmap_tblock_sizze_40099);
    bool partitioned_gather_over_array_res_38185;
    int64_t partitioned_gather_over_array_res_38188;
    bool loop_while_38189;
    int64_t p_38192;
    
    if (memblock_set_device(ctx, &mem_param_42207, &mem_42204, "mem_42204") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_42210, &preVals_mem_42199, "preVals_mem_42199") != 0)
        return 1;
    loop_while_38189 = loop_cond_38184;
    p_38192 = (int64_t) 0;
    while (loop_while_38189) {
        int64_t lower_bound_38193 = mul64(psizze_37680, p_38192);
        int64_t min_arg1_38194 = add64(psizze_37680, lower_bound_38193);
        int64_t min_res_38195 = smin64(n_37678, min_arg1_38194);
        int64_t j_m_i_38196 = sub64(min_res_38195, lower_bound_38193);
        bool empty_slice_38197 = j_m_i_38196 == (int64_t) 0;
        int64_t m_38198 = sub64(j_m_i_38196, (int64_t) 1);
        int64_t i_p_m_t_s_38199 = add64(lower_bound_38193, m_38198);
        bool zzero_leq_i_p_m_t_s_38200 = sle64((int64_t) 0, i_p_m_t_s_38199);
        bool i_p_m_t_s_leq_w_38201 = slt64(i_p_m_t_s_38199, n_37678);
        bool zzero_lte_i_38202 = sle64((int64_t) 0, lower_bound_38193);
        bool i_lte_j_38203 = sle64(lower_bound_38193, min_res_38195);
        bool y_38204 = i_p_m_t_s_leq_w_38201 && zzero_lte_i_38202;
        bool y_38205 = zzero_leq_i_p_m_t_s_38200 && y_38204;
        bool forwards_ok_38206 = i_lte_j_38203 && y_38205;
        bool ok_or_empty_38207 = empty_slice_38197 || forwards_ok_38206;
        bool index_certs_38208;
        
        if (!ok_or_empty_38207) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) lower_bound_38193, ":", (long long) min_res_38195, "] out of bounds for array of shape [", (long long) n_37678, "].", "-> #0  ftbasics.fut:49:18-45\n   #1  ftSMJ.fut:460:5-50\n   #2  ftSMJ.fut:459:1-460:50\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_42212, bytes_42203, "mem_42212")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42212.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_42207.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {ni_37677})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_42215, bytes_42203, "mem_42215")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_42722 = sext_i64_i32(sdiv_up64(ni_37677, segmap_tblock_sizze_40099));
        
        {
            err = gpu_kernel_gather_payloads_double_GFURzisegmap_40103(ctx, segmap_usable_groups_40100, 1, 1, *ctx->tuning_params.gather_payloads_double_GFURzisegmap_tblock_sizze_40081, 1, 1, (int64_t) 0, ni_37677, lower_bound_38193, min_res_38195, j_m_i_38196, ys_mem_42201.mem, mem_param_42207.mem, mem_param_42210.mem, mem_42215.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t tmp_38223 = add64((int64_t) 1, p_38192);
        bool loop_cond_38224 = slt64(tmp_38223, m_38183);
        
        if (memblock_set_device(ctx, &mem_param_tmp_42716, &mem_42212, "mem_42212") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_42717, &mem_42215, "mem_42215") != 0)
            return 1;
        
        bool loop_while_tmp_42718 = loop_cond_38224;
        int64_t p_tmp_42721 = tmp_38223;
        
        if (memblock_set_device(ctx, &mem_param_42207, &mem_param_tmp_42716, "mem_param_tmp_42716") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_42210, &mem_param_tmp_42717, "mem_param_tmp_42717") != 0)
            return 1;
        loop_while_38189 = loop_while_tmp_42718;
        p_38192 = p_tmp_42721;
    }
    if (memblock_set_device(ctx, &ext_mem_42221, &mem_param_42207, "mem_param_42207") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_42220, &mem_param_42210, "mem_param_42210") != 0)
        return 1;
    partitioned_gather_over_array_res_38185 = loop_while_38189;
    partitioned_gather_over_array_res_38188 = p_38192;
    if (memblock_unref_device(ctx, &mem_42204, "mem_42204") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_42223, bytes_42203, "mem_42223")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42223.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42220.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {ni_37677})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_42220, "ext_mem_42220") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_42706, &mem_42223, "mem_42223") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_43277, &mem_out_42706, "mem_out_42706") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_42223, "mem_42223") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_42717, "mem_param_tmp_42717") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_42716, "mem_param_tmp_42716") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42215, "mem_42215") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42212, "mem_42212") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42210, "mem_param_42210") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42207, "mem_param_42207") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42220, "ext_mem_42220") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42221, "ext_mem_42221") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42204, "mem_42204") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_42706, "mem_out_42706") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_float(struct futhark_context *ctx, struct memblock_device *mem_out_p_43278, struct memblock_device is_mem_42199, struct memblock_device ys_mem_42200, int64_t niz2084U_35830, int64_t dz2083U_35831, int64_t incr_35832, int64_t psizze_35833)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_42224;
    
    mem_42224.references = NULL;
    
    struct memblock_device mem_param_tmp_42737;
    
    mem_param_tmp_42737.references = NULL;
    
    struct memblock_device mem_param_tmp_42736;
    
    mem_param_tmp_42736.references = NULL;
    
    struct memblock_device mem_42216;
    
    mem_42216.references = NULL;
    
    struct memblock_device mem_42213;
    
    mem_42213.references = NULL;
    
    struct memblock_device mem_param_42211;
    
    mem_param_42211.references = NULL;
    
    struct memblock_device mem_param_42208;
    
    mem_param_42208.references = NULL;
    
    struct memblock_device ext_mem_42221;
    
    ext_mem_42221.references = NULL;
    
    struct memblock_device ext_mem_42222;
    
    ext_mem_42222.references = NULL;
    
    struct memblock_device mem_42205;
    
    mem_42205.references = NULL;
    
    struct memblock_device mem_42203;
    
    mem_42203.references = NULL;
    
    struct memblock_device mem_out_42706;
    
    mem_out_42706.references = NULL;
    
    struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
    struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
    struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
    struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
    struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
    int64_t bytes_42202 = (int64_t) 8 * niz2084U_35830;
    bool zzero_38179 = psizze_35833 == (int64_t) 0;
    bool nonzzero_38180 = !zzero_38179;
    bool nonzzero_cert_38181;
    
    if (!nonzzero_38180) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftbasics.fut:24:22-28\n   #1  ftSMJ.fut:429:5-41\n   #2  ftSMJ.fut:428:1-429:41\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_42204 = (int64_t) 4 * niz2084U_35830;
    int64_t segmap_tblock_sizze_39735;
    
    segmap_tblock_sizze_39735 = *ctx->tuning_params.gather_payloads_floatzisegmap_tblock_sizze_39727;
    
    int64_t segmap_usable_groups_39736 = sdiv_up64(niz2084U_35830, segmap_tblock_sizze_39735);
    
    if (memblock_alloc_device(ctx, &mem_42203, bytes_42202, "mem_42203")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_42707 = sext_i64_i32(sdiv_up64(niz2084U_35830, segmap_tblock_sizze_39735));
    
    {
        err = gpu_kernel_gather_payloads_floatzisegmap_39739(ctx, segmap_usable_groups_39736, 1, 1, *ctx->tuning_params.gather_payloads_floatzisegmap_tblock_sizze_39727, 1, 1, (int64_t) 0, niz2084U_35830, incr_35832, is_mem_42199.mem, mem_42203.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t zm_lhs_38177 = add64(dz2083U_35831, psizze_35833);
    int64_t zs_lhs_38178 = sub64(zm_lhs_38177, (int64_t) 1);
    int64_t m_38182 = sdiv64(zs_lhs_38178, psizze_35833);
    
    if (memblock_alloc_device(ctx, &mem_42205, bytes_42204, "mem_42205")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_f32(ctx, mem_42205, niz2084U_35830, 0.0F) != 0) {
        err = 1;
        goto cleanup;
    }
    
    bool loop_cond_38184 = slt64((int64_t) 0, m_38182);
    int64_t segmap_tblock_sizze_39763;
    
    segmap_tblock_sizze_39763 = *ctx->tuning_params.gather_payloads_floatzisegmap_tblock_sizze_39745;
    
    int64_t segmap_usable_groups_39764 = sdiv_up_safe64(niz2084U_35830, segmap_tblock_sizze_39763);
    bool partitioned_gather_res_38185;
    int64_t partitioned_gather_res_38188;
    bool loop_while_38189;
    int64_t p_38192;
    
    if (memblock_set_device(ctx, &mem_param_42208, &mem_42203, "mem_42203") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_42211, &mem_42205, "mem_42205") != 0)
        return 1;
    loop_while_38189 = loop_cond_38184;
    p_38192 = (int64_t) 0;
    while (loop_while_38189) {
        int64_t lower_bound_38193 = mul64(psizze_35833, p_38192);
        int64_t min_arg1_38194 = add64(psizze_35833, lower_bound_38193);
        int64_t min_res_38195 = smin64(dz2083U_35831, min_arg1_38194);
        int64_t j_m_i_38196 = sub64(min_res_38195, lower_bound_38193);
        bool empty_slice_38197 = j_m_i_38196 == (int64_t) 0;
        int64_t m_38198 = sub64(j_m_i_38196, (int64_t) 1);
        int64_t i_p_m_t_s_38199 = add64(lower_bound_38193, m_38198);
        bool zzero_leq_i_p_m_t_s_38200 = sle64((int64_t) 0, i_p_m_t_s_38199);
        bool i_p_m_t_s_leq_w_38201 = slt64(i_p_m_t_s_38199, dz2083U_35831);
        bool zzero_lte_i_38202 = sle64((int64_t) 0, lower_bound_38193);
        bool i_lte_j_38203 = sle64(lower_bound_38193, min_res_38195);
        bool y_38204 = i_p_m_t_s_leq_w_38201 && zzero_lte_i_38202;
        bool y_38205 = zzero_leq_i_p_m_t_s_38200 && y_38204;
        bool forwards_ok_38206 = i_lte_j_38203 && y_38205;
        bool ok_or_empty_38207 = empty_slice_38197 || forwards_ok_38206;
        bool index_certs_38208;
        
        if (!ok_or_empty_38207) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) lower_bound_38193, ":", (long long) min_res_38195, "] out of bounds for array of shape [", (long long) dz2083U_35831, "].", "-> #0  ftbasics.fut:31:18-45\n   #1  ftSMJ.fut:429:5-41\n   #2  ftSMJ.fut:428:1-429:41\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_42213, bytes_42202, "mem_42213")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42213.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_42208.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {niz2084U_35830})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_42216, bytes_42204, "mem_42216")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_42742 = sext_i64_i32(sdiv_up64(niz2084U_35830, segmap_tblock_sizze_39763));
        
        {
            err = gpu_kernel_gather_payloads_floatzisegmap_39767(ctx, segmap_usable_groups_39764, 1, 1, *ctx->tuning_params.gather_payloads_floatzisegmap_tblock_sizze_39745, 1, 1, (int64_t) 0, niz2084U_35830, lower_bound_38193, min_res_38195, j_m_i_38196, ys_mem_42200.mem, mem_param_42208.mem, mem_param_42211.mem, mem_42216.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t tmp_38223 = add64((int64_t) 1, p_38192);
        bool loop_cond_38224 = slt64(tmp_38223, m_38182);
        
        if (memblock_set_device(ctx, &mem_param_tmp_42736, &mem_42213, "mem_42213") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_42737, &mem_42216, "mem_42216") != 0)
            return 1;
        
        bool loop_while_tmp_42738 = loop_cond_38224;
        int64_t p_tmp_42741 = tmp_38223;
        
        if (memblock_set_device(ctx, &mem_param_42208, &mem_param_tmp_42736, "mem_param_tmp_42736") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_42211, &mem_param_tmp_42737, "mem_param_tmp_42737") != 0)
            return 1;
        loop_while_38189 = loop_while_tmp_42738;
        p_38192 = p_tmp_42741;
    }
    if (memblock_set_device(ctx, &ext_mem_42222, &mem_param_42208, "mem_param_42208") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_42221, &mem_param_42211, "mem_param_42211") != 0)
        return 1;
    partitioned_gather_res_38185 = loop_while_38189;
    partitioned_gather_res_38188 = p_38192;
    if (memblock_unref_device(ctx, &mem_42203, "mem_42203") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42205, "mem_42205") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_42224, bytes_42204, "mem_42224")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_42224.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42221.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {niz2084U_35830})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_42221, "ext_mem_42221") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_42706, &mem_42224, "mem_42224") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_43278, &mem_out_42706, "mem_out_42706") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_42224, "mem_42224") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_42737, "mem_param_tmp_42737") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_42736, "mem_param_tmp_42736") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42216, "mem_42216") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42213, "mem_42213") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42211, "mem_param_42211") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42208, "mem_param_42208") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42221, "ext_mem_42221") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42222, "ext_mem_42222") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42205, "mem_42205") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42203, "mem_42203") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_42706, "mem_out_42706") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_float_GFUR(struct futhark_context *ctx, struct memblock_device *mem_out_p_43279, struct memblock_device preVals_mem_42199, struct memblock_device is_mem_42200, struct memblock_device ys_mem_42201, int64_t ni_37376, int64_t n_37377, int64_t incr_37378, int64_t psizze_37379)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_42223;
    
    mem_42223.references = NULL;
    
    struct memblock_device mem_param_tmp_42717;
    
    mem_param_tmp_42717.references = NULL;
    
    struct memblock_device mem_param_tmp_42716;
    
    mem_param_tmp_42716.references = NULL;
    
    struct memblock_device mem_42215;
    
    mem_42215.references = NULL;
    
    struct memblock_device mem_42212;
    
    mem_42212.references = NULL;
    
    struct memblock_device mem_param_42210;
    
    mem_param_42210.references = NULL;
    
    struct memblock_device mem_param_42207;
    
    mem_param_42207.references = NULL;
    
    struct memblock_device ext_mem_42220;
    
    ext_mem_42220.references = NULL;
    
    struct memblock_device ext_mem_42221;
    
    ext_mem_42221.references = NULL;
    
    struct memblock_device mem_42204;
    
    mem_42204.references = NULL;
    
    struct memblock_device mem_out_42706;
    
    mem_out_42706.references = NULL;
    
    struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
    struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
    struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
    struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
    struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
    int64_t bytes_42203 = (int64_t) 8 * ni_37376;
    bool zzero_38180 = psizze_37379 == (int64_t) 0;
    bool nonzzero_38181 = !zzero_38180;
    bool nonzzero_cert_38182;
    
    if (!nonzzero_38181) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftbasics.fut:43:22-28\n   #1  ftSMJ.fut:457:5-50\n   #2  ftSMJ.fut:456:1-457:50\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_42214 = (int64_t) 4 * ni_37376;
    int64_t segmap_tblock_sizze_40015;
    
    segmap_tblock_sizze_40015 = *ctx->tuning_params.gather_payloads_float_GFURzisegmap_tblock_sizze_40007;
    
    int64_t segmap_usable_groups_40016 = sdiv_up64(ni_37376, segmap_tblock_sizze_40015);
    
    if (memblock_alloc_device(ctx, &mem_42204, bytes_42203, "mem_42204")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_42707 = sext_i64_i32(sdiv_up64(ni_37376, segmap_tblock_sizze_40015));
    
    {
        err = gpu_kernel_gather_payloads_float_GFURzisegmap_40019(ctx, segmap_usable_groups_40016, 1, 1, *ctx->tuning_params.gather_payloads_float_GFURzisegmap_tblock_sizze_40007, 1, 1, (int64_t) 0, ni_37376, incr_37378, is_mem_42200.mem, mem_42204.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t zm_lhs_38178 = add64(n_37377, psizze_37379);
    int64_t zs_lhs_38179 = sub64(zm_lhs_38178, (int64_t) 1);
    int64_t m_38183 = sdiv64(zs_lhs_38179, psizze_37379);
    bool loop_cond_38184 = slt64((int64_t) 0, m_38183);
    int64_t segmap_tblock_sizze_40043;
    
    segmap_tblock_sizze_40043 = *ctx->tuning_params.gather_payloads_float_GFURzisegmap_tblock_sizze_40025;
    
    int64_t segmap_usable_groups_40044 = sdiv_up_safe64(ni_37376, segmap_tblock_sizze_40043);
    bool partitioned_gather_over_array_res_38185;
    int64_t partitioned_gather_over_array_res_38188;
    bool loop_while_38189;
    int64_t p_38192;
    
    if (memblock_set_device(ctx, &mem_param_42207, &mem_42204, "mem_42204") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_42210, &preVals_mem_42199, "preVals_mem_42199") != 0)
        return 1;
    loop_while_38189 = loop_cond_38184;
    p_38192 = (int64_t) 0;
    while (loop_while_38189) {
        int64_t lower_bound_38193 = mul64(psizze_37379, p_38192);
        int64_t min_arg1_38194 = add64(psizze_37379, lower_bound_38193);
        int64_t min_res_38195 = smin64(n_37377, min_arg1_38194);
        int64_t j_m_i_38196 = sub64(min_res_38195, lower_bound_38193);
        bool empty_slice_38197 = j_m_i_38196 == (int64_t) 0;
        int64_t m_38198 = sub64(j_m_i_38196, (int64_t) 1);
        int64_t i_p_m_t_s_38199 = add64(lower_bound_38193, m_38198);
        bool zzero_leq_i_p_m_t_s_38200 = sle64((int64_t) 0, i_p_m_t_s_38199);
        bool i_p_m_t_s_leq_w_38201 = slt64(i_p_m_t_s_38199, n_37377);
        bool zzero_lte_i_38202 = sle64((int64_t) 0, lower_bound_38193);
        bool i_lte_j_38203 = sle64(lower_bound_38193, min_res_38195);
        bool y_38204 = i_p_m_t_s_leq_w_38201 && zzero_lte_i_38202;
        bool y_38205 = zzero_leq_i_p_m_t_s_38200 && y_38204;
        bool forwards_ok_38206 = i_lte_j_38203 && y_38205;
        bool ok_or_empty_38207 = empty_slice_38197 || forwards_ok_38206;
        bool index_certs_38208;
        
        if (!ok_or_empty_38207) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) lower_bound_38193, ":", (long long) min_res_38195, "] out of bounds for array of shape [", (long long) n_37377, "].", "-> #0  ftbasics.fut:49:18-45\n   #1  ftSMJ.fut:457:5-50\n   #2  ftSMJ.fut:456:1-457:50\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_42212, bytes_42203, "mem_42212")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42212.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_42207.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {ni_37376})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_42215, bytes_42214, "mem_42215")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_42722 = sext_i64_i32(sdiv_up64(ni_37376, segmap_tblock_sizze_40043));
        
        {
            err = gpu_kernel_gather_payloads_float_GFURzisegmap_40047(ctx, segmap_usable_groups_40044, 1, 1, *ctx->tuning_params.gather_payloads_float_GFURzisegmap_tblock_sizze_40025, 1, 1, (int64_t) 0, ni_37376, lower_bound_38193, min_res_38195, j_m_i_38196, ys_mem_42201.mem, mem_param_42207.mem, mem_param_42210.mem, mem_42215.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t tmp_38223 = add64((int64_t) 1, p_38192);
        bool loop_cond_38224 = slt64(tmp_38223, m_38183);
        
        if (memblock_set_device(ctx, &mem_param_tmp_42716, &mem_42212, "mem_42212") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_42717, &mem_42215, "mem_42215") != 0)
            return 1;
        
        bool loop_while_tmp_42718 = loop_cond_38224;
        int64_t p_tmp_42721 = tmp_38223;
        
        if (memblock_set_device(ctx, &mem_param_42207, &mem_param_tmp_42716, "mem_param_tmp_42716") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_42210, &mem_param_tmp_42717, "mem_param_tmp_42717") != 0)
            return 1;
        loop_while_38189 = loop_while_tmp_42718;
        p_38192 = p_tmp_42721;
    }
    if (memblock_set_device(ctx, &ext_mem_42221, &mem_param_42207, "mem_param_42207") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_42220, &mem_param_42210, "mem_param_42210") != 0)
        return 1;
    partitioned_gather_over_array_res_38185 = loop_while_38189;
    partitioned_gather_over_array_res_38188 = p_38192;
    if (memblock_unref_device(ctx, &mem_42204, "mem_42204") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_42223, bytes_42214, "mem_42223")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_42223.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42220.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {ni_37376})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_42220, "ext_mem_42220") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_42706, &mem_42223, "mem_42223") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_43279, &mem_out_42706, "mem_out_42706") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_42223, "mem_42223") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_42717, "mem_param_tmp_42717") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_42716, "mem_param_tmp_42716") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42215, "mem_42215") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42212, "mem_42212") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42210, "mem_param_42210") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42207, "mem_param_42207") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42220, "ext_mem_42220") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42221, "ext_mem_42221") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42204, "mem_42204") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_42706, "mem_out_42706") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_int(struct futhark_context *ctx, struct memblock_device *mem_out_p_43280, struct memblock_device is_mem_42199, struct memblock_device ys_mem_42200, int64_t niz2084U_35181, int64_t dz2083U_35182, int64_t incr_35183, int64_t psizze_35184)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_42224;
    
    mem_42224.references = NULL;
    
    struct memblock_device mem_param_tmp_42737;
    
    mem_param_tmp_42737.references = NULL;
    
    struct memblock_device mem_param_tmp_42736;
    
    mem_param_tmp_42736.references = NULL;
    
    struct memblock_device mem_42216;
    
    mem_42216.references = NULL;
    
    struct memblock_device mem_42213;
    
    mem_42213.references = NULL;
    
    struct memblock_device mem_param_42211;
    
    mem_param_42211.references = NULL;
    
    struct memblock_device mem_param_42208;
    
    mem_param_42208.references = NULL;
    
    struct memblock_device ext_mem_42221;
    
    ext_mem_42221.references = NULL;
    
    struct memblock_device ext_mem_42222;
    
    ext_mem_42222.references = NULL;
    
    struct memblock_device mem_42205;
    
    mem_42205.references = NULL;
    
    struct memblock_device mem_42203;
    
    mem_42203.references = NULL;
    
    struct memblock_device mem_out_42706;
    
    mem_out_42706.references = NULL;
    
    struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
    struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
    struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
    struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
    struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
    int64_t bytes_42202 = (int64_t) 8 * niz2084U_35181;
    bool zzero_38179 = psizze_35184 == (int64_t) 0;
    bool nonzzero_38180 = !zzero_38179;
    bool nonzzero_cert_38181;
    
    if (!nonzzero_38180) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftbasics.fut:24:22-28\n   #1  ftSMJ.fut:423:5-41\n   #2  ftSMJ.fut:422:1-423:41\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_42204 = (int64_t) 4 * niz2084U_35181;
    int64_t segmap_tblock_sizze_39623;
    
    segmap_tblock_sizze_39623 = *ctx->tuning_params.gather_payloads_intzisegmap_tblock_sizze_39615;
    
    int64_t segmap_usable_groups_39624 = sdiv_up64(niz2084U_35181, segmap_tblock_sizze_39623);
    
    if (memblock_alloc_device(ctx, &mem_42203, bytes_42202, "mem_42203")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_42707 = sext_i64_i32(sdiv_up64(niz2084U_35181, segmap_tblock_sizze_39623));
    
    {
        err = gpu_kernel_gather_payloads_intzisegmap_39627(ctx, segmap_usable_groups_39624, 1, 1, *ctx->tuning_params.gather_payloads_intzisegmap_tblock_sizze_39615, 1, 1, (int64_t) 0, niz2084U_35181, incr_35183, is_mem_42199.mem, mem_42203.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t zm_lhs_38177 = add64(dz2083U_35182, psizze_35184);
    int64_t zs_lhs_38178 = sub64(zm_lhs_38177, (int64_t) 1);
    int64_t m_38182 = sdiv64(zs_lhs_38178, psizze_35184);
    
    if (memblock_alloc_device(ctx, &mem_42205, bytes_42204, "mem_42205")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, mem_42205, niz2084U_35181, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    bool loop_cond_38184 = slt64((int64_t) 0, m_38182);
    int64_t segmap_tblock_sizze_39651;
    
    segmap_tblock_sizze_39651 = *ctx->tuning_params.gather_payloads_intzisegmap_tblock_sizze_39633;
    
    int64_t segmap_usable_groups_39652 = sdiv_up_safe64(niz2084U_35181, segmap_tblock_sizze_39651);
    bool partitioned_gather_res_38185;
    int64_t partitioned_gather_res_38188;
    bool loop_while_38189;
    int64_t p_38192;
    
    if (memblock_set_device(ctx, &mem_param_42208, &mem_42203, "mem_42203") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_42211, &mem_42205, "mem_42205") != 0)
        return 1;
    loop_while_38189 = loop_cond_38184;
    p_38192 = (int64_t) 0;
    while (loop_while_38189) {
        int64_t lower_bound_38193 = mul64(psizze_35184, p_38192);
        int64_t min_arg1_38194 = add64(psizze_35184, lower_bound_38193);
        int64_t min_res_38195 = smin64(dz2083U_35182, min_arg1_38194);
        int64_t j_m_i_38196 = sub64(min_res_38195, lower_bound_38193);
        bool empty_slice_38197 = j_m_i_38196 == (int64_t) 0;
        int64_t m_38198 = sub64(j_m_i_38196, (int64_t) 1);
        int64_t i_p_m_t_s_38199 = add64(lower_bound_38193, m_38198);
        bool zzero_leq_i_p_m_t_s_38200 = sle64((int64_t) 0, i_p_m_t_s_38199);
        bool i_p_m_t_s_leq_w_38201 = slt64(i_p_m_t_s_38199, dz2083U_35182);
        bool zzero_lte_i_38202 = sle64((int64_t) 0, lower_bound_38193);
        bool i_lte_j_38203 = sle64(lower_bound_38193, min_res_38195);
        bool y_38204 = i_p_m_t_s_leq_w_38201 && zzero_lte_i_38202;
        bool y_38205 = zzero_leq_i_p_m_t_s_38200 && y_38204;
        bool forwards_ok_38206 = i_lte_j_38203 && y_38205;
        bool ok_or_empty_38207 = empty_slice_38197 || forwards_ok_38206;
        bool index_certs_38208;
        
        if (!ok_or_empty_38207) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) lower_bound_38193, ":", (long long) min_res_38195, "] out of bounds for array of shape [", (long long) dz2083U_35182, "].", "-> #0  ftbasics.fut:31:18-45\n   #1  ftSMJ.fut:423:5-41\n   #2  ftSMJ.fut:422:1-423:41\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_42213, bytes_42202, "mem_42213")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42213.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_42208.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {niz2084U_35181})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_42216, bytes_42204, "mem_42216")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_42742 = sext_i64_i32(sdiv_up64(niz2084U_35181, segmap_tblock_sizze_39651));
        
        {
            err = gpu_kernel_gather_payloads_intzisegmap_39655(ctx, segmap_usable_groups_39652, 1, 1, *ctx->tuning_params.gather_payloads_intzisegmap_tblock_sizze_39633, 1, 1, (int64_t) 0, niz2084U_35181, lower_bound_38193, min_res_38195, j_m_i_38196, ys_mem_42200.mem, mem_param_42208.mem, mem_param_42211.mem, mem_42216.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t tmp_38223 = add64((int64_t) 1, p_38192);
        bool loop_cond_38224 = slt64(tmp_38223, m_38182);
        
        if (memblock_set_device(ctx, &mem_param_tmp_42736, &mem_42213, "mem_42213") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_42737, &mem_42216, "mem_42216") != 0)
            return 1;
        
        bool loop_while_tmp_42738 = loop_cond_38224;
        int64_t p_tmp_42741 = tmp_38223;
        
        if (memblock_set_device(ctx, &mem_param_42208, &mem_param_tmp_42736, "mem_param_tmp_42736") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_42211, &mem_param_tmp_42737, "mem_param_tmp_42737") != 0)
            return 1;
        loop_while_38189 = loop_while_tmp_42738;
        p_38192 = p_tmp_42741;
    }
    if (memblock_set_device(ctx, &ext_mem_42222, &mem_param_42208, "mem_param_42208") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_42221, &mem_param_42211, "mem_param_42211") != 0)
        return 1;
    partitioned_gather_res_38185 = loop_while_38189;
    partitioned_gather_res_38188 = p_38192;
    if (memblock_unref_device(ctx, &mem_42203, "mem_42203") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42205, "mem_42205") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_42224, bytes_42204, "mem_42224")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_42224.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42221.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {niz2084U_35181})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_42221, "ext_mem_42221") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_42706, &mem_42224, "mem_42224") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_43280, &mem_out_42706, "mem_out_42706") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_42224, "mem_42224") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_42737, "mem_param_tmp_42737") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_42736, "mem_param_tmp_42736") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42216, "mem_42216") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42213, "mem_42213") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42211, "mem_param_42211") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42208, "mem_param_42208") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42221, "ext_mem_42221") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42222, "ext_mem_42222") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42205, "mem_42205") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42203, "mem_42203") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_42706, "mem_out_42706") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_int_GFUR(struct futhark_context *ctx, struct memblock_device *mem_out_p_43281, struct memblock_device preVals_mem_42199, struct memblock_device is_mem_42200, struct memblock_device ys_mem_42201, int64_t ni_36774, int64_t n_36775, int64_t incr_36776, int64_t psizze_36777)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_42223;
    
    mem_42223.references = NULL;
    
    struct memblock_device mem_param_tmp_42717;
    
    mem_param_tmp_42717.references = NULL;
    
    struct memblock_device mem_param_tmp_42716;
    
    mem_param_tmp_42716.references = NULL;
    
    struct memblock_device mem_42215;
    
    mem_42215.references = NULL;
    
    struct memblock_device mem_42212;
    
    mem_42212.references = NULL;
    
    struct memblock_device mem_param_42210;
    
    mem_param_42210.references = NULL;
    
    struct memblock_device mem_param_42207;
    
    mem_param_42207.references = NULL;
    
    struct memblock_device ext_mem_42220;
    
    ext_mem_42220.references = NULL;
    
    struct memblock_device ext_mem_42221;
    
    ext_mem_42221.references = NULL;
    
    struct memblock_device mem_42204;
    
    mem_42204.references = NULL;
    
    struct memblock_device mem_out_42706;
    
    mem_out_42706.references = NULL;
    
    struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
    struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
    struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
    struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
    struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
    int64_t bytes_42203 = (int64_t) 8 * ni_36774;
    bool zzero_38180 = psizze_36777 == (int64_t) 0;
    bool nonzzero_38181 = !zzero_38180;
    bool nonzzero_cert_38182;
    
    if (!nonzzero_38181) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftbasics.fut:43:22-28\n   #1  ftSMJ.fut:451:5-50\n   #2  ftSMJ.fut:450:1-451:50\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_42214 = (int64_t) 4 * ni_36774;
    int64_t segmap_tblock_sizze_39903;
    
    segmap_tblock_sizze_39903 = *ctx->tuning_params.gather_payloads_int_GFURzisegmap_tblock_sizze_39895;
    
    int64_t segmap_usable_groups_39904 = sdiv_up64(ni_36774, segmap_tblock_sizze_39903);
    
    if (memblock_alloc_device(ctx, &mem_42204, bytes_42203, "mem_42204")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_42707 = sext_i64_i32(sdiv_up64(ni_36774, segmap_tblock_sizze_39903));
    
    {
        err = gpu_kernel_gather_payloads_int_GFURzisegmap_39907(ctx, segmap_usable_groups_39904, 1, 1, *ctx->tuning_params.gather_payloads_int_GFURzisegmap_tblock_sizze_39895, 1, 1, (int64_t) 0, ni_36774, incr_36776, is_mem_42200.mem, mem_42204.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t zm_lhs_38178 = add64(n_36775, psizze_36777);
    int64_t zs_lhs_38179 = sub64(zm_lhs_38178, (int64_t) 1);
    int64_t m_38183 = sdiv64(zs_lhs_38179, psizze_36777);
    bool loop_cond_38184 = slt64((int64_t) 0, m_38183);
    int64_t segmap_tblock_sizze_39931;
    
    segmap_tblock_sizze_39931 = *ctx->tuning_params.gather_payloads_int_GFURzisegmap_tblock_sizze_39913;
    
    int64_t segmap_usable_groups_39932 = sdiv_up_safe64(ni_36774, segmap_tblock_sizze_39931);
    bool partitioned_gather_over_array_res_38185;
    int64_t partitioned_gather_over_array_res_38188;
    bool loop_while_38189;
    int64_t p_38192;
    
    if (memblock_set_device(ctx, &mem_param_42207, &mem_42204, "mem_42204") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_42210, &preVals_mem_42199, "preVals_mem_42199") != 0)
        return 1;
    loop_while_38189 = loop_cond_38184;
    p_38192 = (int64_t) 0;
    while (loop_while_38189) {
        int64_t lower_bound_38193 = mul64(psizze_36777, p_38192);
        int64_t min_arg1_38194 = add64(psizze_36777, lower_bound_38193);
        int64_t min_res_38195 = smin64(n_36775, min_arg1_38194);
        int64_t j_m_i_38196 = sub64(min_res_38195, lower_bound_38193);
        bool empty_slice_38197 = j_m_i_38196 == (int64_t) 0;
        int64_t m_38198 = sub64(j_m_i_38196, (int64_t) 1);
        int64_t i_p_m_t_s_38199 = add64(lower_bound_38193, m_38198);
        bool zzero_leq_i_p_m_t_s_38200 = sle64((int64_t) 0, i_p_m_t_s_38199);
        bool i_p_m_t_s_leq_w_38201 = slt64(i_p_m_t_s_38199, n_36775);
        bool zzero_lte_i_38202 = sle64((int64_t) 0, lower_bound_38193);
        bool i_lte_j_38203 = sle64(lower_bound_38193, min_res_38195);
        bool y_38204 = i_p_m_t_s_leq_w_38201 && zzero_lte_i_38202;
        bool y_38205 = zzero_leq_i_p_m_t_s_38200 && y_38204;
        bool forwards_ok_38206 = i_lte_j_38203 && y_38205;
        bool ok_or_empty_38207 = empty_slice_38197 || forwards_ok_38206;
        bool index_certs_38208;
        
        if (!ok_or_empty_38207) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) lower_bound_38193, ":", (long long) min_res_38195, "] out of bounds for array of shape [", (long long) n_36775, "].", "-> #0  ftbasics.fut:49:18-45\n   #1  ftSMJ.fut:451:5-50\n   #2  ftSMJ.fut:450:1-451:50\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_42212, bytes_42203, "mem_42212")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42212.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_42207.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {ni_36774})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_42215, bytes_42214, "mem_42215")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_42722 = sext_i64_i32(sdiv_up64(ni_36774, segmap_tblock_sizze_39931));
        
        {
            err = gpu_kernel_gather_payloads_int_GFURzisegmap_39935(ctx, segmap_usable_groups_39932, 1, 1, *ctx->tuning_params.gather_payloads_int_GFURzisegmap_tblock_sizze_39913, 1, 1, (int64_t) 0, ni_36774, lower_bound_38193, min_res_38195, j_m_i_38196, ys_mem_42201.mem, mem_param_42207.mem, mem_param_42210.mem, mem_42215.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t tmp_38223 = add64((int64_t) 1, p_38192);
        bool loop_cond_38224 = slt64(tmp_38223, m_38183);
        
        if (memblock_set_device(ctx, &mem_param_tmp_42716, &mem_42212, "mem_42212") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_42717, &mem_42215, "mem_42215") != 0)
            return 1;
        
        bool loop_while_tmp_42718 = loop_cond_38224;
        int64_t p_tmp_42721 = tmp_38223;
        
        if (memblock_set_device(ctx, &mem_param_42207, &mem_param_tmp_42716, "mem_param_tmp_42716") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_42210, &mem_param_tmp_42717, "mem_param_tmp_42717") != 0)
            return 1;
        loop_while_38189 = loop_while_tmp_42718;
        p_38192 = p_tmp_42721;
    }
    if (memblock_set_device(ctx, &ext_mem_42221, &mem_param_42207, "mem_param_42207") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_42220, &mem_param_42210, "mem_param_42210") != 0)
        return 1;
    partitioned_gather_over_array_res_38185 = loop_while_38189;
    partitioned_gather_over_array_res_38188 = p_38192;
    if (memblock_unref_device(ctx, &mem_42204, "mem_42204") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_42223, bytes_42214, "mem_42223")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_42223.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42220.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {ni_36774})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_42220, "ext_mem_42220") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_42706, &mem_42223, "mem_42223") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_43281, &mem_out_42706, "mem_out_42706") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_42223, "mem_42223") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_42717, "mem_param_tmp_42717") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_42716, "mem_param_tmp_42716") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42215, "mem_42215") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42212, "mem_42212") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42210, "mem_param_42210") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42207, "mem_param_42207") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42220, "ext_mem_42220") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42221, "ext_mem_42221") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42204, "mem_42204") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_42706, "mem_out_42706") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_long(struct futhark_context *ctx, struct memblock_device *mem_out_p_43282, struct memblock_device is_mem_42199, struct memblock_device ys_mem_42200, int64_t niz2084U_35490, int64_t dz2083U_35491, int64_t incr_35492, int64_t psizze_35493)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_42224;
    
    mem_42224.references = NULL;
    
    struct memblock_device mem_param_tmp_42737;
    
    mem_param_tmp_42737.references = NULL;
    
    struct memblock_device mem_param_tmp_42736;
    
    mem_param_tmp_42736.references = NULL;
    
    struct memblock_device mem_42216;
    
    mem_42216.references = NULL;
    
    struct memblock_device mem_42213;
    
    mem_42213.references = NULL;
    
    struct memblock_device mem_param_42211;
    
    mem_param_42211.references = NULL;
    
    struct memblock_device mem_param_42208;
    
    mem_param_42208.references = NULL;
    
    struct memblock_device ext_mem_42221;
    
    ext_mem_42221.references = NULL;
    
    struct memblock_device ext_mem_42222;
    
    ext_mem_42222.references = NULL;
    
    struct memblock_device mem_42205;
    
    mem_42205.references = NULL;
    
    struct memblock_device mem_42203;
    
    mem_42203.references = NULL;
    
    struct memblock_device mem_out_42706;
    
    mem_out_42706.references = NULL;
    
    struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
    struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
    struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
    struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
    struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
    int64_t bytes_42202 = (int64_t) 8 * niz2084U_35490;
    bool zzero_38179 = psizze_35493 == (int64_t) 0;
    bool nonzzero_38180 = !zzero_38179;
    bool nonzzero_cert_38181;
    
    if (!nonzzero_38180) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftbasics.fut:24:22-28\n   #1  ftSMJ.fut:426:5-41\n   #2  ftSMJ.fut:425:1-426:41\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t segmap_tblock_sizze_39679;
    
    segmap_tblock_sizze_39679 = *ctx->tuning_params.gather_payloads_longzisegmap_tblock_sizze_39671;
    
    int64_t segmap_usable_groups_39680 = sdiv_up64(niz2084U_35490, segmap_tblock_sizze_39679);
    
    if (memblock_alloc_device(ctx, &mem_42203, bytes_42202, "mem_42203")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_42707 = sext_i64_i32(sdiv_up64(niz2084U_35490, segmap_tblock_sizze_39679));
    
    {
        err = gpu_kernel_gather_payloads_longzisegmap_39683(ctx, segmap_usable_groups_39680, 1, 1, *ctx->tuning_params.gather_payloads_longzisegmap_tblock_sizze_39671, 1, 1, (int64_t) 0, niz2084U_35490, incr_35492, is_mem_42199.mem, mem_42203.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t zm_lhs_38177 = add64(dz2083U_35491, psizze_35493);
    int64_t zs_lhs_38178 = sub64(zm_lhs_38177, (int64_t) 1);
    int64_t m_38182 = sdiv64(zs_lhs_38178, psizze_35493);
    
    if (memblock_alloc_device(ctx, &mem_42205, bytes_42202, "mem_42205")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_42205, niz2084U_35490, (int64_t) 0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    bool loop_cond_38184 = slt64((int64_t) 0, m_38182);
    int64_t segmap_tblock_sizze_39707;
    
    segmap_tblock_sizze_39707 = *ctx->tuning_params.gather_payloads_longzisegmap_tblock_sizze_39689;
    
    int64_t segmap_usable_groups_39708 = sdiv_up_safe64(niz2084U_35490, segmap_tblock_sizze_39707);
    bool partitioned_gather_res_38185;
    int64_t partitioned_gather_res_38188;
    bool loop_while_38189;
    int64_t p_38192;
    
    if (memblock_set_device(ctx, &mem_param_42208, &mem_42203, "mem_42203") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_42211, &mem_42205, "mem_42205") != 0)
        return 1;
    loop_while_38189 = loop_cond_38184;
    p_38192 = (int64_t) 0;
    while (loop_while_38189) {
        int64_t lower_bound_38193 = mul64(psizze_35493, p_38192);
        int64_t min_arg1_38194 = add64(psizze_35493, lower_bound_38193);
        int64_t min_res_38195 = smin64(dz2083U_35491, min_arg1_38194);
        int64_t j_m_i_38196 = sub64(min_res_38195, lower_bound_38193);
        bool empty_slice_38197 = j_m_i_38196 == (int64_t) 0;
        int64_t m_38198 = sub64(j_m_i_38196, (int64_t) 1);
        int64_t i_p_m_t_s_38199 = add64(lower_bound_38193, m_38198);
        bool zzero_leq_i_p_m_t_s_38200 = sle64((int64_t) 0, i_p_m_t_s_38199);
        bool i_p_m_t_s_leq_w_38201 = slt64(i_p_m_t_s_38199, dz2083U_35491);
        bool zzero_lte_i_38202 = sle64((int64_t) 0, lower_bound_38193);
        bool i_lte_j_38203 = sle64(lower_bound_38193, min_res_38195);
        bool y_38204 = i_p_m_t_s_leq_w_38201 && zzero_lte_i_38202;
        bool y_38205 = zzero_leq_i_p_m_t_s_38200 && y_38204;
        bool forwards_ok_38206 = i_lte_j_38203 && y_38205;
        bool ok_or_empty_38207 = empty_slice_38197 || forwards_ok_38206;
        bool index_certs_38208;
        
        if (!ok_or_empty_38207) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) lower_bound_38193, ":", (long long) min_res_38195, "] out of bounds for array of shape [", (long long) dz2083U_35491, "].", "-> #0  ftbasics.fut:31:18-45\n   #1  ftSMJ.fut:426:5-41\n   #2  ftSMJ.fut:425:1-426:41\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_42213, bytes_42202, "mem_42213")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42213.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_42208.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {niz2084U_35490})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_42216, bytes_42202, "mem_42216")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_42742 = sext_i64_i32(sdiv_up64(niz2084U_35490, segmap_tblock_sizze_39707));
        
        {
            err = gpu_kernel_gather_payloads_longzisegmap_39711(ctx, segmap_usable_groups_39708, 1, 1, *ctx->tuning_params.gather_payloads_longzisegmap_tblock_sizze_39689, 1, 1, (int64_t) 0, niz2084U_35490, lower_bound_38193, min_res_38195, j_m_i_38196, ys_mem_42200.mem, mem_param_42208.mem, mem_param_42211.mem, mem_42216.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t tmp_38223 = add64((int64_t) 1, p_38192);
        bool loop_cond_38224 = slt64(tmp_38223, m_38182);
        
        if (memblock_set_device(ctx, &mem_param_tmp_42736, &mem_42213, "mem_42213") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_42737, &mem_42216, "mem_42216") != 0)
            return 1;
        
        bool loop_while_tmp_42738 = loop_cond_38224;
        int64_t p_tmp_42741 = tmp_38223;
        
        if (memblock_set_device(ctx, &mem_param_42208, &mem_param_tmp_42736, "mem_param_tmp_42736") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_42211, &mem_param_tmp_42737, "mem_param_tmp_42737") != 0)
            return 1;
        loop_while_38189 = loop_while_tmp_42738;
        p_38192 = p_tmp_42741;
    }
    if (memblock_set_device(ctx, &ext_mem_42222, &mem_param_42208, "mem_param_42208") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_42221, &mem_param_42211, "mem_param_42211") != 0)
        return 1;
    partitioned_gather_res_38185 = loop_while_38189;
    partitioned_gather_res_38188 = p_38192;
    if (memblock_unref_device(ctx, &mem_42203, "mem_42203") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42205, "mem_42205") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_42224, bytes_42202, "mem_42224")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42224.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42221.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {niz2084U_35490})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_42221, "ext_mem_42221") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_42706, &mem_42224, "mem_42224") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_43282, &mem_out_42706, "mem_out_42706") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_42224, "mem_42224") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_42737, "mem_param_tmp_42737") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_42736, "mem_param_tmp_42736") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42216, "mem_42216") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42213, "mem_42213") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42211, "mem_param_42211") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42208, "mem_param_42208") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42221, "ext_mem_42221") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42222, "ext_mem_42222") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42205, "mem_42205") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42203, "mem_42203") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_42706, "mem_out_42706") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_long_GFUR(struct futhark_context *ctx, struct memblock_device *mem_out_p_43283, struct memblock_device preVals_mem_42199, struct memblock_device is_mem_42200, struct memblock_device ys_mem_42201, int64_t ni_37075, int64_t n_37076, int64_t incr_37077, int64_t psizze_37078)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_42223;
    
    mem_42223.references = NULL;
    
    struct memblock_device mem_param_tmp_42717;
    
    mem_param_tmp_42717.references = NULL;
    
    struct memblock_device mem_param_tmp_42716;
    
    mem_param_tmp_42716.references = NULL;
    
    struct memblock_device mem_42215;
    
    mem_42215.references = NULL;
    
    struct memblock_device mem_42212;
    
    mem_42212.references = NULL;
    
    struct memblock_device mem_param_42210;
    
    mem_param_42210.references = NULL;
    
    struct memblock_device mem_param_42207;
    
    mem_param_42207.references = NULL;
    
    struct memblock_device ext_mem_42220;
    
    ext_mem_42220.references = NULL;
    
    struct memblock_device ext_mem_42221;
    
    ext_mem_42221.references = NULL;
    
    struct memblock_device mem_42204;
    
    mem_42204.references = NULL;
    
    struct memblock_device mem_out_42706;
    
    mem_out_42706.references = NULL;
    
    struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
    struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
    struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
    struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
    struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
    int64_t bytes_42203 = (int64_t) 8 * ni_37075;
    bool zzero_38180 = psizze_37078 == (int64_t) 0;
    bool nonzzero_38181 = !zzero_38180;
    bool nonzzero_cert_38182;
    
    if (!nonzzero_38181) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftbasics.fut:43:22-28\n   #1  ftSMJ.fut:454:5-50\n   #2  ftSMJ.fut:453:1-454:50\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t segmap_tblock_sizze_39959;
    
    segmap_tblock_sizze_39959 = *ctx->tuning_params.gather_payloads_long_GFURzisegmap_tblock_sizze_39951;
    
    int64_t segmap_usable_groups_39960 = sdiv_up64(ni_37075, segmap_tblock_sizze_39959);
    
    if (memblock_alloc_device(ctx, &mem_42204, bytes_42203, "mem_42204")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_42707 = sext_i64_i32(sdiv_up64(ni_37075, segmap_tblock_sizze_39959));
    
    {
        err = gpu_kernel_gather_payloads_long_GFURzisegmap_39963(ctx, segmap_usable_groups_39960, 1, 1, *ctx->tuning_params.gather_payloads_long_GFURzisegmap_tblock_sizze_39951, 1, 1, (int64_t) 0, ni_37075, incr_37077, is_mem_42200.mem, mem_42204.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t zm_lhs_38178 = add64(n_37076, psizze_37078);
    int64_t zs_lhs_38179 = sub64(zm_lhs_38178, (int64_t) 1);
    int64_t m_38183 = sdiv64(zs_lhs_38179, psizze_37078);
    bool loop_cond_38184 = slt64((int64_t) 0, m_38183);
    int64_t segmap_tblock_sizze_39987;
    
    segmap_tblock_sizze_39987 = *ctx->tuning_params.gather_payloads_long_GFURzisegmap_tblock_sizze_39969;
    
    int64_t segmap_usable_groups_39988 = sdiv_up_safe64(ni_37075, segmap_tblock_sizze_39987);
    bool partitioned_gather_over_array_res_38185;
    int64_t partitioned_gather_over_array_res_38188;
    bool loop_while_38189;
    int64_t p_38192;
    
    if (memblock_set_device(ctx, &mem_param_42207, &mem_42204, "mem_42204") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_42210, &preVals_mem_42199, "preVals_mem_42199") != 0)
        return 1;
    loop_while_38189 = loop_cond_38184;
    p_38192 = (int64_t) 0;
    while (loop_while_38189) {
        int64_t lower_bound_38193 = mul64(psizze_37078, p_38192);
        int64_t min_arg1_38194 = add64(psizze_37078, lower_bound_38193);
        int64_t min_res_38195 = smin64(n_37076, min_arg1_38194);
        int64_t j_m_i_38196 = sub64(min_res_38195, lower_bound_38193);
        bool empty_slice_38197 = j_m_i_38196 == (int64_t) 0;
        int64_t m_38198 = sub64(j_m_i_38196, (int64_t) 1);
        int64_t i_p_m_t_s_38199 = add64(lower_bound_38193, m_38198);
        bool zzero_leq_i_p_m_t_s_38200 = sle64((int64_t) 0, i_p_m_t_s_38199);
        bool i_p_m_t_s_leq_w_38201 = slt64(i_p_m_t_s_38199, n_37076);
        bool zzero_lte_i_38202 = sle64((int64_t) 0, lower_bound_38193);
        bool i_lte_j_38203 = sle64(lower_bound_38193, min_res_38195);
        bool y_38204 = i_p_m_t_s_leq_w_38201 && zzero_lte_i_38202;
        bool y_38205 = zzero_leq_i_p_m_t_s_38200 && y_38204;
        bool forwards_ok_38206 = i_lte_j_38203 && y_38205;
        bool ok_or_empty_38207 = empty_slice_38197 || forwards_ok_38206;
        bool index_certs_38208;
        
        if (!ok_or_empty_38207) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) lower_bound_38193, ":", (long long) min_res_38195, "] out of bounds for array of shape [", (long long) n_37076, "].", "-> #0  ftbasics.fut:49:18-45\n   #1  ftSMJ.fut:454:5-50\n   #2  ftSMJ.fut:453:1-454:50\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_42212, bytes_42203, "mem_42212")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42212.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_42207.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {ni_37075})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_42215, bytes_42203, "mem_42215")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_42722 = sext_i64_i32(sdiv_up64(ni_37075, segmap_tblock_sizze_39987));
        
        {
            err = gpu_kernel_gather_payloads_long_GFURzisegmap_39991(ctx, segmap_usable_groups_39988, 1, 1, *ctx->tuning_params.gather_payloads_long_GFURzisegmap_tblock_sizze_39969, 1, 1, (int64_t) 0, ni_37075, lower_bound_38193, min_res_38195, j_m_i_38196, ys_mem_42201.mem, mem_param_42207.mem, mem_param_42210.mem, mem_42215.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t tmp_38223 = add64((int64_t) 1, p_38192);
        bool loop_cond_38224 = slt64(tmp_38223, m_38183);
        
        if (memblock_set_device(ctx, &mem_param_tmp_42716, &mem_42212, "mem_42212") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_42717, &mem_42215, "mem_42215") != 0)
            return 1;
        
        bool loop_while_tmp_42718 = loop_cond_38224;
        int64_t p_tmp_42721 = tmp_38223;
        
        if (memblock_set_device(ctx, &mem_param_42207, &mem_param_tmp_42716, "mem_param_tmp_42716") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_42210, &mem_param_tmp_42717, "mem_param_tmp_42717") != 0)
            return 1;
        loop_while_38189 = loop_while_tmp_42718;
        p_38192 = p_tmp_42721;
    }
    if (memblock_set_device(ctx, &ext_mem_42221, &mem_param_42207, "mem_param_42207") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_42220, &mem_param_42210, "mem_param_42210") != 0)
        return 1;
    partitioned_gather_over_array_res_38185 = loop_while_38189;
    partitioned_gather_over_array_res_38188 = p_38192;
    if (memblock_unref_device(ctx, &mem_42204, "mem_42204") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_42223, bytes_42203, "mem_42223")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42223.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42220.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {ni_37075})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_42220, "ext_mem_42220") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_42706, &mem_42223, "mem_42223") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_43283, &mem_out_42706, "mem_out_42706") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_42223, "mem_42223") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_42717, "mem_param_tmp_42717") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_42716, "mem_param_tmp_42716") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42215, "mem_42215") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42212, "mem_42212") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42210, "mem_param_42210") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42207, "mem_param_42207") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42220, "ext_mem_42220") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42221, "ext_mem_42221") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42204, "mem_42204") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_42706, "mem_out_42706") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_short(struct futhark_context *ctx, struct memblock_device *mem_out_p_43284, struct memblock_device is_mem_42199, struct memblock_device ys_mem_42200, int64_t niz2084U_34869, int64_t dz2083U_34870, int64_t incr_34871, int64_t psizze_34872)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_42224;
    
    mem_42224.references = NULL;
    
    struct memblock_device mem_param_tmp_42737;
    
    mem_param_tmp_42737.references = NULL;
    
    struct memblock_device mem_param_tmp_42736;
    
    mem_param_tmp_42736.references = NULL;
    
    struct memblock_device mem_42216;
    
    mem_42216.references = NULL;
    
    struct memblock_device mem_42213;
    
    mem_42213.references = NULL;
    
    struct memblock_device mem_param_42211;
    
    mem_param_42211.references = NULL;
    
    struct memblock_device mem_param_42208;
    
    mem_param_42208.references = NULL;
    
    struct memblock_device ext_mem_42221;
    
    ext_mem_42221.references = NULL;
    
    struct memblock_device ext_mem_42222;
    
    ext_mem_42222.references = NULL;
    
    struct memblock_device mem_42205;
    
    mem_42205.references = NULL;
    
    struct memblock_device mem_42203;
    
    mem_42203.references = NULL;
    
    struct memblock_device mem_out_42706;
    
    mem_out_42706.references = NULL;
    
    struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
    struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
    struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
    struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
    struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
    int64_t bytes_42202 = (int64_t) 8 * niz2084U_34869;
    bool zzero_38179 = psizze_34872 == (int64_t) 0;
    bool nonzzero_38180 = !zzero_38179;
    bool nonzzero_cert_38181;
    
    if (!nonzzero_38180) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftbasics.fut:24:22-28\n   #1  ftSMJ.fut:420:5-41\n   #2  ftSMJ.fut:419:1-420:41\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_42204 = (int64_t) 2 * niz2084U_34869;
    int64_t segmap_tblock_sizze_39567;
    
    segmap_tblock_sizze_39567 = *ctx->tuning_params.gather_payloads_shortzisegmap_tblock_sizze_39559;
    
    int64_t segmap_usable_groups_39568 = sdiv_up64(niz2084U_34869, segmap_tblock_sizze_39567);
    
    if (memblock_alloc_device(ctx, &mem_42203, bytes_42202, "mem_42203")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_42707 = sext_i64_i32(sdiv_up64(niz2084U_34869, segmap_tblock_sizze_39567));
    
    {
        err = gpu_kernel_gather_payloads_shortzisegmap_39571(ctx, segmap_usable_groups_39568, 1, 1, *ctx->tuning_params.gather_payloads_shortzisegmap_tblock_sizze_39559, 1, 1, (int64_t) 0, niz2084U_34869, incr_34871, is_mem_42199.mem, mem_42203.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t zm_lhs_38177 = add64(dz2083U_34870, psizze_34872);
    int64_t zs_lhs_38178 = sub64(zm_lhs_38177, (int64_t) 1);
    int64_t m_38182 = sdiv64(zs_lhs_38178, psizze_34872);
    
    if (memblock_alloc_device(ctx, &mem_42205, bytes_42204, "mem_42205")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i16(ctx, mem_42205, niz2084U_34869, (int16_t) 0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    bool loop_cond_38184 = slt64((int64_t) 0, m_38182);
    int64_t segmap_tblock_sizze_39595;
    
    segmap_tblock_sizze_39595 = *ctx->tuning_params.gather_payloads_shortzisegmap_tblock_sizze_39577;
    
    int64_t segmap_usable_groups_39596 = sdiv_up_safe64(niz2084U_34869, segmap_tblock_sizze_39595);
    bool partitioned_gather_res_38185;
    int64_t partitioned_gather_res_38188;
    bool loop_while_38189;
    int64_t p_38192;
    
    if (memblock_set_device(ctx, &mem_param_42208, &mem_42203, "mem_42203") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_42211, &mem_42205, "mem_42205") != 0)
        return 1;
    loop_while_38189 = loop_cond_38184;
    p_38192 = (int64_t) 0;
    while (loop_while_38189) {
        int64_t lower_bound_38193 = mul64(psizze_34872, p_38192);
        int64_t min_arg1_38194 = add64(psizze_34872, lower_bound_38193);
        int64_t min_res_38195 = smin64(dz2083U_34870, min_arg1_38194);
        int64_t j_m_i_38196 = sub64(min_res_38195, lower_bound_38193);
        bool empty_slice_38197 = j_m_i_38196 == (int64_t) 0;
        int64_t m_38198 = sub64(j_m_i_38196, (int64_t) 1);
        int64_t i_p_m_t_s_38199 = add64(lower_bound_38193, m_38198);
        bool zzero_leq_i_p_m_t_s_38200 = sle64((int64_t) 0, i_p_m_t_s_38199);
        bool i_p_m_t_s_leq_w_38201 = slt64(i_p_m_t_s_38199, dz2083U_34870);
        bool zzero_lte_i_38202 = sle64((int64_t) 0, lower_bound_38193);
        bool i_lte_j_38203 = sle64(lower_bound_38193, min_res_38195);
        bool y_38204 = i_p_m_t_s_leq_w_38201 && zzero_lte_i_38202;
        bool y_38205 = zzero_leq_i_p_m_t_s_38200 && y_38204;
        bool forwards_ok_38206 = i_lte_j_38203 && y_38205;
        bool ok_or_empty_38207 = empty_slice_38197 || forwards_ok_38206;
        bool index_certs_38208;
        
        if (!ok_or_empty_38207) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) lower_bound_38193, ":", (long long) min_res_38195, "] out of bounds for array of shape [", (long long) dz2083U_34870, "].", "-> #0  ftbasics.fut:31:18-45\n   #1  ftSMJ.fut:420:5-41\n   #2  ftSMJ.fut:419:1-420:41\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_42213, bytes_42202, "mem_42213")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42213.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_42208.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {niz2084U_34869})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_42216, bytes_42204, "mem_42216")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_42742 = sext_i64_i32(sdiv_up64(niz2084U_34869, segmap_tblock_sizze_39595));
        
        {
            err = gpu_kernel_gather_payloads_shortzisegmap_39599(ctx, segmap_usable_groups_39596, 1, 1, *ctx->tuning_params.gather_payloads_shortzisegmap_tblock_sizze_39577, 1, 1, (int64_t) 0, niz2084U_34869, lower_bound_38193, min_res_38195, j_m_i_38196, ys_mem_42200.mem, mem_param_42208.mem, mem_param_42211.mem, mem_42216.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t tmp_38223 = add64((int64_t) 1, p_38192);
        bool loop_cond_38224 = slt64(tmp_38223, m_38182);
        
        if (memblock_set_device(ctx, &mem_param_tmp_42736, &mem_42213, "mem_42213") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_42737, &mem_42216, "mem_42216") != 0)
            return 1;
        
        bool loop_while_tmp_42738 = loop_cond_38224;
        int64_t p_tmp_42741 = tmp_38223;
        
        if (memblock_set_device(ctx, &mem_param_42208, &mem_param_tmp_42736, "mem_param_tmp_42736") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_42211, &mem_param_tmp_42737, "mem_param_tmp_42737") != 0)
            return 1;
        loop_while_38189 = loop_while_tmp_42738;
        p_38192 = p_tmp_42741;
    }
    if (memblock_set_device(ctx, &ext_mem_42222, &mem_param_42208, "mem_param_42208") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_42221, &mem_param_42211, "mem_param_42211") != 0)
        return 1;
    partitioned_gather_res_38185 = loop_while_38189;
    partitioned_gather_res_38188 = p_38192;
    if (memblock_unref_device(ctx, &mem_42203, "mem_42203") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42205, "mem_42205") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_42224, bytes_42204, "mem_42224")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_2b(ctx, 1, mem_42224.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42221.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {niz2084U_34869})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_42221, "ext_mem_42221") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_42706, &mem_42224, "mem_42224") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_43284, &mem_out_42706, "mem_out_42706") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_42224, "mem_42224") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_42737, "mem_param_tmp_42737") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_42736, "mem_param_tmp_42736") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42216, "mem_42216") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42213, "mem_42213") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42211, "mem_param_42211") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42208, "mem_param_42208") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42221, "ext_mem_42221") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42222, "ext_mem_42222") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42205, "mem_42205") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42203, "mem_42203") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_42706, "mem_out_42706") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_short_GFUR(struct futhark_context *ctx, struct memblock_device *mem_out_p_43285, struct memblock_device preVals_mem_42199, struct memblock_device is_mem_42200, struct memblock_device ys_mem_42201, int64_t ni_36473, int64_t n_36474, int64_t incr_36475, int64_t psizze_36476)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_42223;
    
    mem_42223.references = NULL;
    
    struct memblock_device mem_param_tmp_42717;
    
    mem_param_tmp_42717.references = NULL;
    
    struct memblock_device mem_param_tmp_42716;
    
    mem_param_tmp_42716.references = NULL;
    
    struct memblock_device mem_42215;
    
    mem_42215.references = NULL;
    
    struct memblock_device mem_42212;
    
    mem_42212.references = NULL;
    
    struct memblock_device mem_param_42210;
    
    mem_param_42210.references = NULL;
    
    struct memblock_device mem_param_42207;
    
    mem_param_42207.references = NULL;
    
    struct memblock_device ext_mem_42220;
    
    ext_mem_42220.references = NULL;
    
    struct memblock_device ext_mem_42221;
    
    ext_mem_42221.references = NULL;
    
    struct memblock_device mem_42204;
    
    mem_42204.references = NULL;
    
    struct memblock_device mem_out_42706;
    
    mem_out_42706.references = NULL;
    
    struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
    struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
    struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
    struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
    struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
    int64_t bytes_42203 = (int64_t) 8 * ni_36473;
    bool zzero_38180 = psizze_36476 == (int64_t) 0;
    bool nonzzero_38181 = !zzero_38180;
    bool nonzzero_cert_38182;
    
    if (!nonzzero_38181) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftbasics.fut:43:22-28\n   #1  ftSMJ.fut:448:5-50\n   #2  ftSMJ.fut:447:1-448:50\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_42214 = (int64_t) 2 * ni_36473;
    int64_t segmap_tblock_sizze_39847;
    
    segmap_tblock_sizze_39847 = *ctx->tuning_params.gather_payloads_short_GFURzisegmap_tblock_sizze_39839;
    
    int64_t segmap_usable_groups_39848 = sdiv_up64(ni_36473, segmap_tblock_sizze_39847);
    
    if (memblock_alloc_device(ctx, &mem_42204, bytes_42203, "mem_42204")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_42707 = sext_i64_i32(sdiv_up64(ni_36473, segmap_tblock_sizze_39847));
    
    {
        err = gpu_kernel_gather_payloads_short_GFURzisegmap_39851(ctx, segmap_usable_groups_39848, 1, 1, *ctx->tuning_params.gather_payloads_short_GFURzisegmap_tblock_sizze_39839, 1, 1, (int64_t) 0, ni_36473, incr_36475, is_mem_42200.mem, mem_42204.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t zm_lhs_38178 = add64(n_36474, psizze_36476);
    int64_t zs_lhs_38179 = sub64(zm_lhs_38178, (int64_t) 1);
    int64_t m_38183 = sdiv64(zs_lhs_38179, psizze_36476);
    bool loop_cond_38184 = slt64((int64_t) 0, m_38183);
    int64_t segmap_tblock_sizze_39875;
    
    segmap_tblock_sizze_39875 = *ctx->tuning_params.gather_payloads_short_GFURzisegmap_tblock_sizze_39857;
    
    int64_t segmap_usable_groups_39876 = sdiv_up_safe64(ni_36473, segmap_tblock_sizze_39875);
    bool partitioned_gather_over_array_res_38185;
    int64_t partitioned_gather_over_array_res_38188;
    bool loop_while_38189;
    int64_t p_38192;
    
    if (memblock_set_device(ctx, &mem_param_42207, &mem_42204, "mem_42204") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_42210, &preVals_mem_42199, "preVals_mem_42199") != 0)
        return 1;
    loop_while_38189 = loop_cond_38184;
    p_38192 = (int64_t) 0;
    while (loop_while_38189) {
        int64_t lower_bound_38193 = mul64(psizze_36476, p_38192);
        int64_t min_arg1_38194 = add64(psizze_36476, lower_bound_38193);
        int64_t min_res_38195 = smin64(n_36474, min_arg1_38194);
        int64_t j_m_i_38196 = sub64(min_res_38195, lower_bound_38193);
        bool empty_slice_38197 = j_m_i_38196 == (int64_t) 0;
        int64_t m_38198 = sub64(j_m_i_38196, (int64_t) 1);
        int64_t i_p_m_t_s_38199 = add64(lower_bound_38193, m_38198);
        bool zzero_leq_i_p_m_t_s_38200 = sle64((int64_t) 0, i_p_m_t_s_38199);
        bool i_p_m_t_s_leq_w_38201 = slt64(i_p_m_t_s_38199, n_36474);
        bool zzero_lte_i_38202 = sle64((int64_t) 0, lower_bound_38193);
        bool i_lte_j_38203 = sle64(lower_bound_38193, min_res_38195);
        bool y_38204 = i_p_m_t_s_leq_w_38201 && zzero_lte_i_38202;
        bool y_38205 = zzero_leq_i_p_m_t_s_38200 && y_38204;
        bool forwards_ok_38206 = i_lte_j_38203 && y_38205;
        bool ok_or_empty_38207 = empty_slice_38197 || forwards_ok_38206;
        bool index_certs_38208;
        
        if (!ok_or_empty_38207) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) lower_bound_38193, ":", (long long) min_res_38195, "] out of bounds for array of shape [", (long long) n_36474, "].", "-> #0  ftbasics.fut:49:18-45\n   #1  ftSMJ.fut:448:5-50\n   #2  ftSMJ.fut:447:1-448:50\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_42212, bytes_42203, "mem_42212")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42212.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_42207.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {ni_36473})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_42215, bytes_42214, "mem_42215")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_42722 = sext_i64_i32(sdiv_up64(ni_36473, segmap_tblock_sizze_39875));
        
        {
            err = gpu_kernel_gather_payloads_short_GFURzisegmap_39879(ctx, segmap_usable_groups_39876, 1, 1, *ctx->tuning_params.gather_payloads_short_GFURzisegmap_tblock_sizze_39857, 1, 1, (int64_t) 0, ni_36473, lower_bound_38193, min_res_38195, j_m_i_38196, ys_mem_42201.mem, mem_param_42207.mem, mem_param_42210.mem, mem_42215.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t tmp_38223 = add64((int64_t) 1, p_38192);
        bool loop_cond_38224 = slt64(tmp_38223, m_38183);
        
        if (memblock_set_device(ctx, &mem_param_tmp_42716, &mem_42212, "mem_42212") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_42717, &mem_42215, "mem_42215") != 0)
            return 1;
        
        bool loop_while_tmp_42718 = loop_cond_38224;
        int64_t p_tmp_42721 = tmp_38223;
        
        if (memblock_set_device(ctx, &mem_param_42207, &mem_param_tmp_42716, "mem_param_tmp_42716") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_42210, &mem_param_tmp_42717, "mem_param_tmp_42717") != 0)
            return 1;
        loop_while_38189 = loop_while_tmp_42718;
        p_38192 = p_tmp_42721;
    }
    if (memblock_set_device(ctx, &ext_mem_42221, &mem_param_42207, "mem_param_42207") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_42220, &mem_param_42210, "mem_param_42210") != 0)
        return 1;
    partitioned_gather_over_array_res_38185 = loop_while_38189;
    partitioned_gather_over_array_res_38188 = p_38192;
    if (memblock_unref_device(ctx, &mem_42204, "mem_42204") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_42223, bytes_42214, "mem_42223")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_2b(ctx, 1, mem_42223.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42220.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {ni_36473})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_42220, "ext_mem_42220") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_42706, &mem_42223, "mem_42223") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_43285, &mem_out_42706, "mem_out_42706") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_42223, "mem_42223") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_42717, "mem_param_tmp_42717") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_42716, "mem_param_tmp_42716") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42215, "mem_42215") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42212, "mem_42212") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42210, "mem_param_42210") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42207, "mem_param_42207") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42220, "ext_mem_42220") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42221, "ext_mem_42221") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42204, "mem_42204") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_42706, "mem_out_42706") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_inner_SMJ_double(struct futhark_context *ctx, struct memblock_device *mem_out_p_43286, struct memblock_device *mem_out_p_43287, struct memblock_device *mem_out_p_43288, int64_t *out_prim_out_43289, struct memblock_device tR_mem_42199, struct memblock_device tS_mem_42200, int64_t nR_34519, int64_t nS_34520, int64_t offset_R_34523, int64_t offset_S_34524, int64_t partitionsPerWindow_34525, int64_t numberOfWindows_34526, int64_t extParallelism_34527, int64_t scatter_psizze_34528)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_42477;
    
    mem_42477.references = NULL;
    
    struct memblock_device mem_42475;
    
    mem_42475.references = NULL;
    
    struct memblock_device mem_42473;
    
    mem_42473.references = NULL;
    
    struct memblock_device mem_param_tmp_43215;
    
    mem_param_tmp_43215.references = NULL;
    
    struct memblock_device mem_param_tmp_43214;
    
    mem_param_tmp_43214.references = NULL;
    
    struct memblock_device mem_param_tmp_43213;
    
    mem_param_tmp_43213.references = NULL;
    
    struct memblock_device mem_42459;
    
    mem_42459.references = NULL;
    
    struct memblock_device mem_42457;
    
    mem_42457.references = NULL;
    
    struct memblock_device mem_42452;
    
    mem_42452.references = NULL;
    
    struct memblock_device mem_42450;
    
    mem_42450.references = NULL;
    
    struct memblock_device mem_42448;
    
    mem_42448.references = NULL;
    
    struct memblock_device mem_param_42446;
    
    mem_param_42446.references = NULL;
    
    struct memblock_device mem_param_42443;
    
    mem_param_42443.references = NULL;
    
    struct memblock_device mem_param_42440;
    
    mem_param_42440.references = NULL;
    
    struct memblock_device ext_mem_42469;
    
    ext_mem_42469.references = NULL;
    
    struct memblock_device ext_mem_42470;
    
    ext_mem_42470.references = NULL;
    
    struct memblock_device ext_mem_42471;
    
    ext_mem_42471.references = NULL;
    
    struct memblock_device mem_42455;
    
    mem_42455.references = NULL;
    
    struct memblock_device mem_42454;
    
    mem_42454.references = NULL;
    
    struct memblock_device mem_42453;
    
    mem_42453.references = NULL;
    
    struct memblock_device mem_42427;
    
    mem_42427.references = NULL;
    
    struct memblock_device mem_42425;
    
    mem_42425.references = NULL;
    
    struct memblock_device mem_42423;
    
    mem_42423.references = NULL;
    
    struct memblock_device mem_42412;
    
    mem_42412.references = NULL;
    
    struct memblock_device mem_42410;
    
    mem_42410.references = NULL;
    
    struct memblock_device mem_42408;
    
    mem_42408.references = NULL;
    
    struct memblock_device mem_42404;
    
    mem_42404.references = NULL;
    
    struct memblock_device mem_42402;
    
    mem_42402.references = NULL;
    
    struct memblock_device mem_42406;
    
    mem_42406.references = NULL;
    
    struct memblock_device mem_42398;
    
    mem_42398.references = NULL;
    
    struct memblock_device mem_42399;
    
    mem_42399.references = NULL;
    
    struct memblock_device ext_mem_42400;
    
    ext_mem_42400.references = NULL;
    
    struct memblock_device mem_42395;
    
    mem_42395.references = NULL;
    
    struct memblock_device mem_42396;
    
    mem_42396.references = NULL;
    
    struct memblock_device ext_mem_42397;
    
    ext_mem_42397.references = NULL;
    
    struct memblock_device mem_42394;
    
    mem_42394.references = NULL;
    
    struct memblock_device incprefixes_mem_43016;
    
    incprefixes_mem_43016.references = NULL;
    
    struct memblock_device aggregates_mem_43014;
    
    aggregates_mem_43014.references = NULL;
    
    struct memblock_device incprefixes_mem_43012;
    
    incprefixes_mem_43012.references = NULL;
    
    struct memblock_device aggregates_mem_43010;
    
    aggregates_mem_43010.references = NULL;
    
    struct memblock_device status_flags_mem_43008;
    
    status_flags_mem_43008.references = NULL;
    
    struct memblock_device mem_42391;
    
    mem_42391.references = NULL;
    
    struct memblock_device mem_42389;
    
    mem_42389.references = NULL;
    
    struct memblock_device mem_42387;
    
    mem_42387.references = NULL;
    
    struct memblock_device mem_42383;
    
    mem_42383.references = NULL;
    
    struct memblock_device mem_42381;
    
    mem_42381.references = NULL;
    
    struct memblock_device mem_42379;
    
    mem_42379.references = NULL;
    
    struct memblock_device mem_42377;
    
    mem_42377.references = NULL;
    
    struct memblock_device incprefixes_mem_42875;
    
    incprefixes_mem_42875.references = NULL;
    
    struct memblock_device aggregates_mem_42873;
    
    aggregates_mem_42873.references = NULL;
    
    struct memblock_device status_flags_mem_42851;
    
    status_flags_mem_42851.references = NULL;
    
    struct memblock_device mem_42375;
    
    mem_42375.references = NULL;
    
    struct memblock_device mem_42373;
    
    mem_42373.references = NULL;
    
    struct memblock_device mem_param_tmp_42763;
    
    mem_param_tmp_42763.references = NULL;
    
    struct memblock_device mem_param_tmp_42762;
    
    mem_param_tmp_42762.references = NULL;
    
    struct memblock_device mem_42352;
    
    mem_42352.references = NULL;
    
    struct memblock_device mem_42350;
    
    mem_42350.references = NULL;
    
    struct memblock_device mem_42285;
    
    mem_42285.references = NULL;
    
    struct memblock_device mem_42283;
    
    mem_42283.references = NULL;
    
    struct memblock_device mem_42346;
    
    mem_42346.references = NULL;
    
    struct memblock_device mem_42344;
    
    mem_42344.references = NULL;
    
    struct memblock_device ext_mem_42347;
    
    ext_mem_42347.references = NULL;
    
    struct memblock_device ext_mem_42348;
    
    ext_mem_42348.references = NULL;
    
    struct memblock_device ext_mem_42224;
    
    ext_mem_42224.references = NULL;
    
    struct memblock_device ext_mem_42355;
    
    ext_mem_42355.references = NULL;
    
    struct memblock_device ext_mem_42358;
    
    ext_mem_42358.references = NULL;
    
    struct memblock_device mem_42223;
    
    mem_42223.references = NULL;
    
    struct memblock_device ext_mem_42361;
    
    ext_mem_42361.references = NULL;
    
    struct memblock_device ext_mem_42364;
    
    ext_mem_42364.references = NULL;
    
    struct memblock_device ext_mem_42221;
    
    ext_mem_42221.references = NULL;
    
    struct memblock_device ext_mem_42220;
    
    ext_mem_42220.references = NULL;
    
    struct memblock_device mem_param_42217;
    
    mem_param_42217.references = NULL;
    
    struct memblock_device mem_param_42214;
    
    mem_param_42214.references = NULL;
    
    struct memblock_device ext_mem_42369;
    
    ext_mem_42369.references = NULL;
    
    struct memblock_device ext_mem_42370;
    
    ext_mem_42370.references = NULL;
    
    struct memblock_device mem_42222;
    
    mem_42222.references = NULL;
    
    struct memblock_device mem_42219;
    
    mem_42219.references = NULL;
    
    struct memblock_device mem_42218;
    
    mem_42218.references = NULL;
    
    struct memblock_device mem_42209;
    
    mem_42209.references = NULL;
    
    struct memblock_device mem_42210;
    
    mem_42210.references = NULL;
    
    struct memblock_device ext_mem_42211;
    
    ext_mem_42211.references = NULL;
    
    struct memblock_device mem_42206;
    
    mem_42206.references = NULL;
    
    struct memblock_device mem_42207;
    
    mem_42207.references = NULL;
    
    struct memblock_device ext_mem_42208;
    
    ext_mem_42208.references = NULL;
    
    struct memblock_device mem_42205;
    
    mem_42205.references = NULL;
    
    struct memblock_device mem_42203;
    
    mem_42203.references = NULL;
    
    struct memblock_device ext_mem_42201;
    
    ext_mem_42201.references = NULL;
    
    struct memblock_device mem_out_42708;
    
    mem_out_42708.references = NULL;
    
    struct memblock_device mem_out_42707;
    
    mem_out_42707.references = NULL;
    
    struct memblock_device mem_out_42706;
    
    mem_out_42706.references = NULL;
    
    struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
    struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
    struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
    struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
    struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
    int64_t prim_out_42709;
    int64_t zm_lhs_39067 = add64(nR_34519, extParallelism_34527);
    int64_t zs_lhs_39068 = sub64(zm_lhs_39067, (int64_t) 1);
    bool zzero_39069 = extParallelism_34527 == (int64_t) 0;
    bool nonzzero_39070 = !zzero_39069;
    bool nonzzero_cert_39071;
    
    if (!nonzzero_39070) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftSMJ.fut:48:39-55\n   #1  ftSMJ.fut:327:87-89\n   #2  ftSMJ.fut:404:133-136\n   #3  ftSMJ.fut:393:1-404:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t numIter_39072 = sdiv64(zs_lhs_39068, extParallelism_34527);
    
    if (futrts_indicesWithIncrement_9920(ctx, &ext_mem_42201, tR_mem_42199, nR_34519, offset_R_34523) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t bytes_42202 = (int64_t) 8 * nR_34519;
    
    if (memblock_alloc_device(ctx, &mem_42203, bytes_42202, "mem_42203")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_42203, nR_34519, (int64_t) -1) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42205, bytes_42202, "mem_42205")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_42205, nR_34519, (int64_t) 0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    bool loop_cond_39076 = slt64((int64_t) 0, numIter_39072);
    bool cond_39077 = slt64((int64_t) 0, nS_34520);
    int64_t tmp_39078 = sub64(nS_34520, (int64_t) 1);
    bool loop_not_taken_39079 = !cond_39077;
    bool loop_not_taken_39080 = !loop_cond_39076;
    bool x_39081 = sle64((int64_t) 0, tmp_39078);
    bool y_39082 = slt64(tmp_39078, nS_34520);
    bool protect_cond_conj_39083 = loop_cond_39076 && cond_39077;
    
    if (protect_cond_conj_39083) {
        if (memblock_alloc_device(ctx, &mem_42207, (int64_t) 8, "mem_42207")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_doublezigpuseq_42730(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, tS_mem_42200.mem, mem_42207.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42208, &mem_42207, "mem_42207") != 0)
            return 1;
    } else {
        if (memblock_alloc_device(ctx, &mem_42206, (int64_t) 8, "mem_42206")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_f64(ctx, mem_42206, (int64_t) 1, 0.0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42208, &mem_42206, "mem_42206") != 0)
            return 1;
    }
    
    bool bounds_check_39086 = x_39081 && y_39082;
    bool protect_assert_disj_39087 = loop_not_taken_39079 || bounds_check_39086;
    bool protect_assert_disj_39088 = loop_not_taken_39080 || protect_assert_disj_39087;
    bool index_certs_39089;
    
    if (!protect_assert_disj_39088) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) tmp_39078, "] out of bounds for array of shape [", (long long) nS_34520, "].", "-> #0  ftSMJ.fut:60:34-42\n   #1  ftSMJ.fut:327:87-89\n   #2  ftSMJ.fut:404:133-136\n   #3  ftSMJ.fut:393:1-404:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    if (protect_cond_conj_39083) {
        if (memblock_alloc_device(ctx, &mem_42210, (int64_t) 8, "mem_42210")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_doublezigpuseq_42756(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, tmp_39078, tS_mem_42200.mem, mem_42210.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42211, &mem_42210, "mem_42210") != 0)
            return 1;
    } else {
        if (memblock_alloc_device(ctx, &mem_42209, (int64_t) 8, "mem_42209")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_f64(ctx, mem_42209, (int64_t) 1, 0.0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42211, &mem_42209, "mem_42209") != 0)
            return 1;
    }
    if (memblock_alloc_device(ctx, &mem_42218, (int64_t) 8, "mem_42218")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42219, (int64_t) 8, "mem_42219")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42222, (int64_t) 1, "mem_42222")) {
        err = 1;
        goto cleanup;
    }
    
    int64_t ext_42368;
    int64_t ext_42367;
    int64_t ext_42366;
    int64_t ext_42365;
    bool defunc_0_find_joinTuples_res_39092;
    int64_t defunc_0_find_joinTuples_res_39093;
    bool loop_while_39096;
    int64_t p_39097;
    int64_t ctx_param_ext_42212;
    int64_t ctx_param_ext_42213;
    int64_t ctx_param_ext_42215;
    int64_t ctx_param_ext_42216;
    
    if (memblock_set_device(ctx, &mem_param_42214, &mem_42205, "mem_42205") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_42217, &mem_42203, "mem_42203") != 0)
        return 1;
    ctx_param_ext_42212 = (int64_t) 0;
    ctx_param_ext_42213 = (int64_t) 1;
    ctx_param_ext_42215 = (int64_t) 0;
    ctx_param_ext_42216 = (int64_t) 1;
    loop_while_39096 = loop_cond_39076;
    p_39097 = (int64_t) 0;
    while (loop_while_39096) {
        int64_t start_39100 = mul64(extParallelism_34527, p_39097);
        int64_t min_arg1_39101 = sub64(nR_34519, start_39100);
        int64_t min_res_39102 = smin64(extParallelism_34527, min_arg1_39101);
        int64_t iter_R_39103 = add64(start_39100, min_res_39102);
        bool empty_slice_39104 = min_res_39102 == (int64_t) 0;
        int64_t m_39105 = sub64(min_res_39102, (int64_t) 1);
        int64_t i_p_m_t_s_39106 = add64(start_39100, m_39105);
        bool zzero_leq_i_p_m_t_s_39107 = sle64((int64_t) 0, i_p_m_t_s_39106);
        bool i_p_m_t_s_leq_w_39108 = slt64(i_p_m_t_s_39106, nR_34519);
        bool zzero_lte_i_39109 = sle64((int64_t) 0, start_39100);
        bool i_lte_j_39110 = sle64(start_39100, iter_R_39103);
        bool y_39111 = i_p_m_t_s_leq_w_39108 && zzero_lte_i_39109;
        bool y_39112 = zzero_leq_i_p_m_t_s_39107 && y_39111;
        bool forwards_ok_39113 = i_lte_j_39110 && y_39112;
        bool ok_or_empty_39114 = empty_slice_39104 || forwards_ok_39113;
        bool index_certs_39115;
        
        if (!ok_or_empty_39114) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) start_39100, ":", (long long) iter_R_39103, "] out of bounds for array of shape [", (long long) nR_34519, "].", "-> #0  ftSMJ.fut:55:20-49\n   #1  ftSMJ.fut:327:87-89\n   #2  ftSMJ.fut:404:133-136\n   #3  ftSMJ.fut:393:1-404:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        bool y_39121 = slt64(m_39105, min_res_39102);
        bool x_39120 = sle64((int64_t) 0, m_39105);
        bool bounds_check_39122 = x_39120 && y_39121;
        bool index_certs_39123;
        
        if (!bounds_check_39122) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) m_39105, "] out of bounds for array of shape [", (long long) min_res_39102, "].", "-> #0  ftSMJ.fut:58:21-40\n   #1  ftSMJ.fut:327:87-89\n   #2  ftSMJ.fut:404:133-136\n   #3  ftSMJ.fut:393:1-404:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        bool y_39117 = slt64((int64_t) 0, min_res_39102);
        bool index_certs_39118;
        
        if (!y_39117) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) (int64_t) 0, "] out of bounds for array of shape [", (long long) min_res_39102, "].", "-> #0  ftSMJ.fut:57:21-30\n   #1  ftSMJ.fut:327:87-89\n   #2  ftSMJ.fut:404:133-136\n   #3  ftSMJ.fut:393:1-404:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_doublezigpuseq_42772(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, start_39100, i_p_m_t_s_39106, tR_mem_42199.mem, mem_42218.mem, mem_42219.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (cond_39077) {
            if (memblock_set_device(ctx, &ext_mem_42220, &ext_mem_42211, "ext_mem_42211") != 0)
                return 1;
        } else if (memblock_set_device(ctx, &ext_mem_42220, &mem_42218, "mem_42218") != 0)
            return 1;
        if (cond_39077) {
            if (memblock_set_device(ctx, &ext_mem_42221, &ext_mem_42208, "ext_mem_42208") != 0)
                return 1;
        } else if (memblock_set_device(ctx, &ext_mem_42221, &mem_42219, "mem_42219") != 0)
            return 1;
        {
            err = gpu_kernel_inner_SMJ_doublezigpuseq_42778(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, mem_42219.mem, ext_mem_42220.mem, mem_42222.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_unref_device(ctx, &ext_mem_42220, "ext_mem_42220") != 0)
            return 1;
        
        bool read_res_43290;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_43290, mem_42222.mem, (int64_t) 0 * sizeof(bool), sizeof(bool))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        bool defunc_0_gt_res_39127 = read_res_43290;
        int64_t ext_42363;
        int64_t ext_42362;
        int64_t ext_42360;
        int64_t ext_42359;
        int64_t loopres_39128;
        
        if (defunc_0_gt_res_39127) {
            if (memblock_set_device(ctx, &ext_mem_42364, &mem_param_42214, "mem_param_42214") != 0)
                return 1;
            ext_42363 = ctx_param_ext_42212;
            ext_42362 = ctx_param_ext_42213;
            if (memblock_set_device(ctx, &ext_mem_42361, &mem_param_42217, "mem_param_42217") != 0)
                return 1;
            ext_42360 = ctx_param_ext_42215;
            ext_42359 = ctx_param_ext_42216;
            loopres_39128 = numIter_39072;
        } else {
            if (memblock_alloc_device(ctx, &mem_42223, (int64_t) 1, "mem_42223")) {
                err = 1;
                goto cleanup;
            }
            {
                err = gpu_kernel_inner_SMJ_doublezigpuseq_42784(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, mem_42218.mem, ext_mem_42221.mem, mem_42223.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            
            bool read_res_43291;
            
            if ((err = gpu_scalar_from_device(ctx, &read_res_43291, mem_42223.mem, (int64_t) 0 * sizeof(bool), sizeof(bool))) != 0)
                goto cleanup;
            if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                err = 1;
                goto cleanup;
            }
            
            bool defunc_0_gt_res_39131 = read_res_43291;
            
            if (memblock_unref_device(ctx, &mem_42223, "mem_42223") != 0)
                return 1;
            
            int64_t ext_42357;
            
            if (defunc_0_gt_res_39131) {
                ext_42357 = ctx_param_ext_42212;
            } else {
                ext_42357 = (int64_t) 0;
            }
            
            int64_t ext_42356;
            
            if (defunc_0_gt_res_39131) {
                ext_42356 = ctx_param_ext_42213;
            } else {
                ext_42356 = (int64_t) 1;
            }
            
            int64_t ext_42354;
            
            if (defunc_0_gt_res_39131) {
                ext_42354 = ctx_param_ext_42215;
            } else {
                ext_42354 = (int64_t) 0;
            }
            
            int64_t ext_42353;
            
            if (defunc_0_gt_res_39131) {
                ext_42353 = ctx_param_ext_42216;
            } else {
                ext_42353 = (int64_t) 1;
            }
            
            int64_t loopres_f_res_39132;
            
            if (defunc_0_gt_res_39131) {
                int64_t tmp_39506 = add64((int64_t) 1, p_39097);
                
                if (memblock_set_device(ctx, &ext_mem_42358, &mem_param_42214, "mem_param_42214") != 0)
                    return 1;
                if (memblock_set_device(ctx, &ext_mem_42355, &mem_param_42217, "mem_param_42217") != 0)
                    return 1;
                loopres_f_res_39132 = tmp_39506;
            } else {
                if (futrts_indicesWithIncrement_9920(ctx, &ext_mem_42224, tS_mem_42200, nS_34520, offset_S_34524) != 0) {
                    err = 1;
                    goto cleanup;
                }
                
                bool suff_outer_par_41157;
                
                suff_outer_par_41157 = *ctx->tuning_params.inner_SMJ_doublezisuff_outer_par_0 <= min_res_39102;
                if (ctx->logging)
                    fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "inner_SMJ_double.suff_outer_par_0", (long) min_res_39102, suff_outer_par_41157 ? "true" : "false");
                
                int64_t tile_sizze_41780;
                
                tile_sizze_41780 = *ctx->tuning_params.inner_SMJ_doublezitile_sizze_41779;
                
                int64_t tile_sizze_41425;
                
                tile_sizze_41425 = *ctx->tuning_params.inner_SMJ_doublezitile_sizze_41424;
                
                int64_t num_whole_tiles_41796 = squot_safe64(nS_34520, tile_sizze_41780);
                int64_t residual_input_42020 = srem_safe64(nS_34520, tile_sizze_41780);
                bool cond_42021 = residual_input_42020 == (int64_t) 0;
                int64_t binop_x_42037 = tile_sizze_41780 * num_whole_tiles_41796;
                int64_t bytes_42282 = (int64_t) 8 * min_res_39102;
                int64_t bytes_42245 = (int64_t) 8 * tile_sizze_41780;
                int64_t num_whole_tiles_41441 = squot_safe64(nS_34520, tile_sizze_41425);
                int64_t residual_input_41665 = srem_safe64(nS_34520, tile_sizze_41425);
                bool cond_41666 = residual_input_41665 == (int64_t) 0;
                int64_t binop_x_41682 = tile_sizze_41425 * num_whole_tiles_41441;
                int64_t bytes_42306 = (int64_t) 8 * tile_sizze_41425;
                int64_t shared_memory_capacity_42842;
                
                shared_memory_capacity_42842 = ctx->max_shared_memory;
                if (suff_outer_par_41157 && sle64(sdiv_up64(bytes_42306, (int64_t) 8) * (int64_t) 8 + sdiv_up64(bytes_42306, (int64_t) 8) * (int64_t) 8 + sdiv_up64(bytes_42306, (int64_t) 8) * (int64_t) 8, shared_memory_capacity_42842)) {
                    int64_t ldim_41426 = sdiv_up64(min_res_39102, tile_sizze_41425);
                    
                    if (memblock_alloc_device(ctx, &mem_42344, bytes_42282, "mem_42344")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &mem_42346, bytes_42282, "mem_42346")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t num_chunks_42790 = sext_i64_i32(sdiv_up64(tile_sizze_41425, tile_sizze_41425));
                    int32_t virt_num_tblocks_42791 = sext_i64_i32(ldim_41426);
                    
                    {
                        err = gpu_kernel_inner_SMJ_doublezisegmap_intrablock_41423(ctx, ldim_41426, 1, 1, *ctx->tuning_params.inner_SMJ_doublezitile_sizze_41424, 1, 1, bytes_42306 + srem64((int64_t) 8 - srem64(bytes_42306, (int64_t) 8), (int64_t) 8) + (bytes_42306 + srem64((int64_t) 8 - srem64(bytes_42306, (int64_t) 8), (int64_t) 8)) + (bytes_42306 + srem64((int64_t) 8 - srem64(bytes_42306, (int64_t) 8), (int64_t) 8)), nS_34520, start_39100, min_res_39102, ldim_41426, num_whole_tiles_41441, residual_input_41665, cond_41666, binop_x_41682, tR_mem_42199.mem, tS_mem_42200.mem, ext_mem_42224.mem, mem_42344.mem, mem_42346.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_set_device(ctx, &ext_mem_42348, &mem_42344, "mem_42344") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &ext_mem_42347, &mem_42346, "mem_42346") != 0)
                        return 1;
                } else {
                    int64_t ldim_41781 = sdiv_up64(min_res_39102, tile_sizze_41780);
                    
                    if (memblock_alloc_device(ctx, &mem_42283, bytes_42282, "mem_42283")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &mem_42285, bytes_42282, "mem_42285")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t num_chunks_42816 = sext_i64_i32(sdiv_up64(tile_sizze_41780, tile_sizze_41780));
                    int32_t virt_num_tblocks_42817 = sext_i64_i32(ldim_41781);
                    
                    {
                        err = gpu_kernel_inner_SMJ_doublezisegmap_intrablock_41778(ctx, ldim_41781, 1, 1, *ctx->tuning_params.inner_SMJ_doublezitile_sizze_41779, 1, 1, bytes_42245 + srem64((int64_t) 8 - srem64(bytes_42245, (int64_t) 8), (int64_t) 8) + (bytes_42245 + srem64((int64_t) 8 - srem64(bytes_42245, (int64_t) 8), (int64_t) 8)) + (bytes_42245 + srem64((int64_t) 8 - srem64(bytes_42245, (int64_t) 8), (int64_t) 8)), nS_34520, start_39100, min_res_39102, ldim_41781, num_whole_tiles_41796, residual_input_42020, cond_42021, binop_x_42037, tR_mem_42199.mem, tS_mem_42200.mem, ext_mem_42224.mem, mem_42283.mem, mem_42285.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_set_device(ctx, &ext_mem_42348, &mem_42283, "mem_42283") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &ext_mem_42347, &mem_42285, "mem_42285") != 0)
                        return 1;
                }
                if (memblock_unref_device(ctx, &ext_mem_42224, "ext_mem_42224") != 0)
                    return 1;
                if (memblock_alloc_device(ctx, &mem_42350, bytes_42202, "mem_42350")) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42350.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_42217.mem, ctx_param_ext_42215, (int64_t []) {ctx_param_ext_42216}, (int64_t []) {nR_34519})) != 0)
                    goto cleanup;
                if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42350.mem, start_39100, (int64_t []) {(int64_t) 1}, ext_mem_42348.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {min_res_39102})) != 0)
                    goto cleanup;
                if (memblock_unref_device(ctx, &ext_mem_42348, "ext_mem_42348") != 0)
                    return 1;
                if (memblock_alloc_device(ctx, &mem_42352, bytes_42202, "mem_42352")) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42352.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_42214.mem, ctx_param_ext_42212, (int64_t []) {ctx_param_ext_42213}, (int64_t []) {nR_34519})) != 0)
                    goto cleanup;
                if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42352.mem, start_39100, (int64_t []) {(int64_t) 1}, ext_mem_42347.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {min_res_39102})) != 0)
                    goto cleanup;
                if (memblock_unref_device(ctx, &ext_mem_42347, "ext_mem_42347") != 0)
                    return 1;
                
                int64_t tmp_39179 = add64((int64_t) 1, p_39097);
                
                if (memblock_set_device(ctx, &ext_mem_42358, &mem_42352, "mem_42352") != 0)
                    return 1;
                if (memblock_set_device(ctx, &ext_mem_42355, &mem_42350, "mem_42350") != 0)
                    return 1;
                loopres_f_res_39132 = tmp_39179;
            }
            if (memblock_set_device(ctx, &ext_mem_42364, &ext_mem_42358, "ext_mem_42358") != 0)
                return 1;
            ext_42363 = ext_42357;
            ext_42362 = ext_42356;
            if (memblock_set_device(ctx, &ext_mem_42361, &ext_mem_42355, "ext_mem_42355") != 0)
                return 1;
            ext_42360 = ext_42354;
            ext_42359 = ext_42353;
            loopres_39128 = loopres_f_res_39132;
        }
        if (memblock_unref_device(ctx, &ext_mem_42221, "ext_mem_42221") != 0)
            return 1;
        
        bool loop_cond_39180 = slt64(loopres_39128, numIter_39072);
        
        if (memblock_set_device(ctx, &mem_param_tmp_42762, &ext_mem_42364, "ext_mem_42364") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_42763, &ext_mem_42361, "ext_mem_42361") != 0)
            return 1;
        
        int64_t ctx_param_ext_tmp_42764 = ext_42363;
        int64_t ctx_param_ext_tmp_42765 = ext_42362;
        int64_t ctx_param_ext_tmp_42766 = ext_42360;
        int64_t ctx_param_ext_tmp_42767 = ext_42359;
        bool loop_while_tmp_42768 = loop_cond_39180;
        int64_t p_tmp_42769 = loopres_39128;
        
        if (memblock_set_device(ctx, &mem_param_42214, &mem_param_tmp_42762, "mem_param_tmp_42762") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_42217, &mem_param_tmp_42763, "mem_param_tmp_42763") != 0)
            return 1;
        ctx_param_ext_42212 = ctx_param_ext_tmp_42764;
        ctx_param_ext_42213 = ctx_param_ext_tmp_42765;
        ctx_param_ext_42215 = ctx_param_ext_tmp_42766;
        ctx_param_ext_42216 = ctx_param_ext_tmp_42767;
        loop_while_39096 = loop_while_tmp_42768;
        p_39097 = p_tmp_42769;
    }
    if (memblock_set_device(ctx, &ext_mem_42370, &mem_param_42214, "mem_param_42214") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_42369, &mem_param_42217, "mem_param_42217") != 0)
        return 1;
    ext_42368 = ctx_param_ext_42212;
    ext_42367 = ctx_param_ext_42213;
    ext_42366 = ctx_param_ext_42215;
    ext_42365 = ctx_param_ext_42216;
    defunc_0_find_joinTuples_res_39092 = loop_while_39096;
    defunc_0_find_joinTuples_res_39093 = p_39097;
    if (memblock_unref_device(ctx, &mem_42203, "mem_42203") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42205, "mem_42205") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_42208, "ext_mem_42208") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_42211, "ext_mem_42211") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42218, "mem_42218") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42219, "mem_42219") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42222, "mem_42222") != 0)
        return 1;
    
    int64_t segscan_tblock_sizze_41334;
    
    segscan_tblock_sizze_41334 = *ctx->tuning_params.inner_SMJ_doublezisegscan_tblock_sizze_41333;
    
    int64_t num_tblocks_41336;
    int64_t max_num_tblocks_42843;
    
    max_num_tblocks_42843 = *ctx->tuning_params.inner_SMJ_doublezisegscan_num_tblocks_41335;
    num_tblocks_41336 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nR_34519, segscan_tblock_sizze_41334), max_num_tblocks_42843)));
    if (memblock_alloc_device(ctx, &mem_42373, bytes_42202, "mem_42373")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42375, bytes_42202, "mem_42375")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, nR_34519)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_42844;
        
        shared_memory_42844 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_42845;
        
        thread_block_sizze_42845 = ctx->max_thread_block_size;
        
        int64_t registers_42846;
        
        registers_42846 = ctx->max_registers;
        
        int64_t thread_block_sizze_42847;
        
        thread_block_sizze_42847 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_42848 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_42844, thread_block_sizze_42845), (int64_t) 8), squot64(squot64(registers_42846, thread_block_sizze_42847) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
        int64_t num_virt_blocks_42849 = sdiv_up64(nR_34519, segscan_tblock_sizze_41334 * chunk_sizze_42848);
        int64_t num_virt_threads_42850 = num_virt_blocks_42849 * segscan_tblock_sizze_41334;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_42848, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_42851, num_virt_blocks_42849, "status_flags_mem_42851")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_42851, num_virt_blocks_42849, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_42873, (int64_t) 8 * num_virt_blocks_42849, "aggregates_mem_42873")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_42875, (int64_t) 8 * num_virt_blocks_42849, "incprefixes_mem_42875")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_doublezisegscan_41339(ctx, num_tblocks_41336, 1, 1, *ctx->tuning_params.inner_SMJ_doublezisegscan_tblock_sizze_41333, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_41334), chunk_sizze_42848 * segscan_tblock_sizze_41334 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_41334), chunk_sizze_42848 * segscan_tblock_sizze_41334 * (int64_t) 8), (int64_t) 8), (int64_t) 8), nR_34519, num_tblocks_41336, ext_42367, ext_42368, num_virt_blocks_42849, num_virt_threads_42850, ext_mem_42370.mem, mem_42373.mem, mem_42375.mem, status_flags_mem_42851.mem, aggregates_mem_42873.mem, incprefixes_mem_42875.mem, global_dynid_mem_42877.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    
    bool cond_39190 = nR_34519 == (int64_t) 0;
    bool x_39191 = !cond_39190;
    int64_t tmp_39192 = sub64(nR_34519, (int64_t) 1);
    bool x_39193 = sle64((int64_t) 0, tmp_39192);
    bool y_39194 = slt64(tmp_39192, nR_34519);
    bool bounds_check_39195 = x_39193 && y_39194;
    bool protect_assert_disj_39196 = cond_39190 || bounds_check_39195;
    bool index_certs_39197;
    
    if (!protect_assert_disj_39196) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) tmp_39192, "] out of bounds for array of shape [", (long long) nR_34519, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:327:7-328:73\n   #3  ftSMJ.fut:404:133-136\n   #4  ftSMJ.fut:393:1-404:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t m_f_res_39198;
    
    if (x_39191) {
        int64_t read_res_43292;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_43292, mem_42373.mem, tmp_39192 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_39513 = read_res_43292;
        
        m_f_res_39198 = x_39513;
    } else {
        m_f_res_39198 = (int64_t) 0;
    }
    
    int64_t m_39200;
    
    if (cond_39190) {
        m_39200 = (int64_t) 0;
    } else {
        m_39200 = m_f_res_39198;
    }
    
    int64_t m_39210 = sub64(m_39200, (int64_t) 1);
    bool i_p_m_t_s_leq_w_39212 = slt64(m_39210, nR_34519);
    bool zzero_leq_i_p_m_t_s_39211 = sle64((int64_t) 0, m_39210);
    bool y_39214 = zzero_leq_i_p_m_t_s_39211 && i_p_m_t_s_leq_w_39212;
    bool i_lte_j_39213 = sle64((int64_t) 0, m_39200);
    bool forwards_ok_39215 = i_lte_j_39213 && y_39214;
    bool eq_x_zz_39207 = (int64_t) 0 == m_f_res_39198;
    bool p_and_eq_x_y_39208 = x_39191 && eq_x_zz_39207;
    bool empty_slice_39209 = cond_39190 || p_and_eq_x_y_39208;
    bool ok_or_empty_39216 = empty_slice_39209 || forwards_ok_39215;
    bool index_certs_39217;
    
    if (!ok_or_empty_39216) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_39200, "] out of bounds for array of shape [", (long long) nR_34519, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:327:7-328:73\n   #3  ftSMJ.fut:404:133-136\n   #4  ftSMJ.fut:393:1-404:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_42376 = (int64_t) 8 * m_39200;
    
    if (memblock_alloc_device(ctx, &mem_42377, bytes_42376, "mem_42377")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42377.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42370.mem, ext_42368, (int64_t []) {ext_42367}, (int64_t []) {m_39200})) != 0)
        goto cleanup;
    if (memblock_alloc_device(ctx, &mem_42379, bytes_42376, "mem_42379")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42379.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42369.mem, ext_42366, (int64_t []) {ext_42365}, (int64_t []) {m_39200})) != 0)
        goto cleanup;
    if (memblock_alloc_device(ctx, &mem_42381, bytes_42376, "mem_42381")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42381.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42201.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_39200})) != 0)
        goto cleanup;
    if (memblock_alloc_device(ctx, &mem_42383, bytes_42376, "mem_42383")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42383.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, tR_mem_42199.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_39200})) != 0)
        goto cleanup;
    
    int64_t segmap_tblock_sizze_41344;
    
    segmap_tblock_sizze_41344 = *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_41343;
    
    int64_t num_tblocks_41346;
    int64_t max_num_tblocks_42986;
    
    max_num_tblocks_42986 = *ctx->tuning_params.inner_SMJ_doublezisegmap_num_tblocks_41345;
    num_tblocks_41346 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nR_34519, segmap_tblock_sizze_41344), max_num_tblocks_42986)));
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_42987 = sext_i64_i32(sdiv_up64(nR_34519, segmap_tblock_sizze_41344));
    
    {
        err = gpu_kernel_inner_SMJ_doublezisegmap_41341(ctx, num_tblocks_41346, 1, 1, *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_41343, 1, 1, (int64_t) 0, nR_34519, m_39200, num_tblocks_41346, ext_42365, ext_42366, ext_42367, ext_42368, virt_num_tblocks_42987, tR_mem_42199.mem, ext_mem_42201.mem, ext_mem_42369.mem, ext_mem_42370.mem, mem_42373.mem, mem_42375.mem, mem_42377.mem, mem_42379.mem, mem_42381.mem, mem_42383.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &ext_mem_42201, "ext_mem_42201") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_42369, "ext_mem_42369") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_42370, "ext_mem_42370") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42373, "mem_42373") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42375, "mem_42375") != 0)
        return 1;
    
    int64_t segscan_tblock_sizze_41350;
    
    segscan_tblock_sizze_41350 = *ctx->tuning_params.inner_SMJ_doublezisegscan_tblock_sizze_41349;
    
    int64_t num_tblocks_41352;
    int64_t max_num_tblocks_43000;
    
    max_num_tblocks_43000 = *ctx->tuning_params.inner_SMJ_doublezisegscan_num_tblocks_41351;
    num_tblocks_41352 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_39200, segscan_tblock_sizze_41350), max_num_tblocks_43000)));
    if (memblock_alloc_device(ctx, &mem_42387, bytes_42376, "mem_42387")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42389, bytes_42376, "mem_42389")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42391, bytes_42376, "mem_42391")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, m_39200)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_43001;
        
        shared_memory_43001 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_43002;
        
        thread_block_sizze_43002 = ctx->max_thread_block_size;
        
        int64_t registers_43003;
        
        registers_43003 = ctx->max_registers;
        
        int64_t thread_block_sizze_43004;
        
        thread_block_sizze_43004 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_43005 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_43001, thread_block_sizze_43002), (int64_t) 8), squot64(squot64(registers_43003, thread_block_sizze_43004) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
        int64_t num_virt_blocks_43006 = sdiv_up64(m_39200, segscan_tblock_sizze_41350 * chunk_sizze_43005);
        int64_t num_virt_threads_43007 = num_virt_blocks_43006 * segscan_tblock_sizze_41350;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_43005, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_43008, num_virt_blocks_43006, "status_flags_mem_43008")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_43008, num_virt_blocks_43006, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_43010, (int64_t) 8 * num_virt_blocks_43006, "aggregates_mem_43010")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_43012, (int64_t) 8 * num_virt_blocks_43006, "incprefixes_mem_43012")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_43014, (int64_t) 8 * num_virt_blocks_43006, "aggregates_mem_43014")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_43016, (int64_t) 8 * num_virt_blocks_43006, "incprefixes_mem_43016")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_doublezisegscan_41355(ctx, num_tblocks_41352, 1, 1, *ctx->tuning_params.inner_SMJ_doublezisegscan_tblock_sizze_41349, 1, 1, smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_41350, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_41350), smax64(chunk_sizze_43005 * segscan_tblock_sizze_41350 * (int64_t) 8, chunk_sizze_43005 * segscan_tblock_sizze_41350 * (int64_t) 8)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_41350, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_41350), smax64(chunk_sizze_43005 * segscan_tblock_sizze_41350 * (int64_t) 8, chunk_sizze_43005 * segscan_tblock_sizze_41350 * (int64_t) 8)), (int64_t) 8), (int64_t) 8), m_39200, num_tblocks_41352, num_virt_blocks_43006, num_virt_threads_43007, mem_42377.mem, mem_42387.mem, mem_42389.mem, mem_42391.mem, status_flags_mem_43008.mem, aggregates_mem_43010.mem, incprefixes_mem_43012.mem, aggregates_mem_43014.mem, incprefixes_mem_43016.mem, global_dynid_mem_43018.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    
    int64_t segmap_tblock_sizze_41371;
    
    segmap_tblock_sizze_41371 = *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_41359;
    
    int64_t segmap_usable_groups_41372 = sdiv_up64(m_39200, segmap_tblock_sizze_41371);
    
    if (memblock_alloc_device(ctx, &mem_42394, bytes_42376, "mem_42394")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_43153 = sext_i64_i32(sdiv_up64(m_39200, segmap_tblock_sizze_41371));
    
    {
        err = gpu_kernel_inner_SMJ_doublezisegmap_41375(ctx, segmap_usable_groups_41372, 1, 1, *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_41359, 1, 1, (int64_t) 0, m_39200, mem_42387.mem, mem_42394.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_42387, "mem_42387") != 0)
        return 1;
    
    bool cond_39251 = slt64((int64_t) 0, m_39200);
    bool y_39252 = slt64(m_39210, m_39200);
    bool bounds_check_39253 = zzero_leq_i_p_m_t_s_39211 && y_39252;
    bool loop_not_taken_39254 = !cond_39251;
    bool protect_assert_disj_39255 = bounds_check_39253 || loop_not_taken_39254;
    bool index_certs_39256;
    
    if (!protect_assert_disj_39255) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) m_39210, "] out of bounds for array of shape [", (long long) m_39200, "].", "-> #0  ftSMJ.fut:285:10-41\n   #1  ftSMJ.fut:327:7-328:73\n   #2  ftSMJ.fut:404:133-136\n   #3  ftSMJ.fut:393:1-404:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    if (cond_39251) {
        if (memblock_alloc_device(ctx, &mem_42396, (int64_t) 8, "mem_42396")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_doublezigpuseq_43162(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, m_39210, mem_42394.mem, mem_42396.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42397, &mem_42396, "mem_42396") != 0)
            return 1;
    } else {
        if (memblock_alloc_device(ctx, &mem_42395, (int64_t) 8, "mem_42395")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i64(ctx, mem_42395, (int64_t) 1, (int64_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42397, &mem_42395, "mem_42395") != 0)
            return 1;
    }
    if (cond_39251) {
        if (memblock_alloc_device(ctx, &mem_42399, (int64_t) 8, "mem_42399")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_doublezigpuseq_43168(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, m_39210, mem_42377.mem, mem_42399.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42400, &mem_42399, "mem_42399") != 0)
            return 1;
    } else {
        if (memblock_alloc_device(ctx, &mem_42398, (int64_t) 8, "mem_42398")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i64(ctx, mem_42398, (int64_t) 1, (int64_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42400, &mem_42398, "mem_42398") != 0)
            return 1;
    }
    
    bool zzero_39268 = scatter_psizze_34528 == (int64_t) 0;
    bool nonzzero_39269 = !zzero_39268;
    bool nonzzero_cert_39270;
    
    if (!nonzzero_39269) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftbasics.fut:66:23-29\n   #1  ftSMJ.fut:327:7-328:73\n   #2  ftSMJ.fut:404:133-136\n   #3  ftSMJ.fut:393:1-404:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    bool x_39335 = !empty_slice_39209;
    bool protect_assert_disj_39336 = empty_slice_39209 || bounds_check_39253;
    bool index_certs_39337;
    
    if (!protect_assert_disj_39336) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) m_39210, "] out of bounds for array of shape [", (long long) m_39200, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:327:7-328:73\n   #3  ftSMJ.fut:404:133-136\n   #4  ftSMJ.fut:393:1-404:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t m_f_res_39338;
    
    if (x_39335) {
        int64_t read_res_43293;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_43293, mem_42389.mem, m_39210 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_39521 = read_res_43293;
        
        m_f_res_39338 = x_39521;
    } else {
        m_f_res_39338 = (int64_t) 0;
    }
    
    int64_t m_39340;
    
    if (empty_slice_39209) {
        m_39340 = (int64_t) 0;
    } else {
        m_39340 = m_f_res_39338;
    }
    
    int64_t m_39350 = sub64(m_39340, (int64_t) 1);
    bool i_p_m_t_s_leq_w_39352 = slt64(m_39350, m_39200);
    bool zzero_leq_i_p_m_t_s_39351 = sle64((int64_t) 0, m_39350);
    bool y_39354 = zzero_leq_i_p_m_t_s_39351 && i_p_m_t_s_leq_w_39352;
    bool i_lte_j_39353 = sle64((int64_t) 0, m_39340);
    bool forwards_ok_39355 = i_lte_j_39353 && y_39354;
    bool eq_x_zz_39347 = (int64_t) 0 == m_f_res_39338;
    bool p_and_eq_x_y_39348 = x_39335 && eq_x_zz_39347;
    bool empty_slice_39349 = empty_slice_39209 || p_and_eq_x_y_39348;
    bool ok_or_empty_39356 = empty_slice_39349 || forwards_ok_39355;
    bool index_certs_39357;
    
    if (!ok_or_empty_39356) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_39340, "] out of bounds for array of shape [", (long long) m_39200, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:327:7-328:73\n   #3  ftSMJ.fut:404:133-136\n   #4  ftSMJ.fut:393:1-404:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_42401 = (int64_t) 8 * m_39340;
    
    if (memblock_alloc_device(ctx, &mem_42406, (int64_t) 8, "mem_42406")) {
        err = 1;
        goto cleanup;
    }
    {
        err = gpu_kernel_inner_SMJ_doublezigpuseq_43174(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, ext_mem_42397.mem, ext_mem_42400.mem, mem_42406.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (memblock_unref_device(ctx, &ext_mem_42397, "ext_mem_42397") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_42400, "ext_mem_42400") != 0)
        return 1;
    
    int64_t n_pairs_t_res_39261;
    
    if (cond_39251) {
        int64_t read_res_43294;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_43294, mem_42406.mem, (int64_t) 0 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_42197 = read_res_43294;
        
        n_pairs_t_res_39261 = x_42197;
    } else {
        n_pairs_t_res_39261 = (int64_t) 0;
    }
    if (memblock_unref_device(ctx, &mem_42406, "mem_42406") != 0)
        return 1;
    
    int64_t n_pairs_39262;
    
    if (cond_39251) {
        n_pairs_39262 = n_pairs_t_res_39261;
    } else {
        n_pairs_39262 = (int64_t) 0;
    }
    
    int64_t bytes_42407 = (int64_t) 8 * n_pairs_39262;
    int64_t segmap_tblock_sizze_41386;
    
    segmap_tblock_sizze_41386 = *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_41385;
    
    int64_t num_tblocks_41388;
    int64_t max_num_tblocks_43180;
    
    max_num_tblocks_43180 = *ctx->tuning_params.inner_SMJ_doublezisegmap_num_tblocks_41387;
    num_tblocks_41388 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_39200, segmap_tblock_sizze_41386), max_num_tblocks_43180)));
    if (memblock_alloc_device(ctx, &mem_42402, bytes_42401, "mem_42402")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42402.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_42377.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_39340})) != 0)
        goto cleanup;
    if (memblock_alloc_device(ctx, &mem_42404, bytes_42401, "mem_42404")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42404.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_42394.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_39340})) != 0)
        goto cleanup;
    
    int64_t segmap_tblock_sizze_41394;
    
    segmap_tblock_sizze_41394 = *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_41393;
    
    int64_t num_tblocks_41396;
    int64_t max_num_tblocks_43181;
    
    max_num_tblocks_43181 = *ctx->tuning_params.inner_SMJ_doublezisegmap_num_tblocks_41395;
    num_tblocks_41396 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_39200, segmap_tblock_sizze_41394), max_num_tblocks_43181)));
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_43182 = sext_i64_i32(sdiv_up64(m_39200, segmap_tblock_sizze_41394));
    
    {
        err = gpu_kernel_inner_SMJ_doublezisegmap_41391(ctx, num_tblocks_41396, 1, 1, *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_41393, 1, 1, (int64_t) 0, m_39200, m_39340, num_tblocks_41396, virt_num_tblocks_43182, mem_42377.mem, mem_42389.mem, mem_42391.mem, mem_42394.mem, mem_42402.mem, mem_42404.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_42377, "mem_42377") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42389, "mem_42389") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42391, "mem_42391") != 0)
        return 1;
    
    bool cond_39367 = slt64((int64_t) 0, m_39340);
    int64_t segmap_tblock_sizze_41409;
    
    segmap_tblock_sizze_41409 = *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_41401;
    if (memblock_alloc_device(ctx, &mem_42408, bytes_42407, "mem_42408")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_f64(ctx, mem_42408, n_pairs_39262, 0.0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42410, bytes_42407, "mem_42410")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_42410, n_pairs_39262, (int64_t) -1) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42412, bytes_42407, "mem_42412")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_42412, n_pairs_39262, (int64_t) -1) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t zm_lhs_39266 = add64(scatter_psizze_34528, n_pairs_39262);
    int64_t zs_lhs_39267 = sub64(zm_lhs_39266, (int64_t) 1);
    int64_t m_39271 = sdiv64(zs_lhs_39267, scatter_psizze_34528);
    bool loop_cond_39272 = slt64((int64_t) 0, m_39271);
    bool partitioned_scatter_res_39273;
    int64_t partitioned_scatter_res_39277;
    bool loop_while_39278;
    int64_t p_39282;
    
    loop_while_39278 = loop_cond_39272;
    p_39282 = (int64_t) 0;
    while (loop_while_39278) {
        int64_t lower_bound_39283 = mul64(scatter_psizze_34528, p_39282);
        int64_t min_arg1_39284 = add64(scatter_psizze_34528, lower_bound_39283);
        int64_t min_res_39285 = smin64(n_pairs_39262, min_arg1_39284);
        int64_t j_m_i_39286 = sub64(min_res_39285, lower_bound_39283);
        bool empty_slice_39287 = j_m_i_39286 == (int64_t) 0;
        int64_t m_39288 = sub64(j_m_i_39286, (int64_t) 1);
        int64_t i_p_m_t_s_39289 = add64(lower_bound_39283, m_39288);
        bool zzero_leq_i_p_m_t_s_39290 = sle64((int64_t) 0, i_p_m_t_s_39289);
        bool i_p_m_t_s_leq_w_39291 = slt64(i_p_m_t_s_39289, n_pairs_39262);
        bool zzero_lte_i_39292 = sle64((int64_t) 0, lower_bound_39283);
        bool i_lte_j_39293 = sle64(lower_bound_39283, min_res_39285);
        bool y_39294 = i_p_m_t_s_leq_w_39291 && zzero_lte_i_39292;
        bool y_39295 = zzero_leq_i_p_m_t_s_39290 && y_39294;
        bool forwards_ok_39296 = i_lte_j_39293 && y_39295;
        bool ok_or_empty_39297 = empty_slice_39287 || forwards_ok_39296;
        bool index_certs_39298;
        
        if (!ok_or_empty_39297) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) lower_bound_39283, ":", (long long) min_res_39285, "] out of bounds for array of shape [", (long long) n_pairs_39262, "].", "-> #0  ftbasics.fut:72:25-56\n   #1  ftSMJ.fut:327:7-328:73\n   #2  ftSMJ.fut:404:133-136\n   #3  ftSMJ.fut:393:1-404:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t bytes_42422 = (int64_t) 8 * j_m_i_39286;
        
        if (memblock_alloc_device(ctx, &mem_42423, bytes_42422, "mem_42423")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42423.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_42408.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_39283, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_39286})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_42425, bytes_42422, "mem_42425")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42425.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_42410.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_39283, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_39286})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_42427, bytes_42422, "mem_42427")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42427.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_42412.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_39283, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_39286})) != 0)
            goto cleanup;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_43200 = sext_i64_i32(sdiv_up64(m_39200, segmap_tblock_sizze_41386));
        
        {
            err = gpu_kernel_inner_SMJ_doublezisegmap_41383(ctx, num_tblocks_41388, 1, 1, *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_41385, 1, 1, (int64_t) 0, m_39200, lower_bound_39283, min_res_39285, j_m_i_39286, num_tblocks_41388, virt_num_tblocks_43200, mem_42379.mem, mem_42381.mem, mem_42383.mem, mem_42394.mem, mem_42423.mem, mem_42425.mem, mem_42427.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t tmp_39312 = add64((int64_t) 1, p_39282);
        
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42408.mem, lower_bound_39283, (int64_t []) {(int64_t) 1}, mem_42423.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_39286})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_42423, "mem_42423") != 0)
            return 1;
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42410.mem, lower_bound_39283, (int64_t []) {(int64_t) 1}, mem_42425.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_39286})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_42425, "mem_42425") != 0)
            return 1;
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42412.mem, lower_bound_39283, (int64_t []) {(int64_t) 1}, mem_42427.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_39286})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_42427, "mem_42427") != 0)
            return 1;
        
        bool loop_cond_39323 = slt64(tmp_39312, m_39271);
        bool loop_while_tmp_43195 = loop_cond_39323;
        int64_t p_tmp_43199 = tmp_39312;
        
        loop_while_39278 = loop_while_tmp_43195;
        p_39282 = p_tmp_43199;
    }
    partitioned_scatter_res_39273 = loop_while_39278;
    partitioned_scatter_res_39277 = p_39282;
    if (memblock_unref_device(ctx, &mem_42379, "mem_42379") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42381, "mem_42381") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42383, "mem_42383") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42394, "mem_42394") != 0)
        return 1;
    
    bool loop_cond_t_res_39368 = slt64(m_39200, n_pairs_39262);
    bool x_39369 = cond_39367 && loop_cond_t_res_39368;
    
    if (memblock_alloc_device(ctx, &mem_42453, (int64_t) 8, "mem_42453")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42454, (int64_t) 8, "mem_42454")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42455, (int64_t) 8, "mem_42455")) {
        err = 1;
        goto cleanup;
    }
    
    bool joinTups_to_joinPairs_InnerJoin_res_39370;
    int64_t joinTups_to_joinPairs_InnerJoin_res_39374;
    bool loop_while_39375;
    int64_t p_39379;
    
    if (memblock_set_device(ctx, &mem_param_42440, &mem_42408, "mem_42408") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_42443, &mem_42410, "mem_42410") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_42446, &mem_42412, "mem_42412") != 0)
        return 1;
    loop_while_39375 = x_39369;
    p_39379 = (int64_t) 0;
    while (loop_while_39375) {
        bool x_39380 = sle64((int64_t) 0, p_39379);
        bool y_39381 = slt64(p_39379, m_39340);
        bool bounds_check_39382 = x_39380 && y_39381;
        bool index_certs_39383;
        
        if (!bounds_check_39382) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) p_39379, "] out of bounds for array of shape [", (long long) m_39340, "].", "-> #0  ftSMJ.fut:300:13-42\n   #1  ftSMJ.fut:327:7-328:73\n   #2  ftSMJ.fut:404:133-136\n   #3  ftSMJ.fut:393:1-404:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t read_res_43295;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_43295, mem_42404.mem, p_39379 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t loopres_39384 = read_res_43295;
        int64_t read_res_43296;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_43296, mem_42402.mem, p_39379 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t loopres_39385 = read_res_43296;
        bool x_39386 = sle64((int64_t) 0, loopres_39384);
        bool y_39387 = slt64(loopres_39384, n_pairs_39262);
        bool bounds_check_39388 = x_39386 && y_39387;
        bool index_certs_39389;
        
        if (!bounds_check_39388) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) loopres_39384, "] out of bounds for array of shape [", (long long) n_pairs_39262, "].", "-> #0  ftSMJ.fut:302:52-61\n   #1  ftSMJ.fut:327:7-328:73\n   #2  ftSMJ.fut:404:133-136\n   #3  ftSMJ.fut:393:1-404:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t tmp_39400 = add64(loopres_39384, loopres_39385);
        bool empty_slice_39404 = loopres_39385 == (int64_t) 0;
        int64_t m_39405 = sub64(loopres_39385, (int64_t) 1);
        int64_t i_p_m_t_s_39406 = add64(loopres_39384, m_39405);
        bool zzero_leq_i_p_m_t_s_39407 = sle64((int64_t) 0, i_p_m_t_s_39406);
        bool i_p_m_t_s_leq_w_39408 = slt64(i_p_m_t_s_39406, n_pairs_39262);
        bool i_lte_j_39409 = sle64(loopres_39384, tmp_39400);
        bool y_39410 = x_39386 && i_p_m_t_s_leq_w_39408;
        bool y_39411 = zzero_leq_i_p_m_t_s_39407 && y_39410;
        bool forwards_ok_39412 = i_lte_j_39409 && y_39411;
        bool ok_or_empty_39413 = empty_slice_39404 || forwards_ok_39412;
        bool index_certs_39414;
        
        if (!ok_or_empty_39413) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) loopres_39384, ":", (long long) tmp_39400, "] out of bounds for array of shape [", (long long) n_pairs_39262, "].", "-> #0  ftSMJ.fut:306:14-55\n   #1  ftSMJ.fut:327:7-328:73\n   #2  ftSMJ.fut:404:133-136\n   #3  ftSMJ.fut:393:1-404:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t bytes_42456 = (int64_t) 8 * loopres_39385;
        int64_t segmap_usable_groups_41410 = sdiv_up64(loopres_39385, segmap_tblock_sizze_41409);
        int64_t tmp_39399 = add64((int64_t) 1, p_39379);
        
        if (memblock_alloc_device(ctx, &mem_42448, bytes_42407, "mem_42448")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42448.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_42440.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_39262})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_42450, bytes_42407, "mem_42450")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42450.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_42443.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_39262})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_42452, bytes_42407, "mem_42452")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42452.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_42446.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_39262})) != 0)
            goto cleanup;
        
        bool cond_39418 = slt64(tmp_39399, m_39340);
        bool x_39419 = loop_cond_t_res_39368 && cond_39418;
        
        {
            err = gpu_kernel_inner_SMJ_doublezigpuseq_43221(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, loopres_39384, mem_param_42440.mem, mem_param_42443.mem, mem_param_42446.mem, mem_42453.mem, mem_42454.mem, mem_42455.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_42457, bytes_42456, "mem_42457")) {
            err = 1;
            goto cleanup;
        }
        
        int64_t replicate_n_43227 = loopres_39385;
        int64_t tblock_sizze_43232;
        
        tblock_sizze_43232 = *ctx->tuning_params.inner_SMJ_doublezitblock_sizze_43232;
        
        int64_t virt_num_tblocks_43233 = sdiv_up64(replicate_n_43227, tblock_sizze_43232);
        int64_t num_tblocks_43234 = smin64(virt_num_tblocks_43233, (int64_t) 1048576);
        
        {
            err = gpu_kernel_inner_SMJ_doublezireplicate_43228(ctx, num_tblocks_43234, 1, 1, tblock_sizze_43232, 1, 1, (int64_t) 0, loopres_39385, replicate_n_43227, virt_num_tblocks_43233, num_tblocks_43234, mem_42453.mem, mem_42457.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_42459, bytes_42456, "mem_42459")) {
            err = 1;
            goto cleanup;
        }
        
        int64_t replicate_n_43247 = loopres_39385;
        int64_t tblock_sizze_43252;
        
        tblock_sizze_43252 = *ctx->tuning_params.inner_SMJ_doublezitblock_sizze_43252;
        
        int64_t virt_num_tblocks_43253 = sdiv_up64(replicate_n_43247, tblock_sizze_43252);
        int64_t num_tblocks_43254 = smin64(virt_num_tblocks_43253, (int64_t) 1048576);
        
        {
            err = gpu_kernel_inner_SMJ_doublezireplicate_43248(ctx, num_tblocks_43254, 1, 1, tblock_sizze_43252, 1, 1, (int64_t) 0, loopres_39385, replicate_n_43247, virt_num_tblocks_43253, num_tblocks_43254, mem_42454.mem, mem_42459.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_43267 = sext_i64_i32(sdiv_up64(loopres_39385, segmap_tblock_sizze_41409));
        
        {
            err = gpu_kernel_inner_SMJ_doublezisegmap_41413(ctx, segmap_usable_groups_41410, 1, 1, *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_41401, 1, 1, (int64_t) 0, loopres_39384, loopres_39385, mem_42452.mem, mem_42455.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42448.mem, loopres_39384, (int64_t []) {(int64_t) 1}, mem_42457.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {loopres_39385})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_42457, "mem_42457") != 0)
            return 1;
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42450.mem, loopres_39384, (int64_t []) {(int64_t) 1}, mem_42459.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {loopres_39385})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_42459, "mem_42459") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_43213, &mem_42448, "mem_42448") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_43214, &mem_42450, "mem_42450") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_43215, &mem_42452, "mem_42452") != 0)
            return 1;
        
        bool loop_while_tmp_43216 = x_39419;
        int64_t p_tmp_43220 = tmp_39399;
        
        if (memblock_set_device(ctx, &mem_param_42440, &mem_param_tmp_43213, "mem_param_tmp_43213") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_42443, &mem_param_tmp_43214, "mem_param_tmp_43214") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_42446, &mem_param_tmp_43215, "mem_param_tmp_43215") != 0)
            return 1;
        loop_while_39375 = loop_while_tmp_43216;
        p_39379 = p_tmp_43220;
    }
    if (memblock_set_device(ctx, &ext_mem_42471, &mem_param_42440, "mem_param_42440") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_42470, &mem_param_42443, "mem_param_42443") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_42469, &mem_param_42446, "mem_param_42446") != 0)
        return 1;
    joinTups_to_joinPairs_InnerJoin_res_39370 = loop_while_39375;
    joinTups_to_joinPairs_InnerJoin_res_39374 = p_39379;
    if (memblock_unref_device(ctx, &mem_42402, "mem_42402") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42404, "mem_42404") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42408, "mem_42408") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42410, "mem_42410") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42412, "mem_42412") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42453, "mem_42453") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42454, "mem_42454") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42455, "mem_42455") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_42473, bytes_42407, "mem_42473")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42473.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42471.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_39262})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_42471, "ext_mem_42471") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_42475, bytes_42407, "mem_42475")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42475.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42470.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_39262})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_42470, "ext_mem_42470") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_42477, bytes_42407, "mem_42477")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42477.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42469.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_39262})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_42469, "ext_mem_42469") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_42706, &mem_42475, "mem_42475") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_42707, &mem_42477, "mem_42477") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_42708, &mem_42473, "mem_42473") != 0)
        return 1;
    prim_out_42709 = n_pairs_39262;
    if (memblock_set_device(ctx, &*mem_out_p_43286, &mem_out_42706, "mem_out_42706") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_43287, &mem_out_42707, "mem_out_42707") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_43288, &mem_out_42708, "mem_out_42708") != 0)
        return 1;
    *out_prim_out_43289 = prim_out_42709;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_42477, "mem_42477") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42475, "mem_42475") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42473, "mem_42473") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_43215, "mem_param_tmp_43215") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_43214, "mem_param_tmp_43214") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_43213, "mem_param_tmp_43213") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42459, "mem_42459") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42457, "mem_42457") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42452, "mem_42452") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42450, "mem_42450") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42448, "mem_42448") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42446, "mem_param_42446") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42443, "mem_param_42443") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42440, "mem_param_42440") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42469, "ext_mem_42469") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42470, "ext_mem_42470") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42471, "ext_mem_42471") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42455, "mem_42455") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42454, "mem_42454") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42453, "mem_42453") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42427, "mem_42427") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42425, "mem_42425") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42423, "mem_42423") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42412, "mem_42412") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42410, "mem_42410") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42408, "mem_42408") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42404, "mem_42404") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42402, "mem_42402") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42406, "mem_42406") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42398, "mem_42398") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42399, "mem_42399") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42400, "ext_mem_42400") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42395, "mem_42395") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42396, "mem_42396") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42397, "ext_mem_42397") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42394, "mem_42394") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_43016, "incprefixes_mem_43016") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_43014, "aggregates_mem_43014") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_43012, "incprefixes_mem_43012") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_43010, "aggregates_mem_43010") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_43008, "status_flags_mem_43008") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42391, "mem_42391") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42389, "mem_42389") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42387, "mem_42387") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42383, "mem_42383") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42381, "mem_42381") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42379, "mem_42379") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42377, "mem_42377") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_42875, "incprefixes_mem_42875") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_42873, "aggregates_mem_42873") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_42851, "status_flags_mem_42851") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42375, "mem_42375") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42373, "mem_42373") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_42763, "mem_param_tmp_42763") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_42762, "mem_param_tmp_42762") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42352, "mem_42352") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42350, "mem_42350") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42285, "mem_42285") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42283, "mem_42283") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42346, "mem_42346") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42344, "mem_42344") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42347, "ext_mem_42347") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42348, "ext_mem_42348") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42224, "ext_mem_42224") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42355, "ext_mem_42355") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42358, "ext_mem_42358") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42223, "mem_42223") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42361, "ext_mem_42361") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42364, "ext_mem_42364") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42221, "ext_mem_42221") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42220, "ext_mem_42220") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42217, "mem_param_42217") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42214, "mem_param_42214") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42369, "ext_mem_42369") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42370, "ext_mem_42370") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42222, "mem_42222") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42219, "mem_42219") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42218, "mem_42218") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42209, "mem_42209") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42210, "mem_42210") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42211, "ext_mem_42211") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42206, "mem_42206") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42207, "mem_42207") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42208, "ext_mem_42208") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42205, "mem_42205") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42203, "mem_42203") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42201, "ext_mem_42201") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_42708, "mem_out_42708") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_42707, "mem_out_42707") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_42706, "mem_out_42706") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_inner_SMJ_float(struct futhark_context *ctx, struct memblock_device *mem_out_p_43297, struct memblock_device *mem_out_p_43298, struct memblock_device *mem_out_p_43299, int64_t *out_prim_out_43300, struct memblock_device tR_mem_42199, struct memblock_device tS_mem_42200, int64_t nR_32229, int64_t nS_32230, int64_t offset_R_32233, int64_t offset_S_32234, int64_t partitionsPerWindow_32235, int64_t numberOfWindows_32236, int64_t extParallelism_32237, int64_t scatter_psizze_32238)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_42477;
    
    mem_42477.references = NULL;
    
    struct memblock_device mem_42475;
    
    mem_42475.references = NULL;
    
    struct memblock_device mem_42473;
    
    mem_42473.references = NULL;
    
    struct memblock_device mem_param_tmp_43215;
    
    mem_param_tmp_43215.references = NULL;
    
    struct memblock_device mem_param_tmp_43214;
    
    mem_param_tmp_43214.references = NULL;
    
    struct memblock_device mem_param_tmp_43213;
    
    mem_param_tmp_43213.references = NULL;
    
    struct memblock_device mem_42459;
    
    mem_42459.references = NULL;
    
    struct memblock_device mem_42457;
    
    mem_42457.references = NULL;
    
    struct memblock_device mem_42452;
    
    mem_42452.references = NULL;
    
    struct memblock_device mem_42450;
    
    mem_42450.references = NULL;
    
    struct memblock_device mem_42448;
    
    mem_42448.references = NULL;
    
    struct memblock_device mem_param_42446;
    
    mem_param_42446.references = NULL;
    
    struct memblock_device mem_param_42443;
    
    mem_param_42443.references = NULL;
    
    struct memblock_device mem_param_42440;
    
    mem_param_42440.references = NULL;
    
    struct memblock_device ext_mem_42469;
    
    ext_mem_42469.references = NULL;
    
    struct memblock_device ext_mem_42470;
    
    ext_mem_42470.references = NULL;
    
    struct memblock_device ext_mem_42471;
    
    ext_mem_42471.references = NULL;
    
    struct memblock_device mem_42455;
    
    mem_42455.references = NULL;
    
    struct memblock_device mem_42454;
    
    mem_42454.references = NULL;
    
    struct memblock_device mem_42453;
    
    mem_42453.references = NULL;
    
    struct memblock_device mem_42427;
    
    mem_42427.references = NULL;
    
    struct memblock_device mem_42425;
    
    mem_42425.references = NULL;
    
    struct memblock_device mem_42423;
    
    mem_42423.references = NULL;
    
    struct memblock_device mem_42412;
    
    mem_42412.references = NULL;
    
    struct memblock_device mem_42410;
    
    mem_42410.references = NULL;
    
    struct memblock_device mem_42408;
    
    mem_42408.references = NULL;
    
    struct memblock_device mem_42404;
    
    mem_42404.references = NULL;
    
    struct memblock_device mem_42402;
    
    mem_42402.references = NULL;
    
    struct memblock_device mem_42406;
    
    mem_42406.references = NULL;
    
    struct memblock_device mem_42398;
    
    mem_42398.references = NULL;
    
    struct memblock_device mem_42399;
    
    mem_42399.references = NULL;
    
    struct memblock_device ext_mem_42400;
    
    ext_mem_42400.references = NULL;
    
    struct memblock_device mem_42395;
    
    mem_42395.references = NULL;
    
    struct memblock_device mem_42396;
    
    mem_42396.references = NULL;
    
    struct memblock_device ext_mem_42397;
    
    ext_mem_42397.references = NULL;
    
    struct memblock_device mem_42394;
    
    mem_42394.references = NULL;
    
    struct memblock_device incprefixes_mem_43016;
    
    incprefixes_mem_43016.references = NULL;
    
    struct memblock_device aggregates_mem_43014;
    
    aggregates_mem_43014.references = NULL;
    
    struct memblock_device incprefixes_mem_43012;
    
    incprefixes_mem_43012.references = NULL;
    
    struct memblock_device aggregates_mem_43010;
    
    aggregates_mem_43010.references = NULL;
    
    struct memblock_device status_flags_mem_43008;
    
    status_flags_mem_43008.references = NULL;
    
    struct memblock_device mem_42391;
    
    mem_42391.references = NULL;
    
    struct memblock_device mem_42389;
    
    mem_42389.references = NULL;
    
    struct memblock_device mem_42387;
    
    mem_42387.references = NULL;
    
    struct memblock_device mem_42383;
    
    mem_42383.references = NULL;
    
    struct memblock_device mem_42381;
    
    mem_42381.references = NULL;
    
    struct memblock_device mem_42379;
    
    mem_42379.references = NULL;
    
    struct memblock_device mem_42377;
    
    mem_42377.references = NULL;
    
    struct memblock_device incprefixes_mem_42875;
    
    incprefixes_mem_42875.references = NULL;
    
    struct memblock_device aggregates_mem_42873;
    
    aggregates_mem_42873.references = NULL;
    
    struct memblock_device status_flags_mem_42851;
    
    status_flags_mem_42851.references = NULL;
    
    struct memblock_device mem_42375;
    
    mem_42375.references = NULL;
    
    struct memblock_device mem_42373;
    
    mem_42373.references = NULL;
    
    struct memblock_device mem_param_tmp_42763;
    
    mem_param_tmp_42763.references = NULL;
    
    struct memblock_device mem_param_tmp_42762;
    
    mem_param_tmp_42762.references = NULL;
    
    struct memblock_device mem_42352;
    
    mem_42352.references = NULL;
    
    struct memblock_device mem_42350;
    
    mem_42350.references = NULL;
    
    struct memblock_device mem_42285;
    
    mem_42285.references = NULL;
    
    struct memblock_device mem_42283;
    
    mem_42283.references = NULL;
    
    struct memblock_device mem_42346;
    
    mem_42346.references = NULL;
    
    struct memblock_device mem_42344;
    
    mem_42344.references = NULL;
    
    struct memblock_device ext_mem_42347;
    
    ext_mem_42347.references = NULL;
    
    struct memblock_device ext_mem_42348;
    
    ext_mem_42348.references = NULL;
    
    struct memblock_device ext_mem_42224;
    
    ext_mem_42224.references = NULL;
    
    struct memblock_device ext_mem_42355;
    
    ext_mem_42355.references = NULL;
    
    struct memblock_device ext_mem_42358;
    
    ext_mem_42358.references = NULL;
    
    struct memblock_device mem_42223;
    
    mem_42223.references = NULL;
    
    struct memblock_device ext_mem_42361;
    
    ext_mem_42361.references = NULL;
    
    struct memblock_device ext_mem_42364;
    
    ext_mem_42364.references = NULL;
    
    struct memblock_device ext_mem_42221;
    
    ext_mem_42221.references = NULL;
    
    struct memblock_device ext_mem_42220;
    
    ext_mem_42220.references = NULL;
    
    struct memblock_device mem_param_42217;
    
    mem_param_42217.references = NULL;
    
    struct memblock_device mem_param_42214;
    
    mem_param_42214.references = NULL;
    
    struct memblock_device ext_mem_42369;
    
    ext_mem_42369.references = NULL;
    
    struct memblock_device ext_mem_42370;
    
    ext_mem_42370.references = NULL;
    
    struct memblock_device mem_42222;
    
    mem_42222.references = NULL;
    
    struct memblock_device mem_42219;
    
    mem_42219.references = NULL;
    
    struct memblock_device mem_42218;
    
    mem_42218.references = NULL;
    
    struct memblock_device mem_42209;
    
    mem_42209.references = NULL;
    
    struct memblock_device mem_42210;
    
    mem_42210.references = NULL;
    
    struct memblock_device ext_mem_42211;
    
    ext_mem_42211.references = NULL;
    
    struct memblock_device mem_42206;
    
    mem_42206.references = NULL;
    
    struct memblock_device mem_42207;
    
    mem_42207.references = NULL;
    
    struct memblock_device ext_mem_42208;
    
    ext_mem_42208.references = NULL;
    
    struct memblock_device mem_42205;
    
    mem_42205.references = NULL;
    
    struct memblock_device mem_42203;
    
    mem_42203.references = NULL;
    
    struct memblock_device ext_mem_42201;
    
    ext_mem_42201.references = NULL;
    
    struct memblock_device mem_out_42708;
    
    mem_out_42708.references = NULL;
    
    struct memblock_device mem_out_42707;
    
    mem_out_42707.references = NULL;
    
    struct memblock_device mem_out_42706;
    
    mem_out_42706.references = NULL;
    
    struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
    struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
    struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
    struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
    struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
    int64_t prim_out_42709;
    int64_t zm_lhs_39067 = add64(nR_32229, extParallelism_32237);
    int64_t zs_lhs_39068 = sub64(zm_lhs_39067, (int64_t) 1);
    bool zzero_39069 = extParallelism_32237 == (int64_t) 0;
    bool nonzzero_39070 = !zzero_39069;
    bool nonzzero_cert_39071;
    
    if (!nonzzero_39070) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftSMJ.fut:48:39-55\n   #1  ftSMJ.fut:327:87-89\n   #2  ftSMJ.fut:391:133-136\n   #3  ftSMJ.fut:380:1-391:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t numIter_39072 = sdiv64(zs_lhs_39068, extParallelism_32237);
    
    if (futrts_indicesWithIncrement_9844(ctx, &ext_mem_42201, tR_mem_42199, nR_32229, offset_R_32233) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t bytes_42202 = (int64_t) 8 * nR_32229;
    
    if (memblock_alloc_device(ctx, &mem_42203, bytes_42202, "mem_42203")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_42203, nR_32229, (int64_t) -1) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42205, bytes_42202, "mem_42205")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_42205, nR_32229, (int64_t) 0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    bool loop_cond_39076 = slt64((int64_t) 0, numIter_39072);
    bool cond_39077 = slt64((int64_t) 0, nS_32230);
    int64_t tmp_39078 = sub64(nS_32230, (int64_t) 1);
    bool loop_not_taken_39079 = !cond_39077;
    bool loop_not_taken_39080 = !loop_cond_39076;
    bool x_39081 = sle64((int64_t) 0, tmp_39078);
    bool y_39082 = slt64(tmp_39078, nS_32230);
    bool protect_cond_conj_39083 = loop_cond_39076 && cond_39077;
    
    if (protect_cond_conj_39083) {
        if (memblock_alloc_device(ctx, &mem_42207, (int64_t) 4, "mem_42207")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_floatzigpuseq_42730(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, tS_mem_42200.mem, mem_42207.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42208, &mem_42207, "mem_42207") != 0)
            return 1;
    } else {
        if (memblock_alloc_device(ctx, &mem_42206, (int64_t) 4, "mem_42206")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_f32(ctx, mem_42206, (int64_t) 1, 0.0F) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42208, &mem_42206, "mem_42206") != 0)
            return 1;
    }
    
    bool bounds_check_39086 = x_39081 && y_39082;
    bool protect_assert_disj_39087 = loop_not_taken_39079 || bounds_check_39086;
    bool protect_assert_disj_39088 = loop_not_taken_39080 || protect_assert_disj_39087;
    bool index_certs_39089;
    
    if (!protect_assert_disj_39088) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) tmp_39078, "] out of bounds for array of shape [", (long long) nS_32230, "].", "-> #0  ftSMJ.fut:60:34-42\n   #1  ftSMJ.fut:327:87-89\n   #2  ftSMJ.fut:391:133-136\n   #3  ftSMJ.fut:380:1-391:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    if (protect_cond_conj_39083) {
        if (memblock_alloc_device(ctx, &mem_42210, (int64_t) 4, "mem_42210")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_floatzigpuseq_42756(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, tmp_39078, tS_mem_42200.mem, mem_42210.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42211, &mem_42210, "mem_42210") != 0)
            return 1;
    } else {
        if (memblock_alloc_device(ctx, &mem_42209, (int64_t) 4, "mem_42209")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_f32(ctx, mem_42209, (int64_t) 1, 0.0F) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42211, &mem_42209, "mem_42209") != 0)
            return 1;
    }
    if (memblock_alloc_device(ctx, &mem_42218, (int64_t) 4, "mem_42218")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42219, (int64_t) 4, "mem_42219")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42222, (int64_t) 1, "mem_42222")) {
        err = 1;
        goto cleanup;
    }
    
    int64_t ext_42368;
    int64_t ext_42367;
    int64_t ext_42366;
    int64_t ext_42365;
    bool defunc_0_find_joinTuples_res_39092;
    int64_t defunc_0_find_joinTuples_res_39093;
    bool loop_while_39096;
    int64_t p_39097;
    int64_t ctx_param_ext_42212;
    int64_t ctx_param_ext_42213;
    int64_t ctx_param_ext_42215;
    int64_t ctx_param_ext_42216;
    
    if (memblock_set_device(ctx, &mem_param_42214, &mem_42205, "mem_42205") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_42217, &mem_42203, "mem_42203") != 0)
        return 1;
    ctx_param_ext_42212 = (int64_t) 0;
    ctx_param_ext_42213 = (int64_t) 1;
    ctx_param_ext_42215 = (int64_t) 0;
    ctx_param_ext_42216 = (int64_t) 1;
    loop_while_39096 = loop_cond_39076;
    p_39097 = (int64_t) 0;
    while (loop_while_39096) {
        int64_t start_39100 = mul64(extParallelism_32237, p_39097);
        int64_t min_arg1_39101 = sub64(nR_32229, start_39100);
        int64_t min_res_39102 = smin64(extParallelism_32237, min_arg1_39101);
        int64_t iter_R_39103 = add64(start_39100, min_res_39102);
        bool empty_slice_39104 = min_res_39102 == (int64_t) 0;
        int64_t m_39105 = sub64(min_res_39102, (int64_t) 1);
        int64_t i_p_m_t_s_39106 = add64(start_39100, m_39105);
        bool zzero_leq_i_p_m_t_s_39107 = sle64((int64_t) 0, i_p_m_t_s_39106);
        bool i_p_m_t_s_leq_w_39108 = slt64(i_p_m_t_s_39106, nR_32229);
        bool zzero_lte_i_39109 = sle64((int64_t) 0, start_39100);
        bool i_lte_j_39110 = sle64(start_39100, iter_R_39103);
        bool y_39111 = i_p_m_t_s_leq_w_39108 && zzero_lte_i_39109;
        bool y_39112 = zzero_leq_i_p_m_t_s_39107 && y_39111;
        bool forwards_ok_39113 = i_lte_j_39110 && y_39112;
        bool ok_or_empty_39114 = empty_slice_39104 || forwards_ok_39113;
        bool index_certs_39115;
        
        if (!ok_or_empty_39114) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) start_39100, ":", (long long) iter_R_39103, "] out of bounds for array of shape [", (long long) nR_32229, "].", "-> #0  ftSMJ.fut:55:20-49\n   #1  ftSMJ.fut:327:87-89\n   #2  ftSMJ.fut:391:133-136\n   #3  ftSMJ.fut:380:1-391:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        bool y_39121 = slt64(m_39105, min_res_39102);
        bool x_39120 = sle64((int64_t) 0, m_39105);
        bool bounds_check_39122 = x_39120 && y_39121;
        bool index_certs_39123;
        
        if (!bounds_check_39122) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) m_39105, "] out of bounds for array of shape [", (long long) min_res_39102, "].", "-> #0  ftSMJ.fut:58:21-40\n   #1  ftSMJ.fut:327:87-89\n   #2  ftSMJ.fut:391:133-136\n   #3  ftSMJ.fut:380:1-391:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        bool y_39117 = slt64((int64_t) 0, min_res_39102);
        bool index_certs_39118;
        
        if (!y_39117) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) (int64_t) 0, "] out of bounds for array of shape [", (long long) min_res_39102, "].", "-> #0  ftSMJ.fut:57:21-30\n   #1  ftSMJ.fut:327:87-89\n   #2  ftSMJ.fut:391:133-136\n   #3  ftSMJ.fut:380:1-391:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_floatzigpuseq_42772(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, start_39100, i_p_m_t_s_39106, tR_mem_42199.mem, mem_42218.mem, mem_42219.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (cond_39077) {
            if (memblock_set_device(ctx, &ext_mem_42220, &ext_mem_42211, "ext_mem_42211") != 0)
                return 1;
        } else if (memblock_set_device(ctx, &ext_mem_42220, &mem_42218, "mem_42218") != 0)
            return 1;
        if (cond_39077) {
            if (memblock_set_device(ctx, &ext_mem_42221, &ext_mem_42208, "ext_mem_42208") != 0)
                return 1;
        } else if (memblock_set_device(ctx, &ext_mem_42221, &mem_42219, "mem_42219") != 0)
            return 1;
        {
            err = gpu_kernel_inner_SMJ_floatzigpuseq_42778(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, mem_42219.mem, ext_mem_42220.mem, mem_42222.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_unref_device(ctx, &ext_mem_42220, "ext_mem_42220") != 0)
            return 1;
        
        bool read_res_43301;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_43301, mem_42222.mem, (int64_t) 0 * sizeof(bool), sizeof(bool))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        bool defunc_0_gt_res_39127 = read_res_43301;
        int64_t ext_42363;
        int64_t ext_42362;
        int64_t ext_42360;
        int64_t ext_42359;
        int64_t loopres_39128;
        
        if (defunc_0_gt_res_39127) {
            if (memblock_set_device(ctx, &ext_mem_42364, &mem_param_42214, "mem_param_42214") != 0)
                return 1;
            ext_42363 = ctx_param_ext_42212;
            ext_42362 = ctx_param_ext_42213;
            if (memblock_set_device(ctx, &ext_mem_42361, &mem_param_42217, "mem_param_42217") != 0)
                return 1;
            ext_42360 = ctx_param_ext_42215;
            ext_42359 = ctx_param_ext_42216;
            loopres_39128 = numIter_39072;
        } else {
            if (memblock_alloc_device(ctx, &mem_42223, (int64_t) 1, "mem_42223")) {
                err = 1;
                goto cleanup;
            }
            {
                err = gpu_kernel_inner_SMJ_floatzigpuseq_42784(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, mem_42218.mem, ext_mem_42221.mem, mem_42223.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            
            bool read_res_43302;
            
            if ((err = gpu_scalar_from_device(ctx, &read_res_43302, mem_42223.mem, (int64_t) 0 * sizeof(bool), sizeof(bool))) != 0)
                goto cleanup;
            if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                err = 1;
                goto cleanup;
            }
            
            bool defunc_0_gt_res_39131 = read_res_43302;
            
            if (memblock_unref_device(ctx, &mem_42223, "mem_42223") != 0)
                return 1;
            
            int64_t ext_42357;
            
            if (defunc_0_gt_res_39131) {
                ext_42357 = ctx_param_ext_42212;
            } else {
                ext_42357 = (int64_t) 0;
            }
            
            int64_t ext_42356;
            
            if (defunc_0_gt_res_39131) {
                ext_42356 = ctx_param_ext_42213;
            } else {
                ext_42356 = (int64_t) 1;
            }
            
            int64_t ext_42354;
            
            if (defunc_0_gt_res_39131) {
                ext_42354 = ctx_param_ext_42215;
            } else {
                ext_42354 = (int64_t) 0;
            }
            
            int64_t ext_42353;
            
            if (defunc_0_gt_res_39131) {
                ext_42353 = ctx_param_ext_42216;
            } else {
                ext_42353 = (int64_t) 1;
            }
            
            int64_t loopres_f_res_39132;
            
            if (defunc_0_gt_res_39131) {
                int64_t tmp_39506 = add64((int64_t) 1, p_39097);
                
                if (memblock_set_device(ctx, &ext_mem_42358, &mem_param_42214, "mem_param_42214") != 0)
                    return 1;
                if (memblock_set_device(ctx, &ext_mem_42355, &mem_param_42217, "mem_param_42217") != 0)
                    return 1;
                loopres_f_res_39132 = tmp_39506;
            } else {
                if (futrts_indicesWithIncrement_9844(ctx, &ext_mem_42224, tS_mem_42200, nS_32230, offset_S_32234) != 0) {
                    err = 1;
                    goto cleanup;
                }
                
                bool suff_outer_par_40897;
                
                suff_outer_par_40897 = *ctx->tuning_params.inner_SMJ_floatzisuff_outer_par_0 <= min_res_39102;
                if (ctx->logging)
                    fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "inner_SMJ_float.suff_outer_par_0", (long) min_res_39102, suff_outer_par_40897 ? "true" : "false");
                
                int64_t tile_sizze_41780;
                
                tile_sizze_41780 = *ctx->tuning_params.inner_SMJ_floatzitile_sizze_41779;
                
                int64_t tile_sizze_41425;
                
                tile_sizze_41425 = *ctx->tuning_params.inner_SMJ_floatzitile_sizze_41424;
                
                int64_t num_whole_tiles_41796 = squot_safe64(nS_32230, tile_sizze_41780);
                int64_t residual_input_42020 = srem_safe64(nS_32230, tile_sizze_41780);
                bool cond_42021 = residual_input_42020 == (int64_t) 0;
                int64_t binop_x_42037 = tile_sizze_41780 * num_whole_tiles_41796;
                int64_t bytes_42282 = (int64_t) 8 * min_res_39102;
                int64_t bytes_42245 = (int64_t) 8 * tile_sizze_41780;
                int64_t bytes_42247 = (int64_t) 4 * tile_sizze_41780;
                int64_t num_whole_tiles_41441 = squot_safe64(nS_32230, tile_sizze_41425);
                int64_t residual_input_41665 = srem_safe64(nS_32230, tile_sizze_41425);
                bool cond_41666 = residual_input_41665 == (int64_t) 0;
                int64_t binop_x_41682 = tile_sizze_41425 * num_whole_tiles_41441;
                int64_t bytes_42306 = (int64_t) 8 * tile_sizze_41425;
                int64_t bytes_42308 = (int64_t) 4 * tile_sizze_41425;
                int64_t shared_memory_capacity_42842;
                
                shared_memory_capacity_42842 = ctx->max_shared_memory;
                if (suff_outer_par_40897 && sle64(sdiv_up64(bytes_42306, (int64_t) 8) * (int64_t) 8 + sdiv_up64(bytes_42308, (int64_t) 8) * (int64_t) 8 + sdiv_up64(bytes_42306, (int64_t) 8) * (int64_t) 8, shared_memory_capacity_42842)) {
                    int64_t ldim_41426 = sdiv_up64(min_res_39102, tile_sizze_41425);
                    
                    if (memblock_alloc_device(ctx, &mem_42344, bytes_42282, "mem_42344")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &mem_42346, bytes_42282, "mem_42346")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t num_chunks_42790 = sext_i64_i32(sdiv_up64(tile_sizze_41425, tile_sizze_41425));
                    int32_t virt_num_tblocks_42791 = sext_i64_i32(ldim_41426);
                    
                    {
                        err = gpu_kernel_inner_SMJ_floatzisegmap_intrablock_41423(ctx, ldim_41426, 1, 1, *ctx->tuning_params.inner_SMJ_floatzitile_sizze_41424, 1, 1, bytes_42306 + srem64((int64_t) 8 - srem64(bytes_42306, (int64_t) 8), (int64_t) 8) + (bytes_42308 + srem64((int64_t) 8 - srem64(bytes_42308, (int64_t) 8), (int64_t) 8)) + (bytes_42306 + srem64((int64_t) 8 - srem64(bytes_42306, (int64_t) 8), (int64_t) 8)), nS_32230, start_39100, min_res_39102, ldim_41426, num_whole_tiles_41441, residual_input_41665, cond_41666, binop_x_41682, tR_mem_42199.mem, tS_mem_42200.mem, ext_mem_42224.mem, mem_42344.mem, mem_42346.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_set_device(ctx, &ext_mem_42348, &mem_42344, "mem_42344") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &ext_mem_42347, &mem_42346, "mem_42346") != 0)
                        return 1;
                } else {
                    int64_t ldim_41781 = sdiv_up64(min_res_39102, tile_sizze_41780);
                    
                    if (memblock_alloc_device(ctx, &mem_42283, bytes_42282, "mem_42283")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &mem_42285, bytes_42282, "mem_42285")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t num_chunks_42816 = sext_i64_i32(sdiv_up64(tile_sizze_41780, tile_sizze_41780));
                    int32_t virt_num_tblocks_42817 = sext_i64_i32(ldim_41781);
                    
                    {
                        err = gpu_kernel_inner_SMJ_floatzisegmap_intrablock_41778(ctx, ldim_41781, 1, 1, *ctx->tuning_params.inner_SMJ_floatzitile_sizze_41779, 1, 1, bytes_42245 + srem64((int64_t) 8 - srem64(bytes_42245, (int64_t) 8), (int64_t) 8) + (bytes_42247 + srem64((int64_t) 8 - srem64(bytes_42247, (int64_t) 8), (int64_t) 8)) + (bytes_42245 + srem64((int64_t) 8 - srem64(bytes_42245, (int64_t) 8), (int64_t) 8)), nS_32230, start_39100, min_res_39102, ldim_41781, num_whole_tiles_41796, residual_input_42020, cond_42021, binop_x_42037, tR_mem_42199.mem, tS_mem_42200.mem, ext_mem_42224.mem, mem_42283.mem, mem_42285.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_set_device(ctx, &ext_mem_42348, &mem_42283, "mem_42283") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &ext_mem_42347, &mem_42285, "mem_42285") != 0)
                        return 1;
                }
                if (memblock_unref_device(ctx, &ext_mem_42224, "ext_mem_42224") != 0)
                    return 1;
                if (memblock_alloc_device(ctx, &mem_42350, bytes_42202, "mem_42350")) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42350.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_42217.mem, ctx_param_ext_42215, (int64_t []) {ctx_param_ext_42216}, (int64_t []) {nR_32229})) != 0)
                    goto cleanup;
                if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42350.mem, start_39100, (int64_t []) {(int64_t) 1}, ext_mem_42348.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {min_res_39102})) != 0)
                    goto cleanup;
                if (memblock_unref_device(ctx, &ext_mem_42348, "ext_mem_42348") != 0)
                    return 1;
                if (memblock_alloc_device(ctx, &mem_42352, bytes_42202, "mem_42352")) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42352.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_42214.mem, ctx_param_ext_42212, (int64_t []) {ctx_param_ext_42213}, (int64_t []) {nR_32229})) != 0)
                    goto cleanup;
                if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42352.mem, start_39100, (int64_t []) {(int64_t) 1}, ext_mem_42347.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {min_res_39102})) != 0)
                    goto cleanup;
                if (memblock_unref_device(ctx, &ext_mem_42347, "ext_mem_42347") != 0)
                    return 1;
                
                int64_t tmp_39179 = add64((int64_t) 1, p_39097);
                
                if (memblock_set_device(ctx, &ext_mem_42358, &mem_42352, "mem_42352") != 0)
                    return 1;
                if (memblock_set_device(ctx, &ext_mem_42355, &mem_42350, "mem_42350") != 0)
                    return 1;
                loopres_f_res_39132 = tmp_39179;
            }
            if (memblock_set_device(ctx, &ext_mem_42364, &ext_mem_42358, "ext_mem_42358") != 0)
                return 1;
            ext_42363 = ext_42357;
            ext_42362 = ext_42356;
            if (memblock_set_device(ctx, &ext_mem_42361, &ext_mem_42355, "ext_mem_42355") != 0)
                return 1;
            ext_42360 = ext_42354;
            ext_42359 = ext_42353;
            loopres_39128 = loopres_f_res_39132;
        }
        if (memblock_unref_device(ctx, &ext_mem_42221, "ext_mem_42221") != 0)
            return 1;
        
        bool loop_cond_39180 = slt64(loopres_39128, numIter_39072);
        
        if (memblock_set_device(ctx, &mem_param_tmp_42762, &ext_mem_42364, "ext_mem_42364") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_42763, &ext_mem_42361, "ext_mem_42361") != 0)
            return 1;
        
        int64_t ctx_param_ext_tmp_42764 = ext_42363;
        int64_t ctx_param_ext_tmp_42765 = ext_42362;
        int64_t ctx_param_ext_tmp_42766 = ext_42360;
        int64_t ctx_param_ext_tmp_42767 = ext_42359;
        bool loop_while_tmp_42768 = loop_cond_39180;
        int64_t p_tmp_42769 = loopres_39128;
        
        if (memblock_set_device(ctx, &mem_param_42214, &mem_param_tmp_42762, "mem_param_tmp_42762") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_42217, &mem_param_tmp_42763, "mem_param_tmp_42763") != 0)
            return 1;
        ctx_param_ext_42212 = ctx_param_ext_tmp_42764;
        ctx_param_ext_42213 = ctx_param_ext_tmp_42765;
        ctx_param_ext_42215 = ctx_param_ext_tmp_42766;
        ctx_param_ext_42216 = ctx_param_ext_tmp_42767;
        loop_while_39096 = loop_while_tmp_42768;
        p_39097 = p_tmp_42769;
    }
    if (memblock_set_device(ctx, &ext_mem_42370, &mem_param_42214, "mem_param_42214") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_42369, &mem_param_42217, "mem_param_42217") != 0)
        return 1;
    ext_42368 = ctx_param_ext_42212;
    ext_42367 = ctx_param_ext_42213;
    ext_42366 = ctx_param_ext_42215;
    ext_42365 = ctx_param_ext_42216;
    defunc_0_find_joinTuples_res_39092 = loop_while_39096;
    defunc_0_find_joinTuples_res_39093 = p_39097;
    if (memblock_unref_device(ctx, &mem_42203, "mem_42203") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42205, "mem_42205") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_42208, "ext_mem_42208") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_42211, "ext_mem_42211") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42218, "mem_42218") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42219, "mem_42219") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42222, "mem_42222") != 0)
        return 1;
    
    int64_t segscan_tblock_sizze_41074;
    
    segscan_tblock_sizze_41074 = *ctx->tuning_params.inner_SMJ_floatzisegscan_tblock_sizze_41073;
    
    int64_t num_tblocks_41076;
    int64_t max_num_tblocks_42843;
    
    max_num_tblocks_42843 = *ctx->tuning_params.inner_SMJ_floatzisegscan_num_tblocks_41075;
    num_tblocks_41076 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nR_32229, segscan_tblock_sizze_41074), max_num_tblocks_42843)));
    if (memblock_alloc_device(ctx, &mem_42373, bytes_42202, "mem_42373")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42375, bytes_42202, "mem_42375")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, nR_32229)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_42844;
        
        shared_memory_42844 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_42845;
        
        thread_block_sizze_42845 = ctx->max_thread_block_size;
        
        int64_t registers_42846;
        
        registers_42846 = ctx->max_registers;
        
        int64_t thread_block_sizze_42847;
        
        thread_block_sizze_42847 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_42848 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_42844, thread_block_sizze_42845), (int64_t) 8), squot64(squot64(registers_42846, thread_block_sizze_42847) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
        int64_t num_virt_blocks_42849 = sdiv_up64(nR_32229, segscan_tblock_sizze_41074 * chunk_sizze_42848);
        int64_t num_virt_threads_42850 = num_virt_blocks_42849 * segscan_tblock_sizze_41074;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_42848, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_42851, num_virt_blocks_42849, "status_flags_mem_42851")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_42851, num_virt_blocks_42849, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_42873, (int64_t) 8 * num_virt_blocks_42849, "aggregates_mem_42873")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_42875, (int64_t) 8 * num_virt_blocks_42849, "incprefixes_mem_42875")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_floatzisegscan_41079(ctx, num_tblocks_41076, 1, 1, *ctx->tuning_params.inner_SMJ_floatzisegscan_tblock_sizze_41073, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_41074), chunk_sizze_42848 * segscan_tblock_sizze_41074 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_41074), chunk_sizze_42848 * segscan_tblock_sizze_41074 * (int64_t) 8), (int64_t) 8), (int64_t) 8), nR_32229, num_tblocks_41076, ext_42367, ext_42368, num_virt_blocks_42849, num_virt_threads_42850, ext_mem_42370.mem, mem_42373.mem, mem_42375.mem, status_flags_mem_42851.mem, aggregates_mem_42873.mem, incprefixes_mem_42875.mem, global_dynid_mem_42877.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    
    bool cond_39190 = nR_32229 == (int64_t) 0;
    bool x_39191 = !cond_39190;
    int64_t tmp_39192 = sub64(nR_32229, (int64_t) 1);
    bool x_39193 = sle64((int64_t) 0, tmp_39192);
    bool y_39194 = slt64(tmp_39192, nR_32229);
    bool bounds_check_39195 = x_39193 && y_39194;
    bool protect_assert_disj_39196 = cond_39190 || bounds_check_39195;
    bool index_certs_39197;
    
    if (!protect_assert_disj_39196) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) tmp_39192, "] out of bounds for array of shape [", (long long) nR_32229, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:327:7-328:73\n   #3  ftSMJ.fut:391:133-136\n   #4  ftSMJ.fut:380:1-391:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t m_f_res_39198;
    
    if (x_39191) {
        int64_t read_res_43303;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_43303, mem_42373.mem, tmp_39192 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_39513 = read_res_43303;
        
        m_f_res_39198 = x_39513;
    } else {
        m_f_res_39198 = (int64_t) 0;
    }
    
    int64_t m_39200;
    
    if (cond_39190) {
        m_39200 = (int64_t) 0;
    } else {
        m_39200 = m_f_res_39198;
    }
    
    int64_t m_39210 = sub64(m_39200, (int64_t) 1);
    bool i_p_m_t_s_leq_w_39212 = slt64(m_39210, nR_32229);
    bool zzero_leq_i_p_m_t_s_39211 = sle64((int64_t) 0, m_39210);
    bool y_39214 = zzero_leq_i_p_m_t_s_39211 && i_p_m_t_s_leq_w_39212;
    bool i_lte_j_39213 = sle64((int64_t) 0, m_39200);
    bool forwards_ok_39215 = i_lte_j_39213 && y_39214;
    bool eq_x_zz_39207 = (int64_t) 0 == m_f_res_39198;
    bool p_and_eq_x_y_39208 = x_39191 && eq_x_zz_39207;
    bool empty_slice_39209 = cond_39190 || p_and_eq_x_y_39208;
    bool ok_or_empty_39216 = empty_slice_39209 || forwards_ok_39215;
    bool index_certs_39217;
    
    if (!ok_or_empty_39216) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_39200, "] out of bounds for array of shape [", (long long) nR_32229, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:327:7-328:73\n   #3  ftSMJ.fut:391:133-136\n   #4  ftSMJ.fut:380:1-391:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_42376 = (int64_t) 8 * m_39200;
    
    if (memblock_alloc_device(ctx, &mem_42377, bytes_42376, "mem_42377")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42377.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42370.mem, ext_42368, (int64_t []) {ext_42367}, (int64_t []) {m_39200})) != 0)
        goto cleanup;
    if (memblock_alloc_device(ctx, &mem_42379, bytes_42376, "mem_42379")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42379.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42369.mem, ext_42366, (int64_t []) {ext_42365}, (int64_t []) {m_39200})) != 0)
        goto cleanup;
    if (memblock_alloc_device(ctx, &mem_42381, bytes_42376, "mem_42381")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42381.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42201.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_39200})) != 0)
        goto cleanup;
    
    int64_t bytes_42382 = (int64_t) 4 * m_39200;
    
    if (memblock_alloc_device(ctx, &mem_42383, bytes_42382, "mem_42383")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_42383.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, tR_mem_42199.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_39200})) != 0)
        goto cleanup;
    
    int64_t segmap_tblock_sizze_41084;
    
    segmap_tblock_sizze_41084 = *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_41083;
    
    int64_t num_tblocks_41086;
    int64_t max_num_tblocks_42986;
    
    max_num_tblocks_42986 = *ctx->tuning_params.inner_SMJ_floatzisegmap_num_tblocks_41085;
    num_tblocks_41086 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nR_32229, segmap_tblock_sizze_41084), max_num_tblocks_42986)));
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_42987 = sext_i64_i32(sdiv_up64(nR_32229, segmap_tblock_sizze_41084));
    
    {
        err = gpu_kernel_inner_SMJ_floatzisegmap_41081(ctx, num_tblocks_41086, 1, 1, *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_41083, 1, 1, (int64_t) 0, nR_32229, m_39200, num_tblocks_41086, ext_42365, ext_42366, ext_42367, ext_42368, virt_num_tblocks_42987, tR_mem_42199.mem, ext_mem_42201.mem, ext_mem_42369.mem, ext_mem_42370.mem, mem_42373.mem, mem_42375.mem, mem_42377.mem, mem_42379.mem, mem_42381.mem, mem_42383.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &ext_mem_42201, "ext_mem_42201") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_42369, "ext_mem_42369") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_42370, "ext_mem_42370") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42373, "mem_42373") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42375, "mem_42375") != 0)
        return 1;
    
    int64_t segscan_tblock_sizze_41090;
    
    segscan_tblock_sizze_41090 = *ctx->tuning_params.inner_SMJ_floatzisegscan_tblock_sizze_41089;
    
    int64_t num_tblocks_41092;
    int64_t max_num_tblocks_43000;
    
    max_num_tblocks_43000 = *ctx->tuning_params.inner_SMJ_floatzisegscan_num_tblocks_41091;
    num_tblocks_41092 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_39200, segscan_tblock_sizze_41090), max_num_tblocks_43000)));
    if (memblock_alloc_device(ctx, &mem_42387, bytes_42376, "mem_42387")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42389, bytes_42376, "mem_42389")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42391, bytes_42376, "mem_42391")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, m_39200)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_43001;
        
        shared_memory_43001 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_43002;
        
        thread_block_sizze_43002 = ctx->max_thread_block_size;
        
        int64_t registers_43003;
        
        registers_43003 = ctx->max_registers;
        
        int64_t thread_block_sizze_43004;
        
        thread_block_sizze_43004 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_43005 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_43001, thread_block_sizze_43002), (int64_t) 8), squot64(squot64(registers_43003, thread_block_sizze_43004) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
        int64_t num_virt_blocks_43006 = sdiv_up64(m_39200, segscan_tblock_sizze_41090 * chunk_sizze_43005);
        int64_t num_virt_threads_43007 = num_virt_blocks_43006 * segscan_tblock_sizze_41090;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_43005, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_43008, num_virt_blocks_43006, "status_flags_mem_43008")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_43008, num_virt_blocks_43006, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_43010, (int64_t) 8 * num_virt_blocks_43006, "aggregates_mem_43010")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_43012, (int64_t) 8 * num_virt_blocks_43006, "incprefixes_mem_43012")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_43014, (int64_t) 8 * num_virt_blocks_43006, "aggregates_mem_43014")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_43016, (int64_t) 8 * num_virt_blocks_43006, "incprefixes_mem_43016")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_floatzisegscan_41095(ctx, num_tblocks_41092, 1, 1, *ctx->tuning_params.inner_SMJ_floatzisegscan_tblock_sizze_41089, 1, 1, smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_41090, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_41090), smax64(chunk_sizze_43005 * segscan_tblock_sizze_41090 * (int64_t) 8, chunk_sizze_43005 * segscan_tblock_sizze_41090 * (int64_t) 8)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_41090, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_41090), smax64(chunk_sizze_43005 * segscan_tblock_sizze_41090 * (int64_t) 8, chunk_sizze_43005 * segscan_tblock_sizze_41090 * (int64_t) 8)), (int64_t) 8), (int64_t) 8), m_39200, num_tblocks_41092, num_virt_blocks_43006, num_virt_threads_43007, mem_42377.mem, mem_42387.mem, mem_42389.mem, mem_42391.mem, status_flags_mem_43008.mem, aggregates_mem_43010.mem, incprefixes_mem_43012.mem, aggregates_mem_43014.mem, incprefixes_mem_43016.mem, global_dynid_mem_43018.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    
    int64_t segmap_tblock_sizze_41111;
    
    segmap_tblock_sizze_41111 = *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_41099;
    
    int64_t segmap_usable_groups_41112 = sdiv_up64(m_39200, segmap_tblock_sizze_41111);
    
    if (memblock_alloc_device(ctx, &mem_42394, bytes_42376, "mem_42394")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_43153 = sext_i64_i32(sdiv_up64(m_39200, segmap_tblock_sizze_41111));
    
    {
        err = gpu_kernel_inner_SMJ_floatzisegmap_41115(ctx, segmap_usable_groups_41112, 1, 1, *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_41099, 1, 1, (int64_t) 0, m_39200, mem_42387.mem, mem_42394.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_42387, "mem_42387") != 0)
        return 1;
    
    bool cond_39251 = slt64((int64_t) 0, m_39200);
    bool y_39252 = slt64(m_39210, m_39200);
    bool bounds_check_39253 = zzero_leq_i_p_m_t_s_39211 && y_39252;
    bool loop_not_taken_39254 = !cond_39251;
    bool protect_assert_disj_39255 = bounds_check_39253 || loop_not_taken_39254;
    bool index_certs_39256;
    
    if (!protect_assert_disj_39255) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) m_39210, "] out of bounds for array of shape [", (long long) m_39200, "].", "-> #0  ftSMJ.fut:285:10-41\n   #1  ftSMJ.fut:327:7-328:73\n   #2  ftSMJ.fut:391:133-136\n   #3  ftSMJ.fut:380:1-391:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    if (cond_39251) {
        if (memblock_alloc_device(ctx, &mem_42396, (int64_t) 8, "mem_42396")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_floatzigpuseq_43162(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, m_39210, mem_42394.mem, mem_42396.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42397, &mem_42396, "mem_42396") != 0)
            return 1;
    } else {
        if (memblock_alloc_device(ctx, &mem_42395, (int64_t) 8, "mem_42395")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i64(ctx, mem_42395, (int64_t) 1, (int64_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42397, &mem_42395, "mem_42395") != 0)
            return 1;
    }
    if (cond_39251) {
        if (memblock_alloc_device(ctx, &mem_42399, (int64_t) 8, "mem_42399")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_floatzigpuseq_43168(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, m_39210, mem_42377.mem, mem_42399.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42400, &mem_42399, "mem_42399") != 0)
            return 1;
    } else {
        if (memblock_alloc_device(ctx, &mem_42398, (int64_t) 8, "mem_42398")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i64(ctx, mem_42398, (int64_t) 1, (int64_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42400, &mem_42398, "mem_42398") != 0)
            return 1;
    }
    
    bool zzero_39268 = scatter_psizze_32238 == (int64_t) 0;
    bool nonzzero_39269 = !zzero_39268;
    bool nonzzero_cert_39270;
    
    if (!nonzzero_39269) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftbasics.fut:66:23-29\n   #1  ftSMJ.fut:327:7-328:73\n   #2  ftSMJ.fut:391:133-136\n   #3  ftSMJ.fut:380:1-391:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    bool x_39335 = !empty_slice_39209;
    bool protect_assert_disj_39336 = empty_slice_39209 || bounds_check_39253;
    bool index_certs_39337;
    
    if (!protect_assert_disj_39336) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) m_39210, "] out of bounds for array of shape [", (long long) m_39200, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:327:7-328:73\n   #3  ftSMJ.fut:391:133-136\n   #4  ftSMJ.fut:380:1-391:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t m_f_res_39338;
    
    if (x_39335) {
        int64_t read_res_43304;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_43304, mem_42389.mem, m_39210 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_39521 = read_res_43304;
        
        m_f_res_39338 = x_39521;
    } else {
        m_f_res_39338 = (int64_t) 0;
    }
    
    int64_t m_39340;
    
    if (empty_slice_39209) {
        m_39340 = (int64_t) 0;
    } else {
        m_39340 = m_f_res_39338;
    }
    
    int64_t m_39350 = sub64(m_39340, (int64_t) 1);
    bool i_p_m_t_s_leq_w_39352 = slt64(m_39350, m_39200);
    bool zzero_leq_i_p_m_t_s_39351 = sle64((int64_t) 0, m_39350);
    bool y_39354 = zzero_leq_i_p_m_t_s_39351 && i_p_m_t_s_leq_w_39352;
    bool i_lte_j_39353 = sle64((int64_t) 0, m_39340);
    bool forwards_ok_39355 = i_lte_j_39353 && y_39354;
    bool eq_x_zz_39347 = (int64_t) 0 == m_f_res_39338;
    bool p_and_eq_x_y_39348 = x_39335 && eq_x_zz_39347;
    bool empty_slice_39349 = empty_slice_39209 || p_and_eq_x_y_39348;
    bool ok_or_empty_39356 = empty_slice_39349 || forwards_ok_39355;
    bool index_certs_39357;
    
    if (!ok_or_empty_39356) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_39340, "] out of bounds for array of shape [", (long long) m_39200, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:327:7-328:73\n   #3  ftSMJ.fut:391:133-136\n   #4  ftSMJ.fut:380:1-391:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_42401 = (int64_t) 8 * m_39340;
    
    if (memblock_alloc_device(ctx, &mem_42406, (int64_t) 8, "mem_42406")) {
        err = 1;
        goto cleanup;
    }
    {
        err = gpu_kernel_inner_SMJ_floatzigpuseq_43174(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, ext_mem_42397.mem, ext_mem_42400.mem, mem_42406.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (memblock_unref_device(ctx, &ext_mem_42397, "ext_mem_42397") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_42400, "ext_mem_42400") != 0)
        return 1;
    
    int64_t n_pairs_t_res_39261;
    
    if (cond_39251) {
        int64_t read_res_43305;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_43305, mem_42406.mem, (int64_t) 0 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_42197 = read_res_43305;
        
        n_pairs_t_res_39261 = x_42197;
    } else {
        n_pairs_t_res_39261 = (int64_t) 0;
    }
    if (memblock_unref_device(ctx, &mem_42406, "mem_42406") != 0)
        return 1;
    
    int64_t n_pairs_39262;
    
    if (cond_39251) {
        n_pairs_39262 = n_pairs_t_res_39261;
    } else {
        n_pairs_39262 = (int64_t) 0;
    }
    
    int64_t bytes_42407 = (int64_t) 4 * n_pairs_39262;
    int64_t bytes_42409 = (int64_t) 8 * n_pairs_39262;
    int64_t segmap_tblock_sizze_41126;
    
    segmap_tblock_sizze_41126 = *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_41125;
    
    int64_t num_tblocks_41128;
    int64_t max_num_tblocks_43180;
    
    max_num_tblocks_43180 = *ctx->tuning_params.inner_SMJ_floatzisegmap_num_tblocks_41127;
    num_tblocks_41128 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_39200, segmap_tblock_sizze_41126), max_num_tblocks_43180)));
    if (memblock_alloc_device(ctx, &mem_42402, bytes_42401, "mem_42402")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42402.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_42377.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_39340})) != 0)
        goto cleanup;
    if (memblock_alloc_device(ctx, &mem_42404, bytes_42401, "mem_42404")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42404.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_42394.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_39340})) != 0)
        goto cleanup;
    
    int64_t segmap_tblock_sizze_41134;
    
    segmap_tblock_sizze_41134 = *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_41133;
    
    int64_t num_tblocks_41136;
    int64_t max_num_tblocks_43181;
    
    max_num_tblocks_43181 = *ctx->tuning_params.inner_SMJ_floatzisegmap_num_tblocks_41135;
    num_tblocks_41136 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_39200, segmap_tblock_sizze_41134), max_num_tblocks_43181)));
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_43182 = sext_i64_i32(sdiv_up64(m_39200, segmap_tblock_sizze_41134));
    
    {
        err = gpu_kernel_inner_SMJ_floatzisegmap_41131(ctx, num_tblocks_41136, 1, 1, *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_41133, 1, 1, (int64_t) 0, m_39200, m_39340, num_tblocks_41136, virt_num_tblocks_43182, mem_42377.mem, mem_42389.mem, mem_42391.mem, mem_42394.mem, mem_42402.mem, mem_42404.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_42377, "mem_42377") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42389, "mem_42389") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42391, "mem_42391") != 0)
        return 1;
    
    bool cond_39367 = slt64((int64_t) 0, m_39340);
    int64_t segmap_tblock_sizze_41149;
    
    segmap_tblock_sizze_41149 = *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_41141;
    if (memblock_alloc_device(ctx, &mem_42408, bytes_42407, "mem_42408")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_f32(ctx, mem_42408, n_pairs_39262, 0.0F) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42410, bytes_42409, "mem_42410")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_42410, n_pairs_39262, (int64_t) -1) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42412, bytes_42409, "mem_42412")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_42412, n_pairs_39262, (int64_t) -1) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t zm_lhs_39266 = add64(scatter_psizze_32238, n_pairs_39262);
    int64_t zs_lhs_39267 = sub64(zm_lhs_39266, (int64_t) 1);
    int64_t m_39271 = sdiv64(zs_lhs_39267, scatter_psizze_32238);
    bool loop_cond_39272 = slt64((int64_t) 0, m_39271);
    bool partitioned_scatter_res_39273;
    int64_t partitioned_scatter_res_39277;
    bool loop_while_39278;
    int64_t p_39282;
    
    loop_while_39278 = loop_cond_39272;
    p_39282 = (int64_t) 0;
    while (loop_while_39278) {
        int64_t lower_bound_39283 = mul64(scatter_psizze_32238, p_39282);
        int64_t min_arg1_39284 = add64(scatter_psizze_32238, lower_bound_39283);
        int64_t min_res_39285 = smin64(n_pairs_39262, min_arg1_39284);
        int64_t j_m_i_39286 = sub64(min_res_39285, lower_bound_39283);
        bool empty_slice_39287 = j_m_i_39286 == (int64_t) 0;
        int64_t m_39288 = sub64(j_m_i_39286, (int64_t) 1);
        int64_t i_p_m_t_s_39289 = add64(lower_bound_39283, m_39288);
        bool zzero_leq_i_p_m_t_s_39290 = sle64((int64_t) 0, i_p_m_t_s_39289);
        bool i_p_m_t_s_leq_w_39291 = slt64(i_p_m_t_s_39289, n_pairs_39262);
        bool zzero_lte_i_39292 = sle64((int64_t) 0, lower_bound_39283);
        bool i_lte_j_39293 = sle64(lower_bound_39283, min_res_39285);
        bool y_39294 = i_p_m_t_s_leq_w_39291 && zzero_lte_i_39292;
        bool y_39295 = zzero_leq_i_p_m_t_s_39290 && y_39294;
        bool forwards_ok_39296 = i_lte_j_39293 && y_39295;
        bool ok_or_empty_39297 = empty_slice_39287 || forwards_ok_39296;
        bool index_certs_39298;
        
        if (!ok_or_empty_39297) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) lower_bound_39283, ":", (long long) min_res_39285, "] out of bounds for array of shape [", (long long) n_pairs_39262, "].", "-> #0  ftbasics.fut:72:25-56\n   #1  ftSMJ.fut:327:7-328:73\n   #2  ftSMJ.fut:391:133-136\n   #3  ftSMJ.fut:380:1-391:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t bytes_42422 = (int64_t) 4 * j_m_i_39286;
        int64_t bytes_42424 = (int64_t) 8 * j_m_i_39286;
        
        if (memblock_alloc_device(ctx, &mem_42423, bytes_42422, "mem_42423")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_42423.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_42408.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_39283, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_39286})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_42425, bytes_42424, "mem_42425")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42425.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_42410.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_39283, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_39286})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_42427, bytes_42424, "mem_42427")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42427.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_42412.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_39283, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_39286})) != 0)
            goto cleanup;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_43200 = sext_i64_i32(sdiv_up64(m_39200, segmap_tblock_sizze_41126));
        
        {
            err = gpu_kernel_inner_SMJ_floatzisegmap_41123(ctx, num_tblocks_41128, 1, 1, *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_41125, 1, 1, (int64_t) 0, m_39200, lower_bound_39283, min_res_39285, j_m_i_39286, num_tblocks_41128, virt_num_tblocks_43200, mem_42379.mem, mem_42381.mem, mem_42383.mem, mem_42394.mem, mem_42423.mem, mem_42425.mem, mem_42427.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t tmp_39312 = add64((int64_t) 1, p_39282);
        
        if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_42408.mem, lower_bound_39283, (int64_t []) {(int64_t) 1}, mem_42423.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_39286})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_42423, "mem_42423") != 0)
            return 1;
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42410.mem, lower_bound_39283, (int64_t []) {(int64_t) 1}, mem_42425.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_39286})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_42425, "mem_42425") != 0)
            return 1;
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42412.mem, lower_bound_39283, (int64_t []) {(int64_t) 1}, mem_42427.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_39286})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_42427, "mem_42427") != 0)
            return 1;
        
        bool loop_cond_39323 = slt64(tmp_39312, m_39271);
        bool loop_while_tmp_43195 = loop_cond_39323;
        int64_t p_tmp_43199 = tmp_39312;
        
        loop_while_39278 = loop_while_tmp_43195;
        p_39282 = p_tmp_43199;
    }
    partitioned_scatter_res_39273 = loop_while_39278;
    partitioned_scatter_res_39277 = p_39282;
    if (memblock_unref_device(ctx, &mem_42379, "mem_42379") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42381, "mem_42381") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42383, "mem_42383") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42394, "mem_42394") != 0)
        return 1;
    
    bool loop_cond_t_res_39368 = slt64(m_39200, n_pairs_39262);
    bool x_39369 = cond_39367 && loop_cond_t_res_39368;
    
    if (memblock_alloc_device(ctx, &mem_42453, (int64_t) 4, "mem_42453")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42454, (int64_t) 8, "mem_42454")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42455, (int64_t) 8, "mem_42455")) {
        err = 1;
        goto cleanup;
    }
    
    bool joinTups_to_joinPairs_InnerJoin_res_39370;
    int64_t joinTups_to_joinPairs_InnerJoin_res_39374;
    bool loop_while_39375;
    int64_t p_39379;
    
    if (memblock_set_device(ctx, &mem_param_42440, &mem_42408, "mem_42408") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_42443, &mem_42410, "mem_42410") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_42446, &mem_42412, "mem_42412") != 0)
        return 1;
    loop_while_39375 = x_39369;
    p_39379 = (int64_t) 0;
    while (loop_while_39375) {
        bool x_39380 = sle64((int64_t) 0, p_39379);
        bool y_39381 = slt64(p_39379, m_39340);
        bool bounds_check_39382 = x_39380 && y_39381;
        bool index_certs_39383;
        
        if (!bounds_check_39382) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) p_39379, "] out of bounds for array of shape [", (long long) m_39340, "].", "-> #0  ftSMJ.fut:300:13-42\n   #1  ftSMJ.fut:327:7-328:73\n   #2  ftSMJ.fut:391:133-136\n   #3  ftSMJ.fut:380:1-391:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t read_res_43306;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_43306, mem_42404.mem, p_39379 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t loopres_39384 = read_res_43306;
        int64_t read_res_43307;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_43307, mem_42402.mem, p_39379 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t loopres_39385 = read_res_43307;
        bool x_39386 = sle64((int64_t) 0, loopres_39384);
        bool y_39387 = slt64(loopres_39384, n_pairs_39262);
        bool bounds_check_39388 = x_39386 && y_39387;
        bool index_certs_39389;
        
        if (!bounds_check_39388) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) loopres_39384, "] out of bounds for array of shape [", (long long) n_pairs_39262, "].", "-> #0  ftSMJ.fut:302:52-61\n   #1  ftSMJ.fut:327:7-328:73\n   #2  ftSMJ.fut:391:133-136\n   #3  ftSMJ.fut:380:1-391:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t tmp_39400 = add64(loopres_39384, loopres_39385);
        bool empty_slice_39404 = loopres_39385 == (int64_t) 0;
        int64_t m_39405 = sub64(loopres_39385, (int64_t) 1);
        int64_t i_p_m_t_s_39406 = add64(loopres_39384, m_39405);
        bool zzero_leq_i_p_m_t_s_39407 = sle64((int64_t) 0, i_p_m_t_s_39406);
        bool i_p_m_t_s_leq_w_39408 = slt64(i_p_m_t_s_39406, n_pairs_39262);
        bool i_lte_j_39409 = sle64(loopres_39384, tmp_39400);
        bool y_39410 = x_39386 && i_p_m_t_s_leq_w_39408;
        bool y_39411 = zzero_leq_i_p_m_t_s_39407 && y_39410;
        bool forwards_ok_39412 = i_lte_j_39409 && y_39411;
        bool ok_or_empty_39413 = empty_slice_39404 || forwards_ok_39412;
        bool index_certs_39414;
        
        if (!ok_or_empty_39413) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) loopres_39384, ":", (long long) tmp_39400, "] out of bounds for array of shape [", (long long) n_pairs_39262, "].", "-> #0  ftSMJ.fut:306:14-55\n   #1  ftSMJ.fut:327:7-328:73\n   #2  ftSMJ.fut:391:133-136\n   #3  ftSMJ.fut:380:1-391:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t bytes_42456 = (int64_t) 4 * loopres_39385;
        int64_t bytes_42458 = (int64_t) 8 * loopres_39385;
        int64_t segmap_usable_groups_41150 = sdiv_up64(loopres_39385, segmap_tblock_sizze_41149);
        int64_t tmp_39399 = add64((int64_t) 1, p_39379);
        
        if (memblock_alloc_device(ctx, &mem_42448, bytes_42407, "mem_42448")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_42448.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_42440.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_39262})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_42450, bytes_42409, "mem_42450")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42450.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_42443.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_39262})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_42452, bytes_42409, "mem_42452")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42452.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_42446.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_39262})) != 0)
            goto cleanup;
        
        bool cond_39418 = slt64(tmp_39399, m_39340);
        bool x_39419 = loop_cond_t_res_39368 && cond_39418;
        
        {
            err = gpu_kernel_inner_SMJ_floatzigpuseq_43221(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, loopres_39384, mem_param_42440.mem, mem_param_42443.mem, mem_param_42446.mem, mem_42453.mem, mem_42454.mem, mem_42455.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_42457, bytes_42456, "mem_42457")) {
            err = 1;
            goto cleanup;
        }
        
        int64_t replicate_n_43227 = loopres_39385;
        int64_t tblock_sizze_43232;
        
        tblock_sizze_43232 = *ctx->tuning_params.inner_SMJ_floatzitblock_sizze_43232;
        
        int64_t virt_num_tblocks_43233 = sdiv_up64(replicate_n_43227, tblock_sizze_43232);
        int64_t num_tblocks_43234 = smin64(virt_num_tblocks_43233, (int64_t) 1048576);
        
        {
            err = gpu_kernel_inner_SMJ_floatzireplicate_43228(ctx, num_tblocks_43234, 1, 1, tblock_sizze_43232, 1, 1, (int64_t) 0, loopres_39385, replicate_n_43227, virt_num_tblocks_43233, num_tblocks_43234, mem_42453.mem, mem_42457.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_42459, bytes_42458, "mem_42459")) {
            err = 1;
            goto cleanup;
        }
        
        int64_t replicate_n_43247 = loopres_39385;
        int64_t tblock_sizze_43252;
        
        tblock_sizze_43252 = *ctx->tuning_params.inner_SMJ_floatzitblock_sizze_43252;
        
        int64_t virt_num_tblocks_43253 = sdiv_up64(replicate_n_43247, tblock_sizze_43252);
        int64_t num_tblocks_43254 = smin64(virt_num_tblocks_43253, (int64_t) 1048576);
        
        {
            err = gpu_kernel_inner_SMJ_floatzireplicate_43248(ctx, num_tblocks_43254, 1, 1, tblock_sizze_43252, 1, 1, (int64_t) 0, loopres_39385, replicate_n_43247, virt_num_tblocks_43253, num_tblocks_43254, mem_42454.mem, mem_42459.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_43267 = sext_i64_i32(sdiv_up64(loopres_39385, segmap_tblock_sizze_41149));
        
        {
            err = gpu_kernel_inner_SMJ_floatzisegmap_41153(ctx, segmap_usable_groups_41150, 1, 1, *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_41141, 1, 1, (int64_t) 0, loopres_39384, loopres_39385, mem_42452.mem, mem_42455.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_42448.mem, loopres_39384, (int64_t []) {(int64_t) 1}, mem_42457.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {loopres_39385})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_42457, "mem_42457") != 0)
            return 1;
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42450.mem, loopres_39384, (int64_t []) {(int64_t) 1}, mem_42459.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {loopres_39385})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_42459, "mem_42459") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_43213, &mem_42448, "mem_42448") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_43214, &mem_42450, "mem_42450") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_43215, &mem_42452, "mem_42452") != 0)
            return 1;
        
        bool loop_while_tmp_43216 = x_39419;
        int64_t p_tmp_43220 = tmp_39399;
        
        if (memblock_set_device(ctx, &mem_param_42440, &mem_param_tmp_43213, "mem_param_tmp_43213") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_42443, &mem_param_tmp_43214, "mem_param_tmp_43214") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_42446, &mem_param_tmp_43215, "mem_param_tmp_43215") != 0)
            return 1;
        loop_while_39375 = loop_while_tmp_43216;
        p_39379 = p_tmp_43220;
    }
    if (memblock_set_device(ctx, &ext_mem_42471, &mem_param_42440, "mem_param_42440") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_42470, &mem_param_42443, "mem_param_42443") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_42469, &mem_param_42446, "mem_param_42446") != 0)
        return 1;
    joinTups_to_joinPairs_InnerJoin_res_39370 = loop_while_39375;
    joinTups_to_joinPairs_InnerJoin_res_39374 = p_39379;
    if (memblock_unref_device(ctx, &mem_42402, "mem_42402") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42404, "mem_42404") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42408, "mem_42408") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42410, "mem_42410") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42412, "mem_42412") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42453, "mem_42453") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42454, "mem_42454") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42455, "mem_42455") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_42473, bytes_42407, "mem_42473")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_42473.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42471.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_39262})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_42471, "ext_mem_42471") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_42475, bytes_42409, "mem_42475")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42475.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42470.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_39262})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_42470, "ext_mem_42470") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_42477, bytes_42409, "mem_42477")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42477.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42469.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_39262})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_42469, "ext_mem_42469") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_42706, &mem_42475, "mem_42475") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_42707, &mem_42477, "mem_42477") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_42708, &mem_42473, "mem_42473") != 0)
        return 1;
    prim_out_42709 = n_pairs_39262;
    if (memblock_set_device(ctx, &*mem_out_p_43297, &mem_out_42706, "mem_out_42706") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_43298, &mem_out_42707, "mem_out_42707") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_43299, &mem_out_42708, "mem_out_42708") != 0)
        return 1;
    *out_prim_out_43300 = prim_out_42709;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_42477, "mem_42477") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42475, "mem_42475") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42473, "mem_42473") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_43215, "mem_param_tmp_43215") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_43214, "mem_param_tmp_43214") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_43213, "mem_param_tmp_43213") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42459, "mem_42459") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42457, "mem_42457") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42452, "mem_42452") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42450, "mem_42450") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42448, "mem_42448") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42446, "mem_param_42446") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42443, "mem_param_42443") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42440, "mem_param_42440") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42469, "ext_mem_42469") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42470, "ext_mem_42470") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42471, "ext_mem_42471") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42455, "mem_42455") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42454, "mem_42454") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42453, "mem_42453") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42427, "mem_42427") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42425, "mem_42425") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42423, "mem_42423") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42412, "mem_42412") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42410, "mem_42410") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42408, "mem_42408") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42404, "mem_42404") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42402, "mem_42402") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42406, "mem_42406") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42398, "mem_42398") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42399, "mem_42399") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42400, "ext_mem_42400") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42395, "mem_42395") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42396, "mem_42396") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42397, "ext_mem_42397") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42394, "mem_42394") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_43016, "incprefixes_mem_43016") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_43014, "aggregates_mem_43014") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_43012, "incprefixes_mem_43012") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_43010, "aggregates_mem_43010") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_43008, "status_flags_mem_43008") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42391, "mem_42391") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42389, "mem_42389") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42387, "mem_42387") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42383, "mem_42383") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42381, "mem_42381") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42379, "mem_42379") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42377, "mem_42377") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_42875, "incprefixes_mem_42875") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_42873, "aggregates_mem_42873") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_42851, "status_flags_mem_42851") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42375, "mem_42375") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42373, "mem_42373") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_42763, "mem_param_tmp_42763") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_42762, "mem_param_tmp_42762") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42352, "mem_42352") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42350, "mem_42350") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42285, "mem_42285") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42283, "mem_42283") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42346, "mem_42346") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42344, "mem_42344") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42347, "ext_mem_42347") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42348, "ext_mem_42348") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42224, "ext_mem_42224") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42355, "ext_mem_42355") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42358, "ext_mem_42358") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42223, "mem_42223") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42361, "ext_mem_42361") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42364, "ext_mem_42364") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42221, "ext_mem_42221") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42220, "ext_mem_42220") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42217, "mem_param_42217") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42214, "mem_param_42214") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42369, "ext_mem_42369") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42370, "ext_mem_42370") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42222, "mem_42222") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42219, "mem_42219") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42218, "mem_42218") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42209, "mem_42209") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42210, "mem_42210") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42211, "ext_mem_42211") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42206, "mem_42206") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42207, "mem_42207") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42208, "ext_mem_42208") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42205, "mem_42205") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42203, "mem_42203") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42201, "ext_mem_42201") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_42708, "mem_out_42708") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_42707, "mem_out_42707") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_42706, "mem_out_42706") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_inner_SMJ_int(struct futhark_context *ctx, struct memblock_device *mem_out_p_43308, struct memblock_device *mem_out_p_43309, struct memblock_device *mem_out_p_43310, int64_t *out_prim_out_43311, struct memblock_device tR_mem_42199, struct memblock_device tS_mem_42200, int64_t nR_27729, int64_t nS_27730, int64_t offset_R_27733, int64_t offset_S_27734, int64_t partitionsPerWindow_27735, int64_t numberOfWindows_27736, int64_t extParallelism_27737, int64_t scatter_psizze_27738)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_42477;
    
    mem_42477.references = NULL;
    
    struct memblock_device mem_42475;
    
    mem_42475.references = NULL;
    
    struct memblock_device mem_42473;
    
    mem_42473.references = NULL;
    
    struct memblock_device mem_param_tmp_43195;
    
    mem_param_tmp_43195.references = NULL;
    
    struct memblock_device mem_param_tmp_43194;
    
    mem_param_tmp_43194.references = NULL;
    
    struct memblock_device mem_param_tmp_43193;
    
    mem_param_tmp_43193.references = NULL;
    
    struct memblock_device mem_42459;
    
    mem_42459.references = NULL;
    
    struct memblock_device mem_42457;
    
    mem_42457.references = NULL;
    
    struct memblock_device mem_42452;
    
    mem_42452.references = NULL;
    
    struct memblock_device mem_42450;
    
    mem_42450.references = NULL;
    
    struct memblock_device mem_42448;
    
    mem_42448.references = NULL;
    
    struct memblock_device mem_param_42446;
    
    mem_param_42446.references = NULL;
    
    struct memblock_device mem_param_42443;
    
    mem_param_42443.references = NULL;
    
    struct memblock_device mem_param_42440;
    
    mem_param_42440.references = NULL;
    
    struct memblock_device ext_mem_42469;
    
    ext_mem_42469.references = NULL;
    
    struct memblock_device ext_mem_42470;
    
    ext_mem_42470.references = NULL;
    
    struct memblock_device ext_mem_42471;
    
    ext_mem_42471.references = NULL;
    
    struct memblock_device mem_42455;
    
    mem_42455.references = NULL;
    
    struct memblock_device mem_42454;
    
    mem_42454.references = NULL;
    
    struct memblock_device mem_42453;
    
    mem_42453.references = NULL;
    
    struct memblock_device mem_42427;
    
    mem_42427.references = NULL;
    
    struct memblock_device mem_42425;
    
    mem_42425.references = NULL;
    
    struct memblock_device mem_42423;
    
    mem_42423.references = NULL;
    
    struct memblock_device mem_42412;
    
    mem_42412.references = NULL;
    
    struct memblock_device mem_42410;
    
    mem_42410.references = NULL;
    
    struct memblock_device mem_42408;
    
    mem_42408.references = NULL;
    
    struct memblock_device mem_42404;
    
    mem_42404.references = NULL;
    
    struct memblock_device mem_42402;
    
    mem_42402.references = NULL;
    
    struct memblock_device mem_42406;
    
    mem_42406.references = NULL;
    
    struct memblock_device mem_42398;
    
    mem_42398.references = NULL;
    
    struct memblock_device mem_42399;
    
    mem_42399.references = NULL;
    
    struct memblock_device ext_mem_42400;
    
    ext_mem_42400.references = NULL;
    
    struct memblock_device mem_42395;
    
    mem_42395.references = NULL;
    
    struct memblock_device mem_42396;
    
    mem_42396.references = NULL;
    
    struct memblock_device ext_mem_42397;
    
    ext_mem_42397.references = NULL;
    
    struct memblock_device mem_42394;
    
    mem_42394.references = NULL;
    
    struct memblock_device incprefixes_mem_42996;
    
    incprefixes_mem_42996.references = NULL;
    
    struct memblock_device aggregates_mem_42994;
    
    aggregates_mem_42994.references = NULL;
    
    struct memblock_device incprefixes_mem_42992;
    
    incprefixes_mem_42992.references = NULL;
    
    struct memblock_device aggregates_mem_42990;
    
    aggregates_mem_42990.references = NULL;
    
    struct memblock_device status_flags_mem_42988;
    
    status_flags_mem_42988.references = NULL;
    
    struct memblock_device mem_42391;
    
    mem_42391.references = NULL;
    
    struct memblock_device mem_42389;
    
    mem_42389.references = NULL;
    
    struct memblock_device mem_42387;
    
    mem_42387.references = NULL;
    
    struct memblock_device mem_42383;
    
    mem_42383.references = NULL;
    
    struct memblock_device mem_42381;
    
    mem_42381.references = NULL;
    
    struct memblock_device mem_42379;
    
    mem_42379.references = NULL;
    
    struct memblock_device mem_42377;
    
    mem_42377.references = NULL;
    
    struct memblock_device incprefixes_mem_42875;
    
    incprefixes_mem_42875.references = NULL;
    
    struct memblock_device aggregates_mem_42873;
    
    aggregates_mem_42873.references = NULL;
    
    struct memblock_device status_flags_mem_42851;
    
    status_flags_mem_42851.references = NULL;
    
    struct memblock_device mem_42375;
    
    mem_42375.references = NULL;
    
    struct memblock_device mem_42373;
    
    mem_42373.references = NULL;
    
    struct memblock_device mem_param_tmp_42763;
    
    mem_param_tmp_42763.references = NULL;
    
    struct memblock_device mem_param_tmp_42762;
    
    mem_param_tmp_42762.references = NULL;
    
    struct memblock_device mem_42352;
    
    mem_42352.references = NULL;
    
    struct memblock_device mem_42350;
    
    mem_42350.references = NULL;
    
    struct memblock_device mem_42285;
    
    mem_42285.references = NULL;
    
    struct memblock_device mem_42283;
    
    mem_42283.references = NULL;
    
    struct memblock_device mem_42346;
    
    mem_42346.references = NULL;
    
    struct memblock_device mem_42344;
    
    mem_42344.references = NULL;
    
    struct memblock_device ext_mem_42347;
    
    ext_mem_42347.references = NULL;
    
    struct memblock_device ext_mem_42348;
    
    ext_mem_42348.references = NULL;
    
    struct memblock_device ext_mem_42224;
    
    ext_mem_42224.references = NULL;
    
    struct memblock_device ext_mem_42355;
    
    ext_mem_42355.references = NULL;
    
    struct memblock_device ext_mem_42358;
    
    ext_mem_42358.references = NULL;
    
    struct memblock_device mem_42223;
    
    mem_42223.references = NULL;
    
    struct memblock_device ext_mem_42361;
    
    ext_mem_42361.references = NULL;
    
    struct memblock_device ext_mem_42364;
    
    ext_mem_42364.references = NULL;
    
    struct memblock_device ext_mem_42221;
    
    ext_mem_42221.references = NULL;
    
    struct memblock_device ext_mem_42220;
    
    ext_mem_42220.references = NULL;
    
    struct memblock_device mem_param_42217;
    
    mem_param_42217.references = NULL;
    
    struct memblock_device mem_param_42214;
    
    mem_param_42214.references = NULL;
    
    struct memblock_device ext_mem_42369;
    
    ext_mem_42369.references = NULL;
    
    struct memblock_device ext_mem_42370;
    
    ext_mem_42370.references = NULL;
    
    struct memblock_device mem_42222;
    
    mem_42222.references = NULL;
    
    struct memblock_device mem_42219;
    
    mem_42219.references = NULL;
    
    struct memblock_device mem_42218;
    
    mem_42218.references = NULL;
    
    struct memblock_device mem_42209;
    
    mem_42209.references = NULL;
    
    struct memblock_device mem_42210;
    
    mem_42210.references = NULL;
    
    struct memblock_device ext_mem_42211;
    
    ext_mem_42211.references = NULL;
    
    struct memblock_device mem_42206;
    
    mem_42206.references = NULL;
    
    struct memblock_device mem_42207;
    
    mem_42207.references = NULL;
    
    struct memblock_device ext_mem_42208;
    
    ext_mem_42208.references = NULL;
    
    struct memblock_device mem_42205;
    
    mem_42205.references = NULL;
    
    struct memblock_device mem_42203;
    
    mem_42203.references = NULL;
    
    struct memblock_device ext_mem_42201;
    
    ext_mem_42201.references = NULL;
    
    struct memblock_device mem_out_42708;
    
    mem_out_42708.references = NULL;
    
    struct memblock_device mem_out_42707;
    
    mem_out_42707.references = NULL;
    
    struct memblock_device mem_out_42706;
    
    mem_out_42706.references = NULL;
    
    struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
    struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
    struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
    struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
    struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
    int64_t prim_out_42709;
    int64_t zm_lhs_39067 = add64(nR_27729, extParallelism_27737);
    int64_t zs_lhs_39068 = sub64(zm_lhs_39067, (int64_t) 1);
    bool zzero_39069 = extParallelism_27737 == (int64_t) 0;
    bool nonzzero_39070 = !zzero_39069;
    bool nonzzero_cert_39071;
    
    if (!nonzzero_39070) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftSMJ.fut:48:39-55\n   #1  ftSMJ.fut:327:87-89\n   #2  ftSMJ.fut:365:133-136\n   #3  ftSMJ.fut:354:1-365:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t numIter_39072 = sdiv64(zs_lhs_39068, extParallelism_27737);
    
    if (futrts_indicesWithIncrement_9701(ctx, &ext_mem_42201, tR_mem_42199, nR_27729, offset_R_27733) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t bytes_42202 = (int64_t) 8 * nR_27729;
    
    if (memblock_alloc_device(ctx, &mem_42203, bytes_42202, "mem_42203")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_42203, nR_27729, (int64_t) -1) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42205, bytes_42202, "mem_42205")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_42205, nR_27729, (int64_t) 0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    bool loop_cond_39076 = slt64((int64_t) 0, numIter_39072);
    bool cond_39077 = slt64((int64_t) 0, nS_27730);
    int64_t tmp_39078 = sub64(nS_27730, (int64_t) 1);
    bool loop_not_taken_39079 = !cond_39077;
    bool loop_not_taken_39080 = !loop_cond_39076;
    bool x_39081 = sle64((int64_t) 0, tmp_39078);
    bool y_39082 = slt64(tmp_39078, nS_27730);
    bool protect_cond_conj_39083 = loop_cond_39076 && cond_39077;
    
    if (protect_cond_conj_39083) {
        if (memblock_alloc_device(ctx, &mem_42207, (int64_t) 4, "mem_42207")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_intzigpuseq_42730(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, tS_mem_42200.mem, mem_42207.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42208, &mem_42207, "mem_42207") != 0)
            return 1;
    } else {
        if (memblock_alloc_device(ctx, &mem_42206, (int64_t) 4, "mem_42206")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i32(ctx, mem_42206, (int64_t) 1, 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42208, &mem_42206, "mem_42206") != 0)
            return 1;
    }
    
    bool bounds_check_39086 = x_39081 && y_39082;
    bool protect_assert_disj_39087 = loop_not_taken_39079 || bounds_check_39086;
    bool protect_assert_disj_39088 = loop_not_taken_39080 || protect_assert_disj_39087;
    bool index_certs_39089;
    
    if (!protect_assert_disj_39088) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) tmp_39078, "] out of bounds for array of shape [", (long long) nS_27730, "].", "-> #0  ftSMJ.fut:60:34-42\n   #1  ftSMJ.fut:327:87-89\n   #2  ftSMJ.fut:365:133-136\n   #3  ftSMJ.fut:354:1-365:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    if (protect_cond_conj_39083) {
        if (memblock_alloc_device(ctx, &mem_42210, (int64_t) 4, "mem_42210")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_intzigpuseq_42756(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, tmp_39078, tS_mem_42200.mem, mem_42210.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42211, &mem_42210, "mem_42210") != 0)
            return 1;
    } else {
        if (memblock_alloc_device(ctx, &mem_42209, (int64_t) 4, "mem_42209")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i32(ctx, mem_42209, (int64_t) 1, 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42211, &mem_42209, "mem_42209") != 0)
            return 1;
    }
    if (memblock_alloc_device(ctx, &mem_42218, (int64_t) 4, "mem_42218")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42219, (int64_t) 4, "mem_42219")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42222, (int64_t) 1, "mem_42222")) {
        err = 1;
        goto cleanup;
    }
    
    int64_t ext_42368;
    int64_t ext_42367;
    int64_t ext_42366;
    int64_t ext_42365;
    bool defunc_0_find_joinTuples_res_39092;
    int64_t defunc_0_find_joinTuples_res_39093;
    bool loop_while_39096;
    int64_t p_39097;
    int64_t ctx_param_ext_42212;
    int64_t ctx_param_ext_42213;
    int64_t ctx_param_ext_42215;
    int64_t ctx_param_ext_42216;
    
    if (memblock_set_device(ctx, &mem_param_42214, &mem_42205, "mem_42205") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_42217, &mem_42203, "mem_42203") != 0)
        return 1;
    ctx_param_ext_42212 = (int64_t) 0;
    ctx_param_ext_42213 = (int64_t) 1;
    ctx_param_ext_42215 = (int64_t) 0;
    ctx_param_ext_42216 = (int64_t) 1;
    loop_while_39096 = loop_cond_39076;
    p_39097 = (int64_t) 0;
    while (loop_while_39096) {
        int64_t start_39100 = mul64(extParallelism_27737, p_39097);
        int64_t min_arg1_39101 = sub64(nR_27729, start_39100);
        int64_t min_res_39102 = smin64(extParallelism_27737, min_arg1_39101);
        int64_t iter_R_39103 = add64(start_39100, min_res_39102);
        bool empty_slice_39104 = min_res_39102 == (int64_t) 0;
        int64_t m_39105 = sub64(min_res_39102, (int64_t) 1);
        int64_t i_p_m_t_s_39106 = add64(start_39100, m_39105);
        bool zzero_leq_i_p_m_t_s_39107 = sle64((int64_t) 0, i_p_m_t_s_39106);
        bool i_p_m_t_s_leq_w_39108 = slt64(i_p_m_t_s_39106, nR_27729);
        bool zzero_lte_i_39109 = sle64((int64_t) 0, start_39100);
        bool i_lte_j_39110 = sle64(start_39100, iter_R_39103);
        bool y_39111 = i_p_m_t_s_leq_w_39108 && zzero_lte_i_39109;
        bool y_39112 = zzero_leq_i_p_m_t_s_39107 && y_39111;
        bool forwards_ok_39113 = i_lte_j_39110 && y_39112;
        bool ok_or_empty_39114 = empty_slice_39104 || forwards_ok_39113;
        bool index_certs_39115;
        
        if (!ok_or_empty_39114) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) start_39100, ":", (long long) iter_R_39103, "] out of bounds for array of shape [", (long long) nR_27729, "].", "-> #0  ftSMJ.fut:55:20-49\n   #1  ftSMJ.fut:327:87-89\n   #2  ftSMJ.fut:365:133-136\n   #3  ftSMJ.fut:354:1-365:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        bool y_39121 = slt64(m_39105, min_res_39102);
        bool x_39120 = sle64((int64_t) 0, m_39105);
        bool bounds_check_39122 = x_39120 && y_39121;
        bool index_certs_39123;
        
        if (!bounds_check_39122) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) m_39105, "] out of bounds for array of shape [", (long long) min_res_39102, "].", "-> #0  ftSMJ.fut:58:21-40\n   #1  ftSMJ.fut:327:87-89\n   #2  ftSMJ.fut:365:133-136\n   #3  ftSMJ.fut:354:1-365:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        bool y_39117 = slt64((int64_t) 0, min_res_39102);
        bool index_certs_39118;
        
        if (!y_39117) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) (int64_t) 0, "] out of bounds for array of shape [", (long long) min_res_39102, "].", "-> #0  ftSMJ.fut:57:21-30\n   #1  ftSMJ.fut:327:87-89\n   #2  ftSMJ.fut:365:133-136\n   #3  ftSMJ.fut:354:1-365:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_intzigpuseq_42772(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, start_39100, i_p_m_t_s_39106, tR_mem_42199.mem, mem_42218.mem, mem_42219.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (cond_39077) {
            if (memblock_set_device(ctx, &ext_mem_42220, &ext_mem_42211, "ext_mem_42211") != 0)
                return 1;
        } else if (memblock_set_device(ctx, &ext_mem_42220, &mem_42218, "mem_42218") != 0)
            return 1;
        if (cond_39077) {
            if (memblock_set_device(ctx, &ext_mem_42221, &ext_mem_42208, "ext_mem_42208") != 0)
                return 1;
        } else if (memblock_set_device(ctx, &ext_mem_42221, &mem_42219, "mem_42219") != 0)
            return 1;
        {
            err = gpu_kernel_inner_SMJ_intzigpuseq_42778(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, mem_42219.mem, ext_mem_42220.mem, mem_42222.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_unref_device(ctx, &ext_mem_42220, "ext_mem_42220") != 0)
            return 1;
        
        bool read_res_43312;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_43312, mem_42222.mem, (int64_t) 0 * sizeof(bool), sizeof(bool))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        bool defunc_0_gt_res_39127 = read_res_43312;
        int64_t ext_42363;
        int64_t ext_42362;
        int64_t ext_42360;
        int64_t ext_42359;
        int64_t loopres_39128;
        
        if (defunc_0_gt_res_39127) {
            if (memblock_set_device(ctx, &ext_mem_42364, &mem_param_42214, "mem_param_42214") != 0)
                return 1;
            ext_42363 = ctx_param_ext_42212;
            ext_42362 = ctx_param_ext_42213;
            if (memblock_set_device(ctx, &ext_mem_42361, &mem_param_42217, "mem_param_42217") != 0)
                return 1;
            ext_42360 = ctx_param_ext_42215;
            ext_42359 = ctx_param_ext_42216;
            loopres_39128 = numIter_39072;
        } else {
            if (memblock_alloc_device(ctx, &mem_42223, (int64_t) 1, "mem_42223")) {
                err = 1;
                goto cleanup;
            }
            {
                err = gpu_kernel_inner_SMJ_intzigpuseq_42784(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, mem_42218.mem, ext_mem_42221.mem, mem_42223.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            
            bool read_res_43313;
            
            if ((err = gpu_scalar_from_device(ctx, &read_res_43313, mem_42223.mem, (int64_t) 0 * sizeof(bool), sizeof(bool))) != 0)
                goto cleanup;
            if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                err = 1;
                goto cleanup;
            }
            
            bool defunc_0_gt_res_39131 = read_res_43313;
            
            if (memblock_unref_device(ctx, &mem_42223, "mem_42223") != 0)
                return 1;
            
            int64_t ext_42357;
            
            if (defunc_0_gt_res_39131) {
                ext_42357 = ctx_param_ext_42212;
            } else {
                ext_42357 = (int64_t) 0;
            }
            
            int64_t ext_42356;
            
            if (defunc_0_gt_res_39131) {
                ext_42356 = ctx_param_ext_42213;
            } else {
                ext_42356 = (int64_t) 1;
            }
            
            int64_t ext_42354;
            
            if (defunc_0_gt_res_39131) {
                ext_42354 = ctx_param_ext_42215;
            } else {
                ext_42354 = (int64_t) 0;
            }
            
            int64_t ext_42353;
            
            if (defunc_0_gt_res_39131) {
                ext_42353 = ctx_param_ext_42216;
            } else {
                ext_42353 = (int64_t) 1;
            }
            
            int64_t loopres_f_res_39132;
            
            if (defunc_0_gt_res_39131) {
                int64_t tmp_39506 = add64((int64_t) 1, p_39097);
                
                if (memblock_set_device(ctx, &ext_mem_42358, &mem_param_42214, "mem_param_42214") != 0)
                    return 1;
                if (memblock_set_device(ctx, &ext_mem_42355, &mem_param_42217, "mem_param_42217") != 0)
                    return 1;
                loopres_f_res_39132 = tmp_39506;
            } else {
                if (futrts_indicesWithIncrement_9701(ctx, &ext_mem_42224, tS_mem_42200, nS_27730, offset_S_27734) != 0) {
                    err = 1;
                    goto cleanup;
                }
                
                bool suff_outer_par_40377;
                
                suff_outer_par_40377 = *ctx->tuning_params.inner_SMJ_intzisuff_outer_par_0 <= min_res_39102;
                if (ctx->logging)
                    fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "inner_SMJ_int.suff_outer_par_0", (long) min_res_39102, suff_outer_par_40377 ? "true" : "false");
                
                int64_t tile_sizze_41780;
                
                tile_sizze_41780 = *ctx->tuning_params.inner_SMJ_intzitile_sizze_41779;
                
                int64_t tile_sizze_41425;
                
                tile_sizze_41425 = *ctx->tuning_params.inner_SMJ_intzitile_sizze_41424;
                
                int64_t num_whole_tiles_41796 = squot_safe64(nS_27730, tile_sizze_41780);
                int64_t residual_input_42020 = srem_safe64(nS_27730, tile_sizze_41780);
                bool cond_42021 = residual_input_42020 == (int64_t) 0;
                int64_t binop_x_42037 = tile_sizze_41780 * num_whole_tiles_41796;
                int64_t bytes_42282 = (int64_t) 8 * min_res_39102;
                int64_t bytes_42245 = (int64_t) 8 * tile_sizze_41780;
                int64_t bytes_42247 = (int64_t) 4 * tile_sizze_41780;
                int64_t num_whole_tiles_41441 = squot_safe64(nS_27730, tile_sizze_41425);
                int64_t residual_input_41665 = srem_safe64(nS_27730, tile_sizze_41425);
                bool cond_41666 = residual_input_41665 == (int64_t) 0;
                int64_t binop_x_41682 = tile_sizze_41425 * num_whole_tiles_41441;
                int64_t bytes_42306 = (int64_t) 8 * tile_sizze_41425;
                int64_t bytes_42308 = (int64_t) 4 * tile_sizze_41425;
                int64_t shared_memory_capacity_42842;
                
                shared_memory_capacity_42842 = ctx->max_shared_memory;
                if (suff_outer_par_40377 && sle64(sdiv_up64(bytes_42306, (int64_t) 8) * (int64_t) 8 + sdiv_up64(bytes_42308, (int64_t) 8) * (int64_t) 8 + sdiv_up64(bytes_42306, (int64_t) 8) * (int64_t) 8, shared_memory_capacity_42842)) {
                    int64_t ldim_41426 = sdiv_up64(min_res_39102, tile_sizze_41425);
                    
                    if (memblock_alloc_device(ctx, &mem_42344, bytes_42282, "mem_42344")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &mem_42346, bytes_42282, "mem_42346")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t num_chunks_42790 = sext_i64_i32(sdiv_up64(tile_sizze_41425, tile_sizze_41425));
                    int32_t virt_num_tblocks_42791 = sext_i64_i32(ldim_41426);
                    
                    {
                        err = gpu_kernel_inner_SMJ_intzisegmap_intrablock_41423(ctx, ldim_41426, 1, 1, *ctx->tuning_params.inner_SMJ_intzitile_sizze_41424, 1, 1, bytes_42306 + srem64((int64_t) 8 - srem64(bytes_42306, (int64_t) 8), (int64_t) 8) + (bytes_42308 + srem64((int64_t) 8 - srem64(bytes_42308, (int64_t) 8), (int64_t) 8)) + (bytes_42306 + srem64((int64_t) 8 - srem64(bytes_42306, (int64_t) 8), (int64_t) 8)), nS_27730, start_39100, min_res_39102, ldim_41426, num_whole_tiles_41441, residual_input_41665, cond_41666, binop_x_41682, tR_mem_42199.mem, tS_mem_42200.mem, ext_mem_42224.mem, mem_42344.mem, mem_42346.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_set_device(ctx, &ext_mem_42348, &mem_42344, "mem_42344") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &ext_mem_42347, &mem_42346, "mem_42346") != 0)
                        return 1;
                } else {
                    int64_t ldim_41781 = sdiv_up64(min_res_39102, tile_sizze_41780);
                    
                    if (memblock_alloc_device(ctx, &mem_42283, bytes_42282, "mem_42283")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &mem_42285, bytes_42282, "mem_42285")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t num_chunks_42816 = sext_i64_i32(sdiv_up64(tile_sizze_41780, tile_sizze_41780));
                    int32_t virt_num_tblocks_42817 = sext_i64_i32(ldim_41781);
                    
                    {
                        err = gpu_kernel_inner_SMJ_intzisegmap_intrablock_41778(ctx, ldim_41781, 1, 1, *ctx->tuning_params.inner_SMJ_intzitile_sizze_41779, 1, 1, bytes_42245 + srem64((int64_t) 8 - srem64(bytes_42245, (int64_t) 8), (int64_t) 8) + (bytes_42247 + srem64((int64_t) 8 - srem64(bytes_42247, (int64_t) 8), (int64_t) 8)) + (bytes_42245 + srem64((int64_t) 8 - srem64(bytes_42245, (int64_t) 8), (int64_t) 8)), nS_27730, start_39100, min_res_39102, ldim_41781, num_whole_tiles_41796, residual_input_42020, cond_42021, binop_x_42037, tR_mem_42199.mem, tS_mem_42200.mem, ext_mem_42224.mem, mem_42283.mem, mem_42285.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_set_device(ctx, &ext_mem_42348, &mem_42283, "mem_42283") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &ext_mem_42347, &mem_42285, "mem_42285") != 0)
                        return 1;
                }
                if (memblock_unref_device(ctx, &ext_mem_42224, "ext_mem_42224") != 0)
                    return 1;
                if (memblock_alloc_device(ctx, &mem_42350, bytes_42202, "mem_42350")) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42350.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_42217.mem, ctx_param_ext_42215, (int64_t []) {ctx_param_ext_42216}, (int64_t []) {nR_27729})) != 0)
                    goto cleanup;
                if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42350.mem, start_39100, (int64_t []) {(int64_t) 1}, ext_mem_42348.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {min_res_39102})) != 0)
                    goto cleanup;
                if (memblock_unref_device(ctx, &ext_mem_42348, "ext_mem_42348") != 0)
                    return 1;
                if (memblock_alloc_device(ctx, &mem_42352, bytes_42202, "mem_42352")) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42352.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_42214.mem, ctx_param_ext_42212, (int64_t []) {ctx_param_ext_42213}, (int64_t []) {nR_27729})) != 0)
                    goto cleanup;
                if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42352.mem, start_39100, (int64_t []) {(int64_t) 1}, ext_mem_42347.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {min_res_39102})) != 0)
                    goto cleanup;
                if (memblock_unref_device(ctx, &ext_mem_42347, "ext_mem_42347") != 0)
                    return 1;
                
                int64_t tmp_39179 = add64((int64_t) 1, p_39097);
                
                if (memblock_set_device(ctx, &ext_mem_42358, &mem_42352, "mem_42352") != 0)
                    return 1;
                if (memblock_set_device(ctx, &ext_mem_42355, &mem_42350, "mem_42350") != 0)
                    return 1;
                loopres_f_res_39132 = tmp_39179;
            }
            if (memblock_set_device(ctx, &ext_mem_42364, &ext_mem_42358, "ext_mem_42358") != 0)
                return 1;
            ext_42363 = ext_42357;
            ext_42362 = ext_42356;
            if (memblock_set_device(ctx, &ext_mem_42361, &ext_mem_42355, "ext_mem_42355") != 0)
                return 1;
            ext_42360 = ext_42354;
            ext_42359 = ext_42353;
            loopres_39128 = loopres_f_res_39132;
        }
        if (memblock_unref_device(ctx, &ext_mem_42221, "ext_mem_42221") != 0)
            return 1;
        
        bool loop_cond_39180 = slt64(loopres_39128, numIter_39072);
        
        if (memblock_set_device(ctx, &mem_param_tmp_42762, &ext_mem_42364, "ext_mem_42364") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_42763, &ext_mem_42361, "ext_mem_42361") != 0)
            return 1;
        
        int64_t ctx_param_ext_tmp_42764 = ext_42363;
        int64_t ctx_param_ext_tmp_42765 = ext_42362;
        int64_t ctx_param_ext_tmp_42766 = ext_42360;
        int64_t ctx_param_ext_tmp_42767 = ext_42359;
        bool loop_while_tmp_42768 = loop_cond_39180;
        int64_t p_tmp_42769 = loopres_39128;
        
        if (memblock_set_device(ctx, &mem_param_42214, &mem_param_tmp_42762, "mem_param_tmp_42762") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_42217, &mem_param_tmp_42763, "mem_param_tmp_42763") != 0)
            return 1;
        ctx_param_ext_42212 = ctx_param_ext_tmp_42764;
        ctx_param_ext_42213 = ctx_param_ext_tmp_42765;
        ctx_param_ext_42215 = ctx_param_ext_tmp_42766;
        ctx_param_ext_42216 = ctx_param_ext_tmp_42767;
        loop_while_39096 = loop_while_tmp_42768;
        p_39097 = p_tmp_42769;
    }
    if (memblock_set_device(ctx, &ext_mem_42370, &mem_param_42214, "mem_param_42214") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_42369, &mem_param_42217, "mem_param_42217") != 0)
        return 1;
    ext_42368 = ctx_param_ext_42212;
    ext_42367 = ctx_param_ext_42213;
    ext_42366 = ctx_param_ext_42215;
    ext_42365 = ctx_param_ext_42216;
    defunc_0_find_joinTuples_res_39092 = loop_while_39096;
    defunc_0_find_joinTuples_res_39093 = p_39097;
    if (memblock_unref_device(ctx, &mem_42203, "mem_42203") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42205, "mem_42205") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_42208, "ext_mem_42208") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_42211, "ext_mem_42211") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42218, "mem_42218") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42219, "mem_42219") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42222, "mem_42222") != 0)
        return 1;
    
    int64_t segscan_tblock_sizze_40554;
    
    segscan_tblock_sizze_40554 = *ctx->tuning_params.inner_SMJ_intzisegscan_tblock_sizze_40553;
    
    int64_t num_tblocks_40556;
    int64_t max_num_tblocks_42843;
    
    max_num_tblocks_42843 = *ctx->tuning_params.inner_SMJ_intzisegscan_num_tblocks_40555;
    num_tblocks_40556 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nR_27729, segscan_tblock_sizze_40554), max_num_tblocks_42843)));
    if (memblock_alloc_device(ctx, &mem_42373, bytes_42202, "mem_42373")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42375, bytes_42202, "mem_42375")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, nR_27729)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_42844;
        
        shared_memory_42844 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_42845;
        
        thread_block_sizze_42845 = ctx->max_thread_block_size;
        
        int64_t registers_42846;
        
        registers_42846 = ctx->max_registers;
        
        int64_t thread_block_sizze_42847;
        
        thread_block_sizze_42847 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_42848 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_42844, thread_block_sizze_42845), (int64_t) 8), squot64(squot64(registers_42846, thread_block_sizze_42847) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
        int64_t num_virt_blocks_42849 = sdiv_up64(nR_27729, segscan_tblock_sizze_40554 * chunk_sizze_42848);
        int64_t num_virt_threads_42850 = num_virt_blocks_42849 * segscan_tblock_sizze_40554;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_42848, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_42851, num_virt_blocks_42849, "status_flags_mem_42851")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_42851, num_virt_blocks_42849, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_42873, (int64_t) 8 * num_virt_blocks_42849, "aggregates_mem_42873")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_42875, (int64_t) 8 * num_virt_blocks_42849, "incprefixes_mem_42875")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_intzisegscan_40559(ctx, num_tblocks_40556, 1, 1, *ctx->tuning_params.inner_SMJ_intzisegscan_tblock_sizze_40553, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_40554), chunk_sizze_42848 * segscan_tblock_sizze_40554 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_40554), chunk_sizze_42848 * segscan_tblock_sizze_40554 * (int64_t) 8), (int64_t) 8), (int64_t) 8), nR_27729, num_tblocks_40556, ext_42367, ext_42368, num_virt_blocks_42849, num_virt_threads_42850, ext_mem_42370.mem, mem_42373.mem, mem_42375.mem, status_flags_mem_42851.mem, aggregates_mem_42873.mem, incprefixes_mem_42875.mem, global_dynid_mem_42877.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    
    bool cond_39190 = nR_27729 == (int64_t) 0;
    bool x_39191 = !cond_39190;
    int64_t tmp_39192 = sub64(nR_27729, (int64_t) 1);
    bool x_39193 = sle64((int64_t) 0, tmp_39192);
    bool y_39194 = slt64(tmp_39192, nR_27729);
    bool bounds_check_39195 = x_39193 && y_39194;
    bool protect_assert_disj_39196 = cond_39190 || bounds_check_39195;
    bool index_certs_39197;
    
    if (!protect_assert_disj_39196) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) tmp_39192, "] out of bounds for array of shape [", (long long) nR_27729, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:327:7-328:73\n   #3  ftSMJ.fut:365:133-136\n   #4  ftSMJ.fut:354:1-365:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t m_f_res_39198;
    
    if (x_39191) {
        int64_t read_res_43314;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_43314, mem_42373.mem, tmp_39192 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_39513 = read_res_43314;
        
        m_f_res_39198 = x_39513;
    } else {
        m_f_res_39198 = (int64_t) 0;
    }
    
    int64_t m_39200;
    
    if (cond_39190) {
        m_39200 = (int64_t) 0;
    } else {
        m_39200 = m_f_res_39198;
    }
    
    int64_t m_39210 = sub64(m_39200, (int64_t) 1);
    bool i_p_m_t_s_leq_w_39212 = slt64(m_39210, nR_27729);
    bool zzero_leq_i_p_m_t_s_39211 = sle64((int64_t) 0, m_39210);
    bool y_39214 = zzero_leq_i_p_m_t_s_39211 && i_p_m_t_s_leq_w_39212;
    bool i_lte_j_39213 = sle64((int64_t) 0, m_39200);
    bool forwards_ok_39215 = i_lte_j_39213 && y_39214;
    bool eq_x_zz_39207 = (int64_t) 0 == m_f_res_39198;
    bool p_and_eq_x_y_39208 = x_39191 && eq_x_zz_39207;
    bool empty_slice_39209 = cond_39190 || p_and_eq_x_y_39208;
    bool ok_or_empty_39216 = empty_slice_39209 || forwards_ok_39215;
    bool index_certs_39217;
    
    if (!ok_or_empty_39216) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_39200, "] out of bounds for array of shape [", (long long) nR_27729, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:327:7-328:73\n   #3  ftSMJ.fut:365:133-136\n   #4  ftSMJ.fut:354:1-365:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_42376 = (int64_t) 8 * m_39200;
    
    if (memblock_alloc_device(ctx, &mem_42377, bytes_42376, "mem_42377")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42377.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42370.mem, ext_42368, (int64_t []) {ext_42367}, (int64_t []) {m_39200})) != 0)
        goto cleanup;
    if (memblock_alloc_device(ctx, &mem_42379, bytes_42376, "mem_42379")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42379.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42369.mem, ext_42366, (int64_t []) {ext_42365}, (int64_t []) {m_39200})) != 0)
        goto cleanup;
    if (memblock_alloc_device(ctx, &mem_42381, bytes_42376, "mem_42381")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42381.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42201.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_39200})) != 0)
        goto cleanup;
    
    int64_t bytes_42382 = (int64_t) 4 * m_39200;
    
    if (memblock_alloc_device(ctx, &mem_42383, bytes_42382, "mem_42383")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_42383.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, tR_mem_42199.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_39200})) != 0)
        goto cleanup;
    
    int64_t segmap_tblock_sizze_40564;
    
    segmap_tblock_sizze_40564 = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_40563;
    
    int64_t num_tblocks_40566;
    int64_t max_num_tblocks_42966;
    
    max_num_tblocks_42966 = *ctx->tuning_params.inner_SMJ_intzisegmap_num_tblocks_40565;
    num_tblocks_40566 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nR_27729, segmap_tblock_sizze_40564), max_num_tblocks_42966)));
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_42967 = sext_i64_i32(sdiv_up64(nR_27729, segmap_tblock_sizze_40564));
    
    {
        err = gpu_kernel_inner_SMJ_intzisegmap_40561(ctx, num_tblocks_40566, 1, 1, *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_40563, 1, 1, (int64_t) 0, nR_27729, m_39200, num_tblocks_40566, ext_42365, ext_42366, ext_42367, ext_42368, virt_num_tblocks_42967, tR_mem_42199.mem, ext_mem_42201.mem, ext_mem_42369.mem, ext_mem_42370.mem, mem_42373.mem, mem_42375.mem, mem_42377.mem, mem_42379.mem, mem_42381.mem, mem_42383.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &ext_mem_42201, "ext_mem_42201") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_42369, "ext_mem_42369") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_42370, "ext_mem_42370") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42373, "mem_42373") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42375, "mem_42375") != 0)
        return 1;
    
    int64_t segscan_tblock_sizze_40570;
    
    segscan_tblock_sizze_40570 = *ctx->tuning_params.inner_SMJ_intzisegscan_tblock_sizze_40569;
    
    int64_t num_tblocks_40572;
    int64_t max_num_tblocks_42980;
    
    max_num_tblocks_42980 = *ctx->tuning_params.inner_SMJ_intzisegscan_num_tblocks_40571;
    num_tblocks_40572 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_39200, segscan_tblock_sizze_40570), max_num_tblocks_42980)));
    if (memblock_alloc_device(ctx, &mem_42387, bytes_42376, "mem_42387")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42389, bytes_42376, "mem_42389")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42391, bytes_42376, "mem_42391")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, m_39200)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_42981;
        
        shared_memory_42981 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_42982;
        
        thread_block_sizze_42982 = ctx->max_thread_block_size;
        
        int64_t registers_42983;
        
        registers_42983 = ctx->max_registers;
        
        int64_t thread_block_sizze_42984;
        
        thread_block_sizze_42984 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_42985 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_42981, thread_block_sizze_42982), (int64_t) 8), squot64(squot64(registers_42983, thread_block_sizze_42984) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
        int64_t num_virt_blocks_42986 = sdiv_up64(m_39200, segscan_tblock_sizze_40570 * chunk_sizze_42985);
        int64_t num_virt_threads_42987 = num_virt_blocks_42986 * segscan_tblock_sizze_40570;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_42985, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_42988, num_virt_blocks_42986, "status_flags_mem_42988")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_42988, num_virt_blocks_42986, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_42990, (int64_t) 8 * num_virt_blocks_42986, "aggregates_mem_42990")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_42992, (int64_t) 8 * num_virt_blocks_42986, "incprefixes_mem_42992")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_42994, (int64_t) 8 * num_virt_blocks_42986, "aggregates_mem_42994")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_42996, (int64_t) 8 * num_virt_blocks_42986, "incprefixes_mem_42996")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_intzisegscan_40575(ctx, num_tblocks_40572, 1, 1, *ctx->tuning_params.inner_SMJ_intzisegscan_tblock_sizze_40569, 1, 1, smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_40570, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_40570), smax64(chunk_sizze_42985 * segscan_tblock_sizze_40570 * (int64_t) 8, chunk_sizze_42985 * segscan_tblock_sizze_40570 * (int64_t) 8)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_40570, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_40570), smax64(chunk_sizze_42985 * segscan_tblock_sizze_40570 * (int64_t) 8, chunk_sizze_42985 * segscan_tblock_sizze_40570 * (int64_t) 8)), (int64_t) 8), (int64_t) 8), m_39200, num_tblocks_40572, num_virt_blocks_42986, num_virt_threads_42987, mem_42377.mem, mem_42387.mem, mem_42389.mem, mem_42391.mem, status_flags_mem_42988.mem, aggregates_mem_42990.mem, incprefixes_mem_42992.mem, aggregates_mem_42994.mem, incprefixes_mem_42996.mem, global_dynid_mem_42998.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    
    int64_t segmap_tblock_sizze_40591;
    
    segmap_tblock_sizze_40591 = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_40579;
    
    int64_t segmap_usable_groups_40592 = sdiv_up64(m_39200, segmap_tblock_sizze_40591);
    
    if (memblock_alloc_device(ctx, &mem_42394, bytes_42376, "mem_42394")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_43133 = sext_i64_i32(sdiv_up64(m_39200, segmap_tblock_sizze_40591));
    
    {
        err = gpu_kernel_inner_SMJ_intzisegmap_40595(ctx, segmap_usable_groups_40592, 1, 1, *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_40579, 1, 1, (int64_t) 0, m_39200, mem_42387.mem, mem_42394.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_42387, "mem_42387") != 0)
        return 1;
    
    bool cond_39251 = slt64((int64_t) 0, m_39200);
    bool y_39252 = slt64(m_39210, m_39200);
    bool bounds_check_39253 = zzero_leq_i_p_m_t_s_39211 && y_39252;
    bool loop_not_taken_39254 = !cond_39251;
    bool protect_assert_disj_39255 = bounds_check_39253 || loop_not_taken_39254;
    bool index_certs_39256;
    
    if (!protect_assert_disj_39255) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) m_39210, "] out of bounds for array of shape [", (long long) m_39200, "].", "-> #0  ftSMJ.fut:285:10-41\n   #1  ftSMJ.fut:327:7-328:73\n   #2  ftSMJ.fut:365:133-136\n   #3  ftSMJ.fut:354:1-365:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    if (cond_39251) {
        if (memblock_alloc_device(ctx, &mem_42396, (int64_t) 8, "mem_42396")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_intzigpuseq_43142(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, m_39210, mem_42394.mem, mem_42396.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42397, &mem_42396, "mem_42396") != 0)
            return 1;
    } else {
        if (memblock_alloc_device(ctx, &mem_42395, (int64_t) 8, "mem_42395")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i64(ctx, mem_42395, (int64_t) 1, (int64_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42397, &mem_42395, "mem_42395") != 0)
            return 1;
    }
    if (cond_39251) {
        if (memblock_alloc_device(ctx, &mem_42399, (int64_t) 8, "mem_42399")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_intzigpuseq_43148(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, m_39210, mem_42377.mem, mem_42399.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42400, &mem_42399, "mem_42399") != 0)
            return 1;
    } else {
        if (memblock_alloc_device(ctx, &mem_42398, (int64_t) 8, "mem_42398")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i64(ctx, mem_42398, (int64_t) 1, (int64_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42400, &mem_42398, "mem_42398") != 0)
            return 1;
    }
    
    bool zzero_39268 = scatter_psizze_27738 == (int64_t) 0;
    bool nonzzero_39269 = !zzero_39268;
    bool nonzzero_cert_39270;
    
    if (!nonzzero_39269) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftbasics.fut:66:23-29\n   #1  ftSMJ.fut:327:7-328:73\n   #2  ftSMJ.fut:365:133-136\n   #3  ftSMJ.fut:354:1-365:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    bool x_39335 = !empty_slice_39209;
    bool protect_assert_disj_39336 = empty_slice_39209 || bounds_check_39253;
    bool index_certs_39337;
    
    if (!protect_assert_disj_39336) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) m_39210, "] out of bounds for array of shape [", (long long) m_39200, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:327:7-328:73\n   #3  ftSMJ.fut:365:133-136\n   #4  ftSMJ.fut:354:1-365:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t m_f_res_39338;
    
    if (x_39335) {
        int64_t read_res_43315;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_43315, mem_42389.mem, m_39210 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_39521 = read_res_43315;
        
        m_f_res_39338 = x_39521;
    } else {
        m_f_res_39338 = (int64_t) 0;
    }
    
    int64_t m_39340;
    
    if (empty_slice_39209) {
        m_39340 = (int64_t) 0;
    } else {
        m_39340 = m_f_res_39338;
    }
    
    int64_t m_39350 = sub64(m_39340, (int64_t) 1);
    bool i_p_m_t_s_leq_w_39352 = slt64(m_39350, m_39200);
    bool zzero_leq_i_p_m_t_s_39351 = sle64((int64_t) 0, m_39350);
    bool y_39354 = zzero_leq_i_p_m_t_s_39351 && i_p_m_t_s_leq_w_39352;
    bool i_lte_j_39353 = sle64((int64_t) 0, m_39340);
    bool forwards_ok_39355 = i_lte_j_39353 && y_39354;
    bool eq_x_zz_39347 = (int64_t) 0 == m_f_res_39338;
    bool p_and_eq_x_y_39348 = x_39335 && eq_x_zz_39347;
    bool empty_slice_39349 = empty_slice_39209 || p_and_eq_x_y_39348;
    bool ok_or_empty_39356 = empty_slice_39349 || forwards_ok_39355;
    bool index_certs_39357;
    
    if (!ok_or_empty_39356) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_39340, "] out of bounds for array of shape [", (long long) m_39200, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:327:7-328:73\n   #3  ftSMJ.fut:365:133-136\n   #4  ftSMJ.fut:354:1-365:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_42401 = (int64_t) 8 * m_39340;
    
    if (memblock_alloc_device(ctx, &mem_42406, (int64_t) 8, "mem_42406")) {
        err = 1;
        goto cleanup;
    }
    {
        err = gpu_kernel_inner_SMJ_intzigpuseq_43154(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, ext_mem_42397.mem, ext_mem_42400.mem, mem_42406.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (memblock_unref_device(ctx, &ext_mem_42397, "ext_mem_42397") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_42400, "ext_mem_42400") != 0)
        return 1;
    
    int64_t n_pairs_t_res_39261;
    
    if (cond_39251) {
        int64_t read_res_43316;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_43316, mem_42406.mem, (int64_t) 0 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_42197 = read_res_43316;
        
        n_pairs_t_res_39261 = x_42197;
    } else {
        n_pairs_t_res_39261 = (int64_t) 0;
    }
    if (memblock_unref_device(ctx, &mem_42406, "mem_42406") != 0)
        return 1;
    
    int64_t n_pairs_39262;
    
    if (cond_39251) {
        n_pairs_39262 = n_pairs_t_res_39261;
    } else {
        n_pairs_39262 = (int64_t) 0;
    }
    
    int64_t bytes_42407 = (int64_t) 4 * n_pairs_39262;
    int64_t bytes_42409 = (int64_t) 8 * n_pairs_39262;
    int64_t segmap_tblock_sizze_40606;
    
    segmap_tblock_sizze_40606 = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_40605;
    
    int64_t num_tblocks_40608;
    int64_t max_num_tblocks_43160;
    
    max_num_tblocks_43160 = *ctx->tuning_params.inner_SMJ_intzisegmap_num_tblocks_40607;
    num_tblocks_40608 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_39200, segmap_tblock_sizze_40606), max_num_tblocks_43160)));
    if (memblock_alloc_device(ctx, &mem_42402, bytes_42401, "mem_42402")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42402.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_42377.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_39340})) != 0)
        goto cleanup;
    if (memblock_alloc_device(ctx, &mem_42404, bytes_42401, "mem_42404")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42404.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_42394.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_39340})) != 0)
        goto cleanup;
    
    int64_t segmap_tblock_sizze_40614;
    
    segmap_tblock_sizze_40614 = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_40613;
    
    int64_t num_tblocks_40616;
    int64_t max_num_tblocks_43161;
    
    max_num_tblocks_43161 = *ctx->tuning_params.inner_SMJ_intzisegmap_num_tblocks_40615;
    num_tblocks_40616 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_39200, segmap_tblock_sizze_40614), max_num_tblocks_43161)));
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_43162 = sext_i64_i32(sdiv_up64(m_39200, segmap_tblock_sizze_40614));
    
    {
        err = gpu_kernel_inner_SMJ_intzisegmap_40611(ctx, num_tblocks_40616, 1, 1, *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_40613, 1, 1, (int64_t) 0, m_39200, m_39340, num_tblocks_40616, virt_num_tblocks_43162, mem_42377.mem, mem_42389.mem, mem_42391.mem, mem_42394.mem, mem_42402.mem, mem_42404.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_42377, "mem_42377") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42389, "mem_42389") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42391, "mem_42391") != 0)
        return 1;
    
    bool cond_39367 = slt64((int64_t) 0, m_39340);
    int64_t segmap_tblock_sizze_40629;
    
    segmap_tblock_sizze_40629 = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_40621;
    if (memblock_alloc_device(ctx, &mem_42408, bytes_42407, "mem_42408")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, mem_42408, n_pairs_39262, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42410, bytes_42409, "mem_42410")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_42410, n_pairs_39262, (int64_t) -1) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42412, bytes_42409, "mem_42412")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_42412, n_pairs_39262, (int64_t) -1) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t zm_lhs_39266 = add64(scatter_psizze_27738, n_pairs_39262);
    int64_t zs_lhs_39267 = sub64(zm_lhs_39266, (int64_t) 1);
    int64_t m_39271 = sdiv64(zs_lhs_39267, scatter_psizze_27738);
    bool loop_cond_39272 = slt64((int64_t) 0, m_39271);
    bool partitioned_scatter_res_39273;
    int64_t partitioned_scatter_res_39277;
    bool loop_while_39278;
    int64_t p_39282;
    
    loop_while_39278 = loop_cond_39272;
    p_39282 = (int64_t) 0;
    while (loop_while_39278) {
        int64_t lower_bound_39283 = mul64(scatter_psizze_27738, p_39282);
        int64_t min_arg1_39284 = add64(scatter_psizze_27738, lower_bound_39283);
        int64_t min_res_39285 = smin64(n_pairs_39262, min_arg1_39284);
        int64_t j_m_i_39286 = sub64(min_res_39285, lower_bound_39283);
        bool empty_slice_39287 = j_m_i_39286 == (int64_t) 0;
        int64_t m_39288 = sub64(j_m_i_39286, (int64_t) 1);
        int64_t i_p_m_t_s_39289 = add64(lower_bound_39283, m_39288);
        bool zzero_leq_i_p_m_t_s_39290 = sle64((int64_t) 0, i_p_m_t_s_39289);
        bool i_p_m_t_s_leq_w_39291 = slt64(i_p_m_t_s_39289, n_pairs_39262);
        bool zzero_lte_i_39292 = sle64((int64_t) 0, lower_bound_39283);
        bool i_lte_j_39293 = sle64(lower_bound_39283, min_res_39285);
        bool y_39294 = i_p_m_t_s_leq_w_39291 && zzero_lte_i_39292;
        bool y_39295 = zzero_leq_i_p_m_t_s_39290 && y_39294;
        bool forwards_ok_39296 = i_lte_j_39293 && y_39295;
        bool ok_or_empty_39297 = empty_slice_39287 || forwards_ok_39296;
        bool index_certs_39298;
        
        if (!ok_or_empty_39297) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) lower_bound_39283, ":", (long long) min_res_39285, "] out of bounds for array of shape [", (long long) n_pairs_39262, "].", "-> #0  ftbasics.fut:72:25-56\n   #1  ftSMJ.fut:327:7-328:73\n   #2  ftSMJ.fut:365:133-136\n   #3  ftSMJ.fut:354:1-365:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t bytes_42422 = (int64_t) 4 * j_m_i_39286;
        int64_t bytes_42424 = (int64_t) 8 * j_m_i_39286;
        
        if (memblock_alloc_device(ctx, &mem_42423, bytes_42422, "mem_42423")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_42423.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_42408.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_39283, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_39286})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_42425, bytes_42424, "mem_42425")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42425.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_42410.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_39283, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_39286})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_42427, bytes_42424, "mem_42427")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42427.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_42412.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_39283, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_39286})) != 0)
            goto cleanup;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_43180 = sext_i64_i32(sdiv_up64(m_39200, segmap_tblock_sizze_40606));
        
        {
            err = gpu_kernel_inner_SMJ_intzisegmap_40603(ctx, num_tblocks_40608, 1, 1, *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_40605, 1, 1, (int64_t) 0, m_39200, lower_bound_39283, min_res_39285, j_m_i_39286, num_tblocks_40608, virt_num_tblocks_43180, mem_42379.mem, mem_42381.mem, mem_42383.mem, mem_42394.mem, mem_42423.mem, mem_42425.mem, mem_42427.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t tmp_39312 = add64((int64_t) 1, p_39282);
        
        if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_42408.mem, lower_bound_39283, (int64_t []) {(int64_t) 1}, mem_42423.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_39286})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_42423, "mem_42423") != 0)
            return 1;
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42410.mem, lower_bound_39283, (int64_t []) {(int64_t) 1}, mem_42425.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_39286})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_42425, "mem_42425") != 0)
            return 1;
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42412.mem, lower_bound_39283, (int64_t []) {(int64_t) 1}, mem_42427.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_39286})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_42427, "mem_42427") != 0)
            return 1;
        
        bool loop_cond_39323 = slt64(tmp_39312, m_39271);
        bool loop_while_tmp_43175 = loop_cond_39323;
        int64_t p_tmp_43179 = tmp_39312;
        
        loop_while_39278 = loop_while_tmp_43175;
        p_39282 = p_tmp_43179;
    }
    partitioned_scatter_res_39273 = loop_while_39278;
    partitioned_scatter_res_39277 = p_39282;
    if (memblock_unref_device(ctx, &mem_42379, "mem_42379") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42381, "mem_42381") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42383, "mem_42383") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42394, "mem_42394") != 0)
        return 1;
    
    bool loop_cond_t_res_39368 = slt64(m_39200, n_pairs_39262);
    bool x_39369 = cond_39367 && loop_cond_t_res_39368;
    
    if (memblock_alloc_device(ctx, &mem_42453, (int64_t) 4, "mem_42453")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42454, (int64_t) 8, "mem_42454")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42455, (int64_t) 8, "mem_42455")) {
        err = 1;
        goto cleanup;
    }
    
    bool joinTups_to_joinPairs_InnerJoin_res_39370;
    int64_t joinTups_to_joinPairs_InnerJoin_res_39374;
    bool loop_while_39375;
    int64_t p_39379;
    
    if (memblock_set_device(ctx, &mem_param_42440, &mem_42408, "mem_42408") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_42443, &mem_42410, "mem_42410") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_42446, &mem_42412, "mem_42412") != 0)
        return 1;
    loop_while_39375 = x_39369;
    p_39379 = (int64_t) 0;
    while (loop_while_39375) {
        bool x_39380 = sle64((int64_t) 0, p_39379);
        bool y_39381 = slt64(p_39379, m_39340);
        bool bounds_check_39382 = x_39380 && y_39381;
        bool index_certs_39383;
        
        if (!bounds_check_39382) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) p_39379, "] out of bounds for array of shape [", (long long) m_39340, "].", "-> #0  ftSMJ.fut:300:13-42\n   #1  ftSMJ.fut:327:7-328:73\n   #2  ftSMJ.fut:365:133-136\n   #3  ftSMJ.fut:354:1-365:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t read_res_43317;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_43317, mem_42404.mem, p_39379 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t loopres_39384 = read_res_43317;
        int64_t read_res_43318;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_43318, mem_42402.mem, p_39379 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t loopres_39385 = read_res_43318;
        bool x_39386 = sle64((int64_t) 0, loopres_39384);
        bool y_39387 = slt64(loopres_39384, n_pairs_39262);
        bool bounds_check_39388 = x_39386 && y_39387;
        bool index_certs_39389;
        
        if (!bounds_check_39388) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) loopres_39384, "] out of bounds for array of shape [", (long long) n_pairs_39262, "].", "-> #0  ftSMJ.fut:302:52-61\n   #1  ftSMJ.fut:327:7-328:73\n   #2  ftSMJ.fut:365:133-136\n   #3  ftSMJ.fut:354:1-365:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t tmp_39400 = add64(loopres_39384, loopres_39385);
        bool empty_slice_39404 = loopres_39385 == (int64_t) 0;
        int64_t m_39405 = sub64(loopres_39385, (int64_t) 1);
        int64_t i_p_m_t_s_39406 = add64(loopres_39384, m_39405);
        bool zzero_leq_i_p_m_t_s_39407 = sle64((int64_t) 0, i_p_m_t_s_39406);
        bool i_p_m_t_s_leq_w_39408 = slt64(i_p_m_t_s_39406, n_pairs_39262);
        bool i_lte_j_39409 = sle64(loopres_39384, tmp_39400);
        bool y_39410 = x_39386 && i_p_m_t_s_leq_w_39408;
        bool y_39411 = zzero_leq_i_p_m_t_s_39407 && y_39410;
        bool forwards_ok_39412 = i_lte_j_39409 && y_39411;
        bool ok_or_empty_39413 = empty_slice_39404 || forwards_ok_39412;
        bool index_certs_39414;
        
        if (!ok_or_empty_39413) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) loopres_39384, ":", (long long) tmp_39400, "] out of bounds for array of shape [", (long long) n_pairs_39262, "].", "-> #0  ftSMJ.fut:306:14-55\n   #1  ftSMJ.fut:327:7-328:73\n   #2  ftSMJ.fut:365:133-136\n   #3  ftSMJ.fut:354:1-365:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t bytes_42456 = (int64_t) 4 * loopres_39385;
        int64_t bytes_42458 = (int64_t) 8 * loopres_39385;
        int64_t segmap_usable_groups_40630 = sdiv_up64(loopres_39385, segmap_tblock_sizze_40629);
        int64_t tmp_39399 = add64((int64_t) 1, p_39379);
        
        if (memblock_alloc_device(ctx, &mem_42448, bytes_42407, "mem_42448")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_42448.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_42440.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_39262})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_42450, bytes_42409, "mem_42450")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42450.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_42443.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_39262})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_42452, bytes_42409, "mem_42452")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42452.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_42446.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_39262})) != 0)
            goto cleanup;
        
        bool cond_39418 = slt64(tmp_39399, m_39340);
        bool x_39419 = loop_cond_t_res_39368 && cond_39418;
        
        {
            err = gpu_kernel_inner_SMJ_intzigpuseq_43201(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, loopres_39384, mem_param_42440.mem, mem_param_42443.mem, mem_param_42446.mem, mem_42453.mem, mem_42454.mem, mem_42455.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_42457, bytes_42456, "mem_42457")) {
            err = 1;
            goto cleanup;
        }
        
        int64_t replicate_n_43207 = loopres_39385;
        int64_t tblock_sizze_43212;
        
        tblock_sizze_43212 = *ctx->tuning_params.inner_SMJ_intzitblock_sizze_43212;
        
        int64_t virt_num_tblocks_43213 = sdiv_up64(replicate_n_43207, tblock_sizze_43212);
        int64_t num_tblocks_43214 = smin64(virt_num_tblocks_43213, (int64_t) 1048576);
        
        {
            err = gpu_kernel_inner_SMJ_intzireplicate_43208(ctx, num_tblocks_43214, 1, 1, tblock_sizze_43212, 1, 1, (int64_t) 0, loopres_39385, replicate_n_43207, virt_num_tblocks_43213, num_tblocks_43214, mem_42453.mem, mem_42457.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_42459, bytes_42458, "mem_42459")) {
            err = 1;
            goto cleanup;
        }
        
        int64_t replicate_n_43227 = loopres_39385;
        int64_t tblock_sizze_43232;
        
        tblock_sizze_43232 = *ctx->tuning_params.inner_SMJ_intzitblock_sizze_43232;
        
        int64_t virt_num_tblocks_43233 = sdiv_up64(replicate_n_43227, tblock_sizze_43232);
        int64_t num_tblocks_43234 = smin64(virt_num_tblocks_43233, (int64_t) 1048576);
        
        {
            err = gpu_kernel_inner_SMJ_intzireplicate_43228(ctx, num_tblocks_43234, 1, 1, tblock_sizze_43232, 1, 1, (int64_t) 0, loopres_39385, replicate_n_43227, virt_num_tblocks_43233, num_tblocks_43234, mem_42454.mem, mem_42459.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_43247 = sext_i64_i32(sdiv_up64(loopres_39385, segmap_tblock_sizze_40629));
        
        {
            err = gpu_kernel_inner_SMJ_intzisegmap_40633(ctx, segmap_usable_groups_40630, 1, 1, *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_40621, 1, 1, (int64_t) 0, loopres_39384, loopres_39385, mem_42452.mem, mem_42455.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_42448.mem, loopres_39384, (int64_t []) {(int64_t) 1}, mem_42457.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {loopres_39385})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_42457, "mem_42457") != 0)
            return 1;
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42450.mem, loopres_39384, (int64_t []) {(int64_t) 1}, mem_42459.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {loopres_39385})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_42459, "mem_42459") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_43193, &mem_42448, "mem_42448") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_43194, &mem_42450, "mem_42450") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_43195, &mem_42452, "mem_42452") != 0)
            return 1;
        
        bool loop_while_tmp_43196 = x_39419;
        int64_t p_tmp_43200 = tmp_39399;
        
        if (memblock_set_device(ctx, &mem_param_42440, &mem_param_tmp_43193, "mem_param_tmp_43193") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_42443, &mem_param_tmp_43194, "mem_param_tmp_43194") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_42446, &mem_param_tmp_43195, "mem_param_tmp_43195") != 0)
            return 1;
        loop_while_39375 = loop_while_tmp_43196;
        p_39379 = p_tmp_43200;
    }
    if (memblock_set_device(ctx, &ext_mem_42471, &mem_param_42440, "mem_param_42440") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_42470, &mem_param_42443, "mem_param_42443") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_42469, &mem_param_42446, "mem_param_42446") != 0)
        return 1;
    joinTups_to_joinPairs_InnerJoin_res_39370 = loop_while_39375;
    joinTups_to_joinPairs_InnerJoin_res_39374 = p_39379;
    if (memblock_unref_device(ctx, &mem_42402, "mem_42402") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42404, "mem_42404") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42408, "mem_42408") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42410, "mem_42410") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42412, "mem_42412") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42453, "mem_42453") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42454, "mem_42454") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42455, "mem_42455") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_42473, bytes_42407, "mem_42473")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_42473.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42471.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_39262})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_42471, "ext_mem_42471") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_42475, bytes_42409, "mem_42475")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42475.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42470.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_39262})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_42470, "ext_mem_42470") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_42477, bytes_42409, "mem_42477")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42477.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42469.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_39262})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_42469, "ext_mem_42469") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_42706, &mem_42475, "mem_42475") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_42707, &mem_42477, "mem_42477") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_42708, &mem_42473, "mem_42473") != 0)
        return 1;
    prim_out_42709 = n_pairs_39262;
    if (memblock_set_device(ctx, &*mem_out_p_43308, &mem_out_42706, "mem_out_42706") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_43309, &mem_out_42707, "mem_out_42707") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_43310, &mem_out_42708, "mem_out_42708") != 0)
        return 1;
    *out_prim_out_43311 = prim_out_42709;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_42477, "mem_42477") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42475, "mem_42475") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42473, "mem_42473") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_43195, "mem_param_tmp_43195") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_43194, "mem_param_tmp_43194") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_43193, "mem_param_tmp_43193") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42459, "mem_42459") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42457, "mem_42457") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42452, "mem_42452") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42450, "mem_42450") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42448, "mem_42448") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42446, "mem_param_42446") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42443, "mem_param_42443") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42440, "mem_param_42440") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42469, "ext_mem_42469") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42470, "ext_mem_42470") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42471, "ext_mem_42471") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42455, "mem_42455") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42454, "mem_42454") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42453, "mem_42453") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42427, "mem_42427") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42425, "mem_42425") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42423, "mem_42423") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42412, "mem_42412") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42410, "mem_42410") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42408, "mem_42408") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42404, "mem_42404") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42402, "mem_42402") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42406, "mem_42406") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42398, "mem_42398") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42399, "mem_42399") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42400, "ext_mem_42400") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42395, "mem_42395") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42396, "mem_42396") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42397, "ext_mem_42397") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42394, "mem_42394") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_42996, "incprefixes_mem_42996") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_42994, "aggregates_mem_42994") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_42992, "incprefixes_mem_42992") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_42990, "aggregates_mem_42990") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_42988, "status_flags_mem_42988") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42391, "mem_42391") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42389, "mem_42389") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42387, "mem_42387") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42383, "mem_42383") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42381, "mem_42381") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42379, "mem_42379") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42377, "mem_42377") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_42875, "incprefixes_mem_42875") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_42873, "aggregates_mem_42873") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_42851, "status_flags_mem_42851") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42375, "mem_42375") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42373, "mem_42373") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_42763, "mem_param_tmp_42763") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_42762, "mem_param_tmp_42762") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42352, "mem_42352") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42350, "mem_42350") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42285, "mem_42285") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42283, "mem_42283") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42346, "mem_42346") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42344, "mem_42344") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42347, "ext_mem_42347") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42348, "ext_mem_42348") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42224, "ext_mem_42224") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42355, "ext_mem_42355") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42358, "ext_mem_42358") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42223, "mem_42223") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42361, "ext_mem_42361") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42364, "ext_mem_42364") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42221, "ext_mem_42221") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42220, "ext_mem_42220") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42217, "mem_param_42217") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42214, "mem_param_42214") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42369, "ext_mem_42369") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42370, "ext_mem_42370") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42222, "mem_42222") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42219, "mem_42219") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42218, "mem_42218") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42209, "mem_42209") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42210, "mem_42210") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42211, "ext_mem_42211") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42206, "mem_42206") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42207, "mem_42207") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42208, "ext_mem_42208") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42205, "mem_42205") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42203, "mem_42203") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42201, "ext_mem_42201") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_42708, "mem_out_42708") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_42707, "mem_out_42707") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_42706, "mem_out_42706") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_inner_SMJ_long(struct futhark_context *ctx, struct memblock_device *mem_out_p_43319, struct memblock_device *mem_out_p_43320, struct memblock_device *mem_out_p_43321, int64_t *out_prim_out_43322, struct memblock_device tR_mem_42199, struct memblock_device tS_mem_42200, int64_t nR_29939, int64_t nS_29940, int64_t offset_R_29943, int64_t offset_S_29944, int64_t partitionsPerWindow_29945, int64_t numberOfWindows_29946, int64_t extParallelism_29947, int64_t scatter_psizze_29948)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_42477;
    
    mem_42477.references = NULL;
    
    struct memblock_device mem_42475;
    
    mem_42475.references = NULL;
    
    struct memblock_device mem_42473;
    
    mem_42473.references = NULL;
    
    struct memblock_device mem_param_tmp_43195;
    
    mem_param_tmp_43195.references = NULL;
    
    struct memblock_device mem_param_tmp_43194;
    
    mem_param_tmp_43194.references = NULL;
    
    struct memblock_device mem_param_tmp_43193;
    
    mem_param_tmp_43193.references = NULL;
    
    struct memblock_device mem_42459;
    
    mem_42459.references = NULL;
    
    struct memblock_device mem_42457;
    
    mem_42457.references = NULL;
    
    struct memblock_device mem_42452;
    
    mem_42452.references = NULL;
    
    struct memblock_device mem_42450;
    
    mem_42450.references = NULL;
    
    struct memblock_device mem_42448;
    
    mem_42448.references = NULL;
    
    struct memblock_device mem_param_42446;
    
    mem_param_42446.references = NULL;
    
    struct memblock_device mem_param_42443;
    
    mem_param_42443.references = NULL;
    
    struct memblock_device mem_param_42440;
    
    mem_param_42440.references = NULL;
    
    struct memblock_device ext_mem_42469;
    
    ext_mem_42469.references = NULL;
    
    struct memblock_device ext_mem_42470;
    
    ext_mem_42470.references = NULL;
    
    struct memblock_device ext_mem_42471;
    
    ext_mem_42471.references = NULL;
    
    struct memblock_device mem_42455;
    
    mem_42455.references = NULL;
    
    struct memblock_device mem_42454;
    
    mem_42454.references = NULL;
    
    struct memblock_device mem_42453;
    
    mem_42453.references = NULL;
    
    struct memblock_device mem_42427;
    
    mem_42427.references = NULL;
    
    struct memblock_device mem_42425;
    
    mem_42425.references = NULL;
    
    struct memblock_device mem_42423;
    
    mem_42423.references = NULL;
    
    struct memblock_device mem_42412;
    
    mem_42412.references = NULL;
    
    struct memblock_device mem_42410;
    
    mem_42410.references = NULL;
    
    struct memblock_device mem_42408;
    
    mem_42408.references = NULL;
    
    struct memblock_device mem_42404;
    
    mem_42404.references = NULL;
    
    struct memblock_device mem_42402;
    
    mem_42402.references = NULL;
    
    struct memblock_device mem_42406;
    
    mem_42406.references = NULL;
    
    struct memblock_device mem_42398;
    
    mem_42398.references = NULL;
    
    struct memblock_device mem_42399;
    
    mem_42399.references = NULL;
    
    struct memblock_device ext_mem_42400;
    
    ext_mem_42400.references = NULL;
    
    struct memblock_device mem_42395;
    
    mem_42395.references = NULL;
    
    struct memblock_device mem_42396;
    
    mem_42396.references = NULL;
    
    struct memblock_device ext_mem_42397;
    
    ext_mem_42397.references = NULL;
    
    struct memblock_device mem_42394;
    
    mem_42394.references = NULL;
    
    struct memblock_device incprefixes_mem_42996;
    
    incprefixes_mem_42996.references = NULL;
    
    struct memblock_device aggregates_mem_42994;
    
    aggregates_mem_42994.references = NULL;
    
    struct memblock_device incprefixes_mem_42992;
    
    incprefixes_mem_42992.references = NULL;
    
    struct memblock_device aggregates_mem_42990;
    
    aggregates_mem_42990.references = NULL;
    
    struct memblock_device status_flags_mem_42988;
    
    status_flags_mem_42988.references = NULL;
    
    struct memblock_device mem_42391;
    
    mem_42391.references = NULL;
    
    struct memblock_device mem_42389;
    
    mem_42389.references = NULL;
    
    struct memblock_device mem_42387;
    
    mem_42387.references = NULL;
    
    struct memblock_device mem_42383;
    
    mem_42383.references = NULL;
    
    struct memblock_device mem_42381;
    
    mem_42381.references = NULL;
    
    struct memblock_device mem_42379;
    
    mem_42379.references = NULL;
    
    struct memblock_device mem_42377;
    
    mem_42377.references = NULL;
    
    struct memblock_device incprefixes_mem_42855;
    
    incprefixes_mem_42855.references = NULL;
    
    struct memblock_device aggregates_mem_42853;
    
    aggregates_mem_42853.references = NULL;
    
    struct memblock_device status_flags_mem_42831;
    
    status_flags_mem_42831.references = NULL;
    
    struct memblock_device mem_42375;
    
    mem_42375.references = NULL;
    
    struct memblock_device mem_42373;
    
    mem_42373.references = NULL;
    
    struct memblock_device mem_param_tmp_42743;
    
    mem_param_tmp_42743.references = NULL;
    
    struct memblock_device mem_param_tmp_42742;
    
    mem_param_tmp_42742.references = NULL;
    
    struct memblock_device mem_42352;
    
    mem_42352.references = NULL;
    
    struct memblock_device mem_42350;
    
    mem_42350.references = NULL;
    
    struct memblock_device mem_42285;
    
    mem_42285.references = NULL;
    
    struct memblock_device mem_42283;
    
    mem_42283.references = NULL;
    
    struct memblock_device mem_42346;
    
    mem_42346.references = NULL;
    
    struct memblock_device mem_42344;
    
    mem_42344.references = NULL;
    
    struct memblock_device ext_mem_42347;
    
    ext_mem_42347.references = NULL;
    
    struct memblock_device ext_mem_42348;
    
    ext_mem_42348.references = NULL;
    
    struct memblock_device ext_mem_42224;
    
    ext_mem_42224.references = NULL;
    
    struct memblock_device ext_mem_42355;
    
    ext_mem_42355.references = NULL;
    
    struct memblock_device ext_mem_42358;
    
    ext_mem_42358.references = NULL;
    
    struct memblock_device mem_42223;
    
    mem_42223.references = NULL;
    
    struct memblock_device ext_mem_42361;
    
    ext_mem_42361.references = NULL;
    
    struct memblock_device ext_mem_42364;
    
    ext_mem_42364.references = NULL;
    
    struct memblock_device ext_mem_42221;
    
    ext_mem_42221.references = NULL;
    
    struct memblock_device ext_mem_42220;
    
    ext_mem_42220.references = NULL;
    
    struct memblock_device mem_param_42217;
    
    mem_param_42217.references = NULL;
    
    struct memblock_device mem_param_42214;
    
    mem_param_42214.references = NULL;
    
    struct memblock_device ext_mem_42369;
    
    ext_mem_42369.references = NULL;
    
    struct memblock_device ext_mem_42370;
    
    ext_mem_42370.references = NULL;
    
    struct memblock_device mem_42222;
    
    mem_42222.references = NULL;
    
    struct memblock_device mem_42219;
    
    mem_42219.references = NULL;
    
    struct memblock_device mem_42218;
    
    mem_42218.references = NULL;
    
    struct memblock_device mem_42209;
    
    mem_42209.references = NULL;
    
    struct memblock_device mem_42210;
    
    mem_42210.references = NULL;
    
    struct memblock_device ext_mem_42211;
    
    ext_mem_42211.references = NULL;
    
    struct memblock_device mem_42206;
    
    mem_42206.references = NULL;
    
    struct memblock_device mem_42207;
    
    mem_42207.references = NULL;
    
    struct memblock_device ext_mem_42208;
    
    ext_mem_42208.references = NULL;
    
    struct memblock_device mem_42205;
    
    mem_42205.references = NULL;
    
    struct memblock_device mem_42203;
    
    mem_42203.references = NULL;
    
    struct memblock_device ext_mem_42201;
    
    ext_mem_42201.references = NULL;
    
    struct memblock_device mem_out_42708;
    
    mem_out_42708.references = NULL;
    
    struct memblock_device mem_out_42707;
    
    mem_out_42707.references = NULL;
    
    struct memblock_device mem_out_42706;
    
    mem_out_42706.references = NULL;
    
    struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
    struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
    struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
    struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
    struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
    int64_t prim_out_42709;
    int64_t zm_lhs_39067 = add64(nR_29939, extParallelism_29947);
    int64_t zs_lhs_39068 = sub64(zm_lhs_39067, (int64_t) 1);
    bool zzero_39069 = extParallelism_29947 == (int64_t) 0;
    bool nonzzero_39070 = !zzero_39069;
    bool nonzzero_cert_39071;
    
    if (!nonzzero_39070) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftSMJ.fut:48:39-55\n   #1  ftSMJ.fut:327:87-89\n   #2  ftSMJ.fut:378:133-136\n   #3  ftSMJ.fut:367:1-378:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t numIter_39072 = sdiv64(zs_lhs_39068, extParallelism_29947);
    
    if (futrts_indicesWithIncrement_9775(ctx, &ext_mem_42201, tR_mem_42199, nR_29939, offset_R_29943) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t bytes_42202 = (int64_t) 8 * nR_29939;
    
    if (memblock_alloc_device(ctx, &mem_42203, bytes_42202, "mem_42203")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_42203, nR_29939, (int64_t) -1) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42205, bytes_42202, "mem_42205")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_42205, nR_29939, (int64_t) 0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    bool loop_cond_39076 = slt64((int64_t) 0, numIter_39072);
    bool cond_39077 = slt64((int64_t) 0, nS_29940);
    int64_t tmp_39078 = sub64(nS_29940, (int64_t) 1);
    bool loop_not_taken_39079 = !cond_39077;
    bool loop_not_taken_39080 = !loop_cond_39076;
    bool x_39081 = sle64((int64_t) 0, tmp_39078);
    bool y_39082 = slt64(tmp_39078, nS_29940);
    bool protect_cond_conj_39083 = loop_cond_39076 && cond_39077;
    
    if (protect_cond_conj_39083) {
        if (memblock_alloc_device(ctx, &mem_42207, (int64_t) 8, "mem_42207")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_longzigpuseq_42730(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, tS_mem_42200.mem, mem_42207.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42208, &mem_42207, "mem_42207") != 0)
            return 1;
    } else {
        if (memblock_alloc_device(ctx, &mem_42206, (int64_t) 8, "mem_42206")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i64(ctx, mem_42206, (int64_t) 1, (int64_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42208, &mem_42206, "mem_42206") != 0)
            return 1;
    }
    
    bool bounds_check_39086 = x_39081 && y_39082;
    bool protect_assert_disj_39087 = loop_not_taken_39079 || bounds_check_39086;
    bool protect_assert_disj_39088 = loop_not_taken_39080 || protect_assert_disj_39087;
    bool index_certs_39089;
    
    if (!protect_assert_disj_39088) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) tmp_39078, "] out of bounds for array of shape [", (long long) nS_29940, "].", "-> #0  ftSMJ.fut:60:34-42\n   #1  ftSMJ.fut:327:87-89\n   #2  ftSMJ.fut:378:133-136\n   #3  ftSMJ.fut:367:1-378:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    if (protect_cond_conj_39083) {
        if (memblock_alloc_device(ctx, &mem_42210, (int64_t) 8, "mem_42210")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_longzigpuseq_42736(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, tmp_39078, tS_mem_42200.mem, mem_42210.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42211, &mem_42210, "mem_42210") != 0)
            return 1;
    } else {
        if (memblock_alloc_device(ctx, &mem_42209, (int64_t) 8, "mem_42209")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i64(ctx, mem_42209, (int64_t) 1, (int64_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42211, &mem_42209, "mem_42209") != 0)
            return 1;
    }
    if (memblock_alloc_device(ctx, &mem_42218, (int64_t) 8, "mem_42218")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42219, (int64_t) 8, "mem_42219")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42222, (int64_t) 1, "mem_42222")) {
        err = 1;
        goto cleanup;
    }
    
    int64_t ext_42368;
    int64_t ext_42367;
    int64_t ext_42366;
    int64_t ext_42365;
    bool defunc_0_find_joinTuples_res_39092;
    int64_t defunc_0_find_joinTuples_res_39093;
    bool loop_while_39096;
    int64_t p_39097;
    int64_t ctx_param_ext_42212;
    int64_t ctx_param_ext_42213;
    int64_t ctx_param_ext_42215;
    int64_t ctx_param_ext_42216;
    
    if (memblock_set_device(ctx, &mem_param_42214, &mem_42205, "mem_42205") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_42217, &mem_42203, "mem_42203") != 0)
        return 1;
    ctx_param_ext_42212 = (int64_t) 0;
    ctx_param_ext_42213 = (int64_t) 1;
    ctx_param_ext_42215 = (int64_t) 0;
    ctx_param_ext_42216 = (int64_t) 1;
    loop_while_39096 = loop_cond_39076;
    p_39097 = (int64_t) 0;
    while (loop_while_39096) {
        int64_t start_39100 = mul64(extParallelism_29947, p_39097);
        int64_t min_arg1_39101 = sub64(nR_29939, start_39100);
        int64_t min_res_39102 = smin64(extParallelism_29947, min_arg1_39101);
        int64_t iter_R_39103 = add64(start_39100, min_res_39102);
        bool empty_slice_39104 = min_res_39102 == (int64_t) 0;
        int64_t m_39105 = sub64(min_res_39102, (int64_t) 1);
        int64_t i_p_m_t_s_39106 = add64(start_39100, m_39105);
        bool zzero_leq_i_p_m_t_s_39107 = sle64((int64_t) 0, i_p_m_t_s_39106);
        bool i_p_m_t_s_leq_w_39108 = slt64(i_p_m_t_s_39106, nR_29939);
        bool zzero_lte_i_39109 = sle64((int64_t) 0, start_39100);
        bool i_lte_j_39110 = sle64(start_39100, iter_R_39103);
        bool y_39111 = i_p_m_t_s_leq_w_39108 && zzero_lte_i_39109;
        bool y_39112 = zzero_leq_i_p_m_t_s_39107 && y_39111;
        bool forwards_ok_39113 = i_lte_j_39110 && y_39112;
        bool ok_or_empty_39114 = empty_slice_39104 || forwards_ok_39113;
        bool index_certs_39115;
        
        if (!ok_or_empty_39114) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) start_39100, ":", (long long) iter_R_39103, "] out of bounds for array of shape [", (long long) nR_29939, "].", "-> #0  ftSMJ.fut:55:20-49\n   #1  ftSMJ.fut:327:87-89\n   #2  ftSMJ.fut:378:133-136\n   #3  ftSMJ.fut:367:1-378:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        bool y_39121 = slt64(m_39105, min_res_39102);
        bool x_39120 = sle64((int64_t) 0, m_39105);
        bool bounds_check_39122 = x_39120 && y_39121;
        bool index_certs_39123;
        
        if (!bounds_check_39122) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) m_39105, "] out of bounds for array of shape [", (long long) min_res_39102, "].", "-> #0  ftSMJ.fut:58:21-40\n   #1  ftSMJ.fut:327:87-89\n   #2  ftSMJ.fut:378:133-136\n   #3  ftSMJ.fut:367:1-378:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        bool y_39117 = slt64((int64_t) 0, min_res_39102);
        bool index_certs_39118;
        
        if (!y_39117) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) (int64_t) 0, "] out of bounds for array of shape [", (long long) min_res_39102, "].", "-> #0  ftSMJ.fut:57:21-30\n   #1  ftSMJ.fut:327:87-89\n   #2  ftSMJ.fut:378:133-136\n   #3  ftSMJ.fut:367:1-378:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_longzigpuseq_42752(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, start_39100, i_p_m_t_s_39106, tR_mem_42199.mem, mem_42218.mem, mem_42219.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (cond_39077) {
            if (memblock_set_device(ctx, &ext_mem_42220, &ext_mem_42211, "ext_mem_42211") != 0)
                return 1;
        } else if (memblock_set_device(ctx, &ext_mem_42220, &mem_42218, "mem_42218") != 0)
            return 1;
        if (cond_39077) {
            if (memblock_set_device(ctx, &ext_mem_42221, &ext_mem_42208, "ext_mem_42208") != 0)
                return 1;
        } else if (memblock_set_device(ctx, &ext_mem_42221, &mem_42219, "mem_42219") != 0)
            return 1;
        {
            err = gpu_kernel_inner_SMJ_longzigpuseq_42758(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, mem_42219.mem, ext_mem_42220.mem, mem_42222.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_unref_device(ctx, &ext_mem_42220, "ext_mem_42220") != 0)
            return 1;
        
        bool read_res_43323;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_43323, mem_42222.mem, (int64_t) 0 * sizeof(bool), sizeof(bool))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        bool defunc_0_gt_res_39127 = read_res_43323;
        int64_t ext_42363;
        int64_t ext_42362;
        int64_t ext_42360;
        int64_t ext_42359;
        int64_t loopres_39128;
        
        if (defunc_0_gt_res_39127) {
            if (memblock_set_device(ctx, &ext_mem_42364, &mem_param_42214, "mem_param_42214") != 0)
                return 1;
            ext_42363 = ctx_param_ext_42212;
            ext_42362 = ctx_param_ext_42213;
            if (memblock_set_device(ctx, &ext_mem_42361, &mem_param_42217, "mem_param_42217") != 0)
                return 1;
            ext_42360 = ctx_param_ext_42215;
            ext_42359 = ctx_param_ext_42216;
            loopres_39128 = numIter_39072;
        } else {
            if (memblock_alloc_device(ctx, &mem_42223, (int64_t) 1, "mem_42223")) {
                err = 1;
                goto cleanup;
            }
            {
                err = gpu_kernel_inner_SMJ_longzigpuseq_42764(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, mem_42218.mem, ext_mem_42221.mem, mem_42223.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            
            bool read_res_43324;
            
            if ((err = gpu_scalar_from_device(ctx, &read_res_43324, mem_42223.mem, (int64_t) 0 * sizeof(bool), sizeof(bool))) != 0)
                goto cleanup;
            if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                err = 1;
                goto cleanup;
            }
            
            bool defunc_0_gt_res_39131 = read_res_43324;
            
            if (memblock_unref_device(ctx, &mem_42223, "mem_42223") != 0)
                return 1;
            
            int64_t ext_42357;
            
            if (defunc_0_gt_res_39131) {
                ext_42357 = ctx_param_ext_42212;
            } else {
                ext_42357 = (int64_t) 0;
            }
            
            int64_t ext_42356;
            
            if (defunc_0_gt_res_39131) {
                ext_42356 = ctx_param_ext_42213;
            } else {
                ext_42356 = (int64_t) 1;
            }
            
            int64_t ext_42354;
            
            if (defunc_0_gt_res_39131) {
                ext_42354 = ctx_param_ext_42215;
            } else {
                ext_42354 = (int64_t) 0;
            }
            
            int64_t ext_42353;
            
            if (defunc_0_gt_res_39131) {
                ext_42353 = ctx_param_ext_42216;
            } else {
                ext_42353 = (int64_t) 1;
            }
            
            int64_t loopres_f_res_39132;
            
            if (defunc_0_gt_res_39131) {
                int64_t tmp_39506 = add64((int64_t) 1, p_39097);
                
                if (memblock_set_device(ctx, &ext_mem_42358, &mem_param_42214, "mem_param_42214") != 0)
                    return 1;
                if (memblock_set_device(ctx, &ext_mem_42355, &mem_param_42217, "mem_param_42217") != 0)
                    return 1;
                loopres_f_res_39132 = tmp_39506;
            } else {
                if (futrts_indicesWithIncrement_9775(ctx, &ext_mem_42224, tS_mem_42200, nS_29940, offset_S_29944) != 0) {
                    err = 1;
                    goto cleanup;
                }
                
                bool suff_outer_par_40637;
                
                suff_outer_par_40637 = *ctx->tuning_params.inner_SMJ_longzisuff_outer_par_0 <= min_res_39102;
                if (ctx->logging)
                    fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "inner_SMJ_long.suff_outer_par_0", (long) min_res_39102, suff_outer_par_40637 ? "true" : "false");
                
                int64_t tile_sizze_41780;
                
                tile_sizze_41780 = *ctx->tuning_params.inner_SMJ_longzitile_sizze_41779;
                
                int64_t tile_sizze_41425;
                
                tile_sizze_41425 = *ctx->tuning_params.inner_SMJ_longzitile_sizze_41424;
                
                int64_t num_whole_tiles_41796 = squot_safe64(nS_29940, tile_sizze_41780);
                int64_t residual_input_42020 = srem_safe64(nS_29940, tile_sizze_41780);
                bool cond_42021 = residual_input_42020 == (int64_t) 0;
                int64_t binop_x_42037 = tile_sizze_41780 * num_whole_tiles_41796;
                int64_t bytes_42282 = (int64_t) 8 * min_res_39102;
                int64_t bytes_42245 = (int64_t) 8 * tile_sizze_41780;
                int64_t num_whole_tiles_41441 = squot_safe64(nS_29940, tile_sizze_41425);
                int64_t residual_input_41665 = srem_safe64(nS_29940, tile_sizze_41425);
                bool cond_41666 = residual_input_41665 == (int64_t) 0;
                int64_t binop_x_41682 = tile_sizze_41425 * num_whole_tiles_41441;
                int64_t bytes_42306 = (int64_t) 8 * tile_sizze_41425;
                int64_t shared_memory_capacity_42822;
                
                shared_memory_capacity_42822 = ctx->max_shared_memory;
                if (suff_outer_par_40637 && sle64(sdiv_up64(bytes_42306, (int64_t) 8) * (int64_t) 8 + sdiv_up64(bytes_42306, (int64_t) 8) * (int64_t) 8 + sdiv_up64(bytes_42306, (int64_t) 8) * (int64_t) 8, shared_memory_capacity_42822)) {
                    int64_t ldim_41426 = sdiv_up64(min_res_39102, tile_sizze_41425);
                    
                    if (memblock_alloc_device(ctx, &mem_42344, bytes_42282, "mem_42344")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &mem_42346, bytes_42282, "mem_42346")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t num_chunks_42770 = sext_i64_i32(sdiv_up64(tile_sizze_41425, tile_sizze_41425));
                    int32_t virt_num_tblocks_42771 = sext_i64_i32(ldim_41426);
                    
                    {
                        err = gpu_kernel_inner_SMJ_longzisegmap_intrablock_41423(ctx, ldim_41426, 1, 1, *ctx->tuning_params.inner_SMJ_longzitile_sizze_41424, 1, 1, bytes_42306 + srem64((int64_t) 8 - srem64(bytes_42306, (int64_t) 8), (int64_t) 8) + (bytes_42306 + srem64((int64_t) 8 - srem64(bytes_42306, (int64_t) 8), (int64_t) 8)) + (bytes_42306 + srem64((int64_t) 8 - srem64(bytes_42306, (int64_t) 8), (int64_t) 8)), nS_29940, start_39100, min_res_39102, ldim_41426, num_whole_tiles_41441, residual_input_41665, cond_41666, binop_x_41682, tR_mem_42199.mem, tS_mem_42200.mem, ext_mem_42224.mem, mem_42344.mem, mem_42346.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_set_device(ctx, &ext_mem_42348, &mem_42344, "mem_42344") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &ext_mem_42347, &mem_42346, "mem_42346") != 0)
                        return 1;
                } else {
                    int64_t ldim_41781 = sdiv_up64(min_res_39102, tile_sizze_41780);
                    
                    if (memblock_alloc_device(ctx, &mem_42283, bytes_42282, "mem_42283")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &mem_42285, bytes_42282, "mem_42285")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t num_chunks_42796 = sext_i64_i32(sdiv_up64(tile_sizze_41780, tile_sizze_41780));
                    int32_t virt_num_tblocks_42797 = sext_i64_i32(ldim_41781);
                    
                    {
                        err = gpu_kernel_inner_SMJ_longzisegmap_intrablock_41778(ctx, ldim_41781, 1, 1, *ctx->tuning_params.inner_SMJ_longzitile_sizze_41779, 1, 1, bytes_42245 + srem64((int64_t) 8 - srem64(bytes_42245, (int64_t) 8), (int64_t) 8) + (bytes_42245 + srem64((int64_t) 8 - srem64(bytes_42245, (int64_t) 8), (int64_t) 8)) + (bytes_42245 + srem64((int64_t) 8 - srem64(bytes_42245, (int64_t) 8), (int64_t) 8)), nS_29940, start_39100, min_res_39102, ldim_41781, num_whole_tiles_41796, residual_input_42020, cond_42021, binop_x_42037, tR_mem_42199.mem, tS_mem_42200.mem, ext_mem_42224.mem, mem_42283.mem, mem_42285.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_set_device(ctx, &ext_mem_42348, &mem_42283, "mem_42283") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &ext_mem_42347, &mem_42285, "mem_42285") != 0)
                        return 1;
                }
                if (memblock_unref_device(ctx, &ext_mem_42224, "ext_mem_42224") != 0)
                    return 1;
                if (memblock_alloc_device(ctx, &mem_42350, bytes_42202, "mem_42350")) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42350.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_42217.mem, ctx_param_ext_42215, (int64_t []) {ctx_param_ext_42216}, (int64_t []) {nR_29939})) != 0)
                    goto cleanup;
                if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42350.mem, start_39100, (int64_t []) {(int64_t) 1}, ext_mem_42348.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {min_res_39102})) != 0)
                    goto cleanup;
                if (memblock_unref_device(ctx, &ext_mem_42348, "ext_mem_42348") != 0)
                    return 1;
                if (memblock_alloc_device(ctx, &mem_42352, bytes_42202, "mem_42352")) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42352.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_42214.mem, ctx_param_ext_42212, (int64_t []) {ctx_param_ext_42213}, (int64_t []) {nR_29939})) != 0)
                    goto cleanup;
                if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42352.mem, start_39100, (int64_t []) {(int64_t) 1}, ext_mem_42347.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {min_res_39102})) != 0)
                    goto cleanup;
                if (memblock_unref_device(ctx, &ext_mem_42347, "ext_mem_42347") != 0)
                    return 1;
                
                int64_t tmp_39179 = add64((int64_t) 1, p_39097);
                
                if (memblock_set_device(ctx, &ext_mem_42358, &mem_42352, "mem_42352") != 0)
                    return 1;
                if (memblock_set_device(ctx, &ext_mem_42355, &mem_42350, "mem_42350") != 0)
                    return 1;
                loopres_f_res_39132 = tmp_39179;
            }
            if (memblock_set_device(ctx, &ext_mem_42364, &ext_mem_42358, "ext_mem_42358") != 0)
                return 1;
            ext_42363 = ext_42357;
            ext_42362 = ext_42356;
            if (memblock_set_device(ctx, &ext_mem_42361, &ext_mem_42355, "ext_mem_42355") != 0)
                return 1;
            ext_42360 = ext_42354;
            ext_42359 = ext_42353;
            loopres_39128 = loopres_f_res_39132;
        }
        if (memblock_unref_device(ctx, &ext_mem_42221, "ext_mem_42221") != 0)
            return 1;
        
        bool loop_cond_39180 = slt64(loopres_39128, numIter_39072);
        
        if (memblock_set_device(ctx, &mem_param_tmp_42742, &ext_mem_42364, "ext_mem_42364") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_42743, &ext_mem_42361, "ext_mem_42361") != 0)
            return 1;
        
        int64_t ctx_param_ext_tmp_42744 = ext_42363;
        int64_t ctx_param_ext_tmp_42745 = ext_42362;
        int64_t ctx_param_ext_tmp_42746 = ext_42360;
        int64_t ctx_param_ext_tmp_42747 = ext_42359;
        bool loop_while_tmp_42748 = loop_cond_39180;
        int64_t p_tmp_42749 = loopres_39128;
        
        if (memblock_set_device(ctx, &mem_param_42214, &mem_param_tmp_42742, "mem_param_tmp_42742") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_42217, &mem_param_tmp_42743, "mem_param_tmp_42743") != 0)
            return 1;
        ctx_param_ext_42212 = ctx_param_ext_tmp_42744;
        ctx_param_ext_42213 = ctx_param_ext_tmp_42745;
        ctx_param_ext_42215 = ctx_param_ext_tmp_42746;
        ctx_param_ext_42216 = ctx_param_ext_tmp_42747;
        loop_while_39096 = loop_while_tmp_42748;
        p_39097 = p_tmp_42749;
    }
    if (memblock_set_device(ctx, &ext_mem_42370, &mem_param_42214, "mem_param_42214") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_42369, &mem_param_42217, "mem_param_42217") != 0)
        return 1;
    ext_42368 = ctx_param_ext_42212;
    ext_42367 = ctx_param_ext_42213;
    ext_42366 = ctx_param_ext_42215;
    ext_42365 = ctx_param_ext_42216;
    defunc_0_find_joinTuples_res_39092 = loop_while_39096;
    defunc_0_find_joinTuples_res_39093 = p_39097;
    if (memblock_unref_device(ctx, &mem_42203, "mem_42203") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42205, "mem_42205") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_42208, "ext_mem_42208") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_42211, "ext_mem_42211") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42218, "mem_42218") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42219, "mem_42219") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42222, "mem_42222") != 0)
        return 1;
    
    int64_t segscan_tblock_sizze_40814;
    
    segscan_tblock_sizze_40814 = *ctx->tuning_params.inner_SMJ_longzisegscan_tblock_sizze_40813;
    
    int64_t num_tblocks_40816;
    int64_t max_num_tblocks_42823;
    
    max_num_tblocks_42823 = *ctx->tuning_params.inner_SMJ_longzisegscan_num_tblocks_40815;
    num_tblocks_40816 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nR_29939, segscan_tblock_sizze_40814), max_num_tblocks_42823)));
    if (memblock_alloc_device(ctx, &mem_42373, bytes_42202, "mem_42373")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42375, bytes_42202, "mem_42375")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, nR_29939)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_42824;
        
        shared_memory_42824 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_42825;
        
        thread_block_sizze_42825 = ctx->max_thread_block_size;
        
        int64_t registers_42826;
        
        registers_42826 = ctx->max_registers;
        
        int64_t thread_block_sizze_42827;
        
        thread_block_sizze_42827 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_42828 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_42824, thread_block_sizze_42825), (int64_t) 8), squot64(squot64(registers_42826, thread_block_sizze_42827) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
        int64_t num_virt_blocks_42829 = sdiv_up64(nR_29939, segscan_tblock_sizze_40814 * chunk_sizze_42828);
        int64_t num_virt_threads_42830 = num_virt_blocks_42829 * segscan_tblock_sizze_40814;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_42828, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_42831, num_virt_blocks_42829, "status_flags_mem_42831")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_42831, num_virt_blocks_42829, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_42853, (int64_t) 8 * num_virt_blocks_42829, "aggregates_mem_42853")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_42855, (int64_t) 8 * num_virt_blocks_42829, "incprefixes_mem_42855")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_longzisegscan_40819(ctx, num_tblocks_40816, 1, 1, *ctx->tuning_params.inner_SMJ_longzisegscan_tblock_sizze_40813, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_40814), chunk_sizze_42828 * segscan_tblock_sizze_40814 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_40814), chunk_sizze_42828 * segscan_tblock_sizze_40814 * (int64_t) 8), (int64_t) 8), (int64_t) 8), nR_29939, num_tblocks_40816, ext_42367, ext_42368, num_virt_blocks_42829, num_virt_threads_42830, ext_mem_42370.mem, mem_42373.mem, mem_42375.mem, status_flags_mem_42831.mem, aggregates_mem_42853.mem, incprefixes_mem_42855.mem, global_dynid_mem_42857.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    
    bool cond_39190 = nR_29939 == (int64_t) 0;
    bool x_39191 = !cond_39190;
    int64_t tmp_39192 = sub64(nR_29939, (int64_t) 1);
    bool x_39193 = sle64((int64_t) 0, tmp_39192);
    bool y_39194 = slt64(tmp_39192, nR_29939);
    bool bounds_check_39195 = x_39193 && y_39194;
    bool protect_assert_disj_39196 = cond_39190 || bounds_check_39195;
    bool index_certs_39197;
    
    if (!protect_assert_disj_39196) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) tmp_39192, "] out of bounds for array of shape [", (long long) nR_29939, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:327:7-328:73\n   #3  ftSMJ.fut:378:133-136\n   #4  ftSMJ.fut:367:1-378:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t m_f_res_39198;
    
    if (x_39191) {
        int64_t read_res_43325;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_43325, mem_42373.mem, tmp_39192 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_39513 = read_res_43325;
        
        m_f_res_39198 = x_39513;
    } else {
        m_f_res_39198 = (int64_t) 0;
    }
    
    int64_t m_39200;
    
    if (cond_39190) {
        m_39200 = (int64_t) 0;
    } else {
        m_39200 = m_f_res_39198;
    }
    
    int64_t m_39210 = sub64(m_39200, (int64_t) 1);
    bool i_p_m_t_s_leq_w_39212 = slt64(m_39210, nR_29939);
    bool zzero_leq_i_p_m_t_s_39211 = sle64((int64_t) 0, m_39210);
    bool y_39214 = zzero_leq_i_p_m_t_s_39211 && i_p_m_t_s_leq_w_39212;
    bool i_lte_j_39213 = sle64((int64_t) 0, m_39200);
    bool forwards_ok_39215 = i_lte_j_39213 && y_39214;
    bool eq_x_zz_39207 = (int64_t) 0 == m_f_res_39198;
    bool p_and_eq_x_y_39208 = x_39191 && eq_x_zz_39207;
    bool empty_slice_39209 = cond_39190 || p_and_eq_x_y_39208;
    bool ok_or_empty_39216 = empty_slice_39209 || forwards_ok_39215;
    bool index_certs_39217;
    
    if (!ok_or_empty_39216) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_39200, "] out of bounds for array of shape [", (long long) nR_29939, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:327:7-328:73\n   #3  ftSMJ.fut:378:133-136\n   #4  ftSMJ.fut:367:1-378:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_42376 = (int64_t) 8 * m_39200;
    
    if (memblock_alloc_device(ctx, &mem_42377, bytes_42376, "mem_42377")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42377.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42370.mem, ext_42368, (int64_t []) {ext_42367}, (int64_t []) {m_39200})) != 0)
        goto cleanup;
    if (memblock_alloc_device(ctx, &mem_42379, bytes_42376, "mem_42379")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42379.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42369.mem, ext_42366, (int64_t []) {ext_42365}, (int64_t []) {m_39200})) != 0)
        goto cleanup;
    if (memblock_alloc_device(ctx, &mem_42381, bytes_42376, "mem_42381")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42381.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42201.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_39200})) != 0)
        goto cleanup;
    if (memblock_alloc_device(ctx, &mem_42383, bytes_42376, "mem_42383")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42383.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, tR_mem_42199.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_39200})) != 0)
        goto cleanup;
    
    int64_t segmap_tblock_sizze_40824;
    
    segmap_tblock_sizze_40824 = *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_40823;
    
    int64_t num_tblocks_40826;
    int64_t max_num_tblocks_42966;
    
    max_num_tblocks_42966 = *ctx->tuning_params.inner_SMJ_longzisegmap_num_tblocks_40825;
    num_tblocks_40826 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nR_29939, segmap_tblock_sizze_40824), max_num_tblocks_42966)));
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_42967 = sext_i64_i32(sdiv_up64(nR_29939, segmap_tblock_sizze_40824));
    
    {
        err = gpu_kernel_inner_SMJ_longzisegmap_40821(ctx, num_tblocks_40826, 1, 1, *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_40823, 1, 1, (int64_t) 0, nR_29939, m_39200, num_tblocks_40826, ext_42365, ext_42366, ext_42367, ext_42368, virt_num_tblocks_42967, tR_mem_42199.mem, ext_mem_42201.mem, ext_mem_42369.mem, ext_mem_42370.mem, mem_42373.mem, mem_42375.mem, mem_42377.mem, mem_42379.mem, mem_42381.mem, mem_42383.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &ext_mem_42201, "ext_mem_42201") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_42369, "ext_mem_42369") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_42370, "ext_mem_42370") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42373, "mem_42373") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42375, "mem_42375") != 0)
        return 1;
    
    int64_t segscan_tblock_sizze_40830;
    
    segscan_tblock_sizze_40830 = *ctx->tuning_params.inner_SMJ_longzisegscan_tblock_sizze_40829;
    
    int64_t num_tblocks_40832;
    int64_t max_num_tblocks_42980;
    
    max_num_tblocks_42980 = *ctx->tuning_params.inner_SMJ_longzisegscan_num_tblocks_40831;
    num_tblocks_40832 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_39200, segscan_tblock_sizze_40830), max_num_tblocks_42980)));
    if (memblock_alloc_device(ctx, &mem_42387, bytes_42376, "mem_42387")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42389, bytes_42376, "mem_42389")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42391, bytes_42376, "mem_42391")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, m_39200)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_42981;
        
        shared_memory_42981 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_42982;
        
        thread_block_sizze_42982 = ctx->max_thread_block_size;
        
        int64_t registers_42983;
        
        registers_42983 = ctx->max_registers;
        
        int64_t thread_block_sizze_42984;
        
        thread_block_sizze_42984 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_42985 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_42981, thread_block_sizze_42982), (int64_t) 8), squot64(squot64(registers_42983, thread_block_sizze_42984) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
        int64_t num_virt_blocks_42986 = sdiv_up64(m_39200, segscan_tblock_sizze_40830 * chunk_sizze_42985);
        int64_t num_virt_threads_42987 = num_virt_blocks_42986 * segscan_tblock_sizze_40830;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_42985, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_42988, num_virt_blocks_42986, "status_flags_mem_42988")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_42988, num_virt_blocks_42986, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_42990, (int64_t) 8 * num_virt_blocks_42986, "aggregates_mem_42990")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_42992, (int64_t) 8 * num_virt_blocks_42986, "incprefixes_mem_42992")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_42994, (int64_t) 8 * num_virt_blocks_42986, "aggregates_mem_42994")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_42996, (int64_t) 8 * num_virt_blocks_42986, "incprefixes_mem_42996")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_longzisegscan_40835(ctx, num_tblocks_40832, 1, 1, *ctx->tuning_params.inner_SMJ_longzisegscan_tblock_sizze_40829, 1, 1, smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_40830, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_40830), smax64(chunk_sizze_42985 * segscan_tblock_sizze_40830 * (int64_t) 8, chunk_sizze_42985 * segscan_tblock_sizze_40830 * (int64_t) 8)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_40830, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_40830), smax64(chunk_sizze_42985 * segscan_tblock_sizze_40830 * (int64_t) 8, chunk_sizze_42985 * segscan_tblock_sizze_40830 * (int64_t) 8)), (int64_t) 8), (int64_t) 8), m_39200, num_tblocks_40832, num_virt_blocks_42986, num_virt_threads_42987, mem_42377.mem, mem_42387.mem, mem_42389.mem, mem_42391.mem, status_flags_mem_42988.mem, aggregates_mem_42990.mem, incprefixes_mem_42992.mem, aggregates_mem_42994.mem, incprefixes_mem_42996.mem, global_dynid_mem_42998.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    
    int64_t segmap_tblock_sizze_40851;
    
    segmap_tblock_sizze_40851 = *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_40839;
    
    int64_t segmap_usable_groups_40852 = sdiv_up64(m_39200, segmap_tblock_sizze_40851);
    
    if (memblock_alloc_device(ctx, &mem_42394, bytes_42376, "mem_42394")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_43133 = sext_i64_i32(sdiv_up64(m_39200, segmap_tblock_sizze_40851));
    
    {
        err = gpu_kernel_inner_SMJ_longzisegmap_40855(ctx, segmap_usable_groups_40852, 1, 1, *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_40839, 1, 1, (int64_t) 0, m_39200, mem_42387.mem, mem_42394.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_42387, "mem_42387") != 0)
        return 1;
    
    bool cond_39251 = slt64((int64_t) 0, m_39200);
    bool y_39252 = slt64(m_39210, m_39200);
    bool bounds_check_39253 = zzero_leq_i_p_m_t_s_39211 && y_39252;
    bool loop_not_taken_39254 = !cond_39251;
    bool protect_assert_disj_39255 = bounds_check_39253 || loop_not_taken_39254;
    bool index_certs_39256;
    
    if (!protect_assert_disj_39255) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) m_39210, "] out of bounds for array of shape [", (long long) m_39200, "].", "-> #0  ftSMJ.fut:285:10-41\n   #1  ftSMJ.fut:327:7-328:73\n   #2  ftSMJ.fut:378:133-136\n   #3  ftSMJ.fut:367:1-378:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    if (cond_39251) {
        if (memblock_alloc_device(ctx, &mem_42396, (int64_t) 8, "mem_42396")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_longzigpuseq_43142(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, m_39210, mem_42394.mem, mem_42396.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42397, &mem_42396, "mem_42396") != 0)
            return 1;
    } else {
        if (memblock_alloc_device(ctx, &mem_42395, (int64_t) 8, "mem_42395")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i64(ctx, mem_42395, (int64_t) 1, (int64_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42397, &mem_42395, "mem_42395") != 0)
            return 1;
    }
    if (cond_39251) {
        if (memblock_alloc_device(ctx, &mem_42399, (int64_t) 8, "mem_42399")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_longzigpuseq_43148(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, m_39210, mem_42377.mem, mem_42399.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42400, &mem_42399, "mem_42399") != 0)
            return 1;
    } else {
        if (memblock_alloc_device(ctx, &mem_42398, (int64_t) 8, "mem_42398")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i64(ctx, mem_42398, (int64_t) 1, (int64_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42400, &mem_42398, "mem_42398") != 0)
            return 1;
    }
    
    bool zzero_39268 = scatter_psizze_29948 == (int64_t) 0;
    bool nonzzero_39269 = !zzero_39268;
    bool nonzzero_cert_39270;
    
    if (!nonzzero_39269) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftbasics.fut:66:23-29\n   #1  ftSMJ.fut:327:7-328:73\n   #2  ftSMJ.fut:378:133-136\n   #3  ftSMJ.fut:367:1-378:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    bool x_39335 = !empty_slice_39209;
    bool protect_assert_disj_39336 = empty_slice_39209 || bounds_check_39253;
    bool index_certs_39337;
    
    if (!protect_assert_disj_39336) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) m_39210, "] out of bounds for array of shape [", (long long) m_39200, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:327:7-328:73\n   #3  ftSMJ.fut:378:133-136\n   #4  ftSMJ.fut:367:1-378:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t m_f_res_39338;
    
    if (x_39335) {
        int64_t read_res_43326;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_43326, mem_42389.mem, m_39210 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_39521 = read_res_43326;
        
        m_f_res_39338 = x_39521;
    } else {
        m_f_res_39338 = (int64_t) 0;
    }
    
    int64_t m_39340;
    
    if (empty_slice_39209) {
        m_39340 = (int64_t) 0;
    } else {
        m_39340 = m_f_res_39338;
    }
    
    int64_t m_39350 = sub64(m_39340, (int64_t) 1);
    bool i_p_m_t_s_leq_w_39352 = slt64(m_39350, m_39200);
    bool zzero_leq_i_p_m_t_s_39351 = sle64((int64_t) 0, m_39350);
    bool y_39354 = zzero_leq_i_p_m_t_s_39351 && i_p_m_t_s_leq_w_39352;
    bool i_lte_j_39353 = sle64((int64_t) 0, m_39340);
    bool forwards_ok_39355 = i_lte_j_39353 && y_39354;
    bool eq_x_zz_39347 = (int64_t) 0 == m_f_res_39338;
    bool p_and_eq_x_y_39348 = x_39335 && eq_x_zz_39347;
    bool empty_slice_39349 = empty_slice_39209 || p_and_eq_x_y_39348;
    bool ok_or_empty_39356 = empty_slice_39349 || forwards_ok_39355;
    bool index_certs_39357;
    
    if (!ok_or_empty_39356) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_39340, "] out of bounds for array of shape [", (long long) m_39200, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:327:7-328:73\n   #3  ftSMJ.fut:378:133-136\n   #4  ftSMJ.fut:367:1-378:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_42401 = (int64_t) 8 * m_39340;
    
    if (memblock_alloc_device(ctx, &mem_42406, (int64_t) 8, "mem_42406")) {
        err = 1;
        goto cleanup;
    }
    {
        err = gpu_kernel_inner_SMJ_longzigpuseq_43154(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, ext_mem_42397.mem, ext_mem_42400.mem, mem_42406.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (memblock_unref_device(ctx, &ext_mem_42397, "ext_mem_42397") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_42400, "ext_mem_42400") != 0)
        return 1;
    
    int64_t n_pairs_t_res_39261;
    
    if (cond_39251) {
        int64_t read_res_43327;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_43327, mem_42406.mem, (int64_t) 0 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_42197 = read_res_43327;
        
        n_pairs_t_res_39261 = x_42197;
    } else {
        n_pairs_t_res_39261 = (int64_t) 0;
    }
    if (memblock_unref_device(ctx, &mem_42406, "mem_42406") != 0)
        return 1;
    
    int64_t n_pairs_39262;
    
    if (cond_39251) {
        n_pairs_39262 = n_pairs_t_res_39261;
    } else {
        n_pairs_39262 = (int64_t) 0;
    }
    
    int64_t bytes_42407 = (int64_t) 8 * n_pairs_39262;
    int64_t segmap_tblock_sizze_40866;
    
    segmap_tblock_sizze_40866 = *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_40865;
    
    int64_t num_tblocks_40868;
    int64_t max_num_tblocks_43160;
    
    max_num_tblocks_43160 = *ctx->tuning_params.inner_SMJ_longzisegmap_num_tblocks_40867;
    num_tblocks_40868 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_39200, segmap_tblock_sizze_40866), max_num_tblocks_43160)));
    if (memblock_alloc_device(ctx, &mem_42402, bytes_42401, "mem_42402")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42402.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_42377.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_39340})) != 0)
        goto cleanup;
    if (memblock_alloc_device(ctx, &mem_42404, bytes_42401, "mem_42404")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42404.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_42394.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_39340})) != 0)
        goto cleanup;
    
    int64_t segmap_tblock_sizze_40874;
    
    segmap_tblock_sizze_40874 = *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_40873;
    
    int64_t num_tblocks_40876;
    int64_t max_num_tblocks_43161;
    
    max_num_tblocks_43161 = *ctx->tuning_params.inner_SMJ_longzisegmap_num_tblocks_40875;
    num_tblocks_40876 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_39200, segmap_tblock_sizze_40874), max_num_tblocks_43161)));
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_43162 = sext_i64_i32(sdiv_up64(m_39200, segmap_tblock_sizze_40874));
    
    {
        err = gpu_kernel_inner_SMJ_longzisegmap_40871(ctx, num_tblocks_40876, 1, 1, *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_40873, 1, 1, (int64_t) 0, m_39200, m_39340, num_tblocks_40876, virt_num_tblocks_43162, mem_42377.mem, mem_42389.mem, mem_42391.mem, mem_42394.mem, mem_42402.mem, mem_42404.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_42377, "mem_42377") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42389, "mem_42389") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42391, "mem_42391") != 0)
        return 1;
    
    bool cond_39367 = slt64((int64_t) 0, m_39340);
    int64_t segmap_tblock_sizze_40889;
    
    segmap_tblock_sizze_40889 = *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_40881;
    if (memblock_alloc_device(ctx, &mem_42408, bytes_42407, "mem_42408")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_42408, n_pairs_39262, (int64_t) 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42410, bytes_42407, "mem_42410")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_42410, n_pairs_39262, (int64_t) -1) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42412, bytes_42407, "mem_42412")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_42412, n_pairs_39262, (int64_t) -1) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t zm_lhs_39266 = add64(scatter_psizze_29948, n_pairs_39262);
    int64_t zs_lhs_39267 = sub64(zm_lhs_39266, (int64_t) 1);
    int64_t m_39271 = sdiv64(zs_lhs_39267, scatter_psizze_29948);
    bool loop_cond_39272 = slt64((int64_t) 0, m_39271);
    bool partitioned_scatter_res_39273;
    int64_t partitioned_scatter_res_39277;
    bool loop_while_39278;
    int64_t p_39282;
    
    loop_while_39278 = loop_cond_39272;
    p_39282 = (int64_t) 0;
    while (loop_while_39278) {
        int64_t lower_bound_39283 = mul64(scatter_psizze_29948, p_39282);
        int64_t min_arg1_39284 = add64(scatter_psizze_29948, lower_bound_39283);
        int64_t min_res_39285 = smin64(n_pairs_39262, min_arg1_39284);
        int64_t j_m_i_39286 = sub64(min_res_39285, lower_bound_39283);
        bool empty_slice_39287 = j_m_i_39286 == (int64_t) 0;
        int64_t m_39288 = sub64(j_m_i_39286, (int64_t) 1);
        int64_t i_p_m_t_s_39289 = add64(lower_bound_39283, m_39288);
        bool zzero_leq_i_p_m_t_s_39290 = sle64((int64_t) 0, i_p_m_t_s_39289);
        bool i_p_m_t_s_leq_w_39291 = slt64(i_p_m_t_s_39289, n_pairs_39262);
        bool zzero_lte_i_39292 = sle64((int64_t) 0, lower_bound_39283);
        bool i_lte_j_39293 = sle64(lower_bound_39283, min_res_39285);
        bool y_39294 = i_p_m_t_s_leq_w_39291 && zzero_lte_i_39292;
        bool y_39295 = zzero_leq_i_p_m_t_s_39290 && y_39294;
        bool forwards_ok_39296 = i_lte_j_39293 && y_39295;
        bool ok_or_empty_39297 = empty_slice_39287 || forwards_ok_39296;
        bool index_certs_39298;
        
        if (!ok_or_empty_39297) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) lower_bound_39283, ":", (long long) min_res_39285, "] out of bounds for array of shape [", (long long) n_pairs_39262, "].", "-> #0  ftbasics.fut:72:25-56\n   #1  ftSMJ.fut:327:7-328:73\n   #2  ftSMJ.fut:378:133-136\n   #3  ftSMJ.fut:367:1-378:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t bytes_42422 = (int64_t) 8 * j_m_i_39286;
        
        if (memblock_alloc_device(ctx, &mem_42423, bytes_42422, "mem_42423")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42423.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_42408.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_39283, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_39286})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_42425, bytes_42422, "mem_42425")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42425.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_42410.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_39283, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_39286})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_42427, bytes_42422, "mem_42427")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42427.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_42412.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_39283, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_39286})) != 0)
            goto cleanup;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_43180 = sext_i64_i32(sdiv_up64(m_39200, segmap_tblock_sizze_40866));
        
        {
            err = gpu_kernel_inner_SMJ_longzisegmap_40863(ctx, num_tblocks_40868, 1, 1, *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_40865, 1, 1, (int64_t) 0, m_39200, lower_bound_39283, min_res_39285, j_m_i_39286, num_tblocks_40868, virt_num_tblocks_43180, mem_42379.mem, mem_42381.mem, mem_42383.mem, mem_42394.mem, mem_42423.mem, mem_42425.mem, mem_42427.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t tmp_39312 = add64((int64_t) 1, p_39282);
        
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42408.mem, lower_bound_39283, (int64_t []) {(int64_t) 1}, mem_42423.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_39286})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_42423, "mem_42423") != 0)
            return 1;
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42410.mem, lower_bound_39283, (int64_t []) {(int64_t) 1}, mem_42425.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_39286})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_42425, "mem_42425") != 0)
            return 1;
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42412.mem, lower_bound_39283, (int64_t []) {(int64_t) 1}, mem_42427.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_39286})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_42427, "mem_42427") != 0)
            return 1;
        
        bool loop_cond_39323 = slt64(tmp_39312, m_39271);
        bool loop_while_tmp_43175 = loop_cond_39323;
        int64_t p_tmp_43179 = tmp_39312;
        
        loop_while_39278 = loop_while_tmp_43175;
        p_39282 = p_tmp_43179;
    }
    partitioned_scatter_res_39273 = loop_while_39278;
    partitioned_scatter_res_39277 = p_39282;
    if (memblock_unref_device(ctx, &mem_42379, "mem_42379") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42381, "mem_42381") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42383, "mem_42383") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42394, "mem_42394") != 0)
        return 1;
    
    bool loop_cond_t_res_39368 = slt64(m_39200, n_pairs_39262);
    bool x_39369 = cond_39367 && loop_cond_t_res_39368;
    
    if (memblock_alloc_device(ctx, &mem_42453, (int64_t) 8, "mem_42453")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42454, (int64_t) 8, "mem_42454")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42455, (int64_t) 8, "mem_42455")) {
        err = 1;
        goto cleanup;
    }
    
    bool joinTups_to_joinPairs_InnerJoin_res_39370;
    int64_t joinTups_to_joinPairs_InnerJoin_res_39374;
    bool loop_while_39375;
    int64_t p_39379;
    
    if (memblock_set_device(ctx, &mem_param_42440, &mem_42408, "mem_42408") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_42443, &mem_42410, "mem_42410") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_42446, &mem_42412, "mem_42412") != 0)
        return 1;
    loop_while_39375 = x_39369;
    p_39379 = (int64_t) 0;
    while (loop_while_39375) {
        bool x_39380 = sle64((int64_t) 0, p_39379);
        bool y_39381 = slt64(p_39379, m_39340);
        bool bounds_check_39382 = x_39380 && y_39381;
        bool index_certs_39383;
        
        if (!bounds_check_39382) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) p_39379, "] out of bounds for array of shape [", (long long) m_39340, "].", "-> #0  ftSMJ.fut:300:13-42\n   #1  ftSMJ.fut:327:7-328:73\n   #2  ftSMJ.fut:378:133-136\n   #3  ftSMJ.fut:367:1-378:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t read_res_43328;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_43328, mem_42404.mem, p_39379 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t loopres_39384 = read_res_43328;
        int64_t read_res_43329;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_43329, mem_42402.mem, p_39379 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t loopres_39385 = read_res_43329;
        bool x_39386 = sle64((int64_t) 0, loopres_39384);
        bool y_39387 = slt64(loopres_39384, n_pairs_39262);
        bool bounds_check_39388 = x_39386 && y_39387;
        bool index_certs_39389;
        
        if (!bounds_check_39388) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) loopres_39384, "] out of bounds for array of shape [", (long long) n_pairs_39262, "].", "-> #0  ftSMJ.fut:302:52-61\n   #1  ftSMJ.fut:327:7-328:73\n   #2  ftSMJ.fut:378:133-136\n   #3  ftSMJ.fut:367:1-378:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t tmp_39400 = add64(loopres_39384, loopres_39385);
        bool empty_slice_39404 = loopres_39385 == (int64_t) 0;
        int64_t m_39405 = sub64(loopres_39385, (int64_t) 1);
        int64_t i_p_m_t_s_39406 = add64(loopres_39384, m_39405);
        bool zzero_leq_i_p_m_t_s_39407 = sle64((int64_t) 0, i_p_m_t_s_39406);
        bool i_p_m_t_s_leq_w_39408 = slt64(i_p_m_t_s_39406, n_pairs_39262);
        bool i_lte_j_39409 = sle64(loopres_39384, tmp_39400);
        bool y_39410 = x_39386 && i_p_m_t_s_leq_w_39408;
        bool y_39411 = zzero_leq_i_p_m_t_s_39407 && y_39410;
        bool forwards_ok_39412 = i_lte_j_39409 && y_39411;
        bool ok_or_empty_39413 = empty_slice_39404 || forwards_ok_39412;
        bool index_certs_39414;
        
        if (!ok_or_empty_39413) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) loopres_39384, ":", (long long) tmp_39400, "] out of bounds for array of shape [", (long long) n_pairs_39262, "].", "-> #0  ftSMJ.fut:306:14-55\n   #1  ftSMJ.fut:327:7-328:73\n   #2  ftSMJ.fut:378:133-136\n   #3  ftSMJ.fut:367:1-378:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t bytes_42456 = (int64_t) 8 * loopres_39385;
        int64_t segmap_usable_groups_40890 = sdiv_up64(loopres_39385, segmap_tblock_sizze_40889);
        int64_t tmp_39399 = add64((int64_t) 1, p_39379);
        
        if (memblock_alloc_device(ctx, &mem_42448, bytes_42407, "mem_42448")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42448.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_42440.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_39262})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_42450, bytes_42407, "mem_42450")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42450.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_42443.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_39262})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_42452, bytes_42407, "mem_42452")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42452.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_42446.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_39262})) != 0)
            goto cleanup;
        
        bool cond_39418 = slt64(tmp_39399, m_39340);
        bool x_39419 = loop_cond_t_res_39368 && cond_39418;
        
        {
            err = gpu_kernel_inner_SMJ_longzigpuseq_43201(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, loopres_39384, mem_param_42440.mem, mem_param_42443.mem, mem_param_42446.mem, mem_42453.mem, mem_42454.mem, mem_42455.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_42457, bytes_42456, "mem_42457")) {
            err = 1;
            goto cleanup;
        }
        
        int64_t replicate_n_43207 = loopres_39385;
        int64_t tblock_sizze_43212;
        
        tblock_sizze_43212 = *ctx->tuning_params.inner_SMJ_longzitblock_sizze_43212;
        
        int64_t virt_num_tblocks_43213 = sdiv_up64(replicate_n_43207, tblock_sizze_43212);
        int64_t num_tblocks_43214 = smin64(virt_num_tblocks_43213, (int64_t) 1048576);
        
        {
            err = gpu_kernel_inner_SMJ_longzireplicate_43208(ctx, num_tblocks_43214, 1, 1, tblock_sizze_43212, 1, 1, (int64_t) 0, loopres_39385, replicate_n_43207, virt_num_tblocks_43213, num_tblocks_43214, mem_42453.mem, mem_42457.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_42459, bytes_42456, "mem_42459")) {
            err = 1;
            goto cleanup;
        }
        
        int64_t replicate_n_43227 = loopres_39385;
        int64_t tblock_sizze_43232;
        
        tblock_sizze_43232 = *ctx->tuning_params.inner_SMJ_longzitblock_sizze_43232;
        
        int64_t virt_num_tblocks_43233 = sdiv_up64(replicate_n_43227, tblock_sizze_43232);
        int64_t num_tblocks_43234 = smin64(virt_num_tblocks_43233, (int64_t) 1048576);
        
        {
            err = gpu_kernel_inner_SMJ_longzireplicate_43228(ctx, num_tblocks_43234, 1, 1, tblock_sizze_43232, 1, 1, (int64_t) 0, loopres_39385, replicate_n_43227, virt_num_tblocks_43233, num_tblocks_43234, mem_42454.mem, mem_42459.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_43247 = sext_i64_i32(sdiv_up64(loopres_39385, segmap_tblock_sizze_40889));
        
        {
            err = gpu_kernel_inner_SMJ_longzisegmap_40893(ctx, segmap_usable_groups_40890, 1, 1, *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_40881, 1, 1, (int64_t) 0, loopres_39384, loopres_39385, mem_42452.mem, mem_42455.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42448.mem, loopres_39384, (int64_t []) {(int64_t) 1}, mem_42457.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {loopres_39385})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_42457, "mem_42457") != 0)
            return 1;
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42450.mem, loopres_39384, (int64_t []) {(int64_t) 1}, mem_42459.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {loopres_39385})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_42459, "mem_42459") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_43193, &mem_42448, "mem_42448") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_43194, &mem_42450, "mem_42450") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_43195, &mem_42452, "mem_42452") != 0)
            return 1;
        
        bool loop_while_tmp_43196 = x_39419;
        int64_t p_tmp_43200 = tmp_39399;
        
        if (memblock_set_device(ctx, &mem_param_42440, &mem_param_tmp_43193, "mem_param_tmp_43193") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_42443, &mem_param_tmp_43194, "mem_param_tmp_43194") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_42446, &mem_param_tmp_43195, "mem_param_tmp_43195") != 0)
            return 1;
        loop_while_39375 = loop_while_tmp_43196;
        p_39379 = p_tmp_43200;
    }
    if (memblock_set_device(ctx, &ext_mem_42471, &mem_param_42440, "mem_param_42440") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_42470, &mem_param_42443, "mem_param_42443") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_42469, &mem_param_42446, "mem_param_42446") != 0)
        return 1;
    joinTups_to_joinPairs_InnerJoin_res_39370 = loop_while_39375;
    joinTups_to_joinPairs_InnerJoin_res_39374 = p_39379;
    if (memblock_unref_device(ctx, &mem_42402, "mem_42402") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42404, "mem_42404") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42408, "mem_42408") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42410, "mem_42410") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42412, "mem_42412") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42453, "mem_42453") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42454, "mem_42454") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42455, "mem_42455") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_42473, bytes_42407, "mem_42473")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42473.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42471.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_39262})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_42471, "ext_mem_42471") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_42475, bytes_42407, "mem_42475")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42475.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42470.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_39262})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_42470, "ext_mem_42470") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_42477, bytes_42407, "mem_42477")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42477.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42469.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_39262})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_42469, "ext_mem_42469") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_42706, &mem_42475, "mem_42475") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_42707, &mem_42477, "mem_42477") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_42708, &mem_42473, "mem_42473") != 0)
        return 1;
    prim_out_42709 = n_pairs_39262;
    if (memblock_set_device(ctx, &*mem_out_p_43319, &mem_out_42706, "mem_out_42706") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_43320, &mem_out_42707, "mem_out_42707") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_43321, &mem_out_42708, "mem_out_42708") != 0)
        return 1;
    *out_prim_out_43322 = prim_out_42709;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_42477, "mem_42477") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42475, "mem_42475") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42473, "mem_42473") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_43195, "mem_param_tmp_43195") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_43194, "mem_param_tmp_43194") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_43193, "mem_param_tmp_43193") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42459, "mem_42459") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42457, "mem_42457") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42452, "mem_42452") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42450, "mem_42450") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42448, "mem_42448") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42446, "mem_param_42446") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42443, "mem_param_42443") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42440, "mem_param_42440") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42469, "ext_mem_42469") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42470, "ext_mem_42470") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42471, "ext_mem_42471") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42455, "mem_42455") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42454, "mem_42454") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42453, "mem_42453") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42427, "mem_42427") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42425, "mem_42425") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42423, "mem_42423") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42412, "mem_42412") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42410, "mem_42410") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42408, "mem_42408") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42404, "mem_42404") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42402, "mem_42402") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42406, "mem_42406") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42398, "mem_42398") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42399, "mem_42399") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42400, "ext_mem_42400") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42395, "mem_42395") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42396, "mem_42396") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42397, "ext_mem_42397") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42394, "mem_42394") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_42996, "incprefixes_mem_42996") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_42994, "aggregates_mem_42994") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_42992, "incprefixes_mem_42992") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_42990, "aggregates_mem_42990") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_42988, "status_flags_mem_42988") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42391, "mem_42391") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42389, "mem_42389") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42387, "mem_42387") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42383, "mem_42383") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42381, "mem_42381") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42379, "mem_42379") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42377, "mem_42377") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_42855, "incprefixes_mem_42855") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_42853, "aggregates_mem_42853") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_42831, "status_flags_mem_42831") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42375, "mem_42375") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42373, "mem_42373") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_42743, "mem_param_tmp_42743") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_42742, "mem_param_tmp_42742") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42352, "mem_42352") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42350, "mem_42350") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42285, "mem_42285") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42283, "mem_42283") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42346, "mem_42346") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42344, "mem_42344") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42347, "ext_mem_42347") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42348, "ext_mem_42348") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42224, "ext_mem_42224") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42355, "ext_mem_42355") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42358, "ext_mem_42358") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42223, "mem_42223") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42361, "ext_mem_42361") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42364, "ext_mem_42364") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42221, "ext_mem_42221") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42220, "ext_mem_42220") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42217, "mem_param_42217") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42214, "mem_param_42214") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42369, "ext_mem_42369") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42370, "ext_mem_42370") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42222, "mem_42222") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42219, "mem_42219") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42218, "mem_42218") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42209, "mem_42209") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42210, "mem_42210") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42211, "ext_mem_42211") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42206, "mem_42206") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42207, "mem_42207") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42208, "ext_mem_42208") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42205, "mem_42205") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42203, "mem_42203") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42201, "ext_mem_42201") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_42708, "mem_out_42708") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_42707, "mem_out_42707") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_42706, "mem_out_42706") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_inner_SMJ_short(struct futhark_context *ctx, struct memblock_device *mem_out_p_43330, struct memblock_device *mem_out_p_43331, struct memblock_device *mem_out_p_43332, int64_t *out_prim_out_43333, struct memblock_device tR_mem_42199, struct memblock_device tS_mem_42200, int64_t nR_25439, int64_t nS_25440, int64_t offset_R_25443, int64_t offset_S_25444, int64_t partitionsPerWindow_25445, int64_t numberOfWindows_25446, int64_t extParallelism_25447, int64_t scatter_psizze_25448)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_42477;
    
    mem_42477.references = NULL;
    
    struct memblock_device mem_42475;
    
    mem_42475.references = NULL;
    
    struct memblock_device mem_42473;
    
    mem_42473.references = NULL;
    
    struct memblock_device mem_param_tmp_43215;
    
    mem_param_tmp_43215.references = NULL;
    
    struct memblock_device mem_param_tmp_43214;
    
    mem_param_tmp_43214.references = NULL;
    
    struct memblock_device mem_param_tmp_43213;
    
    mem_param_tmp_43213.references = NULL;
    
    struct memblock_device mem_42459;
    
    mem_42459.references = NULL;
    
    struct memblock_device mem_42457;
    
    mem_42457.references = NULL;
    
    struct memblock_device mem_42452;
    
    mem_42452.references = NULL;
    
    struct memblock_device mem_42450;
    
    mem_42450.references = NULL;
    
    struct memblock_device mem_42448;
    
    mem_42448.references = NULL;
    
    struct memblock_device mem_param_42446;
    
    mem_param_42446.references = NULL;
    
    struct memblock_device mem_param_42443;
    
    mem_param_42443.references = NULL;
    
    struct memblock_device mem_param_42440;
    
    mem_param_42440.references = NULL;
    
    struct memblock_device ext_mem_42469;
    
    ext_mem_42469.references = NULL;
    
    struct memblock_device ext_mem_42470;
    
    ext_mem_42470.references = NULL;
    
    struct memblock_device ext_mem_42471;
    
    ext_mem_42471.references = NULL;
    
    struct memblock_device mem_42455;
    
    mem_42455.references = NULL;
    
    struct memblock_device mem_42454;
    
    mem_42454.references = NULL;
    
    struct memblock_device mem_42453;
    
    mem_42453.references = NULL;
    
    struct memblock_device mem_42427;
    
    mem_42427.references = NULL;
    
    struct memblock_device mem_42425;
    
    mem_42425.references = NULL;
    
    struct memblock_device mem_42423;
    
    mem_42423.references = NULL;
    
    struct memblock_device mem_42412;
    
    mem_42412.references = NULL;
    
    struct memblock_device mem_42410;
    
    mem_42410.references = NULL;
    
    struct memblock_device mem_42408;
    
    mem_42408.references = NULL;
    
    struct memblock_device mem_42404;
    
    mem_42404.references = NULL;
    
    struct memblock_device mem_42402;
    
    mem_42402.references = NULL;
    
    struct memblock_device mem_42406;
    
    mem_42406.references = NULL;
    
    struct memblock_device mem_42398;
    
    mem_42398.references = NULL;
    
    struct memblock_device mem_42399;
    
    mem_42399.references = NULL;
    
    struct memblock_device ext_mem_42400;
    
    ext_mem_42400.references = NULL;
    
    struct memblock_device mem_42395;
    
    mem_42395.references = NULL;
    
    struct memblock_device mem_42396;
    
    mem_42396.references = NULL;
    
    struct memblock_device ext_mem_42397;
    
    ext_mem_42397.references = NULL;
    
    struct memblock_device mem_42394;
    
    mem_42394.references = NULL;
    
    struct memblock_device incprefixes_mem_43016;
    
    incprefixes_mem_43016.references = NULL;
    
    struct memblock_device aggregates_mem_43014;
    
    aggregates_mem_43014.references = NULL;
    
    struct memblock_device incprefixes_mem_43012;
    
    incprefixes_mem_43012.references = NULL;
    
    struct memblock_device aggregates_mem_43010;
    
    aggregates_mem_43010.references = NULL;
    
    struct memblock_device status_flags_mem_43008;
    
    status_flags_mem_43008.references = NULL;
    
    struct memblock_device mem_42391;
    
    mem_42391.references = NULL;
    
    struct memblock_device mem_42389;
    
    mem_42389.references = NULL;
    
    struct memblock_device mem_42387;
    
    mem_42387.references = NULL;
    
    struct memblock_device mem_42383;
    
    mem_42383.references = NULL;
    
    struct memblock_device mem_42381;
    
    mem_42381.references = NULL;
    
    struct memblock_device mem_42379;
    
    mem_42379.references = NULL;
    
    struct memblock_device mem_42377;
    
    mem_42377.references = NULL;
    
    struct memblock_device incprefixes_mem_42875;
    
    incprefixes_mem_42875.references = NULL;
    
    struct memblock_device aggregates_mem_42873;
    
    aggregates_mem_42873.references = NULL;
    
    struct memblock_device status_flags_mem_42851;
    
    status_flags_mem_42851.references = NULL;
    
    struct memblock_device mem_42375;
    
    mem_42375.references = NULL;
    
    struct memblock_device mem_42373;
    
    mem_42373.references = NULL;
    
    struct memblock_device mem_param_tmp_42763;
    
    mem_param_tmp_42763.references = NULL;
    
    struct memblock_device mem_param_tmp_42762;
    
    mem_param_tmp_42762.references = NULL;
    
    struct memblock_device mem_42352;
    
    mem_42352.references = NULL;
    
    struct memblock_device mem_42350;
    
    mem_42350.references = NULL;
    
    struct memblock_device mem_42285;
    
    mem_42285.references = NULL;
    
    struct memblock_device mem_42283;
    
    mem_42283.references = NULL;
    
    struct memblock_device mem_42346;
    
    mem_42346.references = NULL;
    
    struct memblock_device mem_42344;
    
    mem_42344.references = NULL;
    
    struct memblock_device ext_mem_42347;
    
    ext_mem_42347.references = NULL;
    
    struct memblock_device ext_mem_42348;
    
    ext_mem_42348.references = NULL;
    
    struct memblock_device ext_mem_42224;
    
    ext_mem_42224.references = NULL;
    
    struct memblock_device ext_mem_42355;
    
    ext_mem_42355.references = NULL;
    
    struct memblock_device ext_mem_42358;
    
    ext_mem_42358.references = NULL;
    
    struct memblock_device mem_42223;
    
    mem_42223.references = NULL;
    
    struct memblock_device ext_mem_42361;
    
    ext_mem_42361.references = NULL;
    
    struct memblock_device ext_mem_42364;
    
    ext_mem_42364.references = NULL;
    
    struct memblock_device ext_mem_42221;
    
    ext_mem_42221.references = NULL;
    
    struct memblock_device ext_mem_42220;
    
    ext_mem_42220.references = NULL;
    
    struct memblock_device mem_param_42217;
    
    mem_param_42217.references = NULL;
    
    struct memblock_device mem_param_42214;
    
    mem_param_42214.references = NULL;
    
    struct memblock_device ext_mem_42369;
    
    ext_mem_42369.references = NULL;
    
    struct memblock_device ext_mem_42370;
    
    ext_mem_42370.references = NULL;
    
    struct memblock_device mem_42222;
    
    mem_42222.references = NULL;
    
    struct memblock_device mem_42219;
    
    mem_42219.references = NULL;
    
    struct memblock_device mem_42218;
    
    mem_42218.references = NULL;
    
    struct memblock_device mem_42209;
    
    mem_42209.references = NULL;
    
    struct memblock_device mem_42210;
    
    mem_42210.references = NULL;
    
    struct memblock_device ext_mem_42211;
    
    ext_mem_42211.references = NULL;
    
    struct memblock_device mem_42206;
    
    mem_42206.references = NULL;
    
    struct memblock_device mem_42207;
    
    mem_42207.references = NULL;
    
    struct memblock_device ext_mem_42208;
    
    ext_mem_42208.references = NULL;
    
    struct memblock_device mem_42205;
    
    mem_42205.references = NULL;
    
    struct memblock_device mem_42203;
    
    mem_42203.references = NULL;
    
    struct memblock_device ext_mem_42201;
    
    ext_mem_42201.references = NULL;
    
    struct memblock_device mem_out_42708;
    
    mem_out_42708.references = NULL;
    
    struct memblock_device mem_out_42707;
    
    mem_out_42707.references = NULL;
    
    struct memblock_device mem_out_42706;
    
    mem_out_42706.references = NULL;
    
    struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
    struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
    struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
    struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
    struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
    int64_t prim_out_42709;
    int64_t zm_lhs_39067 = add64(nR_25439, extParallelism_25447);
    int64_t zs_lhs_39068 = sub64(zm_lhs_39067, (int64_t) 1);
    bool zzero_39069 = extParallelism_25447 == (int64_t) 0;
    bool nonzzero_39070 = !zzero_39069;
    bool nonzzero_cert_39071;
    
    if (!nonzzero_39070) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftSMJ.fut:48:39-55\n   #1  ftSMJ.fut:327:87-89\n   #2  ftSMJ.fut:352:133-136\n   #3  ftSMJ.fut:341:1-352:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t numIter_39072 = sdiv64(zs_lhs_39068, extParallelism_25447);
    
    if (futrts_indicesWithIncrement_9601(ctx, &ext_mem_42201, tR_mem_42199, nR_25439, offset_R_25443) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t bytes_42202 = (int64_t) 8 * nR_25439;
    
    if (memblock_alloc_device(ctx, &mem_42203, bytes_42202, "mem_42203")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_42203, nR_25439, (int64_t) -1) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42205, bytes_42202, "mem_42205")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_42205, nR_25439, (int64_t) 0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    bool loop_cond_39076 = slt64((int64_t) 0, numIter_39072);
    bool cond_39077 = slt64((int64_t) 0, nS_25440);
    int64_t tmp_39078 = sub64(nS_25440, (int64_t) 1);
    bool loop_not_taken_39079 = !cond_39077;
    bool loop_not_taken_39080 = !loop_cond_39076;
    bool x_39081 = sle64((int64_t) 0, tmp_39078);
    bool y_39082 = slt64(tmp_39078, nS_25440);
    bool protect_cond_conj_39083 = loop_cond_39076 && cond_39077;
    
    if (protect_cond_conj_39083) {
        if (memblock_alloc_device(ctx, &mem_42207, (int64_t) 2, "mem_42207")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_shortzigpuseq_42730(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, tS_mem_42200.mem, mem_42207.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42208, &mem_42207, "mem_42207") != 0)
            return 1;
    } else {
        if (memblock_alloc_device(ctx, &mem_42206, (int64_t) 2, "mem_42206")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i16(ctx, mem_42206, (int64_t) 1, (int16_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42208, &mem_42206, "mem_42206") != 0)
            return 1;
    }
    
    bool bounds_check_39086 = x_39081 && y_39082;
    bool protect_assert_disj_39087 = loop_not_taken_39079 || bounds_check_39086;
    bool protect_assert_disj_39088 = loop_not_taken_39080 || protect_assert_disj_39087;
    bool index_certs_39089;
    
    if (!protect_assert_disj_39088) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) tmp_39078, "] out of bounds for array of shape [", (long long) nS_25440, "].", "-> #0  ftSMJ.fut:60:34-42\n   #1  ftSMJ.fut:327:87-89\n   #2  ftSMJ.fut:352:133-136\n   #3  ftSMJ.fut:341:1-352:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    if (protect_cond_conj_39083) {
        if (memblock_alloc_device(ctx, &mem_42210, (int64_t) 2, "mem_42210")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_shortzigpuseq_42756(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, tmp_39078, tS_mem_42200.mem, mem_42210.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42211, &mem_42210, "mem_42210") != 0)
            return 1;
    } else {
        if (memblock_alloc_device(ctx, &mem_42209, (int64_t) 2, "mem_42209")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i16(ctx, mem_42209, (int64_t) 1, (int16_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42211, &mem_42209, "mem_42209") != 0)
            return 1;
    }
    if (memblock_alloc_device(ctx, &mem_42218, (int64_t) 2, "mem_42218")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42219, (int64_t) 2, "mem_42219")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42222, (int64_t) 1, "mem_42222")) {
        err = 1;
        goto cleanup;
    }
    
    int64_t ext_42368;
    int64_t ext_42367;
    int64_t ext_42366;
    int64_t ext_42365;
    bool defunc_0_find_joinTuples_res_39092;
    int64_t defunc_0_find_joinTuples_res_39093;
    bool loop_while_39096;
    int64_t p_39097;
    int64_t ctx_param_ext_42212;
    int64_t ctx_param_ext_42213;
    int64_t ctx_param_ext_42215;
    int64_t ctx_param_ext_42216;
    
    if (memblock_set_device(ctx, &mem_param_42214, &mem_42205, "mem_42205") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_42217, &mem_42203, "mem_42203") != 0)
        return 1;
    ctx_param_ext_42212 = (int64_t) 0;
    ctx_param_ext_42213 = (int64_t) 1;
    ctx_param_ext_42215 = (int64_t) 0;
    ctx_param_ext_42216 = (int64_t) 1;
    loop_while_39096 = loop_cond_39076;
    p_39097 = (int64_t) 0;
    while (loop_while_39096) {
        int64_t start_39100 = mul64(extParallelism_25447, p_39097);
        int64_t min_arg1_39101 = sub64(nR_25439, start_39100);
        int64_t min_res_39102 = smin64(extParallelism_25447, min_arg1_39101);
        int64_t iter_R_39103 = add64(start_39100, min_res_39102);
        bool empty_slice_39104 = min_res_39102 == (int64_t) 0;
        int64_t m_39105 = sub64(min_res_39102, (int64_t) 1);
        int64_t i_p_m_t_s_39106 = add64(start_39100, m_39105);
        bool zzero_leq_i_p_m_t_s_39107 = sle64((int64_t) 0, i_p_m_t_s_39106);
        bool i_p_m_t_s_leq_w_39108 = slt64(i_p_m_t_s_39106, nR_25439);
        bool zzero_lte_i_39109 = sle64((int64_t) 0, start_39100);
        bool i_lte_j_39110 = sle64(start_39100, iter_R_39103);
        bool y_39111 = i_p_m_t_s_leq_w_39108 && zzero_lte_i_39109;
        bool y_39112 = zzero_leq_i_p_m_t_s_39107 && y_39111;
        bool forwards_ok_39113 = i_lte_j_39110 && y_39112;
        bool ok_or_empty_39114 = empty_slice_39104 || forwards_ok_39113;
        bool index_certs_39115;
        
        if (!ok_or_empty_39114) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) start_39100, ":", (long long) iter_R_39103, "] out of bounds for array of shape [", (long long) nR_25439, "].", "-> #0  ftSMJ.fut:55:20-49\n   #1  ftSMJ.fut:327:87-89\n   #2  ftSMJ.fut:352:133-136\n   #3  ftSMJ.fut:341:1-352:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        bool y_39121 = slt64(m_39105, min_res_39102);
        bool x_39120 = sle64((int64_t) 0, m_39105);
        bool bounds_check_39122 = x_39120 && y_39121;
        bool index_certs_39123;
        
        if (!bounds_check_39122) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) m_39105, "] out of bounds for array of shape [", (long long) min_res_39102, "].", "-> #0  ftSMJ.fut:58:21-40\n   #1  ftSMJ.fut:327:87-89\n   #2  ftSMJ.fut:352:133-136\n   #3  ftSMJ.fut:341:1-352:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        bool y_39117 = slt64((int64_t) 0, min_res_39102);
        bool index_certs_39118;
        
        if (!y_39117) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) (int64_t) 0, "] out of bounds for array of shape [", (long long) min_res_39102, "].", "-> #0  ftSMJ.fut:57:21-30\n   #1  ftSMJ.fut:327:87-89\n   #2  ftSMJ.fut:352:133-136\n   #3  ftSMJ.fut:341:1-352:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_shortzigpuseq_42772(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, start_39100, i_p_m_t_s_39106, tR_mem_42199.mem, mem_42218.mem, mem_42219.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (cond_39077) {
            if (memblock_set_device(ctx, &ext_mem_42220, &ext_mem_42211, "ext_mem_42211") != 0)
                return 1;
        } else if (memblock_set_device(ctx, &ext_mem_42220, &mem_42218, "mem_42218") != 0)
            return 1;
        if (cond_39077) {
            if (memblock_set_device(ctx, &ext_mem_42221, &ext_mem_42208, "ext_mem_42208") != 0)
                return 1;
        } else if (memblock_set_device(ctx, &ext_mem_42221, &mem_42219, "mem_42219") != 0)
            return 1;
        {
            err = gpu_kernel_inner_SMJ_shortzigpuseq_42778(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, mem_42219.mem, ext_mem_42220.mem, mem_42222.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_unref_device(ctx, &ext_mem_42220, "ext_mem_42220") != 0)
            return 1;
        
        bool read_res_43334;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_43334, mem_42222.mem, (int64_t) 0 * sizeof(bool), sizeof(bool))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        bool defunc_0_gt_res_39127 = read_res_43334;
        int64_t ext_42363;
        int64_t ext_42362;
        int64_t ext_42360;
        int64_t ext_42359;
        int64_t loopres_39128;
        
        if (defunc_0_gt_res_39127) {
            if (memblock_set_device(ctx, &ext_mem_42364, &mem_param_42214, "mem_param_42214") != 0)
                return 1;
            ext_42363 = ctx_param_ext_42212;
            ext_42362 = ctx_param_ext_42213;
            if (memblock_set_device(ctx, &ext_mem_42361, &mem_param_42217, "mem_param_42217") != 0)
                return 1;
            ext_42360 = ctx_param_ext_42215;
            ext_42359 = ctx_param_ext_42216;
            loopres_39128 = numIter_39072;
        } else {
            if (memblock_alloc_device(ctx, &mem_42223, (int64_t) 1, "mem_42223")) {
                err = 1;
                goto cleanup;
            }
            {
                err = gpu_kernel_inner_SMJ_shortzigpuseq_42784(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, mem_42218.mem, ext_mem_42221.mem, mem_42223.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            
            bool read_res_43335;
            
            if ((err = gpu_scalar_from_device(ctx, &read_res_43335, mem_42223.mem, (int64_t) 0 * sizeof(bool), sizeof(bool))) != 0)
                goto cleanup;
            if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                err = 1;
                goto cleanup;
            }
            
            bool defunc_0_gt_res_39131 = read_res_43335;
            
            if (memblock_unref_device(ctx, &mem_42223, "mem_42223") != 0)
                return 1;
            
            int64_t ext_42357;
            
            if (defunc_0_gt_res_39131) {
                ext_42357 = ctx_param_ext_42212;
            } else {
                ext_42357 = (int64_t) 0;
            }
            
            int64_t ext_42356;
            
            if (defunc_0_gt_res_39131) {
                ext_42356 = ctx_param_ext_42213;
            } else {
                ext_42356 = (int64_t) 1;
            }
            
            int64_t ext_42354;
            
            if (defunc_0_gt_res_39131) {
                ext_42354 = ctx_param_ext_42215;
            } else {
                ext_42354 = (int64_t) 0;
            }
            
            int64_t ext_42353;
            
            if (defunc_0_gt_res_39131) {
                ext_42353 = ctx_param_ext_42216;
            } else {
                ext_42353 = (int64_t) 1;
            }
            
            int64_t loopres_f_res_39132;
            
            if (defunc_0_gt_res_39131) {
                int64_t tmp_39506 = add64((int64_t) 1, p_39097);
                
                if (memblock_set_device(ctx, &ext_mem_42358, &mem_param_42214, "mem_param_42214") != 0)
                    return 1;
                if (memblock_set_device(ctx, &ext_mem_42355, &mem_param_42217, "mem_param_42217") != 0)
                    return 1;
                loopres_f_res_39132 = tmp_39506;
            } else {
                if (futrts_indicesWithIncrement_9601(ctx, &ext_mem_42224, tS_mem_42200, nS_25440, offset_S_25444) != 0) {
                    err = 1;
                    goto cleanup;
                }
                
                bool suff_outer_par_40117;
                
                suff_outer_par_40117 = *ctx->tuning_params.inner_SMJ_shortzisuff_outer_par_0 <= min_res_39102;
                if (ctx->logging)
                    fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "inner_SMJ_short.suff_outer_par_0", (long) min_res_39102, suff_outer_par_40117 ? "true" : "false");
                
                int64_t tile_sizze_41780;
                
                tile_sizze_41780 = *ctx->tuning_params.inner_SMJ_shortzitile_sizze_41779;
                
                int64_t tile_sizze_41425;
                
                tile_sizze_41425 = *ctx->tuning_params.inner_SMJ_shortzitile_sizze_41424;
                
                int64_t num_whole_tiles_41796 = squot_safe64(nS_25440, tile_sizze_41780);
                int64_t residual_input_42020 = srem_safe64(nS_25440, tile_sizze_41780);
                bool cond_42021 = residual_input_42020 == (int64_t) 0;
                int64_t binop_x_42037 = tile_sizze_41780 * num_whole_tiles_41796;
                int64_t bytes_42282 = (int64_t) 8 * min_res_39102;
                int64_t bytes_42245 = (int64_t) 8 * tile_sizze_41780;
                int64_t bytes_42247 = (int64_t) 2 * tile_sizze_41780;
                int64_t num_whole_tiles_41441 = squot_safe64(nS_25440, tile_sizze_41425);
                int64_t residual_input_41665 = srem_safe64(nS_25440, tile_sizze_41425);
                bool cond_41666 = residual_input_41665 == (int64_t) 0;
                int64_t binop_x_41682 = tile_sizze_41425 * num_whole_tiles_41441;
                int64_t bytes_42306 = (int64_t) 8 * tile_sizze_41425;
                int64_t bytes_42308 = (int64_t) 2 * tile_sizze_41425;
                int64_t shared_memory_capacity_42842;
                
                shared_memory_capacity_42842 = ctx->max_shared_memory;
                if (suff_outer_par_40117 && sle64(sdiv_up64(bytes_42306, (int64_t) 8) * (int64_t) 8 + sdiv_up64(bytes_42308, (int64_t) 8) * (int64_t) 8 + sdiv_up64(bytes_42306, (int64_t) 8) * (int64_t) 8, shared_memory_capacity_42842)) {
                    int64_t ldim_41426 = sdiv_up64(min_res_39102, tile_sizze_41425);
                    
                    if (memblock_alloc_device(ctx, &mem_42344, bytes_42282, "mem_42344")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &mem_42346, bytes_42282, "mem_42346")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t num_chunks_42790 = sext_i64_i32(sdiv_up64(tile_sizze_41425, tile_sizze_41425));
                    int32_t virt_num_tblocks_42791 = sext_i64_i32(ldim_41426);
                    
                    {
                        err = gpu_kernel_inner_SMJ_shortzisegmap_intrablock_41423(ctx, ldim_41426, 1, 1, *ctx->tuning_params.inner_SMJ_shortzitile_sizze_41424, 1, 1, bytes_42306 + srem64((int64_t) 8 - srem64(bytes_42306, (int64_t) 8), (int64_t) 8) + (bytes_42308 + srem64((int64_t) 8 - srem64(bytes_42308, (int64_t) 8), (int64_t) 8)) + (bytes_42306 + srem64((int64_t) 8 - srem64(bytes_42306, (int64_t) 8), (int64_t) 8)), nS_25440, start_39100, min_res_39102, ldim_41426, num_whole_tiles_41441, residual_input_41665, cond_41666, binop_x_41682, tR_mem_42199.mem, tS_mem_42200.mem, ext_mem_42224.mem, mem_42344.mem, mem_42346.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_set_device(ctx, &ext_mem_42348, &mem_42344, "mem_42344") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &ext_mem_42347, &mem_42346, "mem_42346") != 0)
                        return 1;
                } else {
                    int64_t ldim_41781 = sdiv_up64(min_res_39102, tile_sizze_41780);
                    
                    if (memblock_alloc_device(ctx, &mem_42283, bytes_42282, "mem_42283")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &mem_42285, bytes_42282, "mem_42285")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t num_chunks_42816 = sext_i64_i32(sdiv_up64(tile_sizze_41780, tile_sizze_41780));
                    int32_t virt_num_tblocks_42817 = sext_i64_i32(ldim_41781);
                    
                    {
                        err = gpu_kernel_inner_SMJ_shortzisegmap_intrablock_41778(ctx, ldim_41781, 1, 1, *ctx->tuning_params.inner_SMJ_shortzitile_sizze_41779, 1, 1, bytes_42245 + srem64((int64_t) 8 - srem64(bytes_42245, (int64_t) 8), (int64_t) 8) + (bytes_42247 + srem64((int64_t) 8 - srem64(bytes_42247, (int64_t) 8), (int64_t) 8)) + (bytes_42245 + srem64((int64_t) 8 - srem64(bytes_42245, (int64_t) 8), (int64_t) 8)), nS_25440, start_39100, min_res_39102, ldim_41781, num_whole_tiles_41796, residual_input_42020, cond_42021, binop_x_42037, tR_mem_42199.mem, tS_mem_42200.mem, ext_mem_42224.mem, mem_42283.mem, mem_42285.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_set_device(ctx, &ext_mem_42348, &mem_42283, "mem_42283") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &ext_mem_42347, &mem_42285, "mem_42285") != 0)
                        return 1;
                }
                if (memblock_unref_device(ctx, &ext_mem_42224, "ext_mem_42224") != 0)
                    return 1;
                if (memblock_alloc_device(ctx, &mem_42350, bytes_42202, "mem_42350")) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42350.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_42217.mem, ctx_param_ext_42215, (int64_t []) {ctx_param_ext_42216}, (int64_t []) {nR_25439})) != 0)
                    goto cleanup;
                if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42350.mem, start_39100, (int64_t []) {(int64_t) 1}, ext_mem_42348.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {min_res_39102})) != 0)
                    goto cleanup;
                if (memblock_unref_device(ctx, &ext_mem_42348, "ext_mem_42348") != 0)
                    return 1;
                if (memblock_alloc_device(ctx, &mem_42352, bytes_42202, "mem_42352")) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42352.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_42214.mem, ctx_param_ext_42212, (int64_t []) {ctx_param_ext_42213}, (int64_t []) {nR_25439})) != 0)
                    goto cleanup;
                if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42352.mem, start_39100, (int64_t []) {(int64_t) 1}, ext_mem_42347.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {min_res_39102})) != 0)
                    goto cleanup;
                if (memblock_unref_device(ctx, &ext_mem_42347, "ext_mem_42347") != 0)
                    return 1;
                
                int64_t tmp_39179 = add64((int64_t) 1, p_39097);
                
                if (memblock_set_device(ctx, &ext_mem_42358, &mem_42352, "mem_42352") != 0)
                    return 1;
                if (memblock_set_device(ctx, &ext_mem_42355, &mem_42350, "mem_42350") != 0)
                    return 1;
                loopres_f_res_39132 = tmp_39179;
            }
            if (memblock_set_device(ctx, &ext_mem_42364, &ext_mem_42358, "ext_mem_42358") != 0)
                return 1;
            ext_42363 = ext_42357;
            ext_42362 = ext_42356;
            if (memblock_set_device(ctx, &ext_mem_42361, &ext_mem_42355, "ext_mem_42355") != 0)
                return 1;
            ext_42360 = ext_42354;
            ext_42359 = ext_42353;
            loopres_39128 = loopres_f_res_39132;
        }
        if (memblock_unref_device(ctx, &ext_mem_42221, "ext_mem_42221") != 0)
            return 1;
        
        bool loop_cond_39180 = slt64(loopres_39128, numIter_39072);
        
        if (memblock_set_device(ctx, &mem_param_tmp_42762, &ext_mem_42364, "ext_mem_42364") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_42763, &ext_mem_42361, "ext_mem_42361") != 0)
            return 1;
        
        int64_t ctx_param_ext_tmp_42764 = ext_42363;
        int64_t ctx_param_ext_tmp_42765 = ext_42362;
        int64_t ctx_param_ext_tmp_42766 = ext_42360;
        int64_t ctx_param_ext_tmp_42767 = ext_42359;
        bool loop_while_tmp_42768 = loop_cond_39180;
        int64_t p_tmp_42769 = loopres_39128;
        
        if (memblock_set_device(ctx, &mem_param_42214, &mem_param_tmp_42762, "mem_param_tmp_42762") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_42217, &mem_param_tmp_42763, "mem_param_tmp_42763") != 0)
            return 1;
        ctx_param_ext_42212 = ctx_param_ext_tmp_42764;
        ctx_param_ext_42213 = ctx_param_ext_tmp_42765;
        ctx_param_ext_42215 = ctx_param_ext_tmp_42766;
        ctx_param_ext_42216 = ctx_param_ext_tmp_42767;
        loop_while_39096 = loop_while_tmp_42768;
        p_39097 = p_tmp_42769;
    }
    if (memblock_set_device(ctx, &ext_mem_42370, &mem_param_42214, "mem_param_42214") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_42369, &mem_param_42217, "mem_param_42217") != 0)
        return 1;
    ext_42368 = ctx_param_ext_42212;
    ext_42367 = ctx_param_ext_42213;
    ext_42366 = ctx_param_ext_42215;
    ext_42365 = ctx_param_ext_42216;
    defunc_0_find_joinTuples_res_39092 = loop_while_39096;
    defunc_0_find_joinTuples_res_39093 = p_39097;
    if (memblock_unref_device(ctx, &mem_42203, "mem_42203") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42205, "mem_42205") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_42208, "ext_mem_42208") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_42211, "ext_mem_42211") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42218, "mem_42218") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42219, "mem_42219") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42222, "mem_42222") != 0)
        return 1;
    
    int64_t segscan_tblock_sizze_40294;
    
    segscan_tblock_sizze_40294 = *ctx->tuning_params.inner_SMJ_shortzisegscan_tblock_sizze_40293;
    
    int64_t num_tblocks_40296;
    int64_t max_num_tblocks_42843;
    
    max_num_tblocks_42843 = *ctx->tuning_params.inner_SMJ_shortzisegscan_num_tblocks_40295;
    num_tblocks_40296 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nR_25439, segscan_tblock_sizze_40294), max_num_tblocks_42843)));
    if (memblock_alloc_device(ctx, &mem_42373, bytes_42202, "mem_42373")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42375, bytes_42202, "mem_42375")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, nR_25439)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_42844;
        
        shared_memory_42844 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_42845;
        
        thread_block_sizze_42845 = ctx->max_thread_block_size;
        
        int64_t registers_42846;
        
        registers_42846 = ctx->max_registers;
        
        int64_t thread_block_sizze_42847;
        
        thread_block_sizze_42847 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_42848 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_42844, thread_block_sizze_42845), (int64_t) 8), squot64(squot64(registers_42846, thread_block_sizze_42847) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
        int64_t num_virt_blocks_42849 = sdiv_up64(nR_25439, segscan_tblock_sizze_40294 * chunk_sizze_42848);
        int64_t num_virt_threads_42850 = num_virt_blocks_42849 * segscan_tblock_sizze_40294;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_42848, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_42851, num_virt_blocks_42849, "status_flags_mem_42851")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_42851, num_virt_blocks_42849, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_42873, (int64_t) 8 * num_virt_blocks_42849, "aggregates_mem_42873")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_42875, (int64_t) 8 * num_virt_blocks_42849, "incprefixes_mem_42875")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_shortzisegscan_40299(ctx, num_tblocks_40296, 1, 1, *ctx->tuning_params.inner_SMJ_shortzisegscan_tblock_sizze_40293, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_40294), chunk_sizze_42848 * segscan_tblock_sizze_40294 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_40294), chunk_sizze_42848 * segscan_tblock_sizze_40294 * (int64_t) 8), (int64_t) 8), (int64_t) 8), nR_25439, num_tblocks_40296, ext_42367, ext_42368, num_virt_blocks_42849, num_virt_threads_42850, ext_mem_42370.mem, mem_42373.mem, mem_42375.mem, status_flags_mem_42851.mem, aggregates_mem_42873.mem, incprefixes_mem_42875.mem, global_dynid_mem_42877.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    
    bool cond_39190 = nR_25439 == (int64_t) 0;
    bool x_39191 = !cond_39190;
    int64_t tmp_39192 = sub64(nR_25439, (int64_t) 1);
    bool x_39193 = sle64((int64_t) 0, tmp_39192);
    bool y_39194 = slt64(tmp_39192, nR_25439);
    bool bounds_check_39195 = x_39193 && y_39194;
    bool protect_assert_disj_39196 = cond_39190 || bounds_check_39195;
    bool index_certs_39197;
    
    if (!protect_assert_disj_39196) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) tmp_39192, "] out of bounds for array of shape [", (long long) nR_25439, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:327:7-328:73\n   #3  ftSMJ.fut:352:133-136\n   #4  ftSMJ.fut:341:1-352:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t m_f_res_39198;
    
    if (x_39191) {
        int64_t read_res_43336;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_43336, mem_42373.mem, tmp_39192 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_39513 = read_res_43336;
        
        m_f_res_39198 = x_39513;
    } else {
        m_f_res_39198 = (int64_t) 0;
    }
    
    int64_t m_39200;
    
    if (cond_39190) {
        m_39200 = (int64_t) 0;
    } else {
        m_39200 = m_f_res_39198;
    }
    
    int64_t m_39210 = sub64(m_39200, (int64_t) 1);
    bool i_p_m_t_s_leq_w_39212 = slt64(m_39210, nR_25439);
    bool zzero_leq_i_p_m_t_s_39211 = sle64((int64_t) 0, m_39210);
    bool y_39214 = zzero_leq_i_p_m_t_s_39211 && i_p_m_t_s_leq_w_39212;
    bool i_lte_j_39213 = sle64((int64_t) 0, m_39200);
    bool forwards_ok_39215 = i_lte_j_39213 && y_39214;
    bool eq_x_zz_39207 = (int64_t) 0 == m_f_res_39198;
    bool p_and_eq_x_y_39208 = x_39191 && eq_x_zz_39207;
    bool empty_slice_39209 = cond_39190 || p_and_eq_x_y_39208;
    bool ok_or_empty_39216 = empty_slice_39209 || forwards_ok_39215;
    bool index_certs_39217;
    
    if (!ok_or_empty_39216) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_39200, "] out of bounds for array of shape [", (long long) nR_25439, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:327:7-328:73\n   #3  ftSMJ.fut:352:133-136\n   #4  ftSMJ.fut:341:1-352:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_42376 = (int64_t) 8 * m_39200;
    
    if (memblock_alloc_device(ctx, &mem_42377, bytes_42376, "mem_42377")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42377.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42370.mem, ext_42368, (int64_t []) {ext_42367}, (int64_t []) {m_39200})) != 0)
        goto cleanup;
    if (memblock_alloc_device(ctx, &mem_42379, bytes_42376, "mem_42379")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42379.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42369.mem, ext_42366, (int64_t []) {ext_42365}, (int64_t []) {m_39200})) != 0)
        goto cleanup;
    if (memblock_alloc_device(ctx, &mem_42381, bytes_42376, "mem_42381")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42381.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42201.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_39200})) != 0)
        goto cleanup;
    
    int64_t bytes_42382 = (int64_t) 2 * m_39200;
    
    if (memblock_alloc_device(ctx, &mem_42383, bytes_42382, "mem_42383")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_2b(ctx, 1, mem_42383.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, tR_mem_42199.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_39200})) != 0)
        goto cleanup;
    
    int64_t segmap_tblock_sizze_40304;
    
    segmap_tblock_sizze_40304 = *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_40303;
    
    int64_t num_tblocks_40306;
    int64_t max_num_tblocks_42986;
    
    max_num_tblocks_42986 = *ctx->tuning_params.inner_SMJ_shortzisegmap_num_tblocks_40305;
    num_tblocks_40306 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nR_25439, segmap_tblock_sizze_40304), max_num_tblocks_42986)));
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_42987 = sext_i64_i32(sdiv_up64(nR_25439, segmap_tblock_sizze_40304));
    
    {
        err = gpu_kernel_inner_SMJ_shortzisegmap_40301(ctx, num_tblocks_40306, 1, 1, *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_40303, 1, 1, (int64_t) 0, nR_25439, m_39200, num_tblocks_40306, ext_42365, ext_42366, ext_42367, ext_42368, virt_num_tblocks_42987, tR_mem_42199.mem, ext_mem_42201.mem, ext_mem_42369.mem, ext_mem_42370.mem, mem_42373.mem, mem_42375.mem, mem_42377.mem, mem_42379.mem, mem_42381.mem, mem_42383.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &ext_mem_42201, "ext_mem_42201") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_42369, "ext_mem_42369") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_42370, "ext_mem_42370") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42373, "mem_42373") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42375, "mem_42375") != 0)
        return 1;
    
    int64_t segscan_tblock_sizze_40310;
    
    segscan_tblock_sizze_40310 = *ctx->tuning_params.inner_SMJ_shortzisegscan_tblock_sizze_40309;
    
    int64_t num_tblocks_40312;
    int64_t max_num_tblocks_43000;
    
    max_num_tblocks_43000 = *ctx->tuning_params.inner_SMJ_shortzisegscan_num_tblocks_40311;
    num_tblocks_40312 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_39200, segscan_tblock_sizze_40310), max_num_tblocks_43000)));
    if (memblock_alloc_device(ctx, &mem_42387, bytes_42376, "mem_42387")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42389, bytes_42376, "mem_42389")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42391, bytes_42376, "mem_42391")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, m_39200)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_43001;
        
        shared_memory_43001 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_43002;
        
        thread_block_sizze_43002 = ctx->max_thread_block_size;
        
        int64_t registers_43003;
        
        registers_43003 = ctx->max_registers;
        
        int64_t thread_block_sizze_43004;
        
        thread_block_sizze_43004 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_43005 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_43001, thread_block_sizze_43002), (int64_t) 8), squot64(squot64(registers_43003, thread_block_sizze_43004) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
        int64_t num_virt_blocks_43006 = sdiv_up64(m_39200, segscan_tblock_sizze_40310 * chunk_sizze_43005);
        int64_t num_virt_threads_43007 = num_virt_blocks_43006 * segscan_tblock_sizze_40310;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_43005, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_43008, num_virt_blocks_43006, "status_flags_mem_43008")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_43008, num_virt_blocks_43006, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_43010, (int64_t) 8 * num_virt_blocks_43006, "aggregates_mem_43010")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_43012, (int64_t) 8 * num_virt_blocks_43006, "incprefixes_mem_43012")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_43014, (int64_t) 8 * num_virt_blocks_43006, "aggregates_mem_43014")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_43016, (int64_t) 8 * num_virt_blocks_43006, "incprefixes_mem_43016")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_shortzisegscan_40315(ctx, num_tblocks_40312, 1, 1, *ctx->tuning_params.inner_SMJ_shortzisegscan_tblock_sizze_40309, 1, 1, smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_40310, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_40310), smax64(chunk_sizze_43005 * segscan_tblock_sizze_40310 * (int64_t) 8, chunk_sizze_43005 * segscan_tblock_sizze_40310 * (int64_t) 8)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_40310, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_40310), smax64(chunk_sizze_43005 * segscan_tblock_sizze_40310 * (int64_t) 8, chunk_sizze_43005 * segscan_tblock_sizze_40310 * (int64_t) 8)), (int64_t) 8), (int64_t) 8), m_39200, num_tblocks_40312, num_virt_blocks_43006, num_virt_threads_43007, mem_42377.mem, mem_42387.mem, mem_42389.mem, mem_42391.mem, status_flags_mem_43008.mem, aggregates_mem_43010.mem, incprefixes_mem_43012.mem, aggregates_mem_43014.mem, incprefixes_mem_43016.mem, global_dynid_mem_43018.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    
    int64_t segmap_tblock_sizze_40331;
    
    segmap_tblock_sizze_40331 = *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_40319;
    
    int64_t segmap_usable_groups_40332 = sdiv_up64(m_39200, segmap_tblock_sizze_40331);
    
    if (memblock_alloc_device(ctx, &mem_42394, bytes_42376, "mem_42394")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_43153 = sext_i64_i32(sdiv_up64(m_39200, segmap_tblock_sizze_40331));
    
    {
        err = gpu_kernel_inner_SMJ_shortzisegmap_40335(ctx, segmap_usable_groups_40332, 1, 1, *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_40319, 1, 1, (int64_t) 0, m_39200, mem_42387.mem, mem_42394.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_42387, "mem_42387") != 0)
        return 1;
    
    bool cond_39251 = slt64((int64_t) 0, m_39200);
    bool y_39252 = slt64(m_39210, m_39200);
    bool bounds_check_39253 = zzero_leq_i_p_m_t_s_39211 && y_39252;
    bool loop_not_taken_39254 = !cond_39251;
    bool protect_assert_disj_39255 = bounds_check_39253 || loop_not_taken_39254;
    bool index_certs_39256;
    
    if (!protect_assert_disj_39255) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) m_39210, "] out of bounds for array of shape [", (long long) m_39200, "].", "-> #0  ftSMJ.fut:285:10-41\n   #1  ftSMJ.fut:327:7-328:73\n   #2  ftSMJ.fut:352:133-136\n   #3  ftSMJ.fut:341:1-352:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    if (cond_39251) {
        if (memblock_alloc_device(ctx, &mem_42396, (int64_t) 8, "mem_42396")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_shortzigpuseq_43162(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, m_39210, mem_42394.mem, mem_42396.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42397, &mem_42396, "mem_42396") != 0)
            return 1;
    } else {
        if (memblock_alloc_device(ctx, &mem_42395, (int64_t) 8, "mem_42395")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i64(ctx, mem_42395, (int64_t) 1, (int64_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42397, &mem_42395, "mem_42395") != 0)
            return 1;
    }
    if (cond_39251) {
        if (memblock_alloc_device(ctx, &mem_42399, (int64_t) 8, "mem_42399")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_shortzigpuseq_43168(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, m_39210, mem_42377.mem, mem_42399.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42400, &mem_42399, "mem_42399") != 0)
            return 1;
    } else {
        if (memblock_alloc_device(ctx, &mem_42398, (int64_t) 8, "mem_42398")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i64(ctx, mem_42398, (int64_t) 1, (int64_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_42400, &mem_42398, "mem_42398") != 0)
            return 1;
    }
    
    bool zzero_39268 = scatter_psizze_25448 == (int64_t) 0;
    bool nonzzero_39269 = !zzero_39268;
    bool nonzzero_cert_39270;
    
    if (!nonzzero_39269) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftbasics.fut:66:23-29\n   #1  ftSMJ.fut:327:7-328:73\n   #2  ftSMJ.fut:352:133-136\n   #3  ftSMJ.fut:341:1-352:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    bool x_39335 = !empty_slice_39209;
    bool protect_assert_disj_39336 = empty_slice_39209 || bounds_check_39253;
    bool index_certs_39337;
    
    if (!protect_assert_disj_39336) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) m_39210, "] out of bounds for array of shape [", (long long) m_39200, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:327:7-328:73\n   #3  ftSMJ.fut:352:133-136\n   #4  ftSMJ.fut:341:1-352:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t m_f_res_39338;
    
    if (x_39335) {
        int64_t read_res_43337;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_43337, mem_42389.mem, m_39210 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_39521 = read_res_43337;
        
        m_f_res_39338 = x_39521;
    } else {
        m_f_res_39338 = (int64_t) 0;
    }
    
    int64_t m_39340;
    
    if (empty_slice_39209) {
        m_39340 = (int64_t) 0;
    } else {
        m_39340 = m_f_res_39338;
    }
    
    int64_t m_39350 = sub64(m_39340, (int64_t) 1);
    bool i_p_m_t_s_leq_w_39352 = slt64(m_39350, m_39200);
    bool zzero_leq_i_p_m_t_s_39351 = sle64((int64_t) 0, m_39350);
    bool y_39354 = zzero_leq_i_p_m_t_s_39351 && i_p_m_t_s_leq_w_39352;
    bool i_lte_j_39353 = sle64((int64_t) 0, m_39340);
    bool forwards_ok_39355 = i_lte_j_39353 && y_39354;
    bool eq_x_zz_39347 = (int64_t) 0 == m_f_res_39338;
    bool p_and_eq_x_y_39348 = x_39335 && eq_x_zz_39347;
    bool empty_slice_39349 = empty_slice_39209 || p_and_eq_x_y_39348;
    bool ok_or_empty_39356 = empty_slice_39349 || forwards_ok_39355;
    bool index_certs_39357;
    
    if (!ok_or_empty_39356) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_39340, "] out of bounds for array of shape [", (long long) m_39200, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:327:7-328:73\n   #3  ftSMJ.fut:352:133-136\n   #4  ftSMJ.fut:341:1-352:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_42401 = (int64_t) 8 * m_39340;
    
    if (memblock_alloc_device(ctx, &mem_42406, (int64_t) 8, "mem_42406")) {
        err = 1;
        goto cleanup;
    }
    {
        err = gpu_kernel_inner_SMJ_shortzigpuseq_43174(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, ext_mem_42397.mem, ext_mem_42400.mem, mem_42406.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (memblock_unref_device(ctx, &ext_mem_42397, "ext_mem_42397") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_42400, "ext_mem_42400") != 0)
        return 1;
    
    int64_t n_pairs_t_res_39261;
    
    if (cond_39251) {
        int64_t read_res_43338;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_43338, mem_42406.mem, (int64_t) 0 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_42197 = read_res_43338;
        
        n_pairs_t_res_39261 = x_42197;
    } else {
        n_pairs_t_res_39261 = (int64_t) 0;
    }
    if (memblock_unref_device(ctx, &mem_42406, "mem_42406") != 0)
        return 1;
    
    int64_t n_pairs_39262;
    
    if (cond_39251) {
        n_pairs_39262 = n_pairs_t_res_39261;
    } else {
        n_pairs_39262 = (int64_t) 0;
    }
    
    int64_t bytes_42407 = (int64_t) 2 * n_pairs_39262;
    int64_t bytes_42409 = (int64_t) 8 * n_pairs_39262;
    int64_t segmap_tblock_sizze_40346;
    
    segmap_tblock_sizze_40346 = *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_40345;
    
    int64_t num_tblocks_40348;
    int64_t max_num_tblocks_43180;
    
    max_num_tblocks_43180 = *ctx->tuning_params.inner_SMJ_shortzisegmap_num_tblocks_40347;
    num_tblocks_40348 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_39200, segmap_tblock_sizze_40346), max_num_tblocks_43180)));
    if (memblock_alloc_device(ctx, &mem_42402, bytes_42401, "mem_42402")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42402.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_42377.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_39340})) != 0)
        goto cleanup;
    if (memblock_alloc_device(ctx, &mem_42404, bytes_42401, "mem_42404")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42404.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_42394.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_39340})) != 0)
        goto cleanup;
    
    int64_t segmap_tblock_sizze_40354;
    
    segmap_tblock_sizze_40354 = *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_40353;
    
    int64_t num_tblocks_40356;
    int64_t max_num_tblocks_43181;
    
    max_num_tblocks_43181 = *ctx->tuning_params.inner_SMJ_shortzisegmap_num_tblocks_40355;
    num_tblocks_40356 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_39200, segmap_tblock_sizze_40354), max_num_tblocks_43181)));
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_43182 = sext_i64_i32(sdiv_up64(m_39200, segmap_tblock_sizze_40354));
    
    {
        err = gpu_kernel_inner_SMJ_shortzisegmap_40351(ctx, num_tblocks_40356, 1, 1, *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_40353, 1, 1, (int64_t) 0, m_39200, m_39340, num_tblocks_40356, virt_num_tblocks_43182, mem_42377.mem, mem_42389.mem, mem_42391.mem, mem_42394.mem, mem_42402.mem, mem_42404.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_42377, "mem_42377") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42389, "mem_42389") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42391, "mem_42391") != 0)
        return 1;
    
    bool cond_39367 = slt64((int64_t) 0, m_39340);
    int64_t segmap_tblock_sizze_40369;
    
    segmap_tblock_sizze_40369 = *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_40361;
    if (memblock_alloc_device(ctx, &mem_42408, bytes_42407, "mem_42408")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i16(ctx, mem_42408, n_pairs_39262, (int16_t) 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42410, bytes_42409, "mem_42410")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_42410, n_pairs_39262, (int64_t) -1) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42412, bytes_42409, "mem_42412")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_42412, n_pairs_39262, (int64_t) -1) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t zm_lhs_39266 = add64(scatter_psizze_25448, n_pairs_39262);
    int64_t zs_lhs_39267 = sub64(zm_lhs_39266, (int64_t) 1);
    int64_t m_39271 = sdiv64(zs_lhs_39267, scatter_psizze_25448);
    bool loop_cond_39272 = slt64((int64_t) 0, m_39271);
    bool partitioned_scatter_res_39273;
    int64_t partitioned_scatter_res_39277;
    bool loop_while_39278;
    int64_t p_39282;
    
    loop_while_39278 = loop_cond_39272;
    p_39282 = (int64_t) 0;
    while (loop_while_39278) {
        int64_t lower_bound_39283 = mul64(scatter_psizze_25448, p_39282);
        int64_t min_arg1_39284 = add64(scatter_psizze_25448, lower_bound_39283);
        int64_t min_res_39285 = smin64(n_pairs_39262, min_arg1_39284);
        int64_t j_m_i_39286 = sub64(min_res_39285, lower_bound_39283);
        bool empty_slice_39287 = j_m_i_39286 == (int64_t) 0;
        int64_t m_39288 = sub64(j_m_i_39286, (int64_t) 1);
        int64_t i_p_m_t_s_39289 = add64(lower_bound_39283, m_39288);
        bool zzero_leq_i_p_m_t_s_39290 = sle64((int64_t) 0, i_p_m_t_s_39289);
        bool i_p_m_t_s_leq_w_39291 = slt64(i_p_m_t_s_39289, n_pairs_39262);
        bool zzero_lte_i_39292 = sle64((int64_t) 0, lower_bound_39283);
        bool i_lte_j_39293 = sle64(lower_bound_39283, min_res_39285);
        bool y_39294 = i_p_m_t_s_leq_w_39291 && zzero_lte_i_39292;
        bool y_39295 = zzero_leq_i_p_m_t_s_39290 && y_39294;
        bool forwards_ok_39296 = i_lte_j_39293 && y_39295;
        bool ok_or_empty_39297 = empty_slice_39287 || forwards_ok_39296;
        bool index_certs_39298;
        
        if (!ok_or_empty_39297) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) lower_bound_39283, ":", (long long) min_res_39285, "] out of bounds for array of shape [", (long long) n_pairs_39262, "].", "-> #0  ftbasics.fut:72:25-56\n   #1  ftSMJ.fut:327:7-328:73\n   #2  ftSMJ.fut:352:133-136\n   #3  ftSMJ.fut:341:1-352:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t bytes_42422 = (int64_t) 2 * j_m_i_39286;
        int64_t bytes_42424 = (int64_t) 8 * j_m_i_39286;
        
        if (memblock_alloc_device(ctx, &mem_42423, bytes_42422, "mem_42423")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_2b(ctx, 1, mem_42423.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_42408.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_39283, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_39286})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_42425, bytes_42424, "mem_42425")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42425.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_42410.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_39283, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_39286})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_42427, bytes_42424, "mem_42427")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42427.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_42412.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_39283, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_39286})) != 0)
            goto cleanup;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_43200 = sext_i64_i32(sdiv_up64(m_39200, segmap_tblock_sizze_40346));
        
        {
            err = gpu_kernel_inner_SMJ_shortzisegmap_40343(ctx, num_tblocks_40348, 1, 1, *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_40345, 1, 1, (int64_t) 0, m_39200, lower_bound_39283, min_res_39285, j_m_i_39286, num_tblocks_40348, virt_num_tblocks_43200, mem_42379.mem, mem_42381.mem, mem_42383.mem, mem_42394.mem, mem_42423.mem, mem_42425.mem, mem_42427.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t tmp_39312 = add64((int64_t) 1, p_39282);
        
        if ((err = lmad_copy_gpu2gpu_2b(ctx, 1, mem_42408.mem, lower_bound_39283, (int64_t []) {(int64_t) 1}, mem_42423.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_39286})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_42423, "mem_42423") != 0)
            return 1;
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42410.mem, lower_bound_39283, (int64_t []) {(int64_t) 1}, mem_42425.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_39286})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_42425, "mem_42425") != 0)
            return 1;
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42412.mem, lower_bound_39283, (int64_t []) {(int64_t) 1}, mem_42427.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_39286})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_42427, "mem_42427") != 0)
            return 1;
        
        bool loop_cond_39323 = slt64(tmp_39312, m_39271);
        bool loop_while_tmp_43195 = loop_cond_39323;
        int64_t p_tmp_43199 = tmp_39312;
        
        loop_while_39278 = loop_while_tmp_43195;
        p_39282 = p_tmp_43199;
    }
    partitioned_scatter_res_39273 = loop_while_39278;
    partitioned_scatter_res_39277 = p_39282;
    if (memblock_unref_device(ctx, &mem_42379, "mem_42379") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42381, "mem_42381") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42383, "mem_42383") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42394, "mem_42394") != 0)
        return 1;
    
    bool loop_cond_t_res_39368 = slt64(m_39200, n_pairs_39262);
    bool x_39369 = cond_39367 && loop_cond_t_res_39368;
    
    if (memblock_alloc_device(ctx, &mem_42453, (int64_t) 2, "mem_42453")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42454, (int64_t) 8, "mem_42454")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_42455, (int64_t) 8, "mem_42455")) {
        err = 1;
        goto cleanup;
    }
    
    bool joinTups_to_joinPairs_InnerJoin_res_39370;
    int64_t joinTups_to_joinPairs_InnerJoin_res_39374;
    bool loop_while_39375;
    int64_t p_39379;
    
    if (memblock_set_device(ctx, &mem_param_42440, &mem_42408, "mem_42408") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_42443, &mem_42410, "mem_42410") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_42446, &mem_42412, "mem_42412") != 0)
        return 1;
    loop_while_39375 = x_39369;
    p_39379 = (int64_t) 0;
    while (loop_while_39375) {
        bool x_39380 = sle64((int64_t) 0, p_39379);
        bool y_39381 = slt64(p_39379, m_39340);
        bool bounds_check_39382 = x_39380 && y_39381;
        bool index_certs_39383;
        
        if (!bounds_check_39382) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) p_39379, "] out of bounds for array of shape [", (long long) m_39340, "].", "-> #0  ftSMJ.fut:300:13-42\n   #1  ftSMJ.fut:327:7-328:73\n   #2  ftSMJ.fut:352:133-136\n   #3  ftSMJ.fut:341:1-352:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t read_res_43339;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_43339, mem_42404.mem, p_39379 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t loopres_39384 = read_res_43339;
        int64_t read_res_43340;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_43340, mem_42402.mem, p_39379 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t loopres_39385 = read_res_43340;
        bool x_39386 = sle64((int64_t) 0, loopres_39384);
        bool y_39387 = slt64(loopres_39384, n_pairs_39262);
        bool bounds_check_39388 = x_39386 && y_39387;
        bool index_certs_39389;
        
        if (!bounds_check_39388) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) loopres_39384, "] out of bounds for array of shape [", (long long) n_pairs_39262, "].", "-> #0  ftSMJ.fut:302:52-61\n   #1  ftSMJ.fut:327:7-328:73\n   #2  ftSMJ.fut:352:133-136\n   #3  ftSMJ.fut:341:1-352:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t tmp_39400 = add64(loopres_39384, loopres_39385);
        bool empty_slice_39404 = loopres_39385 == (int64_t) 0;
        int64_t m_39405 = sub64(loopres_39385, (int64_t) 1);
        int64_t i_p_m_t_s_39406 = add64(loopres_39384, m_39405);
        bool zzero_leq_i_p_m_t_s_39407 = sle64((int64_t) 0, i_p_m_t_s_39406);
        bool i_p_m_t_s_leq_w_39408 = slt64(i_p_m_t_s_39406, n_pairs_39262);
        bool i_lte_j_39409 = sle64(loopres_39384, tmp_39400);
        bool y_39410 = x_39386 && i_p_m_t_s_leq_w_39408;
        bool y_39411 = zzero_leq_i_p_m_t_s_39407 && y_39410;
        bool forwards_ok_39412 = i_lte_j_39409 && y_39411;
        bool ok_or_empty_39413 = empty_slice_39404 || forwards_ok_39412;
        bool index_certs_39414;
        
        if (!ok_or_empty_39413) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) loopres_39384, ":", (long long) tmp_39400, "] out of bounds for array of shape [", (long long) n_pairs_39262, "].", "-> #0  ftSMJ.fut:306:14-55\n   #1  ftSMJ.fut:327:7-328:73\n   #2  ftSMJ.fut:352:133-136\n   #3  ftSMJ.fut:341:1-352:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t bytes_42456 = (int64_t) 2 * loopres_39385;
        int64_t bytes_42458 = (int64_t) 8 * loopres_39385;
        int64_t segmap_usable_groups_40370 = sdiv_up64(loopres_39385, segmap_tblock_sizze_40369);
        int64_t tmp_39399 = add64((int64_t) 1, p_39379);
        
        if (memblock_alloc_device(ctx, &mem_42448, bytes_42407, "mem_42448")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_2b(ctx, 1, mem_42448.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_42440.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_39262})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_42450, bytes_42409, "mem_42450")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42450.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_42443.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_39262})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_42452, bytes_42409, "mem_42452")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42452.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_42446.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_39262})) != 0)
            goto cleanup;
        
        bool cond_39418 = slt64(tmp_39399, m_39340);
        bool x_39419 = loop_cond_t_res_39368 && cond_39418;
        
        {
            err = gpu_kernel_inner_SMJ_shortzigpuseq_43221(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, loopres_39384, mem_param_42440.mem, mem_param_42443.mem, mem_param_42446.mem, mem_42453.mem, mem_42454.mem, mem_42455.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_42457, bytes_42456, "mem_42457")) {
            err = 1;
            goto cleanup;
        }
        
        int64_t replicate_n_43227 = loopres_39385;
        int64_t tblock_sizze_43232;
        
        tblock_sizze_43232 = *ctx->tuning_params.inner_SMJ_shortzitblock_sizze_43232;
        
        int64_t virt_num_tblocks_43233 = sdiv_up64(replicate_n_43227, tblock_sizze_43232);
        int64_t num_tblocks_43234 = smin64(virt_num_tblocks_43233, (int64_t) 1048576);
        
        {
            err = gpu_kernel_inner_SMJ_shortzireplicate_43228(ctx, num_tblocks_43234, 1, 1, tblock_sizze_43232, 1, 1, (int64_t) 0, loopres_39385, replicate_n_43227, virt_num_tblocks_43233, num_tblocks_43234, mem_42453.mem, mem_42457.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_42459, bytes_42458, "mem_42459")) {
            err = 1;
            goto cleanup;
        }
        
        int64_t replicate_n_43247 = loopres_39385;
        int64_t tblock_sizze_43252;
        
        tblock_sizze_43252 = *ctx->tuning_params.inner_SMJ_shortzitblock_sizze_43252;
        
        int64_t virt_num_tblocks_43253 = sdiv_up64(replicate_n_43247, tblock_sizze_43252);
        int64_t num_tblocks_43254 = smin64(virt_num_tblocks_43253, (int64_t) 1048576);
        
        {
            err = gpu_kernel_inner_SMJ_shortzireplicate_43248(ctx, num_tblocks_43254, 1, 1, tblock_sizze_43252, 1, 1, (int64_t) 0, loopres_39385, replicate_n_43247, virt_num_tblocks_43253, num_tblocks_43254, mem_42454.mem, mem_42459.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_43267 = sext_i64_i32(sdiv_up64(loopres_39385, segmap_tblock_sizze_40369));
        
        {
            err = gpu_kernel_inner_SMJ_shortzisegmap_40373(ctx, segmap_usable_groups_40370, 1, 1, *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_40361, 1, 1, (int64_t) 0, loopres_39384, loopres_39385, mem_42452.mem, mem_42455.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if ((err = lmad_copy_gpu2gpu_2b(ctx, 1, mem_42448.mem, loopres_39384, (int64_t []) {(int64_t) 1}, mem_42457.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {loopres_39385})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_42457, "mem_42457") != 0)
            return 1;
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42450.mem, loopres_39384, (int64_t []) {(int64_t) 1}, mem_42459.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {loopres_39385})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_42459, "mem_42459") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_43213, &mem_42448, "mem_42448") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_43214, &mem_42450, "mem_42450") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_43215, &mem_42452, "mem_42452") != 0)
            return 1;
        
        bool loop_while_tmp_43216 = x_39419;
        int64_t p_tmp_43220 = tmp_39399;
        
        if (memblock_set_device(ctx, &mem_param_42440, &mem_param_tmp_43213, "mem_param_tmp_43213") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_42443, &mem_param_tmp_43214, "mem_param_tmp_43214") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_42446, &mem_param_tmp_43215, "mem_param_tmp_43215") != 0)
            return 1;
        loop_while_39375 = loop_while_tmp_43216;
        p_39379 = p_tmp_43220;
    }
    if (memblock_set_device(ctx, &ext_mem_42471, &mem_param_42440, "mem_param_42440") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_42470, &mem_param_42443, "mem_param_42443") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_42469, &mem_param_42446, "mem_param_42446") != 0)
        return 1;
    joinTups_to_joinPairs_InnerJoin_res_39370 = loop_while_39375;
    joinTups_to_joinPairs_InnerJoin_res_39374 = p_39379;
    if (memblock_unref_device(ctx, &mem_42402, "mem_42402") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42404, "mem_42404") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42408, "mem_42408") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42410, "mem_42410") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42412, "mem_42412") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42453, "mem_42453") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42454, "mem_42454") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_42455, "mem_42455") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_42473, bytes_42407, "mem_42473")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_2b(ctx, 1, mem_42473.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42471.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_39262})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_42471, "ext_mem_42471") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_42475, bytes_42409, "mem_42475")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42475.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42470.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_39262})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_42470, "ext_mem_42470") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_42477, bytes_42409, "mem_42477")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_42477.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_42469.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_39262})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_42469, "ext_mem_42469") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_42706, &mem_42475, "mem_42475") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_42707, &mem_42477, "mem_42477") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_42708, &mem_42473, "mem_42473") != 0)
        return 1;
    prim_out_42709 = n_pairs_39262;
    if (memblock_set_device(ctx, &*mem_out_p_43330, &mem_out_42706, "mem_out_42706") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_43331, &mem_out_42707, "mem_out_42707") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_43332, &mem_out_42708, "mem_out_42708") != 0)
        return 1;
    *out_prim_out_43333 = prim_out_42709;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_42477, "mem_42477") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42475, "mem_42475") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42473, "mem_42473") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_43215, "mem_param_tmp_43215") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_43214, "mem_param_tmp_43214") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_43213, "mem_param_tmp_43213") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42459, "mem_42459") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42457, "mem_42457") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42452, "mem_42452") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42450, "mem_42450") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42448, "mem_42448") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42446, "mem_param_42446") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42443, "mem_param_42443") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42440, "mem_param_42440") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42469, "ext_mem_42469") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42470, "ext_mem_42470") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42471, "ext_mem_42471") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42455, "mem_42455") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42454, "mem_42454") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42453, "mem_42453") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42427, "mem_42427") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42425, "mem_42425") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42423, "mem_42423") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42412, "mem_42412") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42410, "mem_42410") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42408, "mem_42408") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42404, "mem_42404") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42402, "mem_42402") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42406, "mem_42406") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42398, "mem_42398") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42399, "mem_42399") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42400, "ext_mem_42400") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42395, "mem_42395") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42396, "mem_42396") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42397, "ext_mem_42397") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42394, "mem_42394") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_43016, "incprefixes_mem_43016") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_43014, "aggregates_mem_43014") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_43012, "incprefixes_mem_43012") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_43010, "aggregates_mem_43010") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_43008, "status_flags_mem_43008") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42391, "mem_42391") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42389, "mem_42389") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42387, "mem_42387") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42383, "mem_42383") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42381, "mem_42381") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42379, "mem_42379") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42377, "mem_42377") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_42875, "incprefixes_mem_42875") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_42873, "aggregates_mem_42873") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_42851, "status_flags_mem_42851") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42375, "mem_42375") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42373, "mem_42373") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_42763, "mem_param_tmp_42763") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_42762, "mem_param_tmp_42762") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42352, "mem_42352") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42350, "mem_42350") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42285, "mem_42285") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42283, "mem_42283") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42346, "mem_42346") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42344, "mem_42344") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42347, "ext_mem_42347") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42348, "ext_mem_42348") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42224, "ext_mem_42224") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42355, "ext_mem_42355") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42358, "ext_mem_42358") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42223, "mem_42223") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42361, "ext_mem_42361") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42364, "ext_mem_42364") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42221, "ext_mem_42221") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42220, "ext_mem_42220") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42217, "mem_param_42217") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_42214, "mem_param_42214") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42369, "ext_mem_42369") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42370, "ext_mem_42370") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42222, "mem_42222") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42219, "mem_42219") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42218, "mem_42218") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42209, "mem_42209") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42210, "mem_42210") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42211, "ext_mem_42211") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42206, "mem_42206") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42207, "mem_42207") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42208, "ext_mem_42208") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42205, "mem_42205") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42203, "mem_42203") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_42201, "ext_mem_42201") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_42708, "mem_out_42708") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_42707, "mem_out_42707") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_42706, "mem_out_42706") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_max_idx(struct futhark_context *ctx, int64_t *out_prim_out_43341, struct memblock_device eta_p_mem_42199, int64_t nz2080U_37756)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device segred_tmp_mem_42731;
    
    segred_tmp_mem_42731.references = NULL;
    
    struct memblock_device mem_42201;
    
    mem_42201.references = NULL;
    
    struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
    struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
    struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
    struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
    struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
    int64_t prim_out_42706;
    int64_t segred_tblock_sizze_39548;
    
    segred_tblock_sizze_39548 = *ctx->tuning_params.max_idxzisegred_tblock_sizze_39547;
    
    int64_t num_tblocks_39550;
    int64_t max_num_tblocks_42707;
    
    max_num_tblocks_42707 = *ctx->tuning_params.max_idxzisegred_num_tblocks_39549;
    num_tblocks_39550 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nz2080U_37756, segred_tblock_sizze_39548), max_num_tblocks_42707)));
    if (memblock_alloc_device(ctx, &mem_42201, (int64_t) 8, "mem_42201")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegRed");
    
    int64_t chunk_sizze_42708 = (int64_t) 1;
    
    if (memblock_alloc_device(ctx, &segred_tmp_mem_42731, (int64_t) 8 * num_tblocks_39550, "segred_tmp_mem_42731")) {
        err = 1;
        goto cleanup;
    }
    
    int64_t num_threads_42733 = num_tblocks_39550 * segred_tblock_sizze_39548;
    
    {
        err = gpu_kernel_max_idxzisegred_nonseg_39555(ctx, num_tblocks_39550, 1, 1, *ctx->tuning_params.max_idxzisegred_tblock_sizze_39547, 1, 1, 8 + ((int64_t) 8 * segred_tblock_sizze_39548 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_39548, (int64_t) 8), (int64_t) 8)), nz2080U_37756, num_tblocks_39550, num_threads_42733, eta_p_mem_42199.mem, mem_42201.mem, counters_mem_42709.mem, segred_tmp_mem_42731.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t read_res_43342;
    
    if ((err = gpu_scalar_from_device(ctx, &read_res_43342, mem_42201.mem, (int64_t) 0 * sizeof(int64_t), sizeof(int64_t))) != 0)
        goto cleanup;
    if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t defunc_0_reduce_res_39423 = read_res_43342;
    
    if (memblock_unref_device(ctx, &mem_42201, "mem_42201") != 0)
        return 1;
    prim_out_42706 = defunc_0_reduce_res_39423;
    *out_prim_out_43341 = prim_out_42706;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &segred_tmp_mem_42731, "segred_tmp_mem_42731") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42201, "mem_42201") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_min_idx(struct futhark_context *ctx, int64_t *out_prim_out_43343, struct memblock_device eta_p_mem_42199, int64_t nz2080U_37716)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device segred_tmp_mem_42731;
    
    segred_tmp_mem_42731.references = NULL;
    
    struct memblock_device mem_42201;
    
    mem_42201.references = NULL;
    
    struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
    struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
    struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
    struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
    struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
    int64_t prim_out_42706;
    int64_t segred_tblock_sizze_39538;
    
    segred_tblock_sizze_39538 = *ctx->tuning_params.min_idxzisegred_tblock_sizze_39537;
    
    int64_t num_tblocks_39540;
    int64_t max_num_tblocks_42707;
    
    max_num_tblocks_42707 = *ctx->tuning_params.min_idxzisegred_num_tblocks_39539;
    num_tblocks_39540 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nz2080U_37716, segred_tblock_sizze_39538), max_num_tblocks_42707)));
    if (memblock_alloc_device(ctx, &mem_42201, (int64_t) 8, "mem_42201")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegRed");
    
    int64_t chunk_sizze_42708 = (int64_t) 1;
    
    if (memblock_alloc_device(ctx, &segred_tmp_mem_42731, (int64_t) 8 * num_tblocks_39540, "segred_tmp_mem_42731")) {
        err = 1;
        goto cleanup;
    }
    
    int64_t num_threads_42733 = num_tblocks_39540 * segred_tblock_sizze_39538;
    
    {
        err = gpu_kernel_min_idxzisegred_nonseg_39545(ctx, num_tblocks_39540, 1, 1, *ctx->tuning_params.min_idxzisegred_tblock_sizze_39537, 1, 1, 8 + ((int64_t) 8 * segred_tblock_sizze_39538 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_39538, (int64_t) 8), (int64_t) 8)), nz2080U_37716, num_tblocks_39540, num_threads_42733, eta_p_mem_42199.mem, mem_42201.mem, counters_mem_42709.mem, segred_tmp_mem_42731.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t read_res_43344;
    
    if ((err = gpu_scalar_from_device(ctx, &read_res_43344, mem_42201.mem, (int64_t) 0 * sizeof(int64_t), sizeof(int64_t))) != 0)
        goto cleanup;
    if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t defunc_0_reduce_res_39423 = read_res_43344;
    
    if (memblock_unref_device(ctx, &mem_42201, "mem_42201") != 0)
        return 1;
    prim_out_42706 = defunc_0_reduce_res_39423;
    *out_prim_out_43343 = prim_out_42706;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &segred_tmp_mem_42731, "segred_tmp_mem_42731") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_42201, "mem_42201") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_indicesWithIncrement_9601(struct futhark_context *ctx, struct memblock_device *mem_out_p_43345, struct memblock_device xs_mem_42199, int64_t n_22930, int64_t incr_22931)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_42201;
    
    mem_42201.references = NULL;
    
    struct memblock_device mem_out_42706;
    
    mem_out_42706.references = NULL;
    
    struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
    struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
    struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
    struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
    struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
    int64_t rng_22936 = add64(n_22930, incr_22931);
    bool bounds_invalid_upwards_22940 = slt64(rng_22936, incr_22931);
    bool valid_22945 = !bounds_invalid_upwards_22940;
    bool range_valid_c_22946;
    
    if (!valid_22945) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) incr_22931, "..<", (long long) rng_22936, " is invalid.", "-> #0  ftbasics.fut:11:25-40\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_42200 = (int64_t) 8 * n_22930;
    
    if (memblock_alloc_device(ctx, &mem_42201, bytes_42200, "mem_42201")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhiota_i64(ctx, mem_42201, n_22930, incr_22931, (int64_t) 1) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_set_device(ctx, &mem_out_42706, &mem_42201, "mem_42201") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_43345, &mem_out_42706, "mem_out_42706") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_42201, "mem_42201") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_42706, "mem_out_42706") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_indicesWithIncrement_9701(struct futhark_context *ctx, struct memblock_device *mem_out_p_43346, struct memblock_device xs_mem_42199, int64_t n_25481, int64_t incr_25482)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_42201;
    
    mem_42201.references = NULL;
    
    struct memblock_device mem_out_42706;
    
    mem_out_42706.references = NULL;
    
    struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
    struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
    struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
    struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
    struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
    int64_t rng_25487 = add64(n_25481, incr_25482);
    bool bounds_invalid_upwards_25491 = slt64(rng_25487, incr_25482);
    bool valid_25496 = !bounds_invalid_upwards_25491;
    bool range_valid_c_25497;
    
    if (!valid_25496) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) incr_25482, "..<", (long long) rng_25487, " is invalid.", "-> #0  ftbasics.fut:11:25-40\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_42200 = (int64_t) 8 * n_25481;
    
    if (memblock_alloc_device(ctx, &mem_42201, bytes_42200, "mem_42201")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhiota_i64(ctx, mem_42201, n_25481, incr_25482, (int64_t) 1) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_set_device(ctx, &mem_out_42706, &mem_42201, "mem_42201") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_43346, &mem_out_42706, "mem_out_42706") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_42201, "mem_42201") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_42706, "mem_out_42706") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_indicesWithIncrement_9775(struct futhark_context *ctx, struct memblock_device *mem_out_p_43347, struct memblock_device xs_mem_42199, int64_t n_27762, int64_t incr_27763)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_42201;
    
    mem_42201.references = NULL;
    
    struct memblock_device mem_out_42706;
    
    mem_out_42706.references = NULL;
    
    struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
    struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
    struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
    struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
    struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
    int64_t rng_27768 = add64(n_27762, incr_27763);
    bool bounds_invalid_upwards_27772 = slt64(rng_27768, incr_27763);
    bool valid_27777 = !bounds_invalid_upwards_27772;
    bool range_valid_c_27778;
    
    if (!valid_27777) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) incr_27763, "..<", (long long) rng_27768, " is invalid.", "-> #0  ftbasics.fut:11:25-40\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_42200 = (int64_t) 8 * n_27762;
    
    if (memblock_alloc_device(ctx, &mem_42201, bytes_42200, "mem_42201")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhiota_i64(ctx, mem_42201, n_27762, incr_27763, (int64_t) 1) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_set_device(ctx, &mem_out_42706, &mem_42201, "mem_42201") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_43347, &mem_out_42706, "mem_out_42706") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_42201, "mem_42201") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_42706, "mem_out_42706") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_indicesWithIncrement_9844(struct futhark_context *ctx, struct memblock_device *mem_out_p_43348, struct memblock_device xs_mem_42199, int64_t n_29981, int64_t incr_29982)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_42201;
    
    mem_42201.references = NULL;
    
    struct memblock_device mem_out_42706;
    
    mem_out_42706.references = NULL;
    
    struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
    struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
    struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
    struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
    struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
    int64_t rng_29987 = add64(n_29981, incr_29982);
    bool bounds_invalid_upwards_29991 = slt64(rng_29987, incr_29982);
    bool valid_29996 = !bounds_invalid_upwards_29991;
    bool range_valid_c_29997;
    
    if (!valid_29996) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) incr_29982, "..<", (long long) rng_29987, " is invalid.", "-> #0  ftbasics.fut:11:25-40\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_42200 = (int64_t) 8 * n_29981;
    
    if (memblock_alloc_device(ctx, &mem_42201, bytes_42200, "mem_42201")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhiota_i64(ctx, mem_42201, n_29981, incr_29982, (int64_t) 1) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_set_device(ctx, &mem_out_42706, &mem_42201, "mem_42201") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_43348, &mem_out_42706, "mem_out_42706") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_42201, "mem_42201") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_42706, "mem_out_42706") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_indicesWithIncrement_9920(struct futhark_context *ctx, struct memblock_device *mem_out_p_43349, struct memblock_device xs_mem_42199, int64_t n_32271, int64_t incr_32272)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_42201;
    
    mem_42201.references = NULL;
    
    struct memblock_device mem_out_42706;
    
    mem_out_42706.references = NULL;
    
    struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
    struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
    struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
    struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
    struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
    int64_t rng_32277 = add64(n_32271, incr_32272);
    bool bounds_invalid_upwards_32281 = slt64(rng_32277, incr_32272);
    bool valid_32286 = !bounds_invalid_upwards_32281;
    bool range_valid_c_32287;
    
    if (!valid_32286) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) incr_32272, "..<", (long long) rng_32277, " is invalid.", "-> #0  ftbasics.fut:11:25-40\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_42200 = (int64_t) 8 * n_32271;
    
    if (memblock_alloc_device(ctx, &mem_42201, bytes_42200, "mem_42201")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhiota_i64(ctx, mem_42201, n_32271, incr_32272, (int64_t) 1) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_set_device(ctx, &mem_out_42706, &mem_42201, "mem_42201") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_43349, &mem_out_42706, "mem_out_42706") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_42201, "mem_42201") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_42706, "mem_out_42706") != 0)
            return 1;
    }
    return err;
}

int futhark_entry_gather_payloads_double(struct futhark_context *ctx, struct futhark_f64_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_i64_1d *in2, const struct futhark_f64_1d *in3)
{
    int64_t niz2084U_36170 = (int64_t) 0;
    int64_t dz2083U_36171 = (int64_t) 0;
    int64_t incr_36172 = (int64_t) 0;
    int64_t psizze_36173 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_42706;
    
    mem_out_42706.references = NULL;
    
    struct memblock_device ys_mem_42200;
    
    ys_mem_42200.references = NULL;
    
    struct memblock_device is_mem_42199;
    
    is_mem_42199.references = NULL;
    incr_36172 = in0;
    psizze_36173 = in1;
    is_mem_42199 = in2->mem;
    niz2084U_36170 = in2->shape[0];
    ys_mem_42200 = in3->mem;
    dz2083U_36171 = in3->shape[0];
    if (!(niz2084U_36170 == in2->shape[0] && dz2083U_36171 == in3->shape[0])) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_gather_payloads_double(ctx, &mem_out_42706, is_mem_42199, ys_mem_42200, niz2084U_36170, dz2083U_36171, incr_36172, psizze_36173);
        if (ret == 0) {
            struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
            struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
            struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
            struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
            struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
            
            assert((*out0 = (struct futhark_f64_1d *) malloc(sizeof(struct futhark_f64_1d))) != NULL);
            (*out0)->mem = mem_out_42706;
            (*out0)->shape[0] = niz2084U_36170;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_gather_payloads_double_GFUR(struct futhark_context *ctx, struct futhark_f64_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_f64_1d *in2, const struct futhark_i64_1d *in3, const struct futhark_f64_1d *in4)
{
    int64_t ni_37677 = (int64_t) 0;
    int64_t n_37678 = (int64_t) 0;
    int64_t incr_37679 = (int64_t) 0;
    int64_t psizze_37680 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_42706;
    
    mem_out_42706.references = NULL;
    
    struct memblock_device ys_mem_42201;
    
    ys_mem_42201.references = NULL;
    
    struct memblock_device is_mem_42200;
    
    is_mem_42200.references = NULL;
    
    struct memblock_device preVals_mem_42199;
    
    preVals_mem_42199.references = NULL;
    incr_37679 = in0;
    psizze_37680 = in1;
    preVals_mem_42199 = in2->mem;
    ni_37677 = in2->shape[0];
    is_mem_42200 = in3->mem;
    ni_37677 = in3->shape[0];
    ys_mem_42201 = in4->mem;
    n_37678 = in4->shape[0];
    if (!(ni_37677 == in2->shape[0] && (ni_37677 == in3->shape[0] && n_37678 == in4->shape[0]))) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_gather_payloads_double_GFUR(ctx, &mem_out_42706, preVals_mem_42199, is_mem_42200, ys_mem_42201, ni_37677, n_37678, incr_37679, psizze_37680);
        if (ret == 0) {
            struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
            struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
            struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
            struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
            struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
            
            assert((*out0 = (struct futhark_f64_1d *) malloc(sizeof(struct futhark_f64_1d))) != NULL);
            (*out0)->mem = mem_out_42706;
            (*out0)->shape[0] = ni_37677;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_gather_payloads_float(struct futhark_context *ctx, struct futhark_f32_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_i64_1d *in2, const struct futhark_f32_1d *in3)
{
    int64_t niz2084U_35830 = (int64_t) 0;
    int64_t dz2083U_35831 = (int64_t) 0;
    int64_t incr_35832 = (int64_t) 0;
    int64_t psizze_35833 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_42706;
    
    mem_out_42706.references = NULL;
    
    struct memblock_device ys_mem_42200;
    
    ys_mem_42200.references = NULL;
    
    struct memblock_device is_mem_42199;
    
    is_mem_42199.references = NULL;
    incr_35832 = in0;
    psizze_35833 = in1;
    is_mem_42199 = in2->mem;
    niz2084U_35830 = in2->shape[0];
    ys_mem_42200 = in3->mem;
    dz2083U_35831 = in3->shape[0];
    if (!(niz2084U_35830 == in2->shape[0] && dz2083U_35831 == in3->shape[0])) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_gather_payloads_float(ctx, &mem_out_42706, is_mem_42199, ys_mem_42200, niz2084U_35830, dz2083U_35831, incr_35832, psizze_35833);
        if (ret == 0) {
            struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
            struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
            struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
            struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
            struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
            
            assert((*out0 = (struct futhark_f32_1d *) malloc(sizeof(struct futhark_f32_1d))) != NULL);
            (*out0)->mem = mem_out_42706;
            (*out0)->shape[0] = niz2084U_35830;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_gather_payloads_float_GFUR(struct futhark_context *ctx, struct futhark_f32_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_f32_1d *in2, const struct futhark_i64_1d *in3, const struct futhark_f32_1d *in4)
{
    int64_t ni_37376 = (int64_t) 0;
    int64_t n_37377 = (int64_t) 0;
    int64_t incr_37378 = (int64_t) 0;
    int64_t psizze_37379 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_42706;
    
    mem_out_42706.references = NULL;
    
    struct memblock_device ys_mem_42201;
    
    ys_mem_42201.references = NULL;
    
    struct memblock_device is_mem_42200;
    
    is_mem_42200.references = NULL;
    
    struct memblock_device preVals_mem_42199;
    
    preVals_mem_42199.references = NULL;
    incr_37378 = in0;
    psizze_37379 = in1;
    preVals_mem_42199 = in2->mem;
    ni_37376 = in2->shape[0];
    is_mem_42200 = in3->mem;
    ni_37376 = in3->shape[0];
    ys_mem_42201 = in4->mem;
    n_37377 = in4->shape[0];
    if (!(ni_37376 == in2->shape[0] && (ni_37376 == in3->shape[0] && n_37377 == in4->shape[0]))) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_gather_payloads_float_GFUR(ctx, &mem_out_42706, preVals_mem_42199, is_mem_42200, ys_mem_42201, ni_37376, n_37377, incr_37378, psizze_37379);
        if (ret == 0) {
            struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
            struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
            struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
            struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
            struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
            
            assert((*out0 = (struct futhark_f32_1d *) malloc(sizeof(struct futhark_f32_1d))) != NULL);
            (*out0)->mem = mem_out_42706;
            (*out0)->shape[0] = ni_37376;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_gather_payloads_int(struct futhark_context *ctx, struct futhark_i32_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_i64_1d *in2, const struct futhark_i32_1d *in3)
{
    int64_t niz2084U_35181 = (int64_t) 0;
    int64_t dz2083U_35182 = (int64_t) 0;
    int64_t incr_35183 = (int64_t) 0;
    int64_t psizze_35184 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_42706;
    
    mem_out_42706.references = NULL;
    
    struct memblock_device ys_mem_42200;
    
    ys_mem_42200.references = NULL;
    
    struct memblock_device is_mem_42199;
    
    is_mem_42199.references = NULL;
    incr_35183 = in0;
    psizze_35184 = in1;
    is_mem_42199 = in2->mem;
    niz2084U_35181 = in2->shape[0];
    ys_mem_42200 = in3->mem;
    dz2083U_35182 = in3->shape[0];
    if (!(niz2084U_35181 == in2->shape[0] && dz2083U_35182 == in3->shape[0])) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_gather_payloads_int(ctx, &mem_out_42706, is_mem_42199, ys_mem_42200, niz2084U_35181, dz2083U_35182, incr_35183, psizze_35184);
        if (ret == 0) {
            struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
            struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
            struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
            struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
            struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
            
            assert((*out0 = (struct futhark_i32_1d *) malloc(sizeof(struct futhark_i32_1d))) != NULL);
            (*out0)->mem = mem_out_42706;
            (*out0)->shape[0] = niz2084U_35181;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_gather_payloads_int_GFUR(struct futhark_context *ctx, struct futhark_i32_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_i32_1d *in2, const struct futhark_i64_1d *in3, const struct futhark_i32_1d *in4)
{
    int64_t ni_36774 = (int64_t) 0;
    int64_t n_36775 = (int64_t) 0;
    int64_t incr_36776 = (int64_t) 0;
    int64_t psizze_36777 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_42706;
    
    mem_out_42706.references = NULL;
    
    struct memblock_device ys_mem_42201;
    
    ys_mem_42201.references = NULL;
    
    struct memblock_device is_mem_42200;
    
    is_mem_42200.references = NULL;
    
    struct memblock_device preVals_mem_42199;
    
    preVals_mem_42199.references = NULL;
    incr_36776 = in0;
    psizze_36777 = in1;
    preVals_mem_42199 = in2->mem;
    ni_36774 = in2->shape[0];
    is_mem_42200 = in3->mem;
    ni_36774 = in3->shape[0];
    ys_mem_42201 = in4->mem;
    n_36775 = in4->shape[0];
    if (!(ni_36774 == in2->shape[0] && (ni_36774 == in3->shape[0] && n_36775 == in4->shape[0]))) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_gather_payloads_int_GFUR(ctx, &mem_out_42706, preVals_mem_42199, is_mem_42200, ys_mem_42201, ni_36774, n_36775, incr_36776, psizze_36777);
        if (ret == 0) {
            struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
            struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
            struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
            struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
            struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
            
            assert((*out0 = (struct futhark_i32_1d *) malloc(sizeof(struct futhark_i32_1d))) != NULL);
            (*out0)->mem = mem_out_42706;
            (*out0)->shape[0] = ni_36774;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_gather_payloads_long(struct futhark_context *ctx, struct futhark_i64_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_i64_1d *in2, const struct futhark_i64_1d *in3)
{
    int64_t niz2084U_35490 = (int64_t) 0;
    int64_t dz2083U_35491 = (int64_t) 0;
    int64_t incr_35492 = (int64_t) 0;
    int64_t psizze_35493 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_42706;
    
    mem_out_42706.references = NULL;
    
    struct memblock_device ys_mem_42200;
    
    ys_mem_42200.references = NULL;
    
    struct memblock_device is_mem_42199;
    
    is_mem_42199.references = NULL;
    incr_35492 = in0;
    psizze_35493 = in1;
    is_mem_42199 = in2->mem;
    niz2084U_35490 = in2->shape[0];
    ys_mem_42200 = in3->mem;
    dz2083U_35491 = in3->shape[0];
    if (!(niz2084U_35490 == in2->shape[0] && dz2083U_35491 == in3->shape[0])) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_gather_payloads_long(ctx, &mem_out_42706, is_mem_42199, ys_mem_42200, niz2084U_35490, dz2083U_35491, incr_35492, psizze_35493);
        if (ret == 0) {
            struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
            struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
            struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
            struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
            struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
            
            assert((*out0 = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d))) != NULL);
            (*out0)->mem = mem_out_42706;
            (*out0)->shape[0] = niz2084U_35490;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_gather_payloads_long_GFUR(struct futhark_context *ctx, struct futhark_i64_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_i64_1d *in2, const struct futhark_i64_1d *in3, const struct futhark_i64_1d *in4)
{
    int64_t ni_37075 = (int64_t) 0;
    int64_t n_37076 = (int64_t) 0;
    int64_t incr_37077 = (int64_t) 0;
    int64_t psizze_37078 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_42706;
    
    mem_out_42706.references = NULL;
    
    struct memblock_device ys_mem_42201;
    
    ys_mem_42201.references = NULL;
    
    struct memblock_device is_mem_42200;
    
    is_mem_42200.references = NULL;
    
    struct memblock_device preVals_mem_42199;
    
    preVals_mem_42199.references = NULL;
    incr_37077 = in0;
    psizze_37078 = in1;
    preVals_mem_42199 = in2->mem;
    ni_37075 = in2->shape[0];
    is_mem_42200 = in3->mem;
    ni_37075 = in3->shape[0];
    ys_mem_42201 = in4->mem;
    n_37076 = in4->shape[0];
    if (!(ni_37075 == in2->shape[0] && (ni_37075 == in3->shape[0] && n_37076 == in4->shape[0]))) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_gather_payloads_long_GFUR(ctx, &mem_out_42706, preVals_mem_42199, is_mem_42200, ys_mem_42201, ni_37075, n_37076, incr_37077, psizze_37078);
        if (ret == 0) {
            struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
            struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
            struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
            struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
            struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
            
            assert((*out0 = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d))) != NULL);
            (*out0)->mem = mem_out_42706;
            (*out0)->shape[0] = ni_37075;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_gather_payloads_short(struct futhark_context *ctx, struct futhark_i16_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_i64_1d *in2, const struct futhark_i16_1d *in3)
{
    int64_t niz2084U_34869 = (int64_t) 0;
    int64_t dz2083U_34870 = (int64_t) 0;
    int64_t incr_34871 = (int64_t) 0;
    int64_t psizze_34872 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_42706;
    
    mem_out_42706.references = NULL;
    
    struct memblock_device ys_mem_42200;
    
    ys_mem_42200.references = NULL;
    
    struct memblock_device is_mem_42199;
    
    is_mem_42199.references = NULL;
    incr_34871 = in0;
    psizze_34872 = in1;
    is_mem_42199 = in2->mem;
    niz2084U_34869 = in2->shape[0];
    ys_mem_42200 = in3->mem;
    dz2083U_34870 = in3->shape[0];
    if (!(niz2084U_34869 == in2->shape[0] && dz2083U_34870 == in3->shape[0])) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_gather_payloads_short(ctx, &mem_out_42706, is_mem_42199, ys_mem_42200, niz2084U_34869, dz2083U_34870, incr_34871, psizze_34872);
        if (ret == 0) {
            struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
            struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
            struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
            struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
            struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
            
            assert((*out0 = (struct futhark_i16_1d *) malloc(sizeof(struct futhark_i16_1d))) != NULL);
            (*out0)->mem = mem_out_42706;
            (*out0)->shape[0] = niz2084U_34869;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_gather_payloads_short_GFUR(struct futhark_context *ctx, struct futhark_i16_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_i16_1d *in2, const struct futhark_i64_1d *in3, const struct futhark_i16_1d *in4)
{
    int64_t ni_36473 = (int64_t) 0;
    int64_t n_36474 = (int64_t) 0;
    int64_t incr_36475 = (int64_t) 0;
    int64_t psizze_36476 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_42706;
    
    mem_out_42706.references = NULL;
    
    struct memblock_device ys_mem_42201;
    
    ys_mem_42201.references = NULL;
    
    struct memblock_device is_mem_42200;
    
    is_mem_42200.references = NULL;
    
    struct memblock_device preVals_mem_42199;
    
    preVals_mem_42199.references = NULL;
    incr_36475 = in0;
    psizze_36476 = in1;
    preVals_mem_42199 = in2->mem;
    ni_36473 = in2->shape[0];
    is_mem_42200 = in3->mem;
    ni_36473 = in3->shape[0];
    ys_mem_42201 = in4->mem;
    n_36474 = in4->shape[0];
    if (!(ni_36473 == in2->shape[0] && (ni_36473 == in3->shape[0] && n_36474 == in4->shape[0]))) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_gather_payloads_short_GFUR(ctx, &mem_out_42706, preVals_mem_42199, is_mem_42200, ys_mem_42201, ni_36473, n_36474, incr_36475, psizze_36476);
        if (ret == 0) {
            struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
            struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
            struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
            struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
            struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
            
            assert((*out0 = (struct futhark_i16_1d *) malloc(sizeof(struct futhark_i16_1d))) != NULL);
            (*out0)->mem = mem_out_42706;
            (*out0)->shape[0] = ni_36473;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_inner_SMJ_double(struct futhark_context *ctx, struct futhark_opaque_joinPairs_double **out0, const struct futhark_f64_1d *in0, const struct futhark_f64_1d *in1, const int64_t in2, const int64_t in3, const int64_t in4, const int64_t in5, const int64_t in6, const int64_t in7)
{
    int64_t nR_34519 = (int64_t) 0;
    int64_t nS_34520 = (int64_t) 0;
    int64_t offset_R_34523 = (int64_t) 0;
    int64_t offset_S_34524 = (int64_t) 0;
    int64_t partitionsPerWindow_34525 = (int64_t) 0;
    int64_t numberOfWindows_34526 = (int64_t) 0;
    int64_t extParallelism_34527 = (int64_t) 0;
    int64_t scatter_psizze_34528 = (int64_t) 0;
    int64_t prim_out_42709 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_42708;
    
    mem_out_42708.references = NULL;
    
    struct memblock_device mem_out_42707;
    
    mem_out_42707.references = NULL;
    
    struct memblock_device mem_out_42706;
    
    mem_out_42706.references = NULL;
    
    struct memblock_device tS_mem_42200;
    
    tS_mem_42200.references = NULL;
    
    struct memblock_device tR_mem_42199;
    
    tR_mem_42199.references = NULL;
    tR_mem_42199 = in0->mem;
    nR_34519 = in0->shape[0];
    tS_mem_42200 = in1->mem;
    nS_34520 = in1->shape[0];
    offset_R_34523 = in2;
    offset_S_34524 = in3;
    partitionsPerWindow_34525 = in4;
    numberOfWindows_34526 = in5;
    extParallelism_34527 = in6;
    scatter_psizze_34528 = in7;
    if (!(nR_34519 == in0->shape[0] && nS_34520 == in1->shape[0])) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_inner_SMJ_double(ctx, &mem_out_42706, &mem_out_42707, &mem_out_42708, &prim_out_42709, tR_mem_42199, tS_mem_42200, nR_34519, nS_34520, offset_R_34523, offset_S_34524, partitionsPerWindow_34525, numberOfWindows_34526, extParallelism_34527, scatter_psizze_34528);
        if (ret == 0) {
            struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
            struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
            struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
            struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
            struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
            
            assert((*out0 = (struct futhark_opaque_joinPairs_double *) malloc(sizeof(struct futhark_opaque_joinPairs_double))) != NULL);
            assert(((*out0)->v0 = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d))) != NULL);
            (*out0)->v0->mem = mem_out_42706;
            (*out0)->v0->shape[0] = prim_out_42709;
            assert(((*out0)->v1 = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d))) != NULL);
            (*out0)->v1->mem = mem_out_42707;
            (*out0)->v1->shape[0] = prim_out_42709;
            assert(((*out0)->v2 = (struct futhark_f64_1d *) malloc(sizeof(struct futhark_f64_1d))) != NULL);
            (*out0)->v2->mem = mem_out_42708;
            (*out0)->v2->shape[0] = prim_out_42709;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_inner_SMJ_float(struct futhark_context *ctx, struct futhark_opaque_joinPairs_float **out0, const struct futhark_f32_1d *in0, const struct futhark_f32_1d *in1, const int64_t in2, const int64_t in3, const int64_t in4, const int64_t in5, const int64_t in6, const int64_t in7)
{
    int64_t nR_32229 = (int64_t) 0;
    int64_t nS_32230 = (int64_t) 0;
    int64_t offset_R_32233 = (int64_t) 0;
    int64_t offset_S_32234 = (int64_t) 0;
    int64_t partitionsPerWindow_32235 = (int64_t) 0;
    int64_t numberOfWindows_32236 = (int64_t) 0;
    int64_t extParallelism_32237 = (int64_t) 0;
    int64_t scatter_psizze_32238 = (int64_t) 0;
    int64_t prim_out_42709 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_42708;
    
    mem_out_42708.references = NULL;
    
    struct memblock_device mem_out_42707;
    
    mem_out_42707.references = NULL;
    
    struct memblock_device mem_out_42706;
    
    mem_out_42706.references = NULL;
    
    struct memblock_device tS_mem_42200;
    
    tS_mem_42200.references = NULL;
    
    struct memblock_device tR_mem_42199;
    
    tR_mem_42199.references = NULL;
    tR_mem_42199 = in0->mem;
    nR_32229 = in0->shape[0];
    tS_mem_42200 = in1->mem;
    nS_32230 = in1->shape[0];
    offset_R_32233 = in2;
    offset_S_32234 = in3;
    partitionsPerWindow_32235 = in4;
    numberOfWindows_32236 = in5;
    extParallelism_32237 = in6;
    scatter_psizze_32238 = in7;
    if (!(nR_32229 == in0->shape[0] && nS_32230 == in1->shape[0])) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_inner_SMJ_float(ctx, &mem_out_42706, &mem_out_42707, &mem_out_42708, &prim_out_42709, tR_mem_42199, tS_mem_42200, nR_32229, nS_32230, offset_R_32233, offset_S_32234, partitionsPerWindow_32235, numberOfWindows_32236, extParallelism_32237, scatter_psizze_32238);
        if (ret == 0) {
            struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
            struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
            struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
            struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
            struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
            
            assert((*out0 = (struct futhark_opaque_joinPairs_float *) malloc(sizeof(struct futhark_opaque_joinPairs_float))) != NULL);
            assert(((*out0)->v0 = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d))) != NULL);
            (*out0)->v0->mem = mem_out_42706;
            (*out0)->v0->shape[0] = prim_out_42709;
            assert(((*out0)->v1 = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d))) != NULL);
            (*out0)->v1->mem = mem_out_42707;
            (*out0)->v1->shape[0] = prim_out_42709;
            assert(((*out0)->v2 = (struct futhark_f32_1d *) malloc(sizeof(struct futhark_f32_1d))) != NULL);
            (*out0)->v2->mem = mem_out_42708;
            (*out0)->v2->shape[0] = prim_out_42709;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_inner_SMJ_int(struct futhark_context *ctx, struct futhark_opaque_joinPairs_int **out0, const struct futhark_i32_1d *in0, const struct futhark_i32_1d *in1, const int64_t in2, const int64_t in3, const int64_t in4, const int64_t in5, const int64_t in6, const int64_t in7)
{
    int64_t nR_27729 = (int64_t) 0;
    int64_t nS_27730 = (int64_t) 0;
    int64_t offset_R_27733 = (int64_t) 0;
    int64_t offset_S_27734 = (int64_t) 0;
    int64_t partitionsPerWindow_27735 = (int64_t) 0;
    int64_t numberOfWindows_27736 = (int64_t) 0;
    int64_t extParallelism_27737 = (int64_t) 0;
    int64_t scatter_psizze_27738 = (int64_t) 0;
    int64_t prim_out_42709 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_42708;
    
    mem_out_42708.references = NULL;
    
    struct memblock_device mem_out_42707;
    
    mem_out_42707.references = NULL;
    
    struct memblock_device mem_out_42706;
    
    mem_out_42706.references = NULL;
    
    struct memblock_device tS_mem_42200;
    
    tS_mem_42200.references = NULL;
    
    struct memblock_device tR_mem_42199;
    
    tR_mem_42199.references = NULL;
    tR_mem_42199 = in0->mem;
    nR_27729 = in0->shape[0];
    tS_mem_42200 = in1->mem;
    nS_27730 = in1->shape[0];
    offset_R_27733 = in2;
    offset_S_27734 = in3;
    partitionsPerWindow_27735 = in4;
    numberOfWindows_27736 = in5;
    extParallelism_27737 = in6;
    scatter_psizze_27738 = in7;
    if (!(nR_27729 == in0->shape[0] && nS_27730 == in1->shape[0])) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_inner_SMJ_int(ctx, &mem_out_42706, &mem_out_42707, &mem_out_42708, &prim_out_42709, tR_mem_42199, tS_mem_42200, nR_27729, nS_27730, offset_R_27733, offset_S_27734, partitionsPerWindow_27735, numberOfWindows_27736, extParallelism_27737, scatter_psizze_27738);
        if (ret == 0) {
            struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
            struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
            struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
            struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
            struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
            
            assert((*out0 = (struct futhark_opaque_joinPairs_int *) malloc(sizeof(struct futhark_opaque_joinPairs_int))) != NULL);
            assert(((*out0)->v0 = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d))) != NULL);
            (*out0)->v0->mem = mem_out_42706;
            (*out0)->v0->shape[0] = prim_out_42709;
            assert(((*out0)->v1 = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d))) != NULL);
            (*out0)->v1->mem = mem_out_42707;
            (*out0)->v1->shape[0] = prim_out_42709;
            assert(((*out0)->v2 = (struct futhark_i32_1d *) malloc(sizeof(struct futhark_i32_1d))) != NULL);
            (*out0)->v2->mem = mem_out_42708;
            (*out0)->v2->shape[0] = prim_out_42709;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_inner_SMJ_long(struct futhark_context *ctx, struct futhark_opaque_joinPairs_long **out0, const struct futhark_i64_1d *in0, const struct futhark_i64_1d *in1, const int64_t in2, const int64_t in3, const int64_t in4, const int64_t in5, const int64_t in6, const int64_t in7)
{
    int64_t nR_29939 = (int64_t) 0;
    int64_t nS_29940 = (int64_t) 0;
    int64_t offset_R_29943 = (int64_t) 0;
    int64_t offset_S_29944 = (int64_t) 0;
    int64_t partitionsPerWindow_29945 = (int64_t) 0;
    int64_t numberOfWindows_29946 = (int64_t) 0;
    int64_t extParallelism_29947 = (int64_t) 0;
    int64_t scatter_psizze_29948 = (int64_t) 0;
    int64_t prim_out_42709 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_42708;
    
    mem_out_42708.references = NULL;
    
    struct memblock_device mem_out_42707;
    
    mem_out_42707.references = NULL;
    
    struct memblock_device mem_out_42706;
    
    mem_out_42706.references = NULL;
    
    struct memblock_device tS_mem_42200;
    
    tS_mem_42200.references = NULL;
    
    struct memblock_device tR_mem_42199;
    
    tR_mem_42199.references = NULL;
    tR_mem_42199 = in0->mem;
    nR_29939 = in0->shape[0];
    tS_mem_42200 = in1->mem;
    nS_29940 = in1->shape[0];
    offset_R_29943 = in2;
    offset_S_29944 = in3;
    partitionsPerWindow_29945 = in4;
    numberOfWindows_29946 = in5;
    extParallelism_29947 = in6;
    scatter_psizze_29948 = in7;
    if (!(nR_29939 == in0->shape[0] && nS_29940 == in1->shape[0])) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_inner_SMJ_long(ctx, &mem_out_42706, &mem_out_42707, &mem_out_42708, &prim_out_42709, tR_mem_42199, tS_mem_42200, nR_29939, nS_29940, offset_R_29943, offset_S_29944, partitionsPerWindow_29945, numberOfWindows_29946, extParallelism_29947, scatter_psizze_29948);
        if (ret == 0) {
            struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
            struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
            struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
            struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
            struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
            
            assert((*out0 = (struct futhark_opaque_joinPairs_long *) malloc(sizeof(struct futhark_opaque_joinPairs_long))) != NULL);
            assert(((*out0)->v0 = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d))) != NULL);
            (*out0)->v0->mem = mem_out_42706;
            (*out0)->v0->shape[0] = prim_out_42709;
            assert(((*out0)->v1 = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d))) != NULL);
            (*out0)->v1->mem = mem_out_42707;
            (*out0)->v1->shape[0] = prim_out_42709;
            assert(((*out0)->v2 = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d))) != NULL);
            (*out0)->v2->mem = mem_out_42708;
            (*out0)->v2->shape[0] = prim_out_42709;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_inner_SMJ_short(struct futhark_context *ctx, struct futhark_opaque_joinPairs_short **out0, const struct futhark_i16_1d *in0, const struct futhark_i16_1d *in1, const int64_t in2, const int64_t in3, const int64_t in4, const int64_t in5, const int64_t in6, const int64_t in7)
{
    int64_t nR_25439 = (int64_t) 0;
    int64_t nS_25440 = (int64_t) 0;
    int64_t offset_R_25443 = (int64_t) 0;
    int64_t offset_S_25444 = (int64_t) 0;
    int64_t partitionsPerWindow_25445 = (int64_t) 0;
    int64_t numberOfWindows_25446 = (int64_t) 0;
    int64_t extParallelism_25447 = (int64_t) 0;
    int64_t scatter_psizze_25448 = (int64_t) 0;
    int64_t prim_out_42709 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_42708;
    
    mem_out_42708.references = NULL;
    
    struct memblock_device mem_out_42707;
    
    mem_out_42707.references = NULL;
    
    struct memblock_device mem_out_42706;
    
    mem_out_42706.references = NULL;
    
    struct memblock_device tS_mem_42200;
    
    tS_mem_42200.references = NULL;
    
    struct memblock_device tR_mem_42199;
    
    tR_mem_42199.references = NULL;
    tR_mem_42199 = in0->mem;
    nR_25439 = in0->shape[0];
    tS_mem_42200 = in1->mem;
    nS_25440 = in1->shape[0];
    offset_R_25443 = in2;
    offset_S_25444 = in3;
    partitionsPerWindow_25445 = in4;
    numberOfWindows_25446 = in5;
    extParallelism_25447 = in6;
    scatter_psizze_25448 = in7;
    if (!(nR_25439 == in0->shape[0] && nS_25440 == in1->shape[0])) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_inner_SMJ_short(ctx, &mem_out_42706, &mem_out_42707, &mem_out_42708, &prim_out_42709, tR_mem_42199, tS_mem_42200, nR_25439, nS_25440, offset_R_25443, offset_S_25444, partitionsPerWindow_25445, numberOfWindows_25446, extParallelism_25447, scatter_psizze_25448);
        if (ret == 0) {
            struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
            struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
            struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
            struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
            struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
            
            assert((*out0 = (struct futhark_opaque_joinPairs_short *) malloc(sizeof(struct futhark_opaque_joinPairs_short))) != NULL);
            assert(((*out0)->v0 = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d))) != NULL);
            (*out0)->v0->mem = mem_out_42706;
            (*out0)->v0->shape[0] = prim_out_42709;
            assert(((*out0)->v1 = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d))) != NULL);
            (*out0)->v1->mem = mem_out_42707;
            (*out0)->v1->shape[0] = prim_out_42709;
            assert(((*out0)->v2 = (struct futhark_i16_1d *) malloc(sizeof(struct futhark_i16_1d))) != NULL);
            (*out0)->v2->mem = mem_out_42708;
            (*out0)->v2->shape[0] = prim_out_42709;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_max_idx(struct futhark_context *ctx, int64_t *out0, const struct futhark_i64_1d *in0)
{
    int64_t nz2080U_37756 = (int64_t) 0;
    int64_t prim_out_42706 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device eta_p_mem_42199;
    
    eta_p_mem_42199.references = NULL;
    eta_p_mem_42199 = in0->mem;
    nz2080U_37756 = in0->shape[0];
    if (!(nz2080U_37756 == in0->shape[0])) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_max_idx(ctx, &prim_out_42706, eta_p_mem_42199, nz2080U_37756);
        if (ret == 0) {
            struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
            struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
            struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
            struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
            struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
            
            *out0 = prim_out_42706;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_min_idx(struct futhark_context *ctx, int64_t *out0, const struct futhark_i64_1d *in0)
{
    int64_t nz2080U_37716 = (int64_t) 0;
    int64_t prim_out_42706 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device eta_p_mem_42199;
    
    eta_p_mem_42199.references = NULL;
    eta_p_mem_42199 = in0->mem;
    nz2080U_37716 = in0->shape[0];
    if (!(nz2080U_37716 == in0->shape[0])) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_min_idx(ctx, &prim_out_42706, eta_p_mem_42199, nz2080U_37716);
        if (ret == 0) {
            struct memblock_device counters_mem_42709 = ctx->constants->counters_mem_42709;
            struct memblock_device global_dynid_mem_42857 = ctx->constants->global_dynid_mem_42857;
            struct memblock_device global_dynid_mem_42877 = ctx->constants->global_dynid_mem_42877;
            struct memblock_device global_dynid_mem_42998 = ctx->constants->global_dynid_mem_42998;
            struct memblock_device global_dynid_mem_43018 = ctx->constants->global_dynid_mem_43018;
            
            *out0 = prim_out_42706;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
  
