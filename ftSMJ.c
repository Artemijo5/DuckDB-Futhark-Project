// Generated by Futhark 0.26.0 (prerelease - include info below when reporting bugs).
// git: 1de4f0c (Fri Jan 24 11:10:52 2025 +0100)
// Compiled with GHC 9.4.8.

// We need to define _GNU_SOURCE before
// _any_ headers files are imported to get
// the usage statistics of a thread (i.e. have RUSAGE_THREAD) on GNU/Linux
// https://manpages.courier-mta.org/htmlman2/getrusage.2.html
#ifndef _GNU_SOURCE // Avoid possible double-definition warning.
#define _GNU_SOURCE
#endif

#ifdef __clang__
#pragma clang diagnostic ignored "-Wunused-function"
#pragma clang diagnostic ignored "-Wunused-variable"
#pragma clang diagnostic ignored "-Wunused-const-variable"
#pragma clang diagnostic ignored "-Wparentheses"
#pragma clang diagnostic ignored "-Wunused-label"
#pragma clang diagnostic ignored "-Wunused-but-set-variable"
#elif __GNUC__
#pragma GCC diagnostic ignored "-Wunused-function"
#pragma GCC diagnostic ignored "-Wunused-variable"
#pragma GCC diagnostic ignored "-Wunused-const-variable"
#pragma GCC diagnostic ignored "-Wparentheses"
#pragma GCC diagnostic ignored "-Wunused-label"
#pragma GCC diagnostic ignored "-Wunused-but-set-variable"
#endif

// Headers
#include <stdint.h>
#include <stddef.h>
#include <stdbool.h>
#include <stdio.h>
#include <float.h>

#include <cuda.h>
#include <cuda_runtime.h>
#include <nvrtc.h>

#ifdef __cplusplus
extern "C" {
#endif

// Initialisation
struct futhark_context_config;
struct futhark_context_config *futhark_context_config_new(void);
void futhark_context_config_free(struct futhark_context_config *cfg);
int futhark_context_config_set_tuning_param(struct futhark_context_config *cfg, const char *param_name, size_t new_value);
struct futhark_context;
struct futhark_context *futhark_context_new(struct futhark_context_config *cfg);
void futhark_context_free(struct futhark_context *cfg);
void futhark_context_config_set_default_thread_block_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_grid_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_group_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_num_groups(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_tile_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_reg_tile_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_registers(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_cache(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_threshold(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_unified_memory(struct futhark_context_config *cfg, int flag);
void futhark_context_config_add_nvrtc_option(struct futhark_context_config *cfg, const char *opt);
void futhark_context_config_set_device(struct futhark_context_config *cfg, const char *s);
const char *futhark_context_config_get_program(struct futhark_context_config *cfg);
void futhark_context_config_set_program(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_dump_ptx_to(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_load_ptx_from(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_set_debugging(struct futhark_context_config *cfg, int flag);
void futhark_context_config_set_profiling(struct futhark_context_config *cfg, int flag);
void futhark_context_config_set_logging(struct futhark_context_config *cfg, int flag);
int futhark_get_tuning_param_count(void);
const char *futhark_get_tuning_param_name(int);
const char *futhark_get_tuning_param_class(int);

// Arrays
struct futhark_f32_1d;
struct futhark_f32_1d *futhark_new_f32_1d(struct futhark_context *ctx, const float *data, int64_t dim0);
struct futhark_f32_1d *futhark_new_raw_f32_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0);
int futhark_free_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr);
int futhark_values_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr, float *data);
int futhark_index_f32_1d(struct futhark_context *ctx, float *out, struct futhark_f32_1d *arr, int64_t i0);
CUdeviceptr futhark_values_raw_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr);
const int64_t *futhark_shape_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr);
struct futhark_f64_1d;
struct futhark_f64_1d *futhark_new_f64_1d(struct futhark_context *ctx, const double *data, int64_t dim0);
struct futhark_f64_1d *futhark_new_raw_f64_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0);
int futhark_free_f64_1d(struct futhark_context *ctx, struct futhark_f64_1d *arr);
int futhark_values_f64_1d(struct futhark_context *ctx, struct futhark_f64_1d *arr, double *data);
int futhark_index_f64_1d(struct futhark_context *ctx, double *out, struct futhark_f64_1d *arr, int64_t i0);
CUdeviceptr futhark_values_raw_f64_1d(struct futhark_context *ctx, struct futhark_f64_1d *arr);
const int64_t *futhark_shape_f64_1d(struct futhark_context *ctx, struct futhark_f64_1d *arr);
struct futhark_i16_1d;
struct futhark_i16_1d *futhark_new_i16_1d(struct futhark_context *ctx, const int16_t *data, int64_t dim0);
struct futhark_i16_1d *futhark_new_raw_i16_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0);
int futhark_free_i16_1d(struct futhark_context *ctx, struct futhark_i16_1d *arr);
int futhark_values_i16_1d(struct futhark_context *ctx, struct futhark_i16_1d *arr, int16_t *data);
int futhark_index_i16_1d(struct futhark_context *ctx, int16_t *out, struct futhark_i16_1d *arr, int64_t i0);
CUdeviceptr futhark_values_raw_i16_1d(struct futhark_context *ctx, struct futhark_i16_1d *arr);
const int64_t *futhark_shape_i16_1d(struct futhark_context *ctx, struct futhark_i16_1d *arr);
struct futhark_i32_1d;
struct futhark_i32_1d *futhark_new_i32_1d(struct futhark_context *ctx, const int32_t *data, int64_t dim0);
struct futhark_i32_1d *futhark_new_raw_i32_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0);
int futhark_free_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr);
int futhark_values_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr, int32_t *data);
int futhark_index_i32_1d(struct futhark_context *ctx, int32_t *out, struct futhark_i32_1d *arr, int64_t i0);
CUdeviceptr futhark_values_raw_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr);
const int64_t *futhark_shape_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr);
struct futhark_i64_1d;
struct futhark_i64_1d *futhark_new_i64_1d(struct futhark_context *ctx, const int64_t *data, int64_t dim0);
struct futhark_i64_1d *futhark_new_raw_i64_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0);
int futhark_free_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr);
int futhark_values_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr, int64_t *data);
int futhark_index_i64_1d(struct futhark_context *ctx, int64_t *out, struct futhark_i64_1d *arr, int64_t i0);
CUdeviceptr futhark_values_raw_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr);
const int64_t *futhark_shape_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr);

// Opaque values
struct futhark_opaque_joinPairs_double;
struct futhark_opaque_joinPairs_float;
struct futhark_opaque_joinPairs_int;
struct futhark_opaque_joinPairs_long;
struct futhark_opaque_joinPairs_short;
int futhark_free_opaque_joinPairs_double(struct futhark_context *ctx, struct futhark_opaque_joinPairs_double *obj);
int futhark_store_opaque_joinPairs_double(struct futhark_context *ctx, const struct futhark_opaque_joinPairs_double *obj, void **p, size_t *n);
struct futhark_opaque_joinPairs_double *futhark_restore_opaque_joinPairs_double(struct futhark_context *ctx, const void *p);
int futhark_project_opaque_joinPairs_double_ix(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_double *obj);
int futhark_project_opaque_joinPairs_double_iy(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_double *obj);
int futhark_project_opaque_joinPairs_double_vs(struct futhark_context *ctx, struct futhark_f64_1d **out, const struct futhark_opaque_joinPairs_double *obj);
int futhark_new_opaque_joinPairs_double(struct futhark_context *ctx, struct futhark_opaque_joinPairs_double **out, const struct futhark_i64_1d *f_ix, const struct futhark_i64_1d *f_iy, const struct futhark_f64_1d *f_vs);
int futhark_free_opaque_joinPairs_float(struct futhark_context *ctx, struct futhark_opaque_joinPairs_float *obj);
int futhark_store_opaque_joinPairs_float(struct futhark_context *ctx, const struct futhark_opaque_joinPairs_float *obj, void **p, size_t *n);
struct futhark_opaque_joinPairs_float *futhark_restore_opaque_joinPairs_float(struct futhark_context *ctx, const void *p);
int futhark_project_opaque_joinPairs_float_ix(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_float *obj);
int futhark_project_opaque_joinPairs_float_iy(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_float *obj);
int futhark_project_opaque_joinPairs_float_vs(struct futhark_context *ctx, struct futhark_f32_1d **out, const struct futhark_opaque_joinPairs_float *obj);
int futhark_new_opaque_joinPairs_float(struct futhark_context *ctx, struct futhark_opaque_joinPairs_float **out, const struct futhark_i64_1d *f_ix, const struct futhark_i64_1d *f_iy, const struct futhark_f32_1d *f_vs);
int futhark_free_opaque_joinPairs_int(struct futhark_context *ctx, struct futhark_opaque_joinPairs_int *obj);
int futhark_store_opaque_joinPairs_int(struct futhark_context *ctx, const struct futhark_opaque_joinPairs_int *obj, void **p, size_t *n);
struct futhark_opaque_joinPairs_int *futhark_restore_opaque_joinPairs_int(struct futhark_context *ctx, const void *p);
int futhark_project_opaque_joinPairs_int_ix(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_int *obj);
int futhark_project_opaque_joinPairs_int_iy(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_int *obj);
int futhark_project_opaque_joinPairs_int_vs(struct futhark_context *ctx, struct futhark_i32_1d **out, const struct futhark_opaque_joinPairs_int *obj);
int futhark_new_opaque_joinPairs_int(struct futhark_context *ctx, struct futhark_opaque_joinPairs_int **out, const struct futhark_i64_1d *f_ix, const struct futhark_i64_1d *f_iy, const struct futhark_i32_1d *f_vs);
int futhark_free_opaque_joinPairs_long(struct futhark_context *ctx, struct futhark_opaque_joinPairs_long *obj);
int futhark_store_opaque_joinPairs_long(struct futhark_context *ctx, const struct futhark_opaque_joinPairs_long *obj, void **p, size_t *n);
struct futhark_opaque_joinPairs_long *futhark_restore_opaque_joinPairs_long(struct futhark_context *ctx, const void *p);
int futhark_project_opaque_joinPairs_long_ix(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_long *obj);
int futhark_project_opaque_joinPairs_long_iy(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_long *obj);
int futhark_project_opaque_joinPairs_long_vs(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_long *obj);
int futhark_new_opaque_joinPairs_long(struct futhark_context *ctx, struct futhark_opaque_joinPairs_long **out, const struct futhark_i64_1d *f_ix, const struct futhark_i64_1d *f_iy, const struct futhark_i64_1d *f_vs);
int futhark_free_opaque_joinPairs_short(struct futhark_context *ctx, struct futhark_opaque_joinPairs_short *obj);
int futhark_store_opaque_joinPairs_short(struct futhark_context *ctx, const struct futhark_opaque_joinPairs_short *obj, void **p, size_t *n);
struct futhark_opaque_joinPairs_short *futhark_restore_opaque_joinPairs_short(struct futhark_context *ctx, const void *p);
int futhark_project_opaque_joinPairs_short_ix(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_short *obj);
int futhark_project_opaque_joinPairs_short_iy(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_short *obj);
int futhark_project_opaque_joinPairs_short_vs(struct futhark_context *ctx, struct futhark_i16_1d **out, const struct futhark_opaque_joinPairs_short *obj);
int futhark_new_opaque_joinPairs_short(struct futhark_context *ctx, struct futhark_opaque_joinPairs_short **out, const struct futhark_i64_1d *f_ix, const struct futhark_i64_1d *f_iy, const struct futhark_i16_1d *f_vs);

// Entry points
int futhark_entry_gather_payloads_double(struct futhark_context *ctx, struct futhark_f64_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_i64_1d *in2, const struct futhark_f64_1d *in3);
int futhark_entry_gather_payloads_double_GFUR(struct futhark_context *ctx, struct futhark_f64_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_f64_1d *in2, const struct futhark_i64_1d *in3, const struct futhark_f64_1d *in4);
int futhark_entry_gather_payloads_float(struct futhark_context *ctx, struct futhark_f32_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_i64_1d *in2, const struct futhark_f32_1d *in3);
int futhark_entry_gather_payloads_float_GFUR(struct futhark_context *ctx, struct futhark_f32_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_f32_1d *in2, const struct futhark_i64_1d *in3, const struct futhark_f32_1d *in4);
int futhark_entry_gather_payloads_int(struct futhark_context *ctx, struct futhark_i32_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_i64_1d *in2, const struct futhark_i32_1d *in3);
int futhark_entry_gather_payloads_int_GFUR(struct futhark_context *ctx, struct futhark_i32_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_i32_1d *in2, const struct futhark_i64_1d *in3, const struct futhark_i32_1d *in4);
int futhark_entry_gather_payloads_long(struct futhark_context *ctx, struct futhark_i64_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_i64_1d *in2, const struct futhark_i64_1d *in3);
int futhark_entry_gather_payloads_long_GFUR(struct futhark_context *ctx, struct futhark_i64_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_i64_1d *in2, const struct futhark_i64_1d *in3, const struct futhark_i64_1d *in4);
int futhark_entry_gather_payloads_short(struct futhark_context *ctx, struct futhark_i16_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_i64_1d *in2, const struct futhark_i16_1d *in3);
int futhark_entry_gather_payloads_short_GFUR(struct futhark_context *ctx, struct futhark_i16_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_i16_1d *in2, const struct futhark_i64_1d *in3, const struct futhark_i16_1d *in4);
int futhark_entry_inner_SMJ_double(struct futhark_context *ctx, struct futhark_opaque_joinPairs_double **out0, const struct futhark_f64_1d *in0, const struct futhark_f64_1d *in1, const int64_t in2, const int64_t in3, const int64_t in4, const int64_t in5, const int64_t in6, const int64_t in7);
int futhark_entry_inner_SMJ_float(struct futhark_context *ctx, struct futhark_opaque_joinPairs_float **out0, const struct futhark_f32_1d *in0, const struct futhark_f32_1d *in1, const int64_t in2, const int64_t in3, const int64_t in4, const int64_t in5, const int64_t in6, const int64_t in7);
int futhark_entry_inner_SMJ_int(struct futhark_context *ctx, struct futhark_opaque_joinPairs_int **out0, const struct futhark_i32_1d *in0, const struct futhark_i32_1d *in1, const int64_t in2, const int64_t in3, const int64_t in4, const int64_t in5, const int64_t in6, const int64_t in7);
int futhark_entry_inner_SMJ_long(struct futhark_context *ctx, struct futhark_opaque_joinPairs_long **out0, const struct futhark_i64_1d *in0, const struct futhark_i64_1d *in1, const int64_t in2, const int64_t in3, const int64_t in4, const int64_t in5, const int64_t in6, const int64_t in7);
int futhark_entry_inner_SMJ_short(struct futhark_context *ctx, struct futhark_opaque_joinPairs_short **out0, const struct futhark_i16_1d *in0, const struct futhark_i16_1d *in1, const int64_t in2, const int64_t in3, const int64_t in4, const int64_t in5, const int64_t in6, const int64_t in7);
int futhark_entry_max_idx(struct futhark_context *ctx, int64_t *out0, const struct futhark_i64_1d *in0);
int futhark_entry_min_idx(struct futhark_context *ctx, int64_t *out0, const struct futhark_i64_1d *in0);

// Miscellaneous
int futhark_context_sync(struct futhark_context *ctx);
void futhark_context_config_set_cache_file(struct futhark_context_config *cfg, const char *f);
char *futhark_context_get_error(struct futhark_context *ctx);
void futhark_context_set_logging_file(struct futhark_context *ctx, FILE *f);
void futhark_context_pause_profiling(struct futhark_context *ctx);
void futhark_context_unpause_profiling(struct futhark_context *ctx);
char *futhark_context_report(struct futhark_context *ctx);
int futhark_context_clear_caches(struct futhark_context *ctx);
#define FUTHARK_BACKEND_cuda
#define FUTHARK_SUCCESS 0
#define FUTHARK_PROGRAM_ERROR 2
#define FUTHARK_OUT_OF_MEMORY 3

#ifdef __cplusplus
}
#endif

#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <math.h>
#include <stdint.h>
// If NDEBUG is set, the assert() macro will do nothing. Since Futhark
// (unfortunately) makes use of assert() for error detection (and even some
// side effects), we want to avoid that.
#undef NDEBUG
#include <assert.h>
#include <stdarg.h>
#define SCALAR_FUN_ATTR static inline
// Start of util.h.
//
// Various helper functions that are useful in all generated C code.

#include <errno.h>
#include <string.h>

static const char *fut_progname = "(embedded Futhark)";

static void futhark_panic(int eval, const char *fmt, ...) __attribute__((noreturn));
static char* msgprintf(const char *s, ...);
static void* slurp_file(const char *filename, size_t *size);
static int dump_file(const char *file, const void *buf, size_t n);
struct str_builder;
static void str_builder_init(struct str_builder *b);
static void str_builder(struct str_builder *b, const char *s, ...);
static char *strclone(const char *str);

static void futhark_panic(int eval, const char *fmt, ...) {
  va_list ap;
  va_start(ap, fmt);
  fprintf(stderr, "%s: ", fut_progname);
  vfprintf(stderr, fmt, ap);
  va_end(ap);
  exit(eval);
}

// For generating arbitrary-sized error messages.  It is the callers
// responsibility to free the buffer at some point.
static char* msgprintf(const char *s, ...) {
  va_list vl;
  va_start(vl, s);
  size_t needed = 1 + (size_t)vsnprintf(NULL, 0, s, vl);
  char *buffer = (char*) malloc(needed);
  va_start(vl, s); // Must re-init.
  vsnprintf(buffer, needed, s, vl);
  return buffer;
}

static inline void check_err(int errval, int sets_errno, const char *fun, int line,
                             const char *msg, ...) {
  if (errval) {
    char errnum[10];

    va_list vl;
    va_start(vl, msg);

    fprintf(stderr, "ERROR: ");
    vfprintf(stderr, msg, vl);
    fprintf(stderr, " in %s() at line %d with error code %s\n",
            fun, line,
            sets_errno ? strerror(errno) : errnum);
    exit(errval);
  }
}

#define CHECK_ERR(err, ...) check_err(err, 0, __func__, __LINE__, __VA_ARGS__)
#define CHECK_ERRNO(err, ...) check_err(err, 1, __func__, __LINE__, __VA_ARGS__)

// Read the rest of an open file into a NUL-terminated string; returns
// NULL on error.
static void* fslurp_file(FILE *f, size_t *size) {
  long start = ftell(f);
  fseek(f, 0, SEEK_END);
  long src_size = ftell(f)-start;
  fseek(f, start, SEEK_SET);
  unsigned char *s = (unsigned char*) malloc((size_t)src_size + 1);
  if (fread(s, 1, (size_t)src_size, f) != (size_t)src_size) {
    free(s);
    s = NULL;
  } else {
    s[src_size] = '\0';
  }

  if (size) {
    *size = (size_t)src_size;
  }

  return s;
}

// Read a file into a NUL-terminated string; returns NULL on error.
static void* slurp_file(const char *filename, size_t *size) {
  FILE *f = fopen(filename, "rb"); // To avoid Windows messing with linebreaks.
  if (f == NULL) return NULL;
  unsigned char *s = fslurp_file(f, size);
  fclose(f);
  return s;
}

// Dump 'n' bytes from 'buf' into the file at the designated location.
// Returns 0 on success.
static int dump_file(const char *file, const void *buf, size_t n) {
  FILE *f = fopen(file, "w");

  if (f == NULL) {
    return 1;
  }

  if (fwrite(buf, sizeof(char), n, f) != n) {
    return 1;
  }

  if (fclose(f) != 0) {
    return 1;
  }

  return 0;
}

struct str_builder {
  char *str;
  size_t capacity; // Size of buffer.
  size_t used; // Bytes used, *not* including final zero.
};

static void str_builder_init(struct str_builder *b) {
  b->capacity = 10;
  b->used = 0;
  b->str = malloc(b->capacity);
  b->str[0] = 0;
}

static void str_builder(struct str_builder *b, const char *s, ...) {
  va_list vl;
  va_start(vl, s);
  size_t needed = (size_t)vsnprintf(NULL, 0, s, vl);

  while (b->capacity < b->used + needed + 1) {
    b->capacity *= 2;
    b->str = realloc(b->str, b->capacity);
  }

  va_start(vl, s); // Must re-init.
  vsnprintf(b->str+b->used, b->capacity-b->used, s, vl);
  b->used += needed;
}

static void str_builder_str(struct str_builder *b, const char *s) {
  size_t needed = strlen(s);
  if (b->capacity < b->used + needed + 1) {
    b->capacity *= 2;
    b->str = realloc(b->str, b->capacity);
  }
  strcpy(b->str+b->used, s);
  b->used += needed;
}

static void str_builder_char(struct str_builder *b, char c) {
  size_t needed = 1;
  if (b->capacity < b->used + needed + 1) {
    b->capacity *= 2;
    b->str = realloc(b->str, b->capacity);
  }
  b->str[b->used] = c;
  b->str[b->used+1] = 0;
  b->used += needed;
}

static void str_builder_json_str(struct str_builder* sb, const char* s) {
  str_builder_char(sb, '"');
  for (int j = 0; s[j]; j++) {
    char c = s[j];
    switch (c) {
    case '\n':
      str_builder_str(sb, "\\n");
      break;
    case '"':
      str_builder_str(sb, "\\\"");
      break;
    default:
      str_builder_char(sb, c);
    }
  }
  str_builder_char(sb, '"');
}

static char *strclone(const char *str) {
  size_t size = strlen(str) + 1;
  char *copy = (char*) malloc(size);
  if (copy == NULL) {
    return NULL;
  }

  memcpy(copy, str, size);
  return copy;
}

// Assumes NULL-terminated.
static char *strconcat(const char *src_fragments[]) {
  size_t src_len = 0;
  const char **p;

  for (p = src_fragments; *p; p++) {
    src_len += strlen(*p);
  }

  char *src = (char*) malloc(src_len + 1);
  size_t n = 0;
  for (p = src_fragments; *p; p++) {
    strcpy(src + n, *p);
    n += strlen(*p);
  }

  return src;
}

// End of util.h.
// Start of cache.h

#define CACHE_HASH_SIZE 8 // In 32-bit words.

struct cache_hash {
  uint32_t hash[CACHE_HASH_SIZE];
};

// Initialise a blank cache.
static void cache_hash_init(struct cache_hash *c);

// Hash some bytes and add them to the accumulated hash.
static void cache_hash(struct cache_hash *out, const char *in, size_t n);

// Try to restore cache contents from a file with the given name.
// Assumes the cache is invalid if it contains the given hash.
// Allocates memory and reads the cache conents, which is returned in
// *buf with size *buflen.  If the cache is successfully loaded, this
// function returns 0.  Otherwise it returns nonzero.  Errno is set if
// the failure to load the cache is due to anything except invalid
// cache conents.  Note that failing to restore the cache is not
// necessarily a problem: it might just be invalid or not created yet.
static int cache_restore(const char *fname, const struct cache_hash *hash,
                         unsigned char **buf, size_t *buflen);

// Store cache contents in the given file, with the given hash.
static int cache_store(const char *fname, const struct cache_hash *hash,
                       const unsigned char *buf, size_t buflen);

// Now for the implementation.

static void cache_hash_init(struct cache_hash *c) {
  memset(c->hash, 0, CACHE_HASH_SIZE * sizeof(uint32_t));
}

static void cache_hash(struct cache_hash *out, const char *in, size_t n) {
  // Adaptation of djb2 for larger output size by storing intermediate
  // states.
  uint32_t hash = 5381;
  for (size_t i = 0; i < n; i++) {
    hash = ((hash << 5) + hash) + in[i];
    out->hash[i % CACHE_HASH_SIZE] ^= hash;
  }
}

#define CACHE_HEADER_SIZE 8
static const char cache_header[CACHE_HEADER_SIZE] = "FUTHARK\0";

static int cache_restore(const char *fname, const struct cache_hash *hash,
                         unsigned char **buf, size_t *buflen) {
  FILE *f = fopen(fname, "rb");

  if (f == NULL) {
    return 1;
  }

  char f_header[CACHE_HEADER_SIZE];

  if (fread(f_header, sizeof(char), CACHE_HEADER_SIZE, f) != CACHE_HEADER_SIZE) {
    goto error;
  }

  if (memcmp(f_header, cache_header, CACHE_HEADER_SIZE) != 0) {
    goto error;
  }

  if (fseek(f, 0, SEEK_END) != 0) {
    goto error;
  }
  int64_t f_size = (int64_t)ftell(f);
  if (fseek(f, CACHE_HEADER_SIZE, SEEK_SET) != 0) {
    goto error;
  }

  int64_t expected_size;

  if (fread(&expected_size, sizeof(int64_t), 1, f) != 1) {
    goto error;
  }

  if (f_size != expected_size) {
    errno = 0;
    goto error;
  }

  int32_t f_hash[CACHE_HASH_SIZE];

  if (fread(f_hash, sizeof(int32_t), CACHE_HASH_SIZE, f) != CACHE_HASH_SIZE) {
    goto error;
  }

  if (memcmp(f_hash, hash->hash, CACHE_HASH_SIZE) != 0) {
    errno = 0;
    goto error;
  }

  *buflen = f_size - CACHE_HEADER_SIZE - sizeof(int64_t) - CACHE_HASH_SIZE*sizeof(int32_t);
  *buf = malloc(*buflen);
  if (fread(*buf, sizeof(char), *buflen, f) != *buflen) {
    free(*buf);
    goto error;
  }

  fclose(f);

  return 0;

 error:
  fclose(f);
  return 1;
}

static int cache_store(const char *fname, const struct cache_hash *hash,
                       const unsigned char *buf, size_t buflen) {
  FILE *f = fopen(fname, "wb");

  if (f == NULL) {
    return 1;
  }

  if (fwrite(cache_header, CACHE_HEADER_SIZE, 1, f) != 1) {
    goto error;
  }

  int64_t size = CACHE_HEADER_SIZE + sizeof(int64_t) + CACHE_HASH_SIZE*sizeof(int32_t) + buflen;

  if (fwrite(&size, sizeof(size), 1, f) != 1) {
    goto error;
  }

  if (fwrite(hash->hash, sizeof(int32_t), CACHE_HASH_SIZE, f) != CACHE_HASH_SIZE) {
    goto error;
  }

  if (fwrite(buf, sizeof(unsigned char), buflen, f) != buflen) {
    goto error;
  }

  fclose(f);

  return 0;

 error:
  fclose(f);
  return 1;
}

// End of cache.h
// Start of half.h.

// Conversion functions are from http://half.sourceforge.net/, but
// translated to C.
//
// Copyright (c) 2012-2021 Christian Rau
//
// Permission is hereby granted, free of charge, to any person obtaining a copy
// of this software and associated documentation files (the "Software"), to deal
// in the Software without restriction, including without limitation the rights
// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
// copies of the Software, and to permit persons to whom the Software is
// furnished to do so, subject to the following conditions:
//
// The above copyright notice and this permission notice shall be included in
// all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
// THE SOFTWARE.

#ifndef __OPENCL_VERSION__
#define __constant
#endif

__constant static const uint16_t base_table[512] = {
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0001, 0x0002, 0x0004, 0x0008, 0x0010, 0x0020, 0x0040, 0x0080, 0x0100,
  0x0200, 0x0400, 0x0800, 0x0C00, 0x1000, 0x1400, 0x1800, 0x1C00, 0x2000, 0x2400, 0x2800, 0x2C00, 0x3000, 0x3400, 0x3800, 0x3C00,
  0x4000, 0x4400, 0x4800, 0x4C00, 0x5000, 0x5400, 0x5800, 0x5C00, 0x6000, 0x6400, 0x6800, 0x6C00, 0x7000, 0x7400, 0x7800, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8001, 0x8002, 0x8004, 0x8008, 0x8010, 0x8020, 0x8040, 0x8080, 0x8100,
  0x8200, 0x8400, 0x8800, 0x8C00, 0x9000, 0x9400, 0x9800, 0x9C00, 0xA000, 0xA400, 0xA800, 0xAC00, 0xB000, 0xB400, 0xB800, 0xBC00,
  0xC000, 0xC400, 0xC800, 0xCC00, 0xD000, 0xD400, 0xD800, 0xDC00, 0xE000, 0xE400, 0xE800, 0xEC00, 0xF000, 0xF400, 0xF800, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00 };

__constant static const unsigned char shift_table[512] = {
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13 };

__constant static const uint32_t mantissa_table[2048] = {
  0x00000000, 0x33800000, 0x34000000, 0x34400000, 0x34800000, 0x34A00000, 0x34C00000, 0x34E00000, 0x35000000, 0x35100000, 0x35200000, 0x35300000, 0x35400000, 0x35500000, 0x35600000, 0x35700000,
  0x35800000, 0x35880000, 0x35900000, 0x35980000, 0x35A00000, 0x35A80000, 0x35B00000, 0x35B80000, 0x35C00000, 0x35C80000, 0x35D00000, 0x35D80000, 0x35E00000, 0x35E80000, 0x35F00000, 0x35F80000,
  0x36000000, 0x36040000, 0x36080000, 0x360C0000, 0x36100000, 0x36140000, 0x36180000, 0x361C0000, 0x36200000, 0x36240000, 0x36280000, 0x362C0000, 0x36300000, 0x36340000, 0x36380000, 0x363C0000,
  0x36400000, 0x36440000, 0x36480000, 0x364C0000, 0x36500000, 0x36540000, 0x36580000, 0x365C0000, 0x36600000, 0x36640000, 0x36680000, 0x366C0000, 0x36700000, 0x36740000, 0x36780000, 0x367C0000,
  0x36800000, 0x36820000, 0x36840000, 0x36860000, 0x36880000, 0x368A0000, 0x368C0000, 0x368E0000, 0x36900000, 0x36920000, 0x36940000, 0x36960000, 0x36980000, 0x369A0000, 0x369C0000, 0x369E0000,
  0x36A00000, 0x36A20000, 0x36A40000, 0x36A60000, 0x36A80000, 0x36AA0000, 0x36AC0000, 0x36AE0000, 0x36B00000, 0x36B20000, 0x36B40000, 0x36B60000, 0x36B80000, 0x36BA0000, 0x36BC0000, 0x36BE0000,
  0x36C00000, 0x36C20000, 0x36C40000, 0x36C60000, 0x36C80000, 0x36CA0000, 0x36CC0000, 0x36CE0000, 0x36D00000, 0x36D20000, 0x36D40000, 0x36D60000, 0x36D80000, 0x36DA0000, 0x36DC0000, 0x36DE0000,
  0x36E00000, 0x36E20000, 0x36E40000, 0x36E60000, 0x36E80000, 0x36EA0000, 0x36EC0000, 0x36EE0000, 0x36F00000, 0x36F20000, 0x36F40000, 0x36F60000, 0x36F80000, 0x36FA0000, 0x36FC0000, 0x36FE0000,
  0x37000000, 0x37010000, 0x37020000, 0x37030000, 0x37040000, 0x37050000, 0x37060000, 0x37070000, 0x37080000, 0x37090000, 0x370A0000, 0x370B0000, 0x370C0000, 0x370D0000, 0x370E0000, 0x370F0000,
  0x37100000, 0x37110000, 0x37120000, 0x37130000, 0x37140000, 0x37150000, 0x37160000, 0x37170000, 0x37180000, 0x37190000, 0x371A0000, 0x371B0000, 0x371C0000, 0x371D0000, 0x371E0000, 0x371F0000,
  0x37200000, 0x37210000, 0x37220000, 0x37230000, 0x37240000, 0x37250000, 0x37260000, 0x37270000, 0x37280000, 0x37290000, 0x372A0000, 0x372B0000, 0x372C0000, 0x372D0000, 0x372E0000, 0x372F0000,
  0x37300000, 0x37310000, 0x37320000, 0x37330000, 0x37340000, 0x37350000, 0x37360000, 0x37370000, 0x37380000, 0x37390000, 0x373A0000, 0x373B0000, 0x373C0000, 0x373D0000, 0x373E0000, 0x373F0000,
  0x37400000, 0x37410000, 0x37420000, 0x37430000, 0x37440000, 0x37450000, 0x37460000, 0x37470000, 0x37480000, 0x37490000, 0x374A0000, 0x374B0000, 0x374C0000, 0x374D0000, 0x374E0000, 0x374F0000,
  0x37500000, 0x37510000, 0x37520000, 0x37530000, 0x37540000, 0x37550000, 0x37560000, 0x37570000, 0x37580000, 0x37590000, 0x375A0000, 0x375B0000, 0x375C0000, 0x375D0000, 0x375E0000, 0x375F0000,
  0x37600000, 0x37610000, 0x37620000, 0x37630000, 0x37640000, 0x37650000, 0x37660000, 0x37670000, 0x37680000, 0x37690000, 0x376A0000, 0x376B0000, 0x376C0000, 0x376D0000, 0x376E0000, 0x376F0000,
  0x37700000, 0x37710000, 0x37720000, 0x37730000, 0x37740000, 0x37750000, 0x37760000, 0x37770000, 0x37780000, 0x37790000, 0x377A0000, 0x377B0000, 0x377C0000, 0x377D0000, 0x377E0000, 0x377F0000,
  0x37800000, 0x37808000, 0x37810000, 0x37818000, 0x37820000, 0x37828000, 0x37830000, 0x37838000, 0x37840000, 0x37848000, 0x37850000, 0x37858000, 0x37860000, 0x37868000, 0x37870000, 0x37878000,
  0x37880000, 0x37888000, 0x37890000, 0x37898000, 0x378A0000, 0x378A8000, 0x378B0000, 0x378B8000, 0x378C0000, 0x378C8000, 0x378D0000, 0x378D8000, 0x378E0000, 0x378E8000, 0x378F0000, 0x378F8000,
  0x37900000, 0x37908000, 0x37910000, 0x37918000, 0x37920000, 0x37928000, 0x37930000, 0x37938000, 0x37940000, 0x37948000, 0x37950000, 0x37958000, 0x37960000, 0x37968000, 0x37970000, 0x37978000,
  0x37980000, 0x37988000, 0x37990000, 0x37998000, 0x379A0000, 0x379A8000, 0x379B0000, 0x379B8000, 0x379C0000, 0x379C8000, 0x379D0000, 0x379D8000, 0x379E0000, 0x379E8000, 0x379F0000, 0x379F8000,
  0x37A00000, 0x37A08000, 0x37A10000, 0x37A18000, 0x37A20000, 0x37A28000, 0x37A30000, 0x37A38000, 0x37A40000, 0x37A48000, 0x37A50000, 0x37A58000, 0x37A60000, 0x37A68000, 0x37A70000, 0x37A78000,
  0x37A80000, 0x37A88000, 0x37A90000, 0x37A98000, 0x37AA0000, 0x37AA8000, 0x37AB0000, 0x37AB8000, 0x37AC0000, 0x37AC8000, 0x37AD0000, 0x37AD8000, 0x37AE0000, 0x37AE8000, 0x37AF0000, 0x37AF8000,
  0x37B00000, 0x37B08000, 0x37B10000, 0x37B18000, 0x37B20000, 0x37B28000, 0x37B30000, 0x37B38000, 0x37B40000, 0x37B48000, 0x37B50000, 0x37B58000, 0x37B60000, 0x37B68000, 0x37B70000, 0x37B78000,
  0x37B80000, 0x37B88000, 0x37B90000, 0x37B98000, 0x37BA0000, 0x37BA8000, 0x37BB0000, 0x37BB8000, 0x37BC0000, 0x37BC8000, 0x37BD0000, 0x37BD8000, 0x37BE0000, 0x37BE8000, 0x37BF0000, 0x37BF8000,
  0x37C00000, 0x37C08000, 0x37C10000, 0x37C18000, 0x37C20000, 0x37C28000, 0x37C30000, 0x37C38000, 0x37C40000, 0x37C48000, 0x37C50000, 0x37C58000, 0x37C60000, 0x37C68000, 0x37C70000, 0x37C78000,
  0x37C80000, 0x37C88000, 0x37C90000, 0x37C98000, 0x37CA0000, 0x37CA8000, 0x37CB0000, 0x37CB8000, 0x37CC0000, 0x37CC8000, 0x37CD0000, 0x37CD8000, 0x37CE0000, 0x37CE8000, 0x37CF0000, 0x37CF8000,
  0x37D00000, 0x37D08000, 0x37D10000, 0x37D18000, 0x37D20000, 0x37D28000, 0x37D30000, 0x37D38000, 0x37D40000, 0x37D48000, 0x37D50000, 0x37D58000, 0x37D60000, 0x37D68000, 0x37D70000, 0x37D78000,
  0x37D80000, 0x37D88000, 0x37D90000, 0x37D98000, 0x37DA0000, 0x37DA8000, 0x37DB0000, 0x37DB8000, 0x37DC0000, 0x37DC8000, 0x37DD0000, 0x37DD8000, 0x37DE0000, 0x37DE8000, 0x37DF0000, 0x37DF8000,
  0x37E00000, 0x37E08000, 0x37E10000, 0x37E18000, 0x37E20000, 0x37E28000, 0x37E30000, 0x37E38000, 0x37E40000, 0x37E48000, 0x37E50000, 0x37E58000, 0x37E60000, 0x37E68000, 0x37E70000, 0x37E78000,
  0x37E80000, 0x37E88000, 0x37E90000, 0x37E98000, 0x37EA0000, 0x37EA8000, 0x37EB0000, 0x37EB8000, 0x37EC0000, 0x37EC8000, 0x37ED0000, 0x37ED8000, 0x37EE0000, 0x37EE8000, 0x37EF0000, 0x37EF8000,
  0x37F00000, 0x37F08000, 0x37F10000, 0x37F18000, 0x37F20000, 0x37F28000, 0x37F30000, 0x37F38000, 0x37F40000, 0x37F48000, 0x37F50000, 0x37F58000, 0x37F60000, 0x37F68000, 0x37F70000, 0x37F78000,
  0x37F80000, 0x37F88000, 0x37F90000, 0x37F98000, 0x37FA0000, 0x37FA8000, 0x37FB0000, 0x37FB8000, 0x37FC0000, 0x37FC8000, 0x37FD0000, 0x37FD8000, 0x37FE0000, 0x37FE8000, 0x37FF0000, 0x37FF8000,
  0x38000000, 0x38004000, 0x38008000, 0x3800C000, 0x38010000, 0x38014000, 0x38018000, 0x3801C000, 0x38020000, 0x38024000, 0x38028000, 0x3802C000, 0x38030000, 0x38034000, 0x38038000, 0x3803C000,
  0x38040000, 0x38044000, 0x38048000, 0x3804C000, 0x38050000, 0x38054000, 0x38058000, 0x3805C000, 0x38060000, 0x38064000, 0x38068000, 0x3806C000, 0x38070000, 0x38074000, 0x38078000, 0x3807C000,
  0x38080000, 0x38084000, 0x38088000, 0x3808C000, 0x38090000, 0x38094000, 0x38098000, 0x3809C000, 0x380A0000, 0x380A4000, 0x380A8000, 0x380AC000, 0x380B0000, 0x380B4000, 0x380B8000, 0x380BC000,
  0x380C0000, 0x380C4000, 0x380C8000, 0x380CC000, 0x380D0000, 0x380D4000, 0x380D8000, 0x380DC000, 0x380E0000, 0x380E4000, 0x380E8000, 0x380EC000, 0x380F0000, 0x380F4000, 0x380F8000, 0x380FC000,
  0x38100000, 0x38104000, 0x38108000, 0x3810C000, 0x38110000, 0x38114000, 0x38118000, 0x3811C000, 0x38120000, 0x38124000, 0x38128000, 0x3812C000, 0x38130000, 0x38134000, 0x38138000, 0x3813C000,
  0x38140000, 0x38144000, 0x38148000, 0x3814C000, 0x38150000, 0x38154000, 0x38158000, 0x3815C000, 0x38160000, 0x38164000, 0x38168000, 0x3816C000, 0x38170000, 0x38174000, 0x38178000, 0x3817C000,
  0x38180000, 0x38184000, 0x38188000, 0x3818C000, 0x38190000, 0x38194000, 0x38198000, 0x3819C000, 0x381A0000, 0x381A4000, 0x381A8000, 0x381AC000, 0x381B0000, 0x381B4000, 0x381B8000, 0x381BC000,
  0x381C0000, 0x381C4000, 0x381C8000, 0x381CC000, 0x381D0000, 0x381D4000, 0x381D8000, 0x381DC000, 0x381E0000, 0x381E4000, 0x381E8000, 0x381EC000, 0x381F0000, 0x381F4000, 0x381F8000, 0x381FC000,
  0x38200000, 0x38204000, 0x38208000, 0x3820C000, 0x38210000, 0x38214000, 0x38218000, 0x3821C000, 0x38220000, 0x38224000, 0x38228000, 0x3822C000, 0x38230000, 0x38234000, 0x38238000, 0x3823C000,
  0x38240000, 0x38244000, 0x38248000, 0x3824C000, 0x38250000, 0x38254000, 0x38258000, 0x3825C000, 0x38260000, 0x38264000, 0x38268000, 0x3826C000, 0x38270000, 0x38274000, 0x38278000, 0x3827C000,
  0x38280000, 0x38284000, 0x38288000, 0x3828C000, 0x38290000, 0x38294000, 0x38298000, 0x3829C000, 0x382A0000, 0x382A4000, 0x382A8000, 0x382AC000, 0x382B0000, 0x382B4000, 0x382B8000, 0x382BC000,
  0x382C0000, 0x382C4000, 0x382C8000, 0x382CC000, 0x382D0000, 0x382D4000, 0x382D8000, 0x382DC000, 0x382E0000, 0x382E4000, 0x382E8000, 0x382EC000, 0x382F0000, 0x382F4000, 0x382F8000, 0x382FC000,
  0x38300000, 0x38304000, 0x38308000, 0x3830C000, 0x38310000, 0x38314000, 0x38318000, 0x3831C000, 0x38320000, 0x38324000, 0x38328000, 0x3832C000, 0x38330000, 0x38334000, 0x38338000, 0x3833C000,
  0x38340000, 0x38344000, 0x38348000, 0x3834C000, 0x38350000, 0x38354000, 0x38358000, 0x3835C000, 0x38360000, 0x38364000, 0x38368000, 0x3836C000, 0x38370000, 0x38374000, 0x38378000, 0x3837C000,
  0x38380000, 0x38384000, 0x38388000, 0x3838C000, 0x38390000, 0x38394000, 0x38398000, 0x3839C000, 0x383A0000, 0x383A4000, 0x383A8000, 0x383AC000, 0x383B0000, 0x383B4000, 0x383B8000, 0x383BC000,
  0x383C0000, 0x383C4000, 0x383C8000, 0x383CC000, 0x383D0000, 0x383D4000, 0x383D8000, 0x383DC000, 0x383E0000, 0x383E4000, 0x383E8000, 0x383EC000, 0x383F0000, 0x383F4000, 0x383F8000, 0x383FC000,
  0x38400000, 0x38404000, 0x38408000, 0x3840C000, 0x38410000, 0x38414000, 0x38418000, 0x3841C000, 0x38420000, 0x38424000, 0x38428000, 0x3842C000, 0x38430000, 0x38434000, 0x38438000, 0x3843C000,
  0x38440000, 0x38444000, 0x38448000, 0x3844C000, 0x38450000, 0x38454000, 0x38458000, 0x3845C000, 0x38460000, 0x38464000, 0x38468000, 0x3846C000, 0x38470000, 0x38474000, 0x38478000, 0x3847C000,
  0x38480000, 0x38484000, 0x38488000, 0x3848C000, 0x38490000, 0x38494000, 0x38498000, 0x3849C000, 0x384A0000, 0x384A4000, 0x384A8000, 0x384AC000, 0x384B0000, 0x384B4000, 0x384B8000, 0x384BC000,
  0x384C0000, 0x384C4000, 0x384C8000, 0x384CC000, 0x384D0000, 0x384D4000, 0x384D8000, 0x384DC000, 0x384E0000, 0x384E4000, 0x384E8000, 0x384EC000, 0x384F0000, 0x384F4000, 0x384F8000, 0x384FC000,
  0x38500000, 0x38504000, 0x38508000, 0x3850C000, 0x38510000, 0x38514000, 0x38518000, 0x3851C000, 0x38520000, 0x38524000, 0x38528000, 0x3852C000, 0x38530000, 0x38534000, 0x38538000, 0x3853C000,
  0x38540000, 0x38544000, 0x38548000, 0x3854C000, 0x38550000, 0x38554000, 0x38558000, 0x3855C000, 0x38560000, 0x38564000, 0x38568000, 0x3856C000, 0x38570000, 0x38574000, 0x38578000, 0x3857C000,
  0x38580000, 0x38584000, 0x38588000, 0x3858C000, 0x38590000, 0x38594000, 0x38598000, 0x3859C000, 0x385A0000, 0x385A4000, 0x385A8000, 0x385AC000, 0x385B0000, 0x385B4000, 0x385B8000, 0x385BC000,
  0x385C0000, 0x385C4000, 0x385C8000, 0x385CC000, 0x385D0000, 0x385D4000, 0x385D8000, 0x385DC000, 0x385E0000, 0x385E4000, 0x385E8000, 0x385EC000, 0x385F0000, 0x385F4000, 0x385F8000, 0x385FC000,
  0x38600000, 0x38604000, 0x38608000, 0x3860C000, 0x38610000, 0x38614000, 0x38618000, 0x3861C000, 0x38620000, 0x38624000, 0x38628000, 0x3862C000, 0x38630000, 0x38634000, 0x38638000, 0x3863C000,
  0x38640000, 0x38644000, 0x38648000, 0x3864C000, 0x38650000, 0x38654000, 0x38658000, 0x3865C000, 0x38660000, 0x38664000, 0x38668000, 0x3866C000, 0x38670000, 0x38674000, 0x38678000, 0x3867C000,
  0x38680000, 0x38684000, 0x38688000, 0x3868C000, 0x38690000, 0x38694000, 0x38698000, 0x3869C000, 0x386A0000, 0x386A4000, 0x386A8000, 0x386AC000, 0x386B0000, 0x386B4000, 0x386B8000, 0x386BC000,
  0x386C0000, 0x386C4000, 0x386C8000, 0x386CC000, 0x386D0000, 0x386D4000, 0x386D8000, 0x386DC000, 0x386E0000, 0x386E4000, 0x386E8000, 0x386EC000, 0x386F0000, 0x386F4000, 0x386F8000, 0x386FC000,
  0x38700000, 0x38704000, 0x38708000, 0x3870C000, 0x38710000, 0x38714000, 0x38718000, 0x3871C000, 0x38720000, 0x38724000, 0x38728000, 0x3872C000, 0x38730000, 0x38734000, 0x38738000, 0x3873C000,
  0x38740000, 0x38744000, 0x38748000, 0x3874C000, 0x38750000, 0x38754000, 0x38758000, 0x3875C000, 0x38760000, 0x38764000, 0x38768000, 0x3876C000, 0x38770000, 0x38774000, 0x38778000, 0x3877C000,
  0x38780000, 0x38784000, 0x38788000, 0x3878C000, 0x38790000, 0x38794000, 0x38798000, 0x3879C000, 0x387A0000, 0x387A4000, 0x387A8000, 0x387AC000, 0x387B0000, 0x387B4000, 0x387B8000, 0x387BC000,
  0x387C0000, 0x387C4000, 0x387C8000, 0x387CC000, 0x387D0000, 0x387D4000, 0x387D8000, 0x387DC000, 0x387E0000, 0x387E4000, 0x387E8000, 0x387EC000, 0x387F0000, 0x387F4000, 0x387F8000, 0x387FC000,
  0x38000000, 0x38002000, 0x38004000, 0x38006000, 0x38008000, 0x3800A000, 0x3800C000, 0x3800E000, 0x38010000, 0x38012000, 0x38014000, 0x38016000, 0x38018000, 0x3801A000, 0x3801C000, 0x3801E000,
  0x38020000, 0x38022000, 0x38024000, 0x38026000, 0x38028000, 0x3802A000, 0x3802C000, 0x3802E000, 0x38030000, 0x38032000, 0x38034000, 0x38036000, 0x38038000, 0x3803A000, 0x3803C000, 0x3803E000,
  0x38040000, 0x38042000, 0x38044000, 0x38046000, 0x38048000, 0x3804A000, 0x3804C000, 0x3804E000, 0x38050000, 0x38052000, 0x38054000, 0x38056000, 0x38058000, 0x3805A000, 0x3805C000, 0x3805E000,
  0x38060000, 0x38062000, 0x38064000, 0x38066000, 0x38068000, 0x3806A000, 0x3806C000, 0x3806E000, 0x38070000, 0x38072000, 0x38074000, 0x38076000, 0x38078000, 0x3807A000, 0x3807C000, 0x3807E000,
  0x38080000, 0x38082000, 0x38084000, 0x38086000, 0x38088000, 0x3808A000, 0x3808C000, 0x3808E000, 0x38090000, 0x38092000, 0x38094000, 0x38096000, 0x38098000, 0x3809A000, 0x3809C000, 0x3809E000,
  0x380A0000, 0x380A2000, 0x380A4000, 0x380A6000, 0x380A8000, 0x380AA000, 0x380AC000, 0x380AE000, 0x380B0000, 0x380B2000, 0x380B4000, 0x380B6000, 0x380B8000, 0x380BA000, 0x380BC000, 0x380BE000,
  0x380C0000, 0x380C2000, 0x380C4000, 0x380C6000, 0x380C8000, 0x380CA000, 0x380CC000, 0x380CE000, 0x380D0000, 0x380D2000, 0x380D4000, 0x380D6000, 0x380D8000, 0x380DA000, 0x380DC000, 0x380DE000,
  0x380E0000, 0x380E2000, 0x380E4000, 0x380E6000, 0x380E8000, 0x380EA000, 0x380EC000, 0x380EE000, 0x380F0000, 0x380F2000, 0x380F4000, 0x380F6000, 0x380F8000, 0x380FA000, 0x380FC000, 0x380FE000,
  0x38100000, 0x38102000, 0x38104000, 0x38106000, 0x38108000, 0x3810A000, 0x3810C000, 0x3810E000, 0x38110000, 0x38112000, 0x38114000, 0x38116000, 0x38118000, 0x3811A000, 0x3811C000, 0x3811E000,
  0x38120000, 0x38122000, 0x38124000, 0x38126000, 0x38128000, 0x3812A000, 0x3812C000, 0x3812E000, 0x38130000, 0x38132000, 0x38134000, 0x38136000, 0x38138000, 0x3813A000, 0x3813C000, 0x3813E000,
  0x38140000, 0x38142000, 0x38144000, 0x38146000, 0x38148000, 0x3814A000, 0x3814C000, 0x3814E000, 0x38150000, 0x38152000, 0x38154000, 0x38156000, 0x38158000, 0x3815A000, 0x3815C000, 0x3815E000,
  0x38160000, 0x38162000, 0x38164000, 0x38166000, 0x38168000, 0x3816A000, 0x3816C000, 0x3816E000, 0x38170000, 0x38172000, 0x38174000, 0x38176000, 0x38178000, 0x3817A000, 0x3817C000, 0x3817E000,
  0x38180000, 0x38182000, 0x38184000, 0x38186000, 0x38188000, 0x3818A000, 0x3818C000, 0x3818E000, 0x38190000, 0x38192000, 0x38194000, 0x38196000, 0x38198000, 0x3819A000, 0x3819C000, 0x3819E000,
  0x381A0000, 0x381A2000, 0x381A4000, 0x381A6000, 0x381A8000, 0x381AA000, 0x381AC000, 0x381AE000, 0x381B0000, 0x381B2000, 0x381B4000, 0x381B6000, 0x381B8000, 0x381BA000, 0x381BC000, 0x381BE000,
  0x381C0000, 0x381C2000, 0x381C4000, 0x381C6000, 0x381C8000, 0x381CA000, 0x381CC000, 0x381CE000, 0x381D0000, 0x381D2000, 0x381D4000, 0x381D6000, 0x381D8000, 0x381DA000, 0x381DC000, 0x381DE000,
  0x381E0000, 0x381E2000, 0x381E4000, 0x381E6000, 0x381E8000, 0x381EA000, 0x381EC000, 0x381EE000, 0x381F0000, 0x381F2000, 0x381F4000, 0x381F6000, 0x381F8000, 0x381FA000, 0x381FC000, 0x381FE000,
  0x38200000, 0x38202000, 0x38204000, 0x38206000, 0x38208000, 0x3820A000, 0x3820C000, 0x3820E000, 0x38210000, 0x38212000, 0x38214000, 0x38216000, 0x38218000, 0x3821A000, 0x3821C000, 0x3821E000,
  0x38220000, 0x38222000, 0x38224000, 0x38226000, 0x38228000, 0x3822A000, 0x3822C000, 0x3822E000, 0x38230000, 0x38232000, 0x38234000, 0x38236000, 0x38238000, 0x3823A000, 0x3823C000, 0x3823E000,
  0x38240000, 0x38242000, 0x38244000, 0x38246000, 0x38248000, 0x3824A000, 0x3824C000, 0x3824E000, 0x38250000, 0x38252000, 0x38254000, 0x38256000, 0x38258000, 0x3825A000, 0x3825C000, 0x3825E000,
  0x38260000, 0x38262000, 0x38264000, 0x38266000, 0x38268000, 0x3826A000, 0x3826C000, 0x3826E000, 0x38270000, 0x38272000, 0x38274000, 0x38276000, 0x38278000, 0x3827A000, 0x3827C000, 0x3827E000,
  0x38280000, 0x38282000, 0x38284000, 0x38286000, 0x38288000, 0x3828A000, 0x3828C000, 0x3828E000, 0x38290000, 0x38292000, 0x38294000, 0x38296000, 0x38298000, 0x3829A000, 0x3829C000, 0x3829E000,
  0x382A0000, 0x382A2000, 0x382A4000, 0x382A6000, 0x382A8000, 0x382AA000, 0x382AC000, 0x382AE000, 0x382B0000, 0x382B2000, 0x382B4000, 0x382B6000, 0x382B8000, 0x382BA000, 0x382BC000, 0x382BE000,
  0x382C0000, 0x382C2000, 0x382C4000, 0x382C6000, 0x382C8000, 0x382CA000, 0x382CC000, 0x382CE000, 0x382D0000, 0x382D2000, 0x382D4000, 0x382D6000, 0x382D8000, 0x382DA000, 0x382DC000, 0x382DE000,
  0x382E0000, 0x382E2000, 0x382E4000, 0x382E6000, 0x382E8000, 0x382EA000, 0x382EC000, 0x382EE000, 0x382F0000, 0x382F2000, 0x382F4000, 0x382F6000, 0x382F8000, 0x382FA000, 0x382FC000, 0x382FE000,
  0x38300000, 0x38302000, 0x38304000, 0x38306000, 0x38308000, 0x3830A000, 0x3830C000, 0x3830E000, 0x38310000, 0x38312000, 0x38314000, 0x38316000, 0x38318000, 0x3831A000, 0x3831C000, 0x3831E000,
  0x38320000, 0x38322000, 0x38324000, 0x38326000, 0x38328000, 0x3832A000, 0x3832C000, 0x3832E000, 0x38330000, 0x38332000, 0x38334000, 0x38336000, 0x38338000, 0x3833A000, 0x3833C000, 0x3833E000,
  0x38340000, 0x38342000, 0x38344000, 0x38346000, 0x38348000, 0x3834A000, 0x3834C000, 0x3834E000, 0x38350000, 0x38352000, 0x38354000, 0x38356000, 0x38358000, 0x3835A000, 0x3835C000, 0x3835E000,
  0x38360000, 0x38362000, 0x38364000, 0x38366000, 0x38368000, 0x3836A000, 0x3836C000, 0x3836E000, 0x38370000, 0x38372000, 0x38374000, 0x38376000, 0x38378000, 0x3837A000, 0x3837C000, 0x3837E000,
  0x38380000, 0x38382000, 0x38384000, 0x38386000, 0x38388000, 0x3838A000, 0x3838C000, 0x3838E000, 0x38390000, 0x38392000, 0x38394000, 0x38396000, 0x38398000, 0x3839A000, 0x3839C000, 0x3839E000,
  0x383A0000, 0x383A2000, 0x383A4000, 0x383A6000, 0x383A8000, 0x383AA000, 0x383AC000, 0x383AE000, 0x383B0000, 0x383B2000, 0x383B4000, 0x383B6000, 0x383B8000, 0x383BA000, 0x383BC000, 0x383BE000,
  0x383C0000, 0x383C2000, 0x383C4000, 0x383C6000, 0x383C8000, 0x383CA000, 0x383CC000, 0x383CE000, 0x383D0000, 0x383D2000, 0x383D4000, 0x383D6000, 0x383D8000, 0x383DA000, 0x383DC000, 0x383DE000,
  0x383E0000, 0x383E2000, 0x383E4000, 0x383E6000, 0x383E8000, 0x383EA000, 0x383EC000, 0x383EE000, 0x383F0000, 0x383F2000, 0x383F4000, 0x383F6000, 0x383F8000, 0x383FA000, 0x383FC000, 0x383FE000,
  0x38400000, 0x38402000, 0x38404000, 0x38406000, 0x38408000, 0x3840A000, 0x3840C000, 0x3840E000, 0x38410000, 0x38412000, 0x38414000, 0x38416000, 0x38418000, 0x3841A000, 0x3841C000, 0x3841E000,
  0x38420000, 0x38422000, 0x38424000, 0x38426000, 0x38428000, 0x3842A000, 0x3842C000, 0x3842E000, 0x38430000, 0x38432000, 0x38434000, 0x38436000, 0x38438000, 0x3843A000, 0x3843C000, 0x3843E000,
  0x38440000, 0x38442000, 0x38444000, 0x38446000, 0x38448000, 0x3844A000, 0x3844C000, 0x3844E000, 0x38450000, 0x38452000, 0x38454000, 0x38456000, 0x38458000, 0x3845A000, 0x3845C000, 0x3845E000,
  0x38460000, 0x38462000, 0x38464000, 0x38466000, 0x38468000, 0x3846A000, 0x3846C000, 0x3846E000, 0x38470000, 0x38472000, 0x38474000, 0x38476000, 0x38478000, 0x3847A000, 0x3847C000, 0x3847E000,
  0x38480000, 0x38482000, 0x38484000, 0x38486000, 0x38488000, 0x3848A000, 0x3848C000, 0x3848E000, 0x38490000, 0x38492000, 0x38494000, 0x38496000, 0x38498000, 0x3849A000, 0x3849C000, 0x3849E000,
  0x384A0000, 0x384A2000, 0x384A4000, 0x384A6000, 0x384A8000, 0x384AA000, 0x384AC000, 0x384AE000, 0x384B0000, 0x384B2000, 0x384B4000, 0x384B6000, 0x384B8000, 0x384BA000, 0x384BC000, 0x384BE000,
  0x384C0000, 0x384C2000, 0x384C4000, 0x384C6000, 0x384C8000, 0x384CA000, 0x384CC000, 0x384CE000, 0x384D0000, 0x384D2000, 0x384D4000, 0x384D6000, 0x384D8000, 0x384DA000, 0x384DC000, 0x384DE000,
  0x384E0000, 0x384E2000, 0x384E4000, 0x384E6000, 0x384E8000, 0x384EA000, 0x384EC000, 0x384EE000, 0x384F0000, 0x384F2000, 0x384F4000, 0x384F6000, 0x384F8000, 0x384FA000, 0x384FC000, 0x384FE000,
  0x38500000, 0x38502000, 0x38504000, 0x38506000, 0x38508000, 0x3850A000, 0x3850C000, 0x3850E000, 0x38510000, 0x38512000, 0x38514000, 0x38516000, 0x38518000, 0x3851A000, 0x3851C000, 0x3851E000,
  0x38520000, 0x38522000, 0x38524000, 0x38526000, 0x38528000, 0x3852A000, 0x3852C000, 0x3852E000, 0x38530000, 0x38532000, 0x38534000, 0x38536000, 0x38538000, 0x3853A000, 0x3853C000, 0x3853E000,
  0x38540000, 0x38542000, 0x38544000, 0x38546000, 0x38548000, 0x3854A000, 0x3854C000, 0x3854E000, 0x38550000, 0x38552000, 0x38554000, 0x38556000, 0x38558000, 0x3855A000, 0x3855C000, 0x3855E000,
  0x38560000, 0x38562000, 0x38564000, 0x38566000, 0x38568000, 0x3856A000, 0x3856C000, 0x3856E000, 0x38570000, 0x38572000, 0x38574000, 0x38576000, 0x38578000, 0x3857A000, 0x3857C000, 0x3857E000,
  0x38580000, 0x38582000, 0x38584000, 0x38586000, 0x38588000, 0x3858A000, 0x3858C000, 0x3858E000, 0x38590000, 0x38592000, 0x38594000, 0x38596000, 0x38598000, 0x3859A000, 0x3859C000, 0x3859E000,
  0x385A0000, 0x385A2000, 0x385A4000, 0x385A6000, 0x385A8000, 0x385AA000, 0x385AC000, 0x385AE000, 0x385B0000, 0x385B2000, 0x385B4000, 0x385B6000, 0x385B8000, 0x385BA000, 0x385BC000, 0x385BE000,
  0x385C0000, 0x385C2000, 0x385C4000, 0x385C6000, 0x385C8000, 0x385CA000, 0x385CC000, 0x385CE000, 0x385D0000, 0x385D2000, 0x385D4000, 0x385D6000, 0x385D8000, 0x385DA000, 0x385DC000, 0x385DE000,
  0x385E0000, 0x385E2000, 0x385E4000, 0x385E6000, 0x385E8000, 0x385EA000, 0x385EC000, 0x385EE000, 0x385F0000, 0x385F2000, 0x385F4000, 0x385F6000, 0x385F8000, 0x385FA000, 0x385FC000, 0x385FE000,
  0x38600000, 0x38602000, 0x38604000, 0x38606000, 0x38608000, 0x3860A000, 0x3860C000, 0x3860E000, 0x38610000, 0x38612000, 0x38614000, 0x38616000, 0x38618000, 0x3861A000, 0x3861C000, 0x3861E000,
  0x38620000, 0x38622000, 0x38624000, 0x38626000, 0x38628000, 0x3862A000, 0x3862C000, 0x3862E000, 0x38630000, 0x38632000, 0x38634000, 0x38636000, 0x38638000, 0x3863A000, 0x3863C000, 0x3863E000,
  0x38640000, 0x38642000, 0x38644000, 0x38646000, 0x38648000, 0x3864A000, 0x3864C000, 0x3864E000, 0x38650000, 0x38652000, 0x38654000, 0x38656000, 0x38658000, 0x3865A000, 0x3865C000, 0x3865E000,
  0x38660000, 0x38662000, 0x38664000, 0x38666000, 0x38668000, 0x3866A000, 0x3866C000, 0x3866E000, 0x38670000, 0x38672000, 0x38674000, 0x38676000, 0x38678000, 0x3867A000, 0x3867C000, 0x3867E000,
  0x38680000, 0x38682000, 0x38684000, 0x38686000, 0x38688000, 0x3868A000, 0x3868C000, 0x3868E000, 0x38690000, 0x38692000, 0x38694000, 0x38696000, 0x38698000, 0x3869A000, 0x3869C000, 0x3869E000,
  0x386A0000, 0x386A2000, 0x386A4000, 0x386A6000, 0x386A8000, 0x386AA000, 0x386AC000, 0x386AE000, 0x386B0000, 0x386B2000, 0x386B4000, 0x386B6000, 0x386B8000, 0x386BA000, 0x386BC000, 0x386BE000,
  0x386C0000, 0x386C2000, 0x386C4000, 0x386C6000, 0x386C8000, 0x386CA000, 0x386CC000, 0x386CE000, 0x386D0000, 0x386D2000, 0x386D4000, 0x386D6000, 0x386D8000, 0x386DA000, 0x386DC000, 0x386DE000,
  0x386E0000, 0x386E2000, 0x386E4000, 0x386E6000, 0x386E8000, 0x386EA000, 0x386EC000, 0x386EE000, 0x386F0000, 0x386F2000, 0x386F4000, 0x386F6000, 0x386F8000, 0x386FA000, 0x386FC000, 0x386FE000,
  0x38700000, 0x38702000, 0x38704000, 0x38706000, 0x38708000, 0x3870A000, 0x3870C000, 0x3870E000, 0x38710000, 0x38712000, 0x38714000, 0x38716000, 0x38718000, 0x3871A000, 0x3871C000, 0x3871E000,
  0x38720000, 0x38722000, 0x38724000, 0x38726000, 0x38728000, 0x3872A000, 0x3872C000, 0x3872E000, 0x38730000, 0x38732000, 0x38734000, 0x38736000, 0x38738000, 0x3873A000, 0x3873C000, 0x3873E000,
  0x38740000, 0x38742000, 0x38744000, 0x38746000, 0x38748000, 0x3874A000, 0x3874C000, 0x3874E000, 0x38750000, 0x38752000, 0x38754000, 0x38756000, 0x38758000, 0x3875A000, 0x3875C000, 0x3875E000,
  0x38760000, 0x38762000, 0x38764000, 0x38766000, 0x38768000, 0x3876A000, 0x3876C000, 0x3876E000, 0x38770000, 0x38772000, 0x38774000, 0x38776000, 0x38778000, 0x3877A000, 0x3877C000, 0x3877E000,
  0x38780000, 0x38782000, 0x38784000, 0x38786000, 0x38788000, 0x3878A000, 0x3878C000, 0x3878E000, 0x38790000, 0x38792000, 0x38794000, 0x38796000, 0x38798000, 0x3879A000, 0x3879C000, 0x3879E000,
  0x387A0000, 0x387A2000, 0x387A4000, 0x387A6000, 0x387A8000, 0x387AA000, 0x387AC000, 0x387AE000, 0x387B0000, 0x387B2000, 0x387B4000, 0x387B6000, 0x387B8000, 0x387BA000, 0x387BC000, 0x387BE000,
  0x387C0000, 0x387C2000, 0x387C4000, 0x387C6000, 0x387C8000, 0x387CA000, 0x387CC000, 0x387CE000, 0x387D0000, 0x387D2000, 0x387D4000, 0x387D6000, 0x387D8000, 0x387DA000, 0x387DC000, 0x387DE000,
  0x387E0000, 0x387E2000, 0x387E4000, 0x387E6000, 0x387E8000, 0x387EA000, 0x387EC000, 0x387EE000, 0x387F0000, 0x387F2000, 0x387F4000, 0x387F6000, 0x387F8000, 0x387FA000, 0x387FC000, 0x387FE000 };
__constant static const uint32_t exponent_table[64] = {
  0x00000000, 0x00800000, 0x01000000, 0x01800000, 0x02000000, 0x02800000, 0x03000000, 0x03800000, 0x04000000, 0x04800000, 0x05000000, 0x05800000, 0x06000000, 0x06800000, 0x07000000, 0x07800000,
  0x08000000, 0x08800000, 0x09000000, 0x09800000, 0x0A000000, 0x0A800000, 0x0B000000, 0x0B800000, 0x0C000000, 0x0C800000, 0x0D000000, 0x0D800000, 0x0E000000, 0x0E800000, 0x0F000000, 0x47800000,
  0x80000000, 0x80800000, 0x81000000, 0x81800000, 0x82000000, 0x82800000, 0x83000000, 0x83800000, 0x84000000, 0x84800000, 0x85000000, 0x85800000, 0x86000000, 0x86800000, 0x87000000, 0x87800000,
  0x88000000, 0x88800000, 0x89000000, 0x89800000, 0x8A000000, 0x8A800000, 0x8B000000, 0x8B800000, 0x8C000000, 0x8C800000, 0x8D000000, 0x8D800000, 0x8E000000, 0x8E800000, 0x8F000000, 0xC7800000 };
__constant static const unsigned short offset_table[64] = {
  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024,
  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024 };

SCALAR_FUN_ATTR uint16_t float2halfbits(float value) {
  union { float x; uint32_t y; } u;
  u.x = value;
  uint32_t bits = u.y;

  uint16_t hbits = base_table[bits>>23] + (uint16_t)((bits&0x7FFFFF)>>shift_table[bits>>23]);;

  return hbits;
}

SCALAR_FUN_ATTR float halfbits2float(uint16_t value) {
  uint32_t bits = mantissa_table[offset_table[value>>10]+(value&0x3FF)] + exponent_table[value>>10];

  union { uint32_t x; float y; } u;
  u.x = bits;
  return u.y;
}

SCALAR_FUN_ATTR uint16_t halfbitsnextafter(uint16_t from, uint16_t to) {
  int fabs = from & 0x7FFF, tabs = to & 0x7FFF;
  if(fabs > 0x7C00 || tabs > 0x7C00) {
    return ((from&0x7FFF)>0x7C00) ? (from|0x200) : (to|0x200);
  }
  if(from == to || !(fabs|tabs)) {
    return to;
  }
  if(!fabs) {
    return (to&0x8000)+1;
  }
  unsigned int out =
    from +
    (((from>>15)^(unsigned int)((from^(0x8000|(0x8000-(from>>15))))<(to^(0x8000|(0x8000-(to>>15))))))<<1)
    - 1;
  return out;
}

// End of half.h.
// Start of timing.h.

// The function get_wall_time() returns the wall time in microseconds
// (with an unspecified offset).

#ifdef _WIN32

#include <windows.h>

static int64_t get_wall_time(void) {
  LARGE_INTEGER time,freq;
  assert(QueryPerformanceFrequency(&freq));
  assert(QueryPerformanceCounter(&time));
  return ((double)time.QuadPart / freq.QuadPart) * 1000000;
}

static int64_t get_wall_time_ns(void) {
  return get_wall_time() * 1000;
}

#else
// Assuming POSIX

#include <time.h>
#include <sys/time.h>

static int64_t get_wall_time(void) {
  struct timeval time;
  assert(gettimeofday(&time,NULL) == 0);
  return time.tv_sec * 1000000 + time.tv_usec;
}

static int64_t get_wall_time_ns(void) {
  struct timespec time;
  assert(clock_gettime(CLOCK_REALTIME, &time) == 0);
  return time.tv_sec * 1000000000 + time.tv_nsec;
}

#endif

// End of timing.h.
// Start of lock.h.

// A very simple cross-platform implementation of locks.  Uses
// pthreads on Unix and some Windows thing there.  Futhark's
// host-level code is not multithreaded, but user code may be, so we
// need some mechanism for ensuring atomic access to API functions.
// This is that mechanism.  It is not exposed to user code at all, so
// we do not have to worry about name collisions.

#ifdef _WIN32

typedef HANDLE lock_t;

static void create_lock(lock_t *lock) {
  *lock = CreateMutex(NULL,  // Default security attributes.
                      FALSE, // Initially unlocked.
                      NULL); // Unnamed.
}

static void lock_lock(lock_t *lock) {
  assert(WaitForSingleObject(*lock, INFINITE) == WAIT_OBJECT_0);
}

static void lock_unlock(lock_t *lock) {
  assert(ReleaseMutex(*lock));
}

static void free_lock(lock_t *lock) {
  CloseHandle(*lock);
}

#else
// Assuming POSIX

#include <pthread.h>

typedef pthread_mutex_t lock_t;

static void create_lock(lock_t *lock) {
  int r = pthread_mutex_init(lock, NULL);
  assert(r == 0);
}

static void lock_lock(lock_t *lock) {
  int r = pthread_mutex_lock(lock);
  assert(r == 0);
}

static void lock_unlock(lock_t *lock) {
  int r = pthread_mutex_unlock(lock);
  assert(r == 0);
}

static void free_lock(lock_t *lock) {
  // Nothing to do for pthreads.
  (void)lock;
}

#endif

// End of lock.h.
// Start of free_list.h.

typedef uintptr_t fl_mem;

// An entry in the free list.  May be invalid, to avoid having to
// deallocate entries as soon as they are removed.  There is also a
// tag, to help with memory reuse.
struct free_list_entry {
  size_t size;
  fl_mem mem;
  const char *tag;
  unsigned char valid;
};

struct free_list {
  struct free_list_entry *entries; // Pointer to entries.
  int capacity;                    // Number of entries.
  int used;                        // Number of valid entries.
  lock_t lock;                     // Thread safety.
};

static void free_list_init(struct free_list *l) {
  l->capacity = 30; // Picked arbitrarily.
  l->used = 0;
  l->entries = (struct free_list_entry*) malloc(sizeof(struct free_list_entry) * l->capacity);
  for (int i = 0; i < l->capacity; i++) {
    l->entries[i].valid = 0;
  }
  create_lock(&l->lock);
}

// Remove invalid entries from the free list.
static void free_list_pack(struct free_list *l) {
  lock_lock(&l->lock);
  int p = 0;
  for (int i = 0; i < l->capacity; i++) {
    if (l->entries[i].valid) {
      l->entries[p] = l->entries[i];
      if (i > p) {
        l->entries[i].valid = 0;
      }
      p++;
    }
  }

  // Now p is the number of used elements.  We don't want it to go
  // less than the default capacity (although in practice it's OK as
  // long as it doesn't become 1).
  if (p < 30) {
    p = 30;
  }
  l->entries = realloc(l->entries, p * sizeof(struct free_list_entry));
  l->capacity = p;
  lock_unlock(&l->lock);
}

static void free_list_destroy(struct free_list *l) {
  assert(l->used == 0);
  free(l->entries);
  free_lock(&l->lock);
}

// Not part of the interface, so no locking.
static int free_list_find_invalid(struct free_list *l) {
  int i;
  for (i = 0; i < l->capacity; i++) {
    if (!l->entries[i].valid) {
      break;
    }
  }
  return i;
}

static void free_list_insert(struct free_list *l, size_t size, fl_mem mem, const char *tag) {
  lock_lock(&l->lock);
  int i = free_list_find_invalid(l);

  if (i == l->capacity) {
    // List is full; so we have to grow it.
    int new_capacity = l->capacity * 2 * sizeof(struct free_list_entry);
    l->entries = realloc(l->entries, new_capacity);
    for (int j = 0; j < l->capacity; j++) {
      l->entries[j+l->capacity].valid = 0;
    }
    l->capacity *= 2;
  }

  // Now 'i' points to the first invalid entry.
  l->entries[i].valid = 1;
  l->entries[i].size = size;
  l->entries[i].mem = mem;
  l->entries[i].tag = tag;

  l->used++;
  lock_unlock(&l->lock);
}

// Determine whether this entry in the free list is acceptable for
// satisfying the request.  Not public, so no locking.
static bool free_list_acceptable(size_t size, const char* tag, struct free_list_entry *entry) {
  // We check not just the hard requirement (is the entry acceptable
  // and big enough?) but also put a cap on how much wasted space
  // (internal fragmentation) we allow.  This is necessarily a
  // heuristic, and a crude one.

  if (!entry->valid) {
    return false;
  }

  if (size > entry->size) {
    return false;
  }

  // We know the block fits.  Now the question is whether it is too
  // big.  Our policy is as follows:
  //
  // 1) We don't care about wasted space below 4096 bytes (to avoid
  // churn in tiny allocations).
  //
  // 2) If the tag matches, we allow _any_ amount of wasted space.
  //
  // 3) Otherwise we allow up to 50% wasted space.

  if (entry->size < 4096) {
    return true;
  }

  if (entry->tag == tag) {
    return true;
  }

  if (entry->size < size * 2) {
    return true;
  }

  return false;
}

// Find and remove a memory block of the indicated tag, or if that
// does not exist, another memory block with exactly the desired size.
// Returns 0 on success.
static int free_list_find(struct free_list *l, size_t size, const char *tag,
                          size_t *size_out, fl_mem *mem_out) {
  lock_lock(&l->lock);
  int size_match = -1;
  int i;
  int ret = 1;
  for (i = 0; i < l->capacity; i++) {
    if (free_list_acceptable(size, tag, &l->entries[i]) &&
        (size_match < 0 || l->entries[i].size < l->entries[size_match].size)) {
      // If this entry is valid, has sufficient size, and is smaller than the
      // best entry found so far, use this entry.
      size_match = i;
    }
  }

  if (size_match >= 0) {
    l->entries[size_match].valid = 0;
    *size_out = l->entries[size_match].size;
    *mem_out = l->entries[size_match].mem;
    l->used--;
    ret = 0;
  }
  lock_unlock(&l->lock);
  return ret;
}

// Remove the first block in the free list.  Returns 0 if a block was
// removed, and nonzero if the free list was already empty.
static int free_list_first(struct free_list *l, fl_mem *mem_out) {
  lock_lock(&l->lock);
  int ret = 1;
  for (int i = 0; i < l->capacity; i++) {
    if (l->entries[i].valid) {
      l->entries[i].valid = 0;
      *mem_out = l->entries[i].mem;
      l->used--;
      ret = 0;
      break;
    }
  }
  lock_unlock(&l->lock);
  return ret;
}

// End of free_list.h.
// Start of event_list.h

typedef int (*event_report_fn)(struct str_builder*, void*);

struct event {
  void* data;
  event_report_fn f;
  const char* name;
  char *description;
};

struct event_list {
  struct event *events;
  int num_events;
  int capacity;
};

static void event_list_init(struct event_list *l) {
  l->capacity = 100;
  l->num_events = 0;
  l->events = calloc(l->capacity, sizeof(struct event));
}

static void event_list_free(struct event_list *l) {
  free(l->events);
}

static void add_event_to_list(struct event_list *l,
                              const char* name,
                              char* description,
                              void* data,
                              event_report_fn f) {
  if (l->num_events == l->capacity) {
    l->capacity *= 2;
    l->events = realloc(l->events, l->capacity * sizeof(struct event));
  }
  l->events[l->num_events].name = name;
  l->events[l->num_events].description = description;
  l->events[l->num_events].data = data;
  l->events[l->num_events].f = f;
  l->num_events++;
}

static int report_events_in_list(struct event_list *l,
                                 struct str_builder* sb) {
  int ret = 0;
  for (int i = 0; i < l->num_events; i++) {
    if (i != 0) {
      str_builder_str(sb, ",");
    }
    str_builder_str(sb, "{\"name\":");
    str_builder_json_str(sb, l->events[i].name);
    str_builder_str(sb, ",\"description\":");
    str_builder_json_str(sb, l->events[i].description);
    free(l->events[i].description);
    if (l->events[i].f(sb, l->events[i].data) != 0) {
      ret = 1;
      break;
    }
    str_builder(sb, "}");
  }
  event_list_free(l);
  event_list_init(l);
  return ret;
}

// End of event_list.h

#ifdef _MSC_VER
#define inline __inline
#endif
#include <string.h>
#include <string.h>
#include <errno.h>
#include <assert.h>
#include <ctype.h>


#include <cuda.h>
#include <cuda_runtime.h>
#include <nvrtc.h>


#define FUTHARK_F64_ENABLED

// Start of scalar.h.

// Implementation of the primitive scalar operations.  Very
// repetitive.  This code is inserted directly into both CUDA and
// OpenCL programs, as well as the CPU code, so it has some #ifdefs to
// work everywhere.  Some operations are defined as macros because
// this allows us to use them as constant expressions in things like
// array sizes and static initialisers.

// Some of the #ifdefs are because OpenCL uses type-generic functions
// for some operations (e.g. sqrt), while C and CUDA sensibly use
// distinct functions for different precisions (e.g. sqrtf() and
// sqrt()).  This is quite annoying.  Due to C's unfortunate casting
// rules, it is also really easy to accidentally implement
// floating-point functions in the wrong precision, so be careful.

// Double-precision definitions are only included if the preprocessor
// macro FUTHARK_F64_ENABLED is set.

SCALAR_FUN_ATTR int32_t futrts_to_bits32(float x);
SCALAR_FUN_ATTR float futrts_from_bits32(int32_t x);

SCALAR_FUN_ATTR uint8_t add8(uint8_t x, uint8_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint16_t add16(uint16_t x, uint16_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint32_t add32(uint32_t x, uint32_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint64_t add64(uint64_t x, uint64_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint8_t sub8(uint8_t x, uint8_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint16_t sub16(uint16_t x, uint16_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint32_t sub32(uint32_t x, uint32_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint64_t sub64(uint64_t x, uint64_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint8_t mul8(uint8_t x, uint8_t y) {
  return x * y;
}

SCALAR_FUN_ATTR uint16_t mul16(uint16_t x, uint16_t y) {
  return x * y;
}

SCALAR_FUN_ATTR uint32_t mul32(uint32_t x, uint32_t y) {
  return x * y;
}

SCALAR_FUN_ATTR uint64_t mul64(uint64_t x, uint64_t y) {
  return x * y;
}

#if ISPC

SCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {
  // This strange pattern is used to prevent the ISPC compiler from
  // causing SIGFPEs and bogus results on divisions where inactive lanes
  // have 0-valued divisors. It ensures that any inactive lane instead
  // has a divisor of 1. https://github.com/ispc/ispc/issues/2292
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return x / ys;
}

SCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return x / ys;
}

SCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return x % ys;
}

SCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int8_t q = x / ys;
  int8_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int16_t q = x / ys;
  int16_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  int32_t q = x / ys;
  int32_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int64_t q = x / ys;
  int64_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {
  return sdiv8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {
  return sdiv16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {
  return sdiv32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {
  return sdiv64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int8_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int16_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int32_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int64_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : sdiv8(x, y);
}

SCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : sdiv16(x, y);
}

SCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : sdiv32(x, y);
}

SCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : sdiv64(x, y);
}

SCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {
  return sdiv_safe8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {
  return sdiv_safe16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {
  return sdiv_safe32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {
  return sdiv_safe64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : smod8(x, y);
}

SCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : smod16(x, y);
}

SCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : smod32(x, y);
}

SCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : smod64(x, y);
}

SCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

#else

SCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {
  int8_t q = x / y;
  int8_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {
  int16_t q = x / y;
  int16_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {
  int32_t q = x / y;
  int32_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {
  int64_t q = x / y;
  int64_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {
  return sdiv8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {
  return sdiv16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {
  return sdiv32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {
  return sdiv64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {
  int8_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {
  int16_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {
  int32_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {
  int64_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : sdiv8(x, y);
}

SCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : sdiv16(x, y);
}

SCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : sdiv32(x, y);
}

SCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : sdiv64(x, y);
}

SCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {
  return sdiv_safe8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {
  return sdiv_safe16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {
  return sdiv_safe32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {
  return sdiv_safe64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : smod8(x, y);
}

SCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : smod16(x, y);
}

SCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : smod32(x, y);
}

SCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : smod64(x, y);
}

SCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : x % y;
}

#endif

SCALAR_FUN_ATTR int8_t smin8(int8_t x, int8_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int16_t smin16(int16_t x, int16_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int32_t smin32(int32_t x, int32_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int64_t smin64(int64_t x, int64_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint8_t umin8(uint8_t x, uint8_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint16_t umin16(uint16_t x, uint16_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint32_t umin32(uint32_t x, uint32_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint64_t umin64(uint64_t x, uint64_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int8_t smax8(int8_t x, int8_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR int16_t smax16(int16_t x, int16_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR int32_t smax32(int32_t x, int32_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR int64_t smax64(int64_t x, int64_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint8_t umax8(uint8_t x, uint8_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint16_t umax16(uint16_t x, uint16_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint32_t umax32(uint32_t x, uint32_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint64_t umax64(uint64_t x, uint64_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint8_t shl8(uint8_t x, uint8_t y) {
  return (uint8_t)(x << y);
}

SCALAR_FUN_ATTR uint16_t shl16(uint16_t x, uint16_t y) {
  return (uint16_t)(x << y);
}

SCALAR_FUN_ATTR uint32_t shl32(uint32_t x, uint32_t y) {
  return x << y;
}

SCALAR_FUN_ATTR uint64_t shl64(uint64_t x, uint64_t y) {
  return x << y;
}

SCALAR_FUN_ATTR uint8_t lshr8(uint8_t x, uint8_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint16_t lshr16(uint16_t x, uint16_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint32_t lshr32(uint32_t x, uint32_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint64_t lshr64(uint64_t x, uint64_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int8_t ashr8(int8_t x, int8_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int16_t ashr16(int16_t x, int16_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int32_t ashr32(int32_t x, int32_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int64_t ashr64(int64_t x, int64_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint8_t and8(uint8_t x, uint8_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint16_t and16(uint16_t x, uint16_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint32_t and32(uint32_t x, uint32_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint64_t and64(uint64_t x, uint64_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint8_t or8(uint8_t x, uint8_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint16_t or16(uint16_t x, uint16_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint32_t or32(uint32_t x, uint32_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint64_t or64(uint64_t x, uint64_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint8_t xor8(uint8_t x, uint8_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR uint16_t xor16(uint16_t x, uint16_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR uint32_t xor32(uint32_t x, uint32_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR uint64_t xor64(uint64_t x, uint64_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR bool ult8(uint8_t x, uint8_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ult16(uint16_t x, uint16_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ult32(uint32_t x, uint32_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ult64(uint64_t x, uint64_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ule8(uint8_t x, uint8_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool ule16(uint16_t x, uint16_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool ule32(uint32_t x, uint32_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool ule64(uint64_t x, uint64_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool slt8(int8_t x, int8_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool slt16(int16_t x, int16_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool slt32(int32_t x, int32_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool slt64(int64_t x, int64_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool sle8(int8_t x, int8_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool sle16(int16_t x, int16_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool sle32(int32_t x, int32_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool sle64(int64_t x, int64_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR uint8_t pow8(uint8_t x, uint8_t y) {
  uint8_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint16_t pow16(uint16_t x, uint16_t y) {
  uint16_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint32_t pow32(uint32_t x, uint32_t y) {
  uint32_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint64_t pow64(uint64_t x, uint64_t y) {
  uint64_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR bool itob_i8_bool(int8_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR bool itob_i16_bool(int16_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR bool itob_i32_bool(int32_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR bool itob_i64_bool(int64_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR int8_t btoi_bool_i8(bool x) {
  return x;
}

SCALAR_FUN_ATTR int16_t btoi_bool_i16(bool x) {
  return x;
}

SCALAR_FUN_ATTR int32_t btoi_bool_i32(bool x) {
  return x;
}

SCALAR_FUN_ATTR int64_t btoi_bool_i64(bool x) {
  return x;
}

#define sext_i8_i8(x) ((int8_t) (int8_t) (x))
#define sext_i8_i16(x) ((int16_t) (int8_t) (x))
#define sext_i8_i32(x) ((int32_t) (int8_t) (x))
#define sext_i8_i64(x) ((int64_t) (int8_t) (x))
#define sext_i16_i8(x) ((int8_t) (int16_t) (x))
#define sext_i16_i16(x) ((int16_t) (int16_t) (x))
#define sext_i16_i32(x) ((int32_t) (int16_t) (x))
#define sext_i16_i64(x) ((int64_t) (int16_t) (x))
#define sext_i32_i8(x) ((int8_t) (int32_t) (x))
#define sext_i32_i16(x) ((int16_t) (int32_t) (x))
#define sext_i32_i32(x) ((int32_t) (int32_t) (x))
#define sext_i32_i64(x) ((int64_t) (int32_t) (x))
#define sext_i64_i8(x) ((int8_t) (int64_t) (x))
#define sext_i64_i16(x) ((int16_t) (int64_t) (x))
#define sext_i64_i32(x) ((int32_t) (int64_t) (x))
#define sext_i64_i64(x) ((int64_t) (int64_t) (x))
#define zext_i8_i8(x) ((int8_t) (uint8_t) (x))
#define zext_i8_i16(x) ((int16_t) (uint8_t) (x))
#define zext_i8_i32(x) ((int32_t) (uint8_t) (x))
#define zext_i8_i64(x) ((int64_t) (uint8_t) (x))
#define zext_i16_i8(x) ((int8_t) (uint16_t) (x))
#define zext_i16_i16(x) ((int16_t) (uint16_t) (x))
#define zext_i16_i32(x) ((int32_t) (uint16_t) (x))
#define zext_i16_i64(x) ((int64_t) (uint16_t) (x))
#define zext_i32_i8(x) ((int8_t) (uint32_t) (x))
#define zext_i32_i16(x) ((int16_t) (uint32_t) (x))
#define zext_i32_i32(x) ((int32_t) (uint32_t) (x))
#define zext_i32_i64(x) ((int64_t) (uint32_t) (x))
#define zext_i64_i8(x) ((int8_t) (uint64_t) (x))
#define zext_i64_i16(x) ((int16_t) (uint64_t) (x))
#define zext_i64_i32(x) ((int32_t) (uint64_t) (x))
#define zext_i64_i64(x) ((int64_t) (uint64_t) (x))

SCALAR_FUN_ATTR int8_t abs8(int8_t x) {
  return (int8_t)abs(x);
}

SCALAR_FUN_ATTR int16_t abs16(int16_t x) {
  return (int16_t)abs(x);
}

SCALAR_FUN_ATTR int32_t abs32(int32_t x) {
  return abs(x);
}

SCALAR_FUN_ATTR int64_t abs64(int64_t x) {
#if defined(__OPENCL_VERSION__) || defined(ISPC)
  return abs(x);
#else
  return llabs(x);
#endif
}

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {
  return popcount(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {
  return popcount(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {
  return popcount(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {
  return popcount(x);
}
#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {
  return __popc(zext_i8_i32(x));
}

SCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {
  return __popc(zext_i16_i32(x));
}

SCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {
  return __popc(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {
  return __popcll(x);
}

#else // Not OpenCL or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_popc8(uint8_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc16(uint16_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc32(uint32_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc64(uint64_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR uint8_t  futrts_umul_hi8 ( uint8_t a,  uint8_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint8_t  futrts_smul_hi8 ( int8_t a,  int8_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return mul_hi(a, b); }
#elif defined(__CUDA_ARCH__)
SCALAR_FUN_ATTR  uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return __umulhi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return __umul64hi(a, b); }
SCALAR_FUN_ATTR  uint8_t futrts_smul_hi8 ( int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return __mulhi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return __mul64hi(a, b); }
#elif ISPC
SCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) {
  uint64_t ah = a >> 32;
  uint64_t al = a & 0xffffffff;
  uint64_t bh = b >> 32;
  uint64_t bl = b & 0xffffffff;

  uint64_t p1 = al * bl;
  uint64_t p2 = al * bh;
  uint64_t p3 = ah * bl;
  uint64_t p4 = ah * bh;

  uint64_t p1h = p1 >> 32;
  uint64_t p2h = p2 >> 32;
  uint64_t p3h = p3 >> 32;
  uint64_t p2l = p2 & 0xffffffff;
  uint64_t p3l = p3 & 0xffffffff;

  uint64_t l = p1h + p2l + p3l;
  uint64_t m = (p2 >> 32) + (p3 >> 32);
  uint64_t h = (l >> 32) + m + p4;

  return h;
}
SCALAR_FUN_ATTR  int8_t futrts_smul_hi8 ( int8_t a,  int8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) {
  uint64_t ah = a >> 32;
  uint64_t al = a & 0xffffffff;
  uint64_t bh = b >> 32;
  uint64_t bl = b & 0xffffffff;

  uint64_t p1 =  al * bl;
  int64_t  p2 = al * bh;
  int64_t  p3 = ah * bl;
  uint64_t p4 =  ah * bh;

  uint64_t p1h = p1 >> 32;
  uint64_t p2h = p2 >> 32;
  uint64_t p3h = p3 >> 32;
  uint64_t p2l = p2 & 0xffffffff;
  uint64_t p3l = p3 & 0xffffffff;

  uint64_t l = p1h + p2l + p3l;
  uint64_t m = (p2 >> 32) + (p3 >> 32);
  uint64_t h = (l >> 32) + m + p4;

  return h;
}

#else // Not OpenCL, ISPC, or CUDA, but plain C.
SCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return ((__uint128_t)a) * ((__uint128_t)b) >> 64; }
SCALAR_FUN_ATTR int8_t futrts_smul_hi8(int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }
SCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }
SCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((int64_t)a) * ((int64_t)b) >> 32; }
SCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) { return ((__int128_t)a) * ((__int128_t)b) >> 64; }
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR  uint8_t futrts_umad_hi8 ( uint8_t a,  uint8_t b,  uint8_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR  uint8_t futrts_smad_hi8( int8_t a,  int8_t b,   int8_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return mad_hi(a, b, c); }
#else // Not OpenCL

SCALAR_FUN_ATTR  uint8_t futrts_umad_hi8( uint8_t a,  uint8_t b,  uint8_t c) { return futrts_umul_hi8(a, b) + c; }
SCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return futrts_umul_hi16(a, b) + c; }
SCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return futrts_umul_hi32(a, b) + c; }
SCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return futrts_umul_hi64(a, b) + c; }
SCALAR_FUN_ATTR  uint8_t futrts_smad_hi8 ( int8_t a,  int8_t b,  int8_t c) { return futrts_smul_hi8(a, b) + c; }
SCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return futrts_smul_hi16(a, b) + c; }
SCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return futrts_smul_hi32(a, b) + c; }
SCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return futrts_smul_hi64(a, b) + c; }
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return clz(x);
}

#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return __clz(zext_i8_i32(x)) - 24;
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return __clz(zext_i16_i32(x)) - 16;
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return __clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return __clzll(x);
}

#elif ISPC

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return count_leading_zeros((int32_t)(uint8_t)x)-24;
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return count_leading_zeros((int32_t)(uint16_t)x)-16;
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return count_leading_zeros(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return count_leading_zeros(x);
}

#else // Not OpenCL, ISPC or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return x == 0 ? 8 : __builtin_clz((uint32_t)zext_i8_i32(x)) - 24;
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return x == 0 ? 16 : __builtin_clz((uint32_t)zext_i16_i32(x)) - 16;
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return x == 0 ? 32 : __builtin_clz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return x == 0 ? 64 : __builtin_clzll((uint64_t)x);
}
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  int i = 0;
  for (; i < 8 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  int i = 0;
  for (; i < 16 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  int i = 0;
  for (; i < 32 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  int i = 0;
  for (; i < 64 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  int y = __ffs(x);
  return y == 0 ? 8 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  int y = __ffs(x);
  return y == 0 ? 16 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  int y = __ffs(x);
  return y == 0 ? 32 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  int y = __ffsll(x);
  return y == 0 ? 64 : y - 1;
}

#elif ISPC

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  return x == 0 ? 8 : count_trailing_zeros((int32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  return x == 0 ? 16 : count_trailing_zeros((int32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  return count_trailing_zeros(x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  return count_trailing_zeros(x);
}

#else // Not OpenCL or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  return x == 0 ? 8 : __builtin_ctz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  return x == 0 ? 16 : __builtin_ctz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  return x == 0 ? 32 : __builtin_ctz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  return x == 0 ? 64 : __builtin_ctzll((uint64_t)x);
}
#endif

SCALAR_FUN_ATTR float fdiv32(float x, float y) {
  return x / y;
}

SCALAR_FUN_ATTR float fadd32(float x, float y) {
  return x + y;
}

SCALAR_FUN_ATTR float fsub32(float x, float y) {
  return x - y;
}

SCALAR_FUN_ATTR float fmul32(float x, float y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt32(float x, float y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple32(float x, float y) {
  return x <= y;
}

SCALAR_FUN_ATTR float sitofp_i8_f32(int8_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float sitofp_i16_f32(int16_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float sitofp_i32_f32(int32_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float sitofp_i64_f32(int64_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i8_f32(uint8_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i16_f32(uint16_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i32_f32(uint32_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i64_f32(uint64_t x) {
  return (float) x;
}

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR float fabs32(float x) {
  return fabs(x);
}

SCALAR_FUN_ATTR float fmax32(float x, float y) {
  return fmax(x, y);
}

SCALAR_FUN_ATTR float fmin32(float x, float y) {
  return fmin(x, y);
}

SCALAR_FUN_ATTR float fpow32(float x, float y) {
  return pow(x, y);
}

#elif ISPC

SCALAR_FUN_ATTR float fabs32(float x) {
  return abs(x);
}

SCALAR_FUN_ATTR float fmax32(float x, float y) {
  return isnan(x) ? y : isnan(y) ? x : max(x, y);
}

SCALAR_FUN_ATTR float fmin32(float x, float y) {
  return isnan(x) ? y : isnan(y) ? x : min(x, y);
}

SCALAR_FUN_ATTR float fpow32(float a, float b) {
  float ret;
  foreach_active (i) {
      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));
      ret = insert(ret, i, r);
  }
  return ret;
}

#else // Not OpenCL, but CUDA or plain C.

SCALAR_FUN_ATTR float fabs32(float x) {
  return fabsf(x);
}

SCALAR_FUN_ATTR float fmax32(float x, float y) {
  return fmaxf(x, y);
}

SCALAR_FUN_ATTR float fmin32(float x, float y) {
  return fminf(x, y);
}

SCALAR_FUN_ATTR float fpow32(float x, float y) {
  return powf(x, y);
}
#endif

SCALAR_FUN_ATTR bool futrts_isnan32(float x) {
  return isnan(x);
}

#if ISPC

SCALAR_FUN_ATTR bool futrts_isinf32(float x) {
  return !isnan(x) && isnan(x - x);
}

SCALAR_FUN_ATTR bool futrts_isfinite32(float x) {
  return !isnan(x) && !futrts_isinf32(x);
}

#else

SCALAR_FUN_ATTR bool futrts_isinf32(float x) {
  return isinf(x);
}

#endif

SCALAR_FUN_ATTR int8_t fptosi_f32_i8(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f32_i16(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f32_i32(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f32_i64(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int64_t) x;
  };
}

SCALAR_FUN_ATTR uint8_t fptoui_f32_i8(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f32_i16(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f32_i32(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f32_i64(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f32_bool(float x) {
  return x != 0;
}

SCALAR_FUN_ATTR float btof_bool_f32(bool x) {
  return x ? 1 : 0;
}

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR float futrts_log32(float x) {
  return log(x);
}

SCALAR_FUN_ATTR float futrts_log2_32(float x) {
  return log2(x);
}

SCALAR_FUN_ATTR float futrts_log10_32(float x) {
  return log10(x);
}

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  return log1p(x);
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) {
  return sqrt(x);
}

SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  return cbrt(x);
}

SCALAR_FUN_ATTR float futrts_exp32(float x) {
  return exp(x);
}

SCALAR_FUN_ATTR float futrts_cos32(float x) {
  return cos(x);
}

SCALAR_FUN_ATTR float futrts_sin32(float x) {
  return sin(x);
}

SCALAR_FUN_ATTR float futrts_tan32(float x) {
  return tan(x);
}

SCALAR_FUN_ATTR float futrts_acos32(float x) {
  return acos(x);
}

SCALAR_FUN_ATTR float futrts_asin32(float x) {
  return asin(x);
}

SCALAR_FUN_ATTR float futrts_atan32(float x) {
  return atan(x);
}

SCALAR_FUN_ATTR float futrts_cosh32(float x) {
  return cosh(x);
}

SCALAR_FUN_ATTR float futrts_sinh32(float x) {
  return sinh(x);
}

SCALAR_FUN_ATTR float futrts_tanh32(float x) {
  return tanh(x);
}

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  return acosh(x);
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  return asinh(x);
}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  return atanh(x);
}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {
  return atan2(x, y);
}

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  return hypot(x, y);
}

SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  return tgamma(x);
}

SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  return lgamma(x);
}

SCALAR_FUN_ATTR float futrts_erf32(float x) {
  return erf(x);
}

SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  return erfc(x);
}

SCALAR_FUN_ATTR float fmod32(float x, float y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR float futrts_round32(float x) {
  return rint(x);
}

SCALAR_FUN_ATTR float futrts_floor32(float x) {
  return floor(x);
}

SCALAR_FUN_ATTR float futrts_ceil32(float x) {
  return ceil(x);
}

SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  return nextafter(x, y);
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return mix(v0, v1, t);
}

SCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {
  return ldexp(x, y);
}

SCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {
  return copysign(x, y);
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return mad(a, b, c);
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return fma(a, b, c);
}

#elif ISPC

SCALAR_FUN_ATTR float futrts_log32(float x) {
  return futrts_isfinite32(x) || (futrts_isinf32(x) && x < 0)? log(x) : x;
}

SCALAR_FUN_ATTR float futrts_log2_32(float x) {
  return futrts_log32(x) / log(2.0f);
}

SCALAR_FUN_ATTR float futrts_log10_32(float x) {
  return futrts_log32(x) / log(10.0f);
}

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  if(x == -1.0f || (futrts_isinf32(x) && x > 0.0f)) return x / 0.0f;
  float y = 1.0f + x;
  float z = y - 1.0f;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) {
  return sqrt(x);
}

extern "C" unmasked uniform float cbrtf(uniform float);
SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = cbrtf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float futrts_exp32(float x) {
  return exp(x);
}

SCALAR_FUN_ATTR float futrts_cos32(float x) {
  return cos(x);
}

SCALAR_FUN_ATTR float futrts_sin32(float x) {
  return sin(x);
}

SCALAR_FUN_ATTR float futrts_tan32(float x) {
  return tan(x);
}

SCALAR_FUN_ATTR float futrts_acos32(float x) {
  return acos(x);
}

SCALAR_FUN_ATTR float futrts_asin32(float x) {
  return asin(x);
}

SCALAR_FUN_ATTR float futrts_atan32(float x) {
  return atan(x);
}

SCALAR_FUN_ATTR float futrts_cosh32(float x) {
  return (exp(x)+exp(-x)) / 2.0f;
}

SCALAR_FUN_ATTR float futrts_sinh32(float x) {
  return (exp(x)-exp(-x)) / 2.0f;
}

SCALAR_FUN_ATTR float futrts_tanh32(float x) {
  return futrts_sinh32(x)/futrts_cosh32(x);
}

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  float f = x+sqrt(x*x-1);
  if(futrts_isfinite32(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  float f = x+sqrt(x*x+1);
  if(futrts_isfinite32(f)) return log(f);
  return f;

}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  float f = (1+x)/(1-x);
  if(futrts_isfinite32(f)) return log(f)/2.0f;
  return f;

}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {
  return (x == 0.0f && y == 0.0f) ? 0.0f : atan2(x, y);
}

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  if (futrts_isfinite32(x) && futrts_isfinite32(y)) {
    x = abs(x);
    y = abs(y);
    float a;
    float b;
    if (x >= y){
        a = x;
        b = y;
    } else {
        a = y;
        b = x;
    }
    if(b == 0){
      return a;
    }

    int e;
    float an;
    float bn;
    an = frexp (a, &e);
    bn = ldexp (b, - e);
    float cn;
    cn = sqrt (an * an + bn * bn);
    return ldexp (cn, e);
  } else {
    if (futrts_isinf32(x) || futrts_isinf32(y)) return INFINITY;
    else return x + y;
  }

}

extern "C" unmasked uniform float tgammaf(uniform float x);
SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = tgammaf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float lgammaf(uniform float x);
SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = lgammaf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float erff(uniform float x);
SCALAR_FUN_ATTR float futrts_erf32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = erff(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float erfcf(uniform float x);
SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = erfcf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float fmod32(float x, float y) {
  return x - y * trunc(x/y);
}

SCALAR_FUN_ATTR float futrts_round32(float x) {
  return round(x);
}

SCALAR_FUN_ATTR float futrts_floor32(float x) {
  return floor(x);
}

SCALAR_FUN_ATTR float futrts_ceil32(float x) {
  return ceil(x);
}

extern "C" unmasked uniform float nextafterf(uniform float x, uniform float y);
SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  float res;
  foreach_active (i) {
    uniform float r = nextafterf(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {
  return x * pow((double)2.0, (double)y);
}

SCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {
  int32_t xb = futrts_to_bits32(x);
  int32_t yb = futrts_to_bits32(y);
  return futrts_from_bits32((xb & ~(1<<31)) | (yb & (1<<31)));
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return a * b + c;
}

#else // Not OpenCL or ISPC, but CUDA or plain C.

SCALAR_FUN_ATTR float futrts_log32(float x) {
  return logf(x);
}

SCALAR_FUN_ATTR float futrts_log2_32(float x) {
  return log2f(x);
}

SCALAR_FUN_ATTR float futrts_log10_32(float x) {
  return log10f(x);
}

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  return log1pf(x);
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) {
  return sqrtf(x);
}

SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  return cbrtf(x);
}

SCALAR_FUN_ATTR float futrts_exp32(float x) {
  return expf(x);
}

SCALAR_FUN_ATTR float futrts_cos32(float x) {
  return cosf(x);
}

SCALAR_FUN_ATTR float futrts_sin32(float x) {
  return sinf(x);
}

SCALAR_FUN_ATTR float futrts_tan32(float x) {
  return tanf(x);
}

SCALAR_FUN_ATTR float futrts_acos32(float x) {
  return acosf(x);
}

SCALAR_FUN_ATTR float futrts_asin32(float x) {
  return asinf(x);
}

SCALAR_FUN_ATTR float futrts_atan32(float x) {
  return atanf(x);
}

SCALAR_FUN_ATTR float futrts_cosh32(float x) {
  return coshf(x);
}

SCALAR_FUN_ATTR float futrts_sinh32(float x) {
  return sinhf(x);
}

SCALAR_FUN_ATTR float futrts_tanh32(float x) {
  return tanhf(x);
}

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  return acoshf(x);
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  return asinhf(x);
}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  return atanhf(x);
}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {
  return atan2f(x, y);
}

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  return hypotf(x, y);
}

SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  return tgammaf(x);
}

SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  return lgammaf(x);
}

SCALAR_FUN_ATTR float futrts_erf32(float x) {
  return erff(x);
}

SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  return erfcf(x);
}

SCALAR_FUN_ATTR float fmod32(float x, float y) {
  return fmodf(x, y);
}

SCALAR_FUN_ATTR float futrts_round32(float x) {
  return rintf(x);
}

SCALAR_FUN_ATTR float futrts_floor32(float x) {
  return floorf(x);
}

SCALAR_FUN_ATTR float futrts_ceil32(float x) {
  return ceilf(x);
}

SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  return nextafterf(x, y);
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {
  return ldexpf(x, y);
}

SCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {
  return copysignf(x, y);
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return fmaf(a, b, c);
}
#endif

#if ISPC
SCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {
  return intbits(x);
}

SCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {
  return floatbits(x);
}
#else
SCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {
  union {
    float f;
    int32_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {
  union {
    int32_t f;
    float t;
  } p;

  p.f = x;
  return p.t;
}
#endif

SCALAR_FUN_ATTR float fsignum32(float x) {
  return futrts_isnan32(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);
}

#ifdef FUTHARK_F64_ENABLED

SCALAR_FUN_ATTR double futrts_from_bits64(int64_t x);
SCALAR_FUN_ATTR int64_t futrts_to_bits64(double x);

#if ISPC
SCALAR_FUN_ATTR bool futrts_isinf64(float x) {
  return !isnan(x) && isnan(x - x);
}

SCALAR_FUN_ATTR bool futrts_isfinite64(float x) {
  return !isnan(x) && !futrts_isinf64(x);
}

SCALAR_FUN_ATTR double fdiv64(double x, double y) {
  return x / y;
}

SCALAR_FUN_ATTR double fadd64(double x, double y) {
  return x + y;
}

SCALAR_FUN_ATTR double fsub64(double x, double y) {
  return x - y;
}

SCALAR_FUN_ATTR double fmul64(double x, double y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt64(double x, double y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple64(double x, double y) {
  return x <= y;
}

SCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double fabs64(double x) {
  return abs(x);
}

SCALAR_FUN_ATTR double fmax64(double x, double y) {
  return isnan(x) ? y : isnan(y) ? x : max(x, y);
}

SCALAR_FUN_ATTR double fmin64(double x, double y) {
  return isnan(x) ? y : isnan(y) ? x : min(x, y);
}

SCALAR_FUN_ATTR double fpow64(double a, double b) {
  float ret;
  foreach_active (i) {
      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));
      ret = insert(ret, i, r);
  }
  return ret;
}

SCALAR_FUN_ATTR double futrts_log64(double x) {
  return futrts_isfinite64(x) || (futrts_isinf64(x) && x < 0)? log(x) : x;
}

SCALAR_FUN_ATTR double futrts_log2_64(double x) {
  return futrts_log64(x)/log(2.0d);
}

SCALAR_FUN_ATTR double futrts_log10_64(double x) {
  return futrts_log64(x)/log(10.0d);
}

SCALAR_FUN_ATTR double futrts_log1p_64(double x) {
  if(x == -1.0d || (futrts_isinf64(x) && x > 0.0d)) return x / 0.0d;
  double y = 1.0d + x;
  double z = y - 1.0d;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR double futrts_sqrt64(double x) {
  return sqrt(x);
}

extern "C" unmasked uniform double cbrt(uniform double);
SCALAR_FUN_ATTR double futrts_cbrt64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = cbrtf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_exp64(double x) {
  return exp(x);
}

SCALAR_FUN_ATTR double futrts_cos64(double x) {
  return cos(x);
}

SCALAR_FUN_ATTR double futrts_sin64(double x) {
  return sin(x);
}

SCALAR_FUN_ATTR double futrts_tan64(double x) {
  return tan(x);
}

SCALAR_FUN_ATTR double futrts_acos64(double x) {
  return acos(x);
}

SCALAR_FUN_ATTR double futrts_asin64(double x) {
  return asin(x);
}

SCALAR_FUN_ATTR double futrts_atan64(double x) {
  return atan(x);
}

SCALAR_FUN_ATTR double futrts_cosh64(double x) {
  return (exp(x)+exp(-x)) / 2.0d;
}

SCALAR_FUN_ATTR double futrts_sinh64(double x) {
  return (exp(x)-exp(-x)) / 2.0d;
}

SCALAR_FUN_ATTR double futrts_tanh64(double x) {
  return futrts_sinh64(x)/futrts_cosh64(x);
}

SCALAR_FUN_ATTR double futrts_acosh64(double x) {
  double f = x+sqrt(x*x-1.0d);
  if(futrts_isfinite64(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR double futrts_asinh64(double x) {
  double f = x+sqrt(x*x+1.0d);
  if(futrts_isfinite64(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR double futrts_atanh64(double x) {
  double f = (1.0d+x)/(1.0d-x);
  if(futrts_isfinite64(f)) return log(f)/2.0d;
  return f;

}

SCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {
  return atan2(x, y);
}

extern "C" unmasked uniform double hypot(uniform double x, uniform double y);
SCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {
  double res;
  foreach_active (i) {
    uniform double r = hypot(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double tgamma(uniform double x);
SCALAR_FUN_ATTR double futrts_gamma64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = tgamma(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double lgamma(uniform double x);
SCALAR_FUN_ATTR double futrts_lgamma64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = lgamma(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double erf(uniform double x);
SCALAR_FUN_ATTR double futrts_erf64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = erf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double erfc(uniform double x);
SCALAR_FUN_ATTR double futrts_erfc64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = erfc(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {
  return a * b + c;
}

SCALAR_FUN_ATTR double futrts_round64(double x) {
  return round(x);
}

SCALAR_FUN_ATTR double futrts_ceil64(double x) {
  return ceil(x);
}

extern "C" unmasked uniform double nextafter(uniform float x, uniform double y);
SCALAR_FUN_ATTR float futrts_nextafter64(double x, double y) {
  double res;
  foreach_active (i) {
    uniform double r = nextafter(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_floor64(double x) {
  return floor(x);
}

SCALAR_FUN_ATTR bool futrts_isnan64(double x) {
  return isnan(x);
}

SCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int64_t) x;
  }
}

SCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f64_bool(double x) {
  return x != 0.0;
}

SCALAR_FUN_ATTR double btof_bool_f64(bool x) {
  return x ? 1.0 : 0.0;
}

SCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {
  int64_t res;
  foreach_active (i) {
    uniform double tmp = extract(x, i);
    uniform int64_t r = *((uniform int64_t* uniform)&tmp);
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {
  double res;
  foreach_active (i) {
    uniform int64_t tmp = extract(x, i);
    uniform double r = *((uniform double* uniform)&tmp);
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double fmod64(double x, double y) {
  return x - y * trunc(x/y);
}

SCALAR_FUN_ATTR double fsignum64(double x) {
  return futrts_isnan64(x) ? x : (x > 0 ? 1.0d : 0.0d) - (x < 0 ? 1.0d : 0.0d);
}

SCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {
  return x * pow((double)2.0, (double)y);
}

SCALAR_FUN_ATTR double futrts_copysign64(double x, double y) {
  int64_t xb = futrts_to_bits64(x);
  int64_t yb = futrts_to_bits64(y);
  return futrts_from_bits64((xb & ~(((int64_t)1)<<63)) | (yb & (((int64_t)1)<<63)));
}

SCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float fpconv_f32_f32(float x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f32_f64(float x) {
  return (double) x;
}

SCALAR_FUN_ATTR float fpconv_f64_f32(double x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f64_f64(double x) {
  return (double) x;
}

#else

SCALAR_FUN_ATTR double fdiv64(double x, double y) {
  return x / y;
}

SCALAR_FUN_ATTR double fadd64(double x, double y) {
  return x + y;
}

SCALAR_FUN_ATTR double fsub64(double x, double y) {
  return x - y;
}

SCALAR_FUN_ATTR double fmul64(double x, double y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt64(double x, double y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple64(double x, double y) {
  return x <= y;
}

SCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double fabs64(double x) {
  return fabs(x);
}

SCALAR_FUN_ATTR double fmax64(double x, double y) {
  return fmax(x, y);
}

SCALAR_FUN_ATTR double fmin64(double x, double y) {
  return fmin(x, y);
}

SCALAR_FUN_ATTR double fpow64(double x, double y) {
  return pow(x, y);
}

SCALAR_FUN_ATTR double futrts_log64(double x) {
  return log(x);
}

SCALAR_FUN_ATTR double futrts_log2_64(double x) {
  return log2(x);
}

SCALAR_FUN_ATTR double futrts_log10_64(double x) {
  return log10(x);
}

SCALAR_FUN_ATTR double futrts_log1p_64(double x) {
  return log1p(x);
}

SCALAR_FUN_ATTR double futrts_sqrt64(double x) {
  return sqrt(x);
}

SCALAR_FUN_ATTR double futrts_cbrt64(double x) {
  return cbrt(x);
}

SCALAR_FUN_ATTR double futrts_exp64(double x) {
  return exp(x);
}

SCALAR_FUN_ATTR double futrts_cos64(double x) {
  return cos(x);
}

SCALAR_FUN_ATTR double futrts_sin64(double x) {
  return sin(x);
}

SCALAR_FUN_ATTR double futrts_tan64(double x) {
  return tan(x);
}

SCALAR_FUN_ATTR double futrts_acos64(double x) {
  return acos(x);
}

SCALAR_FUN_ATTR double futrts_asin64(double x) {
  return asin(x);
}

SCALAR_FUN_ATTR double futrts_atan64(double x) {
  return atan(x);
}

SCALAR_FUN_ATTR double futrts_cosh64(double x) {
  return cosh(x);
}

SCALAR_FUN_ATTR double futrts_sinh64(double x) {
  return sinh(x);
}

SCALAR_FUN_ATTR double futrts_tanh64(double x) {
  return tanh(x);
}

SCALAR_FUN_ATTR double futrts_acosh64(double x) {
  return acosh(x);
}

SCALAR_FUN_ATTR double futrts_asinh64(double x) {
  return asinh(x);
}

SCALAR_FUN_ATTR double futrts_atanh64(double x) {
  return atanh(x);
}

SCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {
  return atan2(x, y);
}

SCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {
  return hypot(x, y);
}

SCALAR_FUN_ATTR double futrts_gamma64(double x) {
  return tgamma(x);
}

SCALAR_FUN_ATTR double futrts_lgamma64(double x) {
  return lgamma(x);
}

SCALAR_FUN_ATTR double futrts_erf64(double x) {
  return erf(x);
}

SCALAR_FUN_ATTR double futrts_erfc64(double x) {
  return erfc(x);
}

SCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {
  return fma(a, b, c);
}

SCALAR_FUN_ATTR double futrts_round64(double x) {
  return rint(x);
}

SCALAR_FUN_ATTR double futrts_ceil64(double x) {
  return ceil(x);
}

SCALAR_FUN_ATTR float futrts_nextafter64(float x, float y) {
  return nextafter(x, y);
}

SCALAR_FUN_ATTR double futrts_floor64(double x) {
  return floor(x);
}

SCALAR_FUN_ATTR bool futrts_isnan64(double x) {
  return isnan(x);
}

SCALAR_FUN_ATTR bool futrts_isinf64(double x) {
  return isinf(x);
}

SCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int64_t) x;
  }
}

SCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f64_bool(double x) {
  return x != 0;
}

SCALAR_FUN_ATTR double btof_bool_f64(bool x) {
  return x ? 1 : 0;
}

SCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {
  union {
    double f;
    int64_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {
  union {
    int64_t f;
    double t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR double fmod64(double x, double y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR double fsignum64(double x) {
  return futrts_isnan64(x) ? x : (x > 0) - (x < 0);
}

SCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {
#ifdef __OPENCL_VERSION__
  return mix(v0, v1, t);
#else
  return v0 + (v1 - v0) * t;
#endif
}

SCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {
  return ldexp(x, y);
}

SCALAR_FUN_ATTR float futrts_copysign64(double x, double y) {
  return copysign(x, y);
}

SCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {
#ifdef __OPENCL_VERSION__
  return mad(a, b, c);
#else
  return a * b + c;
#endif
}

SCALAR_FUN_ATTR float fpconv_f32_f32(float x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f32_f64(float x) {
  return (double) x;
}

SCALAR_FUN_ATTR float fpconv_f64_f32(double x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f64_f64(double x) {
  return (double) x;
}

#endif

#endif

// End of scalar.h.
// Start of scalar_f16.h.

// Half-precision is emulated if needed (e.g. in straight C) with the
// native type used if possible.  The emulation works by typedef'ing
// 'float' to 'f16', and then implementing all operations on single
// precision.  To cut down on duplication, we use the same code for
// those Futhark functions that require just operators or casts.  The
// in-memory representation for arrays will still be 16 bits even
// under emulation, so the compiler will have to be careful when
// generating reads or writes.

#if !defined(cl_khr_fp16) && !(defined(__CUDA_ARCH__) && __CUDA_ARCH__ >= 600) && !(defined(ISPC))
#define EMULATE_F16
#endif

#if !defined(EMULATE_F16) && defined(__OPENCL_VERSION__)
#pragma OPENCL EXTENSION cl_khr_fp16 : enable
#endif

#ifdef EMULATE_F16

// Note that the half-precision storage format is still 16 bits - the
// compiler will have to be real careful!
typedef float f16;

#elif ISPC
typedef float16 f16;

#else

#ifdef __CUDA_ARCH__
#include <cuda_fp16.h>
#endif

typedef half f16;

#endif

// Some of these functions convert to single precision because half
// precision versions are not available.

SCALAR_FUN_ATTR f16 fadd16(f16 x, f16 y) {
  return x + y;
}

SCALAR_FUN_ATTR f16 fsub16(f16 x, f16 y) {
  return x - y;
}

SCALAR_FUN_ATTR f16 fmul16(f16 x, f16 y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt16(f16 x, f16 y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple16(f16 x, f16 y) {
  return x <= y;
}

SCALAR_FUN_ATTR f16 sitofp_i8_f16(int8_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 sitofp_i16_f16(int16_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 sitofp_i32_f16(int32_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 sitofp_i64_f16(int64_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i8_f16(uint8_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i16_f16(uint16_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i32_f16(uint32_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i64_f16(uint64_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR int8_t fptosi_f16_i8(f16 x) {
  return (int8_t) (float) x;
}

SCALAR_FUN_ATTR int16_t fptosi_f16_i16(f16 x) {
  return (int16_t) x;
}

SCALAR_FUN_ATTR int32_t fptosi_f16_i32(f16 x) {
  return (int32_t) x;
}

SCALAR_FUN_ATTR int64_t fptosi_f16_i64(f16 x) {
  return (int64_t) x;
}

SCALAR_FUN_ATTR uint8_t fptoui_f16_i8(f16 x) {
  return (uint8_t) (float) x;
}

SCALAR_FUN_ATTR uint16_t fptoui_f16_i16(f16 x) {
  return (uint16_t) x;
}

SCALAR_FUN_ATTR uint32_t fptoui_f16_i32(f16 x) {
  return (uint32_t) x;
}

SCALAR_FUN_ATTR uint64_t fptoui_f16_i64(f16 x) {
  return (uint64_t) x;
}

SCALAR_FUN_ATTR bool ftob_f16_bool(f16 x) {
  return x != (f16)0;
}

SCALAR_FUN_ATTR f16 btof_bool_f16(bool x) {
  return x ? 1 : 0;
}

#ifndef EMULATE_F16
SCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {
  return isnan((float)x);
}

#ifdef __OPENCL_VERSION__

SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return fabs(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return fmax(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return fmin(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return pow(x, y);
}

#elif ISPC
SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return abs(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : max(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : min(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return pow(x, y);
}

#else // Assuming CUDA.

SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return fabsf(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return fmaxf(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return fminf(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return powf(x, y);
}
#endif

#if ISPC
SCALAR_FUN_ATTR bool futrts_isinf16(float x) {
  return !futrts_isnan16(x) && futrts_isnan16(x - x);
}
SCALAR_FUN_ATTR bool futrts_isfinite16(float x) {
  return !futrts_isnan16(x) && !futrts_isinf16(x);
}

#else

SCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {
  return isinf((float)x);
}
#endif

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return log(x);
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return log2(x);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return log10(x);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  return log1p(x);
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return sqrt(x);
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  return cbrt(x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return exp(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return cos(x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return sin(x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return tan(x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return acos(x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return asin(x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return atan(x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return cosh(x);
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return sinh(x);
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return tanh(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  return acosh(x);
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  return asinh(x);
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  return atanh(x);
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return atan2(x, y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return hypot(x, y);
}

SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  return tgamma(x);
}

SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  return lgamma(x);
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  return erf(x);
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  return erfc(x);
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return rint(x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return floor(x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return ceil(x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return nextafter(x, y);
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return mix(v0, v1, t);
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return ldexp(x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return copysign(x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return mad(a, b, c);
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return fma(a, b, c);
}
#elif ISPC

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return futrts_isfinite16(x) || (futrts_isinf16(x) && x < 0) ? log(x) : x;
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return futrts_log16(x) / log(2.0f16);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return futrts_log16(x) / log(10.0f16);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  if(x == -1.0f16 || (futrts_isinf16(x) && x > 0.0f16)) return x / 0.0f16;
  f16 y = 1.0f16 + x;
  f16 z = y - 1.0f16;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return (float16)sqrt((float)x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return exp(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return (float16)cos((float)x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return (float16)sin((float)x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return (float16)tan((float)x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return (float16)acos((float)x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return (float16)asin((float)x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return (float16)atan((float)x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return (exp(x)+exp(-x)) / 2.0f16;
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return (exp(x)-exp(-x)) / 2.0f16;
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return futrts_sinh16(x)/futrts_cosh16(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  float16 f = x+(float16)sqrt((float)(x*x-1));
  if(futrts_isfinite16(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  float16 f = x+(float16)sqrt((float)(x*x+1));
  if(futrts_isfinite16(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  float16 f = (1+x)/(1-x);
  if(futrts_isfinite16(f)) return log(f)/2.0f16;
  return f;
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return (float16)atan2((float)x, (float)y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return (float16)futrts_hypot32((float)x, (float)y);
}

extern "C" unmasked uniform float tgammaf(uniform float x);
SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  f16 res;
  foreach_active (i) {
    uniform f16 r = (f16)tgammaf(extract((float)x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float lgammaf(uniform float x);
SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  f16 res;
  foreach_active (i) {
    uniform f16 r = (f16)lgammaf(extract((float)x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  f16 res = (f16)futrts_cbrt32((float)x);
  return res;
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  f16 res = (f16)futrts_erf32((float)x);
  return res;
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  f16 res = (f16)futrts_erfc32((float)x);
  return res;
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return x - y * (float16)trunc((float) (x/y));
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return (float16)round((float)x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return (float16)floor((float)x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return (float16)ceil((float)x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return (float16)futrts_nextafter32((float)x, (float) y);
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return futrts_ldexp32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return futrts_copysign32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

#else // Assume CUDA.

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return hlog(x);
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return hlog2(x);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return hlog10(x);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  return (f16)log1pf((float)x);
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return hsqrt(x);
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  return cbrtf(x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return hexp(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return hcos(x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return hsin(x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return tanf(x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return acosf(x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return asinf(x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return atanf(x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return coshf(x);
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return sinhf(x);
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return tanhf(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  return acoshf(x);
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  return asinhf(x);
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  return atanhf(x);
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return atan2f(x, y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return hypotf(x, y);
}

SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  return tgammaf(x);
}

SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  return lgammaf(x);
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  return erff(x);
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  return erfcf(x);
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return fmodf(x, y);
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return rintf(x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return hfloor(x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return hceil(x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return __ushort_as_half(halfbitsnextafter(__half_as_ushort(x), __half_as_ushort(y)));
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return futrts_ldexp32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return futrts_copysign32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return fmaf(a, b, c);
}

#endif

// The CUDA __half type cannot be put in unions for some reason, so we
// use bespoke conversion functions instead.
#ifdef __CUDA_ARCH__
SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  return __half_as_ushort(x);
}
SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  return __ushort_as_half(x);
}
#elif ISPC

SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  varying int16_t y = *((varying int16_t * uniform)&x);
  return y;
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  varying f16 y = *((varying f16 * uniform)&x);
  return y;
}
#else
SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  union {
    f16 f;
    int16_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  union {
    int16_t f;
    f16 t;
  } p;

  p.f = x;
  return p.t;
}
#endif

#else // No native f16 - emulate.

SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return fabs32(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return fmax32(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return fmin32(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return fpow32(x, y);
}

SCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {
  return futrts_isnan32(x);
}

SCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {
  return futrts_isinf32(x);
}

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return futrts_log32(x);
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return futrts_log2_32(x);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return futrts_log10_32(x);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  return futrts_log1p_32(x);
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return futrts_sqrt32(x);
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  return futrts_cbrt32(x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return futrts_exp32(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return futrts_cos32(x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return futrts_sin32(x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return futrts_tan32(x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return futrts_acos32(x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return futrts_asin32(x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return futrts_atan32(x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return futrts_cosh32(x);
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return futrts_sinh32(x);
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return futrts_tanh32(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  return futrts_acosh32(x);
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  return futrts_asinh32(x);
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  return futrts_atanh32(x);
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return futrts_atan2_32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return futrts_hypot32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  return futrts_gamma32(x);
}

SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  return futrts_lgamma32(x);
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  return futrts_erf32(x);
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  return futrts_erfc32(x);
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return fmod32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return futrts_round32(x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return futrts_floor32(x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return futrts_ceil32(x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return halfbits2float(halfbitsnextafter(float2halfbits(x), float2halfbits(y)));
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return futrts_lerp32(v0, v1, t);
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return futrts_ldexp32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return futrts_copysign32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return futrts_mad32(a, b, c);
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return futrts_fma32(a, b, c);
}

// Even when we are using an OpenCL that does not support cl_khr_fp16,
// it must still support vload_half for actually creating a
// half-precision number, which can then be efficiently converted to a
// float.  Similarly for vstore_half.
#ifdef __OPENCL_VERSION__

SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  int16_t y;
  // Violating strict aliasing here.
  vstore_half((float)x, 0, (half*)&y);
  return y;
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  return (f16)vload_half(0, (half*)&x);
}

#else

SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  return (int16_t)float2halfbits(x);
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  return halfbits2float((uint16_t)x);
}

SCALAR_FUN_ATTR f16 fsignum16(f16 x) {
  return futrts_isnan16(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);
}

#endif

#endif

SCALAR_FUN_ATTR float fpconv_f16_f16(f16 x) {
  return x;
}

SCALAR_FUN_ATTR float fpconv_f16_f32(f16 x) {
  return x;
}

SCALAR_FUN_ATTR f16 fpconv_f32_f16(float x) {
  return (f16) x;
}

#ifdef FUTHARK_F64_ENABLED

SCALAR_FUN_ATTR double fpconv_f16_f64(f16 x) {
  return (double) x;
}

#if ISPC
SCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {
  return (f16) ((float)x);
}
#else
SCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {
  return (f16) x;
}
#endif
#endif


// End of scalar_f16.h.

// Start of context_prototypes.h
//
// Prototypes for the functions in context.h, or that will be called
// from those functions, that need to be available very early.

struct futhark_context_config;
struct futhark_context;

static void set_error(struct futhark_context* ctx, char *error);

// These are called in context/config new/free functions and contain
// shared setup.  They are generated by the compiler itself.
static int init_constants(struct futhark_context*);
static int free_constants(struct futhark_context*);
static void setup_program(struct futhark_context* ctx);
static void teardown_program(struct futhark_context *ctx);

// Allocate host memory.  Must be freed with host_free().
static void host_alloc(struct futhark_context* ctx, size_t size, const char* tag, size_t* size_out, void** mem_out);
// Allocate memory allocated with host_alloc().
static void host_free(struct futhark_context* ctx, size_t size, const char* tag, void* mem);

// Log that a copy has occurred.
static void log_copy(struct futhark_context* ctx,
                     const char *kind, int r,
                     int64_t dst_offset, int64_t dst_strides[r],
                     int64_t src_offset, int64_t src_strides[r],
                     int64_t shape[r]);

static void log_transpose(struct futhark_context* ctx,
                          int64_t k, int64_t m, int64_t n);

static bool lmad_map_tr(int64_t *num_arrays_out, int64_t *n_out, int64_t *m_out,
                        int r,
                        const int64_t dst_strides[r],
                        const int64_t src_strides[r],
                        const int64_t shape[r]);

static bool lmad_contiguous(int r, int64_t strides[r], int64_t shape[r]);

static bool lmad_memcpyable(int r,
                            int64_t dst_strides[r], int64_t src_strides[r], int64_t shape[r]);

static void add_event(struct futhark_context* ctx,
                      const char* name,
                      char* description,
                      void* data,
                      event_report_fn f);

// Functions that must be defined by the backend.
static void backend_context_config_setup(struct futhark_context_config* cfg);
static void backend_context_config_teardown(struct futhark_context_config* cfg);
static int backend_context_setup(struct futhark_context *ctx);
static void backend_context_teardown(struct futhark_context *ctx);

// End of of context_prototypes.h

struct memblock_device {
    int *references;
    CUdeviceptr mem;
    int64_t size;
    const char *desc;
};
struct memblock {
    int *references;
    unsigned char *mem;
    int64_t size;
    const char *desc;
};
struct constants {
    int dummy;
    struct memblock_device counters_mem_34022;
    struct memblock_device global_dynid_mem_34057;
    struct memblock_device global_dynid_mem_34235;
};
struct tuning_params {
    int dummy;
    int64_t *builtinzhiota_i64zitblock_sizze_34175;
    int64_t *builtinzhreplicate_f32zitblock_sizze_34421;
    int64_t *builtinzhreplicate_f64zitblock_sizze_34421;
    int64_t *builtinzhreplicate_i16zitblock_sizze_34421;
    int64_t *builtinzhreplicate_i32zitblock_sizze_34068;
    int64_t *builtinzhreplicate_i64zitblock_sizze_34192;
    int64_t *builtinzhreplicate_i8zitblock_sizze_34042;
    int64_t *gather_payloads_doublezisegmap_tblock_sizze_33048;
    int64_t *gather_payloads_doublezisegmap_tblock_sizze_33066;
    int64_t *gather_payloads_double_GFURzisegmap_tblock_sizze_33328;
    int64_t *gather_payloads_double_GFURzisegmap_tblock_sizze_33346;
    int64_t *gather_payloads_floatzisegmap_tblock_sizze_32992;
    int64_t *gather_payloads_floatzisegmap_tblock_sizze_33010;
    int64_t *gather_payloads_float_GFURzisegmap_tblock_sizze_33272;
    int64_t *gather_payloads_float_GFURzisegmap_tblock_sizze_33290;
    int64_t *gather_payloads_intzisegmap_tblock_sizze_32880;
    int64_t *gather_payloads_intzisegmap_tblock_sizze_32898;
    int64_t *gather_payloads_int_GFURzisegmap_tblock_sizze_33160;
    int64_t *gather_payloads_int_GFURzisegmap_tblock_sizze_33178;
    int64_t *gather_payloads_longzisegmap_tblock_sizze_32936;
    int64_t *gather_payloads_longzisegmap_tblock_sizze_32954;
    int64_t *gather_payloads_long_GFURzisegmap_tblock_sizze_33216;
    int64_t *gather_payloads_long_GFURzisegmap_tblock_sizze_33234;
    int64_t *gather_payloads_shortzisegmap_tblock_sizze_32824;
    int64_t *gather_payloads_shortzisegmap_tblock_sizze_32842;
    int64_t *gather_payloads_short_GFURzisegmap_tblock_sizze_33104;
    int64_t *gather_payloads_short_GFURzisegmap_tblock_sizze_33122;
    int64_t *inner_SMJ_doublezisegmap_num_tblocks_33730;
    int64_t *inner_SMJ_doublezisegmap_num_tblocks_33772;
    int64_t *inner_SMJ_doublezisegmap_num_tblocks_33780;
    int64_t *inner_SMJ_doublezisegmap_tblock_sizze_33728;
    int64_t *inner_SMJ_doublezisegmap_tblock_sizze_33744;
    int64_t *inner_SMJ_doublezisegmap_tblock_sizze_33770;
    int64_t *inner_SMJ_doublezisegmap_tblock_sizze_33778;
    int64_t *inner_SMJ_doublezisegmap_tblock_sizze_33786;
    int64_t *inner_SMJ_doublezisegscan_num_tblocks_33720;
    int64_t *inner_SMJ_doublezisegscan_num_tblocks_33736;
    int64_t *inner_SMJ_doublezisegscan_tblock_sizze_33718;
    int64_t *inner_SMJ_doublezisegscan_tblock_sizze_33734;
    int64_t *inner_SMJ_doublezitblock_sizze_34469;
    int64_t *inner_SMJ_doublezitblock_sizze_34489;
    int64_t *inner_SMJ_floatzisegmap_num_tblocks_33646;
    int64_t *inner_SMJ_floatzisegmap_num_tblocks_33688;
    int64_t *inner_SMJ_floatzisegmap_num_tblocks_33696;
    int64_t *inner_SMJ_floatzisegmap_tblock_sizze_33644;
    int64_t *inner_SMJ_floatzisegmap_tblock_sizze_33660;
    int64_t *inner_SMJ_floatzisegmap_tblock_sizze_33686;
    int64_t *inner_SMJ_floatzisegmap_tblock_sizze_33694;
    int64_t *inner_SMJ_floatzisegmap_tblock_sizze_33702;
    int64_t *inner_SMJ_floatzisegscan_num_tblocks_33636;
    int64_t *inner_SMJ_floatzisegscan_num_tblocks_33652;
    int64_t *inner_SMJ_floatzisegscan_tblock_sizze_33634;
    int64_t *inner_SMJ_floatzisegscan_tblock_sizze_33650;
    int64_t *inner_SMJ_floatzitblock_sizze_34469;
    int64_t *inner_SMJ_floatzitblock_sizze_34489;
    int64_t *inner_SMJ_intzisegmap_num_tblocks_33478;
    int64_t *inner_SMJ_intzisegmap_num_tblocks_33520;
    int64_t *inner_SMJ_intzisegmap_num_tblocks_33528;
    int64_t *inner_SMJ_intzisegmap_tblock_sizze_33476;
    int64_t *inner_SMJ_intzisegmap_tblock_sizze_33492;
    int64_t *inner_SMJ_intzisegmap_tblock_sizze_33518;
    int64_t *inner_SMJ_intzisegmap_tblock_sizze_33526;
    int64_t *inner_SMJ_intzisegmap_tblock_sizze_33534;
    int64_t *inner_SMJ_intzisegscan_num_tblocks_33468;
    int64_t *inner_SMJ_intzisegscan_num_tblocks_33484;
    int64_t *inner_SMJ_intzisegscan_tblock_sizze_33466;
    int64_t *inner_SMJ_intzisegscan_tblock_sizze_33482;
    int64_t *inner_SMJ_intzitblock_sizze_34449;
    int64_t *inner_SMJ_intzitblock_sizze_34469;
    int64_t *inner_SMJ_longzisegmap_num_tblocks_33562;
    int64_t *inner_SMJ_longzisegmap_num_tblocks_33604;
    int64_t *inner_SMJ_longzisegmap_num_tblocks_33612;
    int64_t *inner_SMJ_longzisegmap_tblock_sizze_33560;
    int64_t *inner_SMJ_longzisegmap_tblock_sizze_33576;
    int64_t *inner_SMJ_longzisegmap_tblock_sizze_33602;
    int64_t *inner_SMJ_longzisegmap_tblock_sizze_33610;
    int64_t *inner_SMJ_longzisegmap_tblock_sizze_33618;
    int64_t *inner_SMJ_longzisegscan_num_tblocks_33552;
    int64_t *inner_SMJ_longzisegscan_num_tblocks_33568;
    int64_t *inner_SMJ_longzisegscan_tblock_sizze_33550;
    int64_t *inner_SMJ_longzisegscan_tblock_sizze_33566;
    int64_t *inner_SMJ_longzitblock_sizze_34449;
    int64_t *inner_SMJ_longzitblock_sizze_34469;
    int64_t *inner_SMJ_shortzisegmap_num_tblocks_33394;
    int64_t *inner_SMJ_shortzisegmap_num_tblocks_33436;
    int64_t *inner_SMJ_shortzisegmap_num_tblocks_33444;
    int64_t *inner_SMJ_shortzisegmap_tblock_sizze_33392;
    int64_t *inner_SMJ_shortzisegmap_tblock_sizze_33408;
    int64_t *inner_SMJ_shortzisegmap_tblock_sizze_33434;
    int64_t *inner_SMJ_shortzisegmap_tblock_sizze_33442;
    int64_t *inner_SMJ_shortzisegmap_tblock_sizze_33450;
    int64_t *inner_SMJ_shortzisegscan_num_tblocks_33384;
    int64_t *inner_SMJ_shortzisegscan_num_tblocks_33400;
    int64_t *inner_SMJ_shortzisegscan_tblock_sizze_33382;
    int64_t *inner_SMJ_shortzisegscan_tblock_sizze_33398;
    int64_t *inner_SMJ_shortzitblock_sizze_34469;
    int64_t *inner_SMJ_shortzitblock_sizze_34489;
    int64_t *max_idxzisegred_num_tblocks_32814;
    int64_t *max_idxzisegred_tblock_sizze_32812;
    int64_t *min_idxzisegred_num_tblocks_32804;
    int64_t *min_idxzisegred_tblock_sizze_32802;
};
static const int num_tuning_params = 101;
static const char *tuning_param_names[] = {"builtin#iota_i64.tblock_size_34175", "builtin#replicate_f32.tblock_size_34421", "builtin#replicate_f64.tblock_size_34421", "builtin#replicate_i16.tblock_size_34421", "builtin#replicate_i32.tblock_size_34068", "builtin#replicate_i64.tblock_size_34192", "builtin#replicate_i8.tblock_size_34042", "gather_payloads_double.segmap_tblock_size_33048", "gather_payloads_double.segmap_tblock_size_33066", "gather_payloads_double_GFUR.segmap_tblock_size_33328", "gather_payloads_double_GFUR.segmap_tblock_size_33346", "gather_payloads_float.segmap_tblock_size_32992", "gather_payloads_float.segmap_tblock_size_33010", "gather_payloads_float_GFUR.segmap_tblock_size_33272", "gather_payloads_float_GFUR.segmap_tblock_size_33290", "gather_payloads_int.segmap_tblock_size_32880", "gather_payloads_int.segmap_tblock_size_32898", "gather_payloads_int_GFUR.segmap_tblock_size_33160", "gather_payloads_int_GFUR.segmap_tblock_size_33178", "gather_payloads_long.segmap_tblock_size_32936", "gather_payloads_long.segmap_tblock_size_32954", "gather_payloads_long_GFUR.segmap_tblock_size_33216", "gather_payloads_long_GFUR.segmap_tblock_size_33234", "gather_payloads_short.segmap_tblock_size_32824", "gather_payloads_short.segmap_tblock_size_32842", "gather_payloads_short_GFUR.segmap_tblock_size_33104", "gather_payloads_short_GFUR.segmap_tblock_size_33122", "inner_SMJ_double.segmap_num_tblocks_33730", "inner_SMJ_double.segmap_num_tblocks_33772", "inner_SMJ_double.segmap_num_tblocks_33780", "inner_SMJ_double.segmap_tblock_size_33728", "inner_SMJ_double.segmap_tblock_size_33744", "inner_SMJ_double.segmap_tblock_size_33770", "inner_SMJ_double.segmap_tblock_size_33778", "inner_SMJ_double.segmap_tblock_size_33786", "inner_SMJ_double.segscan_num_tblocks_33720", "inner_SMJ_double.segscan_num_tblocks_33736", "inner_SMJ_double.segscan_tblock_size_33718", "inner_SMJ_double.segscan_tblock_size_33734", "inner_SMJ_double.tblock_size_34469", "inner_SMJ_double.tblock_size_34489", "inner_SMJ_float.segmap_num_tblocks_33646", "inner_SMJ_float.segmap_num_tblocks_33688", "inner_SMJ_float.segmap_num_tblocks_33696", "inner_SMJ_float.segmap_tblock_size_33644", "inner_SMJ_float.segmap_tblock_size_33660", "inner_SMJ_float.segmap_tblock_size_33686", "inner_SMJ_float.segmap_tblock_size_33694", "inner_SMJ_float.segmap_tblock_size_33702", "inner_SMJ_float.segscan_num_tblocks_33636", "inner_SMJ_float.segscan_num_tblocks_33652", "inner_SMJ_float.segscan_tblock_size_33634", "inner_SMJ_float.segscan_tblock_size_33650", "inner_SMJ_float.tblock_size_34469", "inner_SMJ_float.tblock_size_34489", "inner_SMJ_int.segmap_num_tblocks_33478", "inner_SMJ_int.segmap_num_tblocks_33520", "inner_SMJ_int.segmap_num_tblocks_33528", "inner_SMJ_int.segmap_tblock_size_33476", "inner_SMJ_int.segmap_tblock_size_33492", "inner_SMJ_int.segmap_tblock_size_33518", "inner_SMJ_int.segmap_tblock_size_33526", "inner_SMJ_int.segmap_tblock_size_33534", "inner_SMJ_int.segscan_num_tblocks_33468", "inner_SMJ_int.segscan_num_tblocks_33484", "inner_SMJ_int.segscan_tblock_size_33466", "inner_SMJ_int.segscan_tblock_size_33482", "inner_SMJ_int.tblock_size_34449", "inner_SMJ_int.tblock_size_34469", "inner_SMJ_long.segmap_num_tblocks_33562", "inner_SMJ_long.segmap_num_tblocks_33604", "inner_SMJ_long.segmap_num_tblocks_33612", "inner_SMJ_long.segmap_tblock_size_33560", "inner_SMJ_long.segmap_tblock_size_33576", "inner_SMJ_long.segmap_tblock_size_33602", "inner_SMJ_long.segmap_tblock_size_33610", "inner_SMJ_long.segmap_tblock_size_33618", "inner_SMJ_long.segscan_num_tblocks_33552", "inner_SMJ_long.segscan_num_tblocks_33568", "inner_SMJ_long.segscan_tblock_size_33550", "inner_SMJ_long.segscan_tblock_size_33566", "inner_SMJ_long.tblock_size_34449", "inner_SMJ_long.tblock_size_34469", "inner_SMJ_short.segmap_num_tblocks_33394", "inner_SMJ_short.segmap_num_tblocks_33436", "inner_SMJ_short.segmap_num_tblocks_33444", "inner_SMJ_short.segmap_tblock_size_33392", "inner_SMJ_short.segmap_tblock_size_33408", "inner_SMJ_short.segmap_tblock_size_33434", "inner_SMJ_short.segmap_tblock_size_33442", "inner_SMJ_short.segmap_tblock_size_33450", "inner_SMJ_short.segscan_num_tblocks_33384", "inner_SMJ_short.segscan_num_tblocks_33400", "inner_SMJ_short.segscan_tblock_size_33382", "inner_SMJ_short.segscan_tblock_size_33398", "inner_SMJ_short.tblock_size_34469", "inner_SMJ_short.tblock_size_34489", "max_idx.segred_num_tblocks_32814", "max_idx.segred_tblock_size_32812", "min_idx.segred_num_tblocks_32804", "min_idx.segred_tblock_size_32802", NULL};
static const char *tuning_param_vars[] = {"builtinzhiota_i64zitblock_sizze_34175", "builtinzhreplicate_f32zitblock_sizze_34421", "builtinzhreplicate_f64zitblock_sizze_34421", "builtinzhreplicate_i16zitblock_sizze_34421", "builtinzhreplicate_i32zitblock_sizze_34068", "builtinzhreplicate_i64zitblock_sizze_34192", "builtinzhreplicate_i8zitblock_sizze_34042", "gather_payloads_doublezisegmap_tblock_sizze_33048", "gather_payloads_doublezisegmap_tblock_sizze_33066", "gather_payloads_double_GFURzisegmap_tblock_sizze_33328", "gather_payloads_double_GFURzisegmap_tblock_sizze_33346", "gather_payloads_floatzisegmap_tblock_sizze_32992", "gather_payloads_floatzisegmap_tblock_sizze_33010", "gather_payloads_float_GFURzisegmap_tblock_sizze_33272", "gather_payloads_float_GFURzisegmap_tblock_sizze_33290", "gather_payloads_intzisegmap_tblock_sizze_32880", "gather_payloads_intzisegmap_tblock_sizze_32898", "gather_payloads_int_GFURzisegmap_tblock_sizze_33160", "gather_payloads_int_GFURzisegmap_tblock_sizze_33178", "gather_payloads_longzisegmap_tblock_sizze_32936", "gather_payloads_longzisegmap_tblock_sizze_32954", "gather_payloads_long_GFURzisegmap_tblock_sizze_33216", "gather_payloads_long_GFURzisegmap_tblock_sizze_33234", "gather_payloads_shortzisegmap_tblock_sizze_32824", "gather_payloads_shortzisegmap_tblock_sizze_32842", "gather_payloads_short_GFURzisegmap_tblock_sizze_33104", "gather_payloads_short_GFURzisegmap_tblock_sizze_33122", "inner_SMJ_doublezisegmap_num_tblocks_33730", "inner_SMJ_doublezisegmap_num_tblocks_33772", "inner_SMJ_doublezisegmap_num_tblocks_33780", "inner_SMJ_doublezisegmap_tblock_sizze_33728", "inner_SMJ_doublezisegmap_tblock_sizze_33744", "inner_SMJ_doublezisegmap_tblock_sizze_33770", "inner_SMJ_doublezisegmap_tblock_sizze_33778", "inner_SMJ_doublezisegmap_tblock_sizze_33786", "inner_SMJ_doublezisegscan_num_tblocks_33720", "inner_SMJ_doublezisegscan_num_tblocks_33736", "inner_SMJ_doublezisegscan_tblock_sizze_33718", "inner_SMJ_doublezisegscan_tblock_sizze_33734", "inner_SMJ_doublezitblock_sizze_34469", "inner_SMJ_doublezitblock_sizze_34489", "inner_SMJ_floatzisegmap_num_tblocks_33646", "inner_SMJ_floatzisegmap_num_tblocks_33688", "inner_SMJ_floatzisegmap_num_tblocks_33696", "inner_SMJ_floatzisegmap_tblock_sizze_33644", "inner_SMJ_floatzisegmap_tblock_sizze_33660", "inner_SMJ_floatzisegmap_tblock_sizze_33686", "inner_SMJ_floatzisegmap_tblock_sizze_33694", "inner_SMJ_floatzisegmap_tblock_sizze_33702", "inner_SMJ_floatzisegscan_num_tblocks_33636", "inner_SMJ_floatzisegscan_num_tblocks_33652", "inner_SMJ_floatzisegscan_tblock_sizze_33634", "inner_SMJ_floatzisegscan_tblock_sizze_33650", "inner_SMJ_floatzitblock_sizze_34469", "inner_SMJ_floatzitblock_sizze_34489", "inner_SMJ_intzisegmap_num_tblocks_33478", "inner_SMJ_intzisegmap_num_tblocks_33520", "inner_SMJ_intzisegmap_num_tblocks_33528", "inner_SMJ_intzisegmap_tblock_sizze_33476", "inner_SMJ_intzisegmap_tblock_sizze_33492", "inner_SMJ_intzisegmap_tblock_sizze_33518", "inner_SMJ_intzisegmap_tblock_sizze_33526", "inner_SMJ_intzisegmap_tblock_sizze_33534", "inner_SMJ_intzisegscan_num_tblocks_33468", "inner_SMJ_intzisegscan_num_tblocks_33484", "inner_SMJ_intzisegscan_tblock_sizze_33466", "inner_SMJ_intzisegscan_tblock_sizze_33482", "inner_SMJ_intzitblock_sizze_34449", "inner_SMJ_intzitblock_sizze_34469", "inner_SMJ_longzisegmap_num_tblocks_33562", "inner_SMJ_longzisegmap_num_tblocks_33604", "inner_SMJ_longzisegmap_num_tblocks_33612", "inner_SMJ_longzisegmap_tblock_sizze_33560", "inner_SMJ_longzisegmap_tblock_sizze_33576", "inner_SMJ_longzisegmap_tblock_sizze_33602", "inner_SMJ_longzisegmap_tblock_sizze_33610", "inner_SMJ_longzisegmap_tblock_sizze_33618", "inner_SMJ_longzisegscan_num_tblocks_33552", "inner_SMJ_longzisegscan_num_tblocks_33568", "inner_SMJ_longzisegscan_tblock_sizze_33550", "inner_SMJ_longzisegscan_tblock_sizze_33566", "inner_SMJ_longzitblock_sizze_34449", "inner_SMJ_longzitblock_sizze_34469", "inner_SMJ_shortzisegmap_num_tblocks_33394", "inner_SMJ_shortzisegmap_num_tblocks_33436", "inner_SMJ_shortzisegmap_num_tblocks_33444", "inner_SMJ_shortzisegmap_tblock_sizze_33392", "inner_SMJ_shortzisegmap_tblock_sizze_33408", "inner_SMJ_shortzisegmap_tblock_sizze_33434", "inner_SMJ_shortzisegmap_tblock_sizze_33442", "inner_SMJ_shortzisegmap_tblock_sizze_33450", "inner_SMJ_shortzisegscan_num_tblocks_33384", "inner_SMJ_shortzisegscan_num_tblocks_33400", "inner_SMJ_shortzisegscan_tblock_sizze_33382", "inner_SMJ_shortzisegscan_tblock_sizze_33398", "inner_SMJ_shortzitblock_sizze_34469", "inner_SMJ_shortzitblock_sizze_34489", "max_idxzisegred_num_tblocks_32814", "max_idxzisegred_tblock_sizze_32812", "min_idxzisegred_num_tblocks_32804", "min_idxzisegred_tblock_sizze_32802", NULL};
static const char *tuning_param_classes[] = {"thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "thread_block_size", "grid_size", "thread_block_size", NULL};
static int64_t tuning_param_defaults[] = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
static const int max_failure_args = 2;
static const int f64_required = 1;
static const char *gpu_program[] = {"#define FUTHARK_CUDA\n// start of prelude.cu\n\n#define SCALAR_FUN_ATTR __device__ static inline\n#define FUTHARK_FUN_ATTR __device__ static\n#define FUTHARK_F64_ENABLED\n\ntypedef char int8_t;\ntypedef short int16_t;\ntypedef int int32_t;\ntypedef long long int64_t;\ntypedef unsigned char uint8_t;\ntypedef unsigned short uint16_t;\ntypedef unsigned int uint32_t;\ntypedef unsigned long long uint64_t;\n\n#define __global\n#define __local\n#define __private\n#define __constant\n#define __write_only\n#define __read_only\n\nstatic inline __device__ int get_tblock_id(int d) {\n  switch (d) {\n  case 0: return blockIdx.x;\n  case 1: return blockIdx.y;\n  case 2: return blockIdx.z;\n  default: return 0;\n  }\n}\n\nstatic inline __device__ int get_num_tblocks(int d) {\n  switch(d) {\n  case 0: return gridDim.x;\n  case 1: return gridDim.y;\n  case 2: return gridDim.z;\n  default: return 0;\n  }\n}\n\nstatic inline __device__ int get_global_id(int d) {\n  switch (d) {\n    case 0: return threadIdx.x + blockIdx.x * blockDim.x;\n    case 1: return threadIdx.y + blockIdx.y * blockDim.y;\n    case 2: return threadIdx.z + blockIdx.z * blockDim.z;\n    default: return 0;\n  }\n}\n\nstatic inline __device__ int get_local_id(int d) {\n  switch (d) {\n    case 0: return threadIdx.x;\n    case 1: return threadIdx.y;\n    case 2: return threadIdx.z;\n    default: return 0;\n  }\n}\n\nstatic inline __device__ int get_local_size(int d) {\n  switch (d) {\n    case 0: return blockDim.x;\n    case 1: return blockDim.y;\n    case 2: return blockDim.z;\n    default: return 0;\n  }\n}\n\nstatic inline __device__ int get_global_size(int d) {\n  switch (d) {\n    case 0: return gridDim.x * blockDim.x;\n    case 1: return gridDim.y * blockDim.y;\n    case 2: return gridDim.z * blockDim.z;\n    default: return 0;\n  }\n}\n\n\n#define CLK_LOCAL_MEM_FENCE 1\n#define CLK_GLOBAL_MEM_FENCE 2\nstatic inline __device__ void barrier(int x) {\n  __syncthreads();\n}\nstatic inline __device__ void mem_fence_local() {\n  __threadfence_block();\n}\nstatic inline __device__ void mem_fence_global", "() {\n  __threadfence();\n}\n\nstatic inline __device__ void barrier_local() {\n  __syncthreads();\n}\n\n#define NAN (0.0/0.0)\n#define INFINITY (1.0/0.0)\nextern volatile __shared__ unsigned char shared_mem[];\n\n#define SHARED_MEM_PARAM\n#define FUTHARK_KERNEL extern \"C\" __global__ __launch_bounds__(MAX_THREADS_PER_BLOCK)\n#define FUTHARK_KERNEL_SIZED(a,b,c) extern \"C\" __global__ __launch_bounds__(a*b*c)\n\n// End of prelude.cu\n// Start of half.h.\n\n// Conversion functions are from http://half.sourceforge.net/, but\n// translated to C.\n//\n// Copyright (c) 2012-2021 Christian Rau\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in\n// all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n// THE SOFTWARE.\n\n#ifndef __OPENCL_VERSION__\n#define __constant\n#endif\n\n__constant static const uint16_t base_table[512] = {\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0", "000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0001, 0x0002, 0x0004, 0x0008, 0x0010, 0x0020, 0x0040, 0x0080, 0x0100,\n  0x0200, 0x0400, 0x0800, 0x0C00, 0x1000, 0x1400, 0x1800, 0x1C00, 0x2000, 0x2400, 0x2800, 0x2C00, 0x3000, 0x3400, 0x3800, 0x3C00,\n  0x4000, 0x4400, 0x4800, 0x4C00, 0x5000, 0x5400, 0x5800, 0x5C00, 0x6000, 0x6400, 0x6800, 0x6C00, 0x7000, 0x7400, 0x7800, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8",
                                    "000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8001, 0x8002, 0x8004, 0x8008, 0x8010, 0x8020, 0x8040, 0x8080, 0x8100,\n  0x8200, 0x8400, 0x8800, 0x8C00, 0x9000, 0x9400, 0x9800, 0x9C00, 0xA000, 0xA400, 0xA800, 0xAC00, 0xB000, 0xB400, 0xB800, 0xBC00,\n  0xC000, 0xC400, 0xC800, 0xCC00, 0xD000, 0xD400, 0xD800, 0xDC00, 0xE000, 0xE400, 0xE800, 0xEC00, 0xF000, 0xF400, 0xF800, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00 };\n\n__constant static const unsigned char shift_table[512] = {\n  24, 24, 24, 24, 24, 24,", " 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 2", "4, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13 };\n\n__constant static const uint32_t mantissa_table[2048] = {\n  0x00000000, 0x33800000, 0x34000000, 0x34400000, 0x34800000, 0x34A00000, 0x34C00000, 0x34E00000, 0x35000000, 0x35100000, 0x35200000, 0x35300000, 0x35400000, 0x35500000, 0x35600000, 0x35700000,\n  0x35800000, 0x35880000, 0x35900000, 0x35980000, 0x35A00000, 0x35A80000, 0x35B00000, 0x35B80000, 0x35C00000, 0x35C80000, 0x35D00000, 0x35D80000, 0x35E00000, 0x35E80000, 0x35F00000, 0x35F80000,\n  0x36000000, 0x36040000, 0x36080000, 0x360C0000, 0x36100000, 0x36140000, 0x36180000, 0x361C0000, 0x36200000, 0x36240000, 0x36280000, 0x362C0000, 0x36300000, 0x36340000, 0x36380000, 0x363C0000,\n  0x36400000, 0x36440000, 0x36480000, 0x364C0000, 0x36500000, 0x36540000, 0x36580000, 0x365C0000, 0x36600000, 0x36640000, 0x36680000, 0x366C0000, 0x36700000, 0x36740000, 0x36780000, 0x367C0000,\n  0x36800000, 0x36820000, 0x36840000, 0x36860000, 0x36880000, 0x368A0000, 0x368C0000, 0x368E0000, 0x36900000, 0x36920000, 0x36940000, 0x36960000, 0x36980000, 0x369A0000, 0x369C0000, 0x369E0000,\n  0x36A00000, 0x36A20000, 0x36A40000, 0x36A60000, 0x36A80000, 0x36AA0000, 0x36AC0000, 0x36AE0000, 0x36B00000, 0x36B20000, 0x36B40000, 0x36B60000, 0x36B80000, 0x36BA0000, 0x36BC0000, 0x36BE0000,\n  0x36C00000, 0x36C20000, 0x36C40000, 0x36C60000, 0x36C80000, 0x36CA0000, 0x36CC0000, 0x36CE0000, 0x36D00000, 0x36D20000, 0x36D40000, 0x36D60000, 0x36D80000, 0x36DA0000, 0x36DC0000, 0x36DE0000,\n  0x36E00000, 0x36E20000, 0x36E40000, 0x36E60000, 0x36E80000, 0x36EA0000, 0x36EC0000, 0x36EE0000, 0x36F00000, 0x36F20000, 0x36F40000, 0x36F60000, 0x36F80000, 0x36FA0000, 0x36FC0000, 0x36FE0000,\n  0x37000000, 0x37010000, 0x37020000, 0x37030000, 0x37040000, 0x37050000, 0x37060000, 0x37070000, 0x37080000, 0x37090000, 0x370A0000, 0x370B0000, 0x370C0000, 0x370D0000, 0x370E0000, 0x370F0000,\n  0x37100000, 0x37110000, 0x37120000, 0x37130000, 0x37140000, 0x37150000, 0x37160000, 0x37170000, 0x37180000, 0x37190000, 0x371A0000, 0x37",
                                    "1B0000, 0x371C0000, 0x371D0000, 0x371E0000, 0x371F0000,\n  0x37200000, 0x37210000, 0x37220000, 0x37230000, 0x37240000, 0x37250000, 0x37260000, 0x37270000, 0x37280000, 0x37290000, 0x372A0000, 0x372B0000, 0x372C0000, 0x372D0000, 0x372E0000, 0x372F0000,\n  0x37300000, 0x37310000, 0x37320000, 0x37330000, 0x37340000, 0x37350000, 0x37360000, 0x37370000, 0x37380000, 0x37390000, 0x373A0000, 0x373B0000, 0x373C0000, 0x373D0000, 0x373E0000, 0x373F0000,\n  0x37400000, 0x37410000, 0x37420000, 0x37430000, 0x37440000, 0x37450000, 0x37460000, 0x37470000, 0x37480000, 0x37490000, 0x374A0000, 0x374B0000, 0x374C0000, 0x374D0000, 0x374E0000, 0x374F0000,\n  0x37500000, 0x37510000, 0x37520000, 0x37530000, 0x37540000, 0x37550000, 0x37560000, 0x37570000, 0x37580000, 0x37590000, 0x375A0000, 0x375B0000, 0x375C0000, 0x375D0000, 0x375E0000, 0x375F0000,\n  0x37600000, 0x37610000, 0x37620000, 0x37630000, 0x37640000, 0x37650000, 0x37660000, 0x37670000, 0x37680000, 0x37690000, 0x376A0000, 0x376B0000, 0x376C0000, 0x376D0000, 0x376E0000, 0x376F0000,\n  0x37700000, 0x37710000, 0x37720000, 0x37730000, 0x37740000, 0x37750000, 0x37760000, 0x37770000, 0x37780000, 0x37790000, 0x377A0000, 0x377B0000, 0x377C0000, 0x377D0000, 0x377E0000, 0x377F0000,\n  0x37800000, 0x37808000, 0x37810000, 0x37818000, 0x37820000, 0x37828000, 0x37830000, 0x37838000, 0x37840000, 0x37848000, 0x37850000, 0x37858000, 0x37860000, 0x37868000, 0x37870000, 0x37878000,\n  0x37880000, 0x37888000, 0x37890000, 0x37898000, 0x378A0000, 0x378A8000, 0x378B0000, 0x378B8000, 0x378C0000, 0x378C8000, 0x378D0000, 0x378D8000, 0x378E0000, 0x378E8000, 0x378F0000, 0x378F8000,\n  0x37900000, 0x37908000, 0x37910000, 0x37918000, 0x37920000, 0x37928000, 0x37930000, 0x37938000, 0x37940000, 0x37948000, 0x37950000, 0x37958000, 0x37960000, 0x37968000, 0x37970000, 0x37978000,\n  0x37980000, 0x37988000, 0x37990000, 0x37998000, 0x379A0000, 0x379A8000, 0x379B0000, 0x379B8000, 0x379C0000, 0x379C8000, 0x379D0000, 0x379D8000, 0x379E0000, 0x379E8000, 0x379F0000, 0x379F8000,\n  0x", "37A00000, 0x37A08000, 0x37A10000, 0x37A18000, 0x37A20000, 0x37A28000, 0x37A30000, 0x37A38000, 0x37A40000, 0x37A48000, 0x37A50000, 0x37A58000, 0x37A60000, 0x37A68000, 0x37A70000, 0x37A78000,\n  0x37A80000, 0x37A88000, 0x37A90000, 0x37A98000, 0x37AA0000, 0x37AA8000, 0x37AB0000, 0x37AB8000, 0x37AC0000, 0x37AC8000, 0x37AD0000, 0x37AD8000, 0x37AE0000, 0x37AE8000, 0x37AF0000, 0x37AF8000,\n  0x37B00000, 0x37B08000, 0x37B10000, 0x37B18000, 0x37B20000, 0x37B28000, 0x37B30000, 0x37B38000, 0x37B40000, 0x37B48000, 0x37B50000, 0x37B58000, 0x37B60000, 0x37B68000, 0x37B70000, 0x37B78000,\n  0x37B80000, 0x37B88000, 0x37B90000, 0x37B98000, 0x37BA0000, 0x37BA8000, 0x37BB0000, 0x37BB8000, 0x37BC0000, 0x37BC8000, 0x37BD0000, 0x37BD8000, 0x37BE0000, 0x37BE8000, 0x37BF0000, 0x37BF8000,\n  0x37C00000, 0x37C08000, 0x37C10000, 0x37C18000, 0x37C20000, 0x37C28000, 0x37C30000, 0x37C38000, 0x37C40000, 0x37C48000, 0x37C50000, 0x37C58000, 0x37C60000, 0x37C68000, 0x37C70000, 0x37C78000,\n  0x37C80000, 0x37C88000, 0x37C90000, 0x37C98000, 0x37CA0000, 0x37CA8000, 0x37CB0000, 0x37CB8000, 0x37CC0000, 0x37CC8000, 0x37CD0000, 0x37CD8000, 0x37CE0000, 0x37CE8000, 0x37CF0000, 0x37CF8000,\n  0x37D00000, 0x37D08000, 0x37D10000, 0x37D18000, 0x37D20000, 0x37D28000, 0x37D30000, 0x37D38000, 0x37D40000, 0x37D48000, 0x37D50000, 0x37D58000, 0x37D60000, 0x37D68000, 0x37D70000, 0x37D78000,\n  0x37D80000, 0x37D88000, 0x37D90000, 0x37D98000, 0x37DA0000, 0x37DA8000, 0x37DB0000, 0x37DB8000, 0x37DC0000, 0x37DC8000, 0x37DD0000, 0x37DD8000, 0x37DE0000, 0x37DE8000, 0x37DF0000, 0x37DF8000,\n  0x37E00000, 0x37E08000, 0x37E10000, 0x37E18000, 0x37E20000, 0x37E28000, 0x37E30000, 0x37E38000, 0x37E40000, 0x37E48000, 0x37E50000, 0x37E58000, 0x37E60000, 0x37E68000, 0x37E70000, 0x37E78000,\n  0x37E80000, 0x37E88000, 0x37E90000, 0x37E98000, 0x37EA0000, 0x37EA8000, 0x37EB0000, 0x37EB8000, 0x37EC0000, 0x37EC8000, 0x37ED0000, 0x37ED8000, 0x37EE0000, 0x37EE8000, 0x37EF0000, 0x37EF8000,\n  0x37F00000, 0x37F08000, 0x37F10000, 0x37F18000, 0x37F20000, 0x", "37F28000, 0x37F30000, 0x37F38000, 0x37F40000, 0x37F48000, 0x37F50000, 0x37F58000, 0x37F60000, 0x37F68000, 0x37F70000, 0x37F78000,\n  0x37F80000, 0x37F88000, 0x37F90000, 0x37F98000, 0x37FA0000, 0x37FA8000, 0x37FB0000, 0x37FB8000, 0x37FC0000, 0x37FC8000, 0x37FD0000, 0x37FD8000, 0x37FE0000, 0x37FE8000, 0x37FF0000, 0x37FF8000,\n  0x38000000, 0x38004000, 0x38008000, 0x3800C000, 0x38010000, 0x38014000, 0x38018000, 0x3801C000, 0x38020000, 0x38024000, 0x38028000, 0x3802C000, 0x38030000, 0x38034000, 0x38038000, 0x3803C000,\n  0x38040000, 0x38044000, 0x38048000, 0x3804C000, 0x38050000, 0x38054000, 0x38058000, 0x3805C000, 0x38060000, 0x38064000, 0x38068000, 0x3806C000, 0x38070000, 0x38074000, 0x38078000, 0x3807C000,\n  0x38080000, 0x38084000, 0x38088000, 0x3808C000, 0x38090000, 0x38094000, 0x38098000, 0x3809C000, 0x380A0000, 0x380A4000, 0x380A8000, 0x380AC000, 0x380B0000, 0x380B4000, 0x380B8000, 0x380BC000,\n  0x380C0000, 0x380C4000, 0x380C8000, 0x380CC000, 0x380D0000, 0x380D4000, 0x380D8000, 0x380DC000, 0x380E0000, 0x380E4000, 0x380E8000, 0x380EC000, 0x380F0000, 0x380F4000, 0x380F8000, 0x380FC000,\n  0x38100000, 0x38104000, 0x38108000, 0x3810C000, 0x38110000, 0x38114000, 0x38118000, 0x3811C000, 0x38120000, 0x38124000, 0x38128000, 0x3812C000, 0x38130000, 0x38134000, 0x38138000, 0x3813C000,\n  0x38140000, 0x38144000, 0x38148000, 0x3814C000, 0x38150000, 0x38154000, 0x38158000, 0x3815C000, 0x38160000, 0x38164000, 0x38168000, 0x3816C000, 0x38170000, 0x38174000, 0x38178000, 0x3817C000,\n  0x38180000, 0x38184000, 0x38188000, 0x3818C000, 0x38190000, 0x38194000, 0x38198000, 0x3819C000, 0x381A0000, 0x381A4000, 0x381A8000, 0x381AC000, 0x381B0000, 0x381B4000, 0x381B8000, 0x381BC000,\n  0x381C0000, 0x381C4000, 0x381C8000, 0x381CC000, 0x381D0000, 0x381D4000, 0x381D8000, 0x381DC000, 0x381E0000, 0x381E4000, 0x381E8000, 0x381EC000, 0x381F0000, 0x381F4000, 0x381F8000, 0x381FC000,\n  0x38200000, 0x38204000, 0x38208000, 0x3820C000, 0x38210000, 0x38214000, 0x38218000, 0x3821C000, 0x38220000, 0x38224000, 0x",
                                    "38228000, 0x3822C000, 0x38230000, 0x38234000, 0x38238000, 0x3823C000,\n  0x38240000, 0x38244000, 0x38248000, 0x3824C000, 0x38250000, 0x38254000, 0x38258000, 0x3825C000, 0x38260000, 0x38264000, 0x38268000, 0x3826C000, 0x38270000, 0x38274000, 0x38278000, 0x3827C000,\n  0x38280000, 0x38284000, 0x38288000, 0x3828C000, 0x38290000, 0x38294000, 0x38298000, 0x3829C000, 0x382A0000, 0x382A4000, 0x382A8000, 0x382AC000, 0x382B0000, 0x382B4000, 0x382B8000, 0x382BC000,\n  0x382C0000, 0x382C4000, 0x382C8000, 0x382CC000, 0x382D0000, 0x382D4000, 0x382D8000, 0x382DC000, 0x382E0000, 0x382E4000, 0x382E8000, 0x382EC000, 0x382F0000, 0x382F4000, 0x382F8000, 0x382FC000,\n  0x38300000, 0x38304000, 0x38308000, 0x3830C000, 0x38310000, 0x38314000, 0x38318000, 0x3831C000, 0x38320000, 0x38324000, 0x38328000, 0x3832C000, 0x38330000, 0x38334000, 0x38338000, 0x3833C000,\n  0x38340000, 0x38344000, 0x38348000, 0x3834C000, 0x38350000, 0x38354000, 0x38358000, 0x3835C000, 0x38360000, 0x38364000, 0x38368000, 0x3836C000, 0x38370000, 0x38374000, 0x38378000, 0x3837C000,\n  0x38380000, 0x38384000, 0x38388000, 0x3838C000, 0x38390000, 0x38394000, 0x38398000, 0x3839C000, 0x383A0000, 0x383A4000, 0x383A8000, 0x383AC000, 0x383B0000, 0x383B4000, 0x383B8000, 0x383BC000,\n  0x383C0000, 0x383C4000, 0x383C8000, 0x383CC000, 0x383D0000, 0x383D4000, 0x383D8000, 0x383DC000, 0x383E0000, 0x383E4000, 0x383E8000, 0x383EC000, 0x383F0000, 0x383F4000, 0x383F8000, 0x383FC000,\n  0x38400000, 0x38404000, 0x38408000, 0x3840C000, 0x38410000, 0x38414000, 0x38418000, 0x3841C000, 0x38420000, 0x38424000, 0x38428000, 0x3842C000, 0x38430000, 0x38434000, 0x38438000, 0x3843C000,\n  0x38440000, 0x38444000, 0x38448000, 0x3844C000, 0x38450000, 0x38454000, 0x38458000, 0x3845C000, 0x38460000, 0x38464000, 0x38468000, 0x3846C000, 0x38470000, 0x38474000, 0x38478000, 0x3847C000,\n  0x38480000, 0x38484000, 0x38488000, 0x3848C000, 0x38490000, 0x38494000, 0x38498000, 0x3849C000, 0x384A0000, 0x384A4000, 0x384A8000, 0x384AC000, 0x384B0000, 0x384B4000, 0x384B8000, 0x", "384BC000,\n  0x384C0000, 0x384C4000, 0x384C8000, 0x384CC000, 0x384D0000, 0x384D4000, 0x384D8000, 0x384DC000, 0x384E0000, 0x384E4000, 0x384E8000, 0x384EC000, 0x384F0000, 0x384F4000, 0x384F8000, 0x384FC000,\n  0x38500000, 0x38504000, 0x38508000, 0x3850C000, 0x38510000, 0x38514000, 0x38518000, 0x3851C000, 0x38520000, 0x38524000, 0x38528000, 0x3852C000, 0x38530000, 0x38534000, 0x38538000, 0x3853C000,\n  0x38540000, 0x38544000, 0x38548000, 0x3854C000, 0x38550000, 0x38554000, 0x38558000, 0x3855C000, 0x38560000, 0x38564000, 0x38568000, 0x3856C000, 0x38570000, 0x38574000, 0x38578000, 0x3857C000,\n  0x38580000, 0x38584000, 0x38588000, 0x3858C000, 0x38590000, 0x38594000, 0x38598000, 0x3859C000, 0x385A0000, 0x385A4000, 0x385A8000, 0x385AC000, 0x385B0000, 0x385B4000, 0x385B8000, 0x385BC000,\n  0x385C0000, 0x385C4000, 0x385C8000, 0x385CC000, 0x385D0000, 0x385D4000, 0x385D8000, 0x385DC000, 0x385E0000, 0x385E4000, 0x385E8000, 0x385EC000, 0x385F0000, 0x385F4000, 0x385F8000, 0x385FC000,\n  0x38600000, 0x38604000, 0x38608000, 0x3860C000, 0x38610000, 0x38614000, 0x38618000, 0x3861C000, 0x38620000, 0x38624000, 0x38628000, 0x3862C000, 0x38630000, 0x38634000, 0x38638000, 0x3863C000,\n  0x38640000, 0x38644000, 0x38648000, 0x3864C000, 0x38650000, 0x38654000, 0x38658000, 0x3865C000, 0x38660000, 0x38664000, 0x38668000, 0x3866C000, 0x38670000, 0x38674000, 0x38678000, 0x3867C000,\n  0x38680000, 0x38684000, 0x38688000, 0x3868C000, 0x38690000, 0x38694000, 0x38698000, 0x3869C000, 0x386A0000, 0x386A4000, 0x386A8000, 0x386AC000, 0x386B0000, 0x386B4000, 0x386B8000, 0x386BC000,\n  0x386C0000, 0x386C4000, 0x386C8000, 0x386CC000, 0x386D0000, 0x386D4000, 0x386D8000, 0x386DC000, 0x386E0000, 0x386E4000, 0x386E8000, 0x386EC000, 0x386F0000, 0x386F4000, 0x386F8000, 0x386FC000,\n  0x38700000, 0x38704000, 0x38708000, 0x3870C000, 0x38710000, 0x38714000, 0x38718000, 0x3871C000, 0x38720000, 0x38724000, 0x38728000, 0x3872C000, 0x38730000, 0x38734000, 0x38738000, 0x3873C000,\n  0x38740000, 0x38744000, 0x38748000, 0x3874C000, ", "0x38750000, 0x38754000, 0x38758000, 0x3875C000, 0x38760000, 0x38764000, 0x38768000, 0x3876C000, 0x38770000, 0x38774000, 0x38778000, 0x3877C000,\n  0x38780000, 0x38784000, 0x38788000, 0x3878C000, 0x38790000, 0x38794000, 0x38798000, 0x3879C000, 0x387A0000, 0x387A4000, 0x387A8000, 0x387AC000, 0x387B0000, 0x387B4000, 0x387B8000, 0x387BC000,\n  0x387C0000, 0x387C4000, 0x387C8000, 0x387CC000, 0x387D0000, 0x387D4000, 0x387D8000, 0x387DC000, 0x387E0000, 0x387E4000, 0x387E8000, 0x387EC000, 0x387F0000, 0x387F4000, 0x387F8000, 0x387FC000,\n  0x38000000, 0x38002000, 0x38004000, 0x38006000, 0x38008000, 0x3800A000, 0x3800C000, 0x3800E000, 0x38010000, 0x38012000, 0x38014000, 0x38016000, 0x38018000, 0x3801A000, 0x3801C000, 0x3801E000,\n  0x38020000, 0x38022000, 0x38024000, 0x38026000, 0x38028000, 0x3802A000, 0x3802C000, 0x3802E000, 0x38030000, 0x38032000, 0x38034000, 0x38036000, 0x38038000, 0x3803A000, 0x3803C000, 0x3803E000,\n  0x38040000, 0x38042000, 0x38044000, 0x38046000, 0x38048000, 0x3804A000, 0x3804C000, 0x3804E000, 0x38050000, 0x38052000, 0x38054000, 0x38056000, 0x38058000, 0x3805A000, 0x3805C000, 0x3805E000,\n  0x38060000, 0x38062000, 0x38064000, 0x38066000, 0x38068000, 0x3806A000, 0x3806C000, 0x3806E000, 0x38070000, 0x38072000, 0x38074000, 0x38076000, 0x38078000, 0x3807A000, 0x3807C000, 0x3807E000,\n  0x38080000, 0x38082000, 0x38084000, 0x38086000, 0x38088000, 0x3808A000, 0x3808C000, 0x3808E000, 0x38090000, 0x38092000, 0x38094000, 0x38096000, 0x38098000, 0x3809A000, 0x3809C000, 0x3809E000,\n  0x380A0000, 0x380A2000, 0x380A4000, 0x380A6000, 0x380A8000, 0x380AA000, 0x380AC000, 0x380AE000, 0x380B0000, 0x380B2000, 0x380B4000, 0x380B6000, 0x380B8000, 0x380BA000, 0x380BC000, 0x380BE000,\n  0x380C0000, 0x380C2000, 0x380C4000, 0x380C6000, 0x380C8000, 0x380CA000, 0x380CC000, 0x380CE000, 0x380D0000, 0x380D2000, 0x380D4000, 0x380D6000, 0x380D8000, 0x380DA000, 0x380DC000, 0x380DE000,\n  0x380E0000, 0x380E2000, 0x380E4000, 0x380E6000, 0x380E8000, 0x380EA000, 0x380EC000, 0x380EE000, 0x380F0000, ",
                                    "0x380F2000, 0x380F4000, 0x380F6000, 0x380F8000, 0x380FA000, 0x380FC000, 0x380FE000,\n  0x38100000, 0x38102000, 0x38104000, 0x38106000, 0x38108000, 0x3810A000, 0x3810C000, 0x3810E000, 0x38110000, 0x38112000, 0x38114000, 0x38116000, 0x38118000, 0x3811A000, 0x3811C000, 0x3811E000,\n  0x38120000, 0x38122000, 0x38124000, 0x38126000, 0x38128000, 0x3812A000, 0x3812C000, 0x3812E000, 0x38130000, 0x38132000, 0x38134000, 0x38136000, 0x38138000, 0x3813A000, 0x3813C000, 0x3813E000,\n  0x38140000, 0x38142000, 0x38144000, 0x38146000, 0x38148000, 0x3814A000, 0x3814C000, 0x3814E000, 0x38150000, 0x38152000, 0x38154000, 0x38156000, 0x38158000, 0x3815A000, 0x3815C000, 0x3815E000,\n  0x38160000, 0x38162000, 0x38164000, 0x38166000, 0x38168000, 0x3816A000, 0x3816C000, 0x3816E000, 0x38170000, 0x38172000, 0x38174000, 0x38176000, 0x38178000, 0x3817A000, 0x3817C000, 0x3817E000,\n  0x38180000, 0x38182000, 0x38184000, 0x38186000, 0x38188000, 0x3818A000, 0x3818C000, 0x3818E000, 0x38190000, 0x38192000, 0x38194000, 0x38196000, 0x38198000, 0x3819A000, 0x3819C000, 0x3819E000,\n  0x381A0000, 0x381A2000, 0x381A4000, 0x381A6000, 0x381A8000, 0x381AA000, 0x381AC000, 0x381AE000, 0x381B0000, 0x381B2000, 0x381B4000, 0x381B6000, 0x381B8000, 0x381BA000, 0x381BC000, 0x381BE000,\n  0x381C0000, 0x381C2000, 0x381C4000, 0x381C6000, 0x381C8000, 0x381CA000, 0x381CC000, 0x381CE000, 0x381D0000, 0x381D2000, 0x381D4000, 0x381D6000, 0x381D8000, 0x381DA000, 0x381DC000, 0x381DE000,\n  0x381E0000, 0x381E2000, 0x381E4000, 0x381E6000, 0x381E8000, 0x381EA000, 0x381EC000, 0x381EE000, 0x381F0000, 0x381F2000, 0x381F4000, 0x381F6000, 0x381F8000, 0x381FA000, 0x381FC000, 0x381FE000,\n  0x38200000, 0x38202000, 0x38204000, 0x38206000, 0x38208000, 0x3820A000, 0x3820C000, 0x3820E000, 0x38210000, 0x38212000, 0x38214000, 0x38216000, 0x38218000, 0x3821A000, 0x3821C000, 0x3821E000,\n  0x38220000, 0x38222000, 0x38224000, 0x38226000, 0x38228000, 0x3822A000, 0x3822C000, 0x3822E000, 0x38230000, 0x38232000, 0x38234000, 0x38236000, 0x38238000, 0x3823A000, ", "0x3823C000, 0x3823E000,\n  0x38240000, 0x38242000, 0x38244000, 0x38246000, 0x38248000, 0x3824A000, 0x3824C000, 0x3824E000, 0x38250000, 0x38252000, 0x38254000, 0x38256000, 0x38258000, 0x3825A000, 0x3825C000, 0x3825E000,\n  0x38260000, 0x38262000, 0x38264000, 0x38266000, 0x38268000, 0x3826A000, 0x3826C000, 0x3826E000, 0x38270000, 0x38272000, 0x38274000, 0x38276000, 0x38278000, 0x3827A000, 0x3827C000, 0x3827E000,\n  0x38280000, 0x38282000, 0x38284000, 0x38286000, 0x38288000, 0x3828A000, 0x3828C000, 0x3828E000, 0x38290000, 0x38292000, 0x38294000, 0x38296000, 0x38298000, 0x3829A000, 0x3829C000, 0x3829E000,\n  0x382A0000, 0x382A2000, 0x382A4000, 0x382A6000, 0x382A8000, 0x382AA000, 0x382AC000, 0x382AE000, 0x382B0000, 0x382B2000, 0x382B4000, 0x382B6000, 0x382B8000, 0x382BA000, 0x382BC000, 0x382BE000,\n  0x382C0000, 0x382C2000, 0x382C4000, 0x382C6000, 0x382C8000, 0x382CA000, 0x382CC000, 0x382CE000, 0x382D0000, 0x382D2000, 0x382D4000, 0x382D6000, 0x382D8000, 0x382DA000, 0x382DC000, 0x382DE000,\n  0x382E0000, 0x382E2000, 0x382E4000, 0x382E6000, 0x382E8000, 0x382EA000, 0x382EC000, 0x382EE000, 0x382F0000, 0x382F2000, 0x382F4000, 0x382F6000, 0x382F8000, 0x382FA000, 0x382FC000, 0x382FE000,\n  0x38300000, 0x38302000, 0x38304000, 0x38306000, 0x38308000, 0x3830A000, 0x3830C000, 0x3830E000, 0x38310000, 0x38312000, 0x38314000, 0x38316000, 0x38318000, 0x3831A000, 0x3831C000, 0x3831E000,\n  0x38320000, 0x38322000, 0x38324000, 0x38326000, 0x38328000, 0x3832A000, 0x3832C000, 0x3832E000, 0x38330000, 0x38332000, 0x38334000, 0x38336000, 0x38338000, 0x3833A000, 0x3833C000, 0x3833E000,\n  0x38340000, 0x38342000, 0x38344000, 0x38346000, 0x38348000, 0x3834A000, 0x3834C000, 0x3834E000, 0x38350000, 0x38352000, 0x38354000, 0x38356000, 0x38358000, 0x3835A000, 0x3835C000, 0x3835E000,\n  0x38360000, 0x38362000, 0x38364000, 0x38366000, 0x38368000, 0x3836A000, 0x3836C000, 0x3836E000, 0x38370000, 0x38372000, 0x38374000, 0x38376000, 0x38378000, 0x3837A000, 0x3837C000, 0x3837E000,\n  0x38380000, 0x38382000, 0x38384000", ", 0x38386000, 0x38388000, 0x3838A000, 0x3838C000, 0x3838E000, 0x38390000, 0x38392000, 0x38394000, 0x38396000, 0x38398000, 0x3839A000, 0x3839C000, 0x3839E000,\n  0x383A0000, 0x383A2000, 0x383A4000, 0x383A6000, 0x383A8000, 0x383AA000, 0x383AC000, 0x383AE000, 0x383B0000, 0x383B2000, 0x383B4000, 0x383B6000, 0x383B8000, 0x383BA000, 0x383BC000, 0x383BE000,\n  0x383C0000, 0x383C2000, 0x383C4000, 0x383C6000, 0x383C8000, 0x383CA000, 0x383CC000, 0x383CE000, 0x383D0000, 0x383D2000, 0x383D4000, 0x383D6000, 0x383D8000, 0x383DA000, 0x383DC000, 0x383DE000,\n  0x383E0000, 0x383E2000, 0x383E4000, 0x383E6000, 0x383E8000, 0x383EA000, 0x383EC000, 0x383EE000, 0x383F0000, 0x383F2000, 0x383F4000, 0x383F6000, 0x383F8000, 0x383FA000, 0x383FC000, 0x383FE000,\n  0x38400000, 0x38402000, 0x38404000, 0x38406000, 0x38408000, 0x3840A000, 0x3840C000, 0x3840E000, 0x38410000, 0x38412000, 0x38414000, 0x38416000, 0x38418000, 0x3841A000, 0x3841C000, 0x3841E000,\n  0x38420000, 0x38422000, 0x38424000, 0x38426000, 0x38428000, 0x3842A000, 0x3842C000, 0x3842E000, 0x38430000, 0x38432000, 0x38434000, 0x38436000, 0x38438000, 0x3843A000, 0x3843C000, 0x3843E000,\n  0x38440000, 0x38442000, 0x38444000, 0x38446000, 0x38448000, 0x3844A000, 0x3844C000, 0x3844E000, 0x38450000, 0x38452000, 0x38454000, 0x38456000, 0x38458000, 0x3845A000, 0x3845C000, 0x3845E000,\n  0x38460000, 0x38462000, 0x38464000, 0x38466000, 0x38468000, 0x3846A000, 0x3846C000, 0x3846E000, 0x38470000, 0x38472000, 0x38474000, 0x38476000, 0x38478000, 0x3847A000, 0x3847C000, 0x3847E000,\n  0x38480000, 0x38482000, 0x38484000, 0x38486000, 0x38488000, 0x3848A000, 0x3848C000, 0x3848E000, 0x38490000, 0x38492000, 0x38494000, 0x38496000, 0x38498000, 0x3849A000, 0x3849C000, 0x3849E000,\n  0x384A0000, 0x384A2000, 0x384A4000, 0x384A6000, 0x384A8000, 0x384AA000, 0x384AC000, 0x384AE000, 0x384B0000, 0x384B2000, 0x384B4000, 0x384B6000, 0x384B8000, 0x384BA000, 0x384BC000, 0x384BE000,\n  0x384C0000, 0x384C2000, 0x384C4000, 0x384C6000, 0x384C8000, 0x384CA000, 0x384CC000, 0x384CE000",
                                    ", 0x384D0000, 0x384D2000, 0x384D4000, 0x384D6000, 0x384D8000, 0x384DA000, 0x384DC000, 0x384DE000,\n  0x384E0000, 0x384E2000, 0x384E4000, 0x384E6000, 0x384E8000, 0x384EA000, 0x384EC000, 0x384EE000, 0x384F0000, 0x384F2000, 0x384F4000, 0x384F6000, 0x384F8000, 0x384FA000, 0x384FC000, 0x384FE000,\n  0x38500000, 0x38502000, 0x38504000, 0x38506000, 0x38508000, 0x3850A000, 0x3850C000, 0x3850E000, 0x38510000, 0x38512000, 0x38514000, 0x38516000, 0x38518000, 0x3851A000, 0x3851C000, 0x3851E000,\n  0x38520000, 0x38522000, 0x38524000, 0x38526000, 0x38528000, 0x3852A000, 0x3852C000, 0x3852E000, 0x38530000, 0x38532000, 0x38534000, 0x38536000, 0x38538000, 0x3853A000, 0x3853C000, 0x3853E000,\n  0x38540000, 0x38542000, 0x38544000, 0x38546000, 0x38548000, 0x3854A000, 0x3854C000, 0x3854E000, 0x38550000, 0x38552000, 0x38554000, 0x38556000, 0x38558000, 0x3855A000, 0x3855C000, 0x3855E000,\n  0x38560000, 0x38562000, 0x38564000, 0x38566000, 0x38568000, 0x3856A000, 0x3856C000, 0x3856E000, 0x38570000, 0x38572000, 0x38574000, 0x38576000, 0x38578000, 0x3857A000, 0x3857C000, 0x3857E000,\n  0x38580000, 0x38582000, 0x38584000, 0x38586000, 0x38588000, 0x3858A000, 0x3858C000, 0x3858E000, 0x38590000, 0x38592000, 0x38594000, 0x38596000, 0x38598000, 0x3859A000, 0x3859C000, 0x3859E000,\n  0x385A0000, 0x385A2000, 0x385A4000, 0x385A6000, 0x385A8000, 0x385AA000, 0x385AC000, 0x385AE000, 0x385B0000, 0x385B2000, 0x385B4000, 0x385B6000, 0x385B8000, 0x385BA000, 0x385BC000, 0x385BE000,\n  0x385C0000, 0x385C2000, 0x385C4000, 0x385C6000, 0x385C8000, 0x385CA000, 0x385CC000, 0x385CE000, 0x385D0000, 0x385D2000, 0x385D4000, 0x385D6000, 0x385D8000, 0x385DA000, 0x385DC000, 0x385DE000,\n  0x385E0000, 0x385E2000, 0x385E4000, 0x385E6000, 0x385E8000, 0x385EA000, 0x385EC000, 0x385EE000, 0x385F0000, 0x385F2000, 0x385F4000, 0x385F6000, 0x385F8000, 0x385FA000, 0x385FC000, 0x385FE000,\n  0x38600000, 0x38602000, 0x38604000, 0x38606000, 0x38608000, 0x3860A000, 0x3860C000, 0x3860E000, 0x38610000, 0x38612000, 0x38614000, 0x38616000, 0x38618000", ", 0x3861A000, 0x3861C000, 0x3861E000,\n  0x38620000, 0x38622000, 0x38624000, 0x38626000, 0x38628000, 0x3862A000, 0x3862C000, 0x3862E000, 0x38630000, 0x38632000, 0x38634000, 0x38636000, 0x38638000, 0x3863A000, 0x3863C000, 0x3863E000,\n  0x38640000, 0x38642000, 0x38644000, 0x38646000, 0x38648000, 0x3864A000, 0x3864C000, 0x3864E000, 0x38650000, 0x38652000, 0x38654000, 0x38656000, 0x38658000, 0x3865A000, 0x3865C000, 0x3865E000,\n  0x38660000, 0x38662000, 0x38664000, 0x38666000, 0x38668000, 0x3866A000, 0x3866C000, 0x3866E000, 0x38670000, 0x38672000, 0x38674000, 0x38676000, 0x38678000, 0x3867A000, 0x3867C000, 0x3867E000,\n  0x38680000, 0x38682000, 0x38684000, 0x38686000, 0x38688000, 0x3868A000, 0x3868C000, 0x3868E000, 0x38690000, 0x38692000, 0x38694000, 0x38696000, 0x38698000, 0x3869A000, 0x3869C000, 0x3869E000,\n  0x386A0000, 0x386A2000, 0x386A4000, 0x386A6000, 0x386A8000, 0x386AA000, 0x386AC000, 0x386AE000, 0x386B0000, 0x386B2000, 0x386B4000, 0x386B6000, 0x386B8000, 0x386BA000, 0x386BC000, 0x386BE000,\n  0x386C0000, 0x386C2000, 0x386C4000, 0x386C6000, 0x386C8000, 0x386CA000, 0x386CC000, 0x386CE000, 0x386D0000, 0x386D2000, 0x386D4000, 0x386D6000, 0x386D8000, 0x386DA000, 0x386DC000, 0x386DE000,\n  0x386E0000, 0x386E2000, 0x386E4000, 0x386E6000, 0x386E8000, 0x386EA000, 0x386EC000, 0x386EE000, 0x386F0000, 0x386F2000, 0x386F4000, 0x386F6000, 0x386F8000, 0x386FA000, 0x386FC000, 0x386FE000,\n  0x38700000, 0x38702000, 0x38704000, 0x38706000, 0x38708000, 0x3870A000, 0x3870C000, 0x3870E000, 0x38710000, 0x38712000, 0x38714000, 0x38716000, 0x38718000, 0x3871A000, 0x3871C000, 0x3871E000,\n  0x38720000, 0x38722000, 0x38724000, 0x38726000, 0x38728000, 0x3872A000, 0x3872C000, 0x3872E000, 0x38730000, 0x38732000, 0x38734000, 0x38736000, 0x38738000, 0x3873A000, 0x3873C000, 0x3873E000,\n  0x38740000, 0x38742000, 0x38744000, 0x38746000, 0x38748000, 0x3874A000, 0x3874C000, 0x3874E000, 0x38750000, 0x38752000, 0x38754000, 0x38756000, 0x38758000, 0x3875A000, 0x3875C000, 0x3875E000,\n  0x38760000, 0x387620", "00, 0x38764000, 0x38766000, 0x38768000, 0x3876A000, 0x3876C000, 0x3876E000, 0x38770000, 0x38772000, 0x38774000, 0x38776000, 0x38778000, 0x3877A000, 0x3877C000, 0x3877E000,\n  0x38780000, 0x38782000, 0x38784000, 0x38786000, 0x38788000, 0x3878A000, 0x3878C000, 0x3878E000, 0x38790000, 0x38792000, 0x38794000, 0x38796000, 0x38798000, 0x3879A000, 0x3879C000, 0x3879E000,\n  0x387A0000, 0x387A2000, 0x387A4000, 0x387A6000, 0x387A8000, 0x387AA000, 0x387AC000, 0x387AE000, 0x387B0000, 0x387B2000, 0x387B4000, 0x387B6000, 0x387B8000, 0x387BA000, 0x387BC000, 0x387BE000,\n  0x387C0000, 0x387C2000, 0x387C4000, 0x387C6000, 0x387C8000, 0x387CA000, 0x387CC000, 0x387CE000, 0x387D0000, 0x387D2000, 0x387D4000, 0x387D6000, 0x387D8000, 0x387DA000, 0x387DC000, 0x387DE000,\n  0x387E0000, 0x387E2000, 0x387E4000, 0x387E6000, 0x387E8000, 0x387EA000, 0x387EC000, 0x387EE000, 0x387F0000, 0x387F2000, 0x387F4000, 0x387F6000, 0x387F8000, 0x387FA000, 0x387FC000, 0x387FE000 };\n__constant static const uint32_t exponent_table[64] = {\n  0x00000000, 0x00800000, 0x01000000, 0x01800000, 0x02000000, 0x02800000, 0x03000000, 0x03800000, 0x04000000, 0x04800000, 0x05000000, 0x05800000, 0x06000000, 0x06800000, 0x07000000, 0x07800000,\n  0x08000000, 0x08800000, 0x09000000, 0x09800000, 0x0A000000, 0x0A800000, 0x0B000000, 0x0B800000, 0x0C000000, 0x0C800000, 0x0D000000, 0x0D800000, 0x0E000000, 0x0E800000, 0x0F000000, 0x47800000,\n  0x80000000, 0x80800000, 0x81000000, 0x81800000, 0x82000000, 0x82800000, 0x83000000, 0x83800000, 0x84000000, 0x84800000, 0x85000000, 0x85800000, 0x86000000, 0x86800000, 0x87000000, 0x87800000,\n  0x88000000, 0x88800000, 0x89000000, 0x89800000, 0x8A000000, 0x8A800000, 0x8B000000, 0x8B800000, 0x8C000000, 0x8C800000, 0x8D000000, 0x8D800000, 0x8E000000, 0x8E800000, 0x8F000000, 0xC7800000 };\n__constant static const unsigned short offset_table[64] = {\n  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1",
                                    "024, 1024, 1024, 1024, 1024, 1024,\n  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024 };\n\nSCALAR_FUN_ATTR uint16_t float2halfbits(float value) {\n  union { float x; uint32_t y; } u;\n  u.x = value;\n  uint32_t bits = u.y;\n\n  uint16_t hbits = base_table[bits>>23] + (uint16_t)((bits&0x7FFFFF)>>shift_table[bits>>23]);;\n\n  return hbits;\n}\n\nSCALAR_FUN_ATTR float halfbits2float(uint16_t value) {\n  uint32_t bits = mantissa_table[offset_table[value>>10]+(value&0x3FF)] + exponent_table[value>>10];\n\n  union { uint32_t x; float y; } u;\n  u.x = bits;\n  return u.y;\n}\n\nSCALAR_FUN_ATTR uint16_t halfbitsnextafter(uint16_t from, uint16_t to) {\n  int fabs = from & 0x7FFF, tabs = to & 0x7FFF;\n  if(fabs > 0x7C00 || tabs > 0x7C00) {\n    return ((from&0x7FFF)>0x7C00) ? (from|0x200) : (to|0x200);\n  }\n  if(from == to || !(fabs|tabs)) {\n    return to;\n  }\n  if(!fabs) {\n    return (to&0x8000)+1;\n  }\n  unsigned int out =\n    from +\n    (((from>>15)^(unsigned int)((from^(0x8000|(0x8000-(from>>15))))<(to^(0x8000|(0x8000-(to>>15))))))<<1)\n    - 1;\n  return out;\n}\n\n// End of half.h.\n// Start of scalar.h.\n\n// Implementation of the primitive scalar operations.  Very\n// repetitive.  This code is inserted directly into both CUDA and\n// OpenCL programs, as well as the CPU code, so it has some #ifdefs to\n// work everywhere.  Some operations are defined as macros because\n// this allows us to use them as constant expressions in things like\n// array sizes and static initialisers.\n\n// Some of the #ifdefs are because OpenCL uses type-generic functions\n// for some operations (e.g. sqrt), while C and CUDA sensibly use\n// distinct functions for different precisions (e.g. sqrtf() and\n// sqrt()).  This is quite annoying.  Due to C's unfortunate casting\n// rules, it is also really easy to accidentally implement\n// floating-point functions in the wrong precision, so be careful.\n\n/", "/ Double-precision definitions are only included if the preprocessor\n// macro FUTHARK_F64_ENABLED is set.\n\nSCALAR_FUN_ATTR int32_t futrts_to_bits32(float x);\nSCALAR_FUN_ATTR float futrts_from_bits32(int32_t x);\n\nSCALAR_FUN_ATTR uint8_t add8(uint8_t x, uint8_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint16_t add16(uint16_t x, uint16_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint32_t add32(uint32_t x, uint32_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint64_t add64(uint64_t x, uint64_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint8_t sub8(uint8_t x, uint8_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint16_t sub16(uint16_t x, uint16_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint32_t sub32(uint32_t x, uint32_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint64_t sub64(uint64_t x, uint64_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint8_t mul8(uint8_t x, uint8_t y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR uint16_t mul16(uint16_t x, uint16_t y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR uint32_t mul32(uint32_t x, uint32_t y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR uint64_t mul64(uint64_t x, uint64_t y) {\n  return x * y;\n}\n\n#if ISPC\n\nSCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {\n  // This strange pattern is used to prevent the ISPC compiler from\n  // causing SIGFPEs and bogus results on divisions where inactive lanes\n  // have 0-valued divisors. It ensures that any inactive lane instead\n  // has a divisor of 1. https://github.com/ispc/ispc/issues/2292\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {\n  uint", "8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALA",
                                    "R_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int8_t q = x / ys;\n  int8_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int16_t q = x / ys;\n  int16_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  int32_t q = x / ys;\n  int32_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int64_t q = x / ys;\n  int64_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {\n  return sdiv8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {\n  return sdiv16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y)", " {\n  return sdiv32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {\n  return sdiv64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int8_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int16_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int32_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int64_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : sdiv8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : sdiv16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : sdiv32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : sdiv64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {\n  return sdiv_safe8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {\n  return sdiv_safe16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {\n  return sdiv_safe32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {\n  return sdiv_safe64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : smod8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : smod16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) ", "{\n  return y == 0 ? 0 : smod32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : smod64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  ",
                                    "foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\n#else\n\nSCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {\n  return", " y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {\n  int8_t q = x / y;\n  int8_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {\n  int16_t q = x / y;\n  int16_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {\n  int32_t q = x / y;\n  int32_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {\n  int64_t q = x / y;\n  int64_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {\n  return sdiv8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {\n  return sdiv16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {\n  return sdiv32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {\n  return sdiv64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {\n  int8_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {\n  int16_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {\n  int32_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {\n  int64_t r = ", "x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : sdiv8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : sdiv16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : sdiv32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : sdiv64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {\n  return sdiv_safe8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {\n  return sdiv_safe16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {\n  return sdiv_safe32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {\n  return sdiv_safe64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : smod8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : smod16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : smod32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : smod64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t ",
                                    "y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\n#endif\n\nSCALAR_FUN_ATTR int8_t smin8(int8_t x, int8_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int16_t smin16(int16_t x, int16_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int32_t smin32(int32_t x, int32_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int64_t smin64(int64_t x, int64_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint8_t umin8(uint8_t x, uint8_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint16_t umin16(uint16_t x, uint16_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint32_t umin32(uint32_t x, uint32_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint64_t umin64(uint64_t x, uint64_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int8_t smax8(int8_t x, int8_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR int16_t smax16(int16_t x, int16_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR int32_t smax32(int32_t x, int32_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR int64_t smax64(int64_t x, int64_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint8_t umax8(uint8_t x, uint8_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint16_t umax16(uint16_t x, uint16_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint32_t umax32(uint32_t x, uint32_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint64_t umax64(uint64_t x, uint64_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint8_t shl8(uint8_t x, uint8_t y) {\n  return (uint8_t)(x << y);\n}\n\nS", "CALAR_FUN_ATTR uint16_t shl16(uint16_t x, uint16_t y) {\n  return (uint16_t)(x << y);\n}\n\nSCALAR_FUN_ATTR uint32_t shl32(uint32_t x, uint32_t y) {\n  return x << y;\n}\n\nSCALAR_FUN_ATTR uint64_t shl64(uint64_t x, uint64_t y) {\n  return x << y;\n}\n\nSCALAR_FUN_ATTR uint8_t lshr8(uint8_t x, uint8_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint16_t lshr16(uint16_t x, uint16_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint32_t lshr32(uint32_t x, uint32_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint64_t lshr64(uint64_t x, uint64_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int8_t ashr8(int8_t x, int8_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int16_t ashr16(int16_t x, int16_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int32_t ashr32(int32_t x, int32_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int64_t ashr64(int64_t x, int64_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint8_t and8(uint8_t x, uint8_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint16_t and16(uint16_t x, uint16_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint32_t and32(uint32_t x, uint32_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint64_t and64(uint64_t x, uint64_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint8_t or8(uint8_t x, uint8_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint16_t or16(uint16_t x, uint16_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint32_t or32(uint32_t x, uint32_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint64_t or64(uint64_t x, uint64_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint8_t xor8(uint8_t x, uint8_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR uint16_t xor16(uint16_t x, uint16_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR uint32_t xor32(uint32_t x, uint32_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR uint64_t xor64(uint64_t x, uint64_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR bool ult8(uint8_t x, uint8_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ult16(uint16_t x, uint16_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ult32(uint32_t x, uint32_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ult64(uint64_t x, uint64", "_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ule8(uint8_t x, uint8_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool ule16(uint16_t x, uint16_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool ule32(uint32_t x, uint32_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool ule64(uint64_t x, uint64_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool slt8(int8_t x, int8_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool slt16(int16_t x, int16_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool slt32(int32_t x, int32_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool slt64(int64_t x, int64_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool sle8(int8_t x, int8_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool sle16(int16_t x, int16_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool sle32(int32_t x, int32_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool sle64(int64_t x, int64_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR uint8_t pow8(uint8_t x, uint8_t y) {\n  uint8_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uint16_t pow16(uint16_t x, uint16_t y) {\n  uint16_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uint32_t pow32(uint32_t x, uint32_t y) {\n  uint32_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uint64_t pow64(uint64_t x, uint64_t y) {\n  uint64_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR bool itob_i8_bool(int8_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR bool itob_i16_bool(int16_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR bool itob_i32_bool(int32_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR bool itob_i64_bool(int64_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR int8_t btoi_bool_i8(bool x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR int16_t btoi_bool_i16(bool x",
                                    ") {\n  return x;\n}\n\nSCALAR_FUN_ATTR int32_t btoi_bool_i32(bool x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR int64_t btoi_bool_i64(bool x) {\n  return x;\n}\n\n#define sext_i8_i8(x) ((int8_t) (int8_t) (x))\n#define sext_i8_i16(x) ((int16_t) (int8_t) (x))\n#define sext_i8_i32(x) ((int32_t) (int8_t) (x))\n#define sext_i8_i64(x) ((int64_t) (int8_t) (x))\n#define sext_i16_i8(x) ((int8_t) (int16_t) (x))\n#define sext_i16_i16(x) ((int16_t) (int16_t) (x))\n#define sext_i16_i32(x) ((int32_t) (int16_t) (x))\n#define sext_i16_i64(x) ((int64_t) (int16_t) (x))\n#define sext_i32_i8(x) ((int8_t) (int32_t) (x))\n#define sext_i32_i16(x) ((int16_t) (int32_t) (x))\n#define sext_i32_i32(x) ((int32_t) (int32_t) (x))\n#define sext_i32_i64(x) ((int64_t) (int32_t) (x))\n#define sext_i64_i8(x) ((int8_t) (int64_t) (x))\n#define sext_i64_i16(x) ((int16_t) (int64_t) (x))\n#define sext_i64_i32(x) ((int32_t) (int64_t) (x))\n#define sext_i64_i64(x) ((int64_t) (int64_t) (x))\n#define zext_i8_i8(x) ((int8_t) (uint8_t) (x))\n#define zext_i8_i16(x) ((int16_t) (uint8_t) (x))\n#define zext_i8_i32(x) ((int32_t) (uint8_t) (x))\n#define zext_i8_i64(x) ((int64_t) (uint8_t) (x))\n#define zext_i16_i8(x) ((int8_t) (uint16_t) (x))\n#define zext_i16_i16(x) ((int16_t) (uint16_t) (x))\n#define zext_i16_i32(x) ((int32_t) (uint16_t) (x))\n#define zext_i16_i64(x) ((int64_t) (uint16_t) (x))\n#define zext_i32_i8(x) ((int8_t) (uint32_t) (x))\n#define zext_i32_i16(x) ((int16_t) (uint32_t) (x))\n#define zext_i32_i32(x) ((int32_t) (uint32_t) (x))\n#define zext_i32_i64(x) ((int64_t) (uint32_t) (x))\n#define zext_i64_i8(x) ((int8_t) (uint64_t) (x))\n#define zext_i64_i16(x) ((int16_t) (uint64_t) (x))\n#define zext_i64_i32(x) ((int32_t) (uint64_t) (x))\n#define zext_i64_i64(x) ((int64_t) (uint64_t) (x))\n\nSCALAR_FUN_ATTR int8_t abs8(int8_t x) {\n  return (int8_t)abs(x);\n}\n\nSCALAR_FUN_ATTR int16_t abs16(int16_t x) {\n  return (int16_t)abs(x);\n}\n\nSCALAR_FUN_ATTR int32_t abs32(int32_t x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR int64_t abs64(int64_t x) {\n#if defined(__OPENCL_VER", "SION__) || defined(ISPC)\n  return abs(x);\n#else\n  return llabs(x);\n#endif\n}\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {\n  return popcount(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {\n  return popcount(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {\n  return popcount(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {\n  return popcount(x);\n}\n#elif defined(__CUDA_ARCH__)\n\nSCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {\n  return __popc(zext_i8_i32(x));\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {\n  return __popc(zext_i16_i32(x));\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {\n  return __popc(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {\n  return __popcll(x);\n}\n\n#else // Not OpenCL or CUDA, but plain C.\n\nSCALAR_FUN_ATTR int32_t futrts_popc8(uint8_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc16(uint16_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc32(uint32_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc64(uint64_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR uint8_t  futrts_umul_hi8 ( uint8_t a,  uint8_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint8_t  futrts_smul_hi8 ( int8_t a,  int8_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return m", "ul_hi(a, b); }\n#elif defined(__CUDA_ARCH__)\nSCALAR_FUN_ATTR  uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return __umulhi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return __umul64hi(a, b); }\nSCALAR_FUN_ATTR  uint8_t futrts_smul_hi8 ( int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return __mulhi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return __mul64hi(a, b); }\n#elif ISPC\nSCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) {\n  uint64_t ah = a >> 32;\n  uint64_t al = a & 0xffffffff;\n  uint64_t bh = b >> 32;\n  uint64_t bl = b & 0xffffffff;\n\n  uint64_t p1 = al * bl;\n  uint64_t p2 = al * bh;\n  uint64_t p3 = ah * bl;\n  uint64_t p4 = ah * bh;\n\n  uint64_t p1h = p1 >> 32;\n  uint64_t p2h = p2 >> 32;\n  uint64_t p3h = p3 >> 32;\n  uint64_t p2l = p2 & 0xffffffff;\n  uint64_t p3l = p3 & 0xffffffff;\n\n  uint64_t l = p1h + p2l + p3l;\n  uint64_t m = (p2 >> 32) + (p3 >> 32);\n  uint64_t h = (l >> 32) + m + p4;\n\n  return h;\n}\nSCALAR_FUN_ATTR  int8_t futrts_smul_hi8 ( int8_t a,  int8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR int",
                                    "32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nSCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) {\n  uint64_t ah = a >> 32;\n  uint64_t al = a & 0xffffffff;\n  uint64_t bh = b >> 32;\n  uint64_t bl = b & 0xffffffff;\n\n  uint64_t p1 =  al * bl;\n  int64_t  p2 = al * bh;\n  int64_t  p3 = ah * bl;\n  uint64_t p4 =  ah * bh;\n\n  uint64_t p1h = p1 >> 32;\n  uint64_t p2h = p2 >> 32;\n  uint64_t p3h = p3 >> 32;\n  uint64_t p2l = p2 & 0xffffffff;\n  uint64_t p3l = p3 & 0xffffffff;\n\n  uint64_t l = p1h + p2l + p3l;\n  uint64_t m = (p2 >> 32) + (p3 >> 32);\n  uint64_t h = (l >> 32) + m + p4;\n\n  return h;\n}\n\n#else // Not OpenCL, ISPC, or CUDA, but plain C.\nSCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return ((__uint128_t)a) * ((__uint128_t)b) >> 64; }\nSCALAR_FUN_ATTR int8_t futrts_smul_hi8(int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }\nSCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }\nSCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((int64_t)a) * ((int64_t)b) >> 32; }\nSCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) { return ((__int128_t)a) * ((__int128_t)b) >> 64; }\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR  uint8_t futrts_umad_hi8 ( uint8_t a,  uint8_t b,  uint8_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t ", "a, uint64_t b, uint64_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR  uint8_t futrts_smad_hi8( int8_t a,  int8_t b,   int8_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return mad_hi(a, b, c); }\n#else // Not OpenCL\n\nSCALAR_FUN_ATTR  uint8_t futrts_umad_hi8( uint8_t a,  uint8_t b,  uint8_t c) { return futrts_umul_hi8(a, b) + c; }\nSCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return futrts_umul_hi16(a, b) + c; }\nSCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return futrts_umul_hi32(a, b) + c; }\nSCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return futrts_umul_hi64(a, b) + c; }\nSCALAR_FUN_ATTR  uint8_t futrts_smad_hi8 ( int8_t a,  int8_t b,  int8_t c) { return futrts_smul_hi8(a, b) + c; }\nSCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return futrts_smul_hi16(a, b) + c; }\nSCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return futrts_smul_hi32(a, b) + c; }\nSCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return futrts_smul_hi64(a, b) + c; }\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  return clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return clz(x);\n}\n\n#elif defined(__CUDA_ARCH__)\n\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return __clz(zext_i8_i32(x)) - 24;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return __clz(zext_i16_i32(x)) - 16;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  retur", "n __clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return __clzll(x);\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return count_leading_zeros((int32_t)(uint8_t)x)-24;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return count_leading_zeros((int32_t)(uint16_t)x)-16;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  return count_leading_zeros(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return count_leading_zeros(x);\n}\n\n#else // Not OpenCL, ISPC or CUDA, but plain C.\n\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return x == 0 ? 8 : __builtin_clz((uint32_t)zext_i8_i32(x)) - 24;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return x == 0 ? 16 : __builtin_clz((uint32_t)zext_i16_i32(x)) - 16;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  return x == 0 ? 32 : __builtin_clz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return x == 0 ? 64 : __builtin_clzll((uint64_t)x);\n}\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  int i = 0;\n  for (; i < 8 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  int i = 0;\n  for (; i < 16 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  int i = 0;\n  for (; i < 32 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  int i = 0;\n  for (; i < 64 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\n#elif defined(__CUDA_ARCH__)\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 8 : y - 1;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 16 : y - 1;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 32 : y - 1;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  int y = __ffsll(x);\n  return y == 0 ? 64 : y - 1",
                                    ";\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  return x == 0 ? 8 : count_trailing_zeros((int32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  return x == 0 ? 16 : count_trailing_zeros((int32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  return count_trailing_zeros(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  return count_trailing_zeros(x);\n}\n\n#else // Not OpenCL or CUDA, but plain C.\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  return x == 0 ? 8 : __builtin_ctz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  return x == 0 ? 16 : __builtin_ctz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  return x == 0 ? 32 : __builtin_ctz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  return x == 0 ? 64 : __builtin_ctzll((uint64_t)x);\n}\n#endif\n\nSCALAR_FUN_ATTR float fdiv32(float x, float y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR float fadd32(float x, float y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR float fsub32(float x, float y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR float fmul32(float x, float y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt32(float x, float y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple32(float x, float y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR float sitofp_i8_f32(int8_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float sitofp_i16_f32(int16_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float sitofp_i32_f32(int32_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float sitofp_i64_f32(int64_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i8_f32(uint8_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i16_f32(uint16_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i32_f32(uint32_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i64_f32(uint64_t x) {\n  return (float) x;\n}\n\n#ifdef __OPENCL_VERSION__\nSCALAR_FUN_ATTR float fabs32(float x) {\n  return fabs(x);\n}\n\nSCALAR_FUN_ATTR float fmax32(float x, f", "loat y) {\n  return fmax(x, y);\n}\n\nSCALAR_FUN_ATTR float fmin32(float x, float y) {\n  return fmin(x, y);\n}\n\nSCALAR_FUN_ATTR float fpow32(float x, float y) {\n  return pow(x, y);\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR float fabs32(float x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR float fmax32(float x, float y) {\n  return isnan(x) ? y : isnan(y) ? x : max(x, y);\n}\n\nSCALAR_FUN_ATTR float fmin32(float x, float y) {\n  return isnan(x) ? y : isnan(y) ? x : min(x, y);\n}\n\nSCALAR_FUN_ATTR float fpow32(float a, float b) {\n  float ret;\n  foreach_active (i) {\n      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));\n      ret = insert(ret, i, r);\n  }\n  return ret;\n}\n\n#else // Not OpenCL, but CUDA or plain C.\n\nSCALAR_FUN_ATTR float fabs32(float x) {\n  return fabsf(x);\n}\n\nSCALAR_FUN_ATTR float fmax32(float x, float y) {\n  return fmaxf(x, y);\n}\n\nSCALAR_FUN_ATTR float fmin32(float x, float y) {\n  return fminf(x, y);\n}\n\nSCALAR_FUN_ATTR float fpow32(float x, float y) {\n  return powf(x, y);\n}\n#endif\n\nSCALAR_FUN_ATTR bool futrts_isnan32(float x) {\n  return isnan(x);\n}\n\n#if ISPC\n\nSCALAR_FUN_ATTR bool futrts_isinf32(float x) {\n  return !isnan(x) && isnan(x - x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isfinite32(float x) {\n  return !isnan(x) && !futrts_isinf32(x);\n}\n\n#else\n\nSCALAR_FUN_ATTR bool futrts_isinf32(float x) {\n  return isinf(x);\n}\n\n#endif\n\nSCALAR_FUN_ATTR int8_t fptosi_f32_i8(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f32_i16(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f32_i32(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f32_i64(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  };\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f32_i8(float x) {", "\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f32_i16(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f32_i32(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f32_i64(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR bool ftob_f32_bool(float x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR float btof_bool_f32(bool x) {\n  return x ? 1 : 0;\n}\n\n#ifdef __OPENCL_VERSION__\nSCALAR_FUN_ATTR float futrts_log32(float x) {\n  return log(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log2_32(float x) {\n  return log2(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log10_32(float x) {\n  return log10(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log1p_32(float x) {\n  return log1p(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sqrt32(float x) {\n  return sqrt(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cbrt32(float x) {\n  return cbrt(x);\n}\n\nSCALAR_FUN_ATTR float futrts_exp32(float x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cos32(float x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sin32(float x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tan32(float x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acos32(float x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asin32(float x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan32(float x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cosh32(float x) {\n  return cosh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sinh32(float x) {\n  return sinh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tanh32(float x) {\n  return tanh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acosh32(float x) {\n  return acosh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asinh32(float x) {\n  return asinh(x);\n}\n\nSC",
                                    "ALAR_FUN_ATTR float futrts_atanh32(float x) {\n  return atanh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {\n  return atan2(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {\n  return hypot(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_gamma32(float x) {\n  return tgamma(x);\n}\n\nSCALAR_FUN_ATTR float futrts_lgamma32(float x) {\n  return lgamma(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erf32(float x) {\n  return erf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erfc32(float x) {\n  return erfc(x);\n}\n\nSCALAR_FUN_ATTR float fmod32(float x, float y) {\n  return fmod(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_round32(float x) {\n  return rint(x);\n}\n\nSCALAR_FUN_ATTR float futrts_floor32(float x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR float futrts_ceil32(float x) {\n  return ceil(x);\n}\n\nSCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {\n  return nextafter(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {\n  return mix(v0, v1, t);\n}\n\nSCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {\n  return ldexp(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {\n  return copysign(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {\n  return mad(a, b, c);\n}\n\nSCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {\n  return fma(a, b, c);\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR float futrts_log32(float x) {\n  return futrts_isfinite32(x) || (futrts_isinf32(x) && x < 0)? log(x) : x;\n}\n\nSCALAR_FUN_ATTR float futrts_log2_32(float x) {\n  return futrts_log32(x) / log(2.0f);\n}\n\nSCALAR_FUN_ATTR float futrts_log10_32(float x) {\n  return futrts_log32(x) / log(10.0f);\n}\n\nSCALAR_FUN_ATTR float futrts_log1p_32(float x) {\n  if(x == -1.0f || (futrts_isinf32(x) && x > 0.0f)) return x / 0.0f;\n  float y = 1.0f + x;\n  float z = y - 1.0f;\n  return log(y) - (z-x)/y;\n}\n\nSCALAR_FUN_ATTR float futrts_sqrt32(float x) {\n  return sqrt(x);\n}\n\nextern \"C\" unmasked uniform float cbrtf(uniform float);\nSCALAR_FUN_ATTR float futrts_cbrt32(float", " x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = cbrtf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR float futrts_exp32(float x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cos32(float x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sin32(float x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tan32(float x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acos32(float x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asin32(float x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan32(float x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cosh32(float x) {\n  return (exp(x)+exp(-x)) / 2.0f;\n}\n\nSCALAR_FUN_ATTR float futrts_sinh32(float x) {\n  return (exp(x)-exp(-x)) / 2.0f;\n}\n\nSCALAR_FUN_ATTR float futrts_tanh32(float x) {\n  return futrts_sinh32(x)/futrts_cosh32(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acosh32(float x) {\n  float f = x+sqrt(x*x-1);\n  if(futrts_isfinite32(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR float futrts_asinh32(float x) {\n  float f = x+sqrt(x*x+1);\n  if(futrts_isfinite32(f)) return log(f);\n  return f;\n\n}\n\nSCALAR_FUN_ATTR float futrts_atanh32(float x) {\n  float f = (1+x)/(1-x);\n  if(futrts_isfinite32(f)) return log(f)/2.0f;\n  return f;\n\n}\n\nSCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {\n  return (x == 0.0f && y == 0.0f) ? 0.0f : atan2(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {\n  if (futrts_isfinite32(x) && futrts_isfinite32(y)) {\n    x = abs(x);\n    y = abs(y);\n    float a;\n    float b;\n    if (x >= y){\n        a = x;\n        b = y;\n    } else {\n        a = y;\n        b = x;\n    }\n    if(b == 0){\n      return a;\n    }\n\n    int e;\n    float an;\n    float bn;\n    an = frexp (a, &e);\n    bn = ldexp (b, - e);\n    float cn;\n    cn = sqrt (an * an + bn * bn);\n    return ldexp (cn, e);\n  } else {\n    if (futrts_isinf32(x) || futrts_isinf32(y)) return INFINITY;\n    else return x + y;\n  }\n\n}\n\nextern \"C\" unmasked uniform float tgammaf(", "uniform float x);\nSCALAR_FUN_ATTR float futrts_gamma32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = tgammaf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float lgammaf(uniform float x);\nSCALAR_FUN_ATTR float futrts_lgamma32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = lgammaf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float erff(uniform float x);\nSCALAR_FUN_ATTR float futrts_erf32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = erff(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float erfcf(uniform float x);\nSCALAR_FUN_ATTR float futrts_erfc32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = erfcf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR float fmod32(float x, float y) {\n  return x - y * trunc(x/y);\n}\n\nSCALAR_FUN_ATTR float futrts_round32(float x) {\n  return round(x);\n}\n\nSCALAR_FUN_ATTR float futrts_floor32(float x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR float futrts_ceil32(float x) {\n  return ceil(x);\n}\n\nextern \"C\" unmasked uniform float nextafterf(uniform float x, uniform float y);\nSCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {\n  float res;\n  foreach_active (i) {\n    uniform float r = nextafterf(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {\n  return x * pow((double)2.0, (double)y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {\n  int32_t xb = futrts_to_bits32(x);\n  int32_t yb = futrts_to_bits32(y);\n  return futrts_from_bits32((xb & ~(1<<31)) | (yb & (1<<31)));\n}\n\nSCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR float futr",
                                    "ts_fma32(float a, float b, float c) {\n  return a * b + c;\n}\n\n#else // Not OpenCL or ISPC, but CUDA or plain C.\n\nSCALAR_FUN_ATTR float futrts_log32(float x) {\n  return logf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log2_32(float x) {\n  return log2f(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log10_32(float x) {\n  return log10f(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log1p_32(float x) {\n  return log1pf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sqrt32(float x) {\n  return sqrtf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cbrt32(float x) {\n  return cbrtf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_exp32(float x) {\n  return expf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cos32(float x) {\n  return cosf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sin32(float x) {\n  return sinf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tan32(float x) {\n  return tanf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acos32(float x) {\n  return acosf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asin32(float x) {\n  return asinf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan32(float x) {\n  return atanf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cosh32(float x) {\n  return coshf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sinh32(float x) {\n  return sinhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tanh32(float x) {\n  return tanhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acosh32(float x) {\n  return acoshf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asinh32(float x) {\n  return asinhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atanh32(float x) {\n  return atanhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {\n  return atan2f(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {\n  return hypotf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_gamma32(float x) {\n  return tgammaf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_lgamma32(float x) {\n  return lgammaf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erf32(float x) {\n  return erff(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erfc32(float x) {\n  return erfcf(x);\n}\n\nSCALAR_FUN_ATTR float fmod32(float x, float y) {\n  return fmodf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_round32(float x) {\n  re", "turn rintf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_floor32(float x) {\n  return floorf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_ceil32(float x) {\n  return ceilf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {\n  return nextafterf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {\n  return ldexpf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {\n  return copysignf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {\n  return fmaf(a, b, c);\n}\n#endif\n\n#if ISPC\nSCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {\n  return intbits(x);\n}\n\nSCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {\n  return floatbits(x);\n}\n#else\nSCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {\n  union {\n    float f;\n    int32_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {\n  union {\n    int32_t f;\n    float t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n#endif\n\nSCALAR_FUN_ATTR float fsignum32(float x) {\n  return futrts_isnan32(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nSCALAR_FUN_ATTR double futrts_from_bits64(int64_t x);\nSCALAR_FUN_ATTR int64_t futrts_to_bits64(double x);\n\n#if ISPC\nSCALAR_FUN_ATTR bool futrts_isinf64(float x) {\n  return !isnan(x) && isnan(x - x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isfinite64(float x) {\n  return !isnan(x) && !futrts_isinf64(x);\n}\n\nSCALAR_FUN_ATTR double fdiv64(double x, double y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR double fadd64(double x, double y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR double fsub64(double x, double y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR double fmul64(double x, double y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt64(double x, double y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple64(double x, double y) {\n  return x <= y;\n}", "\n\nSCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double fabs64(double x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR double fmax64(double x, double y) {\n  return isnan(x) ? y : isnan(y) ? x : max(x, y);\n}\n\nSCALAR_FUN_ATTR double fmin64(double x, double y) {\n  return isnan(x) ? y : isnan(y) ? x : min(x, y);\n}\n\nSCALAR_FUN_ATTR double fpow64(double a, double b) {\n  float ret;\n  foreach_active (i) {\n      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));\n      ret = insert(ret, i, r);\n  }\n  return ret;\n}\n\nSCALAR_FUN_ATTR double futrts_log64(double x) {\n  return futrts_isfinite64(x) || (futrts_isinf64(x) && x < 0)? log(x) : x;\n}\n\nSCALAR_FUN_ATTR double futrts_log2_64(double x) {\n  return futrts_log64(x)/log(2.0d);\n}\n\nSCALAR_FUN_ATTR double futrts_log10_64(double x) {\n  return futrts_log64(x)/log(10.0d);\n}\n\nSCALAR_FUN_ATTR double futrts_log1p_64(double x) {\n  if(x == -1.0d || (futrts_isinf64(x) && x > 0.0d)) return x / 0.0d;\n  double y = 1.0d + x;\n  double z = y - 1.0d;\n  return log(y) - (z-x)/y;\n}\n\nSCALAR_FUN_ATTR double futrts_sqrt64(double x) {\n  return sqrt(x);\n}\n\nextern \"C\" unmasked uniform double cbrt(uniform double);\nSCALAR_FUN_ATTR double futrts_cbrt64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = cbrtf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_exp64(double x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cos64(dou",
                                    "ble x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sin64(double x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_tan64(double x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acos64(double x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_asin64(double x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atan64(double x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cosh64(double x) {\n  return (exp(x)+exp(-x)) / 2.0d;\n}\n\nSCALAR_FUN_ATTR double futrts_sinh64(double x) {\n  return (exp(x)-exp(-x)) / 2.0d;\n}\n\nSCALAR_FUN_ATTR double futrts_tanh64(double x) {\n  return futrts_sinh64(x)/futrts_cosh64(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acosh64(double x) {\n  double f = x+sqrt(x*x-1.0d);\n  if(futrts_isfinite64(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR double futrts_asinh64(double x) {\n  double f = x+sqrt(x*x+1.0d);\n  if(futrts_isfinite64(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR double futrts_atanh64(double x) {\n  double f = (1.0d+x)/(1.0d-x);\n  if(futrts_isfinite64(f)) return log(f)/2.0d;\n  return f;\n\n}\n\nSCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {\n  return atan2(x, y);\n}\n\nextern \"C\" unmasked uniform double hypot(uniform double x, uniform double y);\nSCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {\n  double res;\n  foreach_active (i) {\n    uniform double r = hypot(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double tgamma(uniform double x);\nSCALAR_FUN_ATTR double futrts_gamma64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = tgamma(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double lgamma(uniform double x);\nSCALAR_FUN_ATTR double futrts_lgamma64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = lgamma(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double erf(uniform double x);\nSCALAR_FUN_ATTR do", "uble futrts_erf64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = erf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double erfc(uniform double x);\nSCALAR_FUN_ATTR double futrts_erfc64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = erfc(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR double futrts_round64(double x) {\n  return round(x);\n}\n\nSCALAR_FUN_ATTR double futrts_ceil64(double x) {\n  return ceil(x);\n}\n\nextern \"C\" unmasked uniform double nextafter(uniform float x, uniform double y);\nSCALAR_FUN_ATTR float futrts_nextafter64(double x, double y) {\n  double res;\n  foreach_active (i) {\n    uniform double r = nextafter(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_floor64(double x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isnan64(double x) {\n  return isnan(x);\n}\n\nSCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int", "16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR bool ftob_f64_bool(double x) {\n  return x != 0.0;\n}\n\nSCALAR_FUN_ATTR double btof_bool_f64(bool x) {\n  return x ? 1.0 : 0.0;\n}\n\nSCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {\n  int64_t res;\n  foreach_active (i) {\n    uniform double tmp = extract(x, i);\n    uniform int64_t r = *((uniform int64_t* uniform)&tmp);\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {\n  double res;\n  foreach_active (i) {\n    uniform int64_t tmp = extract(x, i);\n    uniform double r = *((uniform double* uniform)&tmp);\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double fmod64(double x, double y) {\n  return x - y * trunc(x/y);\n}\n\nSCALAR_FUN_ATTR double fsignum64(double x) {\n  return futrts_isnan64(x) ? x : (x > 0 ? 1.0d : 0.0d) - (x < 0 ? 1.0d : 0.0d);\n}\n\nSCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {\n  return x * pow((double)2.0, (double)y);\n}\n\nSCALAR_FUN_ATTR double futrts_copysign64(double x, double y) {\n  int64_t xb = futrts_to_bits64(x);\n  int64_t yb = futrts_to_bits64(y);\n  return futrts_from_bits64((xb & ~(((int64_t)1)<<63)) | (yb & (((int64_t)1)<<63)));\n}\n\nSCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR float fpconv_f32_f32(float x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f32_f64(float x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR float fpconv_f64_f32(double x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f64_f64(double x) {\n  return (double) x;\n}\n\n#e",
                                    "lse\n\nSCALAR_FUN_ATTR double fdiv64(double x, double y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR double fadd64(double x, double y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR double fsub64(double x, double y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR double fmul64(double x, double y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt64(double x, double y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple64(double x, double y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double fabs64(double x) {\n  return fabs(x);\n}\n\nSCALAR_FUN_ATTR double fmax64(double x, double y) {\n  return fmax(x, y);\n}\n\nSCALAR_FUN_ATTR double fmin64(double x, double y) {\n  return fmin(x, y);\n}\n\nSCALAR_FUN_ATTR double fpow64(double x, double y) {\n  return pow(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_log64(double x) {\n  return log(x);\n}\n\nSCALAR_FUN_ATTR double futrts_log2_64(double x) {\n  return log2(x);\n}\n\nSCALAR_FUN_ATTR double futrts_log10_64(double x) {\n  return log10(x);\n}\n\nSCALAR_FUN_ATTR double futrts_log1p_64(double x) {\n  return log1p(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sqrt64(double x) {\n  return sqrt(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cbrt64(double x) {\n  return cbrt(x);\n}\n\nSCALAR_FUN_ATTR double futrts_exp64(double x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cos64(double x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sin64(double x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_tan64(double x) {\n  r", "eturn tan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acos64(double x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_asin64(double x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atan64(double x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cosh64(double x) {\n  return cosh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sinh64(double x) {\n  return sinh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_tanh64(double x) {\n  return tanh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acosh64(double x) {\n  return acosh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_asinh64(double x) {\n  return asinh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atanh64(double x) {\n  return atanh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {\n  return atan2(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {\n  return hypot(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_gamma64(double x) {\n  return tgamma(x);\n}\n\nSCALAR_FUN_ATTR double futrts_lgamma64(double x) {\n  return lgamma(x);\n}\n\nSCALAR_FUN_ATTR double futrts_erf64(double x) {\n  return erf(x);\n}\n\nSCALAR_FUN_ATTR double futrts_erfc64(double x) {\n  return erfc(x);\n}\n\nSCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {\n  return fma(a, b, c);\n}\n\nSCALAR_FUN_ATTR double futrts_round64(double x) {\n  return rint(x);\n}\n\nSCALAR_FUN_ATTR double futrts_ceil64(double x) {\n  return ceil(x);\n}\n\nSCALAR_FUN_ATTR float futrts_nextafter64(float x, float y) {\n  return nextafter(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_floor64(double x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isnan64(double x) {\n  return isnan(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isinf64(double x) {\n  return isinf(x);\n}\n\nSCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x", ") {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR bool ftob_f64_bool(double x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR double btof_bool_f64(bool x) {\n  return x ? 1 : 0;\n}\n\nSCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {\n  union {\n    double f;\n    int64_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {\n  union {\n    int64_t f;\n    double t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR double fmod64(double x, double y) {\n  return fmod(x, y);\n}\n\nSCALAR_FUN_ATTR double fsignum64(double x) {\n  return futrts_isnan64(x) ? x : (x > 0) - (x < 0);\n}\n\nSCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {\n#ifdef __OPENCL_VERSION__\n  return mix(v0, v1, t);\n#else\n  return v0 + (v1 - v0) * t;\n#endif\n}\n\nSCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {\n  return ldexp(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign64(double x, double y) {\n  return copysign(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {\n#ifdef __OPENCL_VERSION__\n  return mad(a, b, c);\n#else\n  return a * b + c;\n#endif\n}\n\nSCALAR",
                                    "_FUN_ATTR float fpconv_f32_f32(float x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f32_f64(float x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR float fpconv_f64_f32(double x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f64_f64(double x) {\n  return (double) x;\n}\n\n#endif\n\n#endif\n\n// End of scalar.h.\n// Start of scalar_f16.h.\n\n// Half-precision is emulated if needed (e.g. in straight C) with the\n// native type used if possible.  The emulation works by typedef'ing\n// 'float' to 'f16', and then implementing all operations on single\n// precision.  To cut down on duplication, we use the same code for\n// those Futhark functions that require just operators or casts.  The\n// in-memory representation for arrays will still be 16 bits even\n// under emulation, so the compiler will have to be careful when\n// generating reads or writes.\n\n#if !defined(cl_khr_fp16) && !(defined(__CUDA_ARCH__) && __CUDA_ARCH__ >= 600) && !(defined(ISPC))\n#define EMULATE_F16\n#endif\n\n#if !defined(EMULATE_F16) && defined(__OPENCL_VERSION__)\n#pragma OPENCL EXTENSION cl_khr_fp16 : enable\n#endif\n\n#ifdef EMULATE_F16\n\n// Note that the half-precision storage format is still 16 bits - the\n// compiler will have to be real careful!\ntypedef float f16;\n\n#elif ISPC\ntypedef float16 f16;\n\n#else\n\n#ifdef __CUDA_ARCH__\n#include <cuda_fp16.h>\n#endif\n\ntypedef half f16;\n\n#endif\n\n// Some of these functions convert to single precision because half\n// precision versions are not available.\n\nSCALAR_FUN_ATTR f16 fadd16(f16 x, f16 y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR f16 fsub16(f16 x, f16 y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR f16 fmul16(f16 x, f16 y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt16(f16 x, f16 y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple16(f16 x, f16 y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR f16 sitofp_i8_f16(int8_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 sitofp_i16_f16(int16_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 sitofp_i32_f16(int32_t x) {\n  return (f16) x;\n}\n\nSCALAR", "_FUN_ATTR f16 sitofp_i64_f16(int64_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i8_f16(uint8_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i16_f16(uint16_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i32_f16(uint32_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i64_f16(uint64_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR int8_t fptosi_f16_i8(f16 x) {\n  return (int8_t) (float) x;\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f16_i16(f16 x) {\n  return (int16_t) x;\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f16_i32(f16 x) {\n  return (int32_t) x;\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f16_i64(f16 x) {\n  return (int64_t) x;\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f16_i8(f16 x) {\n  return (uint8_t) (float) x;\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f16_i16(f16 x) {\n  return (uint16_t) x;\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f16_i32(f16 x) {\n  return (uint32_t) x;\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f16_i64(f16 x) {\n  return (uint64_t) x;\n}\n\nSCALAR_FUN_ATTR bool ftob_f16_bool(f16 x) {\n  return x != (f16)0;\n}\n\nSCALAR_FUN_ATTR f16 btof_bool_f16(bool x) {\n  return x ? 1 : 0;\n}\n\n#ifndef EMULATE_F16\nSCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {\n  return isnan((float)x);\n}\n\n#ifdef __OPENCL_VERSION__\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return fabs(x);\n}\n\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return fmax(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {\n  return fmin(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return pow(x, y);\n}\n\n#elif ISPC\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : max(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {\n  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : min(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return pow(x, y);\n}\n\n#else // Assuming CUDA.\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return fabsf(x);\n}\n\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return fmaxf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 ", "x, f16 y) {\n  return fminf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return powf(x, y);\n}\n#endif\n\n#if ISPC\nSCALAR_FUN_ATTR bool futrts_isinf16(float x) {\n  return !futrts_isnan16(x) && futrts_isnan16(x - x);\n}\nSCALAR_FUN_ATTR bool futrts_isfinite16(float x) {\n  return !futrts_isnan16(x) && !futrts_isinf16(x);\n}\n\n#else\n\nSCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {\n  return isinf((float)x);\n}\n#endif\n\n#ifdef __OPENCL_VERSION__\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return log(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return log2(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return log10(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  return log1p(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return sqrt(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  return cbrt(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  return cosh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return sinh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return tanh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  return acosh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  return asinh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  return atanh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return atan2(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return hypot(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {\n  return tgamma(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  return lgamma(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  return e",
                                    "rf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  return erfc(x);\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return fmod(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return rint(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return ceil(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {\n  return nextafter(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return mix(v0, v1, t);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return ldexp(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return copysign(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return mad(a, b, c);\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return fma(a, b, c);\n}\n#elif ISPC\n\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return futrts_isfinite16(x) || (futrts_isinf16(x) && x < 0) ? log(x) : x;\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return futrts_log16(x) / log(2.0f16);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return futrts_log16(x) / log(10.0f16);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  if(x == -1.0f16 || (futrts_isinf16(x) && x > 0.0f16)) return x / 0.0f16;\n  f16 y = 1.0f16 + x;\n  f16 z = y - 1.0f16;\n  return log(y) - (z-x)/y;\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return (float16)sqrt((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return (float16)cos((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return (float16)sin((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return (float16)tan((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return (float16)acos((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return (float16)asin((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return (float16)atan((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  retu", "rn (exp(x)+exp(-x)) / 2.0f16;\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return (exp(x)-exp(-x)) / 2.0f16;\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return futrts_sinh16(x)/futrts_cosh16(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  float16 f = x+(float16)sqrt((float)(x*x-1));\n  if(futrts_isfinite16(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  float16 f = x+(float16)sqrt((float)(x*x+1));\n  if(futrts_isfinite16(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  float16 f = (1+x)/(1-x);\n  if(futrts_isfinite16(f)) return log(f)/2.0f16;\n  return f;\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return (float16)atan2((float)x, (float)y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return (float16)futrts_hypot32((float)x, (float)y);\n}\n\nextern \"C\" unmasked uniform float tgammaf(uniform float x);\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {\n  f16 res;\n  foreach_active (i) {\n    uniform f16 r = (f16)tgammaf(extract((float)x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float lgammaf(uniform float x);\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  f16 res;\n  foreach_active (i) {\n    uniform f16 r = (f16)lgammaf(extract((float)x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  f16 res = (f16)futrts_cbrt32((float)x);\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  f16 res = (f16)futrts_erf32((float)x);\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  f16 res = (f16)futrts_erfc32((float)x);\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return x - y * (float16)trunc((float) (x/y));\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return (float16)round((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return (float16)floor((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return (float16)ceil((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrt", "s_nextafter16(f16 x, f16 y) {\n  return (float16)futrts_nextafter32((float)x, (float) y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return futrts_ldexp32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return futrts_copysign32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\n#else // Assume CUDA.\n\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return hlog(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return hlog2(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return hlog10(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  return (f16)log1pf((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return hsqrt(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  return cbrtf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return hexp(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return hcos(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return hsin(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return tanf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return acosf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return asinf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return atanf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  return coshf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return sinhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return tanhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  return acoshf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  return asinhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  return atanhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return atan2f(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return hypotf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_gamma16(f1",
                                    "6 x) {\n  return tgammaf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  return lgammaf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  return erff(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  return erfcf(x);\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return fmodf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return rintf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return hfloor(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return hceil(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {\n  return __ushort_as_half(halfbitsnextafter(__half_as_ushort(x), __half_as_ushort(y)));\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return futrts_ldexp32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return futrts_copysign32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return fmaf(a, b, c);\n}\n\n#endif\n\n// The CUDA __half type cannot be put in unions for some reason, so we\n// use bespoke conversion functions instead.\n#ifdef __CUDA_ARCH__\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  return __half_as_ushort(x);\n}\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  return __ushort_as_half(x);\n}\n#elif ISPC\n\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  varying int16_t y = *((varying int16_t * uniform)&x);\n  return y;\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  varying f16 y = *((varying f16 * uniform)&x);\n  return y;\n}\n#else\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  union {\n    f16 f;\n    int16_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  union {\n    int16_t f;\n    f16 t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n#endif\n\n#else // No native f16 - emulate.\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return fabs32(x);\n}\n\nSC", "ALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return fmax32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {\n  return fmin32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return fpow32(x, y);\n}\n\nSCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {\n  return futrts_isnan32(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {\n  return futrts_isinf32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return futrts_log32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return futrts_log2_32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return futrts_log10_32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  return futrts_log1p_32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return futrts_sqrt32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  return futrts_cbrt32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return futrts_exp32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return futrts_cos32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return futrts_sin32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return futrts_tan32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return futrts_acos32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return futrts_asin32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return futrts_atan32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  return futrts_cosh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return futrts_sinh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return futrts_tanh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  return futrts_acosh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  return futrts_asinh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  return futrts_atanh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return futrts_atan2_32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return futrts_hypot32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {\n  return futrts_gamma32(x);\n}\n\nSCA", "LAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  return futrts_lgamma32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  return futrts_erf32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  return futrts_erfc32(x);\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return fmod32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return futrts_round32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return futrts_floor32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return futrts_ceil32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {\n  return halfbits2float(halfbitsnextafter(float2halfbits(x), float2halfbits(y)));\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return futrts_lerp32(v0, v1, t);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return futrts_ldexp32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return futrts_copysign32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return futrts_mad32(a, b, c);\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return futrts_fma32(a, b, c);\n}\n\n// Even when we are using an OpenCL that does not support cl_khr_fp16,\n// it must still support vload_half for actually creating a\n// half-precision number, which can then be efficiently converted to a\n// float.  Similarly for vstore_half.\n#ifdef __OPENCL_VERSION__\n\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  int16_t y;\n  // Violating strict aliasing here.\n  vstore_half((float)x, 0, (half*)&y);\n  return y;\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  return (f16)vload_half(0, (half*)&x);\n}\n\n#else\n\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  return (int16_t)float2halfbits(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  return halfbits2float((uint16_t)x);\n}\n\nSCALAR_FUN_ATTR f16 fsignum16(f16 x) {\n  return futrts_isnan16(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);\n}\n\n#endif\n\n#endif\n\nSCALAR_FUN_ATTR float fpconv_f16_f16(f16 x) {\n  retu",
                                    "rn x;\n}\n\nSCALAR_FUN_ATTR float fpconv_f16_f32(f16 x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR f16 fpconv_f32_f16(float x) {\n  return (f16) x;\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nSCALAR_FUN_ATTR double fpconv_f16_f64(f16 x) {\n  return (double) x;\n}\n\n#if ISPC\nSCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {\n  return (f16) ((float)x);\n}\n#else\nSCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {\n  return (f16) x;\n}\n#endif\n#endif\n\n\n// End of scalar_f16.h.\n// Start of atomics.h\n\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_global(volatile __global int32_t *p,\n                                                         int32_t cmp, int32_t val);\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_shared(volatile __local int32_t *p,\n                                                        int32_t cmp, int32_t val);\nSCALAR_FUN_ATTR int32_t atomic_add_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_add_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR float atomic_fadd_f32_global(volatile __global float *p, float x);\nSCALAR_FUN_ATTR float atomic_fadd_f32_shared(volatile __local float *p, float x);\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_global(volatile __global uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_shared(volatile __local uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_global(volatile __global uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_shared(volatile __local uint32", "_t *p, uint32_t x);\nSCALAR_FUN_ATTR int32_t atomic_and_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_and_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_or_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_or_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_shared(volatile __local int32_t *p, int32_t x);\n\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_global(volatile __global int32_t *p,\n                                                         int32_t cmp, int32_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((int32_t*)p, cmp, val);\n#else\n  return atomic_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_shared(volatile __local int32_t *p,\n                                                        int32_t cmp, int32_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((int32_t*)p, cmp, val);\n#else\n  return atomic_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_add_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((int32_t*)p, x);\n#else\n  return atomic_add(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_add_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((int32_t*)p, x);\n#el", "se\n  return atomic_add(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR float atomic_fadd_f32_global(volatile __global float *p, float x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((float*)p, x);\n  // On OpenCL, use technique from\n  // https://pipinspace.github.io/blog/atomic-float-addition-in-opencl.html\n#elif defined(cl_nv_pragma_unroll)\n  // use hardware-supported atomic addition on Nvidia GPUs with inline\n  // PTX assembly\n  float ret;\n  asm volatile(\"atom.global.add.f32 %0,[%1],%2;\":\"=f\"(ret):\"l\"(p),\"f\"(x):\"memory\");\n  return ret;\n#elif defined(__opencl_c_ext_fp32_global_atomic_add)\n  // use hardware-supported atomic addition on some Intel GPUs\n  return atomic_fetch_add_explicit((volatile __global atomic_float*)p,\n                                   x,\n                                   memory_order_relaxed);\n#elif __has_builtin(__builtin_amdgcn_global_atomic_fadd_f32)\n  // use hardware-supported atomic addition on some AMD GPUs\n  return __builtin_amdgcn_global_atomic_fadd_f32(p, x);\n#else\n  // fallback emulation:\n  // https://forums.developer.nvidia.com/t/atomicadd-float-float-atomicmul-float-float/14639/5\n  float old = x;\n  float ret;\n  while ((old=atomic_xchg(p, ret=atomic_xchg(p, 0.0f)+old))!=0.0f);\n  return ret;\n#endif\n}\n\nSCALAR_FUN_ATTR float atomic_fadd_f32_shared(volatile __local float *p, float x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((float*)p, x);\n#else\n  union { int32_t i; float f; } old;\n  union { int32_t i; float f; } assumed;\n  old.f = *p;\n  do {\n    assumed.f = old.f;\n    old.f = old.f + x;\n    old.i = atomic_cmpxchg_i32_shared((volatile __local int32_t*)p, assumed.i, old.i);\n  } while (assumed.i != old.i);\n  return old.f;\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((int32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_shared(volatile",
                                    " __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((int32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((int32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((int32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_global(volatile __global uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_shared(volatile __local uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_global(volatile __global uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_shared(volatile __local uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_and_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((int32_t*)p, x);\n#else\n  return atomic_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_and_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((int32_t*)p, x);\n#else\n  return atomic_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_or_i32_global(volatile __global int32_t *p, ", "int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((int32_t*)p, x);\n#else\n  return atomic_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_or_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((int32_t*)p, x);\n#else\n  return atomic_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\n// Start of 64 bit atomics\n\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP) || defined(cl_khr_int64_base_atomics) && defined(cl_khr_int64_extended_atomics)\n\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_global(volatile __global int64_t *p,\n                                                         int64_t cmp, int64_t val);\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_shared(volatile __local int64_t *p,\n                                                        int64_t cmp, int64_t val);\nSCALAR_FUN_ATTR int64_t atomic_add_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_add_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR uint", "64_t atomic_umax_i64_global(volatile __global uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_shared(volatile __local uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_global(volatile __global uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_shared(volatile __local uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR int64_t atomic_and_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_and_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_or_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_or_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_shared(volatile __local int64_t *p, int64_t x);\n\n#ifdef FUTHARK_F64_ENABLED\nSCALAR_FUN_ATTR double atomic_fadd_f64_global(volatile __global double *p, double x);\nSCALAR_FUN_ATTR double atomic_fadd_f64_shared(volatile __local double *p, double x);\n#endif\n\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_global(volatile __global int64_t *p,\n                                                         int64_t cmp, int64_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((uint64_t*)p, cmp, val);\n#else\n  return atom_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_shared(volatile __local int64_t *p,\n                                                        int64_t cmp, int64_t val) {\n#if defined(F",
                                    "UTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((uint64_t*)p, cmp, val);\n#else\n  return atom_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_add_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((uint64_t*)p, x);\n#else\n  return atom_add(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_add_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((uint64_t*)p, x);\n#else\n  return atom_add(p, x);\n#endif\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nSCALAR_FUN_ATTR double atomic_fadd_f64_global(volatile __global double *p, double x) {\n#if defined(FUTHARK_CUDA) && __CUDA_ARCH__ >= 600 || defined(FUTHARK_HIP)\n  return atomicAdd((double*)p, x);\n  // On OpenCL, use technique from\n  // https://pipinspace.github.io/blog/atomic-float-addition-in-opencl.html\n#elif defined(cl_nv_pragma_unroll)\n  // use hardware-supported atomic addition on Nvidia GPUs with inline\n  // PTX assembly\n  double ret;\n  asm volatile(\"atom.global.add.f64 %0,[%1],%2;\":\"=d\"(ret):\"l\"(p),\"d\"(x):\"memory\");\n  return ret;\n#elif __has_builtin(__builtin_amdgcn_global_atomic_fadd_f64)\n  // use hardware-supported atomic addition on some AMD GPUs\n  return __builtin_amdgcn_global_atomic_fadd_f64(p, x);\n#else\n  // fallback emulation:\n  // https://forums.developer.nvidia.com/t/atomicadd-float-float-atomicmul-float-float/14639/5\n  union {int64_t i; double f;} old;\n  union {int64_t i; double f;} ret;\n  old.f = x;\n  while (1) {\n    ret.i = atom_xchg((volatile __global int64_t*)p, (int64_t)0);\n    ret.f += old.f;\n    old.i = atom_xchg((volatile __global int64_t*)p, ret.i);\n    if (old.i == 0) {\n      break;\n    }\n  }\n  return ret.f;\n#endif\n}\n\nSCALAR_FUN_ATTR double atomic_fadd_f64_shared(volatile __local double *p, double x) {\n#if defined(FUTHARK_CUDA) && __CUDA_ARCH__ >= 600 || defined(FUTHARK_HIP)\n  return atomicAdd((double*)p, x);\n#else\n  union { int64_t i; double f; } old;\n  u", "nion { int64_t i; double f; } assumed;\n  old.f = *p;\n  do {\n    assumed.f = old.f;\n    old.f = old.f + x;\n    old.i = atomic_cmpxchg_i64_shared((volatile __local int64_t*)p, assumed.i, old.i);\n  } while (assumed.i != old.i);\n  return old.f;\n#endif\n}\n\n#endif\n\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMax((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smax64(old, x);\n    old = atomic_cmpxchg_i64_global((volatile __global int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMax((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smax64(old, x);\n    old = atomic_cmpxchg_i64_shared((volatile __local int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMin((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smin64(old, x);\n    old = atomic_cmpxchg_i64_global((volatile __global int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMin((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do ", "{\n    assumed = old;\n    old = smin64(old, x);\n    old = atomic_cmpxchg_i64_shared((volatile __local int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_global(volatile __global uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint64_t*)p, x);\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_shared(volatile __local uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint64_t*)p, x);\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_global(volatile __global uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint64_t*)p, x);\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_shared(volatile __local uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint64_t*)p, x);\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_and_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((uint64_t*)p, x);\n#else\n  return atom_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_and_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((uint64_t*)p, x);\n#else\n  return atom_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_or_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((uint64_t*)p, x);\n#else\n  return atom_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_or_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((uint64_t*)p, x);\n#else\n  return atom_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_global(v",
                                    "olatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\n#endif // defined(FUTHARK_CUDA) || defined(FUTHARK_HIP) || defined(cl_khr_int64_base_atomics) && defined(cl_khr_int64_extended_atomics)\n\n// End of atomics.h\n// Start of transpose.cl\n\n#define GEN_TRANSPOSE_KERNELS(NAME, ELEM_TYPE)                          \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*2, TR_TILE_DIM/TR_ELEMS_PER_THREAD, 1)\\\nvoid map_transpose_##NAME(SHARED_MEM_PARAM                              \\\n                          __global ELEM_TYPE *dst_mem,                  \\\n                          int64_t dst_offset,                           \\\n                          __global ELEM_TYPE *src_mem,                  \\\n                          int64_t src_offset,                           \\\n                          int32_t num_arrays,                           \\\n                          int32_t x_elems,                              \\\n                          int32_t y_elems,                              \\\n                          int32_t mulx,                                 \\\n                          int32_t muly,                                 \\\n                          int32_t repeat_1,                             \\\n                          int32_t repeat_2) {                           \\\n  (void)mulx; (void)muly;                                               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_g", "lobal_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t x_index = global_id_0;                                    \\\n      int32_t y_index = tblock_id_1 * TR_TILE_DIM + get_local_id(1);    \\\n      if (x_index < x_elems) {                                          \\\n        for (int32_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int32_t index_i = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * x_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < y_elems) { \\\n            block[(get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * (TR_TILE_DIM+1) + \\\n                  get_local_id(0)] =                                    \\\n              src_mem[idata_offset + index_i];                          \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_TILE_DIM + get_local_id(0);            \\\n      y_index = tblock_id_0 * TR_TILE_DIM + get_local_id(1);            \\\n      if (x_index < y_elems) {                                          \\\n        for (int32_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int32_t index_out = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * y_elems + x_index; \\\n          if (y_in", "dex + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < x_elems) { \\\n            dst_mem[(odata_offset + index_out)] =                       \\\n              block[get_local_id(0) * (TR_TILE_DIM+1) +                 \\\n                    get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)]; \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM, TR_BLOCK_DIM, 1)                     \\\nvoid map_transpose_##NAME##_low_height(SHARED_MEM_PARAM                 \\\n                                                __global ELEM_TYPE *dst_mem, \\\n                                                int64_t dst_offset,     \\\n                                                __global ELEM_TYPE *src_mem, \\\n                                                int64_t src_offset,     \\\n                                                int32_t num_arrays,     \\\n                                                int32_t x_elems,        \\\n                                                int32_t y_elems,        \\\n                                                int32_t mulx,           \\\n                                                int32_t muly,           \\\n                                                int32_t repeat_1,       \\\n ",
                                    "                                               int32_t repeat_2) {     \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t x_index =                                                 \\\n        tblock_id_0 * TR_BLOCK_DIM * mulx +                             \\\n        get_local_id(0) +                                               \\\n        get_local_id(1)%mulx * TR_BLOCK_DIM;                            \\\n      int32_t y_index = tblock_id_1 * TR_BLOCK_DIM + get_local_id(1)/mulx; \\\n      int32_t index_in = y_index * x_elems + x_index;                   \\\n      if (x_index < x_elems && y_index < y_elems) {                     \\\n        block[get_local_id(1) * (TR_BLOCK_DIM+1) + get_local_id(0)] =   \\\n          src_mem[idata_offset + index_in];                             \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_BLOCK_DIM + get_local_id(0)/mulx;      \\\n      y_index =                                                         \\\n        tblock_id_0 * TR_BLOCK_DIM * mulx +                             \\\n", "        get_local_id(1) +                                               \\\n        (get_local_id(0)%mulx) * TR_BLOCK_DIM;                          \\\n      int32_t index_out = y_index * y_elems + x_index;                  \\\n      if (x_index < y_elems && y_index < x_elems) {                     \\\n        dst_mem[odata_offset + index_out] =                             \\\n          block[get_local_id(0) * (TR_BLOCK_DIM+1) + get_local_id(1)];  \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM, TR_BLOCK_DIM, 1)                     \\\nvoid map_transpose_##NAME##_low_width(SHARED_MEM_PARAM                  \\\n                                      __global ELEM_TYPE *dst_mem,      \\\n                                      int64_t dst_offset,               \\\n                                      __global ELEM_TYPE *src_mem,      \\\n                                      int64_t src_offset,               \\\n                                      int32_t num_arrays,               \\\n                                      int32_t x_elems,                  \\\n                                      int32_t y_elems,                  \\\n                                      int32_t mulx,                     \\\n                                      int32_t muly,                     \\\n                                      int32_t repeat_1,                 \\\n  ", "                                    int32_t repeat_2) {               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t x_index = tblock_id_0 * TR_BLOCK_DIM + get_local_id(0)/muly; \\\n      int32_t y_index =                                                 \\\n        tblock_id_1 * TR_BLOCK_DIM * muly +                             \\\n        get_local_id(1) + (get_local_id(0)%muly) * TR_BLOCK_DIM;        \\\n      int32_t index_in = y_index * x_elems + x_index;                   \\\n      if (x_index < x_elems && y_index < y_elems) {                     \\\n        block[get_local_id(1) * (TR_BLOCK_DIM+1) + get_local_id(0)] =   \\\n          src_mem[idata_offset + index_in];                             \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_BLOCK_DIM * muly +                     \\\n        get_local_id(0) + (get_local_id(1)%muly) * TR_BLOCK_DIM;        \\\n      y_index = tblock_id_0 * TR_BLOCK_DIM + get_local_id(1)/muly;      \\\n      int32_t index_out = y_index * y_elems + x_index;                  \\\n ",
                                    "     if (x_index < y_elems && y_index < x_elems) {                     \\\n        dst_mem[odata_offset + index_out] =                             \\\n          block[get_local_id(0) * (TR_BLOCK_DIM+1) + get_local_id(1)];  \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_num_tblocks(2) * get_local_size(2);            \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_num_tblocks(1) * get_local_size(1);              \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*TR_BLOCK_DIM, 1, 1)                   \\\nvoid map_transpose_##NAME##_small(SHARED_MEM_PARAM                       \\\n                                  __global ELEM_TYPE *dst_mem,          \\\n                                  int64_t dst_offset,                   \\\n                                  __global ELEM_TYPE *src_mem,          \\\n                                  int64_t src_offset,                   \\\n                                  int32_t num_arrays,                   \\\n                                  int32_t x_elems,                      \\\n                                  int32_t y_elems,                      \\\n                                  int32_t mulx,                         \\\n                                  int32_t muly,                         \\\n                                  int32_t repeat_1,                     \\\n                                  int32_t repeat_2) {                   \\\n  (void)mulx; (void)muly;                                               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  ", "int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = global_id_0/(y_elems * x_elems) * y_elems * x_elems; \\\n      int32_t x_index = (global_id_0 % (y_elems * x_elems))/y_elems;    \\\n      int32_t y_index = global_id_0%y_elems;                            \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t index_in = y_index * x_elems + x_index;                   \\\n      int32_t index_out = x_index * y_elems + y_index;                  \\\n      if (global_id_0 < x_elems * y_elems * num_arrays) {               \\\n        dst_mem[odata_offset + index_out] = src_mem[idata_offset + index_in]; \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*2, TR_TILE_DIM/TR_ELEMS_", "PER_THREAD, 1)\\\nvoid map_transpose_##NAME##_large(SHARED_MEM_PARAM                      \\\n                                  __global ELEM_TYPE *dst_mem,          \\\n                                  int64_t dst_offset,                   \\\n                                  __global ELEM_TYPE *src_mem,          \\\n                                  int64_t src_offset,                   \\\n                                  int64_t num_arrays,                   \\\n                                  int64_t x_elems,                      \\\n                                  int64_t y_elems,                      \\\n                                  int64_t mulx,                         \\\n                                  int64_t muly,                         \\\n                                  int32_t repeat_1,                     \\\n                                  int32_t repeat_2) {                   \\\n  (void)mulx; (void)muly;                                               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;             \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int64_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int64_t odata_offset = dst_offset + our_array_offset;             \\\n      int64_t idata_offset = src_offset + our_array_offset;             \\\n      int64_t x_index = global_id_0;                                    \\\n      int64_t y_index = tblock_id_1 * TR_TILE_DIM + get_loc",
                                    "al_id(1);    \\\n      if (x_index < x_elems) {                                          \\\n        for (int64_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int64_t index_i = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * x_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < y_elems) { \\\n            block[(get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * (TR_TILE_DIM+1) + \\\n                  get_local_id(0)] =                                    \\\n              src_mem[idata_offset + index_i];                          \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_TILE_DIM + get_local_id(0);            \\\n      y_index = tblock_id_0 * TR_TILE_DIM + get_local_id(1);            \\\n      if (x_index < y_elems) {                                          \\\n        for (int64_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int64_t index_out = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * y_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < x_elems) { \\\n            dst_mem[(odata_offset + index_out)] =                       \\\n              block[get_local_id(0) * (TR_TILE_DIM+1) +                 \\\n                    get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)]; \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                      ", "                             \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n\nGEN_TRANSPOSE_KERNELS(1b, uint8_t)\nGEN_TRANSPOSE_KERNELS(2b, uint16_t)\nGEN_TRANSPOSE_KERNELS(4b, uint32_t)\nGEN_TRANSPOSE_KERNELS(8b, uint64_t)\n\n// End of transpose.cl\n// Start of copy.cl\n\n#define GEN_COPY_KERNEL(NAME, ELEM_TYPE) \\\nFUTHARK_KERNEL void lmad_copy_##NAME(SHARED_MEM_PARAM                   \\\n                               __global ELEM_TYPE *dst_mem,             \\\n                               int64_t dst_offset,                      \\\n                               __global ELEM_TYPE *src_mem,             \\\n                               int64_t src_offset,                      \\\n                               int64_t n,                               \\\n                               int r,                                   \\\n                               int64_t shape0, int64_t dst_stride0, int64_t src_stride0, \\\n                               int64_t shape1, int64_t dst_stride1, int64_t src_stride1, \\\n                               int64_t shape2, int64_t dst_stride2, int64_t src_stride2, \\\n                               int64_t shape3, int64_t dst_stride3, int64_t src_stride3, \\\n                               int64_t shape4, int64_t dst_stride4, int64_t src_stride4, \\\n                               int64_t shape5, int64_t dst_stride5, int64_t src_stride5, \\\n                               int64_t shape6, int64_t dst_stride6, int64_t src_stride6, \\\n                               int64_t shape7, int64_t dst_stride7, int64_t src_stride7) { \\\n  int64_t gtid = get_global_id(0);                                      \\\n  int64_t remainder = gtid;                                             \\\n                                             ", "                           \\\n  if (gtid >= n) {                                                      \\\n    return;                                                             \\\n  }                                                                     \\\n                                                                        \\\n  if (r > 0) {                                                          \\\n    int64_t i = remainder % shape0;                                     \\\n    dst_offset += i * dst_stride0;                                      \\\n    src_offset += i * src_stride0;                                      \\\n    remainder /= shape0;                                                \\\n  }                                                                     \\\n  if (r > 1) {                                                          \\\n    int64_t i = remainder % shape1;                                     \\\n    dst_offset += i * dst_stride1;                                      \\\n    src_offset += i * src_stride1;                                      \\\n    remainder /= shape1;                                                \\\n  }                                                                     \\\n  if (r > 2) {                                                          \\\n    int64_t i = remainder % shape2;                                     \\\n    dst_offset += i * dst_stride2;                                      \\\n    src_offset += i * src_stride2;                                      \\\n    remainder /= shape2;                                                \\\n  }                                                                     \\\n  if (r > 3) {                                                          \\\n    int64_t i = remainder % shape3;                                     \\\n    dst_offset += i * dst_stride3;                                      \\\n    src_offset += i * src_stride3;                                      \\\n    remainder /= shape3;                       ",
                                    "                         \\\n  }                                                                     \\\n  if (r > 4) {                                                          \\\n    int64_t i = remainder % shape4;                                     \\\n    dst_offset += i * dst_stride4;                                      \\\n    src_offset += i * src_stride4;                                      \\\n    remainder /= shape4;                                                \\\n  }                                                                     \\\n  if (r > 5) {                                                          \\\n    int64_t i = remainder % shape5;                                     \\\n    dst_offset += i * dst_stride5;                                      \\\n    src_offset += i * src_stride5;                                      \\\n    remainder /= shape5;                                                \\\n  }                                                                     \\\n  if (r > 6) {                                                          \\\n    int64_t i = remainder % shape6;                                     \\\n    dst_offset += i * dst_stride6;                                      \\\n    src_offset += i * src_stride6;                                      \\\n    remainder /= shape6;                                                \\\n  }                                                                     \\\n  if (r > 7) {                                                          \\\n    int64_t i = remainder % shape7;                                     \\\n    dst_offset += i * dst_stride7;                                      \\\n    src_offset += i * src_stride7;                                      \\\n    remainder /= shape7;                                                \\\n  }                                                                     \\\n                                                                        \\\n  dst_mem[dst_offset] = src_mem[src_offset];     ", "                       \\\n}\n\nGEN_COPY_KERNEL(1b, uint8_t)\nGEN_COPY_KERNEL(2b, uint16_t)\nGEN_COPY_KERNEL(4b, uint32_t)\nGEN_COPY_KERNEL(8b, uint64_t)\n\n// End of copy.cl\n\n\n\nFUTHARK_KERNEL\nvoid builtinzhiota_i64ziiota_i64_34171(int64_t n_34167, int64_t x_34168, int64_t s_34169, int64_t virt_num_tblocks_34176, int64_t num_tblocks_34177, __global unsigned char *mem_34166)\n{\n    int32_t iota_ltid_34172;\n    int32_t tblock_sizze_34174;\n    int32_t iota_gid_34173;\n    int32_t iota_gtid_34171;\n    int32_t phys_tblock_id_34178;\n    int32_t iterations_34179;\n    \n    iota_ltid_34172 = get_local_id(0);\n    tblock_sizze_34174 = get_local_size(0);\n    iota_gid_34173 = get_tblock_id(0);\n    iota_gtid_34171 = iota_gid_34173 * tblock_sizze_34174 + iota_ltid_34172;\n    phys_tblock_id_34178 = get_tblock_id(0);\n    iterations_34179 = sdiv_up32(sext_i64_i32(virt_num_tblocks_34176) - phys_tblock_id_34178, sext_i64_i32(num_tblocks_34177));\n    for (int32_t i_34180 = 0; i_34180 < iterations_34179; i_34180++) {\n        int32_t virt_tblock_id_34181;\n        int64_t global_tid_34182;\n        \n        virt_tblock_id_34181 = phys_tblock_id_34178 + i_34180 * sext_i64_i32(num_tblocks_34177);\n        global_tid_34182 = sext_i32_i64(virt_tblock_id_34181) * sext_i32_i64(tblock_sizze_34174) + sext_i32_i64(iota_ltid_34172);\n        if (slt64(global_tid_34182, n_34167)) {\n            ((__global int64_t *) mem_34166)[global_tid_34182] = add64(mul64(global_tid_34182, s_34169), x_34168);\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_f32zireplicate_34417(int64_t num_elems_34413, float val_34414, int64_t replicate_n_34416, int64_t virt_num_tblocks_34422, int64_t num_tblocks_34423, __global unsigned char *mem_34412)\n{\n    int32_t replicate_ltid_34418;\n    int32_t tblock_sizze_34420;\n    int32_t replicate_gid_34419;\n    int32_t replicate_gtid_34417;\n    int32_t phys_tblock_id_34424;\n    int32_t iterations_34425;\n", "    \n    replicate_ltid_34418 = get_local_id(0);\n    tblock_sizze_34420 = get_local_size(0);\n    replicate_gid_34419 = get_tblock_id(0);\n    replicate_gtid_34417 = replicate_gid_34419 * tblock_sizze_34420 + replicate_ltid_34418;\n    phys_tblock_id_34424 = get_tblock_id(0);\n    iterations_34425 = sdiv_up32(sext_i64_i32(virt_num_tblocks_34422) - phys_tblock_id_34424, sext_i64_i32(num_tblocks_34423));\n    for (int32_t i_34426 = 0; i_34426 < iterations_34425; i_34426++) {\n        int32_t virt_tblock_id_34427;\n        int64_t global_tid_34428;\n        int64_t slice_34430;\n        int64_t rep_i_34429;\n        int64_t remnant_34431;\n        \n        virt_tblock_id_34427 = phys_tblock_id_34424 + i_34426 * sext_i64_i32(num_tblocks_34423);\n        global_tid_34428 = sext_i32_i64(virt_tblock_id_34427) * sext_i32_i64(tblock_sizze_34420) + sext_i32_i64(replicate_ltid_34418);\n        slice_34430 = num_elems_34413;\n        rep_i_34429 = global_tid_34428;\n        remnant_34431 = global_tid_34428 - rep_i_34429;\n        if (slt64(global_tid_34428, replicate_n_34416)) {\n            ((__global float *) mem_34412)[rep_i_34429] = val_34414;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_f64zireplicate_34417(int64_t num_elems_34413, double val_34414, int64_t replicate_n_34416, int64_t virt_num_tblocks_34422, int64_t num_tblocks_34423, __global unsigned char *mem_34412)\n{\n    int32_t replicate_ltid_34418;\n    int32_t tblock_sizze_34420;\n    int32_t replicate_gid_34419;\n    int32_t replicate_gtid_34417;\n    int32_t phys_tblock_id_34424;\n    int32_t iterations_34425;\n    \n    replicate_ltid_34418 = get_local_id(0);\n    tblock_sizze_34420 = get_local_size(0);\n    replicate_gid_34419 = get_tblock_id(0);\n    replicate_gtid_34417 = replicate_gid_34419 * tblock_sizze_34420 + replicate_ltid_34418;\n    phys_tblock_id_34424 = get_tblock_id(0);\n    iterations_34425 = sdiv_up32(sext_i64_i32(virt_num_tblo",
                                    "cks_34422) - phys_tblock_id_34424, sext_i64_i32(num_tblocks_34423));\n    for (int32_t i_34426 = 0; i_34426 < iterations_34425; i_34426++) {\n        int32_t virt_tblock_id_34427;\n        int64_t global_tid_34428;\n        int64_t slice_34430;\n        int64_t rep_i_34429;\n        int64_t remnant_34431;\n        \n        virt_tblock_id_34427 = phys_tblock_id_34424 + i_34426 * sext_i64_i32(num_tblocks_34423);\n        global_tid_34428 = sext_i32_i64(virt_tblock_id_34427) * sext_i32_i64(tblock_sizze_34420) + sext_i32_i64(replicate_ltid_34418);\n        slice_34430 = num_elems_34413;\n        rep_i_34429 = global_tid_34428;\n        remnant_34431 = global_tid_34428 - rep_i_34429;\n        if (slt64(global_tid_34428, replicate_n_34416)) {\n            ((__global double *) mem_34412)[rep_i_34429] = val_34414;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_i16zireplicate_34417(int64_t num_elems_34413, int16_t val_34414, int64_t replicate_n_34416, int64_t virt_num_tblocks_34422, int64_t num_tblocks_34423, __global unsigned char *mem_34412)\n{\n    int32_t replicate_ltid_34418;\n    int32_t tblock_sizze_34420;\n    int32_t replicate_gid_34419;\n    int32_t replicate_gtid_34417;\n    int32_t phys_tblock_id_34424;\n    int32_t iterations_34425;\n    \n    replicate_ltid_34418 = get_local_id(0);\n    tblock_sizze_34420 = get_local_size(0);\n    replicate_gid_34419 = get_tblock_id(0);\n    replicate_gtid_34417 = replicate_gid_34419 * tblock_sizze_34420 + replicate_ltid_34418;\n    phys_tblock_id_34424 = get_tblock_id(0);\n    iterations_34425 = sdiv_up32(sext_i64_i32(virt_num_tblocks_34422) - phys_tblock_id_34424, sext_i64_i32(num_tblocks_34423));\n    for (int32_t i_34426 = 0; i_34426 < iterations_34425; i_34426++) {\n        int32_t virt_tblock_id_34427;\n        int64_t global_tid_34428;\n        int64_t slice_34430;\n        int64_t rep_i_34429;\n        int64_t remnant_34431;\n        \n        virt_tblock_i", "d_34427 = phys_tblock_id_34424 + i_34426 * sext_i64_i32(num_tblocks_34423);\n        global_tid_34428 = sext_i32_i64(virt_tblock_id_34427) * sext_i32_i64(tblock_sizze_34420) + sext_i32_i64(replicate_ltid_34418);\n        slice_34430 = num_elems_34413;\n        rep_i_34429 = global_tid_34428;\n        remnant_34431 = global_tid_34428 - rep_i_34429;\n        if (slt64(global_tid_34428, replicate_n_34416)) {\n            ((__global int16_t *) mem_34412)[rep_i_34429] = val_34414;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_i32zireplicate_34064(int64_t num_elems_34060, int32_t val_34061, int64_t replicate_n_34063, int64_t virt_num_tblocks_34069, int64_t num_tblocks_34070, __global unsigned char *mem_34059)\n{\n    int32_t replicate_ltid_34065;\n    int32_t tblock_sizze_34067;\n    int32_t replicate_gid_34066;\n    int32_t replicate_gtid_34064;\n    int32_t phys_tblock_id_34071;\n    int32_t iterations_34072;\n    \n    replicate_ltid_34065 = get_local_id(0);\n    tblock_sizze_34067 = get_local_size(0);\n    replicate_gid_34066 = get_tblock_id(0);\n    replicate_gtid_34064 = replicate_gid_34066 * tblock_sizze_34067 + replicate_ltid_34065;\n    phys_tblock_id_34071 = get_tblock_id(0);\n    iterations_34072 = sdiv_up32(sext_i64_i32(virt_num_tblocks_34069) - phys_tblock_id_34071, sext_i64_i32(num_tblocks_34070));\n    for (int32_t i_34073 = 0; i_34073 < iterations_34072; i_34073++) {\n        int32_t virt_tblock_id_34074;\n        int64_t global_tid_34075;\n        int64_t slice_34077;\n        int64_t rep_i_34076;\n        int64_t remnant_34078;\n        \n        virt_tblock_id_34074 = phys_tblock_id_34071 + i_34073 * sext_i64_i32(num_tblocks_34070);\n        global_tid_34075 = sext_i32_i64(virt_tblock_id_34074) * sext_i32_i64(tblock_sizze_34067) + sext_i32_i64(replicate_ltid_34065);\n        slice_34077 = num_elems_34060;\n        rep_i_34076 = global_tid_34075;\n        remnant_34078 = global_tid_34075", " - rep_i_34076;\n        if (slt64(global_tid_34075, replicate_n_34063)) {\n            ((__global int32_t *) mem_34059)[rep_i_34076] = val_34061;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_i64zireplicate_34188(int64_t num_elems_34184, int64_t val_34185, int64_t replicate_n_34187, int64_t virt_num_tblocks_34193, int64_t num_tblocks_34194, __global unsigned char *mem_34183)\n{\n    int32_t replicate_ltid_34189;\n    int32_t tblock_sizze_34191;\n    int32_t replicate_gid_34190;\n    int32_t replicate_gtid_34188;\n    int32_t phys_tblock_id_34195;\n    int32_t iterations_34196;\n    \n    replicate_ltid_34189 = get_local_id(0);\n    tblock_sizze_34191 = get_local_size(0);\n    replicate_gid_34190 = get_tblock_id(0);\n    replicate_gtid_34188 = replicate_gid_34190 * tblock_sizze_34191 + replicate_ltid_34189;\n    phys_tblock_id_34195 = get_tblock_id(0);\n    iterations_34196 = sdiv_up32(sext_i64_i32(virt_num_tblocks_34193) - phys_tblock_id_34195, sext_i64_i32(num_tblocks_34194));\n    for (int32_t i_34197 = 0; i_34197 < iterations_34196; i_34197++) {\n        int32_t virt_tblock_id_34198;\n        int64_t global_tid_34199;\n        int64_t slice_34201;\n        int64_t rep_i_34200;\n        int64_t remnant_34202;\n        \n        virt_tblock_id_34198 = phys_tblock_id_34195 + i_34197 * sext_i64_i32(num_tblocks_34194);\n        global_tid_34199 = sext_i32_i64(virt_tblock_id_34198) * sext_i32_i64(tblock_sizze_34191) + sext_i32_i64(replicate_ltid_34189);\n        slice_34201 = num_elems_34184;\n        rep_i_34200 = global_tid_34199;\n        remnant_34202 = global_tid_34199 - rep_i_34200;\n        if (slt64(global_tid_34199, replicate_n_34187)) {\n            ((__global int64_t *) mem_34183)[rep_i_34200] = val_34185;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_i8zireplicate_34038(int64_t num_elems_3",
                                    "4034, int8_t val_34035, int64_t replicate_n_34037, int64_t virt_num_tblocks_34043, int64_t num_tblocks_34044, __global unsigned char *mem_34033)\n{\n    int32_t replicate_ltid_34039;\n    int32_t tblock_sizze_34041;\n    int32_t replicate_gid_34040;\n    int32_t replicate_gtid_34038;\n    int32_t phys_tblock_id_34045;\n    int32_t iterations_34046;\n    \n    replicate_ltid_34039 = get_local_id(0);\n    tblock_sizze_34041 = get_local_size(0);\n    replicate_gid_34040 = get_tblock_id(0);\n    replicate_gtid_34038 = replicate_gid_34040 * tblock_sizze_34041 + replicate_ltid_34039;\n    phys_tblock_id_34045 = get_tblock_id(0);\n    iterations_34046 = sdiv_up32(sext_i64_i32(virt_num_tblocks_34043) - phys_tblock_id_34045, sext_i64_i32(num_tblocks_34044));\n    for (int32_t i_34047 = 0; i_34047 < iterations_34046; i_34047++) {\n        int32_t virt_tblock_id_34048;\n        int64_t global_tid_34049;\n        int64_t slice_34051;\n        int64_t rep_i_34050;\n        int64_t remnant_34052;\n        \n        virt_tblock_id_34048 = phys_tblock_id_34045 + i_34047 * sext_i64_i32(num_tblocks_34044);\n        global_tid_34049 = sext_i32_i64(virt_tblock_id_34048) * sext_i32_i64(tblock_sizze_34041) + sext_i32_i64(replicate_ltid_34039);\n        slice_34051 = num_elems_34034;\n        rep_i_34050 = global_tid_34049;\n        remnant_34052 = global_tid_34049 - rep_i_34050;\n        if (slt64(global_tid_34049, replicate_n_34037)) {\n            ((__global int8_t *) mem_34033)[rep_i_34050] = val_34035;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_doublezisegmap_33060_dim1, 1, 1)\nvoid gather_payloads_doublezisegmap_33060(__global int *global_failure, int64_t niz2084U_29871, int64_t incr_29873, __global unsigned char *is_mem_33832, __global unsigned char *mem_33836)\n{\n    #define segmap_tblock_sizze_33056 (gather_payloads_doublezisegmap_33060zisegmap_tblock_sizze_33056)\n    if (*global_failure >= 0)\n        return;\n", "    \n    int32_t local_tid_34022;\n    int32_t tblock_sizze_34025;\n    int32_t wave_sizze_34024;\n    int32_t block_id_34023;\n    int32_t global_tid_34021;\n    int64_t phys_tid_33060;\n    int64_t global_tid_34026;\n    int64_t slice_34027;\n    int64_t gtid_33059;\n    int64_t remnant_34028;\n    \n    local_tid_34022 = get_local_id(0);\n    tblock_sizze_34025 = get_local_size(0);\n    wave_sizze_34024 = LOCKSTEP_WIDTH;\n    block_id_34023 = get_tblock_id(0);\n    global_tid_34021 = block_id_34023 * tblock_sizze_34025 + local_tid_34022;\n    phys_tid_33060 = sext_i32_i64(global_tid_34021);\n    global_tid_34026 = sext_i32_i64(block_id_34023) * segmap_tblock_sizze_33056 + sext_i32_i64(local_tid_34022);\n    slice_34027 = niz2084U_29871;\n    gtid_33059 = global_tid_34026;\n    remnant_34028 = global_tid_34026 - gtid_33059;\n    if (slt64(gtid_33059, niz2084U_29871)) {\n        int64_t eta_p_33061;\n        int64_t lifted_lambda_res_33062;\n        \n        eta_p_33061 = ((__global int64_t *) is_mem_33832)[gtid_33059];\n        lifted_lambda_res_33062 = sub64(eta_p_33061, incr_29873);\n        ((__global int64_t *) mem_33836)[gtid_33059] = lifted_lambda_res_33062;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_33056\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_doublezisegmap_33088_dim1, 1, 1)\nvoid gather_payloads_doublezisegmap_33088(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t niz2084U_29871, int64_t lower_bound_31864, int64_t min_res_31866, int64_t j_m_i_31867, __global unsigned char *ys_mem_33833, __global unsigned char *mem_param_33841, __global unsigned char *mem_param_33844, __global unsigned char *mem_33849)\n{\n    #define segmap_tblock_sizze_33084 (gather_payloads_doublezisegmap_33088zisegmap_tblock_sizze_33084)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34057;\n    int32_t tblock_sizze_34060;\n    int32_t wave_sizze_34059;\n    int32_t block_id_34058;\n    int32_t global_tid_34056;\n    i", "nt64_t phys_tid_33088;\n    int64_t global_tid_34061;\n    int64_t slice_34062;\n    int64_t gtid_33087;\n    int64_t remnant_34063;\n    \n    local_tid_34057 = get_local_id(0);\n    tblock_sizze_34060 = get_local_size(0);\n    wave_sizze_34059 = LOCKSTEP_WIDTH;\n    block_id_34058 = get_tblock_id(0);\n    global_tid_34056 = block_id_34058 * tblock_sizze_34060 + local_tid_34057;\n    phys_tid_33088 = sext_i32_i64(global_tid_34056);\n    global_tid_34061 = sext_i32_i64(block_id_34058) * segmap_tblock_sizze_33084 + sext_i32_i64(local_tid_34057);\n    slice_34062 = niz2084U_29871;\n    gtid_33087 = global_tid_34061;\n    remnant_34063 = global_tid_34061 - gtid_33087;\n    if (slt64(gtid_33087, niz2084U_29871)) {\n        int64_t eta_p_33089;\n        bool cond_33091;\n        bool cond_t_res_33092;\n        bool x_33093;\n        double lifted_lambda_res_33094;\n        \n        eta_p_33089 = ((__global int64_t *) mem_param_33841)[gtid_33087];\n        cond_33091 = sle64(lower_bound_31864, eta_p_33089);\n        cond_t_res_33092 = slt64(eta_p_33089, min_res_31866);\n        x_33093 = cond_33091 && cond_t_res_33092;\n        if (x_33093) {\n            int64_t tmp_33095;\n            bool x_33096;\n            bool y_33097;\n            bool bounds_check_33098;\n            bool index_certs_33099;\n            double tmp_33100;\n            \n            tmp_33095 = sub64(eta_p_33089, lower_bound_31864);\n            x_33096 = sle64((int64_t) 0, tmp_33095);\n            y_33097 = slt64(tmp_33095, j_m_i_31867);\n            bounds_check_33098 = x_33096 && y_33097;\n            if (!bounds_check_33098) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 0) == -1) {\n                        global_failure_args[0] = (int64_t) tmp_33095;\n                        global_failure_args[1] = (int64_t) j_m_i_31867;\n                        ;\n                    }\n                    return;\n                }\n            }\n            tmp_33100 = ((__global double *) ys_mem_33833)[et",
                                    "a_p_33089];\n            lifted_lambda_res_33094 = tmp_33100;\n        } else {\n            double eta_p_33090 = ((__global double *) mem_param_33844)[gtid_33087];\n            \n            lifted_lambda_res_33094 = eta_p_33090;\n        }\n        ((__global double *) mem_33849)[gtid_33087] = lifted_lambda_res_33094;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_33084\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_double_GFURzisegmap_33340_dim1, 1, 1)\nvoid gather_payloads_double_GFURzisegmap_33340(__global int *global_failure, int64_t ni_31378, int64_t incr_31380, __global unsigned char *is_mem_33833, __global unsigned char *mem_33837)\n{\n    #define segmap_tblock_sizze_33336 (gather_payloads_double_GFURzisegmap_33340zisegmap_tblock_sizze_33336)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34022;\n    int32_t tblock_sizze_34025;\n    int32_t wave_sizze_34024;\n    int32_t block_id_34023;\n    int32_t global_tid_34021;\n    int64_t phys_tid_33340;\n    int64_t global_tid_34026;\n    int64_t slice_34027;\n    int64_t gtid_33339;\n    int64_t remnant_34028;\n    \n    local_tid_34022 = get_local_id(0);\n    tblock_sizze_34025 = get_local_size(0);\n    wave_sizze_34024 = LOCKSTEP_WIDTH;\n    block_id_34023 = get_tblock_id(0);\n    global_tid_34021 = block_id_34023 * tblock_sizze_34025 + local_tid_34022;\n    phys_tid_33340 = sext_i32_i64(global_tid_34021);\n    global_tid_34026 = sext_i32_i64(block_id_34023) * segmap_tblock_sizze_33336 + sext_i32_i64(local_tid_34022);\n    slice_34027 = ni_31378;\n    gtid_33339 = global_tid_34026;\n    remnant_34028 = global_tid_34026 - gtid_33339;\n    if (slt64(gtid_33339, ni_31378)) {\n        int64_t eta_p_33341;\n        int64_t lifted_lambda_res_33342;\n        \n        eta_p_33341 = ((__global int64_t *) is_mem_33833)[gtid_33339];\n        lifted_lambda_res_33342 = sub64(eta_p_33341, incr_31380);\n        ((__global int64_t *) mem_33837)[gtid_33339] = lifted_lambda_res_33342;\n    }\n    \n  error_0:\n    return;\n    #undef ", "segmap_tblock_sizze_33336\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_double_GFURzisegmap_33368_dim1, 1, 1)\nvoid gather_payloads_double_GFURzisegmap_33368(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t ni_31378, int64_t lower_bound_31864, int64_t min_res_31866, int64_t j_m_i_31867, __global unsigned char *ys_mem_33834, __global unsigned char *mem_param_33840, __global unsigned char *mem_param_33843, __global unsigned char *mem_33848)\n{\n    #define segmap_tblock_sizze_33364 (gather_payloads_double_GFURzisegmap_33368zisegmap_tblock_sizze_33364)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34037;\n    int32_t tblock_sizze_34040;\n    int32_t wave_sizze_34039;\n    int32_t block_id_34038;\n    int32_t global_tid_34036;\n    int64_t phys_tid_33368;\n    int64_t global_tid_34041;\n    int64_t slice_34042;\n    int64_t gtid_33367;\n    int64_t remnant_34043;\n    \n    local_tid_34037 = get_local_id(0);\n    tblock_sizze_34040 = get_local_size(0);\n    wave_sizze_34039 = LOCKSTEP_WIDTH;\n    block_id_34038 = get_tblock_id(0);\n    global_tid_34036 = block_id_34038 * tblock_sizze_34040 + local_tid_34037;\n    phys_tid_33368 = sext_i32_i64(global_tid_34036);\n    global_tid_34041 = sext_i32_i64(block_id_34038) * segmap_tblock_sizze_33364 + sext_i32_i64(local_tid_34037);\n    slice_34042 = ni_31378;\n    gtid_33367 = global_tid_34041;\n    remnant_34043 = global_tid_34041 - gtid_33367;\n    if (slt64(gtid_33367, ni_31378)) {\n        int64_t eta_p_33369;\n        bool cond_33371;\n        bool cond_t_res_33372;\n        bool x_33373;\n        double lifted_lambda_res_33374;\n        \n        eta_p_33369 = ((__global int64_t *) mem_param_33840)[gtid_33367];\n        cond_33371 = sle64(lower_bound_31864, eta_p_33369);\n        cond_t_res_33372 = slt64(eta_p_33369, min_res_31866);\n        x_33373 = cond_33371 && cond_t_res_33372;\n        if (x_33373) {\n            int64_t tmp_33375;\n            bool x_33376;\n            bool y_33", "377;\n            bool bounds_check_33378;\n            bool index_certs_33379;\n            double tmp_33380;\n            \n            tmp_33375 = sub64(eta_p_33369, lower_bound_31864);\n            x_33376 = sle64((int64_t) 0, tmp_33375);\n            y_33377 = slt64(tmp_33375, j_m_i_31867);\n            bounds_check_33378 = x_33376 && y_33377;\n            if (!bounds_check_33378) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 1) == -1) {\n                        global_failure_args[0] = (int64_t) tmp_33375;\n                        global_failure_args[1] = (int64_t) j_m_i_31867;\n                        ;\n                    }\n                    return;\n                }\n            }\n            tmp_33380 = ((__global double *) ys_mem_33834)[eta_p_33369];\n            lifted_lambda_res_33374 = tmp_33380;\n        } else {\n            double eta_p_33370 = ((__global double *) mem_param_33843)[gtid_33367];\n            \n            lifted_lambda_res_33374 = eta_p_33370;\n        }\n        ((__global double *) mem_33848)[gtid_33367] = lifted_lambda_res_33374;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_33364\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_floatzisegmap_33004_dim1, 1, 1)\nvoid gather_payloads_floatzisegmap_33004(__global int *global_failure, int64_t niz2084U_29531, int64_t incr_29533, __global unsigned char *is_mem_33832, __global unsigned char *mem_33836)\n{\n    #define segmap_tblock_sizze_33000 (gather_payloads_floatzisegmap_33004zisegmap_tblock_sizze_33000)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34022;\n    int32_t tblock_sizze_34025;\n    int32_t wave_sizze_34024;\n    int32_t block_id_34023;\n    int32_t global_tid_34021;\n    int64_t phys_tid_33004;\n    int64_t global_tid_34026;\n    int64_t slice_34027;\n    int64_t gtid_33003;\n    int64_t remnant_34028;\n    \n    local_tid_34022 = get_local_id(0);\n    tblock_sizze_34025 = get_local_size(0);\n    wave_sizze_34024 = LOCKSTEP_WID",
                                    "TH;\n    block_id_34023 = get_tblock_id(0);\n    global_tid_34021 = block_id_34023 * tblock_sizze_34025 + local_tid_34022;\n    phys_tid_33004 = sext_i32_i64(global_tid_34021);\n    global_tid_34026 = sext_i32_i64(block_id_34023) * segmap_tblock_sizze_33000 + sext_i32_i64(local_tid_34022);\n    slice_34027 = niz2084U_29531;\n    gtid_33003 = global_tid_34026;\n    remnant_34028 = global_tid_34026 - gtid_33003;\n    if (slt64(gtid_33003, niz2084U_29531)) {\n        int64_t eta_p_33005;\n        int64_t lifted_lambda_res_33006;\n        \n        eta_p_33005 = ((__global int64_t *) is_mem_33832)[gtid_33003];\n        lifted_lambda_res_33006 = sub64(eta_p_33005, incr_29533);\n        ((__global int64_t *) mem_33836)[gtid_33003] = lifted_lambda_res_33006;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_33000\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_floatzisegmap_33032_dim1, 1, 1)\nvoid gather_payloads_floatzisegmap_33032(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t niz2084U_29531, int64_t lower_bound_31864, int64_t min_res_31866, int64_t j_m_i_31867, __global unsigned char *ys_mem_33833, __global unsigned char *mem_param_33841, __global unsigned char *mem_param_33844, __global unsigned char *mem_33849)\n{\n    #define segmap_tblock_sizze_33028 (gather_payloads_floatzisegmap_33032zisegmap_tblock_sizze_33028)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34057;\n    int32_t tblock_sizze_34060;\n    int32_t wave_sizze_34059;\n    int32_t block_id_34058;\n    int32_t global_tid_34056;\n    int64_t phys_tid_33032;\n    int64_t global_tid_34061;\n    int64_t slice_34062;\n    int64_t gtid_33031;\n    int64_t remnant_34063;\n    \n    local_tid_34057 = get_local_id(0);\n    tblock_sizze_34060 = get_local_size(0);\n    wave_sizze_34059 = LOCKSTEP_WIDTH;\n    block_id_34058 = get_tblock_id(0);\n    global_tid_34056 = block_id_34058 * tblock_sizze_34060 + local_tid_34057;\n    phys_tid_33032 = sext_i32_i64(global_", "tid_34056);\n    global_tid_34061 = sext_i32_i64(block_id_34058) * segmap_tblock_sizze_33028 + sext_i32_i64(local_tid_34057);\n    slice_34062 = niz2084U_29531;\n    gtid_33031 = global_tid_34061;\n    remnant_34063 = global_tid_34061 - gtid_33031;\n    if (slt64(gtid_33031, niz2084U_29531)) {\n        int64_t eta_p_33033;\n        bool cond_33035;\n        bool cond_t_res_33036;\n        bool x_33037;\n        float lifted_lambda_res_33038;\n        \n        eta_p_33033 = ((__global int64_t *) mem_param_33841)[gtid_33031];\n        cond_33035 = sle64(lower_bound_31864, eta_p_33033);\n        cond_t_res_33036 = slt64(eta_p_33033, min_res_31866);\n        x_33037 = cond_33035 && cond_t_res_33036;\n        if (x_33037) {\n            int64_t tmp_33039;\n            bool x_33040;\n            bool y_33041;\n            bool bounds_check_33042;\n            bool index_certs_33043;\n            float tmp_33044;\n            \n            tmp_33039 = sub64(eta_p_33033, lower_bound_31864);\n            x_33040 = sle64((int64_t) 0, tmp_33039);\n            y_33041 = slt64(tmp_33039, j_m_i_31867);\n            bounds_check_33042 = x_33040 && y_33041;\n            if (!bounds_check_33042) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 2) == -1) {\n                        global_failure_args[0] = (int64_t) tmp_33039;\n                        global_failure_args[1] = (int64_t) j_m_i_31867;\n                        ;\n                    }\n                    return;\n                }\n            }\n            tmp_33044 = ((__global float *) ys_mem_33833)[eta_p_33033];\n            lifted_lambda_res_33038 = tmp_33044;\n        } else {\n            float eta_p_33034 = ((__global float *) mem_param_33844)[gtid_33031];\n            \n            lifted_lambda_res_33038 = eta_p_33034;\n        }\n        ((__global float *) mem_33849)[gtid_33031] = lifted_lambda_res_33038;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_33028\n}\nFUTHARK_KERNEL_SIZED(gather_payl", "oads_float_GFURzisegmap_33284_dim1, 1, 1)\nvoid gather_payloads_float_GFURzisegmap_33284(__global int *global_failure, int64_t ni_31077, int64_t incr_31079, __global unsigned char *is_mem_33833, __global unsigned char *mem_33837)\n{\n    #define segmap_tblock_sizze_33280 (gather_payloads_float_GFURzisegmap_33284zisegmap_tblock_sizze_33280)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34022;\n    int32_t tblock_sizze_34025;\n    int32_t wave_sizze_34024;\n    int32_t block_id_34023;\n    int32_t global_tid_34021;\n    int64_t phys_tid_33284;\n    int64_t global_tid_34026;\n    int64_t slice_34027;\n    int64_t gtid_33283;\n    int64_t remnant_34028;\n    \n    local_tid_34022 = get_local_id(0);\n    tblock_sizze_34025 = get_local_size(0);\n    wave_sizze_34024 = LOCKSTEP_WIDTH;\n    block_id_34023 = get_tblock_id(0);\n    global_tid_34021 = block_id_34023 * tblock_sizze_34025 + local_tid_34022;\n    phys_tid_33284 = sext_i32_i64(global_tid_34021);\n    global_tid_34026 = sext_i32_i64(block_id_34023) * segmap_tblock_sizze_33280 + sext_i32_i64(local_tid_34022);\n    slice_34027 = ni_31077;\n    gtid_33283 = global_tid_34026;\n    remnant_34028 = global_tid_34026 - gtid_33283;\n    if (slt64(gtid_33283, ni_31077)) {\n        int64_t eta_p_33285;\n        int64_t lifted_lambda_res_33286;\n        \n        eta_p_33285 = ((__global int64_t *) is_mem_33833)[gtid_33283];\n        lifted_lambda_res_33286 = sub64(eta_p_33285, incr_31079);\n        ((__global int64_t *) mem_33837)[gtid_33283] = lifted_lambda_res_33286;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_33280\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_float_GFURzisegmap_33312_dim1, 1, 1)\nvoid gather_payloads_float_GFURzisegmap_33312(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t ni_31077, int64_t lower_bound_31864, int64_t min_res_31866, int64_t j_m_i_31867, __global unsigned char *ys_mem_33834, __global unsigned char *mem_param_33840, __global uns",
                                    "igned char *mem_param_33843, __global unsigned char *mem_33848)\n{\n    #define segmap_tblock_sizze_33308 (gather_payloads_float_GFURzisegmap_33312zisegmap_tblock_sizze_33308)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34037;\n    int32_t tblock_sizze_34040;\n    int32_t wave_sizze_34039;\n    int32_t block_id_34038;\n    int32_t global_tid_34036;\n    int64_t phys_tid_33312;\n    int64_t global_tid_34041;\n    int64_t slice_34042;\n    int64_t gtid_33311;\n    int64_t remnant_34043;\n    \n    local_tid_34037 = get_local_id(0);\n    tblock_sizze_34040 = get_local_size(0);\n    wave_sizze_34039 = LOCKSTEP_WIDTH;\n    block_id_34038 = get_tblock_id(0);\n    global_tid_34036 = block_id_34038 * tblock_sizze_34040 + local_tid_34037;\n    phys_tid_33312 = sext_i32_i64(global_tid_34036);\n    global_tid_34041 = sext_i32_i64(block_id_34038) * segmap_tblock_sizze_33308 + sext_i32_i64(local_tid_34037);\n    slice_34042 = ni_31077;\n    gtid_33311 = global_tid_34041;\n    remnant_34043 = global_tid_34041 - gtid_33311;\n    if (slt64(gtid_33311, ni_31077)) {\n        int64_t eta_p_33313;\n        bool cond_33315;\n        bool cond_t_res_33316;\n        bool x_33317;\n        float lifted_lambda_res_33318;\n        \n        eta_p_33313 = ((__global int64_t *) mem_param_33840)[gtid_33311];\n        cond_33315 = sle64(lower_bound_31864, eta_p_33313);\n        cond_t_res_33316 = slt64(eta_p_33313, min_res_31866);\n        x_33317 = cond_33315 && cond_t_res_33316;\n        if (x_33317) {\n            int64_t tmp_33319;\n            bool x_33320;\n            bool y_33321;\n            bool bounds_check_33322;\n            bool index_certs_33323;\n            float tmp_33324;\n            \n            tmp_33319 = sub64(eta_p_33313, lower_bound_31864);\n            x_33320 = sle64((int64_t) 0, tmp_33319);\n            y_33321 = slt64(tmp_33319, j_m_i_31867);\n            bounds_check_33322 = x_33320 && y_33321;\n            if (!bounds_check_33322) {\n                {\n                    if (atom", "ic_cmpxchg_i32_global(global_failure, -1, 3) == -1) {\n                        global_failure_args[0] = (int64_t) tmp_33319;\n                        global_failure_args[1] = (int64_t) j_m_i_31867;\n                        ;\n                    }\n                    return;\n                }\n            }\n            tmp_33324 = ((__global float *) ys_mem_33834)[eta_p_33313];\n            lifted_lambda_res_33318 = tmp_33324;\n        } else {\n            float eta_p_33314 = ((__global float *) mem_param_33843)[gtid_33311];\n            \n            lifted_lambda_res_33318 = eta_p_33314;\n        }\n        ((__global float *) mem_33848)[gtid_33311] = lifted_lambda_res_33318;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_33308\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_intzisegmap_32892_dim1, 1, 1)\nvoid gather_payloads_intzisegmap_32892(__global int *global_failure, int64_t niz2084U_28882, int64_t incr_28884, __global unsigned char *is_mem_33832, __global unsigned char *mem_33836)\n{\n    #define segmap_tblock_sizze_32888 (gather_payloads_intzisegmap_32892zisegmap_tblock_sizze_32888)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34022;\n    int32_t tblock_sizze_34025;\n    int32_t wave_sizze_34024;\n    int32_t block_id_34023;\n    int32_t global_tid_34021;\n    int64_t phys_tid_32892;\n    int64_t global_tid_34026;\n    int64_t slice_34027;\n    int64_t gtid_32891;\n    int64_t remnant_34028;\n    \n    local_tid_34022 = get_local_id(0);\n    tblock_sizze_34025 = get_local_size(0);\n    wave_sizze_34024 = LOCKSTEP_WIDTH;\n    block_id_34023 = get_tblock_id(0);\n    global_tid_34021 = block_id_34023 * tblock_sizze_34025 + local_tid_34022;\n    phys_tid_32892 = sext_i32_i64(global_tid_34021);\n    global_tid_34026 = sext_i32_i64(block_id_34023) * segmap_tblock_sizze_32888 + sext_i32_i64(local_tid_34022);\n    slice_34027 = niz2084U_28882;\n    gtid_32891 = global_tid_34026;\n    remnant_34028 = global_tid_34026 - gtid_32891;\n    if (slt64(gtid_32891, niz20", "84U_28882)) {\n        int64_t eta_p_32893;\n        int64_t lifted_lambda_res_32894;\n        \n        eta_p_32893 = ((__global int64_t *) is_mem_33832)[gtid_32891];\n        lifted_lambda_res_32894 = sub64(eta_p_32893, incr_28884);\n        ((__global int64_t *) mem_33836)[gtid_32891] = lifted_lambda_res_32894;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_32888\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_intzisegmap_32920_dim1, 1, 1)\nvoid gather_payloads_intzisegmap_32920(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t niz2084U_28882, int64_t lower_bound_31864, int64_t min_res_31866, int64_t j_m_i_31867, __global unsigned char *ys_mem_33833, __global unsigned char *mem_param_33841, __global unsigned char *mem_param_33844, __global unsigned char *mem_33849)\n{\n    #define segmap_tblock_sizze_32916 (gather_payloads_intzisegmap_32920zisegmap_tblock_sizze_32916)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34057;\n    int32_t tblock_sizze_34060;\n    int32_t wave_sizze_34059;\n    int32_t block_id_34058;\n    int32_t global_tid_34056;\n    int64_t phys_tid_32920;\n    int64_t global_tid_34061;\n    int64_t slice_34062;\n    int64_t gtid_32919;\n    int64_t remnant_34063;\n    \n    local_tid_34057 = get_local_id(0);\n    tblock_sizze_34060 = get_local_size(0);\n    wave_sizze_34059 = LOCKSTEP_WIDTH;\n    block_id_34058 = get_tblock_id(0);\n    global_tid_34056 = block_id_34058 * tblock_sizze_34060 + local_tid_34057;\n    phys_tid_32920 = sext_i32_i64(global_tid_34056);\n    global_tid_34061 = sext_i32_i64(block_id_34058) * segmap_tblock_sizze_32916 + sext_i32_i64(local_tid_34057);\n    slice_34062 = niz2084U_28882;\n    gtid_32919 = global_tid_34061;\n    remnant_34063 = global_tid_34061 - gtid_32919;\n    if (slt64(gtid_32919, niz2084U_28882)) {\n        int64_t eta_p_32921;\n        bool cond_32923;\n        bool cond_t_res_32924;\n        bool x_32925;\n        int32_t lifted_lambda_res_32926;\n      ",
                                    "  \n        eta_p_32921 = ((__global int64_t *) mem_param_33841)[gtid_32919];\n        cond_32923 = sle64(lower_bound_31864, eta_p_32921);\n        cond_t_res_32924 = slt64(eta_p_32921, min_res_31866);\n        x_32925 = cond_32923 && cond_t_res_32924;\n        if (x_32925) {\n            int64_t tmp_32927;\n            bool x_32928;\n            bool y_32929;\n            bool bounds_check_32930;\n            bool index_certs_32931;\n            int32_t tmp_32932;\n            \n            tmp_32927 = sub64(eta_p_32921, lower_bound_31864);\n            x_32928 = sle64((int64_t) 0, tmp_32927);\n            y_32929 = slt64(tmp_32927, j_m_i_31867);\n            bounds_check_32930 = x_32928 && y_32929;\n            if (!bounds_check_32930) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 4) == -1) {\n                        global_failure_args[0] = (int64_t) tmp_32927;\n                        global_failure_args[1] = (int64_t) j_m_i_31867;\n                        ;\n                    }\n                    return;\n                }\n            }\n            tmp_32932 = ((__global int32_t *) ys_mem_33833)[eta_p_32921];\n            lifted_lambda_res_32926 = tmp_32932;\n        } else {\n            int32_t eta_p_32922 = ((__global int32_t *) mem_param_33844)[gtid_32919];\n            \n            lifted_lambda_res_32926 = eta_p_32922;\n        }\n        ((__global int32_t *) mem_33849)[gtid_32919] = lifted_lambda_res_32926;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_32916\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_int_GFURzisegmap_33172_dim1, 1, 1)\nvoid gather_payloads_int_GFURzisegmap_33172(__global int *global_failure, int64_t ni_30475, int64_t incr_30477, __global unsigned char *is_mem_33833, __global unsigned char *mem_33837)\n{\n    #define segmap_tblock_sizze_33168 (gather_payloads_int_GFURzisegmap_33172zisegmap_tblock_sizze_33168)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34022;\n    int32_t tblock_", "sizze_34025;\n    int32_t wave_sizze_34024;\n    int32_t block_id_34023;\n    int32_t global_tid_34021;\n    int64_t phys_tid_33172;\n    int64_t global_tid_34026;\n    int64_t slice_34027;\n    int64_t gtid_33171;\n    int64_t remnant_34028;\n    \n    local_tid_34022 = get_local_id(0);\n    tblock_sizze_34025 = get_local_size(0);\n    wave_sizze_34024 = LOCKSTEP_WIDTH;\n    block_id_34023 = get_tblock_id(0);\n    global_tid_34021 = block_id_34023 * tblock_sizze_34025 + local_tid_34022;\n    phys_tid_33172 = sext_i32_i64(global_tid_34021);\n    global_tid_34026 = sext_i32_i64(block_id_34023) * segmap_tblock_sizze_33168 + sext_i32_i64(local_tid_34022);\n    slice_34027 = ni_30475;\n    gtid_33171 = global_tid_34026;\n    remnant_34028 = global_tid_34026 - gtid_33171;\n    if (slt64(gtid_33171, ni_30475)) {\n        int64_t eta_p_33173;\n        int64_t lifted_lambda_res_33174;\n        \n        eta_p_33173 = ((__global int64_t *) is_mem_33833)[gtid_33171];\n        lifted_lambda_res_33174 = sub64(eta_p_33173, incr_30477);\n        ((__global int64_t *) mem_33837)[gtid_33171] = lifted_lambda_res_33174;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_33168\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_int_GFURzisegmap_33200_dim1, 1, 1)\nvoid gather_payloads_int_GFURzisegmap_33200(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t ni_30475, int64_t lower_bound_31864, int64_t min_res_31866, int64_t j_m_i_31867, __global unsigned char *ys_mem_33834, __global unsigned char *mem_param_33840, __global unsigned char *mem_param_33843, __global unsigned char *mem_33848)\n{\n    #define segmap_tblock_sizze_33196 (gather_payloads_int_GFURzisegmap_33200zisegmap_tblock_sizze_33196)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34037;\n    int32_t tblock_sizze_34040;\n    int32_t wave_sizze_34039;\n    int32_t block_id_34038;\n    int32_t global_tid_34036;\n    int64_t phys_tid_33200;\n    int64_t global_tid_34041;\n    int64_t ", "slice_34042;\n    int64_t gtid_33199;\n    int64_t remnant_34043;\n    \n    local_tid_34037 = get_local_id(0);\n    tblock_sizze_34040 = get_local_size(0);\n    wave_sizze_34039 = LOCKSTEP_WIDTH;\n    block_id_34038 = get_tblock_id(0);\n    global_tid_34036 = block_id_34038 * tblock_sizze_34040 + local_tid_34037;\n    phys_tid_33200 = sext_i32_i64(global_tid_34036);\n    global_tid_34041 = sext_i32_i64(block_id_34038) * segmap_tblock_sizze_33196 + sext_i32_i64(local_tid_34037);\n    slice_34042 = ni_30475;\n    gtid_33199 = global_tid_34041;\n    remnant_34043 = global_tid_34041 - gtid_33199;\n    if (slt64(gtid_33199, ni_30475)) {\n        int64_t eta_p_33201;\n        bool cond_33203;\n        bool cond_t_res_33204;\n        bool x_33205;\n        int32_t lifted_lambda_res_33206;\n        \n        eta_p_33201 = ((__global int64_t *) mem_param_33840)[gtid_33199];\n        cond_33203 = sle64(lower_bound_31864, eta_p_33201);\n        cond_t_res_33204 = slt64(eta_p_33201, min_res_31866);\n        x_33205 = cond_33203 && cond_t_res_33204;\n        if (x_33205) {\n            int64_t tmp_33207;\n            bool x_33208;\n            bool y_33209;\n            bool bounds_check_33210;\n            bool index_certs_33211;\n            int32_t tmp_33212;\n            \n            tmp_33207 = sub64(eta_p_33201, lower_bound_31864);\n            x_33208 = sle64((int64_t) 0, tmp_33207);\n            y_33209 = slt64(tmp_33207, j_m_i_31867);\n            bounds_check_33210 = x_33208 && y_33209;\n            if (!bounds_check_33210) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 5) == -1) {\n                        global_failure_args[0] = (int64_t) tmp_33207;\n                        global_failure_args[1] = (int64_t) j_m_i_31867;\n                        ;\n                    }\n                    return;\n                }\n            }\n            tmp_33212 = ((__global int32_t *) ys_mem_33834)[eta_p_33201];\n            lifted_lambda_res_33206 = tmp_33212;\n        } els",
                                    "e {\n            int32_t eta_p_33202 = ((__global int32_t *) mem_param_33843)[gtid_33199];\n            \n            lifted_lambda_res_33206 = eta_p_33202;\n        }\n        ((__global int32_t *) mem_33848)[gtid_33199] = lifted_lambda_res_33206;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_33196\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_longzisegmap_32948_dim1, 1, 1)\nvoid gather_payloads_longzisegmap_32948(__global int *global_failure, int64_t niz2084U_29191, int64_t incr_29193, __global unsigned char *is_mem_33832, __global unsigned char *mem_33836)\n{\n    #define segmap_tblock_sizze_32944 (gather_payloads_longzisegmap_32948zisegmap_tblock_sizze_32944)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34022;\n    int32_t tblock_sizze_34025;\n    int32_t wave_sizze_34024;\n    int32_t block_id_34023;\n    int32_t global_tid_34021;\n    int64_t phys_tid_32948;\n    int64_t global_tid_34026;\n    int64_t slice_34027;\n    int64_t gtid_32947;\n    int64_t remnant_34028;\n    \n    local_tid_34022 = get_local_id(0);\n    tblock_sizze_34025 = get_local_size(0);\n    wave_sizze_34024 = LOCKSTEP_WIDTH;\n    block_id_34023 = get_tblock_id(0);\n    global_tid_34021 = block_id_34023 * tblock_sizze_34025 + local_tid_34022;\n    phys_tid_32948 = sext_i32_i64(global_tid_34021);\n    global_tid_34026 = sext_i32_i64(block_id_34023) * segmap_tblock_sizze_32944 + sext_i32_i64(local_tid_34022);\n    slice_34027 = niz2084U_29191;\n    gtid_32947 = global_tid_34026;\n    remnant_34028 = global_tid_34026 - gtid_32947;\n    if (slt64(gtid_32947, niz2084U_29191)) {\n        int64_t eta_p_32949;\n        int64_t lifted_lambda_res_32950;\n        \n        eta_p_32949 = ((__global int64_t *) is_mem_33832)[gtid_32947];\n        lifted_lambda_res_32950 = sub64(eta_p_32949, incr_29193);\n        ((__global int64_t *) mem_33836)[gtid_32947] = lifted_lambda_res_32950;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_32944\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_longziseg", "map_32976_dim1, 1, 1)\nvoid gather_payloads_longzisegmap_32976(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t niz2084U_29191, int64_t lower_bound_31864, int64_t min_res_31866, int64_t j_m_i_31867, __global unsigned char *ys_mem_33833, __global unsigned char *mem_param_33841, __global unsigned char *mem_param_33844, __global unsigned char *mem_33849)\n{\n    #define segmap_tblock_sizze_32972 (gather_payloads_longzisegmap_32976zisegmap_tblock_sizze_32972)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34057;\n    int32_t tblock_sizze_34060;\n    int32_t wave_sizze_34059;\n    int32_t block_id_34058;\n    int32_t global_tid_34056;\n    int64_t phys_tid_32976;\n    int64_t global_tid_34061;\n    int64_t slice_34062;\n    int64_t gtid_32975;\n    int64_t remnant_34063;\n    \n    local_tid_34057 = get_local_id(0);\n    tblock_sizze_34060 = get_local_size(0);\n    wave_sizze_34059 = LOCKSTEP_WIDTH;\n    block_id_34058 = get_tblock_id(0);\n    global_tid_34056 = block_id_34058 * tblock_sizze_34060 + local_tid_34057;\n    phys_tid_32976 = sext_i32_i64(global_tid_34056);\n    global_tid_34061 = sext_i32_i64(block_id_34058) * segmap_tblock_sizze_32972 + sext_i32_i64(local_tid_34057);\n    slice_34062 = niz2084U_29191;\n    gtid_32975 = global_tid_34061;\n    remnant_34063 = global_tid_34061 - gtid_32975;\n    if (slt64(gtid_32975, niz2084U_29191)) {\n        int64_t eta_p_32977;\n        bool cond_32979;\n        bool cond_t_res_32980;\n        bool x_32981;\n        int64_t lifted_lambda_res_32982;\n        \n        eta_p_32977 = ((__global int64_t *) mem_param_33841)[gtid_32975];\n        cond_32979 = sle64(lower_bound_31864, eta_p_32977);\n        cond_t_res_32980 = slt64(eta_p_32977, min_res_31866);\n        x_32981 = cond_32979 && cond_t_res_32980;\n        if (x_32981) {\n            int64_t tmp_32983;\n            bool x_32984;\n            bool y_32985;\n            bool bounds_check_32986;\n            bool index_certs_32987", ";\n            int64_t tmp_32988;\n            \n            tmp_32983 = sub64(eta_p_32977, lower_bound_31864);\n            x_32984 = sle64((int64_t) 0, tmp_32983);\n            y_32985 = slt64(tmp_32983, j_m_i_31867);\n            bounds_check_32986 = x_32984 && y_32985;\n            if (!bounds_check_32986) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 6) == -1) {\n                        global_failure_args[0] = (int64_t) tmp_32983;\n                        global_failure_args[1] = (int64_t) j_m_i_31867;\n                        ;\n                    }\n                    return;\n                }\n            }\n            tmp_32988 = ((__global int64_t *) ys_mem_33833)[eta_p_32977];\n            lifted_lambda_res_32982 = tmp_32988;\n        } else {\n            int64_t eta_p_32978 = ((__global int64_t *) mem_param_33844)[gtid_32975];\n            \n            lifted_lambda_res_32982 = eta_p_32978;\n        }\n        ((__global int64_t *) mem_33849)[gtid_32975] = lifted_lambda_res_32982;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_32972\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_long_GFURzisegmap_33228_dim1, 1, 1)\nvoid gather_payloads_long_GFURzisegmap_33228(__global int *global_failure, int64_t ni_30776, int64_t incr_30778, __global unsigned char *is_mem_33833, __global unsigned char *mem_33837)\n{\n    #define segmap_tblock_sizze_33224 (gather_payloads_long_GFURzisegmap_33228zisegmap_tblock_sizze_33224)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34022;\n    int32_t tblock_sizze_34025;\n    int32_t wave_sizze_34024;\n    int32_t block_id_34023;\n    int32_t global_tid_34021;\n    int64_t phys_tid_33228;\n    int64_t global_tid_34026;\n    int64_t slice_34027;\n    int64_t gtid_33227;\n    int64_t remnant_34028;\n    \n    local_tid_34022 = get_local_id(0);\n    tblock_sizze_34025 = get_local_size(0);\n    wave_sizze_34024 = LOCKSTEP_WIDTH;\n    block_id_34023 = get_tblock_id(0);\n    global_tid_34021 =",
                                    " block_id_34023 * tblock_sizze_34025 + local_tid_34022;\n    phys_tid_33228 = sext_i32_i64(global_tid_34021);\n    global_tid_34026 = sext_i32_i64(block_id_34023) * segmap_tblock_sizze_33224 + sext_i32_i64(local_tid_34022);\n    slice_34027 = ni_30776;\n    gtid_33227 = global_tid_34026;\n    remnant_34028 = global_tid_34026 - gtid_33227;\n    if (slt64(gtid_33227, ni_30776)) {\n        int64_t eta_p_33229;\n        int64_t lifted_lambda_res_33230;\n        \n        eta_p_33229 = ((__global int64_t *) is_mem_33833)[gtid_33227];\n        lifted_lambda_res_33230 = sub64(eta_p_33229, incr_30778);\n        ((__global int64_t *) mem_33837)[gtid_33227] = lifted_lambda_res_33230;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_33224\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_long_GFURzisegmap_33256_dim1, 1, 1)\nvoid gather_payloads_long_GFURzisegmap_33256(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t ni_30776, int64_t lower_bound_31864, int64_t min_res_31866, int64_t j_m_i_31867, __global unsigned char *ys_mem_33834, __global unsigned char *mem_param_33840, __global unsigned char *mem_param_33843, __global unsigned char *mem_33848)\n{\n    #define segmap_tblock_sizze_33252 (gather_payloads_long_GFURzisegmap_33256zisegmap_tblock_sizze_33252)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34037;\n    int32_t tblock_sizze_34040;\n    int32_t wave_sizze_34039;\n    int32_t block_id_34038;\n    int32_t global_tid_34036;\n    int64_t phys_tid_33256;\n    int64_t global_tid_34041;\n    int64_t slice_34042;\n    int64_t gtid_33255;\n    int64_t remnant_34043;\n    \n    local_tid_34037 = get_local_id(0);\n    tblock_sizze_34040 = get_local_size(0);\n    wave_sizze_34039 = LOCKSTEP_WIDTH;\n    block_id_34038 = get_tblock_id(0);\n    global_tid_34036 = block_id_34038 * tblock_sizze_34040 + local_tid_34037;\n    phys_tid_33256 = sext_i32_i64(global_tid_34036);\n    global_tid_34041 = sext_i32_i64(block_id_34038) * segma", "p_tblock_sizze_33252 + sext_i32_i64(local_tid_34037);\n    slice_34042 = ni_30776;\n    gtid_33255 = global_tid_34041;\n    remnant_34043 = global_tid_34041 - gtid_33255;\n    if (slt64(gtid_33255, ni_30776)) {\n        int64_t eta_p_33257;\n        bool cond_33259;\n        bool cond_t_res_33260;\n        bool x_33261;\n        int64_t lifted_lambda_res_33262;\n        \n        eta_p_33257 = ((__global int64_t *) mem_param_33840)[gtid_33255];\n        cond_33259 = sle64(lower_bound_31864, eta_p_33257);\n        cond_t_res_33260 = slt64(eta_p_33257, min_res_31866);\n        x_33261 = cond_33259 && cond_t_res_33260;\n        if (x_33261) {\n            int64_t tmp_33263;\n            bool x_33264;\n            bool y_33265;\n            bool bounds_check_33266;\n            bool index_certs_33267;\n            int64_t tmp_33268;\n            \n            tmp_33263 = sub64(eta_p_33257, lower_bound_31864);\n            x_33264 = sle64((int64_t) 0, tmp_33263);\n            y_33265 = slt64(tmp_33263, j_m_i_31867);\n            bounds_check_33266 = x_33264 && y_33265;\n            if (!bounds_check_33266) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 7) == -1) {\n                        global_failure_args[0] = (int64_t) tmp_33263;\n                        global_failure_args[1] = (int64_t) j_m_i_31867;\n                        ;\n                    }\n                    return;\n                }\n            }\n            tmp_33268 = ((__global int64_t *) ys_mem_33834)[eta_p_33257];\n            lifted_lambda_res_33262 = tmp_33268;\n        } else {\n            int64_t eta_p_33258 = ((__global int64_t *) mem_param_33843)[gtid_33255];\n            \n            lifted_lambda_res_33262 = eta_p_33258;\n        }\n        ((__global int64_t *) mem_33848)[gtid_33255] = lifted_lambda_res_33262;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_33252\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_shortzisegmap_32836_dim1, 1, 1)\nvoid gather_payloads_shortzisegmap", "_32836(__global int *global_failure, int64_t niz2084U_28542, int64_t incr_28544, __global unsigned char *is_mem_33832, __global unsigned char *mem_33836)\n{\n    #define segmap_tblock_sizze_32832 (gather_payloads_shortzisegmap_32836zisegmap_tblock_sizze_32832)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34022;\n    int32_t tblock_sizze_34025;\n    int32_t wave_sizze_34024;\n    int32_t block_id_34023;\n    int32_t global_tid_34021;\n    int64_t phys_tid_32836;\n    int64_t global_tid_34026;\n    int64_t slice_34027;\n    int64_t gtid_32835;\n    int64_t remnant_34028;\n    \n    local_tid_34022 = get_local_id(0);\n    tblock_sizze_34025 = get_local_size(0);\n    wave_sizze_34024 = LOCKSTEP_WIDTH;\n    block_id_34023 = get_tblock_id(0);\n    global_tid_34021 = block_id_34023 * tblock_sizze_34025 + local_tid_34022;\n    phys_tid_32836 = sext_i32_i64(global_tid_34021);\n    global_tid_34026 = sext_i32_i64(block_id_34023) * segmap_tblock_sizze_32832 + sext_i32_i64(local_tid_34022);\n    slice_34027 = niz2084U_28542;\n    gtid_32835 = global_tid_34026;\n    remnant_34028 = global_tid_34026 - gtid_32835;\n    if (slt64(gtid_32835, niz2084U_28542)) {\n        int64_t eta_p_32837;\n        int64_t lifted_lambda_res_32838;\n        \n        eta_p_32837 = ((__global int64_t *) is_mem_33832)[gtid_32835];\n        lifted_lambda_res_32838 = sub64(eta_p_32837, incr_28544);\n        ((__global int64_t *) mem_33836)[gtid_32835] = lifted_lambda_res_32838;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_32832\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_shortzisegmap_32864_dim1, 1, 1)\nvoid gather_payloads_shortzisegmap_32864(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t niz2084U_28542, int64_t lower_bound_31864, int64_t min_res_31866, int64_t j_m_i_31867, __global unsigned char *ys_mem_33833, __global unsigned char *mem_param_33841, __global unsigned char *mem_param_33844, __global unsigned char *mem_33849)\n{\n    #d",
                                    "efine segmap_tblock_sizze_32860 (gather_payloads_shortzisegmap_32864zisegmap_tblock_sizze_32860)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34057;\n    int32_t tblock_sizze_34060;\n    int32_t wave_sizze_34059;\n    int32_t block_id_34058;\n    int32_t global_tid_34056;\n    int64_t phys_tid_32864;\n    int64_t global_tid_34061;\n    int64_t slice_34062;\n    int64_t gtid_32863;\n    int64_t remnant_34063;\n    \n    local_tid_34057 = get_local_id(0);\n    tblock_sizze_34060 = get_local_size(0);\n    wave_sizze_34059 = LOCKSTEP_WIDTH;\n    block_id_34058 = get_tblock_id(0);\n    global_tid_34056 = block_id_34058 * tblock_sizze_34060 + local_tid_34057;\n    phys_tid_32864 = sext_i32_i64(global_tid_34056);\n    global_tid_34061 = sext_i32_i64(block_id_34058) * segmap_tblock_sizze_32860 + sext_i32_i64(local_tid_34057);\n    slice_34062 = niz2084U_28542;\n    gtid_32863 = global_tid_34061;\n    remnant_34063 = global_tid_34061 - gtid_32863;\n    if (slt64(gtid_32863, niz2084U_28542)) {\n        int64_t eta_p_32865;\n        bool cond_32867;\n        bool cond_t_res_32868;\n        bool x_32869;\n        int16_t lifted_lambda_res_32870;\n        \n        eta_p_32865 = ((__global int64_t *) mem_param_33841)[gtid_32863];\n        cond_32867 = sle64(lower_bound_31864, eta_p_32865);\n        cond_t_res_32868 = slt64(eta_p_32865, min_res_31866);\n        x_32869 = cond_32867 && cond_t_res_32868;\n        if (x_32869) {\n            int64_t tmp_32871;\n            bool x_32872;\n            bool y_32873;\n            bool bounds_check_32874;\n            bool index_certs_32875;\n            int16_t tmp_32876;\n            \n            tmp_32871 = sub64(eta_p_32865, lower_bound_31864);\n            x_32872 = sle64((int64_t) 0, tmp_32871);\n            y_32873 = slt64(tmp_32871, j_m_i_31867);\n            bounds_check_32874 = x_32872 && y_32873;\n            if (!bounds_check_32874) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 8) == -1) {\n       ", "                 global_failure_args[0] = (int64_t) tmp_32871;\n                        global_failure_args[1] = (int64_t) j_m_i_31867;\n                        ;\n                    }\n                    return;\n                }\n            }\n            tmp_32876 = ((__global int16_t *) ys_mem_33833)[eta_p_32865];\n            lifted_lambda_res_32870 = tmp_32876;\n        } else {\n            int16_t eta_p_32866 = ((__global int16_t *) mem_param_33844)[gtid_32863];\n            \n            lifted_lambda_res_32870 = eta_p_32866;\n        }\n        ((__global int16_t *) mem_33849)[gtid_32863] = lifted_lambda_res_32870;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_32860\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_short_GFURzisegmap_33116_dim1, 1, 1)\nvoid gather_payloads_short_GFURzisegmap_33116(__global int *global_failure, int64_t ni_30174, int64_t incr_30176, __global unsigned char *is_mem_33833, __global unsigned char *mem_33837)\n{\n    #define segmap_tblock_sizze_33112 (gather_payloads_short_GFURzisegmap_33116zisegmap_tblock_sizze_33112)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34022;\n    int32_t tblock_sizze_34025;\n    int32_t wave_sizze_34024;\n    int32_t block_id_34023;\n    int32_t global_tid_34021;\n    int64_t phys_tid_33116;\n    int64_t global_tid_34026;\n    int64_t slice_34027;\n    int64_t gtid_33115;\n    int64_t remnant_34028;\n    \n    local_tid_34022 = get_local_id(0);\n    tblock_sizze_34025 = get_local_size(0);\n    wave_sizze_34024 = LOCKSTEP_WIDTH;\n    block_id_34023 = get_tblock_id(0);\n    global_tid_34021 = block_id_34023 * tblock_sizze_34025 + local_tid_34022;\n    phys_tid_33116 = sext_i32_i64(global_tid_34021);\n    global_tid_34026 = sext_i32_i64(block_id_34023) * segmap_tblock_sizze_33112 + sext_i32_i64(local_tid_34022);\n    slice_34027 = ni_30174;\n    gtid_33115 = global_tid_34026;\n    remnant_34028 = global_tid_34026 - gtid_33115;\n    if (slt64(gtid_33115, ni_30174)) {\n        int64_t eta_p_33117;\n       ", " int64_t lifted_lambda_res_33118;\n        \n        eta_p_33117 = ((__global int64_t *) is_mem_33833)[gtid_33115];\n        lifted_lambda_res_33118 = sub64(eta_p_33117, incr_30176);\n        ((__global int64_t *) mem_33837)[gtid_33115] = lifted_lambda_res_33118;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_33112\n}\nFUTHARK_KERNEL_SIZED(gather_payloads_short_GFURzisegmap_33144_dim1, 1, 1)\nvoid gather_payloads_short_GFURzisegmap_33144(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t ni_30174, int64_t lower_bound_31864, int64_t min_res_31866, int64_t j_m_i_31867, __global unsigned char *ys_mem_33834, __global unsigned char *mem_param_33840, __global unsigned char *mem_param_33843, __global unsigned char *mem_33848)\n{\n    #define segmap_tblock_sizze_33140 (gather_payloads_short_GFURzisegmap_33144zisegmap_tblock_sizze_33140)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34037;\n    int32_t tblock_sizze_34040;\n    int32_t wave_sizze_34039;\n    int32_t block_id_34038;\n    int32_t global_tid_34036;\n    int64_t phys_tid_33144;\n    int64_t global_tid_34041;\n    int64_t slice_34042;\n    int64_t gtid_33143;\n    int64_t remnant_34043;\n    \n    local_tid_34037 = get_local_id(0);\n    tblock_sizze_34040 = get_local_size(0);\n    wave_sizze_34039 = LOCKSTEP_WIDTH;\n    block_id_34038 = get_tblock_id(0);\n    global_tid_34036 = block_id_34038 * tblock_sizze_34040 + local_tid_34037;\n    phys_tid_33144 = sext_i32_i64(global_tid_34036);\n    global_tid_34041 = sext_i32_i64(block_id_34038) * segmap_tblock_sizze_33140 + sext_i32_i64(local_tid_34037);\n    slice_34042 = ni_30174;\n    gtid_33143 = global_tid_34041;\n    remnant_34043 = global_tid_34041 - gtid_33143;\n    if (slt64(gtid_33143, ni_30174)) {\n        int64_t eta_p_33145;\n        bool cond_33147;\n        bool cond_t_res_33148;\n        bool x_33149;\n        int16_t lifted_lambda_res_33150;\n        \n        eta_p_33145 = ((__global int64_t *) ",
                                    "mem_param_33840)[gtid_33143];\n        cond_33147 = sle64(lower_bound_31864, eta_p_33145);\n        cond_t_res_33148 = slt64(eta_p_33145, min_res_31866);\n        x_33149 = cond_33147 && cond_t_res_33148;\n        if (x_33149) {\n            int64_t tmp_33151;\n            bool x_33152;\n            bool y_33153;\n            bool bounds_check_33154;\n            bool index_certs_33155;\n            int16_t tmp_33156;\n            \n            tmp_33151 = sub64(eta_p_33145, lower_bound_31864);\n            x_33152 = sle64((int64_t) 0, tmp_33151);\n            y_33153 = slt64(tmp_33151, j_m_i_31867);\n            bounds_check_33154 = x_33152 && y_33153;\n            if (!bounds_check_33154) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 9) == -1) {\n                        global_failure_args[0] = (int64_t) tmp_33151;\n                        global_failure_args[1] = (int64_t) j_m_i_31867;\n                        ;\n                    }\n                    return;\n                }\n            }\n            tmp_33156 = ((__global int16_t *) ys_mem_33834)[eta_p_33145];\n            lifted_lambda_res_33150 = tmp_33156;\n        } else {\n            int16_t eta_p_33146 = ((__global int16_t *) mem_param_33843)[gtid_33143];\n            \n            lifted_lambda_res_33150 = eta_p_33146;\n        }\n        ((__global int16_t *) mem_33848)[gtid_33143] = lifted_lambda_res_33150;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_33140\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_doublezigpuseq_34379_dim1, 1, 1)\nvoid inner_SMJ_doublezigpuseq_34379(__global int *global_failure, int64_t m_32502, __global unsigned char *mem_33855, __global unsigned char *mem_33857)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34381;\n    int32_t tblock_sizze_34384;\n    int32_t wave_sizze_34383;\n    int32_t block_id_34382;\n    int32_t global_tid_34380;\n    int64_t tid_34379;\n    int64_t x_33807;\n    \n    local_tid_34381 = get_local_id(0);\n    ", "tblock_sizze_34384 = get_local_size(0);\n    wave_sizze_34383 = LOCKSTEP_WIDTH;\n    block_id_34382 = get_tblock_id(0);\n    global_tid_34380 = block_id_34382 * tblock_sizze_34384 + local_tid_34381;\n    tid_34379 = sext_i32_i64(global_tid_34380);\n    x_33807 = ((__global int64_t *) mem_33855)[m_32502];\n    ((__global int64_t *) mem_33857)[(int64_t) 0] = x_33807;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_doublezigpuseq_34385_dim1, 1, 1)\nvoid inner_SMJ_doublezigpuseq_34385(__global int *global_failure, int64_t m_32502, __global unsigned char *mem_33844, __global unsigned char *mem_33860)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34387;\n    int32_t tblock_sizze_34390;\n    int32_t wave_sizze_34389;\n    int32_t block_id_34388;\n    int32_t global_tid_34386;\n    int64_t tid_34385;\n    int64_t x_33811;\n    \n    local_tid_34387 = get_local_id(0);\n    tblock_sizze_34390 = get_local_size(0);\n    wave_sizze_34389 = LOCKSTEP_WIDTH;\n    block_id_34388 = get_tblock_id(0);\n    global_tid_34386 = block_id_34388 * tblock_sizze_34390 + local_tid_34387;\n    tid_34385 = sext_i32_i64(global_tid_34386);\n    x_33811 = ((__global int64_t *) mem_33844)[m_32502];\n    ((__global int64_t *) mem_33860)[(int64_t) 0] = x_33811;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_doublezigpuseq_34391_dim1, 1, 1)\nvoid inner_SMJ_doublezigpuseq_34391(__global int *global_failure, __global unsigned char *ext_mem_33858, __global unsigned char *ext_mem_33861, __global unsigned char *mem_33867)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34393;\n    int32_t tblock_sizze_34396;\n    int32_t wave_sizze_34395;\n    int32_t block_id_34394;\n    int32_t global_tid_34392;\n    int64_t tid_34391;\n    int64_t zp_lhs_33815;\n    int64_t n_pairs_t_res_33816;\n    int64_t n_pairs_t_res_33817;\n    \n    local_tid_34393 = get_local_id(0);\n    tblock_sizze_34396 = get_local_size(0);\n    wave_sizze_34395 = LOCKSTEP_WIDTH;\n    block_id_34394", " = get_tblock_id(0);\n    global_tid_34392 = block_id_34394 * tblock_sizze_34396 + local_tid_34393;\n    tid_34391 = sext_i32_i64(global_tid_34392);\n    zp_lhs_33815 = ((__global int64_t *) ext_mem_33858)[(int64_t) 0];\n    n_pairs_t_res_33816 = ((__global int64_t *) ext_mem_33861)[(int64_t) 0];\n    n_pairs_t_res_33817 = add64(zp_lhs_33815, n_pairs_t_res_33816);\n    ((__global int64_t *) mem_33867)[(int64_t) 0] = n_pairs_t_res_33817;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_doublezigpuseq_34458_dim1, 1, 1)\nvoid inner_SMJ_doublezigpuseq_34458(__global int *global_failure, int64_t loopres_32670, __global unsigned char *mem_param_33901, __global unsigned char *mem_param_33904, __global unsigned char *mem_param_33907, __global unsigned char *mem_33914, __global unsigned char *mem_33915, __global unsigned char *mem_33916)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34460;\n    int32_t tblock_sizze_34463;\n    int32_t wave_sizze_34462;\n    int32_t block_id_34461;\n    int32_t global_tid_34459;\n    int64_t tid_34458;\n    double loopres_33819;\n    int64_t loopres_33821;\n    int64_t loopres_33823;\n    \n    local_tid_34460 = get_local_id(0);\n    tblock_sizze_34463 = get_local_size(0);\n    wave_sizze_34462 = LOCKSTEP_WIDTH;\n    block_id_34461 = get_tblock_id(0);\n    global_tid_34459 = block_id_34461 * tblock_sizze_34463 + local_tid_34460;\n    tid_34458 = sext_i32_i64(global_tid_34459);\n    loopres_33819 = ((__global double *) mem_param_33901)[loopres_32670];\n    loopres_33821 = ((__global int64_t *) mem_param_33904)[loopres_32670];\n    loopres_33823 = ((__global int64_t *) mem_param_33907)[loopres_32670];\n    ((__global double *) mem_33914)[(int64_t) 0] = loopres_33819;\n    ((__global int64_t *) mem_33915)[(int64_t) 0] = loopres_33821;\n    ((__global int64_t *) mem_33916)[(int64_t) 0] = loopres_33823;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL\nvoid inner_SMJ_doublezireplicate_34465(int64_t loopres_32671, int64_t replicate_n_34464,",
                                    " int64_t virt_num_tblocks_34470, int64_t num_tblocks_34471, __global unsigned char *mem_33914, __global unsigned char *mem_33918)\n{\n    int32_t replicate_ltid_34466;\n    int32_t tblock_sizze_34468;\n    int32_t replicate_gid_34467;\n    int32_t replicate_gtid_34465;\n    int32_t phys_tblock_id_34472;\n    int32_t iterations_34473;\n    \n    replicate_ltid_34466 = get_local_id(0);\n    tblock_sizze_34468 = get_local_size(0);\n    replicate_gid_34467 = get_tblock_id(0);\n    replicate_gtid_34465 = replicate_gid_34467 * tblock_sizze_34468 + replicate_ltid_34466;\n    phys_tblock_id_34472 = get_tblock_id(0);\n    iterations_34473 = sdiv_up32(sext_i64_i32(virt_num_tblocks_34470) - phys_tblock_id_34472, sext_i64_i32(num_tblocks_34471));\n    for (int32_t i_34474 = 0; i_34474 < iterations_34473; i_34474++) {\n        int32_t virt_tblock_id_34475;\n        int64_t global_tid_34476;\n        int64_t slice_34479;\n        int64_t slice_34480;\n        int64_t rep_i_34477;\n        int64_t remnant_34481;\n        int64_t rep_i_34478;\n        int64_t remnant_34482;\n        \n        virt_tblock_id_34475 = phys_tblock_id_34472 + i_34474 * sext_i64_i32(num_tblocks_34471);\n        global_tid_34476 = sext_i32_i64(virt_tblock_id_34475) * sext_i32_i64(tblock_sizze_34468) + sext_i32_i64(replicate_ltid_34466);\n        slice_34479 = (int64_t) 1;\n        slice_34480 = loopres_32671 * slice_34479;\n        rep_i_34477 = squot64(global_tid_34476, slice_34479);\n        remnant_34481 = global_tid_34476 - rep_i_34477 * slice_34479;\n        rep_i_34478 = remnant_34481;\n        remnant_34482 = remnant_34481 - rep_i_34478;\n        if (slt64(global_tid_34476, replicate_n_34464)) {\n            double tmp_34483 = ((__global double *) mem_33914)[rep_i_34478];\n            \n            ((__global double *) mem_33918)[rep_i_34477 + rep_i_34478] = tmp_34483;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid inner_SMJ_doublezireplicate_34485(int64_", "t loopres_32671, int64_t replicate_n_34484, int64_t virt_num_tblocks_34490, int64_t num_tblocks_34491, __global unsigned char *mem_33915, __global unsigned char *mem_33920)\n{\n    int32_t replicate_ltid_34486;\n    int32_t tblock_sizze_34488;\n    int32_t replicate_gid_34487;\n    int32_t replicate_gtid_34485;\n    int32_t phys_tblock_id_34492;\n    int32_t iterations_34493;\n    \n    replicate_ltid_34486 = get_local_id(0);\n    tblock_sizze_34488 = get_local_size(0);\n    replicate_gid_34487 = get_tblock_id(0);\n    replicate_gtid_34485 = replicate_gid_34487 * tblock_sizze_34488 + replicate_ltid_34486;\n    phys_tblock_id_34492 = get_tblock_id(0);\n    iterations_34493 = sdiv_up32(sext_i64_i32(virt_num_tblocks_34490) - phys_tblock_id_34492, sext_i64_i32(num_tblocks_34491));\n    for (int32_t i_34494 = 0; i_34494 < iterations_34493; i_34494++) {\n        int32_t virt_tblock_id_34495;\n        int64_t global_tid_34496;\n        int64_t slice_34499;\n        int64_t slice_34500;\n        int64_t rep_i_34497;\n        int64_t remnant_34501;\n        int64_t rep_i_34498;\n        int64_t remnant_34502;\n        \n        virt_tblock_id_34495 = phys_tblock_id_34492 + i_34494 * sext_i64_i32(num_tblocks_34491);\n        global_tid_34496 = sext_i32_i64(virt_tblock_id_34495) * sext_i32_i64(tblock_sizze_34488) + sext_i32_i64(replicate_ltid_34486);\n        slice_34499 = (int64_t) 1;\n        slice_34500 = loopres_32671 * slice_34499;\n        rep_i_34497 = squot64(global_tid_34496, slice_34499);\n        remnant_34501 = global_tid_34496 - rep_i_34497 * slice_34499;\n        rep_i_34498 = remnant_34501;\n        remnant_34502 = remnant_34501 - rep_i_34498;\n        if (slt64(global_tid_34496, replicate_n_34484)) {\n            int64_t tmp_34503 = ((__global int64_t *) mem_33915)[rep_i_34498];\n            \n            ((__global int64_t *) mem_33920)[rep_i_34497 + rep_i_34498] = tmp_34503;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL", "_SIZED(inner_SMJ_doublezisegmap_33726_dim1, 1, 1)\nvoid inner_SMJ_doublezisegmap_33726(__global int *global_failure, int64_t nR_28192, int64_t offset_R_28196, int64_t m_32498, int64_t num_tblocks_33731, int32_t virt_num_tblocks_34204, __global unsigned char *tR_mem_33832, __global unsigned char *mem_33838, __global unsigned char *mem_33840, __global unsigned char *mem_33842, __global unsigned char *mem_33844)\n{\n    #define segmap_tblock_sizze_33729 (inner_SMJ_doublezisegmap_33726zisegmap_tblock_sizze_33729)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34206;\n    int32_t tblock_sizze_34209;\n    int32_t wave_sizze_34208;\n    int32_t block_id_34207;\n    int32_t global_tid_34205;\n    int64_t phys_tid_33726;\n    int32_t phys_tblock_id_34210;\n    int32_t iterations_34211;\n    \n    local_tid_34206 = get_local_id(0);\n    tblock_sizze_34209 = get_local_size(0);\n    wave_sizze_34208 = LOCKSTEP_WIDTH;\n    block_id_34207 = get_tblock_id(0);\n    global_tid_34205 = block_id_34207 * tblock_sizze_34209 + local_tid_34206;\n    phys_tid_33726 = sext_i32_i64(global_tid_34205);\n    phys_tblock_id_34210 = get_tblock_id(0);\n    iterations_34211 = sdiv_up32(virt_num_tblocks_34204 - phys_tblock_id_34210, sext_i64_i32(num_tblocks_33731));\n    for (int32_t i_34212 = 0; i_34212 < iterations_34211; i_34212++) {\n        int32_t virt_tblock_id_34213;\n        int64_t global_tid_34214;\n        int64_t slice_34215;\n        int64_t write_i_33725;\n        int64_t remnant_34216;\n        \n        virt_tblock_id_34213 = phys_tblock_id_34210 + i_34212 * sext_i64_i32(num_tblocks_33731);\n        global_tid_34214 = sext_i32_i64(virt_tblock_id_34213) * segmap_tblock_sizze_33729 + sext_i32_i64(local_tid_34206);\n        slice_34215 = nR_28192;\n        write_i_33725 = global_tid_34214;\n        remnant_34216 = global_tid_34214 - write_i_33725;\n        if (slt64(write_i_33725, nR_28192)) {\n            double write_value_32519;\n            int64_t index_primexp_33806;\n            \n       ",
                                    "     write_value_32519 = ((__global double *) tR_mem_33832)[write_i_33725];\n            index_primexp_33806 = add64(offset_R_28196, write_i_33725);\n            if (sle64((int64_t) 0, (int64_t) -1) && slt64((int64_t) -1, m_32498)) {\n                ((__global double *) mem_33838)[(int64_t) -1] = write_value_32519;\n            }\n            if (sle64((int64_t) 0, (int64_t) -1) && slt64((int64_t) -1, m_32498)) {\n                ((__global int64_t *) mem_33840)[(int64_t) -1] = index_primexp_33806;\n            }\n            if (sle64((int64_t) 0, (int64_t) -1) && slt64((int64_t) -1, m_32498)) {\n                ((__global int64_t *) mem_33842)[(int64_t) -1] = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, (int64_t) -1) && slt64((int64_t) -1, m_32498)) {\n                ((__global int64_t *) mem_33844)[(int64_t) -1] = (int64_t) 0;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_33729\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_doublezisegmap_33760_dim1, 1, 1)\nvoid inner_SMJ_doublezisegmap_33760(__global int *global_failure, int64_t m_32498, __global unsigned char *mem_33848, __global unsigned char *mem_33855)\n{\n    #define segmap_tblock_sizze_33756 (inner_SMJ_doublezisegmap_33760zisegmap_tblock_sizze_33756)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34372;\n    int32_t tblock_sizze_34375;\n    int32_t wave_sizze_34374;\n    int32_t block_id_34373;\n    int32_t global_tid_34371;\n    int64_t phys_tid_33760;\n    int64_t global_tid_34376;\n    int64_t slice_34377;\n    int64_t gtid_33759;\n    int64_t remnant_34378;\n    \n    local_tid_34372 = get_local_id(0);\n    tblock_sizze_34375 = get_local_size(0);\n    wave_sizze_34374 = LOCKSTEP_WIDTH;\n    block_id_34373 = get_tblock_id(0);\n    global_tid_34371 = block_id_34373 * tblock_sizze_34375 + local_tid_34372;\n    phys_tid_33760 = sext_i32_i64(global_tid_34371);\n    global_tid_34376 = sext_i32_i64(block_", "id_34373) * segmap_tblock_sizze_33756 + sext_i32_i64(local_tid_34372);\n    slice_34377 = m_32498;\n    gtid_33759 = global_tid_34376;\n    remnant_34378 = global_tid_34376 - gtid_33759;\n    if (slt64(gtid_33759, m_32498)) {\n        int64_t zv_lhs_33762;\n        int64_t tmp_33763;\n        bool cond_33765;\n        int64_t lifted_lambda_res_33766;\n        \n        zv_lhs_33762 = add64((int64_t) -1, gtid_33759);\n        tmp_33763 = smod64(zv_lhs_33762, m_32498);\n        cond_33765 = gtid_33759 == (int64_t) 0;\n        if (cond_33765) {\n            lifted_lambda_res_33766 = (int64_t) 0;\n        } else {\n            int64_t lifted_lambda_res_33764 = ((__global int64_t *) mem_33848)[tmp_33763];\n            \n            lifted_lambda_res_33766 = lifted_lambda_res_33764;\n        }\n        ((__global int64_t *) mem_33855)[gtid_33759] = lifted_lambda_res_33766;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_33756\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_doublezisegmap_33768_dim1, 1, 1)\nvoid inner_SMJ_doublezisegmap_33768(__global int *global_failure, int64_t m_32498, int64_t lower_bound_32569, int64_t min_res_32571, int64_t j_m_i_32572, int64_t num_tblocks_33773, int32_t virt_num_tblocks_34437, __global unsigned char *mem_33838, __global unsigned char *mem_33840, __global unsigned char *mem_33842, __global unsigned char *mem_33855, __global unsigned char *mem_33884, __global unsigned char *mem_33886, __global unsigned char *mem_33888)\n{\n    #define segmap_tblock_sizze_33771 (inner_SMJ_doublezisegmap_33768zisegmap_tblock_sizze_33771)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34439;\n    int32_t tblock_sizze_34442;\n    int32_t wave_sizze_34441;\n    int32_t block_id_34440;\n    int32_t global_tid_34438;\n    int64_t phys_tid_33768;\n    int32_t phys_tblock_id_34443;\n    int32_t iterations_34444;\n    \n    local_tid_34439 = get_local_id(0);\n    tblock_sizze_34442 = get_local_size(0);\n    wave_sizze_34441 = LOCKSTEP_WIDTH;\n    block_id_34440 = get_t", "block_id(0);\n    global_tid_34438 = block_id_34440 * tblock_sizze_34442 + local_tid_34439;\n    phys_tid_33768 = sext_i32_i64(global_tid_34438);\n    phys_tblock_id_34443 = get_tblock_id(0);\n    iterations_34444 = sdiv_up32(virt_num_tblocks_34437 - phys_tblock_id_34443, sext_i64_i32(num_tblocks_33773));\n    for (int32_t i_34445 = 0; i_34445 < iterations_34444; i_34445++) {\n        int32_t virt_tblock_id_34446;\n        int64_t global_tid_34447;\n        int64_t slice_34448;\n        int64_t write_i_33767;\n        int64_t remnant_34449;\n        \n        virt_tblock_id_34446 = phys_tblock_id_34443 + i_34445 * sext_i64_i32(num_tblocks_33773);\n        global_tid_34447 = sext_i32_i64(virt_tblock_id_34446) * segmap_tblock_sizze_33771 + sext_i32_i64(local_tid_34439);\n        slice_34448 = m_32498;\n        write_i_33767 = global_tid_34447;\n        remnant_34449 = global_tid_34447 - write_i_33767;\n        if (slt64(write_i_33767, m_32498)) {\n            int64_t eta_p_32753;\n            double write_value_32754;\n            int64_t write_value_32755;\n            int64_t write_value_32756;\n            bool cond_32757;\n            bool cond_t_res_32758;\n            bool x_32759;\n            int64_t lifted_lambda_res_32760;\n            \n            eta_p_32753 = ((__global int64_t *) mem_33855)[write_i_33767];\n            write_value_32754 = ((__global double *) mem_33838)[write_i_33767];\n            write_value_32755 = ((__global int64_t *) mem_33840)[write_i_33767];\n            write_value_32756 = ((__global int64_t *) mem_33842)[write_i_33767];\n            cond_32757 = sle64(lower_bound_32569, eta_p_32753);\n            cond_t_res_32758 = slt64(eta_p_32753, min_res_32571);\n            x_32759 = cond_32757 && cond_t_res_32758;\n            if (x_32759) {\n                int64_t lifted_lambda_res_t_res_32784 = sub64(eta_p_32753, lower_bound_32569);\n                \n                lifted_lambda_res_32760 = lifted_lambda_res_t_res_32784;\n            } else {\n                lifted_lamb",
                                    "da_res_32760 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_32760) && slt64(lifted_lambda_res_32760, j_m_i_32572)) {\n                ((__global double *) mem_33884)[lifted_lambda_res_32760] = write_value_32754;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_32760) && slt64(lifted_lambda_res_32760, j_m_i_32572)) {\n                ((__global int64_t *) mem_33886)[lifted_lambda_res_32760] = write_value_32755;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_32760) && slt64(lifted_lambda_res_32760, j_m_i_32572)) {\n                ((__global int64_t *) mem_33888)[lifted_lambda_res_32760] = write_value_32756;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_33771\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_doublezisegmap_33776_dim1, 1, 1)\nvoid inner_SMJ_doublezisegmap_33776(__global int *global_failure, int64_t m_32498, int64_t m_32626, int64_t num_tblocks_33781, int32_t virt_num_tblocks_34399, __global unsigned char *mem_33844, __global unsigned char *mem_33850, __global unsigned char *mem_33852, __global unsigned char *mem_33855, __global unsigned char *mem_33863, __global unsigned char *mem_33865)\n{\n    #define segmap_tblock_sizze_33779 (inner_SMJ_doublezisegmap_33776zisegmap_tblock_sizze_33779)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34401;\n    int32_t tblock_sizze_34404;\n    int32_t wave_sizze_34403;\n    int32_t block_id_34402;\n    int32_t global_tid_34400;\n    int64_t phys_tid_33776;\n    int32_t phys_tblock_id_34405;\n    int32_t iterations_34406;\n    \n    local_tid_34401 = get_local_id(0);\n    tblock_sizze_34404 = get_local_size(0);\n    wave_sizze_34403 = LOCKSTEP_WIDTH;\n    block_id_34402 = get_tblock_id(0);\n    global_tid_34400 = block_id_34402 * tblock_sizze_34404 + local_tid_34401;\n    phys_tid_33776 = sext_i32_i64(global_tid_34400);\n    phys_tblock_id_34405 = get_tblo", "ck_id(0);\n    iterations_34406 = sdiv_up32(virt_num_tblocks_34399 - phys_tblock_id_34405, sext_i64_i32(num_tblocks_33781));\n    for (int32_t i_34407 = 0; i_34407 < iterations_34406; i_34407++) {\n        int32_t virt_tblock_id_34408;\n        int64_t global_tid_34409;\n        int64_t slice_34410;\n        int64_t write_i_33775;\n        int64_t remnant_34411;\n        \n        virt_tblock_id_34408 = phys_tblock_id_34405 + i_34407 * sext_i64_i32(num_tblocks_33781);\n        global_tid_34409 = sext_i32_i64(virt_tblock_id_34408) * segmap_tblock_sizze_33779 + sext_i32_i64(local_tid_34401);\n        slice_34410 = m_32498;\n        write_i_33775 = global_tid_34409;\n        remnant_34411 = global_tid_34409 - write_i_33775;\n        if (slt64(write_i_33775, m_32498)) {\n            int64_t eta_p_32710;\n            int64_t write_value_32712;\n            int64_t write_value_32713;\n            bool cond_32714;\n            int64_t lifted_lambda_res_32715;\n            \n            eta_p_32710 = ((__global int64_t *) mem_33852)[write_i_33775];\n            write_value_32712 = ((__global int64_t *) mem_33855)[write_i_33775];\n            write_value_32713 = ((__global int64_t *) mem_33844)[write_i_33775];\n            cond_32714 = eta_p_32710 == (int64_t) 1;\n            if (cond_32714) {\n                int64_t eta_p_32711;\n                int64_t lifted_lambda_res_t_res_32789;\n                \n                eta_p_32711 = ((__global int64_t *) mem_33850)[write_i_33775];\n                lifted_lambda_res_t_res_32789 = sub64(eta_p_32711, (int64_t) 1);\n                lifted_lambda_res_32715 = lifted_lambda_res_t_res_32789;\n            } else {\n                lifted_lambda_res_32715 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_32715) && slt64(lifted_lambda_res_32715, m_32626)) {\n                ((__global int64_t *) mem_33865)[lifted_lambda_res_32715] = write_value_32712;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_32715) && slt64(li", "fted_lambda_res_32715, m_32626)) {\n                ((__global int64_t *) mem_33863)[lifted_lambda_res_32715] = write_value_32713;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_33779\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_doublezisegmap_33798_dim1, 1, 1)\nvoid inner_SMJ_doublezisegmap_33798(__global int *global_failure, int64_t loopres_32670, int64_t loopres_32671, __global unsigned char *mem_33913, __global unsigned char *mem_33916)\n{\n    #define segmap_tblock_sizze_33794 (inner_SMJ_doublezisegmap_33798zisegmap_tblock_sizze_33794)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34506;\n    int32_t tblock_sizze_34509;\n    int32_t wave_sizze_34508;\n    int32_t block_id_34507;\n    int32_t global_tid_34505;\n    int64_t phys_tid_33798;\n    int64_t global_tid_34510;\n    int64_t slice_34511;\n    int64_t gtid_33797;\n    int64_t remnant_34512;\n    \n    local_tid_34506 = get_local_id(0);\n    tblock_sizze_34509 = get_local_size(0);\n    wave_sizze_34508 = LOCKSTEP_WIDTH;\n    block_id_34507 = get_tblock_id(0);\n    global_tid_34505 = block_id_34507 * tblock_sizze_34509 + local_tid_34506;\n    phys_tid_33798 = sext_i32_i64(global_tid_34505);\n    global_tid_34510 = sext_i32_i64(block_id_34507) * segmap_tblock_sizze_33794 + sext_i32_i64(local_tid_34506);\n    slice_34511 = loopres_32671;\n    gtid_33797 = global_tid_34510;\n    remnant_34512 = global_tid_34510 - gtid_33797;\n    if (slt64(gtid_33797, loopres_32671)) {\n        int64_t loopres_33827;\n        int64_t tmp_33800;\n        \n        loopres_33827 = ((__global int64_t *) mem_33916)[(int64_t) 0];\n        tmp_33800 = add64(gtid_33797, loopres_33827);\n        ((__global int64_t *) mem_33913)[loopres_32670 + gtid_33797] = tmp_33800;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_33794\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_doublezisegscan_33724_dim1, 1, 1)\nvoid inner_SMJ_doublezisegscan_33724(__global i",
                                    "nt *global_failure, int64_t nR_28192, int64_t num_tblocks_33721, int64_t num_virt_blocks_34029, int64_t num_virt_threads_34030, __global unsigned char *mem_33836, __global unsigned char *status_flags_mem_34031, __global unsigned char *aggregates_mem_34053, __global unsigned char *incprefixes_mem_34055, __global unsigned char *global_dynid_mem_34057)\n{\n    #define segscan_tblock_sizze_33719 (inner_SMJ_doublezisegscan_33724zisegscan_tblock_sizze_33719)\n    #define chunk_sizze_34028 (inner_SMJ_doublezisegscan_33724zichunk_sizze_34028)\n    \n    volatile __local unsigned char *local_mem_34087_backing_0 = &shared_mem[0];\n    const int64_t local_mem_34087_backing_0_offset = 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_33719), chunk_sizze_34028 * segscan_tblock_sizze_33719 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_33719), chunk_sizze_34028 * segscan_tblock_sizze_33719 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34080;\n    int32_t tblock_sizze_34083;\n    int32_t wave_sizze_34082;\n    int32_t block_id_34081;\n    int32_t global_tid_34079;\n    int64_t phys_tid_33724;\n    int32_t chunk_sizze_32b_34084;\n    int64_t byte_offsets_34085;\n    int64_t warp_byte_offset_34086;\n    __local unsigned char *local_mem_34087;\n    int64_t trans_arr_len_34088;\n    int64_t phys_block_id_34094;\n    int64_t virtloop_bound_34095;\n    \n    local_tid_34080 = get_local_id(0);\n    tblock_sizze_34083 = get_local_size(0);\n    wave_sizze_34082 = LOCKSTEP_WIDTH;\n    block_id_34081 = get_tblock_id(0);\n    global_tid_34079 = block_id_34081 * tblock_sizze_34083 + local_tid_34080;\n    phys_tid_33724 = sext_i32_i64(global_tid_34079);\n    chunk_sizze_32b_34084 = sext_i64_i32(chunk_sizze_34028);\n    byte_offsets_34085 = segscan_tblock_sizze_33719 * (int64_t) 8;\n    warp_byte_offset_34086 = (int64_t) 288;\n    // Allocate reusable shared memory\n   ", " { }\n    local_mem_34087 = (__local unsigned char *) local_mem_34087_backing_0;\n    trans_arr_len_34088 = chunk_sizze_34028 * segscan_tblock_sizze_33719;\n    phys_block_id_34094 = get_tblock_id(0);\n    virtloop_bound_34095 = sdiv_up64(num_virt_blocks_34029 - phys_block_id_34094, num_tblocks_33721);\n    for (int64_t virtloop_i_34096 = 0; virtloop_i_34096 < virtloop_bound_34095; virtloop_i_34096++) {\n        int64_t dynamic_id_34097;\n        int64_t block_offset_34098;\n        int64_t sgm_idx_34099;\n        int32_t boundary_34100;\n        int32_t segsizze_compact_34101;\n        int64_t private_mem_34102[chunk_sizze_34028];\n        int64_t thd_offset_34104;\n        int64_t acc_34120;\n        int64_t prefix_34130;\n        bool block_new_sgm_34131;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_34080 == 0) {\n                dynamic_id_34097 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_34057)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_34087)[(int64_t) 0] = dynamic_id_34097;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_34097 == num_virt_blocks_34029 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_34057)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_34097 = ((__local int32_t *) local_mem_34087)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_34098 = dynamic_id_34097 * chunk_sizze_34028 * segscan_tblock_sizze_33719;\n        sgm_idx_34099 = smod64(block_offset_34098, nR_28192);\n        boundary_34100 = sext_i64_i32(smin64(chunk_sizze_34028 * segscan_tblock_sizze_33719, nR_28192 - sgm_idx_34099));\n        segsizze_compact_34101 = sext_i64_i32", "(smin64(chunk_sizze_34028 * segscan_tblock_sizze_33719, nR_28192));\n        thd_offset_34104 = block_offset_34098 + sext_i32_i64(local_tid_34080);\n        // Load and map\n        {\n            for (int64_t i_34105 = 0; i_34105 < chunk_sizze_34028; i_34105++) {\n                int64_t virt_tid_34106 = thd_offset_34104 + i_34105 * segscan_tblock_sizze_33719;\n                int64_t slice_34107 = nR_28192;\n                int64_t gtid_33723 = virt_tid_34106;\n                int64_t remnant_34108 = virt_tid_34106 - gtid_33723;\n                \n                if (slt64(virt_tid_34106, nR_28192)) {\n                    private_mem_34102[i_34105] = (int64_t) 0;\n                } else {\n                    private_mem_34102[i_34105] = (int64_t) 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_34109 = 0; i_34109 < chunk_sizze_34028; i_34109++) {\n                int64_t sharedIdx_34110 = sext_i32_i64(local_tid_34080) + i_34109 * segscan_tblock_sizze_33719;\n                int64_t tmp_34111 = private_mem_34102[i_34109];\n                \n                ((__local int64_t *) local_mem_34087)[sharedIdx_34110] = tmp_34111;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34112 = 0; i_34112 < chunk_sizze_34028; i_34112++) {\n                int64_t sharedIdx_34113 = sext_i32_i64(local_tid_34080) * chunk_sizze_34028 + i_34112;\n                int64_t tmp_34114 = ((__local int64_t *) local_mem_34087)[sharedIdx_34113];\n                \n                private_mem_34102[i_34112] = tmp_34114;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_34115 = 0; i_34115 < chunk_sizze_34028 - (int64_t) 1; i_34115++) {\n                int64_t eta_p_32774;\n                int64_t eta_p_32775;\n                \n                eta_p_32774 = private_mem_34102[i_34115];\n                eta_",
                                    "p_32775 = private_mem_34102[i_34115 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_32776 = add64(eta_p_32774, eta_p_32775);\n                \n                private_mem_34102[i_34115 + (int64_t) 1] = defunc_0_op_res_32776;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_34116 = private_mem_34102[chunk_sizze_34028 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)] = tmp_34116;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_34117;\n            int64_t eta_p_34118;\n            int64_t eta_p_34121;\n            int64_t eta_p_34122;\n            bool ltid_in_bounds_34124 = slt64(sext_i32_i64(local_tid_34080), num_virt_threads_34030);\n            int32_t skip_threads_34125;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_34124) {\n                    eta_p_34118 = ((volatile __local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)];\n                    if ((local_tid_34080 - squot32(local_tid_34080, 32) * 32) == 0) {\n                        eta_p_34117 = eta_p_34118;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_34125 = 1;\n                while (slt32(skip_threads_34125, 32)) {\n                    bool thread_active_34126 = sle32(skip_threads_34125, local_tid_34080 - squot32(local_tid_34080, 32) * 32) && ltid_in_bounds_34124;\n                    \n                    if (thread_active_34126) {\n                        // read operands\n                        {\n                            eta_p_34117 = ((volatile __local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080) - sext_i32_i64(skip_threads_34125)];\n                        }\n                    }\n                    // per", "form operation\n                    {\n                        if (thread_active_34126) {\n                            int64_t defunc_0_op_res_34119 = add64(eta_p_34117, eta_p_34118);\n                            \n                            eta_p_34117 = defunc_0_op_res_34119;\n                        }\n                    }\n                    if (sle32(wave_sizze_34082, skip_threads_34125)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_34126) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)] = eta_p_34117;\n                            eta_p_34118 = eta_p_34117;\n                        }\n                    }\n                    if (sle32(wave_sizze_34082, skip_threads_34125)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_34125 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_34080 - squot32(local_tid_34080, 32) * 32) == 31 && ltid_in_bounds_34124) {\n                    ((volatile __local int64_t *) local_mem_34087)[sext_i32_i64(squot32(local_tid_34080, 32))] = eta_p_34117;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_34127;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_34080, 32) == 0 && ltid_in_bounds_34124) {\n                        eta_p_34122 = ((volatile __local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)];\n                        if ((local_tid_34080 - squot32(local_tid_34080, 32) * 32) == 0) {\n       ", "                     eta_p_34121 = eta_p_34122;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_34127 = 1;\n                    while (slt32(skip_threads_34127, 32)) {\n                        bool thread_active_34128 = sle32(skip_threads_34127, local_tid_34080 - squot32(local_tid_34080, 32) * 32) && (squot32(local_tid_34080, 32) == 0 && ltid_in_bounds_34124);\n                        \n                        if (thread_active_34128) {\n                            // read operands\n                            {\n                                eta_p_34121 = ((volatile __local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080) - sext_i32_i64(skip_threads_34127)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_34128) {\n                                int64_t defunc_0_op_res_34123 = add64(eta_p_34121, eta_p_34122);\n                                \n                                eta_p_34121 = defunc_0_op_res_34123;\n                            }\n                        }\n                        if (sle32(wave_sizze_34082, skip_threads_34127)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_34128) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)] = eta_p_34121;\n                                eta_p_34122 = eta_p_34121;\n                            }\n                        }\n                        if (sle32(wave_sizze_34082, skip_threads_34127)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_34127 *= 2;\n                    }\n    ",
                                    "            }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_34129 = squot32(local_tid_34080, 32) == 0 || !ltid_in_bounds_34124;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_34129) {\n                        eta_p_34118 = eta_p_34117;\n                        eta_p_34117 = ((__local int64_t *) local_mem_34087)[sext_i32_i64(squot32(local_tid_34080, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_34129) {\n                        int64_t defunc_0_op_res_34119 = add64(eta_p_34117, eta_p_34118);\n                        \n                        eta_p_34117 = defunc_0_op_res_34119;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_34129) {\n                        ((__local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)] = eta_p_34117;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_34080, 32) == 0 && ltid_in_bounds_34124) {\n                    ((__local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)] = eta_p_34118;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_34080 == 0) {\n                acc_34120 = ((__local int64_t *) local_mem_34087)[segscan_tblock_sizze_33719 - (int64_t) 1];\n            } else {\n                acc_34120 = ((__local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_34130 = (int64_t) 0;\n        block_new_sgm_34131 = sgm_idx_", "34099 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_34131 && local_tid_34080 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_34055)[dynamic_id_34097] = acc_34120;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_34031)[dynamic_id_34097] = (int8_t) 2;\n                acc_34120 = (int64_t) 0;\n            }\n            if (!block_new_sgm_34131 && slt32(local_tid_34080, wave_sizze_34082)) {\n                if (local_tid_34080 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_34053)[dynamic_id_34097] = acc_34120;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_34031)[dynamic_id_34097] = (int8_t) 1;\n                    \n                    int8_t tmp_34132 = ((volatile __global int8_t *) status_flags_mem_34031)[dynamic_id_34097 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_34087)[(int64_t) 0] = tmp_34132;\n                }\n                mem_fence_local();\n                \n                int8_t status_34133 = ((__local int8_t *) local_mem_34087)[(int64_t) 0];\n                \n                if (status_34133 == (int8_t) 2) {\n                    if (local_tid_34080 == 0) {\n                        prefix_34130 = ((volatile __global int64_t *) incprefixes_mem_34055)[dynamic_id_34097 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_34134 = sext_i64_i32(dynamic_id_34097 - sext_i32_i64(wave_sizze_34082));\n                    \n                    while (slt32(wave_sizze_34082 * -1, readOffset_34134)) {\n                        int32_t read_i_34135 = readOffset_34134 + local_tid_34080;\n                        int64_t aggr_34136 = (int64_t) 0;\n                        int8_t flag_34137 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_34135)) {\n            ", "                flag_34137 = ((volatile __global int8_t *) status_flags_mem_34031)[sext_i32_i64(read_i_34135)];\n                            if (flag_34137 == (int8_t) 2) {\n                                aggr_34136 = ((volatile __global int64_t *) incprefixes_mem_34055)[sext_i32_i64(read_i_34135)];\n                            } else if (flag_34137 == (int8_t) 1) {\n                                aggr_34136 = ((volatile __global int64_t *) aggregates_mem_34053)[sext_i32_i64(read_i_34135)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_34087)[(int64_t) 4 + sext_i32_i64(local_tid_34080)] = aggr_34136;\n                        ((__local int8_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)] = flag_34137;\n                        flag_34137 = ((__local int8_t *) local_mem_34087)[sext_i32_i64(wave_sizze_34082) - (int64_t) 1];\n                        if (slt8(flag_34137, (int8_t) 2)) {\n                            int8_t flg_x_34141;\n                            int8_t flg_y_34142;\n                            int64_t eta_p_34138;\n                            int64_t eta_p_34139;\n                            int32_t skip_threads_34143;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_34142 = ((volatile __local int8_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)];\n                                eta_p_34139 = ((volatile __local int64_t *) local_mem_34087)[(int64_t) 4 + sext_i32_i64(local_tid_34080)];\n                                if ((local_tid_34080 - squot32(local_tid_34080, 32) * 32) == 0) {\n                                    eta_p_34138 = eta_p_34139;\n                                    flg_x_34141 = flg_y_34142;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                ",
                                    "                skip_threads_34143 = 1;\n                                while (slt32(skip_threads_34143, 32)) {\n                                    if (sle32(skip_threads_34143, local_tid_34080 - squot32(local_tid_34080, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_34141 = ((volatile __local int8_t *) local_mem_34087)[sext_i32_i64(local_tid_34080) - sext_i32_i64(skip_threads_34143)];\n                                            eta_p_34138 = ((volatile __local int64_t *) local_mem_34087)[(int64_t) 4 + (sext_i32_i64(local_tid_34080) - sext_i32_i64(skip_threads_34143))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_34142 == (int8_t) 2 || flg_y_34142 == (int8_t) 0) {\n                                                flg_x_34141 = flg_y_34142;\n                                                eta_p_34138 = eta_p_34139;\n                                            } else {\n                                                int64_t defunc_0_op_res_34140 = add64(eta_p_34138, eta_p_34139);\n                                                \n                                                eta_p_34138 = defunc_0_op_res_34140;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)] = flg_x_34141;\n                                            flg_y_34142 = flg_x_34141;\n                                            ((volatile __local int64_t *) local_mem_34087)[(int64_t) 4 + sext_i32_i64(local_tid_34080)] = eta_p_34138;\n                                            eta_p_34139 = eta_p", "_34138;\n                                        }\n                                    }\n                                    skip_threads_34143 *= 2;\n                                }\n                            }\n                        }\n                        flag_34137 = ((__local int8_t *) local_mem_34087)[sext_i32_i64(wave_sizze_34082) - (int64_t) 1];\n                        aggr_34136 = ((__local int64_t *) local_mem_34087)[(int64_t) 4 + (sext_i32_i64(wave_sizze_34082) - (int64_t) 1)];\n                        if (flag_34137 == (int8_t) 2) {\n                            readOffset_34134 = wave_sizze_34082 * -1;\n                        } else if (flag_34137 == (int8_t) 1) {\n                            readOffset_34134 -= wave_sizze_34082;\n                        }\n                        if (slt8((int8_t) 0, flag_34137)) {\n                            int64_t eta_p_34144 = aggr_34136;\n                            int64_t eta_p_34145 = prefix_34130;\n                            int64_t defunc_0_op_res_34146 = add64(eta_p_34144, eta_p_34145);\n                            \n                            prefix_34130 = defunc_0_op_res_34146;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_34080 == 0) {\n                    if (boundary_34100 == sext_i64_i32(segscan_tblock_sizze_33719 * chunk_sizze_34028)) {\n                        int64_t eta_p_34147 = prefix_34130;\n                        int64_t eta_p_34148 = acc_34120;\n                        int64_t defunc_0_op_res_34149 = add64(eta_p_34147, eta_p_34148);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_34055)[dynamic_id_34097] = defunc_0_op_res_34149;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_34031)[dynamic_id_34097] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_34087)[(i", "nt64_t) 4] = prefix_34130;\n                    acc_34120 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_34097 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_34130 = ((__local int64_t *) local_mem_34087)[(int64_t) 4];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_34150;\n            int64_t eta_p_34151;\n            int64_t eta_p_34153 = prefix_34130;\n            int64_t eta_p_34154 = acc_34120;\n            \n            if (slt32(local_tid_34080 * chunk_sizze_32b_34084, boundary_34100) && !block_new_sgm_34131) {\n                int64_t defunc_0_op_res_34155 = add64(eta_p_34153, eta_p_34154);\n                \n                eta_p_34150 = defunc_0_op_res_34155;\n            } else {\n                eta_p_34150 = acc_34120;\n            }\n            \n            int32_t stopping_point_34156 = segsizze_compact_34101 - srem32(local_tid_34080 * chunk_sizze_32b_34084 - 1 + segsizze_compact_34101 - boundary_34100, segsizze_compact_34101);\n            \n            for (int64_t i_34157 = 0; i_34157 < chunk_sizze_34028; i_34157++) {\n                if (slt32(sext_i64_i32(i_34157), stopping_point_34156 - 1)) {\n                    eta_p_34151 = private_mem_34102[i_34157];\n                    \n                    int64_t defunc_0_op_res_34152 = add64(eta_p_34150, eta_p_34151);\n                    \n                    private_mem_34102[i_34157] = defunc_0_op_res_34152;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_34158 = 0; i_34158 < chunk_sizze_34028; i_34158++) {\n                int64_t sharedIdx_34159 = sext_i32_i64(local_tid_34080) * chunk_sizze_34028 + i_34158;\n                int64_t tmp_34160 = private_mem_34102[i_34158];\n                \n                ((__local int64_t *) local_mem_34087)[sharedIdx_34",
                                    "159] = tmp_34160;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34161 = 0; i_34161 < chunk_sizze_34028; i_34161++) {\n                int64_t flat_idx_34162 = thd_offset_34104 + i_34161 * segscan_tblock_sizze_33719;\n                int64_t slice_34163 = nR_28192;\n                int64_t gtid_33723 = flat_idx_34162;\n                int64_t remnant_34164 = flat_idx_34162 - gtid_33723;\n                \n                if (slt64(flat_idx_34162, nR_28192)) {\n                    int64_t tmp_34165 = ((__local int64_t *) local_mem_34087)[flat_idx_34162 - block_offset_34098];\n                    \n                    ((__global int64_t *) mem_33836)[gtid_33723] = tmp_34165;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_33719\n    #undef chunk_sizze_34028\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_doublezisegscan_33740_dim1, 1, 1)\nvoid inner_SMJ_doublezisegscan_33740(__global int *global_failure, int64_t m_32498, int64_t num_tblocks_33737, int64_t num_virt_blocks_34223, int64_t num_virt_threads_34224, __global unsigned char *mem_33844, __global unsigned char *mem_33848, __global unsigned char *mem_33850, __global unsigned char *mem_33852, __global unsigned char *status_flags_mem_34225, __global unsigned char *aggregates_mem_34227, __global unsigned char *incprefixes_mem_34229, __global unsigned char *aggregates_mem_34231, __global unsigned char *incprefixes_mem_34233, __global unsigned char *global_dynid_mem_34235)\n{\n    #define segscan_tblock_sizze_33735 (inner_SMJ_doublezisegscan_33740zisegscan_tblock_sizze_33735)\n    #define chunk_sizze_34222 (inner_SMJ_doublezisegscan_33740zichunk_sizze_34222)\n    \n    volatile __local unsigned char *local_mem_34247_backing_0 = &shared_mem[0];\n    const int64_t local_mem_34247_backing_0_offset = 0 + (smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_33735, (int64_t) 8) * (int64_t) 8 + (int", "64_t) 8 * segscan_tblock_sizze_33735), smax64(chunk_sizze_34222 * segscan_tblock_sizze_33735 * (int64_t) 8, chunk_sizze_34222 * segscan_tblock_sizze_33735 * (int64_t) 8)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_33735, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_33735), smax64(chunk_sizze_34222 * segscan_tblock_sizze_33735 * (int64_t) 8, chunk_sizze_34222 * segscan_tblock_sizze_33735 * (int64_t) 8)), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34238;\n    int32_t tblock_sizze_34241;\n    int32_t wave_sizze_34240;\n    int32_t block_id_34239;\n    int32_t global_tid_34237;\n    int64_t phys_tid_33740;\n    int32_t chunk_sizze_32b_34242;\n    int64_t byte_offsets_34243;\n    int64_t byte_offsets_34244;\n    int64_t warp_byte_offset_34245;\n    int64_t warp_byte_offset_34246;\n    __local unsigned char *local_mem_34247;\n    int64_t trans_arr_len_34248;\n    int64_t phys_block_id_34257;\n    int64_t virtloop_bound_34258;\n    \n    local_tid_34238 = get_local_id(0);\n    tblock_sizze_34241 = get_local_size(0);\n    wave_sizze_34240 = LOCKSTEP_WIDTH;\n    block_id_34239 = get_tblock_id(0);\n    global_tid_34237 = block_id_34239 * tblock_sizze_34241 + local_tid_34238;\n    phys_tid_33740 = sext_i32_i64(global_tid_34237);\n    chunk_sizze_32b_34242 = sext_i64_i32(chunk_sizze_34222);\n    byte_offsets_34243 = segscan_tblock_sizze_33735 * (int64_t) 8;\n    byte_offsets_34244 = sdiv_up64(byte_offsets_34243, (int64_t) 8) * (int64_t) 8 + segscan_tblock_sizze_33735 * (int64_t) 8;\n    warp_byte_offset_34245 = (int64_t) 288;\n    warp_byte_offset_34246 = sdiv_up64(warp_byte_offset_34245, (int64_t) 8) * (int64_t) 8 + (int64_t) 256;\n    // Allocate reusable shared memory\n    { }\n    local_mem_34247 = (__local unsigned char *) local_mem_34247_backing_0;\n    trans_arr_len_34248 = chunk_sizze_34222 * segscan_tblock_sizze_33735;\n    phys_block_id_34257 = get_tblock_i", "d(0);\n    virtloop_bound_34258 = sdiv_up64(num_virt_blocks_34223 - phys_block_id_34257, num_tblocks_33737);\n    for (int64_t virtloop_i_34259 = 0; virtloop_i_34259 < virtloop_bound_34258; virtloop_i_34259++) {\n        int64_t dynamic_id_34260;\n        int64_t block_offset_34261;\n        int64_t sgm_idx_34262;\n        int32_t boundary_34263;\n        int32_t segsizze_compact_34264;\n        int64_t private_mem_34265[chunk_sizze_34222];\n        int64_t private_mem_34267[chunk_sizze_34222];\n        int64_t thd_offset_34269;\n        int64_t acc_34295;\n        int64_t acc_34296;\n        int64_t prefix_34309;\n        int64_t prefix_34310;\n        bool block_new_sgm_34311;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_34238 == 0) {\n                dynamic_id_34260 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_34235)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_34247)[(int64_t) 0] = dynamic_id_34260;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_34260 == num_virt_blocks_34223 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_34235)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_34260 = ((__local int32_t *) local_mem_34247)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_34261 = dynamic_id_34260 * chunk_sizze_34222 * segscan_tblock_sizze_33735;\n        sgm_idx_34262 = smod64(block_offset_34261, m_32498);\n        boundary_34263 = sext_i64_i32(smin64(chunk_sizze_34222 * segscan_tblock_sizze_33735, m_32498 - sgm_idx_34262));\n        segsizze_compact_34264 = sext_i64_i32(smin64(chunk_sizze_34222 * segscan_tblock_sizze_33735, m_32498));\n        thd_offs",
                                    "et_34269 = block_offset_34261 + sext_i32_i64(local_tid_34238);\n        // Load and map\n        {\n            for (int64_t i_34270 = 0; i_34270 < chunk_sizze_34222; i_34270++) {\n                int64_t virt_tid_34271 = thd_offset_34269 + i_34270 * segscan_tblock_sizze_33735;\n                int64_t slice_34272 = m_32498;\n                int64_t gtid_33739 = virt_tid_34271;\n                int64_t remnant_34273 = virt_tid_34271 - gtid_33739;\n                \n                if (slt64(virt_tid_34271, m_32498)) {\n                    int64_t x_32733 = ((__global int64_t *) mem_33844)[gtid_33739];\n                    bool lifted_lambda_res_32735 = slt64((int64_t) 1, x_32733);\n                    int64_t defunc_0_f_res_32736 = btoi_bool_i64(lifted_lambda_res_32735);\n                    \n                    ((__global int64_t *) mem_33852)[gtid_33739] = defunc_0_f_res_32736;\n                    private_mem_34265[i_34270] = x_32733;\n                    private_mem_34267[i_34270] = defunc_0_f_res_32736;\n                } else {\n                    private_mem_34265[i_34270] = (int64_t) 0;\n                    private_mem_34267[i_34270] = (int64_t) 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_34274 = 0; i_34274 < chunk_sizze_34222; i_34274++) {\n                int64_t sharedIdx_34275 = sext_i32_i64(local_tid_34238) + i_34274 * segscan_tblock_sizze_33735;\n                int64_t tmp_34276 = private_mem_34265[i_34274];\n                \n                ((__local int64_t *) local_mem_34247)[sharedIdx_34275] = tmp_34276;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34277 = 0; i_34277 < chunk_sizze_34222; i_34277++) {\n                int64_t sharedIdx_34278 = sext_i32_i64(local_tid_34238) * chunk_sizze_34222 + i_34277;\n                int64_t tmp_34279 = ((__local int64_t *) local_mem_34247)[sharedIdx_34278];\n                \n              ", "  private_mem_34265[i_34277] = tmp_34279;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34280 = 0; i_34280 < chunk_sizze_34222; i_34280++) {\n                int64_t sharedIdx_34281 = sext_i32_i64(local_tid_34238) + i_34280 * segscan_tblock_sizze_33735;\n                int64_t tmp_34282 = private_mem_34267[i_34280];\n                \n                ((__local int64_t *) local_mem_34247)[sharedIdx_34281] = tmp_34282;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34283 = 0; i_34283 < chunk_sizze_34222; i_34283++) {\n                int64_t sharedIdx_34284 = sext_i32_i64(local_tid_34238) * chunk_sizze_34222 + i_34283;\n                int64_t tmp_34285 = ((__local int64_t *) local_mem_34247)[sharedIdx_34284];\n                \n                private_mem_34267[i_34283] = tmp_34285;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_34286 = 0; i_34286 < chunk_sizze_34222 - (int64_t) 1; i_34286++) {\n                int64_t eta_p_32523;\n                int64_t eta_p_32524;\n                \n                eta_p_32523 = private_mem_34265[i_34286];\n                eta_p_32524 = private_mem_34265[i_34286 + (int64_t) 1];\n                \n                int64_t eta_p_32616;\n                int64_t eta_p_32617;\n                \n                eta_p_32616 = private_mem_34267[i_34286];\n                eta_p_32617 = private_mem_34267[i_34286 + (int64_t) 1];\n                \n                int64_t lifted_lambda_res_32525 = add64(eta_p_32523, eta_p_32524);\n                int64_t defunc_0_op_res_32618 = add64(eta_p_32616, eta_p_32617);\n                \n                private_mem_34265[i_34286 + (int64_t) 1] = lifted_lambda_res_32525;\n                private_mem_34267[i_34286 + (int64_t) 1] = defunc_0_op_res_32618;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_34287 = private_mem", "_34265[chunk_sizze_34222 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)] = tmp_34287;\n            \n            int64_t tmp_34288 = private_mem_34267[chunk_sizze_34222 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(local_tid_34238)] = tmp_34288;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_34289;\n            int64_t eta_p_34290;\n            int64_t eta_p_34291;\n            int64_t eta_p_34292;\n            int64_t eta_p_34297;\n            int64_t eta_p_34298;\n            int64_t eta_p_34299;\n            int64_t eta_p_34300;\n            bool ltid_in_bounds_34303 = slt64(sext_i32_i64(local_tid_34238), num_virt_threads_34224);\n            int32_t skip_threads_34304;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_34303) {\n                    eta_p_34291 = ((volatile __local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)];\n                    eta_p_34292 = ((volatile __local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(local_tid_34238)];\n                    if ((local_tid_34238 - squot32(local_tid_34238, 32) * 32) == 0) {\n                        eta_p_34289 = eta_p_34291;\n                        eta_p_34290 = eta_p_34292;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_34304 = 1;\n                while (slt32(skip_threads_34304, 32)) {\n                    bool thread_active_34305 = sle32(skip_threads_34304, local_tid_34238 - squot32(local_tid_34238, 32) * 32) && ltid_in_bounds_34303;\n                    \n                    if (thread_active_34305) {\n                        // read operands\n                        {\n              ",
                                    "              eta_p_34289 = ((volatile __local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238) - sext_i32_i64(skip_threads_34304)];\n                            eta_p_34290 = ((volatile __local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + (sext_i32_i64(local_tid_34238) - sext_i32_i64(skip_threads_34304))];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_34305) {\n                            int64_t lifted_lambda_res_34293 = add64(eta_p_34289, eta_p_34291);\n                            int64_t defunc_0_op_res_34294 = add64(eta_p_34290, eta_p_34292);\n                            \n                            eta_p_34289 = lifted_lambda_res_34293;\n                            eta_p_34290 = defunc_0_op_res_34294;\n                        }\n                    }\n                    if (sle32(wave_sizze_34240, skip_threads_34304)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_34305) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)] = eta_p_34289;\n                            eta_p_34291 = eta_p_34289;\n                            ((volatile __local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(local_tid_34238)] = eta_p_34290;\n                            eta_p_34292 = eta_p_34290;\n                        }\n                    }\n                    if (sle32(wave_sizze_34240, skip_threads_34304)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_34304 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_34238 - squo", "t32(local_tid_34238, 32) * 32) == 31 && ltid_in_bounds_34303) {\n                    ((volatile __local int64_t *) local_mem_34247)[sext_i32_i64(squot32(local_tid_34238, 32))] = eta_p_34289;\n                    ((volatile __local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(squot32(local_tid_34238, 32))] = eta_p_34290;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_34306;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_34238, 32) == 0 && ltid_in_bounds_34303) {\n                        eta_p_34299 = ((volatile __local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)];\n                        eta_p_34300 = ((volatile __local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(local_tid_34238)];\n                        if ((local_tid_34238 - squot32(local_tid_34238, 32) * 32) == 0) {\n                            eta_p_34297 = eta_p_34299;\n                            eta_p_34298 = eta_p_34300;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_34306 = 1;\n                    while (slt32(skip_threads_34306, 32)) {\n                        bool thread_active_34307 = sle32(skip_threads_34306, local_tid_34238 - squot32(local_tid_34238, 32) * 32) && (squot32(local_tid_34238, 32) == 0 && ltid_in_bounds_34303);\n                        \n                        if (thread_active_34307) {\n                            // read operands\n                            {\n                                eta_p_34297 = ((volatile __local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238) - sext_i32_i64(skip_threads_34306)];\n             ", "                   eta_p_34298 = ((volatile __local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + (sext_i32_i64(local_tid_34238) - sext_i32_i64(skip_threads_34306))];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_34307) {\n                                int64_t lifted_lambda_res_34301 = add64(eta_p_34297, eta_p_34299);\n                                int64_t defunc_0_op_res_34302 = add64(eta_p_34298, eta_p_34300);\n                                \n                                eta_p_34297 = lifted_lambda_res_34301;\n                                eta_p_34298 = defunc_0_op_res_34302;\n                            }\n                        }\n                        if (sle32(wave_sizze_34240, skip_threads_34306)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_34307) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)] = eta_p_34297;\n                                eta_p_34299 = eta_p_34297;\n                                ((volatile __local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(local_tid_34238)] = eta_p_34298;\n                                eta_p_34300 = eta_p_34298;\n                            }\n                        }\n                        if (sle32(wave_sizze_34240, skip_threads_34306)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_34306 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_34308 = squot32(local_tid_34238, 32) == 0 || !ltid_in_bounds_34303;\n            \n            // carry-in",
                                    " for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_34308) {\n                        eta_p_34291 = eta_p_34289;\n                        eta_p_34292 = eta_p_34290;\n                        eta_p_34289 = ((__local int64_t *) local_mem_34247)[sext_i32_i64(squot32(local_tid_34238, 32)) - (int64_t) 1];\n                        eta_p_34290 = ((__local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + (sext_i32_i64(squot32(local_tid_34238, 32)) - (int64_t) 1)];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_34308) {\n                        int64_t lifted_lambda_res_34293 = add64(eta_p_34289, eta_p_34291);\n                        int64_t defunc_0_op_res_34294 = add64(eta_p_34290, eta_p_34292);\n                        \n                        eta_p_34289 = lifted_lambda_res_34293;\n                        eta_p_34290 = defunc_0_op_res_34294;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_34308) {\n                        ((__local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)] = eta_p_34289;\n                        ((__local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(local_tid_34238)] = eta_p_34290;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_34238, 32) == 0 && ltid_in_bounds_34303) {\n                    ((__local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)] = eta_p_34291;\n                    ((__local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(local_tid_34238)] = eta_p_34292;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE", ");\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_34238 == 0) {\n                acc_34295 = ((__local int64_t *) local_mem_34247)[segscan_tblock_sizze_33735 - (int64_t) 1];\n                acc_34296 = ((__local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + (segscan_tblock_sizze_33735 - (int64_t) 1)];\n            } else {\n                acc_34295 = ((__local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238) - (int64_t) 1];\n                acc_34296 = ((__local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + (sext_i32_i64(local_tid_34238) - (int64_t) 1)];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_34309 = (int64_t) 0;\n        prefix_34310 = (int64_t) 0;\n        block_new_sgm_34311 = sgm_idx_34262 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_34311 && local_tid_34238 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_34229)[dynamic_id_34260] = acc_34295;\n                ((volatile __global int64_t *) incprefixes_mem_34233)[dynamic_id_34260] = acc_34296;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_34225)[dynamic_id_34260] = (int8_t) 2;\n                acc_34295 = (int64_t) 0;\n                acc_34296 = (int64_t) 0;\n            }\n            if (!block_new_sgm_34311 && slt32(local_tid_34238, wave_sizze_34240)) {\n                if (local_tid_34238 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_34227)[dynamic_id_34260] = acc_34295;\n                    ((volatile __global int64_t *) aggregates_mem_34231)[dynamic_id_34260] = acc_34296;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_34225)[dynamic_id_34260] = (int8_t) 1;\n                    \n                    int8_t tmp_34312 = ((volatile __global int8_t *) status_flags_mem_34225)[dynamic_id_34260 - (int64_t) 1]", ";\n                    \n                    ((volatile __local int8_t *) local_mem_34247)[(int64_t) 0] = tmp_34312;\n                }\n                mem_fence_local();\n                \n                int8_t status_34313 = ((__local int8_t *) local_mem_34247)[(int64_t) 0];\n                \n                if (status_34313 == (int8_t) 2) {\n                    if (local_tid_34238 == 0) {\n                        prefix_34309 = ((volatile __global int64_t *) incprefixes_mem_34229)[dynamic_id_34260 - (int64_t) 1];\n                        prefix_34310 = ((volatile __global int64_t *) incprefixes_mem_34233)[dynamic_id_34260 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_34314 = sext_i64_i32(dynamic_id_34260 - sext_i32_i64(wave_sizze_34240));\n                    \n                    while (slt32(wave_sizze_34240 * -1, readOffset_34314)) {\n                        int32_t read_i_34315 = readOffset_34314 + local_tid_34238;\n                        int64_t aggr_34316 = (int64_t) 0;\n                        int64_t aggr_34317 = (int64_t) 0;\n                        int8_t flag_34318 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_34315)) {\n                            flag_34318 = ((volatile __global int8_t *) status_flags_mem_34225)[sext_i32_i64(read_i_34315)];\n                            if (flag_34318 == (int8_t) 2) {\n                                aggr_34316 = ((volatile __global int64_t *) incprefixes_mem_34229)[sext_i32_i64(read_i_34315)];\n                                aggr_34317 = ((volatile __global int64_t *) incprefixes_mem_34233)[sext_i32_i64(read_i_34315)];\n                            } else if (flag_34318 == (int8_t) 1) {\n                                aggr_34316 = ((volatile __global int64_t *) aggregates_mem_34227)[sext_i32_i64(read_i_34315)];\n                                aggr_34317 = ((volatile __global int64_t *) aggregates_mem_34231)[sext_i32_i64(read_i_34315)];\n       ",
                                    "                     }\n                        }\n                        ((__local int64_t *) local_mem_34247)[(int64_t) 4 + sext_i32_i64(local_tid_34238)] = aggr_34316;\n                        ((__local int64_t *) local_mem_34247)[squot64(warp_byte_offset_34245, (int64_t) 8) + sext_i32_i64(local_tid_34238)] = aggr_34317;\n                        ((__local int8_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)] = flag_34318;\n                        flag_34318 = ((__local int8_t *) local_mem_34247)[sext_i32_i64(wave_sizze_34240) - (int64_t) 1];\n                        if (slt8(flag_34318, (int8_t) 2)) {\n                            int8_t flg_x_34325;\n                            int8_t flg_y_34326;\n                            int64_t eta_p_34319;\n                            int64_t eta_p_34320;\n                            int64_t eta_p_34321;\n                            int64_t eta_p_34322;\n                            int32_t skip_threads_34327;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_34326 = ((volatile __local int8_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)];\n                                eta_p_34321 = ((volatile __local int64_t *) local_mem_34247)[(int64_t) 4 + sext_i32_i64(local_tid_34238)];\n                                eta_p_34322 = ((volatile __local int64_t *) local_mem_34247)[squot64(warp_byte_offset_34245, (int64_t) 8) + sext_i32_i64(local_tid_34238)];\n                                if ((local_tid_34238 - squot32(local_tid_34238, 32) * 32) == 0) {\n                                    eta_p_34319 = eta_p_34321;\n                                    eta_p_34320 = eta_p_34322;\n                                    flg_x_34325 = flg_y_34326;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                              ", "  skip_threads_34327 = 1;\n                                while (slt32(skip_threads_34327, 32)) {\n                                    if (sle32(skip_threads_34327, local_tid_34238 - squot32(local_tid_34238, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_34325 = ((volatile __local int8_t *) local_mem_34247)[sext_i32_i64(local_tid_34238) - sext_i32_i64(skip_threads_34327)];\n                                            eta_p_34319 = ((volatile __local int64_t *) local_mem_34247)[(int64_t) 4 + (sext_i32_i64(local_tid_34238) - sext_i32_i64(skip_threads_34327))];\n                                            eta_p_34320 = ((volatile __local int64_t *) local_mem_34247)[squot64(warp_byte_offset_34245, (int64_t) 8) + (sext_i32_i64(local_tid_34238) - sext_i32_i64(skip_threads_34327))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_34326 == (int8_t) 2 || flg_y_34326 == (int8_t) 0) {\n                                                flg_x_34325 = flg_y_34326;\n                                                eta_p_34319 = eta_p_34321;\n                                                eta_p_34320 = eta_p_34322;\n                                            } else {\n                                                int64_t lifted_lambda_res_34323 = add64(eta_p_34319, eta_p_34321);\n                                                int64_t defunc_0_op_res_34324 = add64(eta_p_34320, eta_p_34322);\n                                                \n                                                eta_p_34319 = lifted_lambda_res_34323;\n                                                eta_p_34320 = defunc_0_op_res_34324;\n                                            }\n                                        }\n                                   ", "     // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)] = flg_x_34325;\n                                            flg_y_34326 = flg_x_34325;\n                                            ((volatile __local int64_t *) local_mem_34247)[(int64_t) 4 + sext_i32_i64(local_tid_34238)] = eta_p_34319;\n                                            eta_p_34321 = eta_p_34319;\n                                            ((volatile __local int64_t *) local_mem_34247)[squot64(warp_byte_offset_34245, (int64_t) 8) + sext_i32_i64(local_tid_34238)] = eta_p_34320;\n                                            eta_p_34322 = eta_p_34320;\n                                        }\n                                    }\n                                    skip_threads_34327 *= 2;\n                                }\n                            }\n                        }\n                        flag_34318 = ((__local int8_t *) local_mem_34247)[sext_i32_i64(wave_sizze_34240) - (int64_t) 1];\n                        aggr_34316 = ((__local int64_t *) local_mem_34247)[(int64_t) 4 + (sext_i32_i64(wave_sizze_34240) - (int64_t) 1)];\n                        aggr_34317 = ((__local int64_t *) local_mem_34247)[squot64(warp_byte_offset_34245, (int64_t) 8) + (sext_i32_i64(wave_sizze_34240) - (int64_t) 1)];\n                        if (flag_34318 == (int8_t) 2) {\n                            readOffset_34314 = wave_sizze_34240 * -1;\n                        } else if (flag_34318 == (int8_t) 1) {\n                            readOffset_34314 -= wave_sizze_34240;\n                        }\n                        if (slt8((int8_t) 0, flag_34318)) {\n                            int64_t eta_p_34328 = aggr_34316;\n                            int64_t eta_p_34329 = aggr_34317;\n                            int64_t eta_p_34330 = prefix_34309;\n                            int64_t eta_p_34331 = prefix_34310;",
                                    "\n                            int64_t lifted_lambda_res_34332 = add64(eta_p_34328, eta_p_34330);\n                            int64_t defunc_0_op_res_34333 = add64(eta_p_34329, eta_p_34331);\n                            \n                            prefix_34309 = lifted_lambda_res_34332;\n                            prefix_34310 = defunc_0_op_res_34333;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_34238 == 0) {\n                    if (boundary_34263 == sext_i64_i32(segscan_tblock_sizze_33735 * chunk_sizze_34222)) {\n                        int64_t eta_p_34334 = prefix_34309;\n                        int64_t eta_p_34335 = prefix_34310;\n                        int64_t eta_p_34336 = acc_34295;\n                        int64_t eta_p_34337 = acc_34296;\n                        int64_t lifted_lambda_res_34338 = add64(eta_p_34334, eta_p_34336);\n                        int64_t defunc_0_op_res_34339 = add64(eta_p_34335, eta_p_34337);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_34229)[dynamic_id_34260] = lifted_lambda_res_34338;\n                        ((volatile __global int64_t *) incprefixes_mem_34233)[dynamic_id_34260] = defunc_0_op_res_34339;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_34225)[dynamic_id_34260] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_34247)[(int64_t) 4] = prefix_34309;\n                    ((__local int64_t *) local_mem_34247)[squot64(warp_byte_offset_34245, (int64_t) 8)] = prefix_34310;\n                    acc_34295 = (int64_t) 0;\n                    acc_34296 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_34260 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_34309 = ((__local int64_t *) local_mem_34247)[(int64_t) 4];\n                pr", "efix_34310 = ((__local int64_t *) local_mem_34247)[squot64(warp_byte_offset_34245, (int64_t) 8)];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_34340;\n            int64_t eta_p_34342;\n            int64_t eta_p_34346 = prefix_34309;\n            int64_t eta_p_34348 = acc_34295;\n            int64_t eta_p_34341;\n            int64_t eta_p_34343;\n            int64_t eta_p_34347 = prefix_34310;\n            int64_t eta_p_34349 = acc_34296;\n            \n            if (slt32(local_tid_34238 * chunk_sizze_32b_34242, boundary_34263) && !block_new_sgm_34311) {\n                int64_t lifted_lambda_res_34350 = add64(eta_p_34346, eta_p_34348);\n                int64_t defunc_0_op_res_34351 = add64(eta_p_34347, eta_p_34349);\n                \n                eta_p_34340 = lifted_lambda_res_34350;\n                eta_p_34341 = defunc_0_op_res_34351;\n            } else {\n                eta_p_34340 = acc_34295;\n                eta_p_34341 = acc_34296;\n            }\n            \n            int32_t stopping_point_34352 = segsizze_compact_34264 - srem32(local_tid_34238 * chunk_sizze_32b_34242 - 1 + segsizze_compact_34264 - boundary_34263, segsizze_compact_34264);\n            \n            for (int64_t i_34353 = 0; i_34353 < chunk_sizze_34222; i_34353++) {\n                if (slt32(sext_i64_i32(i_34353), stopping_point_34352 - 1)) {\n                    eta_p_34342 = private_mem_34265[i_34353];\n                    eta_p_34343 = private_mem_34267[i_34353];\n                    \n                    int64_t lifted_lambda_res_34344 = add64(eta_p_34340, eta_p_34342);\n                    int64_t defunc_0_op_res_34345 = add64(eta_p_34341, eta_p_34343);\n                    \n                    private_mem_34265[i_34353] = lifted_lambda_res_34344;\n                    private_mem_34267[i_34353] = defunc_0_op_res_34345;\n                }\n            }\n        }\n        // Transpose scan output and Write it to glo", "bal memory in coalesced fashion\n        {\n            for (int64_t i_34354 = 0; i_34354 < chunk_sizze_34222; i_34354++) {\n                int64_t sharedIdx_34355 = sext_i32_i64(local_tid_34238) * chunk_sizze_34222 + i_34354;\n                int64_t tmp_34356 = private_mem_34265[i_34354];\n                \n                ((__local int64_t *) local_mem_34247)[sharedIdx_34355] = tmp_34356;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34357 = 0; i_34357 < chunk_sizze_34222; i_34357++) {\n                int64_t flat_idx_34358 = thd_offset_34269 + i_34357 * segscan_tblock_sizze_33735;\n                int64_t slice_34359 = m_32498;\n                int64_t gtid_33739 = flat_idx_34358;\n                int64_t remnant_34360 = flat_idx_34358 - gtid_33739;\n                \n                if (slt64(flat_idx_34358, m_32498)) {\n                    int64_t tmp_34361 = ((__local int64_t *) local_mem_34247)[flat_idx_34358 - block_offset_34261];\n                    \n                    ((__global int64_t *) mem_33848)[gtid_33739] = tmp_34361;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34362 = 0; i_34362 < chunk_sizze_34222; i_34362++) {\n                int64_t sharedIdx_34363 = sext_i32_i64(local_tid_34238) * chunk_sizze_34222 + i_34362;\n                int64_t tmp_34364 = private_mem_34267[i_34362];\n                \n                ((__local int64_t *) local_mem_34247)[sharedIdx_34363] = tmp_34364;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34365 = 0; i_34365 < chunk_sizze_34222; i_34365++) {\n                int64_t flat_idx_34366 = thd_offset_34269 + i_34365 * segscan_tblock_sizze_33735;\n                int64_t slice_34367 = m_32498;\n                int64_t gtid_33739 = flat_idx_34366;\n                int64_t remnant_34368 = flat_idx_34366 - gtid_33739;\n                \n                if (slt64(flat_idx_34366, m_32498)) {\n                    int64",
                                    "_t tmp_34369 = ((__local int64_t *) local_mem_34247)[flat_idx_34366 - block_offset_34261];\n                    \n                    ((__global int64_t *) mem_33850)[gtid_33739] = tmp_34369;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_33735\n    #undef chunk_sizze_34222\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_floatzigpuseq_34379_dim1, 1, 1)\nvoid inner_SMJ_floatzigpuseq_34379(__global int *global_failure, int64_t m_32502, __global unsigned char *mem_33855, __global unsigned char *mem_33857)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34381;\n    int32_t tblock_sizze_34384;\n    int32_t wave_sizze_34383;\n    int32_t block_id_34382;\n    int32_t global_tid_34380;\n    int64_t tid_34379;\n    int64_t x_33807;\n    \n    local_tid_34381 = get_local_id(0);\n    tblock_sizze_34384 = get_local_size(0);\n    wave_sizze_34383 = LOCKSTEP_WIDTH;\n    block_id_34382 = get_tblock_id(0);\n    global_tid_34380 = block_id_34382 * tblock_sizze_34384 + local_tid_34381;\n    tid_34379 = sext_i32_i64(global_tid_34380);\n    x_33807 = ((__global int64_t *) mem_33855)[m_32502];\n    ((__global int64_t *) mem_33857)[(int64_t) 0] = x_33807;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_floatzigpuseq_34385_dim1, 1, 1)\nvoid inner_SMJ_floatzigpuseq_34385(__global int *global_failure, int64_t m_32502, __global unsigned char *mem_33844, __global unsigned char *mem_33860)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34387;\n    int32_t tblock_sizze_34390;\n    int32_t wave_sizze_34389;\n    int32_t block_id_34388;\n    int32_t global_tid_34386;\n    int64_t tid_34385;\n    int64_t x_33811;\n    \n    local_tid_34387 = get_local_id(0);\n    tblock_sizze_34390 = get_local_size(0);\n    wave_sizze_34389 = LOCKSTEP_WIDTH;\n    block_id_34388 = get_tblock_id(0);\n    global_tid_34386 = block_id_34388 * tblock_sizze_34390 + local_tid_34387;\n    tid_34385 = s", "ext_i32_i64(global_tid_34386);\n    x_33811 = ((__global int64_t *) mem_33844)[m_32502];\n    ((__global int64_t *) mem_33860)[(int64_t) 0] = x_33811;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_floatzigpuseq_34391_dim1, 1, 1)\nvoid inner_SMJ_floatzigpuseq_34391(__global int *global_failure, __global unsigned char *ext_mem_33858, __global unsigned char *ext_mem_33861, __global unsigned char *mem_33867)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34393;\n    int32_t tblock_sizze_34396;\n    int32_t wave_sizze_34395;\n    int32_t block_id_34394;\n    int32_t global_tid_34392;\n    int64_t tid_34391;\n    int64_t zp_lhs_33815;\n    int64_t n_pairs_t_res_33816;\n    int64_t n_pairs_t_res_33817;\n    \n    local_tid_34393 = get_local_id(0);\n    tblock_sizze_34396 = get_local_size(0);\n    wave_sizze_34395 = LOCKSTEP_WIDTH;\n    block_id_34394 = get_tblock_id(0);\n    global_tid_34392 = block_id_34394 * tblock_sizze_34396 + local_tid_34393;\n    tid_34391 = sext_i32_i64(global_tid_34392);\n    zp_lhs_33815 = ((__global int64_t *) ext_mem_33858)[(int64_t) 0];\n    n_pairs_t_res_33816 = ((__global int64_t *) ext_mem_33861)[(int64_t) 0];\n    n_pairs_t_res_33817 = add64(zp_lhs_33815, n_pairs_t_res_33816);\n    ((__global int64_t *) mem_33867)[(int64_t) 0] = n_pairs_t_res_33817;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_floatzigpuseq_34458_dim1, 1, 1)\nvoid inner_SMJ_floatzigpuseq_34458(__global int *global_failure, int64_t loopres_32670, __global unsigned char *mem_param_33901, __global unsigned char *mem_param_33904, __global unsigned char *mem_param_33907, __global unsigned char *mem_33914, __global unsigned char *mem_33915, __global unsigned char *mem_33916)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34460;\n    int32_t tblock_sizze_34463;\n    int32_t wave_sizze_34462;\n    int32_t block_id_34461;\n    int32_t global_tid_34459;\n    int64_t tid_34458;\n    float loopres_33819;\n    int64_t loopres_3382", "1;\n    int64_t loopres_33823;\n    \n    local_tid_34460 = get_local_id(0);\n    tblock_sizze_34463 = get_local_size(0);\n    wave_sizze_34462 = LOCKSTEP_WIDTH;\n    block_id_34461 = get_tblock_id(0);\n    global_tid_34459 = block_id_34461 * tblock_sizze_34463 + local_tid_34460;\n    tid_34458 = sext_i32_i64(global_tid_34459);\n    loopres_33819 = ((__global float *) mem_param_33901)[loopres_32670];\n    loopres_33821 = ((__global int64_t *) mem_param_33904)[loopres_32670];\n    loopres_33823 = ((__global int64_t *) mem_param_33907)[loopres_32670];\n    ((__global float *) mem_33914)[(int64_t) 0] = loopres_33819;\n    ((__global int64_t *) mem_33915)[(int64_t) 0] = loopres_33821;\n    ((__global int64_t *) mem_33916)[(int64_t) 0] = loopres_33823;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL\nvoid inner_SMJ_floatzireplicate_34465(int64_t loopres_32671, int64_t replicate_n_34464, int64_t virt_num_tblocks_34470, int64_t num_tblocks_34471, __global unsigned char *mem_33914, __global unsigned char *mem_33918)\n{\n    int32_t replicate_ltid_34466;\n    int32_t tblock_sizze_34468;\n    int32_t replicate_gid_34467;\n    int32_t replicate_gtid_34465;\n    int32_t phys_tblock_id_34472;\n    int32_t iterations_34473;\n    \n    replicate_ltid_34466 = get_local_id(0);\n    tblock_sizze_34468 = get_local_size(0);\n    replicate_gid_34467 = get_tblock_id(0);\n    replicate_gtid_34465 = replicate_gid_34467 * tblock_sizze_34468 + replicate_ltid_34466;\n    phys_tblock_id_34472 = get_tblock_id(0);\n    iterations_34473 = sdiv_up32(sext_i64_i32(virt_num_tblocks_34470) - phys_tblock_id_34472, sext_i64_i32(num_tblocks_34471));\n    for (int32_t i_34474 = 0; i_34474 < iterations_34473; i_34474++) {\n        int32_t virt_tblock_id_34475;\n        int64_t global_tid_34476;\n        int64_t slice_34479;\n        int64_t slice_34480;\n        int64_t rep_i_34477;\n        int64_t remnant_34481;\n        int64_t rep_i_34478;\n        int64_t remnant_34482;\n        \n        virt_tblock_id_34475 = phys_tblock_id_34472 + i_34474 *",
                                    " sext_i64_i32(num_tblocks_34471);\n        global_tid_34476 = sext_i32_i64(virt_tblock_id_34475) * sext_i32_i64(tblock_sizze_34468) + sext_i32_i64(replicate_ltid_34466);\n        slice_34479 = (int64_t) 1;\n        slice_34480 = loopres_32671 * slice_34479;\n        rep_i_34477 = squot64(global_tid_34476, slice_34479);\n        remnant_34481 = global_tid_34476 - rep_i_34477 * slice_34479;\n        rep_i_34478 = remnant_34481;\n        remnant_34482 = remnant_34481 - rep_i_34478;\n        if (slt64(global_tid_34476, replicate_n_34464)) {\n            float tmp_34483 = ((__global float *) mem_33914)[rep_i_34478];\n            \n            ((__global float *) mem_33918)[rep_i_34477 + rep_i_34478] = tmp_34483;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid inner_SMJ_floatzireplicate_34485(int64_t loopres_32671, int64_t replicate_n_34484, int64_t virt_num_tblocks_34490, int64_t num_tblocks_34491, __global unsigned char *mem_33915, __global unsigned char *mem_33920)\n{\n    int32_t replicate_ltid_34486;\n    int32_t tblock_sizze_34488;\n    int32_t replicate_gid_34487;\n    int32_t replicate_gtid_34485;\n    int32_t phys_tblock_id_34492;\n    int32_t iterations_34493;\n    \n    replicate_ltid_34486 = get_local_id(0);\n    tblock_sizze_34488 = get_local_size(0);\n    replicate_gid_34487 = get_tblock_id(0);\n    replicate_gtid_34485 = replicate_gid_34487 * tblock_sizze_34488 + replicate_ltid_34486;\n    phys_tblock_id_34492 = get_tblock_id(0);\n    iterations_34493 = sdiv_up32(sext_i64_i32(virt_num_tblocks_34490) - phys_tblock_id_34492, sext_i64_i32(num_tblocks_34491));\n    for (int32_t i_34494 = 0; i_34494 < iterations_34493; i_34494++) {\n        int32_t virt_tblock_id_34495;\n        int64_t global_tid_34496;\n        int64_t slice_34499;\n        int64_t slice_34500;\n        int64_t rep_i_34497;\n        int64_t remnant_34501;\n        int64_t rep_i_34498;\n        int64_t remnant_34502;\n        \n        virt_tblock_id_3", "4495 = phys_tblock_id_34492 + i_34494 * sext_i64_i32(num_tblocks_34491);\n        global_tid_34496 = sext_i32_i64(virt_tblock_id_34495) * sext_i32_i64(tblock_sizze_34488) + sext_i32_i64(replicate_ltid_34486);\n        slice_34499 = (int64_t) 1;\n        slice_34500 = loopres_32671 * slice_34499;\n        rep_i_34497 = squot64(global_tid_34496, slice_34499);\n        remnant_34501 = global_tid_34496 - rep_i_34497 * slice_34499;\n        rep_i_34498 = remnant_34501;\n        remnant_34502 = remnant_34501 - rep_i_34498;\n        if (slt64(global_tid_34496, replicate_n_34484)) {\n            int64_t tmp_34503 = ((__global int64_t *) mem_33915)[rep_i_34498];\n            \n            ((__global int64_t *) mem_33920)[rep_i_34497 + rep_i_34498] = tmp_34503;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_floatzisegmap_33642_dim1, 1, 1)\nvoid inner_SMJ_floatzisegmap_33642(__global int *global_failure, int64_t nR_26587, int64_t offset_R_26591, int64_t m_32498, int64_t num_tblocks_33647, int32_t virt_num_tblocks_34204, __global unsigned char *tR_mem_33832, __global unsigned char *mem_33838, __global unsigned char *mem_33840, __global unsigned char *mem_33842, __global unsigned char *mem_33844)\n{\n    #define segmap_tblock_sizze_33645 (inner_SMJ_floatzisegmap_33642zisegmap_tblock_sizze_33645)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34206;\n    int32_t tblock_sizze_34209;\n    int32_t wave_sizze_34208;\n    int32_t block_id_34207;\n    int32_t global_tid_34205;\n    int64_t phys_tid_33642;\n    int32_t phys_tblock_id_34210;\n    int32_t iterations_34211;\n    \n    local_tid_34206 = get_local_id(0);\n    tblock_sizze_34209 = get_local_size(0);\n    wave_sizze_34208 = LOCKSTEP_WIDTH;\n    block_id_34207 = get_tblock_id(0);\n    global_tid_34205 = block_id_34207 * tblock_sizze_34209 + local_tid_34206;\n    phys_tid_33642 = sext_i32_i64(global_tid_34205);\n    phys_tblock_id_34210 = get", "_tblock_id(0);\n    iterations_34211 = sdiv_up32(virt_num_tblocks_34204 - phys_tblock_id_34210, sext_i64_i32(num_tblocks_33647));\n    for (int32_t i_34212 = 0; i_34212 < iterations_34211; i_34212++) {\n        int32_t virt_tblock_id_34213;\n        int64_t global_tid_34214;\n        int64_t slice_34215;\n        int64_t write_i_33641;\n        int64_t remnant_34216;\n        \n        virt_tblock_id_34213 = phys_tblock_id_34210 + i_34212 * sext_i64_i32(num_tblocks_33647);\n        global_tid_34214 = sext_i32_i64(virt_tblock_id_34213) * segmap_tblock_sizze_33645 + sext_i32_i64(local_tid_34206);\n        slice_34215 = nR_26587;\n        write_i_33641 = global_tid_34214;\n        remnant_34216 = global_tid_34214 - write_i_33641;\n        if (slt64(write_i_33641, nR_26587)) {\n            float write_value_32519;\n            int64_t index_primexp_33806;\n            \n            write_value_32519 = ((__global float *) tR_mem_33832)[write_i_33641];\n            index_primexp_33806 = add64(offset_R_26591, write_i_33641);\n            if (sle64((int64_t) 0, (int64_t) -1) && slt64((int64_t) -1, m_32498)) {\n                ((__global float *) mem_33838)[(int64_t) -1] = write_value_32519;\n            }\n            if (sle64((int64_t) 0, (int64_t) -1) && slt64((int64_t) -1, m_32498)) {\n                ((__global int64_t *) mem_33840)[(int64_t) -1] = index_primexp_33806;\n            }\n            if (sle64((int64_t) 0, (int64_t) -1) && slt64((int64_t) -1, m_32498)) {\n                ((__global int64_t *) mem_33842)[(int64_t) -1] = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, (int64_t) -1) && slt64((int64_t) -1, m_32498)) {\n                ((__global int64_t *) mem_33844)[(int64_t) -1] = (int64_t) 0;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_33645\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_floatzisegmap_33676_dim1, 1, 1)\nvoid inner_SMJ_floatzisegmap_33676(__global int *global_failu",
                                    "re, int64_t m_32498, __global unsigned char *mem_33848, __global unsigned char *mem_33855)\n{\n    #define segmap_tblock_sizze_33672 (inner_SMJ_floatzisegmap_33676zisegmap_tblock_sizze_33672)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34372;\n    int32_t tblock_sizze_34375;\n    int32_t wave_sizze_34374;\n    int32_t block_id_34373;\n    int32_t global_tid_34371;\n    int64_t phys_tid_33676;\n    int64_t global_tid_34376;\n    int64_t slice_34377;\n    int64_t gtid_33675;\n    int64_t remnant_34378;\n    \n    local_tid_34372 = get_local_id(0);\n    tblock_sizze_34375 = get_local_size(0);\n    wave_sizze_34374 = LOCKSTEP_WIDTH;\n    block_id_34373 = get_tblock_id(0);\n    global_tid_34371 = block_id_34373 * tblock_sizze_34375 + local_tid_34372;\n    phys_tid_33676 = sext_i32_i64(global_tid_34371);\n    global_tid_34376 = sext_i32_i64(block_id_34373) * segmap_tblock_sizze_33672 + sext_i32_i64(local_tid_34372);\n    slice_34377 = m_32498;\n    gtid_33675 = global_tid_34376;\n    remnant_34378 = global_tid_34376 - gtid_33675;\n    if (slt64(gtid_33675, m_32498)) {\n        int64_t zv_lhs_33678;\n        int64_t tmp_33679;\n        bool cond_33681;\n        int64_t lifted_lambda_res_33682;\n        \n        zv_lhs_33678 = add64((int64_t) -1, gtid_33675);\n        tmp_33679 = smod64(zv_lhs_33678, m_32498);\n        cond_33681 = gtid_33675 == (int64_t) 0;\n        if (cond_33681) {\n            lifted_lambda_res_33682 = (int64_t) 0;\n        } else {\n            int64_t lifted_lambda_res_33680 = ((__global int64_t *) mem_33848)[tmp_33679];\n            \n            lifted_lambda_res_33682 = lifted_lambda_res_33680;\n        }\n        ((__global int64_t *) mem_33855)[gtid_33675] = lifted_lambda_res_33682;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_33672\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_floatzisegmap_33684_dim1, 1, 1)\nvoid inner_SMJ_floatzisegmap_33684(__global int *global_failure, int64_t m_32498, int64_t lower_bound_32569, int64_t min_res_32571, int64_t j", "_m_i_32572, int64_t num_tblocks_33689, int32_t virt_num_tblocks_34437, __global unsigned char *mem_33838, __global unsigned char *mem_33840, __global unsigned char *mem_33842, __global unsigned char *mem_33855, __global unsigned char *mem_33884, __global unsigned char *mem_33886, __global unsigned char *mem_33888)\n{\n    #define segmap_tblock_sizze_33687 (inner_SMJ_floatzisegmap_33684zisegmap_tblock_sizze_33687)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34439;\n    int32_t tblock_sizze_34442;\n    int32_t wave_sizze_34441;\n    int32_t block_id_34440;\n    int32_t global_tid_34438;\n    int64_t phys_tid_33684;\n    int32_t phys_tblock_id_34443;\n    int32_t iterations_34444;\n    \n    local_tid_34439 = get_local_id(0);\n    tblock_sizze_34442 = get_local_size(0);\n    wave_sizze_34441 = LOCKSTEP_WIDTH;\n    block_id_34440 = get_tblock_id(0);\n    global_tid_34438 = block_id_34440 * tblock_sizze_34442 + local_tid_34439;\n    phys_tid_33684 = sext_i32_i64(global_tid_34438);\n    phys_tblock_id_34443 = get_tblock_id(0);\n    iterations_34444 = sdiv_up32(virt_num_tblocks_34437 - phys_tblock_id_34443, sext_i64_i32(num_tblocks_33689));\n    for (int32_t i_34445 = 0; i_34445 < iterations_34444; i_34445++) {\n        int32_t virt_tblock_id_34446;\n        int64_t global_tid_34447;\n        int64_t slice_34448;\n        int64_t write_i_33683;\n        int64_t remnant_34449;\n        \n        virt_tblock_id_34446 = phys_tblock_id_34443 + i_34445 * sext_i64_i32(num_tblocks_33689);\n        global_tid_34447 = sext_i32_i64(virt_tblock_id_34446) * segmap_tblock_sizze_33687 + sext_i32_i64(local_tid_34439);\n        slice_34448 = m_32498;\n        write_i_33683 = global_tid_34447;\n        remnant_34449 = global_tid_34447 - write_i_33683;\n        if (slt64(write_i_33683, m_32498)) {\n            int64_t eta_p_32753;\n            float write_value_32754;\n            int64_t write_value_32755;\n            int64_t write_value_32756;\n            bool cond_32757;\n            bool cond", "_t_res_32758;\n            bool x_32759;\n            int64_t lifted_lambda_res_32760;\n            \n            eta_p_32753 = ((__global int64_t *) mem_33855)[write_i_33683];\n            write_value_32754 = ((__global float *) mem_33838)[write_i_33683];\n            write_value_32755 = ((__global int64_t *) mem_33840)[write_i_33683];\n            write_value_32756 = ((__global int64_t *) mem_33842)[write_i_33683];\n            cond_32757 = sle64(lower_bound_32569, eta_p_32753);\n            cond_t_res_32758 = slt64(eta_p_32753, min_res_32571);\n            x_32759 = cond_32757 && cond_t_res_32758;\n            if (x_32759) {\n                int64_t lifted_lambda_res_t_res_32784 = sub64(eta_p_32753, lower_bound_32569);\n                \n                lifted_lambda_res_32760 = lifted_lambda_res_t_res_32784;\n            } else {\n                lifted_lambda_res_32760 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_32760) && slt64(lifted_lambda_res_32760, j_m_i_32572)) {\n                ((__global float *) mem_33884)[lifted_lambda_res_32760] = write_value_32754;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_32760) && slt64(lifted_lambda_res_32760, j_m_i_32572)) {\n                ((__global int64_t *) mem_33886)[lifted_lambda_res_32760] = write_value_32755;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_32760) && slt64(lifted_lambda_res_32760, j_m_i_32572)) {\n                ((__global int64_t *) mem_33888)[lifted_lambda_res_32760] = write_value_32756;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_33687\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_floatzisegmap_33692_dim1, 1, 1)\nvoid inner_SMJ_floatzisegmap_33692(__global int *global_failure, int64_t m_32498, int64_t m_32626, int64_t num_tblocks_33697, int32_t virt_num_tblocks_34399, __global unsigned char *mem_33844, __global unsigned char *mem_33850, __global ",
                                    "unsigned char *mem_33852, __global unsigned char *mem_33855, __global unsigned char *mem_33863, __global unsigned char *mem_33865)\n{\n    #define segmap_tblock_sizze_33695 (inner_SMJ_floatzisegmap_33692zisegmap_tblock_sizze_33695)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34401;\n    int32_t tblock_sizze_34404;\n    int32_t wave_sizze_34403;\n    int32_t block_id_34402;\n    int32_t global_tid_34400;\n    int64_t phys_tid_33692;\n    int32_t phys_tblock_id_34405;\n    int32_t iterations_34406;\n    \n    local_tid_34401 = get_local_id(0);\n    tblock_sizze_34404 = get_local_size(0);\n    wave_sizze_34403 = LOCKSTEP_WIDTH;\n    block_id_34402 = get_tblock_id(0);\n    global_tid_34400 = block_id_34402 * tblock_sizze_34404 + local_tid_34401;\n    phys_tid_33692 = sext_i32_i64(global_tid_34400);\n    phys_tblock_id_34405 = get_tblock_id(0);\n    iterations_34406 = sdiv_up32(virt_num_tblocks_34399 - phys_tblock_id_34405, sext_i64_i32(num_tblocks_33697));\n    for (int32_t i_34407 = 0; i_34407 < iterations_34406; i_34407++) {\n        int32_t virt_tblock_id_34408;\n        int64_t global_tid_34409;\n        int64_t slice_34410;\n        int64_t write_i_33691;\n        int64_t remnant_34411;\n        \n        virt_tblock_id_34408 = phys_tblock_id_34405 + i_34407 * sext_i64_i32(num_tblocks_33697);\n        global_tid_34409 = sext_i32_i64(virt_tblock_id_34408) * segmap_tblock_sizze_33695 + sext_i32_i64(local_tid_34401);\n        slice_34410 = m_32498;\n        write_i_33691 = global_tid_34409;\n        remnant_34411 = global_tid_34409 - write_i_33691;\n        if (slt64(write_i_33691, m_32498)) {\n            int64_t eta_p_32710;\n            int64_t write_value_32712;\n            int64_t write_value_32713;\n            bool cond_32714;\n            int64_t lifted_lambda_res_32715;\n            \n            eta_p_32710 = ((__global int64_t *) mem_33852)[write_i_33691];\n            write_value_32712 = ((__global int64_t *) mem_33855)[write_i_33691];\n            write_value_32713", " = ((__global int64_t *) mem_33844)[write_i_33691];\n            cond_32714 = eta_p_32710 == (int64_t) 1;\n            if (cond_32714) {\n                int64_t eta_p_32711;\n                int64_t lifted_lambda_res_t_res_32789;\n                \n                eta_p_32711 = ((__global int64_t *) mem_33850)[write_i_33691];\n                lifted_lambda_res_t_res_32789 = sub64(eta_p_32711, (int64_t) 1);\n                lifted_lambda_res_32715 = lifted_lambda_res_t_res_32789;\n            } else {\n                lifted_lambda_res_32715 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_32715) && slt64(lifted_lambda_res_32715, m_32626)) {\n                ((__global int64_t *) mem_33865)[lifted_lambda_res_32715] = write_value_32712;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_32715) && slt64(lifted_lambda_res_32715, m_32626)) {\n                ((__global int64_t *) mem_33863)[lifted_lambda_res_32715] = write_value_32713;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_33695\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_floatzisegmap_33714_dim1, 1, 1)\nvoid inner_SMJ_floatzisegmap_33714(__global int *global_failure, int64_t loopres_32670, int64_t loopres_32671, __global unsigned char *mem_33913, __global unsigned char *mem_33916)\n{\n    #define segmap_tblock_sizze_33710 (inner_SMJ_floatzisegmap_33714zisegmap_tblock_sizze_33710)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34506;\n    int32_t tblock_sizze_34509;\n    int32_t wave_sizze_34508;\n    int32_t block_id_34507;\n    int32_t global_tid_34505;\n    int64_t phys_tid_33714;\n    int64_t global_tid_34510;\n    int64_t slice_34511;\n    int64_t gtid_33713;\n    int64_t remnant_34512;\n    \n    local_tid_34506 = get_local_id(0);\n    tblock_sizze_34509 = get_local_size(0);\n    wave_sizze_34508 = LOCKSTEP_WIDTH;\n    block_id_34507 = get_tblock_id(0);\n    global_tid_", "34505 = block_id_34507 * tblock_sizze_34509 + local_tid_34506;\n    phys_tid_33714 = sext_i32_i64(global_tid_34505);\n    global_tid_34510 = sext_i32_i64(block_id_34507) * segmap_tblock_sizze_33710 + sext_i32_i64(local_tid_34506);\n    slice_34511 = loopres_32671;\n    gtid_33713 = global_tid_34510;\n    remnant_34512 = global_tid_34510 - gtid_33713;\n    if (slt64(gtid_33713, loopres_32671)) {\n        int64_t loopres_33827;\n        int64_t tmp_33716;\n        \n        loopres_33827 = ((__global int64_t *) mem_33916)[(int64_t) 0];\n        tmp_33716 = add64(gtid_33713, loopres_33827);\n        ((__global int64_t *) mem_33913)[loopres_32670 + gtid_33713] = tmp_33716;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_33710\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_floatzisegscan_33640_dim1, 1, 1)\nvoid inner_SMJ_floatzisegscan_33640(__global int *global_failure, int64_t nR_26587, int64_t num_tblocks_33637, int64_t num_virt_blocks_34029, int64_t num_virt_threads_34030, __global unsigned char *mem_33836, __global unsigned char *status_flags_mem_34031, __global unsigned char *aggregates_mem_34053, __global unsigned char *incprefixes_mem_34055, __global unsigned char *global_dynid_mem_34057)\n{\n    #define segscan_tblock_sizze_33635 (inner_SMJ_floatzisegscan_33640zisegscan_tblock_sizze_33635)\n    #define chunk_sizze_34028 (inner_SMJ_floatzisegscan_33640zichunk_sizze_34028)\n    \n    volatile __local unsigned char *local_mem_34087_backing_0 = &shared_mem[0];\n    const int64_t local_mem_34087_backing_0_offset = 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_33635), chunk_sizze_34028 * segscan_tblock_sizze_33635 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_33635), chunk_sizze_34028 * segscan_tblock_sizze_33635 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34080;\n    int32_t tblock_sizze_34083;\n    int32_t wave_sizze_3408",
                                    "2;\n    int32_t block_id_34081;\n    int32_t global_tid_34079;\n    int64_t phys_tid_33640;\n    int32_t chunk_sizze_32b_34084;\n    int64_t byte_offsets_34085;\n    int64_t warp_byte_offset_34086;\n    __local unsigned char *local_mem_34087;\n    int64_t trans_arr_len_34088;\n    int64_t phys_block_id_34094;\n    int64_t virtloop_bound_34095;\n    \n    local_tid_34080 = get_local_id(0);\n    tblock_sizze_34083 = get_local_size(0);\n    wave_sizze_34082 = LOCKSTEP_WIDTH;\n    block_id_34081 = get_tblock_id(0);\n    global_tid_34079 = block_id_34081 * tblock_sizze_34083 + local_tid_34080;\n    phys_tid_33640 = sext_i32_i64(global_tid_34079);\n    chunk_sizze_32b_34084 = sext_i64_i32(chunk_sizze_34028);\n    byte_offsets_34085 = segscan_tblock_sizze_33635 * (int64_t) 8;\n    warp_byte_offset_34086 = (int64_t) 288;\n    // Allocate reusable shared memory\n    { }\n    local_mem_34087 = (__local unsigned char *) local_mem_34087_backing_0;\n    trans_arr_len_34088 = chunk_sizze_34028 * segscan_tblock_sizze_33635;\n    phys_block_id_34094 = get_tblock_id(0);\n    virtloop_bound_34095 = sdiv_up64(num_virt_blocks_34029 - phys_block_id_34094, num_tblocks_33637);\n    for (int64_t virtloop_i_34096 = 0; virtloop_i_34096 < virtloop_bound_34095; virtloop_i_34096++) {\n        int64_t dynamic_id_34097;\n        int64_t block_offset_34098;\n        int64_t sgm_idx_34099;\n        int32_t boundary_34100;\n        int32_t segsizze_compact_34101;\n        int64_t private_mem_34102[chunk_sizze_34028];\n        int64_t thd_offset_34104;\n        int64_t acc_34120;\n        int64_t prefix_34130;\n        bool block_new_sgm_34131;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_34080 == 0) {\n                dynamic_id_34097 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_34057)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_34087)[(int64_t) 0] = dy", "namic_id_34097;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_34097 == num_virt_blocks_34029 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_34057)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_34097 = ((__local int32_t *) local_mem_34087)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_34098 = dynamic_id_34097 * chunk_sizze_34028 * segscan_tblock_sizze_33635;\n        sgm_idx_34099 = smod64(block_offset_34098, nR_26587);\n        boundary_34100 = sext_i64_i32(smin64(chunk_sizze_34028 * segscan_tblock_sizze_33635, nR_26587 - sgm_idx_34099));\n        segsizze_compact_34101 = sext_i64_i32(smin64(chunk_sizze_34028 * segscan_tblock_sizze_33635, nR_26587));\n        thd_offset_34104 = block_offset_34098 + sext_i32_i64(local_tid_34080);\n        // Load and map\n        {\n            for (int64_t i_34105 = 0; i_34105 < chunk_sizze_34028; i_34105++) {\n                int64_t virt_tid_34106 = thd_offset_34104 + i_34105 * segscan_tblock_sizze_33635;\n                int64_t slice_34107 = nR_26587;\n                int64_t gtid_33639 = virt_tid_34106;\n                int64_t remnant_34108 = virt_tid_34106 - gtid_33639;\n                \n                if (slt64(virt_tid_34106, nR_26587)) {\n                    private_mem_34102[i_34105] = (int64_t) 0;\n                } else {\n                    private_mem_34102[i_34105] = (int64_t) 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_34109 = 0; i_34109 < chunk_sizze_34028; i_34109++) {\n                int64_t sharedIdx_34110 = sext_i32_i64(local_tid_34080) + i_34109 * segscan_tblock_sizze_33635;\n                int64_t tmp_34111 = private_mem_34102[i_34109];\n                \n       ", "         ((__local int64_t *) local_mem_34087)[sharedIdx_34110] = tmp_34111;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34112 = 0; i_34112 < chunk_sizze_34028; i_34112++) {\n                int64_t sharedIdx_34113 = sext_i32_i64(local_tid_34080) * chunk_sizze_34028 + i_34112;\n                int64_t tmp_34114 = ((__local int64_t *) local_mem_34087)[sharedIdx_34113];\n                \n                private_mem_34102[i_34112] = tmp_34114;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_34115 = 0; i_34115 < chunk_sizze_34028 - (int64_t) 1; i_34115++) {\n                int64_t eta_p_32774;\n                int64_t eta_p_32775;\n                \n                eta_p_32774 = private_mem_34102[i_34115];\n                eta_p_32775 = private_mem_34102[i_34115 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_32776 = add64(eta_p_32774, eta_p_32775);\n                \n                private_mem_34102[i_34115 + (int64_t) 1] = defunc_0_op_res_32776;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_34116 = private_mem_34102[chunk_sizze_34028 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)] = tmp_34116;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_34117;\n            int64_t eta_p_34118;\n            int64_t eta_p_34121;\n            int64_t eta_p_34122;\n            bool ltid_in_bounds_34124 = slt64(sext_i32_i64(local_tid_34080), num_virt_threads_34030);\n            int32_t skip_threads_34125;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_34124) {\n                    eta_p_34118 = ((volatile __local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)];\n                    if ((local",
                                    "_tid_34080 - squot32(local_tid_34080, 32) * 32) == 0) {\n                        eta_p_34117 = eta_p_34118;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_34125 = 1;\n                while (slt32(skip_threads_34125, 32)) {\n                    bool thread_active_34126 = sle32(skip_threads_34125, local_tid_34080 - squot32(local_tid_34080, 32) * 32) && ltid_in_bounds_34124;\n                    \n                    if (thread_active_34126) {\n                        // read operands\n                        {\n                            eta_p_34117 = ((volatile __local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080) - sext_i32_i64(skip_threads_34125)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_34126) {\n                            int64_t defunc_0_op_res_34119 = add64(eta_p_34117, eta_p_34118);\n                            \n                            eta_p_34117 = defunc_0_op_res_34119;\n                        }\n                    }\n                    if (sle32(wave_sizze_34082, skip_threads_34125)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_34126) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)] = eta_p_34117;\n                            eta_p_34118 = eta_p_34117;\n                        }\n                    }\n                    if (sle32(wave_sizze_34082, skip_threads_34125)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_34125 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n        ", "    {\n                if ((local_tid_34080 - squot32(local_tid_34080, 32) * 32) == 31 && ltid_in_bounds_34124) {\n                    ((volatile __local int64_t *) local_mem_34087)[sext_i32_i64(squot32(local_tid_34080, 32))] = eta_p_34117;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_34127;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_34080, 32) == 0 && ltid_in_bounds_34124) {\n                        eta_p_34122 = ((volatile __local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)];\n                        if ((local_tid_34080 - squot32(local_tid_34080, 32) * 32) == 0) {\n                            eta_p_34121 = eta_p_34122;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_34127 = 1;\n                    while (slt32(skip_threads_34127, 32)) {\n                        bool thread_active_34128 = sle32(skip_threads_34127, local_tid_34080 - squot32(local_tid_34080, 32) * 32) && (squot32(local_tid_34080, 32) == 0 && ltid_in_bounds_34124);\n                        \n                        if (thread_active_34128) {\n                            // read operands\n                            {\n                                eta_p_34121 = ((volatile __local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080) - sext_i32_i64(skip_threads_34127)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_34128) {\n                                int64_t defunc_0_op_res_34123 = add64(eta_p_34121, eta_p_34122);\n                                \n                                eta_", "p_34121 = defunc_0_op_res_34123;\n                            }\n                        }\n                        if (sle32(wave_sizze_34082, skip_threads_34127)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_34128) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)] = eta_p_34121;\n                                eta_p_34122 = eta_p_34121;\n                            }\n                        }\n                        if (sle32(wave_sizze_34082, skip_threads_34127)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_34127 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_34129 = squot32(local_tid_34080, 32) == 0 || !ltid_in_bounds_34124;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_34129) {\n                        eta_p_34118 = eta_p_34117;\n                        eta_p_34117 = ((__local int64_t *) local_mem_34087)[sext_i32_i64(squot32(local_tid_34080, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_34129) {\n                        int64_t defunc_0_op_res_34119 = add64(eta_p_34117, eta_p_34118);\n                        \n                        eta_p_34117 = defunc_0_op_res_34119;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_34129) {\n                        ((__local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)] = eta_p_34117;\n                    }\n                }\n",
                                    "            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_34080, 32) == 0 && ltid_in_bounds_34124) {\n                    ((__local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)] = eta_p_34118;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_34080 == 0) {\n                acc_34120 = ((__local int64_t *) local_mem_34087)[segscan_tblock_sizze_33635 - (int64_t) 1];\n            } else {\n                acc_34120 = ((__local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_34130 = (int64_t) 0;\n        block_new_sgm_34131 = sgm_idx_34099 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_34131 && local_tid_34080 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_34055)[dynamic_id_34097] = acc_34120;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_34031)[dynamic_id_34097] = (int8_t) 2;\n                acc_34120 = (int64_t) 0;\n            }\n            if (!block_new_sgm_34131 && slt32(local_tid_34080, wave_sizze_34082)) {\n                if (local_tid_34080 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_34053)[dynamic_id_34097] = acc_34120;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_34031)[dynamic_id_34097] = (int8_t) 1;\n                    \n                    int8_t tmp_34132 = ((volatile __global int8_t *) status_flags_mem_34031)[dynamic_id_34097 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_34087)[(int64_t) 0] = tmp_34132;\n                }\n                mem_fence_local();\n                \n                int8_t statu", "s_34133 = ((__local int8_t *) local_mem_34087)[(int64_t) 0];\n                \n                if (status_34133 == (int8_t) 2) {\n                    if (local_tid_34080 == 0) {\n                        prefix_34130 = ((volatile __global int64_t *) incprefixes_mem_34055)[dynamic_id_34097 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_34134 = sext_i64_i32(dynamic_id_34097 - sext_i32_i64(wave_sizze_34082));\n                    \n                    while (slt32(wave_sizze_34082 * -1, readOffset_34134)) {\n                        int32_t read_i_34135 = readOffset_34134 + local_tid_34080;\n                        int64_t aggr_34136 = (int64_t) 0;\n                        int8_t flag_34137 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_34135)) {\n                            flag_34137 = ((volatile __global int8_t *) status_flags_mem_34031)[sext_i32_i64(read_i_34135)];\n                            if (flag_34137 == (int8_t) 2) {\n                                aggr_34136 = ((volatile __global int64_t *) incprefixes_mem_34055)[sext_i32_i64(read_i_34135)];\n                            } else if (flag_34137 == (int8_t) 1) {\n                                aggr_34136 = ((volatile __global int64_t *) aggregates_mem_34053)[sext_i32_i64(read_i_34135)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_34087)[(int64_t) 4 + sext_i32_i64(local_tid_34080)] = aggr_34136;\n                        ((__local int8_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)] = flag_34137;\n                        flag_34137 = ((__local int8_t *) local_mem_34087)[sext_i32_i64(wave_sizze_34082) - (int64_t) 1];\n                        if (slt8(flag_34137, (int8_t) 2)) {\n                            int8_t flg_x_34141;\n                            int8_t flg_y_34142;\n                            int64_t eta_p_34138;\n                            int64_t eta_p_34139;\n ", "                           int32_t skip_threads_34143;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_34142 = ((volatile __local int8_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)];\n                                eta_p_34139 = ((volatile __local int64_t *) local_mem_34087)[(int64_t) 4 + sext_i32_i64(local_tid_34080)];\n                                if ((local_tid_34080 - squot32(local_tid_34080, 32) * 32) == 0) {\n                                    eta_p_34138 = eta_p_34139;\n                                    flg_x_34141 = flg_y_34142;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_34143 = 1;\n                                while (slt32(skip_threads_34143, 32)) {\n                                    if (sle32(skip_threads_34143, local_tid_34080 - squot32(local_tid_34080, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_34141 = ((volatile __local int8_t *) local_mem_34087)[sext_i32_i64(local_tid_34080) - sext_i32_i64(skip_threads_34143)];\n                                            eta_p_34138 = ((volatile __local int64_t *) local_mem_34087)[(int64_t) 4 + (sext_i32_i64(local_tid_34080) - sext_i32_i64(skip_threads_34143))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_34142 == (int8_t) 2 || flg_y_34142 == (int8_t) 0) {\n                                                flg_x_34141 = flg_y_34142;\n                                                eta_p_34138 = eta_p_34139;\n                                            } else {\n       ",
                                    "                                         int64_t defunc_0_op_res_34140 = add64(eta_p_34138, eta_p_34139);\n                                                \n                                                eta_p_34138 = defunc_0_op_res_34140;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)] = flg_x_34141;\n                                            flg_y_34142 = flg_x_34141;\n                                            ((volatile __local int64_t *) local_mem_34087)[(int64_t) 4 + sext_i32_i64(local_tid_34080)] = eta_p_34138;\n                                            eta_p_34139 = eta_p_34138;\n                                        }\n                                    }\n                                    skip_threads_34143 *= 2;\n                                }\n                            }\n                        }\n                        flag_34137 = ((__local int8_t *) local_mem_34087)[sext_i32_i64(wave_sizze_34082) - (int64_t) 1];\n                        aggr_34136 = ((__local int64_t *) local_mem_34087)[(int64_t) 4 + (sext_i32_i64(wave_sizze_34082) - (int64_t) 1)];\n                        if (flag_34137 == (int8_t) 2) {\n                            readOffset_34134 = wave_sizze_34082 * -1;\n                        } else if (flag_34137 == (int8_t) 1) {\n                            readOffset_34134 -= wave_sizze_34082;\n                        }\n                        if (slt8((int8_t) 0, flag_34137)) {\n                            int64_t eta_p_34144 = aggr_34136;\n                            int64_t eta_p_34145 = prefix_34130;\n                            int64_t defunc_0_op_res_34146 = add64(eta_p_34144, eta_p_34145);\n                            \n                            prefix_34130 = defunc_0_op_res_34146;\n", "                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_34080 == 0) {\n                    if (boundary_34100 == sext_i64_i32(segscan_tblock_sizze_33635 * chunk_sizze_34028)) {\n                        int64_t eta_p_34147 = prefix_34130;\n                        int64_t eta_p_34148 = acc_34120;\n                        int64_t defunc_0_op_res_34149 = add64(eta_p_34147, eta_p_34148);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_34055)[dynamic_id_34097] = defunc_0_op_res_34149;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_34031)[dynamic_id_34097] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_34087)[(int64_t) 4] = prefix_34130;\n                    acc_34120 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_34097 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_34130 = ((__local int64_t *) local_mem_34087)[(int64_t) 4];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_34150;\n            int64_t eta_p_34151;\n            int64_t eta_p_34153 = prefix_34130;\n            int64_t eta_p_34154 = acc_34120;\n            \n            if (slt32(local_tid_34080 * chunk_sizze_32b_34084, boundary_34100) && !block_new_sgm_34131) {\n                int64_t defunc_0_op_res_34155 = add64(eta_p_34153, eta_p_34154);\n                \n                eta_p_34150 = defunc_0_op_res_34155;\n            } else {\n                eta_p_34150 = acc_34120;\n            }\n            \n            int32_t stopping_point_34156 = segsizze_compact_34101 - srem32(local_tid_34080 * chunk_sizze_32b_34084 - 1 + segsizze_compact_34101 - boundary_34100, segsizze_compact_34101);\n            \n            for (int64_t i_34157 = 0; ", "i_34157 < chunk_sizze_34028; i_34157++) {\n                if (slt32(sext_i64_i32(i_34157), stopping_point_34156 - 1)) {\n                    eta_p_34151 = private_mem_34102[i_34157];\n                    \n                    int64_t defunc_0_op_res_34152 = add64(eta_p_34150, eta_p_34151);\n                    \n                    private_mem_34102[i_34157] = defunc_0_op_res_34152;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_34158 = 0; i_34158 < chunk_sizze_34028; i_34158++) {\n                int64_t sharedIdx_34159 = sext_i32_i64(local_tid_34080) * chunk_sizze_34028 + i_34158;\n                int64_t tmp_34160 = private_mem_34102[i_34158];\n                \n                ((__local int64_t *) local_mem_34087)[sharedIdx_34159] = tmp_34160;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34161 = 0; i_34161 < chunk_sizze_34028; i_34161++) {\n                int64_t flat_idx_34162 = thd_offset_34104 + i_34161 * segscan_tblock_sizze_33635;\n                int64_t slice_34163 = nR_26587;\n                int64_t gtid_33639 = flat_idx_34162;\n                int64_t remnant_34164 = flat_idx_34162 - gtid_33639;\n                \n                if (slt64(flat_idx_34162, nR_26587)) {\n                    int64_t tmp_34165 = ((__local int64_t *) local_mem_34087)[flat_idx_34162 - block_offset_34098];\n                    \n                    ((__global int64_t *) mem_33836)[gtid_33639] = tmp_34165;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_33635\n    #undef chunk_sizze_34028\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_floatzisegscan_33656_dim1, 1, 1)\nvoid inner_SMJ_floatzisegscan_33656(__global int *global_failure, int64_t m_32498, int64_t num_tblocks_33653, int64_t num_virt_blocks_34223, int64_t num_virt_threads_34224, __global unsigned ch",
                                    "ar *mem_33844, __global unsigned char *mem_33848, __global unsigned char *mem_33850, __global unsigned char *mem_33852, __global unsigned char *status_flags_mem_34225, __global unsigned char *aggregates_mem_34227, __global unsigned char *incprefixes_mem_34229, __global unsigned char *aggregates_mem_34231, __global unsigned char *incprefixes_mem_34233, __global unsigned char *global_dynid_mem_34235)\n{\n    #define segscan_tblock_sizze_33651 (inner_SMJ_floatzisegscan_33656zisegscan_tblock_sizze_33651)\n    #define chunk_sizze_34222 (inner_SMJ_floatzisegscan_33656zichunk_sizze_34222)\n    \n    volatile __local unsigned char *local_mem_34247_backing_0 = &shared_mem[0];\n    const int64_t local_mem_34247_backing_0_offset = 0 + (smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_33651, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_33651), smax64(chunk_sizze_34222 * segscan_tblock_sizze_33651 * (int64_t) 8, chunk_sizze_34222 * segscan_tblock_sizze_33651 * (int64_t) 8)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_33651, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_33651), smax64(chunk_sizze_34222 * segscan_tblock_sizze_33651 * (int64_t) 8, chunk_sizze_34222 * segscan_tblock_sizze_33651 * (int64_t) 8)), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34238;\n    int32_t tblock_sizze_34241;\n    int32_t wave_sizze_34240;\n    int32_t block_id_34239;\n    int32_t global_tid_34237;\n    int64_t phys_tid_33656;\n    int32_t chunk_sizze_32b_34242;\n    int64_t byte_offsets_34243;\n    int64_t byte_offsets_34244;\n    int64_t warp_byte_offset_34245;\n    int64_t warp_byte_offset_34246;\n    __local unsigned char *local_mem_34247;\n    int64_t trans_arr_len_34248;\n    int64_t phys_block_id_34257;\n    int64_t virtloop_bound_34258;\n    \n    local_tid_34238 = get_local_id(0);\n    tblock_sizze_34241 = get_local_size(0);\n    w", "ave_sizze_34240 = LOCKSTEP_WIDTH;\n    block_id_34239 = get_tblock_id(0);\n    global_tid_34237 = block_id_34239 * tblock_sizze_34241 + local_tid_34238;\n    phys_tid_33656 = sext_i32_i64(global_tid_34237);\n    chunk_sizze_32b_34242 = sext_i64_i32(chunk_sizze_34222);\n    byte_offsets_34243 = segscan_tblock_sizze_33651 * (int64_t) 8;\n    byte_offsets_34244 = sdiv_up64(byte_offsets_34243, (int64_t) 8) * (int64_t) 8 + segscan_tblock_sizze_33651 * (int64_t) 8;\n    warp_byte_offset_34245 = (int64_t) 288;\n    warp_byte_offset_34246 = sdiv_up64(warp_byte_offset_34245, (int64_t) 8) * (int64_t) 8 + (int64_t) 256;\n    // Allocate reusable shared memory\n    { }\n    local_mem_34247 = (__local unsigned char *) local_mem_34247_backing_0;\n    trans_arr_len_34248 = chunk_sizze_34222 * segscan_tblock_sizze_33651;\n    phys_block_id_34257 = get_tblock_id(0);\n    virtloop_bound_34258 = sdiv_up64(num_virt_blocks_34223 - phys_block_id_34257, num_tblocks_33653);\n    for (int64_t virtloop_i_34259 = 0; virtloop_i_34259 < virtloop_bound_34258; virtloop_i_34259++) {\n        int64_t dynamic_id_34260;\n        int64_t block_offset_34261;\n        int64_t sgm_idx_34262;\n        int32_t boundary_34263;\n        int32_t segsizze_compact_34264;\n        int64_t private_mem_34265[chunk_sizze_34222];\n        int64_t private_mem_34267[chunk_sizze_34222];\n        int64_t thd_offset_34269;\n        int64_t acc_34295;\n        int64_t acc_34296;\n        int64_t prefix_34309;\n        int64_t prefix_34310;\n        bool block_new_sgm_34311;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_34238 == 0) {\n                dynamic_id_34260 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_34235)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_34247)[(int64_t) 0] = dynamic_id_34260;\n                }\n                // First thread in last (virtual) b", "lock resets global dynamic_id\n                {\n                    if (dynamic_id_34260 == num_virt_blocks_34223 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_34235)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_34260 = ((__local int32_t *) local_mem_34247)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_34261 = dynamic_id_34260 * chunk_sizze_34222 * segscan_tblock_sizze_33651;\n        sgm_idx_34262 = smod64(block_offset_34261, m_32498);\n        boundary_34263 = sext_i64_i32(smin64(chunk_sizze_34222 * segscan_tblock_sizze_33651, m_32498 - sgm_idx_34262));\n        segsizze_compact_34264 = sext_i64_i32(smin64(chunk_sizze_34222 * segscan_tblock_sizze_33651, m_32498));\n        thd_offset_34269 = block_offset_34261 + sext_i32_i64(local_tid_34238);\n        // Load and map\n        {\n            for (int64_t i_34270 = 0; i_34270 < chunk_sizze_34222; i_34270++) {\n                int64_t virt_tid_34271 = thd_offset_34269 + i_34270 * segscan_tblock_sizze_33651;\n                int64_t slice_34272 = m_32498;\n                int64_t gtid_33655 = virt_tid_34271;\n                int64_t remnant_34273 = virt_tid_34271 - gtid_33655;\n                \n                if (slt64(virt_tid_34271, m_32498)) {\n                    int64_t x_32733 = ((__global int64_t *) mem_33844)[gtid_33655];\n                    bool lifted_lambda_res_32735 = slt64((int64_t) 1, x_32733);\n                    int64_t defunc_0_f_res_32736 = btoi_bool_i64(lifted_lambda_res_32735);\n                    \n                    ((__global int64_t *) mem_33852)[gtid_33655] = defunc_0_f_res_32736;\n                    private_mem_34265[i_34270] = x_32733;\n                    private_mem_34267[i_34270] = defunc_0_f_res_32736;\n                } else {\n                    private_mem_34265[i_34270] = (int64_t) 0;\n                    private_mem_34267[i_34270] = (int64_t) 0;",
                                    "\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_34274 = 0; i_34274 < chunk_sizze_34222; i_34274++) {\n                int64_t sharedIdx_34275 = sext_i32_i64(local_tid_34238) + i_34274 * segscan_tblock_sizze_33651;\n                int64_t tmp_34276 = private_mem_34265[i_34274];\n                \n                ((__local int64_t *) local_mem_34247)[sharedIdx_34275] = tmp_34276;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34277 = 0; i_34277 < chunk_sizze_34222; i_34277++) {\n                int64_t sharedIdx_34278 = sext_i32_i64(local_tid_34238) * chunk_sizze_34222 + i_34277;\n                int64_t tmp_34279 = ((__local int64_t *) local_mem_34247)[sharedIdx_34278];\n                \n                private_mem_34265[i_34277] = tmp_34279;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34280 = 0; i_34280 < chunk_sizze_34222; i_34280++) {\n                int64_t sharedIdx_34281 = sext_i32_i64(local_tid_34238) + i_34280 * segscan_tblock_sizze_33651;\n                int64_t tmp_34282 = private_mem_34267[i_34280];\n                \n                ((__local int64_t *) local_mem_34247)[sharedIdx_34281] = tmp_34282;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34283 = 0; i_34283 < chunk_sizze_34222; i_34283++) {\n                int64_t sharedIdx_34284 = sext_i32_i64(local_tid_34238) * chunk_sizze_34222 + i_34283;\n                int64_t tmp_34285 = ((__local int64_t *) local_mem_34247)[sharedIdx_34284];\n                \n                private_mem_34267[i_34283] = tmp_34285;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_34286 = 0; i_34286 < chunk_sizze_34222 - (int64_t) 1; i_34286++) {\n                int64_t eta_p_32523;\n                int64_t eta_p_32524;\n                \n          ", "      eta_p_32523 = private_mem_34265[i_34286];\n                eta_p_32524 = private_mem_34265[i_34286 + (int64_t) 1];\n                \n                int64_t eta_p_32616;\n                int64_t eta_p_32617;\n                \n                eta_p_32616 = private_mem_34267[i_34286];\n                eta_p_32617 = private_mem_34267[i_34286 + (int64_t) 1];\n                \n                int64_t lifted_lambda_res_32525 = add64(eta_p_32523, eta_p_32524);\n                int64_t defunc_0_op_res_32618 = add64(eta_p_32616, eta_p_32617);\n                \n                private_mem_34265[i_34286 + (int64_t) 1] = lifted_lambda_res_32525;\n                private_mem_34267[i_34286 + (int64_t) 1] = defunc_0_op_res_32618;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_34287 = private_mem_34265[chunk_sizze_34222 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)] = tmp_34287;\n            \n            int64_t tmp_34288 = private_mem_34267[chunk_sizze_34222 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(local_tid_34238)] = tmp_34288;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_34289;\n            int64_t eta_p_34290;\n            int64_t eta_p_34291;\n            int64_t eta_p_34292;\n            int64_t eta_p_34297;\n            int64_t eta_p_34298;\n            int64_t eta_p_34299;\n            int64_t eta_p_34300;\n            bool ltid_in_bounds_34303 = slt64(sext_i32_i64(local_tid_34238), num_virt_threads_34224);\n            int32_t skip_threads_34304;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_34303) {\n                    eta_p_34291 = ((volatile __local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)];\n                    eta_p", "_34292 = ((volatile __local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(local_tid_34238)];\n                    if ((local_tid_34238 - squot32(local_tid_34238, 32) * 32) == 0) {\n                        eta_p_34289 = eta_p_34291;\n                        eta_p_34290 = eta_p_34292;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_34304 = 1;\n                while (slt32(skip_threads_34304, 32)) {\n                    bool thread_active_34305 = sle32(skip_threads_34304, local_tid_34238 - squot32(local_tid_34238, 32) * 32) && ltid_in_bounds_34303;\n                    \n                    if (thread_active_34305) {\n                        // read operands\n                        {\n                            eta_p_34289 = ((volatile __local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238) - sext_i32_i64(skip_threads_34304)];\n                            eta_p_34290 = ((volatile __local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + (sext_i32_i64(local_tid_34238) - sext_i32_i64(skip_threads_34304))];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_34305) {\n                            int64_t lifted_lambda_res_34293 = add64(eta_p_34289, eta_p_34291);\n                            int64_t defunc_0_op_res_34294 = add64(eta_p_34290, eta_p_34292);\n                            \n                            eta_p_34289 = lifted_lambda_res_34293;\n                            eta_p_34290 = defunc_0_op_res_34294;\n                        }\n                    }\n                    if (sle32(wave_sizze_34240, skip_threads_34304)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_34305) {\n                        // write result\n                     ",
                                    "   {\n                            ((volatile __local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)] = eta_p_34289;\n                            eta_p_34291 = eta_p_34289;\n                            ((volatile __local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(local_tid_34238)] = eta_p_34290;\n                            eta_p_34292 = eta_p_34290;\n                        }\n                    }\n                    if (sle32(wave_sizze_34240, skip_threads_34304)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_34304 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_34238 - squot32(local_tid_34238, 32) * 32) == 31 && ltid_in_bounds_34303) {\n                    ((volatile __local int64_t *) local_mem_34247)[sext_i32_i64(squot32(local_tid_34238, 32))] = eta_p_34289;\n                    ((volatile __local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(squot32(local_tid_34238, 32))] = eta_p_34290;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_34306;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_34238, 32) == 0 && ltid_in_bounds_34303) {\n                        eta_p_34299 = ((volatile __local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)];\n                        eta_p_34300 = ((volatile __local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(local_tid_34238)];\n                        if ((local_tid_34238 - squot32(local_tid_34238, 32) * 32) == 0) {\n                            eta_p_342", "97 = eta_p_34299;\n                            eta_p_34298 = eta_p_34300;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_34306 = 1;\n                    while (slt32(skip_threads_34306, 32)) {\n                        bool thread_active_34307 = sle32(skip_threads_34306, local_tid_34238 - squot32(local_tid_34238, 32) * 32) && (squot32(local_tid_34238, 32) == 0 && ltid_in_bounds_34303);\n                        \n                        if (thread_active_34307) {\n                            // read operands\n                            {\n                                eta_p_34297 = ((volatile __local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238) - sext_i32_i64(skip_threads_34306)];\n                                eta_p_34298 = ((volatile __local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + (sext_i32_i64(local_tid_34238) - sext_i32_i64(skip_threads_34306))];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_34307) {\n                                int64_t lifted_lambda_res_34301 = add64(eta_p_34297, eta_p_34299);\n                                int64_t defunc_0_op_res_34302 = add64(eta_p_34298, eta_p_34300);\n                                \n                                eta_p_34297 = lifted_lambda_res_34301;\n                                eta_p_34298 = defunc_0_op_res_34302;\n                            }\n                        }\n                        if (sle32(wave_sizze_34240, skip_threads_34306)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_34307) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_34", "247)[sext_i32_i64(local_tid_34238)] = eta_p_34297;\n                                eta_p_34299 = eta_p_34297;\n                                ((volatile __local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(local_tid_34238)] = eta_p_34298;\n                                eta_p_34300 = eta_p_34298;\n                            }\n                        }\n                        if (sle32(wave_sizze_34240, skip_threads_34306)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_34306 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_34308 = squot32(local_tid_34238, 32) == 0 || !ltid_in_bounds_34303;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_34308) {\n                        eta_p_34291 = eta_p_34289;\n                        eta_p_34292 = eta_p_34290;\n                        eta_p_34289 = ((__local int64_t *) local_mem_34247)[sext_i32_i64(squot32(local_tid_34238, 32)) - (int64_t) 1];\n                        eta_p_34290 = ((__local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + (sext_i32_i64(squot32(local_tid_34238, 32)) - (int64_t) 1)];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_34308) {\n                        int64_t lifted_lambda_res_34293 = add64(eta_p_34289, eta_p_34291);\n                        int64_t defunc_0_op_res_34294 = add64(eta_p_34290, eta_p_34292);\n                        \n                        eta_p_34289 = lifted_lambda_res_34293;\n                        eta_p_34290 = defunc_0_op_res_34294;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_c",
                                    "arry_in_34308) {\n                        ((__local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)] = eta_p_34289;\n                        ((__local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(local_tid_34238)] = eta_p_34290;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_34238, 32) == 0 && ltid_in_bounds_34303) {\n                    ((__local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)] = eta_p_34291;\n                    ((__local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(local_tid_34238)] = eta_p_34292;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_34238 == 0) {\n                acc_34295 = ((__local int64_t *) local_mem_34247)[segscan_tblock_sizze_33651 - (int64_t) 1];\n                acc_34296 = ((__local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + (segscan_tblock_sizze_33651 - (int64_t) 1)];\n            } else {\n                acc_34295 = ((__local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238) - (int64_t) 1];\n                acc_34296 = ((__local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + (sext_i32_i64(local_tid_34238) - (int64_t) 1)];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_34309 = (int64_t) 0;\n        prefix_34310 = (int64_t) 0;\n        block_new_sgm_34311 = sgm_idx_34262 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_34311 && local_tid_34238 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_34229)[dynamic_id_34260] = acc_34295;\n                ((volatile __global int64_t *) incprefixes_mem_34233)[dynamic_id_34260] = acc_34296;\n                me", "m_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_34225)[dynamic_id_34260] = (int8_t) 2;\n                acc_34295 = (int64_t) 0;\n                acc_34296 = (int64_t) 0;\n            }\n            if (!block_new_sgm_34311 && slt32(local_tid_34238, wave_sizze_34240)) {\n                if (local_tid_34238 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_34227)[dynamic_id_34260] = acc_34295;\n                    ((volatile __global int64_t *) aggregates_mem_34231)[dynamic_id_34260] = acc_34296;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_34225)[dynamic_id_34260] = (int8_t) 1;\n                    \n                    int8_t tmp_34312 = ((volatile __global int8_t *) status_flags_mem_34225)[dynamic_id_34260 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_34247)[(int64_t) 0] = tmp_34312;\n                }\n                mem_fence_local();\n                \n                int8_t status_34313 = ((__local int8_t *) local_mem_34247)[(int64_t) 0];\n                \n                if (status_34313 == (int8_t) 2) {\n                    if (local_tid_34238 == 0) {\n                        prefix_34309 = ((volatile __global int64_t *) incprefixes_mem_34229)[dynamic_id_34260 - (int64_t) 1];\n                        prefix_34310 = ((volatile __global int64_t *) incprefixes_mem_34233)[dynamic_id_34260 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_34314 = sext_i64_i32(dynamic_id_34260 - sext_i32_i64(wave_sizze_34240));\n                    \n                    while (slt32(wave_sizze_34240 * -1, readOffset_34314)) {\n                        int32_t read_i_34315 = readOffset_34314 + local_tid_34238;\n                        int64_t aggr_34316 = (int64_t) 0;\n                        int64_t aggr_34317 = (int64_t) 0;\n                        int8_t flag_34318 = (int8_t) 0;\n    ", "                    \n                        if (sle32(0, read_i_34315)) {\n                            flag_34318 = ((volatile __global int8_t *) status_flags_mem_34225)[sext_i32_i64(read_i_34315)];\n                            if (flag_34318 == (int8_t) 2) {\n                                aggr_34316 = ((volatile __global int64_t *) incprefixes_mem_34229)[sext_i32_i64(read_i_34315)];\n                                aggr_34317 = ((volatile __global int64_t *) incprefixes_mem_34233)[sext_i32_i64(read_i_34315)];\n                            } else if (flag_34318 == (int8_t) 1) {\n                                aggr_34316 = ((volatile __global int64_t *) aggregates_mem_34227)[sext_i32_i64(read_i_34315)];\n                                aggr_34317 = ((volatile __global int64_t *) aggregates_mem_34231)[sext_i32_i64(read_i_34315)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_34247)[(int64_t) 4 + sext_i32_i64(local_tid_34238)] = aggr_34316;\n                        ((__local int64_t *) local_mem_34247)[squot64(warp_byte_offset_34245, (int64_t) 8) + sext_i32_i64(local_tid_34238)] = aggr_34317;\n                        ((__local int8_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)] = flag_34318;\n                        flag_34318 = ((__local int8_t *) local_mem_34247)[sext_i32_i64(wave_sizze_34240) - (int64_t) 1];\n                        if (slt8(flag_34318, (int8_t) 2)) {\n                            int8_t flg_x_34325;\n                            int8_t flg_y_34326;\n                            int64_t eta_p_34319;\n                            int64_t eta_p_34320;\n                            int64_t eta_p_34321;\n                            int64_t eta_p_34322;\n                            int32_t skip_threads_34327;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_34326 = ((volatile __local int8_t *) loca",
                                    "l_mem_34247)[sext_i32_i64(local_tid_34238)];\n                                eta_p_34321 = ((volatile __local int64_t *) local_mem_34247)[(int64_t) 4 + sext_i32_i64(local_tid_34238)];\n                                eta_p_34322 = ((volatile __local int64_t *) local_mem_34247)[squot64(warp_byte_offset_34245, (int64_t) 8) + sext_i32_i64(local_tid_34238)];\n                                if ((local_tid_34238 - squot32(local_tid_34238, 32) * 32) == 0) {\n                                    eta_p_34319 = eta_p_34321;\n                                    eta_p_34320 = eta_p_34322;\n                                    flg_x_34325 = flg_y_34326;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_34327 = 1;\n                                while (slt32(skip_threads_34327, 32)) {\n                                    if (sle32(skip_threads_34327, local_tid_34238 - squot32(local_tid_34238, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_34325 = ((volatile __local int8_t *) local_mem_34247)[sext_i32_i64(local_tid_34238) - sext_i32_i64(skip_threads_34327)];\n                                            eta_p_34319 = ((volatile __local int64_t *) local_mem_34247)[(int64_t) 4 + (sext_i32_i64(local_tid_34238) - sext_i32_i64(skip_threads_34327))];\n                                            eta_p_34320 = ((volatile __local int64_t *) local_mem_34247)[squot64(warp_byte_offset_34245, (int64_t) 8) + (sext_i32_i64(local_tid_34238) - sext_i32_i64(skip_threads_34327))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_34326 == (int8_t) 2 || flg_y_34326 == (int8_t) 0) {\n       ", "                                         flg_x_34325 = flg_y_34326;\n                                                eta_p_34319 = eta_p_34321;\n                                                eta_p_34320 = eta_p_34322;\n                                            } else {\n                                                int64_t lifted_lambda_res_34323 = add64(eta_p_34319, eta_p_34321);\n                                                int64_t defunc_0_op_res_34324 = add64(eta_p_34320, eta_p_34322);\n                                                \n                                                eta_p_34319 = lifted_lambda_res_34323;\n                                                eta_p_34320 = defunc_0_op_res_34324;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)] = flg_x_34325;\n                                            flg_y_34326 = flg_x_34325;\n                                            ((volatile __local int64_t *) local_mem_34247)[(int64_t) 4 + sext_i32_i64(local_tid_34238)] = eta_p_34319;\n                                            eta_p_34321 = eta_p_34319;\n                                            ((volatile __local int64_t *) local_mem_34247)[squot64(warp_byte_offset_34245, (int64_t) 8) + sext_i32_i64(local_tid_34238)] = eta_p_34320;\n                                            eta_p_34322 = eta_p_34320;\n                                        }\n                                    }\n                                    skip_threads_34327 *= 2;\n                                }\n                            }\n                        }\n                        flag_34318 = ((__local int8_t *) local_mem_34247)[sext_i32_i64(wave_sizze_34240) - (int64_t) 1];\n                        aggr_34316 = ((__local int64_t *) ", "local_mem_34247)[(int64_t) 4 + (sext_i32_i64(wave_sizze_34240) - (int64_t) 1)];\n                        aggr_34317 = ((__local int64_t *) local_mem_34247)[squot64(warp_byte_offset_34245, (int64_t) 8) + (sext_i32_i64(wave_sizze_34240) - (int64_t) 1)];\n                        if (flag_34318 == (int8_t) 2) {\n                            readOffset_34314 = wave_sizze_34240 * -1;\n                        } else if (flag_34318 == (int8_t) 1) {\n                            readOffset_34314 -= wave_sizze_34240;\n                        }\n                        if (slt8((int8_t) 0, flag_34318)) {\n                            int64_t eta_p_34328 = aggr_34316;\n                            int64_t eta_p_34329 = aggr_34317;\n                            int64_t eta_p_34330 = prefix_34309;\n                            int64_t eta_p_34331 = prefix_34310;\n                            int64_t lifted_lambda_res_34332 = add64(eta_p_34328, eta_p_34330);\n                            int64_t defunc_0_op_res_34333 = add64(eta_p_34329, eta_p_34331);\n                            \n                            prefix_34309 = lifted_lambda_res_34332;\n                            prefix_34310 = defunc_0_op_res_34333;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_34238 == 0) {\n                    if (boundary_34263 == sext_i64_i32(segscan_tblock_sizze_33651 * chunk_sizze_34222)) {\n                        int64_t eta_p_34334 = prefix_34309;\n                        int64_t eta_p_34335 = prefix_34310;\n                        int64_t eta_p_34336 = acc_34295;\n                        int64_t eta_p_34337 = acc_34296;\n                        int64_t lifted_lambda_res_34338 = add64(eta_p_34334, eta_p_34336);\n                        int64_t defunc_0_op_res_34339 = add64(eta_p_34335, eta_p_34337);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_34229)[dynamic_id_34260] = lifted_la",
                                    "mbda_res_34338;\n                        ((volatile __global int64_t *) incprefixes_mem_34233)[dynamic_id_34260] = defunc_0_op_res_34339;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_34225)[dynamic_id_34260] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_34247)[(int64_t) 4] = prefix_34309;\n                    ((__local int64_t *) local_mem_34247)[squot64(warp_byte_offset_34245, (int64_t) 8)] = prefix_34310;\n                    acc_34295 = (int64_t) 0;\n                    acc_34296 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_34260 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_34309 = ((__local int64_t *) local_mem_34247)[(int64_t) 4];\n                prefix_34310 = ((__local int64_t *) local_mem_34247)[squot64(warp_byte_offset_34245, (int64_t) 8)];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_34340;\n            int64_t eta_p_34342;\n            int64_t eta_p_34346 = prefix_34309;\n            int64_t eta_p_34348 = acc_34295;\n            int64_t eta_p_34341;\n            int64_t eta_p_34343;\n            int64_t eta_p_34347 = prefix_34310;\n            int64_t eta_p_34349 = acc_34296;\n            \n            if (slt32(local_tid_34238 * chunk_sizze_32b_34242, boundary_34263) && !block_new_sgm_34311) {\n                int64_t lifted_lambda_res_34350 = add64(eta_p_34346, eta_p_34348);\n                int64_t defunc_0_op_res_34351 = add64(eta_p_34347, eta_p_34349);\n                \n                eta_p_34340 = lifted_lambda_res_34350;\n                eta_p_34341 = defunc_0_op_res_34351;\n            } else {\n                eta_p_34340 = acc_34295;\n                eta_p_34341 = acc_34296;\n            }\n            \n            int32_t stopping_point_34352 = segsizze_compact_34264 - srem32(local_tid_34238 * ", "chunk_sizze_32b_34242 - 1 + segsizze_compact_34264 - boundary_34263, segsizze_compact_34264);\n            \n            for (int64_t i_34353 = 0; i_34353 < chunk_sizze_34222; i_34353++) {\n                if (slt32(sext_i64_i32(i_34353), stopping_point_34352 - 1)) {\n                    eta_p_34342 = private_mem_34265[i_34353];\n                    eta_p_34343 = private_mem_34267[i_34353];\n                    \n                    int64_t lifted_lambda_res_34344 = add64(eta_p_34340, eta_p_34342);\n                    int64_t defunc_0_op_res_34345 = add64(eta_p_34341, eta_p_34343);\n                    \n                    private_mem_34265[i_34353] = lifted_lambda_res_34344;\n                    private_mem_34267[i_34353] = defunc_0_op_res_34345;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_34354 = 0; i_34354 < chunk_sizze_34222; i_34354++) {\n                int64_t sharedIdx_34355 = sext_i32_i64(local_tid_34238) * chunk_sizze_34222 + i_34354;\n                int64_t tmp_34356 = private_mem_34265[i_34354];\n                \n                ((__local int64_t *) local_mem_34247)[sharedIdx_34355] = tmp_34356;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34357 = 0; i_34357 < chunk_sizze_34222; i_34357++) {\n                int64_t flat_idx_34358 = thd_offset_34269 + i_34357 * segscan_tblock_sizze_33651;\n                int64_t slice_34359 = m_32498;\n                int64_t gtid_33655 = flat_idx_34358;\n                int64_t remnant_34360 = flat_idx_34358 - gtid_33655;\n                \n                if (slt64(flat_idx_34358, m_32498)) {\n                    int64_t tmp_34361 = ((__local int64_t *) local_mem_34247)[flat_idx_34358 - block_offset_34261];\n                    \n                    ((__global int64_t *) mem_33848)[gtid_33655] = tmp_34361;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n    ", "        for (int64_t i_34362 = 0; i_34362 < chunk_sizze_34222; i_34362++) {\n                int64_t sharedIdx_34363 = sext_i32_i64(local_tid_34238) * chunk_sizze_34222 + i_34362;\n                int64_t tmp_34364 = private_mem_34267[i_34362];\n                \n                ((__local int64_t *) local_mem_34247)[sharedIdx_34363] = tmp_34364;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34365 = 0; i_34365 < chunk_sizze_34222; i_34365++) {\n                int64_t flat_idx_34366 = thd_offset_34269 + i_34365 * segscan_tblock_sizze_33651;\n                int64_t slice_34367 = m_32498;\n                int64_t gtid_33655 = flat_idx_34366;\n                int64_t remnant_34368 = flat_idx_34366 - gtid_33655;\n                \n                if (slt64(flat_idx_34366, m_32498)) {\n                    int64_t tmp_34369 = ((__local int64_t *) local_mem_34247)[flat_idx_34366 - block_offset_34261];\n                    \n                    ((__global int64_t *) mem_33850)[gtid_33655] = tmp_34369;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_33651\n    #undef chunk_sizze_34222\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzigpuseq_34379_dim1, 1, 1)\nvoid inner_SMJ_intzigpuseq_34379(__global int *global_failure, int64_t m_32502, __global unsigned char *mem_33855, __global unsigned char *mem_33857)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34381;\n    int32_t tblock_sizze_34384;\n    int32_t wave_sizze_34383;\n    int32_t block_id_34382;\n    int32_t global_tid_34380;\n    int64_t tid_34379;\n    int64_t x_33807;\n    \n    local_tid_34381 = get_local_id(0);\n    tblock_sizze_34384 = get_local_size(0);\n    wave_sizze_34383 = LOCKSTEP_WIDTH;\n    block_id_34382 = get_tblock_id(0);\n    global_tid_34380 = block_id_34382 * tblock_sizze_34384 + local_tid_34381;\n    tid_34379 = sext_i32_i64(global_tid_34380);\n    x_33807 = ((__global int64_",
                                    "t *) mem_33855)[m_32502];\n    ((__global int64_t *) mem_33857)[(int64_t) 0] = x_33807;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzigpuseq_34385_dim1, 1, 1)\nvoid inner_SMJ_intzigpuseq_34385(__global int *global_failure, int64_t m_32502, __global unsigned char *mem_33844, __global unsigned char *mem_33860)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34387;\n    int32_t tblock_sizze_34390;\n    int32_t wave_sizze_34389;\n    int32_t block_id_34388;\n    int32_t global_tid_34386;\n    int64_t tid_34385;\n    int64_t x_33811;\n    \n    local_tid_34387 = get_local_id(0);\n    tblock_sizze_34390 = get_local_size(0);\n    wave_sizze_34389 = LOCKSTEP_WIDTH;\n    block_id_34388 = get_tblock_id(0);\n    global_tid_34386 = block_id_34388 * tblock_sizze_34390 + local_tid_34387;\n    tid_34385 = sext_i32_i64(global_tid_34386);\n    x_33811 = ((__global int64_t *) mem_33844)[m_32502];\n    ((__global int64_t *) mem_33860)[(int64_t) 0] = x_33811;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzigpuseq_34391_dim1, 1, 1)\nvoid inner_SMJ_intzigpuseq_34391(__global int *global_failure, __global unsigned char *ext_mem_33858, __global unsigned char *ext_mem_33861, __global unsigned char *mem_33867)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34393;\n    int32_t tblock_sizze_34396;\n    int32_t wave_sizze_34395;\n    int32_t block_id_34394;\n    int32_t global_tid_34392;\n    int64_t tid_34391;\n    int64_t zp_lhs_33815;\n    int64_t n_pairs_t_res_33816;\n    int64_t n_pairs_t_res_33817;\n    \n    local_tid_34393 = get_local_id(0);\n    tblock_sizze_34396 = get_local_size(0);\n    wave_sizze_34395 = LOCKSTEP_WIDTH;\n    block_id_34394 = get_tblock_id(0);\n    global_tid_34392 = block_id_34394 * tblock_sizze_34396 + local_tid_34393;\n    tid_34391 = sext_i32_i64(global_tid_34392);\n    zp_lhs_33815 = ((__global int64_t *) ext_mem_33858)[(int64_t) 0];\n    n_pairs_t_res_33816 = ((__global int64_t *) ext_mem_33861)[(int64_", "t) 0];\n    n_pairs_t_res_33817 = add64(zp_lhs_33815, n_pairs_t_res_33816);\n    ((__global int64_t *) mem_33867)[(int64_t) 0] = n_pairs_t_res_33817;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzigpuseq_34438_dim1, 1, 1)\nvoid inner_SMJ_intzigpuseq_34438(__global int *global_failure, int64_t loopres_32670, __global unsigned char *mem_param_33901, __global unsigned char *mem_param_33904, __global unsigned char *mem_param_33907, __global unsigned char *mem_33914, __global unsigned char *mem_33915, __global unsigned char *mem_33916)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34440;\n    int32_t tblock_sizze_34443;\n    int32_t wave_sizze_34442;\n    int32_t block_id_34441;\n    int32_t global_tid_34439;\n    int64_t tid_34438;\n    int32_t loopres_33819;\n    int64_t loopres_33821;\n    int64_t loopres_33823;\n    \n    local_tid_34440 = get_local_id(0);\n    tblock_sizze_34443 = get_local_size(0);\n    wave_sizze_34442 = LOCKSTEP_WIDTH;\n    block_id_34441 = get_tblock_id(0);\n    global_tid_34439 = block_id_34441 * tblock_sizze_34443 + local_tid_34440;\n    tid_34438 = sext_i32_i64(global_tid_34439);\n    loopres_33819 = ((__global int32_t *) mem_param_33901)[loopres_32670];\n    loopres_33821 = ((__global int64_t *) mem_param_33904)[loopres_32670];\n    loopres_33823 = ((__global int64_t *) mem_param_33907)[loopres_32670];\n    ((__global int32_t *) mem_33914)[(int64_t) 0] = loopres_33819;\n    ((__global int64_t *) mem_33915)[(int64_t) 0] = loopres_33821;\n    ((__global int64_t *) mem_33916)[(int64_t) 0] = loopres_33823;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL\nvoid inner_SMJ_intzireplicate_34445(int64_t loopres_32671, int64_t replicate_n_34444, int64_t virt_num_tblocks_34450, int64_t num_tblocks_34451, __global unsigned char *mem_33914, __global unsigned char *mem_33918)\n{\n    int32_t replicate_ltid_34446;\n    int32_t tblock_sizze_34448;\n    int32_t replicate_gid_34447;\n    int32_t replicate_gtid_34445;\n    int32_t phys_tblock_id_3", "4452;\n    int32_t iterations_34453;\n    \n    replicate_ltid_34446 = get_local_id(0);\n    tblock_sizze_34448 = get_local_size(0);\n    replicate_gid_34447 = get_tblock_id(0);\n    replicate_gtid_34445 = replicate_gid_34447 * tblock_sizze_34448 + replicate_ltid_34446;\n    phys_tblock_id_34452 = get_tblock_id(0);\n    iterations_34453 = sdiv_up32(sext_i64_i32(virt_num_tblocks_34450) - phys_tblock_id_34452, sext_i64_i32(num_tblocks_34451));\n    for (int32_t i_34454 = 0; i_34454 < iterations_34453; i_34454++) {\n        int32_t virt_tblock_id_34455;\n        int64_t global_tid_34456;\n        int64_t slice_34459;\n        int64_t slice_34460;\n        int64_t rep_i_34457;\n        int64_t remnant_34461;\n        int64_t rep_i_34458;\n        int64_t remnant_34462;\n        \n        virt_tblock_id_34455 = phys_tblock_id_34452 + i_34454 * sext_i64_i32(num_tblocks_34451);\n        global_tid_34456 = sext_i32_i64(virt_tblock_id_34455) * sext_i32_i64(tblock_sizze_34448) + sext_i32_i64(replicate_ltid_34446);\n        slice_34459 = (int64_t) 1;\n        slice_34460 = loopres_32671 * slice_34459;\n        rep_i_34457 = squot64(global_tid_34456, slice_34459);\n        remnant_34461 = global_tid_34456 - rep_i_34457 * slice_34459;\n        rep_i_34458 = remnant_34461;\n        remnant_34462 = remnant_34461 - rep_i_34458;\n        if (slt64(global_tid_34456, replicate_n_34444)) {\n            int32_t tmp_34463 = ((__global int32_t *) mem_33914)[rep_i_34458];\n            \n            ((__global int32_t *) mem_33918)[rep_i_34457 + rep_i_34458] = tmp_34463;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid inner_SMJ_intzireplicate_34465(int64_t loopres_32671, int64_t replicate_n_34464, int64_t virt_num_tblocks_34470, int64_t num_tblocks_34471, __global unsigned char *mem_33915, __global unsigned char *mem_33920)\n{\n    int32_t replicate_ltid_34466;\n    int32_t tblock_sizze_34468;\n    int32_t replicate_gid_34467;\n    int32_t replica",
                                    "te_gtid_34465;\n    int32_t phys_tblock_id_34472;\n    int32_t iterations_34473;\n    \n    replicate_ltid_34466 = get_local_id(0);\n    tblock_sizze_34468 = get_local_size(0);\n    replicate_gid_34467 = get_tblock_id(0);\n    replicate_gtid_34465 = replicate_gid_34467 * tblock_sizze_34468 + replicate_ltid_34466;\n    phys_tblock_id_34472 = get_tblock_id(0);\n    iterations_34473 = sdiv_up32(sext_i64_i32(virt_num_tblocks_34470) - phys_tblock_id_34472, sext_i64_i32(num_tblocks_34471));\n    for (int32_t i_34474 = 0; i_34474 < iterations_34473; i_34474++) {\n        int32_t virt_tblock_id_34475;\n        int64_t global_tid_34476;\n        int64_t slice_34479;\n        int64_t slice_34480;\n        int64_t rep_i_34477;\n        int64_t remnant_34481;\n        int64_t rep_i_34478;\n        int64_t remnant_34482;\n        \n        virt_tblock_id_34475 = phys_tblock_id_34472 + i_34474 * sext_i64_i32(num_tblocks_34471);\n        global_tid_34476 = sext_i32_i64(virt_tblock_id_34475) * sext_i32_i64(tblock_sizze_34468) + sext_i32_i64(replicate_ltid_34466);\n        slice_34479 = (int64_t) 1;\n        slice_34480 = loopres_32671 * slice_34479;\n        rep_i_34477 = squot64(global_tid_34476, slice_34479);\n        remnant_34481 = global_tid_34476 - rep_i_34477 * slice_34479;\n        rep_i_34478 = remnant_34481;\n        remnant_34482 = remnant_34481 - rep_i_34478;\n        if (slt64(global_tid_34476, replicate_n_34464)) {\n            int64_t tmp_34483 = ((__global int64_t *) mem_33915)[rep_i_34478];\n            \n            ((__global int64_t *) mem_33920)[rep_i_34477 + rep_i_34478] = tmp_34483;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzisegmap_33474_dim1, 1, 1)\nvoid inner_SMJ_intzisegmap_33474(__global int *global_failure, int64_t nR_23386, int64_t offset_R_23390, int64_t m_32498, int64_t num_tblocks_33479, int32_t virt_num_tblocks_34204, __global unsigned char *tR_mem_33832, __global unsigned char *mem", "_33838, __global unsigned char *mem_33840, __global unsigned char *mem_33842, __global unsigned char *mem_33844)\n{\n    #define segmap_tblock_sizze_33477 (inner_SMJ_intzisegmap_33474zisegmap_tblock_sizze_33477)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34206;\n    int32_t tblock_sizze_34209;\n    int32_t wave_sizze_34208;\n    int32_t block_id_34207;\n    int32_t global_tid_34205;\n    int64_t phys_tid_33474;\n    int32_t phys_tblock_id_34210;\n    int32_t iterations_34211;\n    \n    local_tid_34206 = get_local_id(0);\n    tblock_sizze_34209 = get_local_size(0);\n    wave_sizze_34208 = LOCKSTEP_WIDTH;\n    block_id_34207 = get_tblock_id(0);\n    global_tid_34205 = block_id_34207 * tblock_sizze_34209 + local_tid_34206;\n    phys_tid_33474 = sext_i32_i64(global_tid_34205);\n    phys_tblock_id_34210 = get_tblock_id(0);\n    iterations_34211 = sdiv_up32(virt_num_tblocks_34204 - phys_tblock_id_34210, sext_i64_i32(num_tblocks_33479));\n    for (int32_t i_34212 = 0; i_34212 < iterations_34211; i_34212++) {\n        int32_t virt_tblock_id_34213;\n        int64_t global_tid_34214;\n        int64_t slice_34215;\n        int64_t write_i_33473;\n        int64_t remnant_34216;\n        \n        virt_tblock_id_34213 = phys_tblock_id_34210 + i_34212 * sext_i64_i32(num_tblocks_33479);\n        global_tid_34214 = sext_i32_i64(virt_tblock_id_34213) * segmap_tblock_sizze_33477 + sext_i32_i64(local_tid_34206);\n        slice_34215 = nR_23386;\n        write_i_33473 = global_tid_34214;\n        remnant_34216 = global_tid_34214 - write_i_33473;\n        if (slt64(write_i_33473, nR_23386)) {\n            int32_t write_value_32519;\n            int64_t index_primexp_33806;\n            \n            write_value_32519 = ((__global int32_t *) tR_mem_33832)[write_i_33473];\n            index_primexp_33806 = add64(offset_R_23390, write_i_33473);\n            if (sle64((int64_t) 0, (int64_t) -1) && slt64((int64_t) -1, m_32498)) {\n                ((__global int32_t *) mem_33838)[(int64_t) -1] = wri", "te_value_32519;\n            }\n            if (sle64((int64_t) 0, (int64_t) -1) && slt64((int64_t) -1, m_32498)) {\n                ((__global int64_t *) mem_33840)[(int64_t) -1] = index_primexp_33806;\n            }\n            if (sle64((int64_t) 0, (int64_t) -1) && slt64((int64_t) -1, m_32498)) {\n                ((__global int64_t *) mem_33842)[(int64_t) -1] = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, (int64_t) -1) && slt64((int64_t) -1, m_32498)) {\n                ((__global int64_t *) mem_33844)[(int64_t) -1] = (int64_t) 0;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_33477\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzisegmap_33508_dim1, 1, 1)\nvoid inner_SMJ_intzisegmap_33508(__global int *global_failure, int64_t m_32498, __global unsigned char *mem_33848, __global unsigned char *mem_33855)\n{\n    #define segmap_tblock_sizze_33504 (inner_SMJ_intzisegmap_33508zisegmap_tblock_sizze_33504)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34372;\n    int32_t tblock_sizze_34375;\n    int32_t wave_sizze_34374;\n    int32_t block_id_34373;\n    int32_t global_tid_34371;\n    int64_t phys_tid_33508;\n    int64_t global_tid_34376;\n    int64_t slice_34377;\n    int64_t gtid_33507;\n    int64_t remnant_34378;\n    \n    local_tid_34372 = get_local_id(0);\n    tblock_sizze_34375 = get_local_size(0);\n    wave_sizze_34374 = LOCKSTEP_WIDTH;\n    block_id_34373 = get_tblock_id(0);\n    global_tid_34371 = block_id_34373 * tblock_sizze_34375 + local_tid_34372;\n    phys_tid_33508 = sext_i32_i64(global_tid_34371);\n    global_tid_34376 = sext_i32_i64(block_id_34373) * segmap_tblock_sizze_33504 + sext_i32_i64(local_tid_34372);\n    slice_34377 = m_32498;\n    gtid_33507 = global_tid_34376;\n    remnant_34378 = global_tid_34376 - gtid_33507;\n    if (slt64(gtid_33507, m_32498)) {\n        int64_t zv_lhs_33510;\n        int64_t tmp_33511;\n        bool cond_33513;\n    ",
                                    "    int64_t lifted_lambda_res_33514;\n        \n        zv_lhs_33510 = add64((int64_t) -1, gtid_33507);\n        tmp_33511 = smod64(zv_lhs_33510, m_32498);\n        cond_33513 = gtid_33507 == (int64_t) 0;\n        if (cond_33513) {\n            lifted_lambda_res_33514 = (int64_t) 0;\n        } else {\n            int64_t lifted_lambda_res_33512 = ((__global int64_t *) mem_33848)[tmp_33511];\n            \n            lifted_lambda_res_33514 = lifted_lambda_res_33512;\n        }\n        ((__global int64_t *) mem_33855)[gtid_33507] = lifted_lambda_res_33514;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_33504\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzisegmap_33516_dim1, 1, 1)\nvoid inner_SMJ_intzisegmap_33516(__global int *global_failure, int64_t m_32498, int64_t lower_bound_32569, int64_t min_res_32571, int64_t j_m_i_32572, int64_t num_tblocks_33521, int32_t virt_num_tblocks_34417, __global unsigned char *mem_33838, __global unsigned char *mem_33840, __global unsigned char *mem_33842, __global unsigned char *mem_33855, __global unsigned char *mem_33884, __global unsigned char *mem_33886, __global unsigned char *mem_33888)\n{\n    #define segmap_tblock_sizze_33519 (inner_SMJ_intzisegmap_33516zisegmap_tblock_sizze_33519)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34419;\n    int32_t tblock_sizze_34422;\n    int32_t wave_sizze_34421;\n    int32_t block_id_34420;\n    int32_t global_tid_34418;\n    int64_t phys_tid_33516;\n    int32_t phys_tblock_id_34423;\n    int32_t iterations_34424;\n    \n    local_tid_34419 = get_local_id(0);\n    tblock_sizze_34422 = get_local_size(0);\n    wave_sizze_34421 = LOCKSTEP_WIDTH;\n    block_id_34420 = get_tblock_id(0);\n    global_tid_34418 = block_id_34420 * tblock_sizze_34422 + local_tid_34419;\n    phys_tid_33516 = sext_i32_i64(global_tid_34418);\n    phys_tblock_id_34423 = get_tblock_id(0);\n    iterations_34424 = sdiv_up32(virt_num_tblocks_34417 - phys_tblock_id_34423, sext_i64_i32(num_tblocks_33521));\n    for (int32", "_t i_34425 = 0; i_34425 < iterations_34424; i_34425++) {\n        int32_t virt_tblock_id_34426;\n        int64_t global_tid_34427;\n        int64_t slice_34428;\n        int64_t write_i_33515;\n        int64_t remnant_34429;\n        \n        virt_tblock_id_34426 = phys_tblock_id_34423 + i_34425 * sext_i64_i32(num_tblocks_33521);\n        global_tid_34427 = sext_i32_i64(virt_tblock_id_34426) * segmap_tblock_sizze_33519 + sext_i32_i64(local_tid_34419);\n        slice_34428 = m_32498;\n        write_i_33515 = global_tid_34427;\n        remnant_34429 = global_tid_34427 - write_i_33515;\n        if (slt64(write_i_33515, m_32498)) {\n            int64_t eta_p_32753;\n            int32_t write_value_32754;\n            int64_t write_value_32755;\n            int64_t write_value_32756;\n            bool cond_32757;\n            bool cond_t_res_32758;\n            bool x_32759;\n            int64_t lifted_lambda_res_32760;\n            \n            eta_p_32753 = ((__global int64_t *) mem_33855)[write_i_33515];\n            write_value_32754 = ((__global int32_t *) mem_33838)[write_i_33515];\n            write_value_32755 = ((__global int64_t *) mem_33840)[write_i_33515];\n            write_value_32756 = ((__global int64_t *) mem_33842)[write_i_33515];\n            cond_32757 = sle64(lower_bound_32569, eta_p_32753);\n            cond_t_res_32758 = slt64(eta_p_32753, min_res_32571);\n            x_32759 = cond_32757 && cond_t_res_32758;\n            if (x_32759) {\n                int64_t lifted_lambda_res_t_res_32784 = sub64(eta_p_32753, lower_bound_32569);\n                \n                lifted_lambda_res_32760 = lifted_lambda_res_t_res_32784;\n            } else {\n                lifted_lambda_res_32760 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_32760) && slt64(lifted_lambda_res_32760, j_m_i_32572)) {\n                ((__global int32_t *) mem_33884)[lifted_lambda_res_32760] = write_value_32754;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_", "32760) && slt64(lifted_lambda_res_32760, j_m_i_32572)) {\n                ((__global int64_t *) mem_33886)[lifted_lambda_res_32760] = write_value_32755;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_32760) && slt64(lifted_lambda_res_32760, j_m_i_32572)) {\n                ((__global int64_t *) mem_33888)[lifted_lambda_res_32760] = write_value_32756;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_33519\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzisegmap_33524_dim1, 1, 1)\nvoid inner_SMJ_intzisegmap_33524(__global int *global_failure, int64_t m_32498, int64_t m_32626, int64_t num_tblocks_33529, int32_t virt_num_tblocks_34399, __global unsigned char *mem_33844, __global unsigned char *mem_33850, __global unsigned char *mem_33852, __global unsigned char *mem_33855, __global unsigned char *mem_33863, __global unsigned char *mem_33865)\n{\n    #define segmap_tblock_sizze_33527 (inner_SMJ_intzisegmap_33524zisegmap_tblock_sizze_33527)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34401;\n    int32_t tblock_sizze_34404;\n    int32_t wave_sizze_34403;\n    int32_t block_id_34402;\n    int32_t global_tid_34400;\n    int64_t phys_tid_33524;\n    int32_t phys_tblock_id_34405;\n    int32_t iterations_34406;\n    \n    local_tid_34401 = get_local_id(0);\n    tblock_sizze_34404 = get_local_size(0);\n    wave_sizze_34403 = LOCKSTEP_WIDTH;\n    block_id_34402 = get_tblock_id(0);\n    global_tid_34400 = block_id_34402 * tblock_sizze_34404 + local_tid_34401;\n    phys_tid_33524 = sext_i32_i64(global_tid_34400);\n    phys_tblock_id_34405 = get_tblock_id(0);\n    iterations_34406 = sdiv_up32(virt_num_tblocks_34399 - phys_tblock_id_34405, sext_i64_i32(num_tblocks_33529));\n    for (int32_t i_34407 = 0; i_34407 < iterations_34406; i_34407++) {\n        int32_t virt_tblock_id_34408;\n        int64_t global_tid_34409;\n        int64_t slice_34410;\n        int64_t write_i_335",
                                    "23;\n        int64_t remnant_34411;\n        \n        virt_tblock_id_34408 = phys_tblock_id_34405 + i_34407 * sext_i64_i32(num_tblocks_33529);\n        global_tid_34409 = sext_i32_i64(virt_tblock_id_34408) * segmap_tblock_sizze_33527 + sext_i32_i64(local_tid_34401);\n        slice_34410 = m_32498;\n        write_i_33523 = global_tid_34409;\n        remnant_34411 = global_tid_34409 - write_i_33523;\n        if (slt64(write_i_33523, m_32498)) {\n            int64_t eta_p_32710;\n            int64_t write_value_32712;\n            int64_t write_value_32713;\n            bool cond_32714;\n            int64_t lifted_lambda_res_32715;\n            \n            eta_p_32710 = ((__global int64_t *) mem_33852)[write_i_33523];\n            write_value_32712 = ((__global int64_t *) mem_33855)[write_i_33523];\n            write_value_32713 = ((__global int64_t *) mem_33844)[write_i_33523];\n            cond_32714 = eta_p_32710 == (int64_t) 1;\n            if (cond_32714) {\n                int64_t eta_p_32711;\n                int64_t lifted_lambda_res_t_res_32789;\n                \n                eta_p_32711 = ((__global int64_t *) mem_33850)[write_i_33523];\n                lifted_lambda_res_t_res_32789 = sub64(eta_p_32711, (int64_t) 1);\n                lifted_lambda_res_32715 = lifted_lambda_res_t_res_32789;\n            } else {\n                lifted_lambda_res_32715 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_32715) && slt64(lifted_lambda_res_32715, m_32626)) {\n                ((__global int64_t *) mem_33865)[lifted_lambda_res_32715] = write_value_32712;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_32715) && slt64(lifted_lambda_res_32715, m_32626)) {\n                ((__global int64_t *) mem_33863)[lifted_lambda_res_32715] = write_value_32713;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_33527\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intz", "isegmap_33546_dim1, 1, 1)\nvoid inner_SMJ_intzisegmap_33546(__global int *global_failure, int64_t loopres_32670, int64_t loopres_32671, __global unsigned char *mem_33913, __global unsigned char *mem_33916)\n{\n    #define segmap_tblock_sizze_33542 (inner_SMJ_intzisegmap_33546zisegmap_tblock_sizze_33542)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34486;\n    int32_t tblock_sizze_34489;\n    int32_t wave_sizze_34488;\n    int32_t block_id_34487;\n    int32_t global_tid_34485;\n    int64_t phys_tid_33546;\n    int64_t global_tid_34490;\n    int64_t slice_34491;\n    int64_t gtid_33545;\n    int64_t remnant_34492;\n    \n    local_tid_34486 = get_local_id(0);\n    tblock_sizze_34489 = get_local_size(0);\n    wave_sizze_34488 = LOCKSTEP_WIDTH;\n    block_id_34487 = get_tblock_id(0);\n    global_tid_34485 = block_id_34487 * tblock_sizze_34489 + local_tid_34486;\n    phys_tid_33546 = sext_i32_i64(global_tid_34485);\n    global_tid_34490 = sext_i32_i64(block_id_34487) * segmap_tblock_sizze_33542 + sext_i32_i64(local_tid_34486);\n    slice_34491 = loopres_32671;\n    gtid_33545 = global_tid_34490;\n    remnant_34492 = global_tid_34490 - gtid_33545;\n    if (slt64(gtid_33545, loopres_32671)) {\n        int64_t loopres_33827;\n        int64_t tmp_33548;\n        \n        loopres_33827 = ((__global int64_t *) mem_33916)[(int64_t) 0];\n        tmp_33548 = add64(gtid_33545, loopres_33827);\n        ((__global int64_t *) mem_33913)[loopres_32670 + gtid_33545] = tmp_33548;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_33542\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzisegscan_33472_dim1, 1, 1)\nvoid inner_SMJ_intzisegscan_33472(__global int *global_failure, int64_t nR_23386, int64_t num_tblocks_33469, int64_t num_virt_blocks_34029, int64_t num_virt_threads_34030, __global unsigned char *mem_33836, __global unsigned char *status_flags_mem_34031, __global unsigned char *aggregates_mem_34053, __global unsigned char *incprefixes_mem_34055, __global unsigned char *global_dyn", "id_mem_34057)\n{\n    #define segscan_tblock_sizze_33467 (inner_SMJ_intzisegscan_33472zisegscan_tblock_sizze_33467)\n    #define chunk_sizze_34028 (inner_SMJ_intzisegscan_33472zichunk_sizze_34028)\n    \n    volatile __local unsigned char *local_mem_34087_backing_0 = &shared_mem[0];\n    const int64_t local_mem_34087_backing_0_offset = 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_33467), chunk_sizze_34028 * segscan_tblock_sizze_33467 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_33467), chunk_sizze_34028 * segscan_tblock_sizze_33467 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34080;\n    int32_t tblock_sizze_34083;\n    int32_t wave_sizze_34082;\n    int32_t block_id_34081;\n    int32_t global_tid_34079;\n    int64_t phys_tid_33472;\n    int32_t chunk_sizze_32b_34084;\n    int64_t byte_offsets_34085;\n    int64_t warp_byte_offset_34086;\n    __local unsigned char *local_mem_34087;\n    int64_t trans_arr_len_34088;\n    int64_t phys_block_id_34094;\n    int64_t virtloop_bound_34095;\n    \n    local_tid_34080 = get_local_id(0);\n    tblock_sizze_34083 = get_local_size(0);\n    wave_sizze_34082 = LOCKSTEP_WIDTH;\n    block_id_34081 = get_tblock_id(0);\n    global_tid_34079 = block_id_34081 * tblock_sizze_34083 + local_tid_34080;\n    phys_tid_33472 = sext_i32_i64(global_tid_34079);\n    chunk_sizze_32b_34084 = sext_i64_i32(chunk_sizze_34028);\n    byte_offsets_34085 = segscan_tblock_sizze_33467 * (int64_t) 8;\n    warp_byte_offset_34086 = (int64_t) 288;\n    // Allocate reusable shared memory\n    { }\n    local_mem_34087 = (__local unsigned char *) local_mem_34087_backing_0;\n    trans_arr_len_34088 = chunk_sizze_34028 * segscan_tblock_sizze_33467;\n    phys_block_id_34094 = get_tblock_id(0);\n    virtloop_bound_34095 = sdiv_up64(num_virt_blocks_34029 - phys_block_id_34094, num_tblocks_33469);\n    for (int64_t virtloop_i_34096 = 0; virtl",
                                    "oop_i_34096 < virtloop_bound_34095; virtloop_i_34096++) {\n        int64_t dynamic_id_34097;\n        int64_t block_offset_34098;\n        int64_t sgm_idx_34099;\n        int32_t boundary_34100;\n        int32_t segsizze_compact_34101;\n        int64_t private_mem_34102[chunk_sizze_34028];\n        int64_t thd_offset_34104;\n        int64_t acc_34120;\n        int64_t prefix_34130;\n        bool block_new_sgm_34131;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_34080 == 0) {\n                dynamic_id_34097 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_34057)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_34087)[(int64_t) 0] = dynamic_id_34097;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_34097 == num_virt_blocks_34029 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_34057)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_34097 = ((__local int32_t *) local_mem_34087)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_34098 = dynamic_id_34097 * chunk_sizze_34028 * segscan_tblock_sizze_33467;\n        sgm_idx_34099 = smod64(block_offset_34098, nR_23386);\n        boundary_34100 = sext_i64_i32(smin64(chunk_sizze_34028 * segscan_tblock_sizze_33467, nR_23386 - sgm_idx_34099));\n        segsizze_compact_34101 = sext_i64_i32(smin64(chunk_sizze_34028 * segscan_tblock_sizze_33467, nR_23386));\n        thd_offset_34104 = block_offset_34098 + sext_i32_i64(local_tid_34080);\n        // Load and map\n        {\n            for (int64_t i_34105 = 0; i_34105 < chunk_sizze_34028; i_34105++) {\n                int64_t virt_tid_34106 = thd_offset_34104 + i_34105 * segscan_tbloc", "k_sizze_33467;\n                int64_t slice_34107 = nR_23386;\n                int64_t gtid_33471 = virt_tid_34106;\n                int64_t remnant_34108 = virt_tid_34106 - gtid_33471;\n                \n                if (slt64(virt_tid_34106, nR_23386)) {\n                    private_mem_34102[i_34105] = (int64_t) 0;\n                } else {\n                    private_mem_34102[i_34105] = (int64_t) 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_34109 = 0; i_34109 < chunk_sizze_34028; i_34109++) {\n                int64_t sharedIdx_34110 = sext_i32_i64(local_tid_34080) + i_34109 * segscan_tblock_sizze_33467;\n                int64_t tmp_34111 = private_mem_34102[i_34109];\n                \n                ((__local int64_t *) local_mem_34087)[sharedIdx_34110] = tmp_34111;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34112 = 0; i_34112 < chunk_sizze_34028; i_34112++) {\n                int64_t sharedIdx_34113 = sext_i32_i64(local_tid_34080) * chunk_sizze_34028 + i_34112;\n                int64_t tmp_34114 = ((__local int64_t *) local_mem_34087)[sharedIdx_34113];\n                \n                private_mem_34102[i_34112] = tmp_34114;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_34115 = 0; i_34115 < chunk_sizze_34028 - (int64_t) 1; i_34115++) {\n                int64_t eta_p_32774;\n                int64_t eta_p_32775;\n                \n                eta_p_32774 = private_mem_34102[i_34115];\n                eta_p_32775 = private_mem_34102[i_34115 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_32776 = add64(eta_p_32774, eta_p_32775);\n                \n                private_mem_34102[i_34115 + (int64_t) 1] = defunc_0_op_res_32776;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64", "_t tmp_34116 = private_mem_34102[chunk_sizze_34028 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)] = tmp_34116;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_34117;\n            int64_t eta_p_34118;\n            int64_t eta_p_34121;\n            int64_t eta_p_34122;\n            bool ltid_in_bounds_34124 = slt64(sext_i32_i64(local_tid_34080), num_virt_threads_34030);\n            int32_t skip_threads_34125;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_34124) {\n                    eta_p_34118 = ((volatile __local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)];\n                    if ((local_tid_34080 - squot32(local_tid_34080, 32) * 32) == 0) {\n                        eta_p_34117 = eta_p_34118;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_34125 = 1;\n                while (slt32(skip_threads_34125, 32)) {\n                    bool thread_active_34126 = sle32(skip_threads_34125, local_tid_34080 - squot32(local_tid_34080, 32) * 32) && ltid_in_bounds_34124;\n                    \n                    if (thread_active_34126) {\n                        // read operands\n                        {\n                            eta_p_34117 = ((volatile __local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080) - sext_i32_i64(skip_threads_34125)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_34126) {\n                            int64_t defunc_0_op_res_34119 = add64(eta_p_34117, eta_p_34118);\n                            \n                            eta_p_34117 = defunc_0_op_res_34119;\n                        }\n                    }\n                    i",
                                    "f (sle32(wave_sizze_34082, skip_threads_34125)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_34126) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)] = eta_p_34117;\n                            eta_p_34118 = eta_p_34117;\n                        }\n                    }\n                    if (sle32(wave_sizze_34082, skip_threads_34125)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_34125 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_34080 - squot32(local_tid_34080, 32) * 32) == 31 && ltid_in_bounds_34124) {\n                    ((volatile __local int64_t *) local_mem_34087)[sext_i32_i64(squot32(local_tid_34080, 32))] = eta_p_34117;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_34127;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_34080, 32) == 0 && ltid_in_bounds_34124) {\n                        eta_p_34122 = ((volatile __local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)];\n                        if ((local_tid_34080 - squot32(local_tid_34080, 32) * 32) == 0) {\n                            eta_p_34121 = eta_p_34122;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_34127 = 1;\n                    while (slt32(skip_threads_34127, 32)) {\n                        bool thread_active_3", "4128 = sle32(skip_threads_34127, local_tid_34080 - squot32(local_tid_34080, 32) * 32) && (squot32(local_tid_34080, 32) == 0 && ltid_in_bounds_34124);\n                        \n                        if (thread_active_34128) {\n                            // read operands\n                            {\n                                eta_p_34121 = ((volatile __local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080) - sext_i32_i64(skip_threads_34127)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_34128) {\n                                int64_t defunc_0_op_res_34123 = add64(eta_p_34121, eta_p_34122);\n                                \n                                eta_p_34121 = defunc_0_op_res_34123;\n                            }\n                        }\n                        if (sle32(wave_sizze_34082, skip_threads_34127)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_34128) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)] = eta_p_34121;\n                                eta_p_34122 = eta_p_34121;\n                            }\n                        }\n                        if (sle32(wave_sizze_34082, skip_threads_34127)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_34127 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_34129 = squot32(local_tid_34080, 32) == 0 || !ltid_in_bounds_34124;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_c", "arry_in_34129) {\n                        eta_p_34118 = eta_p_34117;\n                        eta_p_34117 = ((__local int64_t *) local_mem_34087)[sext_i32_i64(squot32(local_tid_34080, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_34129) {\n                        int64_t defunc_0_op_res_34119 = add64(eta_p_34117, eta_p_34118);\n                        \n                        eta_p_34117 = defunc_0_op_res_34119;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_34129) {\n                        ((__local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)] = eta_p_34117;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_34080, 32) == 0 && ltid_in_bounds_34124) {\n                    ((__local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)] = eta_p_34118;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_34080 == 0) {\n                acc_34120 = ((__local int64_t *) local_mem_34087)[segscan_tblock_sizze_33467 - (int64_t) 1];\n            } else {\n                acc_34120 = ((__local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_34130 = (int64_t) 0;\n        block_new_sgm_34131 = sgm_idx_34099 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_34131 && local_tid_34080 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_34055)[dynamic_id_34097] = acc_34120;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_34031)[dynamic_id_340",
                                    "97] = (int8_t) 2;\n                acc_34120 = (int64_t) 0;\n            }\n            if (!block_new_sgm_34131 && slt32(local_tid_34080, wave_sizze_34082)) {\n                if (local_tid_34080 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_34053)[dynamic_id_34097] = acc_34120;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_34031)[dynamic_id_34097] = (int8_t) 1;\n                    \n                    int8_t tmp_34132 = ((volatile __global int8_t *) status_flags_mem_34031)[dynamic_id_34097 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_34087)[(int64_t) 0] = tmp_34132;\n                }\n                mem_fence_local();\n                \n                int8_t status_34133 = ((__local int8_t *) local_mem_34087)[(int64_t) 0];\n                \n                if (status_34133 == (int8_t) 2) {\n                    if (local_tid_34080 == 0) {\n                        prefix_34130 = ((volatile __global int64_t *) incprefixes_mem_34055)[dynamic_id_34097 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_34134 = sext_i64_i32(dynamic_id_34097 - sext_i32_i64(wave_sizze_34082));\n                    \n                    while (slt32(wave_sizze_34082 * -1, readOffset_34134)) {\n                        int32_t read_i_34135 = readOffset_34134 + local_tid_34080;\n                        int64_t aggr_34136 = (int64_t) 0;\n                        int8_t flag_34137 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_34135)) {\n                            flag_34137 = ((volatile __global int8_t *) status_flags_mem_34031)[sext_i32_i64(read_i_34135)];\n                            if (flag_34137 == (int8_t) 2) {\n                                aggr_34136 = ((volatile __global int64_t *) incprefixes_mem_34055)[sext_i32_i64(read_i_34135)];\n                            } else if (flag_", "34137 == (int8_t) 1) {\n                                aggr_34136 = ((volatile __global int64_t *) aggregates_mem_34053)[sext_i32_i64(read_i_34135)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_34087)[(int64_t) 4 + sext_i32_i64(local_tid_34080)] = aggr_34136;\n                        ((__local int8_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)] = flag_34137;\n                        flag_34137 = ((__local int8_t *) local_mem_34087)[sext_i32_i64(wave_sizze_34082) - (int64_t) 1];\n                        if (slt8(flag_34137, (int8_t) 2)) {\n                            int8_t flg_x_34141;\n                            int8_t flg_y_34142;\n                            int64_t eta_p_34138;\n                            int64_t eta_p_34139;\n                            int32_t skip_threads_34143;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_34142 = ((volatile __local int8_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)];\n                                eta_p_34139 = ((volatile __local int64_t *) local_mem_34087)[(int64_t) 4 + sext_i32_i64(local_tid_34080)];\n                                if ((local_tid_34080 - squot32(local_tid_34080, 32) * 32) == 0) {\n                                    eta_p_34138 = eta_p_34139;\n                                    flg_x_34141 = flg_y_34142;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_34143 = 1;\n                                while (slt32(skip_threads_34143, 32)) {\n                                    if (sle32(skip_threads_34143, local_tid_34080 - squot32(local_tid_34080, 32) * 32)) {\n                                        // read operands\n                                        {\n           ", "                                 flg_x_34141 = ((volatile __local int8_t *) local_mem_34087)[sext_i32_i64(local_tid_34080) - sext_i32_i64(skip_threads_34143)];\n                                            eta_p_34138 = ((volatile __local int64_t *) local_mem_34087)[(int64_t) 4 + (sext_i32_i64(local_tid_34080) - sext_i32_i64(skip_threads_34143))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_34142 == (int8_t) 2 || flg_y_34142 == (int8_t) 0) {\n                                                flg_x_34141 = flg_y_34142;\n                                                eta_p_34138 = eta_p_34139;\n                                            } else {\n                                                int64_t defunc_0_op_res_34140 = add64(eta_p_34138, eta_p_34139);\n                                                \n                                                eta_p_34138 = defunc_0_op_res_34140;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)] = flg_x_34141;\n                                            flg_y_34142 = flg_x_34141;\n                                            ((volatile __local int64_t *) local_mem_34087)[(int64_t) 4 + sext_i32_i64(local_tid_34080)] = eta_p_34138;\n                                            eta_p_34139 = eta_p_34138;\n                                        }\n                                    }\n                                    skip_threads_34143 *= 2;\n                                }\n                            }\n                        }\n                        flag_34137 = ((__local int8_t *) local_mem_34087)[sext_i32_i64(wave_sizze_34082) ",
                                    "- (int64_t) 1];\n                        aggr_34136 = ((__local int64_t *) local_mem_34087)[(int64_t) 4 + (sext_i32_i64(wave_sizze_34082) - (int64_t) 1)];\n                        if (flag_34137 == (int8_t) 2) {\n                            readOffset_34134 = wave_sizze_34082 * -1;\n                        } else if (flag_34137 == (int8_t) 1) {\n                            readOffset_34134 -= wave_sizze_34082;\n                        }\n                        if (slt8((int8_t) 0, flag_34137)) {\n                            int64_t eta_p_34144 = aggr_34136;\n                            int64_t eta_p_34145 = prefix_34130;\n                            int64_t defunc_0_op_res_34146 = add64(eta_p_34144, eta_p_34145);\n                            \n                            prefix_34130 = defunc_0_op_res_34146;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_34080 == 0) {\n                    if (boundary_34100 == sext_i64_i32(segscan_tblock_sizze_33467 * chunk_sizze_34028)) {\n                        int64_t eta_p_34147 = prefix_34130;\n                        int64_t eta_p_34148 = acc_34120;\n                        int64_t defunc_0_op_res_34149 = add64(eta_p_34147, eta_p_34148);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_34055)[dynamic_id_34097] = defunc_0_op_res_34149;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_34031)[dynamic_id_34097] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_34087)[(int64_t) 4] = prefix_34130;\n                    acc_34120 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_34097 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_34130 = ((__local int64_t *) local_mem_34087)[(int64_t) 4];\n                barrier(CLK_LOCAL_MEM_FENCE);\n           ", " }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_34150;\n            int64_t eta_p_34151;\n            int64_t eta_p_34153 = prefix_34130;\n            int64_t eta_p_34154 = acc_34120;\n            \n            if (slt32(local_tid_34080 * chunk_sizze_32b_34084, boundary_34100) && !block_new_sgm_34131) {\n                int64_t defunc_0_op_res_34155 = add64(eta_p_34153, eta_p_34154);\n                \n                eta_p_34150 = defunc_0_op_res_34155;\n            } else {\n                eta_p_34150 = acc_34120;\n            }\n            \n            int32_t stopping_point_34156 = segsizze_compact_34101 - srem32(local_tid_34080 * chunk_sizze_32b_34084 - 1 + segsizze_compact_34101 - boundary_34100, segsizze_compact_34101);\n            \n            for (int64_t i_34157 = 0; i_34157 < chunk_sizze_34028; i_34157++) {\n                if (slt32(sext_i64_i32(i_34157), stopping_point_34156 - 1)) {\n                    eta_p_34151 = private_mem_34102[i_34157];\n                    \n                    int64_t defunc_0_op_res_34152 = add64(eta_p_34150, eta_p_34151);\n                    \n                    private_mem_34102[i_34157] = defunc_0_op_res_34152;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_34158 = 0; i_34158 < chunk_sizze_34028; i_34158++) {\n                int64_t sharedIdx_34159 = sext_i32_i64(local_tid_34080) * chunk_sizze_34028 + i_34158;\n                int64_t tmp_34160 = private_mem_34102[i_34158];\n                \n                ((__local int64_t *) local_mem_34087)[sharedIdx_34159] = tmp_34160;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34161 = 0; i_34161 < chunk_sizze_34028; i_34161++) {\n                int64_t flat_idx_34162 = thd_offset_34104 + i_34161 * segscan_tblock_sizze_33467;\n                int64_t slice_34163 = nR_23386;\n                int64_t gtid_33471 = flat_id", "x_34162;\n                int64_t remnant_34164 = flat_idx_34162 - gtid_33471;\n                \n                if (slt64(flat_idx_34162, nR_23386)) {\n                    int64_t tmp_34165 = ((__local int64_t *) local_mem_34087)[flat_idx_34162 - block_offset_34098];\n                    \n                    ((__global int64_t *) mem_33836)[gtid_33471] = tmp_34165;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_33467\n    #undef chunk_sizze_34028\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_intzisegscan_33488_dim1, 1, 1)\nvoid inner_SMJ_intzisegscan_33488(__global int *global_failure, int64_t m_32498, int64_t num_tblocks_33485, int64_t num_virt_blocks_34223, int64_t num_virt_threads_34224, __global unsigned char *mem_33844, __global unsigned char *mem_33848, __global unsigned char *mem_33850, __global unsigned char *mem_33852, __global unsigned char *status_flags_mem_34225, __global unsigned char *aggregates_mem_34227, __global unsigned char *incprefixes_mem_34229, __global unsigned char *aggregates_mem_34231, __global unsigned char *incprefixes_mem_34233, __global unsigned char *global_dynid_mem_34235)\n{\n    #define segscan_tblock_sizze_33483 (inner_SMJ_intzisegscan_33488zisegscan_tblock_sizze_33483)\n    #define chunk_sizze_34222 (inner_SMJ_intzisegscan_33488zichunk_sizze_34222)\n    \n    volatile __local unsigned char *local_mem_34247_backing_0 = &shared_mem[0];\n    const int64_t local_mem_34247_backing_0_offset = 0 + (smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_33483, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_33483), smax64(chunk_sizze_34222 * segscan_tblock_sizze_33483 * (int64_t) 8, chunk_sizze_34222 * segscan_tblock_sizze_33483 * (int64_t) 8)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_33483, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_33483), sm",
                                    "ax64(chunk_sizze_34222 * segscan_tblock_sizze_33483 * (int64_t) 8, chunk_sizze_34222 * segscan_tblock_sizze_33483 * (int64_t) 8)), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34238;\n    int32_t tblock_sizze_34241;\n    int32_t wave_sizze_34240;\n    int32_t block_id_34239;\n    int32_t global_tid_34237;\n    int64_t phys_tid_33488;\n    int32_t chunk_sizze_32b_34242;\n    int64_t byte_offsets_34243;\n    int64_t byte_offsets_34244;\n    int64_t warp_byte_offset_34245;\n    int64_t warp_byte_offset_34246;\n    __local unsigned char *local_mem_34247;\n    int64_t trans_arr_len_34248;\n    int64_t phys_block_id_34257;\n    int64_t virtloop_bound_34258;\n    \n    local_tid_34238 = get_local_id(0);\n    tblock_sizze_34241 = get_local_size(0);\n    wave_sizze_34240 = LOCKSTEP_WIDTH;\n    block_id_34239 = get_tblock_id(0);\n    global_tid_34237 = block_id_34239 * tblock_sizze_34241 + local_tid_34238;\n    phys_tid_33488 = sext_i32_i64(global_tid_34237);\n    chunk_sizze_32b_34242 = sext_i64_i32(chunk_sizze_34222);\n    byte_offsets_34243 = segscan_tblock_sizze_33483 * (int64_t) 8;\n    byte_offsets_34244 = sdiv_up64(byte_offsets_34243, (int64_t) 8) * (int64_t) 8 + segscan_tblock_sizze_33483 * (int64_t) 8;\n    warp_byte_offset_34245 = (int64_t) 288;\n    warp_byte_offset_34246 = sdiv_up64(warp_byte_offset_34245, (int64_t) 8) * (int64_t) 8 + (int64_t) 256;\n    // Allocate reusable shared memory\n    { }\n    local_mem_34247 = (__local unsigned char *) local_mem_34247_backing_0;\n    trans_arr_len_34248 = chunk_sizze_34222 * segscan_tblock_sizze_33483;\n    phys_block_id_34257 = get_tblock_id(0);\n    virtloop_bound_34258 = sdiv_up64(num_virt_blocks_34223 - phys_block_id_34257, num_tblocks_33485);\n    for (int64_t virtloop_i_34259 = 0; virtloop_i_34259 < virtloop_bound_34258; virtloop_i_34259++) {\n        int64_t dynamic_id_34260;\n        int64_t block_offset_34261;\n        int64_t sgm_idx_34262;\n        int32_t boundary_34263;\n        int32", "_t segsizze_compact_34264;\n        int64_t private_mem_34265[chunk_sizze_34222];\n        int64_t private_mem_34267[chunk_sizze_34222];\n        int64_t thd_offset_34269;\n        int64_t acc_34295;\n        int64_t acc_34296;\n        int64_t prefix_34309;\n        int64_t prefix_34310;\n        bool block_new_sgm_34311;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_34238 == 0) {\n                dynamic_id_34260 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_34235)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_34247)[(int64_t) 0] = dynamic_id_34260;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_34260 == num_virt_blocks_34223 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_34235)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_34260 = ((__local int32_t *) local_mem_34247)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_34261 = dynamic_id_34260 * chunk_sizze_34222 * segscan_tblock_sizze_33483;\n        sgm_idx_34262 = smod64(block_offset_34261, m_32498);\n        boundary_34263 = sext_i64_i32(smin64(chunk_sizze_34222 * segscan_tblock_sizze_33483, m_32498 - sgm_idx_34262));\n        segsizze_compact_34264 = sext_i64_i32(smin64(chunk_sizze_34222 * segscan_tblock_sizze_33483, m_32498));\n        thd_offset_34269 = block_offset_34261 + sext_i32_i64(local_tid_34238);\n        // Load and map\n        {\n            for (int64_t i_34270 = 0; i_34270 < chunk_sizze_34222; i_34270++) {\n                int64_t virt_tid_34271 = thd_offset_34269 + i_34270 * segscan_tblock_sizze_33483;\n                int64_t slice_34272 = m_32498;\n                int64_t gtid_33487", " = virt_tid_34271;\n                int64_t remnant_34273 = virt_tid_34271 - gtid_33487;\n                \n                if (slt64(virt_tid_34271, m_32498)) {\n                    int64_t x_32733 = ((__global int64_t *) mem_33844)[gtid_33487];\n                    bool lifted_lambda_res_32735 = slt64((int64_t) 1, x_32733);\n                    int64_t defunc_0_f_res_32736 = btoi_bool_i64(lifted_lambda_res_32735);\n                    \n                    ((__global int64_t *) mem_33852)[gtid_33487] = defunc_0_f_res_32736;\n                    private_mem_34265[i_34270] = x_32733;\n                    private_mem_34267[i_34270] = defunc_0_f_res_32736;\n                } else {\n                    private_mem_34265[i_34270] = (int64_t) 0;\n                    private_mem_34267[i_34270] = (int64_t) 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_34274 = 0; i_34274 < chunk_sizze_34222; i_34274++) {\n                int64_t sharedIdx_34275 = sext_i32_i64(local_tid_34238) + i_34274 * segscan_tblock_sizze_33483;\n                int64_t tmp_34276 = private_mem_34265[i_34274];\n                \n                ((__local int64_t *) local_mem_34247)[sharedIdx_34275] = tmp_34276;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34277 = 0; i_34277 < chunk_sizze_34222; i_34277++) {\n                int64_t sharedIdx_34278 = sext_i32_i64(local_tid_34238) * chunk_sizze_34222 + i_34277;\n                int64_t tmp_34279 = ((__local int64_t *) local_mem_34247)[sharedIdx_34278];\n                \n                private_mem_34265[i_34277] = tmp_34279;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34280 = 0; i_34280 < chunk_sizze_34222; i_34280++) {\n                int64_t sharedIdx_34281 = sext_i32_i64(local_tid_34238) + i_34280 * segscan_tblock_sizze_33483;\n                int64_t tmp_34282 = private_mem_34267[i_34280];\n  ",
                                    "              \n                ((__local int64_t *) local_mem_34247)[sharedIdx_34281] = tmp_34282;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34283 = 0; i_34283 < chunk_sizze_34222; i_34283++) {\n                int64_t sharedIdx_34284 = sext_i32_i64(local_tid_34238) * chunk_sizze_34222 + i_34283;\n                int64_t tmp_34285 = ((__local int64_t *) local_mem_34247)[sharedIdx_34284];\n                \n                private_mem_34267[i_34283] = tmp_34285;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_34286 = 0; i_34286 < chunk_sizze_34222 - (int64_t) 1; i_34286++) {\n                int64_t eta_p_32523;\n                int64_t eta_p_32524;\n                \n                eta_p_32523 = private_mem_34265[i_34286];\n                eta_p_32524 = private_mem_34265[i_34286 + (int64_t) 1];\n                \n                int64_t eta_p_32616;\n                int64_t eta_p_32617;\n                \n                eta_p_32616 = private_mem_34267[i_34286];\n                eta_p_32617 = private_mem_34267[i_34286 + (int64_t) 1];\n                \n                int64_t lifted_lambda_res_32525 = add64(eta_p_32523, eta_p_32524);\n                int64_t defunc_0_op_res_32618 = add64(eta_p_32616, eta_p_32617);\n                \n                private_mem_34265[i_34286 + (int64_t) 1] = lifted_lambda_res_32525;\n                private_mem_34267[i_34286 + (int64_t) 1] = defunc_0_op_res_32618;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_34287 = private_mem_34265[chunk_sizze_34222 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)] = tmp_34287;\n            \n            int64_t tmp_34288 = private_mem_34267[chunk_sizze_34222 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_", "i32_i64(local_tid_34238)] = tmp_34288;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_34289;\n            int64_t eta_p_34290;\n            int64_t eta_p_34291;\n            int64_t eta_p_34292;\n            int64_t eta_p_34297;\n            int64_t eta_p_34298;\n            int64_t eta_p_34299;\n            int64_t eta_p_34300;\n            bool ltid_in_bounds_34303 = slt64(sext_i32_i64(local_tid_34238), num_virt_threads_34224);\n            int32_t skip_threads_34304;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_34303) {\n                    eta_p_34291 = ((volatile __local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)];\n                    eta_p_34292 = ((volatile __local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(local_tid_34238)];\n                    if ((local_tid_34238 - squot32(local_tid_34238, 32) * 32) == 0) {\n                        eta_p_34289 = eta_p_34291;\n                        eta_p_34290 = eta_p_34292;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_34304 = 1;\n                while (slt32(skip_threads_34304, 32)) {\n                    bool thread_active_34305 = sle32(skip_threads_34304, local_tid_34238 - squot32(local_tid_34238, 32) * 32) && ltid_in_bounds_34303;\n                    \n                    if (thread_active_34305) {\n                        // read operands\n                        {\n                            eta_p_34289 = ((volatile __local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238) - sext_i32_i64(skip_threads_34304)];\n                            eta_p_34290 = ((volatile __local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + (sext_i32_i64(local_tid_34238) - sext_i32_i64(skip_threads_34304))];\n             ", "           }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_34305) {\n                            int64_t lifted_lambda_res_34293 = add64(eta_p_34289, eta_p_34291);\n                            int64_t defunc_0_op_res_34294 = add64(eta_p_34290, eta_p_34292);\n                            \n                            eta_p_34289 = lifted_lambda_res_34293;\n                            eta_p_34290 = defunc_0_op_res_34294;\n                        }\n                    }\n                    if (sle32(wave_sizze_34240, skip_threads_34304)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_34305) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)] = eta_p_34289;\n                            eta_p_34291 = eta_p_34289;\n                            ((volatile __local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(local_tid_34238)] = eta_p_34290;\n                            eta_p_34292 = eta_p_34290;\n                        }\n                    }\n                    if (sle32(wave_sizze_34240, skip_threads_34304)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_34304 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_34238 - squot32(local_tid_34238, 32) * 32) == 31 && ltid_in_bounds_34303) {\n                    ((volatile __local int64_t *) local_mem_34247)[sext_i32_i64(squot32(local_tid_34238, 32))] = eta_p_34289;\n                    ((volatile __local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(squot32(local_tid_34238, 32))] = eta_p_3429",
                                    "0;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_34306;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_34238, 32) == 0 && ltid_in_bounds_34303) {\n                        eta_p_34299 = ((volatile __local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)];\n                        eta_p_34300 = ((volatile __local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(local_tid_34238)];\n                        if ((local_tid_34238 - squot32(local_tid_34238, 32) * 32) == 0) {\n                            eta_p_34297 = eta_p_34299;\n                            eta_p_34298 = eta_p_34300;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_34306 = 1;\n                    while (slt32(skip_threads_34306, 32)) {\n                        bool thread_active_34307 = sle32(skip_threads_34306, local_tid_34238 - squot32(local_tid_34238, 32) * 32) && (squot32(local_tid_34238, 32) == 0 && ltid_in_bounds_34303);\n                        \n                        if (thread_active_34307) {\n                            // read operands\n                            {\n                                eta_p_34297 = ((volatile __local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238) - sext_i32_i64(skip_threads_34306)];\n                                eta_p_34298 = ((volatile __local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + (sext_i32_i64(local_tid_34238) - sext_i32_i64(skip_threads_34306))];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (threa", "d_active_34307) {\n                                int64_t lifted_lambda_res_34301 = add64(eta_p_34297, eta_p_34299);\n                                int64_t defunc_0_op_res_34302 = add64(eta_p_34298, eta_p_34300);\n                                \n                                eta_p_34297 = lifted_lambda_res_34301;\n                                eta_p_34298 = defunc_0_op_res_34302;\n                            }\n                        }\n                        if (sle32(wave_sizze_34240, skip_threads_34306)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_34307) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)] = eta_p_34297;\n                                eta_p_34299 = eta_p_34297;\n                                ((volatile __local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(local_tid_34238)] = eta_p_34298;\n                                eta_p_34300 = eta_p_34298;\n                            }\n                        }\n                        if (sle32(wave_sizze_34240, skip_threads_34306)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_34306 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_34308 = squot32(local_tid_34238, 32) == 0 || !ltid_in_bounds_34303;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_34308) {\n                        eta_p_34291 = eta_p_34289;\n                        eta_p_34292 = eta_p_34290;\n                        eta_p_34289 = ((__local int64_t *) local_mem_34247)[sext_i32_i64(squot32(local_tid_34", "238, 32)) - (int64_t) 1];\n                        eta_p_34290 = ((__local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + (sext_i32_i64(squot32(local_tid_34238, 32)) - (int64_t) 1)];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_34308) {\n                        int64_t lifted_lambda_res_34293 = add64(eta_p_34289, eta_p_34291);\n                        int64_t defunc_0_op_res_34294 = add64(eta_p_34290, eta_p_34292);\n                        \n                        eta_p_34289 = lifted_lambda_res_34293;\n                        eta_p_34290 = defunc_0_op_res_34294;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_34308) {\n                        ((__local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)] = eta_p_34289;\n                        ((__local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(local_tid_34238)] = eta_p_34290;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_34238, 32) == 0 && ltid_in_bounds_34303) {\n                    ((__local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)] = eta_p_34291;\n                    ((__local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(local_tid_34238)] = eta_p_34292;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_34238 == 0) {\n                acc_34295 = ((__local int64_t *) local_mem_34247)[segscan_tblock_sizze_33483 - (int64_t) 1];\n                acc_34296 = ((__local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + (segscan_tblock_sizze_33483 - (int64_t) 1)];\n        ",
                                    "    } else {\n                acc_34295 = ((__local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238) - (int64_t) 1];\n                acc_34296 = ((__local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + (sext_i32_i64(local_tid_34238) - (int64_t) 1)];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_34309 = (int64_t) 0;\n        prefix_34310 = (int64_t) 0;\n        block_new_sgm_34311 = sgm_idx_34262 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_34311 && local_tid_34238 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_34229)[dynamic_id_34260] = acc_34295;\n                ((volatile __global int64_t *) incprefixes_mem_34233)[dynamic_id_34260] = acc_34296;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_34225)[dynamic_id_34260] = (int8_t) 2;\n                acc_34295 = (int64_t) 0;\n                acc_34296 = (int64_t) 0;\n            }\n            if (!block_new_sgm_34311 && slt32(local_tid_34238, wave_sizze_34240)) {\n                if (local_tid_34238 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_34227)[dynamic_id_34260] = acc_34295;\n                    ((volatile __global int64_t *) aggregates_mem_34231)[dynamic_id_34260] = acc_34296;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_34225)[dynamic_id_34260] = (int8_t) 1;\n                    \n                    int8_t tmp_34312 = ((volatile __global int8_t *) status_flags_mem_34225)[dynamic_id_34260 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_34247)[(int64_t) 0] = tmp_34312;\n                }\n                mem_fence_local();\n                \n                int8_t status_34313 = ((__local int8_t *) local_mem_34247)[(int64_t) 0];\n                \n                if (status_34313 == (int8_t) 2) {\n               ", "     if (local_tid_34238 == 0) {\n                        prefix_34309 = ((volatile __global int64_t *) incprefixes_mem_34229)[dynamic_id_34260 - (int64_t) 1];\n                        prefix_34310 = ((volatile __global int64_t *) incprefixes_mem_34233)[dynamic_id_34260 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_34314 = sext_i64_i32(dynamic_id_34260 - sext_i32_i64(wave_sizze_34240));\n                    \n                    while (slt32(wave_sizze_34240 * -1, readOffset_34314)) {\n                        int32_t read_i_34315 = readOffset_34314 + local_tid_34238;\n                        int64_t aggr_34316 = (int64_t) 0;\n                        int64_t aggr_34317 = (int64_t) 0;\n                        int8_t flag_34318 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_34315)) {\n                            flag_34318 = ((volatile __global int8_t *) status_flags_mem_34225)[sext_i32_i64(read_i_34315)];\n                            if (flag_34318 == (int8_t) 2) {\n                                aggr_34316 = ((volatile __global int64_t *) incprefixes_mem_34229)[sext_i32_i64(read_i_34315)];\n                                aggr_34317 = ((volatile __global int64_t *) incprefixes_mem_34233)[sext_i32_i64(read_i_34315)];\n                            } else if (flag_34318 == (int8_t) 1) {\n                                aggr_34316 = ((volatile __global int64_t *) aggregates_mem_34227)[sext_i32_i64(read_i_34315)];\n                                aggr_34317 = ((volatile __global int64_t *) aggregates_mem_34231)[sext_i32_i64(read_i_34315)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_34247)[(int64_t) 4 + sext_i32_i64(local_tid_34238)] = aggr_34316;\n                        ((__local int64_t *) local_mem_34247)[squot64(warp_byte_offset_34245, (int64_t) 8) + sext_i32_i64(local_tid_34238)] = aggr_34317;\n                        ((__loca", "l int8_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)] = flag_34318;\n                        flag_34318 = ((__local int8_t *) local_mem_34247)[sext_i32_i64(wave_sizze_34240) - (int64_t) 1];\n                        if (slt8(flag_34318, (int8_t) 2)) {\n                            int8_t flg_x_34325;\n                            int8_t flg_y_34326;\n                            int64_t eta_p_34319;\n                            int64_t eta_p_34320;\n                            int64_t eta_p_34321;\n                            int64_t eta_p_34322;\n                            int32_t skip_threads_34327;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_34326 = ((volatile __local int8_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)];\n                                eta_p_34321 = ((volatile __local int64_t *) local_mem_34247)[(int64_t) 4 + sext_i32_i64(local_tid_34238)];\n                                eta_p_34322 = ((volatile __local int64_t *) local_mem_34247)[squot64(warp_byte_offset_34245, (int64_t) 8) + sext_i32_i64(local_tid_34238)];\n                                if ((local_tid_34238 - squot32(local_tid_34238, 32) * 32) == 0) {\n                                    eta_p_34319 = eta_p_34321;\n                                    eta_p_34320 = eta_p_34322;\n                                    flg_x_34325 = flg_y_34326;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_34327 = 1;\n                                while (slt32(skip_threads_34327, 32)) {\n                                    if (sle32(skip_threads_34327, local_tid_34238 - squot32(local_tid_34238, 32) * 32)) {\n                                        // read operands\n                                        {\n                                     ",
                                    "       flg_x_34325 = ((volatile __local int8_t *) local_mem_34247)[sext_i32_i64(local_tid_34238) - sext_i32_i64(skip_threads_34327)];\n                                            eta_p_34319 = ((volatile __local int64_t *) local_mem_34247)[(int64_t) 4 + (sext_i32_i64(local_tid_34238) - sext_i32_i64(skip_threads_34327))];\n                                            eta_p_34320 = ((volatile __local int64_t *) local_mem_34247)[squot64(warp_byte_offset_34245, (int64_t) 8) + (sext_i32_i64(local_tid_34238) - sext_i32_i64(skip_threads_34327))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_34326 == (int8_t) 2 || flg_y_34326 == (int8_t) 0) {\n                                                flg_x_34325 = flg_y_34326;\n                                                eta_p_34319 = eta_p_34321;\n                                                eta_p_34320 = eta_p_34322;\n                                            } else {\n                                                int64_t lifted_lambda_res_34323 = add64(eta_p_34319, eta_p_34321);\n                                                int64_t defunc_0_op_res_34324 = add64(eta_p_34320, eta_p_34322);\n                                                \n                                                eta_p_34319 = lifted_lambda_res_34323;\n                                                eta_p_34320 = defunc_0_op_res_34324;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)] = flg_x_34325;\n                                            flg_y_34326 = flg_x_34325;\n                                            ((volatile __local int64_t *) local_mem_34", "247)[(int64_t) 4 + sext_i32_i64(local_tid_34238)] = eta_p_34319;\n                                            eta_p_34321 = eta_p_34319;\n                                            ((volatile __local int64_t *) local_mem_34247)[squot64(warp_byte_offset_34245, (int64_t) 8) + sext_i32_i64(local_tid_34238)] = eta_p_34320;\n                                            eta_p_34322 = eta_p_34320;\n                                        }\n                                    }\n                                    skip_threads_34327 *= 2;\n                                }\n                            }\n                        }\n                        flag_34318 = ((__local int8_t *) local_mem_34247)[sext_i32_i64(wave_sizze_34240) - (int64_t) 1];\n                        aggr_34316 = ((__local int64_t *) local_mem_34247)[(int64_t) 4 + (sext_i32_i64(wave_sizze_34240) - (int64_t) 1)];\n                        aggr_34317 = ((__local int64_t *) local_mem_34247)[squot64(warp_byte_offset_34245, (int64_t) 8) + (sext_i32_i64(wave_sizze_34240) - (int64_t) 1)];\n                        if (flag_34318 == (int8_t) 2) {\n                            readOffset_34314 = wave_sizze_34240 * -1;\n                        } else if (flag_34318 == (int8_t) 1) {\n                            readOffset_34314 -= wave_sizze_34240;\n                        }\n                        if (slt8((int8_t) 0, flag_34318)) {\n                            int64_t eta_p_34328 = aggr_34316;\n                            int64_t eta_p_34329 = aggr_34317;\n                            int64_t eta_p_34330 = prefix_34309;\n                            int64_t eta_p_34331 = prefix_34310;\n                            int64_t lifted_lambda_res_34332 = add64(eta_p_34328, eta_p_34330);\n                            int64_t defunc_0_op_res_34333 = add64(eta_p_34329, eta_p_34331);\n                            \n                            prefix_34309 = lifted_lambda_res_34332;\n                            prefix_34310 = defunc_0_op_res_34333;\n    ", "                    }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_34238 == 0) {\n                    if (boundary_34263 == sext_i64_i32(segscan_tblock_sizze_33483 * chunk_sizze_34222)) {\n                        int64_t eta_p_34334 = prefix_34309;\n                        int64_t eta_p_34335 = prefix_34310;\n                        int64_t eta_p_34336 = acc_34295;\n                        int64_t eta_p_34337 = acc_34296;\n                        int64_t lifted_lambda_res_34338 = add64(eta_p_34334, eta_p_34336);\n                        int64_t defunc_0_op_res_34339 = add64(eta_p_34335, eta_p_34337);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_34229)[dynamic_id_34260] = lifted_lambda_res_34338;\n                        ((volatile __global int64_t *) incprefixes_mem_34233)[dynamic_id_34260] = defunc_0_op_res_34339;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_34225)[dynamic_id_34260] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_34247)[(int64_t) 4] = prefix_34309;\n                    ((__local int64_t *) local_mem_34247)[squot64(warp_byte_offset_34245, (int64_t) 8)] = prefix_34310;\n                    acc_34295 = (int64_t) 0;\n                    acc_34296 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_34260 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_34309 = ((__local int64_t *) local_mem_34247)[(int64_t) 4];\n                prefix_34310 = ((__local int64_t *) local_mem_34247)[squot64(warp_byte_offset_34245, (int64_t) 8)];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_34340;\n            int64_t eta_p_34342;\n            int64_t eta_p_34346 = prefix_34309;\n            int64_t eta_p_34348 = ",
                                    "acc_34295;\n            int64_t eta_p_34341;\n            int64_t eta_p_34343;\n            int64_t eta_p_34347 = prefix_34310;\n            int64_t eta_p_34349 = acc_34296;\n            \n            if (slt32(local_tid_34238 * chunk_sizze_32b_34242, boundary_34263) && !block_new_sgm_34311) {\n                int64_t lifted_lambda_res_34350 = add64(eta_p_34346, eta_p_34348);\n                int64_t defunc_0_op_res_34351 = add64(eta_p_34347, eta_p_34349);\n                \n                eta_p_34340 = lifted_lambda_res_34350;\n                eta_p_34341 = defunc_0_op_res_34351;\n            } else {\n                eta_p_34340 = acc_34295;\n                eta_p_34341 = acc_34296;\n            }\n            \n            int32_t stopping_point_34352 = segsizze_compact_34264 - srem32(local_tid_34238 * chunk_sizze_32b_34242 - 1 + segsizze_compact_34264 - boundary_34263, segsizze_compact_34264);\n            \n            for (int64_t i_34353 = 0; i_34353 < chunk_sizze_34222; i_34353++) {\n                if (slt32(sext_i64_i32(i_34353), stopping_point_34352 - 1)) {\n                    eta_p_34342 = private_mem_34265[i_34353];\n                    eta_p_34343 = private_mem_34267[i_34353];\n                    \n                    int64_t lifted_lambda_res_34344 = add64(eta_p_34340, eta_p_34342);\n                    int64_t defunc_0_op_res_34345 = add64(eta_p_34341, eta_p_34343);\n                    \n                    private_mem_34265[i_34353] = lifted_lambda_res_34344;\n                    private_mem_34267[i_34353] = defunc_0_op_res_34345;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_34354 = 0; i_34354 < chunk_sizze_34222; i_34354++) {\n                int64_t sharedIdx_34355 = sext_i32_i64(local_tid_34238) * chunk_sizze_34222 + i_34354;\n                int64_t tmp_34356 = private_mem_34265[i_34354];\n                \n                ((__local int64_t *) local_mem_342", "47)[sharedIdx_34355] = tmp_34356;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34357 = 0; i_34357 < chunk_sizze_34222; i_34357++) {\n                int64_t flat_idx_34358 = thd_offset_34269 + i_34357 * segscan_tblock_sizze_33483;\n                int64_t slice_34359 = m_32498;\n                int64_t gtid_33487 = flat_idx_34358;\n                int64_t remnant_34360 = flat_idx_34358 - gtid_33487;\n                \n                if (slt64(flat_idx_34358, m_32498)) {\n                    int64_t tmp_34361 = ((__local int64_t *) local_mem_34247)[flat_idx_34358 - block_offset_34261];\n                    \n                    ((__global int64_t *) mem_33848)[gtid_33487] = tmp_34361;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34362 = 0; i_34362 < chunk_sizze_34222; i_34362++) {\n                int64_t sharedIdx_34363 = sext_i32_i64(local_tid_34238) * chunk_sizze_34222 + i_34362;\n                int64_t tmp_34364 = private_mem_34267[i_34362];\n                \n                ((__local int64_t *) local_mem_34247)[sharedIdx_34363] = tmp_34364;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34365 = 0; i_34365 < chunk_sizze_34222; i_34365++) {\n                int64_t flat_idx_34366 = thd_offset_34269 + i_34365 * segscan_tblock_sizze_33483;\n                int64_t slice_34367 = m_32498;\n                int64_t gtid_33487 = flat_idx_34366;\n                int64_t remnant_34368 = flat_idx_34366 - gtid_33487;\n                \n                if (slt64(flat_idx_34366, m_32498)) {\n                    int64_t tmp_34369 = ((__local int64_t *) local_mem_34247)[flat_idx_34366 - block_offset_34261];\n                    \n                    ((__global int64_t *) mem_33850)[gtid_33487] = tmp_34369;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_33483\n    #undef", " chunk_sizze_34222\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_longzigpuseq_34379_dim1, 1, 1)\nvoid inner_SMJ_longzigpuseq_34379(__global int *global_failure, int64_t m_32502, __global unsigned char *mem_33855, __global unsigned char *mem_33857)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34381;\n    int32_t tblock_sizze_34384;\n    int32_t wave_sizze_34383;\n    int32_t block_id_34382;\n    int32_t global_tid_34380;\n    int64_t tid_34379;\n    int64_t x_33807;\n    \n    local_tid_34381 = get_local_id(0);\n    tblock_sizze_34384 = get_local_size(0);\n    wave_sizze_34383 = LOCKSTEP_WIDTH;\n    block_id_34382 = get_tblock_id(0);\n    global_tid_34380 = block_id_34382 * tblock_sizze_34384 + local_tid_34381;\n    tid_34379 = sext_i32_i64(global_tid_34380);\n    x_33807 = ((__global int64_t *) mem_33855)[m_32502];\n    ((__global int64_t *) mem_33857)[(int64_t) 0] = x_33807;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_longzigpuseq_34385_dim1, 1, 1)\nvoid inner_SMJ_longzigpuseq_34385(__global int *global_failure, int64_t m_32502, __global unsigned char *mem_33844, __global unsigned char *mem_33860)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34387;\n    int32_t tblock_sizze_34390;\n    int32_t wave_sizze_34389;\n    int32_t block_id_34388;\n    int32_t global_tid_34386;\n    int64_t tid_34385;\n    int64_t x_33811;\n    \n    local_tid_34387 = get_local_id(0);\n    tblock_sizze_34390 = get_local_size(0);\n    wave_sizze_34389 = LOCKSTEP_WIDTH;\n    block_id_34388 = get_tblock_id(0);\n    global_tid_34386 = block_id_34388 * tblock_sizze_34390 + local_tid_34387;\n    tid_34385 = sext_i32_i64(global_tid_34386);\n    x_33811 = ((__global int64_t *) mem_33844)[m_32502];\n    ((__global int64_t *) mem_33860)[(int64_t) 0] = x_33811;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_longzigpuseq_34391_dim1, 1, 1)\nvoid inner_SMJ_longzigpuseq_34391(__global int *global_failure, __global unsigned char *ext_mem_33858, __global unsigne",
                                    "d char *ext_mem_33861, __global unsigned char *mem_33867)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34393;\n    int32_t tblock_sizze_34396;\n    int32_t wave_sizze_34395;\n    int32_t block_id_34394;\n    int32_t global_tid_34392;\n    int64_t tid_34391;\n    int64_t zp_lhs_33815;\n    int64_t n_pairs_t_res_33816;\n    int64_t n_pairs_t_res_33817;\n    \n    local_tid_34393 = get_local_id(0);\n    tblock_sizze_34396 = get_local_size(0);\n    wave_sizze_34395 = LOCKSTEP_WIDTH;\n    block_id_34394 = get_tblock_id(0);\n    global_tid_34392 = block_id_34394 * tblock_sizze_34396 + local_tid_34393;\n    tid_34391 = sext_i32_i64(global_tid_34392);\n    zp_lhs_33815 = ((__global int64_t *) ext_mem_33858)[(int64_t) 0];\n    n_pairs_t_res_33816 = ((__global int64_t *) ext_mem_33861)[(int64_t) 0];\n    n_pairs_t_res_33817 = add64(zp_lhs_33815, n_pairs_t_res_33816);\n    ((__global int64_t *) mem_33867)[(int64_t) 0] = n_pairs_t_res_33817;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_longzigpuseq_34438_dim1, 1, 1)\nvoid inner_SMJ_longzigpuseq_34438(__global int *global_failure, int64_t loopres_32670, __global unsigned char *mem_param_33901, __global unsigned char *mem_param_33904, __global unsigned char *mem_param_33907, __global unsigned char *mem_33914, __global unsigned char *mem_33915, __global unsigned char *mem_33916)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34440;\n    int32_t tblock_sizze_34443;\n    int32_t wave_sizze_34442;\n    int32_t block_id_34441;\n    int32_t global_tid_34439;\n    int64_t tid_34438;\n    int64_t loopres_33819;\n    int64_t loopres_33821;\n    int64_t loopres_33823;\n    \n    local_tid_34440 = get_local_id(0);\n    tblock_sizze_34443 = get_local_size(0);\n    wave_sizze_34442 = LOCKSTEP_WIDTH;\n    block_id_34441 = get_tblock_id(0);\n    global_tid_34439 = block_id_34441 * tblock_sizze_34443 + local_tid_34440;\n    tid_34438 = sext_i32_i64(global_tid_34439);\n    loopres_33819 = ((__global int64_t *", ") mem_param_33901)[loopres_32670];\n    loopres_33821 = ((__global int64_t *) mem_param_33904)[loopres_32670];\n    loopres_33823 = ((__global int64_t *) mem_param_33907)[loopres_32670];\n    ((__global int64_t *) mem_33914)[(int64_t) 0] = loopres_33819;\n    ((__global int64_t *) mem_33915)[(int64_t) 0] = loopres_33821;\n    ((__global int64_t *) mem_33916)[(int64_t) 0] = loopres_33823;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL\nvoid inner_SMJ_longzireplicate_34445(int64_t loopres_32671, int64_t replicate_n_34444, int64_t virt_num_tblocks_34450, int64_t num_tblocks_34451, __global unsigned char *mem_33914, __global unsigned char *mem_33918)\n{\n    int32_t replicate_ltid_34446;\n    int32_t tblock_sizze_34448;\n    int32_t replicate_gid_34447;\n    int32_t replicate_gtid_34445;\n    int32_t phys_tblock_id_34452;\n    int32_t iterations_34453;\n    \n    replicate_ltid_34446 = get_local_id(0);\n    tblock_sizze_34448 = get_local_size(0);\n    replicate_gid_34447 = get_tblock_id(0);\n    replicate_gtid_34445 = replicate_gid_34447 * tblock_sizze_34448 + replicate_ltid_34446;\n    phys_tblock_id_34452 = get_tblock_id(0);\n    iterations_34453 = sdiv_up32(sext_i64_i32(virt_num_tblocks_34450) - phys_tblock_id_34452, sext_i64_i32(num_tblocks_34451));\n    for (int32_t i_34454 = 0; i_34454 < iterations_34453; i_34454++) {\n        int32_t virt_tblock_id_34455;\n        int64_t global_tid_34456;\n        int64_t slice_34459;\n        int64_t slice_34460;\n        int64_t rep_i_34457;\n        int64_t remnant_34461;\n        int64_t rep_i_34458;\n        int64_t remnant_34462;\n        \n        virt_tblock_id_34455 = phys_tblock_id_34452 + i_34454 * sext_i64_i32(num_tblocks_34451);\n        global_tid_34456 = sext_i32_i64(virt_tblock_id_34455) * sext_i32_i64(tblock_sizze_34448) + sext_i32_i64(replicate_ltid_34446);\n        slice_34459 = (int64_t) 1;\n        slice_34460 = loopres_32671 * slice_34459;\n        rep_i_34457 = squot64(global_tid_34456, slice_34459);\n        remnant_34461 = global_tid_34456 -", " rep_i_34457 * slice_34459;\n        rep_i_34458 = remnant_34461;\n        remnant_34462 = remnant_34461 - rep_i_34458;\n        if (slt64(global_tid_34456, replicate_n_34444)) {\n            int64_t tmp_34463 = ((__global int64_t *) mem_33914)[rep_i_34458];\n            \n            ((__global int64_t *) mem_33918)[rep_i_34457 + rep_i_34458] = tmp_34463;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid inner_SMJ_longzireplicate_34465(int64_t loopres_32671, int64_t replicate_n_34464, int64_t virt_num_tblocks_34470, int64_t num_tblocks_34471, __global unsigned char *mem_33915, __global unsigned char *mem_33920)\n{\n    int32_t replicate_ltid_34466;\n    int32_t tblock_sizze_34468;\n    int32_t replicate_gid_34467;\n    int32_t replicate_gtid_34465;\n    int32_t phys_tblock_id_34472;\n    int32_t iterations_34473;\n    \n    replicate_ltid_34466 = get_local_id(0);\n    tblock_sizze_34468 = get_local_size(0);\n    replicate_gid_34467 = get_tblock_id(0);\n    replicate_gtid_34465 = replicate_gid_34467 * tblock_sizze_34468 + replicate_ltid_34466;\n    phys_tblock_id_34472 = get_tblock_id(0);\n    iterations_34473 = sdiv_up32(sext_i64_i32(virt_num_tblocks_34470) - phys_tblock_id_34472, sext_i64_i32(num_tblocks_34471));\n    for (int32_t i_34474 = 0; i_34474 < iterations_34473; i_34474++) {\n        int32_t virt_tblock_id_34475;\n        int64_t global_tid_34476;\n        int64_t slice_34479;\n        int64_t slice_34480;\n        int64_t rep_i_34477;\n        int64_t remnant_34481;\n        int64_t rep_i_34478;\n        int64_t remnant_34482;\n        \n        virt_tblock_id_34475 = phys_tblock_id_34472 + i_34474 * sext_i64_i32(num_tblocks_34471);\n        global_tid_34476 = sext_i32_i64(virt_tblock_id_34475) * sext_i32_i64(tblock_sizze_34468) + sext_i32_i64(replicate_ltid_34466);\n        slice_34479 = (int64_t) 1;\n        slice_34480 = loopres_32671 * slice_34479;\n        rep_i_34477 = squot64(global_tid_34476, slice_34479)",
                                    ";\n        remnant_34481 = global_tid_34476 - rep_i_34477 * slice_34479;\n        rep_i_34478 = remnant_34481;\n        remnant_34482 = remnant_34481 - rep_i_34478;\n        if (slt64(global_tid_34476, replicate_n_34464)) {\n            int64_t tmp_34483 = ((__global int64_t *) mem_33915)[rep_i_34478];\n            \n            ((__global int64_t *) mem_33920)[rep_i_34477 + rep_i_34478] = tmp_34483;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_longzisegmap_33558_dim1, 1, 1)\nvoid inner_SMJ_longzisegmap_33558(__global int *global_failure, int64_t nR_24982, int64_t offset_R_24986, int64_t m_32498, int64_t num_tblocks_33563, int32_t virt_num_tblocks_34204, __global unsigned char *tR_mem_33832, __global unsigned char *mem_33838, __global unsigned char *mem_33840, __global unsigned char *mem_33842, __global unsigned char *mem_33844)\n{\n    #define segmap_tblock_sizze_33561 (inner_SMJ_longzisegmap_33558zisegmap_tblock_sizze_33561)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34206;\n    int32_t tblock_sizze_34209;\n    int32_t wave_sizze_34208;\n    int32_t block_id_34207;\n    int32_t global_tid_34205;\n    int64_t phys_tid_33558;\n    int32_t phys_tblock_id_34210;\n    int32_t iterations_34211;\n    \n    local_tid_34206 = get_local_id(0);\n    tblock_sizze_34209 = get_local_size(0);\n    wave_sizze_34208 = LOCKSTEP_WIDTH;\n    block_id_34207 = get_tblock_id(0);\n    global_tid_34205 = block_id_34207 * tblock_sizze_34209 + local_tid_34206;\n    phys_tid_33558 = sext_i32_i64(global_tid_34205);\n    phys_tblock_id_34210 = get_tblock_id(0);\n    iterations_34211 = sdiv_up32(virt_num_tblocks_34204 - phys_tblock_id_34210, sext_i64_i32(num_tblocks_33563));\n    for (int32_t i_34212 = 0; i_34212 < iterations_34211; i_34212++) {\n        int32_t virt_tblock_id_34213;\n        int64_t global_tid_34214;\n        int64_t slice_34215;\n        int64_t write_i_33557;\n        int64_t remnant_3", "4216;\n        \n        virt_tblock_id_34213 = phys_tblock_id_34210 + i_34212 * sext_i64_i32(num_tblocks_33563);\n        global_tid_34214 = sext_i32_i64(virt_tblock_id_34213) * segmap_tblock_sizze_33561 + sext_i32_i64(local_tid_34206);\n        slice_34215 = nR_24982;\n        write_i_33557 = global_tid_34214;\n        remnant_34216 = global_tid_34214 - write_i_33557;\n        if (slt64(write_i_33557, nR_24982)) {\n            int64_t write_value_32519;\n            int64_t index_primexp_33806;\n            \n            write_value_32519 = ((__global int64_t *) tR_mem_33832)[write_i_33557];\n            index_primexp_33806 = add64(offset_R_24986, write_i_33557);\n            if (sle64((int64_t) 0, (int64_t) -1) && slt64((int64_t) -1, m_32498)) {\n                ((__global int64_t *) mem_33838)[(int64_t) -1] = write_value_32519;\n            }\n            if (sle64((int64_t) 0, (int64_t) -1) && slt64((int64_t) -1, m_32498)) {\n                ((__global int64_t *) mem_33840)[(int64_t) -1] = index_primexp_33806;\n            }\n            if (sle64((int64_t) 0, (int64_t) -1) && slt64((int64_t) -1, m_32498)) {\n                ((__global int64_t *) mem_33842)[(int64_t) -1] = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, (int64_t) -1) && slt64((int64_t) -1, m_32498)) {\n                ((__global int64_t *) mem_33844)[(int64_t) -1] = (int64_t) 0;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_33561\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_longzisegmap_33592_dim1, 1, 1)\nvoid inner_SMJ_longzisegmap_33592(__global int *global_failure, int64_t m_32498, __global unsigned char *mem_33848, __global unsigned char *mem_33855)\n{\n    #define segmap_tblock_sizze_33588 (inner_SMJ_longzisegmap_33592zisegmap_tblock_sizze_33588)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34372;\n    int32_t tblock_sizze_34375;\n    int32_t wave_sizze_34374;\n    int32_t block_id_3", "4373;\n    int32_t global_tid_34371;\n    int64_t phys_tid_33592;\n    int64_t global_tid_34376;\n    int64_t slice_34377;\n    int64_t gtid_33591;\n    int64_t remnant_34378;\n    \n    local_tid_34372 = get_local_id(0);\n    tblock_sizze_34375 = get_local_size(0);\n    wave_sizze_34374 = LOCKSTEP_WIDTH;\n    block_id_34373 = get_tblock_id(0);\n    global_tid_34371 = block_id_34373 * tblock_sizze_34375 + local_tid_34372;\n    phys_tid_33592 = sext_i32_i64(global_tid_34371);\n    global_tid_34376 = sext_i32_i64(block_id_34373) * segmap_tblock_sizze_33588 + sext_i32_i64(local_tid_34372);\n    slice_34377 = m_32498;\n    gtid_33591 = global_tid_34376;\n    remnant_34378 = global_tid_34376 - gtid_33591;\n    if (slt64(gtid_33591, m_32498)) {\n        int64_t zv_lhs_33594;\n        int64_t tmp_33595;\n        bool cond_33597;\n        int64_t lifted_lambda_res_33598;\n        \n        zv_lhs_33594 = add64((int64_t) -1, gtid_33591);\n        tmp_33595 = smod64(zv_lhs_33594, m_32498);\n        cond_33597 = gtid_33591 == (int64_t) 0;\n        if (cond_33597) {\n            lifted_lambda_res_33598 = (int64_t) 0;\n        } else {\n            int64_t lifted_lambda_res_33596 = ((__global int64_t *) mem_33848)[tmp_33595];\n            \n            lifted_lambda_res_33598 = lifted_lambda_res_33596;\n        }\n        ((__global int64_t *) mem_33855)[gtid_33591] = lifted_lambda_res_33598;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_33588\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_longzisegmap_33600_dim1, 1, 1)\nvoid inner_SMJ_longzisegmap_33600(__global int *global_failure, int64_t m_32498, int64_t lower_bound_32569, int64_t min_res_32571, int64_t j_m_i_32572, int64_t num_tblocks_33605, int32_t virt_num_tblocks_34417, __global unsigned char *mem_33838, __global unsigned char *mem_33840, __global unsigned char *mem_33842, __global unsigned char *mem_33855, __global unsigned char *mem_33884, __global unsigned char *mem_33886, __global unsigned char *mem_33888)\n{\n    #define segmap_tblock_sizze_33603 ",
                                    "(inner_SMJ_longzisegmap_33600zisegmap_tblock_sizze_33603)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34419;\n    int32_t tblock_sizze_34422;\n    int32_t wave_sizze_34421;\n    int32_t block_id_34420;\n    int32_t global_tid_34418;\n    int64_t phys_tid_33600;\n    int32_t phys_tblock_id_34423;\n    int32_t iterations_34424;\n    \n    local_tid_34419 = get_local_id(0);\n    tblock_sizze_34422 = get_local_size(0);\n    wave_sizze_34421 = LOCKSTEP_WIDTH;\n    block_id_34420 = get_tblock_id(0);\n    global_tid_34418 = block_id_34420 * tblock_sizze_34422 + local_tid_34419;\n    phys_tid_33600 = sext_i32_i64(global_tid_34418);\n    phys_tblock_id_34423 = get_tblock_id(0);\n    iterations_34424 = sdiv_up32(virt_num_tblocks_34417 - phys_tblock_id_34423, sext_i64_i32(num_tblocks_33605));\n    for (int32_t i_34425 = 0; i_34425 < iterations_34424; i_34425++) {\n        int32_t virt_tblock_id_34426;\n        int64_t global_tid_34427;\n        int64_t slice_34428;\n        int64_t write_i_33599;\n        int64_t remnant_34429;\n        \n        virt_tblock_id_34426 = phys_tblock_id_34423 + i_34425 * sext_i64_i32(num_tblocks_33605);\n        global_tid_34427 = sext_i32_i64(virt_tblock_id_34426) * segmap_tblock_sizze_33603 + sext_i32_i64(local_tid_34419);\n        slice_34428 = m_32498;\n        write_i_33599 = global_tid_34427;\n        remnant_34429 = global_tid_34427 - write_i_33599;\n        if (slt64(write_i_33599, m_32498)) {\n            int64_t eta_p_32753;\n            int64_t write_value_32754;\n            int64_t write_value_32755;\n            int64_t write_value_32756;\n            bool cond_32757;\n            bool cond_t_res_32758;\n            bool x_32759;\n            int64_t lifted_lambda_res_32760;\n            \n            eta_p_32753 = ((__global int64_t *) mem_33855)[write_i_33599];\n            write_value_32754 = ((__global int64_t *) mem_33838)[write_i_33599];\n            write_value_32755 = ((__global int64_t *) mem_33840)[write_i_33599];\n            write_va", "lue_32756 = ((__global int64_t *) mem_33842)[write_i_33599];\n            cond_32757 = sle64(lower_bound_32569, eta_p_32753);\n            cond_t_res_32758 = slt64(eta_p_32753, min_res_32571);\n            x_32759 = cond_32757 && cond_t_res_32758;\n            if (x_32759) {\n                int64_t lifted_lambda_res_t_res_32784 = sub64(eta_p_32753, lower_bound_32569);\n                \n                lifted_lambda_res_32760 = lifted_lambda_res_t_res_32784;\n            } else {\n                lifted_lambda_res_32760 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_32760) && slt64(lifted_lambda_res_32760, j_m_i_32572)) {\n                ((__global int64_t *) mem_33884)[lifted_lambda_res_32760] = write_value_32754;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_32760) && slt64(lifted_lambda_res_32760, j_m_i_32572)) {\n                ((__global int64_t *) mem_33886)[lifted_lambda_res_32760] = write_value_32755;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_32760) && slt64(lifted_lambda_res_32760, j_m_i_32572)) {\n                ((__global int64_t *) mem_33888)[lifted_lambda_res_32760] = write_value_32756;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_33603\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_longzisegmap_33608_dim1, 1, 1)\nvoid inner_SMJ_longzisegmap_33608(__global int *global_failure, int64_t m_32498, int64_t m_32626, int64_t num_tblocks_33613, int32_t virt_num_tblocks_34399, __global unsigned char *mem_33844, __global unsigned char *mem_33850, __global unsigned char *mem_33852, __global unsigned char *mem_33855, __global unsigned char *mem_33863, __global unsigned char *mem_33865)\n{\n    #define segmap_tblock_sizze_33611 (inner_SMJ_longzisegmap_33608zisegmap_tblock_sizze_33611)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34401;\n    int32_t tblock_sizze_34404;\n    int32_t ", "wave_sizze_34403;\n    int32_t block_id_34402;\n    int32_t global_tid_34400;\n    int64_t phys_tid_33608;\n    int32_t phys_tblock_id_34405;\n    int32_t iterations_34406;\n    \n    local_tid_34401 = get_local_id(0);\n    tblock_sizze_34404 = get_local_size(0);\n    wave_sizze_34403 = LOCKSTEP_WIDTH;\n    block_id_34402 = get_tblock_id(0);\n    global_tid_34400 = block_id_34402 * tblock_sizze_34404 + local_tid_34401;\n    phys_tid_33608 = sext_i32_i64(global_tid_34400);\n    phys_tblock_id_34405 = get_tblock_id(0);\n    iterations_34406 = sdiv_up32(virt_num_tblocks_34399 - phys_tblock_id_34405, sext_i64_i32(num_tblocks_33613));\n    for (int32_t i_34407 = 0; i_34407 < iterations_34406; i_34407++) {\n        int32_t virt_tblock_id_34408;\n        int64_t global_tid_34409;\n        int64_t slice_34410;\n        int64_t write_i_33607;\n        int64_t remnant_34411;\n        \n        virt_tblock_id_34408 = phys_tblock_id_34405 + i_34407 * sext_i64_i32(num_tblocks_33613);\n        global_tid_34409 = sext_i32_i64(virt_tblock_id_34408) * segmap_tblock_sizze_33611 + sext_i32_i64(local_tid_34401);\n        slice_34410 = m_32498;\n        write_i_33607 = global_tid_34409;\n        remnant_34411 = global_tid_34409 - write_i_33607;\n        if (slt64(write_i_33607, m_32498)) {\n            int64_t eta_p_32710;\n            int64_t write_value_32712;\n            int64_t write_value_32713;\n            bool cond_32714;\n            int64_t lifted_lambda_res_32715;\n            \n            eta_p_32710 = ((__global int64_t *) mem_33852)[write_i_33607];\n            write_value_32712 = ((__global int64_t *) mem_33855)[write_i_33607];\n            write_value_32713 = ((__global int64_t *) mem_33844)[write_i_33607];\n            cond_32714 = eta_p_32710 == (int64_t) 1;\n            if (cond_32714) {\n                int64_t eta_p_32711;\n                int64_t lifted_lambda_res_t_res_32789;\n                \n                eta_p_32711 = ((__global int64_t *) mem_33850)[write_i_33607];\n                lifted_lambda_r",
                                    "es_t_res_32789 = sub64(eta_p_32711, (int64_t) 1);\n                lifted_lambda_res_32715 = lifted_lambda_res_t_res_32789;\n            } else {\n                lifted_lambda_res_32715 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_32715) && slt64(lifted_lambda_res_32715, m_32626)) {\n                ((__global int64_t *) mem_33865)[lifted_lambda_res_32715] = write_value_32712;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_32715) && slt64(lifted_lambda_res_32715, m_32626)) {\n                ((__global int64_t *) mem_33863)[lifted_lambda_res_32715] = write_value_32713;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_33611\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_longzisegmap_33630_dim1, 1, 1)\nvoid inner_SMJ_longzisegmap_33630(__global int *global_failure, int64_t loopres_32670, int64_t loopres_32671, __global unsigned char *mem_33913, __global unsigned char *mem_33916)\n{\n    #define segmap_tblock_sizze_33626 (inner_SMJ_longzisegmap_33630zisegmap_tblock_sizze_33626)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34486;\n    int32_t tblock_sizze_34489;\n    int32_t wave_sizze_34488;\n    int32_t block_id_34487;\n    int32_t global_tid_34485;\n    int64_t phys_tid_33630;\n    int64_t global_tid_34490;\n    int64_t slice_34491;\n    int64_t gtid_33629;\n    int64_t remnant_34492;\n    \n    local_tid_34486 = get_local_id(0);\n    tblock_sizze_34489 = get_local_size(0);\n    wave_sizze_34488 = LOCKSTEP_WIDTH;\n    block_id_34487 = get_tblock_id(0);\n    global_tid_34485 = block_id_34487 * tblock_sizze_34489 + local_tid_34486;\n    phys_tid_33630 = sext_i32_i64(global_tid_34485);\n    global_tid_34490 = sext_i32_i64(block_id_34487) * segmap_tblock_sizze_33626 + sext_i32_i64(local_tid_34486);\n    slice_34491 = loopres_32671;\n    gtid_33629 = global_tid_34490;\n    remnant_34492 = global_tid_34490 - gtid_33629;\n    if (s", "lt64(gtid_33629, loopres_32671)) {\n        int64_t loopres_33827;\n        int64_t tmp_33632;\n        \n        loopres_33827 = ((__global int64_t *) mem_33916)[(int64_t) 0];\n        tmp_33632 = add64(gtid_33629, loopres_33827);\n        ((__global int64_t *) mem_33913)[loopres_32670 + gtid_33629] = tmp_33632;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_33626\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_longzisegscan_33556_dim1, 1, 1)\nvoid inner_SMJ_longzisegscan_33556(__global int *global_failure, int64_t nR_24982, int64_t num_tblocks_33553, int64_t num_virt_blocks_34029, int64_t num_virt_threads_34030, __global unsigned char *mem_33836, __global unsigned char *status_flags_mem_34031, __global unsigned char *aggregates_mem_34053, __global unsigned char *incprefixes_mem_34055, __global unsigned char *global_dynid_mem_34057)\n{\n    #define segscan_tblock_sizze_33551 (inner_SMJ_longzisegscan_33556zisegscan_tblock_sizze_33551)\n    #define chunk_sizze_34028 (inner_SMJ_longzisegscan_33556zichunk_sizze_34028)\n    \n    volatile __local unsigned char *local_mem_34087_backing_0 = &shared_mem[0];\n    const int64_t local_mem_34087_backing_0_offset = 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_33551), chunk_sizze_34028 * segscan_tblock_sizze_33551 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_33551), chunk_sizze_34028 * segscan_tblock_sizze_33551 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34080;\n    int32_t tblock_sizze_34083;\n    int32_t wave_sizze_34082;\n    int32_t block_id_34081;\n    int32_t global_tid_34079;\n    int64_t phys_tid_33556;\n    int32_t chunk_sizze_32b_34084;\n    int64_t byte_offsets_34085;\n    int64_t warp_byte_offset_34086;\n    __local unsigned char *local_mem_34087;\n    int64_t trans_arr_len_34088;\n    int64_t phys_block_id_34094;\n    int64_t virtloop_bound_34095;\n    \n    local_tid_34080 ", "= get_local_id(0);\n    tblock_sizze_34083 = get_local_size(0);\n    wave_sizze_34082 = LOCKSTEP_WIDTH;\n    block_id_34081 = get_tblock_id(0);\n    global_tid_34079 = block_id_34081 * tblock_sizze_34083 + local_tid_34080;\n    phys_tid_33556 = sext_i32_i64(global_tid_34079);\n    chunk_sizze_32b_34084 = sext_i64_i32(chunk_sizze_34028);\n    byte_offsets_34085 = segscan_tblock_sizze_33551 * (int64_t) 8;\n    warp_byte_offset_34086 = (int64_t) 288;\n    // Allocate reusable shared memory\n    { }\n    local_mem_34087 = (__local unsigned char *) local_mem_34087_backing_0;\n    trans_arr_len_34088 = chunk_sizze_34028 * segscan_tblock_sizze_33551;\n    phys_block_id_34094 = get_tblock_id(0);\n    virtloop_bound_34095 = sdiv_up64(num_virt_blocks_34029 - phys_block_id_34094, num_tblocks_33553);\n    for (int64_t virtloop_i_34096 = 0; virtloop_i_34096 < virtloop_bound_34095; virtloop_i_34096++) {\n        int64_t dynamic_id_34097;\n        int64_t block_offset_34098;\n        int64_t sgm_idx_34099;\n        int32_t boundary_34100;\n        int32_t segsizze_compact_34101;\n        int64_t private_mem_34102[chunk_sizze_34028];\n        int64_t thd_offset_34104;\n        int64_t acc_34120;\n        int64_t prefix_34130;\n        bool block_new_sgm_34131;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_34080 == 0) {\n                dynamic_id_34097 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_34057)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_34087)[(int64_t) 0] = dynamic_id_34097;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_34097 == num_virt_blocks_34029 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_34057)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n   ",
                                    "     }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_34097 = ((__local int32_t *) local_mem_34087)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_34098 = dynamic_id_34097 * chunk_sizze_34028 * segscan_tblock_sizze_33551;\n        sgm_idx_34099 = smod64(block_offset_34098, nR_24982);\n        boundary_34100 = sext_i64_i32(smin64(chunk_sizze_34028 * segscan_tblock_sizze_33551, nR_24982 - sgm_idx_34099));\n        segsizze_compact_34101 = sext_i64_i32(smin64(chunk_sizze_34028 * segscan_tblock_sizze_33551, nR_24982));\n        thd_offset_34104 = block_offset_34098 + sext_i32_i64(local_tid_34080);\n        // Load and map\n        {\n            for (int64_t i_34105 = 0; i_34105 < chunk_sizze_34028; i_34105++) {\n                int64_t virt_tid_34106 = thd_offset_34104 + i_34105 * segscan_tblock_sizze_33551;\n                int64_t slice_34107 = nR_24982;\n                int64_t gtid_33555 = virt_tid_34106;\n                int64_t remnant_34108 = virt_tid_34106 - gtid_33555;\n                \n                if (slt64(virt_tid_34106, nR_24982)) {\n                    private_mem_34102[i_34105] = (int64_t) 0;\n                } else {\n                    private_mem_34102[i_34105] = (int64_t) 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_34109 = 0; i_34109 < chunk_sizze_34028; i_34109++) {\n                int64_t sharedIdx_34110 = sext_i32_i64(local_tid_34080) + i_34109 * segscan_tblock_sizze_33551;\n                int64_t tmp_34111 = private_mem_34102[i_34109];\n                \n                ((__local int64_t *) local_mem_34087)[sharedIdx_34110] = tmp_34111;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34112 = 0; i_34112 < chunk_sizze_34028; i_34112++) {\n                int64_t sharedIdx_34113 = sext_i32_i64(local_tid_34080) * chunk_sizze_34028 + i_34112;\n                int64_t tmp_34114 = ((__local", " int64_t *) local_mem_34087)[sharedIdx_34113];\n                \n                private_mem_34102[i_34112] = tmp_34114;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_34115 = 0; i_34115 < chunk_sizze_34028 - (int64_t) 1; i_34115++) {\n                int64_t eta_p_32774;\n                int64_t eta_p_32775;\n                \n                eta_p_32774 = private_mem_34102[i_34115];\n                eta_p_32775 = private_mem_34102[i_34115 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_32776 = add64(eta_p_32774, eta_p_32775);\n                \n                private_mem_34102[i_34115 + (int64_t) 1] = defunc_0_op_res_32776;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_34116 = private_mem_34102[chunk_sizze_34028 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)] = tmp_34116;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_34117;\n            int64_t eta_p_34118;\n            int64_t eta_p_34121;\n            int64_t eta_p_34122;\n            bool ltid_in_bounds_34124 = slt64(sext_i32_i64(local_tid_34080), num_virt_threads_34030);\n            int32_t skip_threads_34125;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_34124) {\n                    eta_p_34118 = ((volatile __local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)];\n                    if ((local_tid_34080 - squot32(local_tid_34080, 32) * 32) == 0) {\n                        eta_p_34117 = eta_p_34118;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_34125 = 1;\n                while (slt32(skip_threads_34125, 32)) {\n                    bool threa", "d_active_34126 = sle32(skip_threads_34125, local_tid_34080 - squot32(local_tid_34080, 32) * 32) && ltid_in_bounds_34124;\n                    \n                    if (thread_active_34126) {\n                        // read operands\n                        {\n                            eta_p_34117 = ((volatile __local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080) - sext_i32_i64(skip_threads_34125)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_34126) {\n                            int64_t defunc_0_op_res_34119 = add64(eta_p_34117, eta_p_34118);\n                            \n                            eta_p_34117 = defunc_0_op_res_34119;\n                        }\n                    }\n                    if (sle32(wave_sizze_34082, skip_threads_34125)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_34126) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)] = eta_p_34117;\n                            eta_p_34118 = eta_p_34117;\n                        }\n                    }\n                    if (sle32(wave_sizze_34082, skip_threads_34125)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_34125 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_34080 - squot32(local_tid_34080, 32) * 32) == 31 && ltid_in_bounds_34124) {\n                    ((volatile __local int64_t *) local_mem_34087)[sext_i32_i64(squot32(local_tid_34080, 32))] = eta_p_34117;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which",
                                    " offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_34127;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_34080, 32) == 0 && ltid_in_bounds_34124) {\n                        eta_p_34122 = ((volatile __local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)];\n                        if ((local_tid_34080 - squot32(local_tid_34080, 32) * 32) == 0) {\n                            eta_p_34121 = eta_p_34122;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_34127 = 1;\n                    while (slt32(skip_threads_34127, 32)) {\n                        bool thread_active_34128 = sle32(skip_threads_34127, local_tid_34080 - squot32(local_tid_34080, 32) * 32) && (squot32(local_tid_34080, 32) == 0 && ltid_in_bounds_34124);\n                        \n                        if (thread_active_34128) {\n                            // read operands\n                            {\n                                eta_p_34121 = ((volatile __local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080) - sext_i32_i64(skip_threads_34127)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_34128) {\n                                int64_t defunc_0_op_res_34123 = add64(eta_p_34121, eta_p_34122);\n                                \n                                eta_p_34121 = defunc_0_op_res_34123;\n                            }\n                        }\n                        if (sle32(wave_sizze_34082, skip_threads_34127)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_34128) {\n                            // write result\n                  ", "          {\n                                ((volatile __local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)] = eta_p_34121;\n                                eta_p_34122 = eta_p_34121;\n                            }\n                        }\n                        if (sle32(wave_sizze_34082, skip_threads_34127)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_34127 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_34129 = squot32(local_tid_34080, 32) == 0 || !ltid_in_bounds_34124;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_34129) {\n                        eta_p_34118 = eta_p_34117;\n                        eta_p_34117 = ((__local int64_t *) local_mem_34087)[sext_i32_i64(squot32(local_tid_34080, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_34129) {\n                        int64_t defunc_0_op_res_34119 = add64(eta_p_34117, eta_p_34118);\n                        \n                        eta_p_34117 = defunc_0_op_res_34119;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_34129) {\n                        ((__local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)] = eta_p_34117;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_34080, 32) == 0 && ltid_in_bounds_34124) {\n                    ((__local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)] = eta_p_34118;\n                }\n            }\n            barrier(", "CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_34080 == 0) {\n                acc_34120 = ((__local int64_t *) local_mem_34087)[segscan_tblock_sizze_33551 - (int64_t) 1];\n            } else {\n                acc_34120 = ((__local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_34130 = (int64_t) 0;\n        block_new_sgm_34131 = sgm_idx_34099 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_34131 && local_tid_34080 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_34055)[dynamic_id_34097] = acc_34120;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_34031)[dynamic_id_34097] = (int8_t) 2;\n                acc_34120 = (int64_t) 0;\n            }\n            if (!block_new_sgm_34131 && slt32(local_tid_34080, wave_sizze_34082)) {\n                if (local_tid_34080 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_34053)[dynamic_id_34097] = acc_34120;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_34031)[dynamic_id_34097] = (int8_t) 1;\n                    \n                    int8_t tmp_34132 = ((volatile __global int8_t *) status_flags_mem_34031)[dynamic_id_34097 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_34087)[(int64_t) 0] = tmp_34132;\n                }\n                mem_fence_local();\n                \n                int8_t status_34133 = ((__local int8_t *) local_mem_34087)[(int64_t) 0];\n                \n                if (status_34133 == (int8_t) 2) {\n                    if (local_tid_34080 == 0) {\n                        prefix_34130 = ((volatile __global int64_t *) incprefixes_mem_34055)[dynamic_id_34097 - (int64_t) 1];\n                    }\n                } else {\n            ",
                                    "        int32_t readOffset_34134 = sext_i64_i32(dynamic_id_34097 - sext_i32_i64(wave_sizze_34082));\n                    \n                    while (slt32(wave_sizze_34082 * -1, readOffset_34134)) {\n                        int32_t read_i_34135 = readOffset_34134 + local_tid_34080;\n                        int64_t aggr_34136 = (int64_t) 0;\n                        int8_t flag_34137 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_34135)) {\n                            flag_34137 = ((volatile __global int8_t *) status_flags_mem_34031)[sext_i32_i64(read_i_34135)];\n                            if (flag_34137 == (int8_t) 2) {\n                                aggr_34136 = ((volatile __global int64_t *) incprefixes_mem_34055)[sext_i32_i64(read_i_34135)];\n                            } else if (flag_34137 == (int8_t) 1) {\n                                aggr_34136 = ((volatile __global int64_t *) aggregates_mem_34053)[sext_i32_i64(read_i_34135)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_34087)[(int64_t) 4 + sext_i32_i64(local_tid_34080)] = aggr_34136;\n                        ((__local int8_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)] = flag_34137;\n                        flag_34137 = ((__local int8_t *) local_mem_34087)[sext_i32_i64(wave_sizze_34082) - (int64_t) 1];\n                        if (slt8(flag_34137, (int8_t) 2)) {\n                            int8_t flg_x_34141;\n                            int8_t flg_y_34142;\n                            int64_t eta_p_34138;\n                            int64_t eta_p_34139;\n                            int32_t skip_threads_34143;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_34142 = ((volatile __local int8_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)];\n                                eta_p_34139 = ((volatile __loca", "l int64_t *) local_mem_34087)[(int64_t) 4 + sext_i32_i64(local_tid_34080)];\n                                if ((local_tid_34080 - squot32(local_tid_34080, 32) * 32) == 0) {\n                                    eta_p_34138 = eta_p_34139;\n                                    flg_x_34141 = flg_y_34142;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_34143 = 1;\n                                while (slt32(skip_threads_34143, 32)) {\n                                    if (sle32(skip_threads_34143, local_tid_34080 - squot32(local_tid_34080, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_34141 = ((volatile __local int8_t *) local_mem_34087)[sext_i32_i64(local_tid_34080) - sext_i32_i64(skip_threads_34143)];\n                                            eta_p_34138 = ((volatile __local int64_t *) local_mem_34087)[(int64_t) 4 + (sext_i32_i64(local_tid_34080) - sext_i32_i64(skip_threads_34143))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_34142 == (int8_t) 2 || flg_y_34142 == (int8_t) 0) {\n                                                flg_x_34141 = flg_y_34142;\n                                                eta_p_34138 = eta_p_34139;\n                                            } else {\n                                                int64_t defunc_0_op_res_34140 = add64(eta_p_34138, eta_p_34139);\n                                                \n                                                eta_p_34138 = defunc_0_op_res_34140;\n                                            }\n                                        }\n                                 ", "       // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)] = flg_x_34141;\n                                            flg_y_34142 = flg_x_34141;\n                                            ((volatile __local int64_t *) local_mem_34087)[(int64_t) 4 + sext_i32_i64(local_tid_34080)] = eta_p_34138;\n                                            eta_p_34139 = eta_p_34138;\n                                        }\n                                    }\n                                    skip_threads_34143 *= 2;\n                                }\n                            }\n                        }\n                        flag_34137 = ((__local int8_t *) local_mem_34087)[sext_i32_i64(wave_sizze_34082) - (int64_t) 1];\n                        aggr_34136 = ((__local int64_t *) local_mem_34087)[(int64_t) 4 + (sext_i32_i64(wave_sizze_34082) - (int64_t) 1)];\n                        if (flag_34137 == (int8_t) 2) {\n                            readOffset_34134 = wave_sizze_34082 * -1;\n                        } else if (flag_34137 == (int8_t) 1) {\n                            readOffset_34134 -= wave_sizze_34082;\n                        }\n                        if (slt8((int8_t) 0, flag_34137)) {\n                            int64_t eta_p_34144 = aggr_34136;\n                            int64_t eta_p_34145 = prefix_34130;\n                            int64_t defunc_0_op_res_34146 = add64(eta_p_34144, eta_p_34145);\n                            \n                            prefix_34130 = defunc_0_op_res_34146;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_34080 == 0) {\n                    if (boundary_34100 == sext_i64_i32(segscan_tblock_sizze_33551 * chunk_sizze_34028)) {\n                        int64_t eta_p_34147 = prefix_34130;\n                        int64_t eta_p_3414",
                                    "8 = acc_34120;\n                        int64_t defunc_0_op_res_34149 = add64(eta_p_34147, eta_p_34148);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_34055)[dynamic_id_34097] = defunc_0_op_res_34149;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_34031)[dynamic_id_34097] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_34087)[(int64_t) 4] = prefix_34130;\n                    acc_34120 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_34097 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_34130 = ((__local int64_t *) local_mem_34087)[(int64_t) 4];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_34150;\n            int64_t eta_p_34151;\n            int64_t eta_p_34153 = prefix_34130;\n            int64_t eta_p_34154 = acc_34120;\n            \n            if (slt32(local_tid_34080 * chunk_sizze_32b_34084, boundary_34100) && !block_new_sgm_34131) {\n                int64_t defunc_0_op_res_34155 = add64(eta_p_34153, eta_p_34154);\n                \n                eta_p_34150 = defunc_0_op_res_34155;\n            } else {\n                eta_p_34150 = acc_34120;\n            }\n            \n            int32_t stopping_point_34156 = segsizze_compact_34101 - srem32(local_tid_34080 * chunk_sizze_32b_34084 - 1 + segsizze_compact_34101 - boundary_34100, segsizze_compact_34101);\n            \n            for (int64_t i_34157 = 0; i_34157 < chunk_sizze_34028; i_34157++) {\n                if (slt32(sext_i64_i32(i_34157), stopping_point_34156 - 1)) {\n                    eta_p_34151 = private_mem_34102[i_34157];\n                    \n                    int64_t defunc_0_op_res_34152 = add64(eta_p_34150, eta_p_34151);\n                    \n                    private_mem_34102[i_34157] = def", "unc_0_op_res_34152;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_34158 = 0; i_34158 < chunk_sizze_34028; i_34158++) {\n                int64_t sharedIdx_34159 = sext_i32_i64(local_tid_34080) * chunk_sizze_34028 + i_34158;\n                int64_t tmp_34160 = private_mem_34102[i_34158];\n                \n                ((__local int64_t *) local_mem_34087)[sharedIdx_34159] = tmp_34160;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34161 = 0; i_34161 < chunk_sizze_34028; i_34161++) {\n                int64_t flat_idx_34162 = thd_offset_34104 + i_34161 * segscan_tblock_sizze_33551;\n                int64_t slice_34163 = nR_24982;\n                int64_t gtid_33555 = flat_idx_34162;\n                int64_t remnant_34164 = flat_idx_34162 - gtid_33555;\n                \n                if (slt64(flat_idx_34162, nR_24982)) {\n                    int64_t tmp_34165 = ((__local int64_t *) local_mem_34087)[flat_idx_34162 - block_offset_34098];\n                    \n                    ((__global int64_t *) mem_33836)[gtid_33555] = tmp_34165;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_33551\n    #undef chunk_sizze_34028\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_longzisegscan_33572_dim1, 1, 1)\nvoid inner_SMJ_longzisegscan_33572(__global int *global_failure, int64_t m_32498, int64_t num_tblocks_33569, int64_t num_virt_blocks_34223, int64_t num_virt_threads_34224, __global unsigned char *mem_33844, __global unsigned char *mem_33848, __global unsigned char *mem_33850, __global unsigned char *mem_33852, __global unsigned char *status_flags_mem_34225, __global unsigned char *aggregates_mem_34227, __global unsigned char *incprefixes_mem_34229, __global unsigned char *aggregates_mem_34231, __global unsigned char *incprefixes_mem_34233, __global ", "unsigned char *global_dynid_mem_34235)\n{\n    #define segscan_tblock_sizze_33567 (inner_SMJ_longzisegscan_33572zisegscan_tblock_sizze_33567)\n    #define chunk_sizze_34222 (inner_SMJ_longzisegscan_33572zichunk_sizze_34222)\n    \n    volatile __local unsigned char *local_mem_34247_backing_0 = &shared_mem[0];\n    const int64_t local_mem_34247_backing_0_offset = 0 + (smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_33567, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_33567), smax64(chunk_sizze_34222 * segscan_tblock_sizze_33567 * (int64_t) 8, chunk_sizze_34222 * segscan_tblock_sizze_33567 * (int64_t) 8)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_33567, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_33567), smax64(chunk_sizze_34222 * segscan_tblock_sizze_33567 * (int64_t) 8, chunk_sizze_34222 * segscan_tblock_sizze_33567 * (int64_t) 8)), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34238;\n    int32_t tblock_sizze_34241;\n    int32_t wave_sizze_34240;\n    int32_t block_id_34239;\n    int32_t global_tid_34237;\n    int64_t phys_tid_33572;\n    int32_t chunk_sizze_32b_34242;\n    int64_t byte_offsets_34243;\n    int64_t byte_offsets_34244;\n    int64_t warp_byte_offset_34245;\n    int64_t warp_byte_offset_34246;\n    __local unsigned char *local_mem_34247;\n    int64_t trans_arr_len_34248;\n    int64_t phys_block_id_34257;\n    int64_t virtloop_bound_34258;\n    \n    local_tid_34238 = get_local_id(0);\n    tblock_sizze_34241 = get_local_size(0);\n    wave_sizze_34240 = LOCKSTEP_WIDTH;\n    block_id_34239 = get_tblock_id(0);\n    global_tid_34237 = block_id_34239 * tblock_sizze_34241 + local_tid_34238;\n    phys_tid_33572 = sext_i32_i64(global_tid_34237);\n    chunk_sizze_32b_34242 = sext_i64_i32(chunk_sizze_34222);\n    byte_offsets_34243 = segscan_tblock_sizze_33567 * (int64_t) 8;\n    byte_offsets_34244 = sdiv_up6",
                                    "4(byte_offsets_34243, (int64_t) 8) * (int64_t) 8 + segscan_tblock_sizze_33567 * (int64_t) 8;\n    warp_byte_offset_34245 = (int64_t) 288;\n    warp_byte_offset_34246 = sdiv_up64(warp_byte_offset_34245, (int64_t) 8) * (int64_t) 8 + (int64_t) 256;\n    // Allocate reusable shared memory\n    { }\n    local_mem_34247 = (__local unsigned char *) local_mem_34247_backing_0;\n    trans_arr_len_34248 = chunk_sizze_34222 * segscan_tblock_sizze_33567;\n    phys_block_id_34257 = get_tblock_id(0);\n    virtloop_bound_34258 = sdiv_up64(num_virt_blocks_34223 - phys_block_id_34257, num_tblocks_33569);\n    for (int64_t virtloop_i_34259 = 0; virtloop_i_34259 < virtloop_bound_34258; virtloop_i_34259++) {\n        int64_t dynamic_id_34260;\n        int64_t block_offset_34261;\n        int64_t sgm_idx_34262;\n        int32_t boundary_34263;\n        int32_t segsizze_compact_34264;\n        int64_t private_mem_34265[chunk_sizze_34222];\n        int64_t private_mem_34267[chunk_sizze_34222];\n        int64_t thd_offset_34269;\n        int64_t acc_34295;\n        int64_t acc_34296;\n        int64_t prefix_34309;\n        int64_t prefix_34310;\n        bool block_new_sgm_34311;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_34238 == 0) {\n                dynamic_id_34260 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_34235)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_34247)[(int64_t) 0] = dynamic_id_34260;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_34260 == num_virt_blocks_34223 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_34235)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_34260 = ((__local int32_t", " *) local_mem_34247)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_34261 = dynamic_id_34260 * chunk_sizze_34222 * segscan_tblock_sizze_33567;\n        sgm_idx_34262 = smod64(block_offset_34261, m_32498);\n        boundary_34263 = sext_i64_i32(smin64(chunk_sizze_34222 * segscan_tblock_sizze_33567, m_32498 - sgm_idx_34262));\n        segsizze_compact_34264 = sext_i64_i32(smin64(chunk_sizze_34222 * segscan_tblock_sizze_33567, m_32498));\n        thd_offset_34269 = block_offset_34261 + sext_i32_i64(local_tid_34238);\n        // Load and map\n        {\n            for (int64_t i_34270 = 0; i_34270 < chunk_sizze_34222; i_34270++) {\n                int64_t virt_tid_34271 = thd_offset_34269 + i_34270 * segscan_tblock_sizze_33567;\n                int64_t slice_34272 = m_32498;\n                int64_t gtid_33571 = virt_tid_34271;\n                int64_t remnant_34273 = virt_tid_34271 - gtid_33571;\n                \n                if (slt64(virt_tid_34271, m_32498)) {\n                    int64_t x_32733 = ((__global int64_t *) mem_33844)[gtid_33571];\n                    bool lifted_lambda_res_32735 = slt64((int64_t) 1, x_32733);\n                    int64_t defunc_0_f_res_32736 = btoi_bool_i64(lifted_lambda_res_32735);\n                    \n                    ((__global int64_t *) mem_33852)[gtid_33571] = defunc_0_f_res_32736;\n                    private_mem_34265[i_34270] = x_32733;\n                    private_mem_34267[i_34270] = defunc_0_f_res_32736;\n                } else {\n                    private_mem_34265[i_34270] = (int64_t) 0;\n                    private_mem_34267[i_34270] = (int64_t) 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_34274 = 0; i_34274 < chunk_sizze_34222; i_34274++) {\n                int64_t sharedIdx_34275 = sext_i32_i64(local_tid_34238) + i_34274 * segscan_tblock_sizze_33567;\n                int64_t tmp_34276 = private_mem_3", "4265[i_34274];\n                \n                ((__local int64_t *) local_mem_34247)[sharedIdx_34275] = tmp_34276;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34277 = 0; i_34277 < chunk_sizze_34222; i_34277++) {\n                int64_t sharedIdx_34278 = sext_i32_i64(local_tid_34238) * chunk_sizze_34222 + i_34277;\n                int64_t tmp_34279 = ((__local int64_t *) local_mem_34247)[sharedIdx_34278];\n                \n                private_mem_34265[i_34277] = tmp_34279;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34280 = 0; i_34280 < chunk_sizze_34222; i_34280++) {\n                int64_t sharedIdx_34281 = sext_i32_i64(local_tid_34238) + i_34280 * segscan_tblock_sizze_33567;\n                int64_t tmp_34282 = private_mem_34267[i_34280];\n                \n                ((__local int64_t *) local_mem_34247)[sharedIdx_34281] = tmp_34282;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34283 = 0; i_34283 < chunk_sizze_34222; i_34283++) {\n                int64_t sharedIdx_34284 = sext_i32_i64(local_tid_34238) * chunk_sizze_34222 + i_34283;\n                int64_t tmp_34285 = ((__local int64_t *) local_mem_34247)[sharedIdx_34284];\n                \n                private_mem_34267[i_34283] = tmp_34285;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_34286 = 0; i_34286 < chunk_sizze_34222 - (int64_t) 1; i_34286++) {\n                int64_t eta_p_32523;\n                int64_t eta_p_32524;\n                \n                eta_p_32523 = private_mem_34265[i_34286];\n                eta_p_32524 = private_mem_34265[i_34286 + (int64_t) 1];\n                \n                int64_t eta_p_32616;\n                int64_t eta_p_32617;\n                \n                eta_p_32616 = private_mem_34267[i_34286];\n                eta_p_32617 = private_mem_34267[i_34286 + (int64_t) 1];\n       ",
                                    "         \n                int64_t lifted_lambda_res_32525 = add64(eta_p_32523, eta_p_32524);\n                int64_t defunc_0_op_res_32618 = add64(eta_p_32616, eta_p_32617);\n                \n                private_mem_34265[i_34286 + (int64_t) 1] = lifted_lambda_res_32525;\n                private_mem_34267[i_34286 + (int64_t) 1] = defunc_0_op_res_32618;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_34287 = private_mem_34265[chunk_sizze_34222 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)] = tmp_34287;\n            \n            int64_t tmp_34288 = private_mem_34267[chunk_sizze_34222 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(local_tid_34238)] = tmp_34288;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_34289;\n            int64_t eta_p_34290;\n            int64_t eta_p_34291;\n            int64_t eta_p_34292;\n            int64_t eta_p_34297;\n            int64_t eta_p_34298;\n            int64_t eta_p_34299;\n            int64_t eta_p_34300;\n            bool ltid_in_bounds_34303 = slt64(sext_i32_i64(local_tid_34238), num_virt_threads_34224);\n            int32_t skip_threads_34304;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_34303) {\n                    eta_p_34291 = ((volatile __local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)];\n                    eta_p_34292 = ((volatile __local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(local_tid_34238)];\n                    if ((local_tid_34238 - squot32(local_tid_34238, 32) * 32) == 0) {\n                        eta_p_34289 = eta_p_34291;\n                        eta_p_34290 = eta_p_34292;\n                    }\n                }\n      ", "      }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_34304 = 1;\n                while (slt32(skip_threads_34304, 32)) {\n                    bool thread_active_34305 = sle32(skip_threads_34304, local_tid_34238 - squot32(local_tid_34238, 32) * 32) && ltid_in_bounds_34303;\n                    \n                    if (thread_active_34305) {\n                        // read operands\n                        {\n                            eta_p_34289 = ((volatile __local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238) - sext_i32_i64(skip_threads_34304)];\n                            eta_p_34290 = ((volatile __local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + (sext_i32_i64(local_tid_34238) - sext_i32_i64(skip_threads_34304))];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_34305) {\n                            int64_t lifted_lambda_res_34293 = add64(eta_p_34289, eta_p_34291);\n                            int64_t defunc_0_op_res_34294 = add64(eta_p_34290, eta_p_34292);\n                            \n                            eta_p_34289 = lifted_lambda_res_34293;\n                            eta_p_34290 = defunc_0_op_res_34294;\n                        }\n                    }\n                    if (sle32(wave_sizze_34240, skip_threads_34304)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_34305) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)] = eta_p_34289;\n                            eta_p_34291 = eta_p_34289;\n                            ((volatile __local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(local_tid_34238)] = eta_p_34290;\n                    ", "        eta_p_34292 = eta_p_34290;\n                        }\n                    }\n                    if (sle32(wave_sizze_34240, skip_threads_34304)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_34304 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_34238 - squot32(local_tid_34238, 32) * 32) == 31 && ltid_in_bounds_34303) {\n                    ((volatile __local int64_t *) local_mem_34247)[sext_i32_i64(squot32(local_tid_34238, 32))] = eta_p_34289;\n                    ((volatile __local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(squot32(local_tid_34238, 32))] = eta_p_34290;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_34306;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_34238, 32) == 0 && ltid_in_bounds_34303) {\n                        eta_p_34299 = ((volatile __local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)];\n                        eta_p_34300 = ((volatile __local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(local_tid_34238)];\n                        if ((local_tid_34238 - squot32(local_tid_34238, 32) * 32) == 0) {\n                            eta_p_34297 = eta_p_34299;\n                            eta_p_34298 = eta_p_34300;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_34306 = 1;\n                    while (slt32(skip_threads_34306, 32)) {\n                        bool thread_acti",
                                    "ve_34307 = sle32(skip_threads_34306, local_tid_34238 - squot32(local_tid_34238, 32) * 32) && (squot32(local_tid_34238, 32) == 0 && ltid_in_bounds_34303);\n                        \n                        if (thread_active_34307) {\n                            // read operands\n                            {\n                                eta_p_34297 = ((volatile __local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238) - sext_i32_i64(skip_threads_34306)];\n                                eta_p_34298 = ((volatile __local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + (sext_i32_i64(local_tid_34238) - sext_i32_i64(skip_threads_34306))];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_34307) {\n                                int64_t lifted_lambda_res_34301 = add64(eta_p_34297, eta_p_34299);\n                                int64_t defunc_0_op_res_34302 = add64(eta_p_34298, eta_p_34300);\n                                \n                                eta_p_34297 = lifted_lambda_res_34301;\n                                eta_p_34298 = defunc_0_op_res_34302;\n                            }\n                        }\n                        if (sle32(wave_sizze_34240, skip_threads_34306)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_34307) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)] = eta_p_34297;\n                                eta_p_34299 = eta_p_34297;\n                                ((volatile __local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(local_tid_34238)] = eta_p_34298;\n                                eta_p_34300 = eta_p_34298;\n                            ", "}\n                        }\n                        if (sle32(wave_sizze_34240, skip_threads_34306)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_34306 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_34308 = squot32(local_tid_34238, 32) == 0 || !ltid_in_bounds_34303;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_34308) {\n                        eta_p_34291 = eta_p_34289;\n                        eta_p_34292 = eta_p_34290;\n                        eta_p_34289 = ((__local int64_t *) local_mem_34247)[sext_i32_i64(squot32(local_tid_34238, 32)) - (int64_t) 1];\n                        eta_p_34290 = ((__local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + (sext_i32_i64(squot32(local_tid_34238, 32)) - (int64_t) 1)];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_34308) {\n                        int64_t lifted_lambda_res_34293 = add64(eta_p_34289, eta_p_34291);\n                        int64_t defunc_0_op_res_34294 = add64(eta_p_34290, eta_p_34292);\n                        \n                        eta_p_34289 = lifted_lambda_res_34293;\n                        eta_p_34290 = defunc_0_op_res_34294;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_34308) {\n                        ((__local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)] = eta_p_34289;\n                        ((__local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(local_tid_34238)] = eta_p_34290;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_F", "ENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_34238, 32) == 0 && ltid_in_bounds_34303) {\n                    ((__local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)] = eta_p_34291;\n                    ((__local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(local_tid_34238)] = eta_p_34292;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_34238 == 0) {\n                acc_34295 = ((__local int64_t *) local_mem_34247)[segscan_tblock_sizze_33567 - (int64_t) 1];\n                acc_34296 = ((__local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + (segscan_tblock_sizze_33567 - (int64_t) 1)];\n            } else {\n                acc_34295 = ((__local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238) - (int64_t) 1];\n                acc_34296 = ((__local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + (sext_i32_i64(local_tid_34238) - (int64_t) 1)];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_34309 = (int64_t) 0;\n        prefix_34310 = (int64_t) 0;\n        block_new_sgm_34311 = sgm_idx_34262 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_34311 && local_tid_34238 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_34229)[dynamic_id_34260] = acc_34295;\n                ((volatile __global int64_t *) incprefixes_mem_34233)[dynamic_id_34260] = acc_34296;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_34225)[dynamic_id_34260] = (int8_t) 2;\n                acc_34295 = (int64_t) 0;\n                acc_34296 = (int64_t) 0;\n            }\n            if (!block_new_sgm_34311 && slt32(local_tid_34238, wave_sizze_34240)) {\n                if (local_tid_34238 == 0) {\n                    (",
                                    "(volatile __global int64_t *) aggregates_mem_34227)[dynamic_id_34260] = acc_34295;\n                    ((volatile __global int64_t *) aggregates_mem_34231)[dynamic_id_34260] = acc_34296;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_34225)[dynamic_id_34260] = (int8_t) 1;\n                    \n                    int8_t tmp_34312 = ((volatile __global int8_t *) status_flags_mem_34225)[dynamic_id_34260 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_34247)[(int64_t) 0] = tmp_34312;\n                }\n                mem_fence_local();\n                \n                int8_t status_34313 = ((__local int8_t *) local_mem_34247)[(int64_t) 0];\n                \n                if (status_34313 == (int8_t) 2) {\n                    if (local_tid_34238 == 0) {\n                        prefix_34309 = ((volatile __global int64_t *) incprefixes_mem_34229)[dynamic_id_34260 - (int64_t) 1];\n                        prefix_34310 = ((volatile __global int64_t *) incprefixes_mem_34233)[dynamic_id_34260 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_34314 = sext_i64_i32(dynamic_id_34260 - sext_i32_i64(wave_sizze_34240));\n                    \n                    while (slt32(wave_sizze_34240 * -1, readOffset_34314)) {\n                        int32_t read_i_34315 = readOffset_34314 + local_tid_34238;\n                        int64_t aggr_34316 = (int64_t) 0;\n                        int64_t aggr_34317 = (int64_t) 0;\n                        int8_t flag_34318 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_34315)) {\n                            flag_34318 = ((volatile __global int8_t *) status_flags_mem_34225)[sext_i32_i64(read_i_34315)];\n                            if (flag_34318 == (int8_t) 2) {\n                                aggr_34316 = ((volatile __global int64_t *) incprefixes_mem_34229)[sext_i3", "2_i64(read_i_34315)];\n                                aggr_34317 = ((volatile __global int64_t *) incprefixes_mem_34233)[sext_i32_i64(read_i_34315)];\n                            } else if (flag_34318 == (int8_t) 1) {\n                                aggr_34316 = ((volatile __global int64_t *) aggregates_mem_34227)[sext_i32_i64(read_i_34315)];\n                                aggr_34317 = ((volatile __global int64_t *) aggregates_mem_34231)[sext_i32_i64(read_i_34315)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_34247)[(int64_t) 4 + sext_i32_i64(local_tid_34238)] = aggr_34316;\n                        ((__local int64_t *) local_mem_34247)[squot64(warp_byte_offset_34245, (int64_t) 8) + sext_i32_i64(local_tid_34238)] = aggr_34317;\n                        ((__local int8_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)] = flag_34318;\n                        flag_34318 = ((__local int8_t *) local_mem_34247)[sext_i32_i64(wave_sizze_34240) - (int64_t) 1];\n                        if (slt8(flag_34318, (int8_t) 2)) {\n                            int8_t flg_x_34325;\n                            int8_t flg_y_34326;\n                            int64_t eta_p_34319;\n                            int64_t eta_p_34320;\n                            int64_t eta_p_34321;\n                            int64_t eta_p_34322;\n                            int32_t skip_threads_34327;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_34326 = ((volatile __local int8_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)];\n                                eta_p_34321 = ((volatile __local int64_t *) local_mem_34247)[(int64_t) 4 + sext_i32_i64(local_tid_34238)];\n                                eta_p_34322 = ((volatile __local int64_t *) local_mem_34247)[squot64(warp_byte_offset_34245, (int64_t) 8) + sext_i32_i64(local_tid_34238)];\n         ", "                       if ((local_tid_34238 - squot32(local_tid_34238, 32) * 32) == 0) {\n                                    eta_p_34319 = eta_p_34321;\n                                    eta_p_34320 = eta_p_34322;\n                                    flg_x_34325 = flg_y_34326;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_34327 = 1;\n                                while (slt32(skip_threads_34327, 32)) {\n                                    if (sle32(skip_threads_34327, local_tid_34238 - squot32(local_tid_34238, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_34325 = ((volatile __local int8_t *) local_mem_34247)[sext_i32_i64(local_tid_34238) - sext_i32_i64(skip_threads_34327)];\n                                            eta_p_34319 = ((volatile __local int64_t *) local_mem_34247)[(int64_t) 4 + (sext_i32_i64(local_tid_34238) - sext_i32_i64(skip_threads_34327))];\n                                            eta_p_34320 = ((volatile __local int64_t *) local_mem_34247)[squot64(warp_byte_offset_34245, (int64_t) 8) + (sext_i32_i64(local_tid_34238) - sext_i32_i64(skip_threads_34327))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_34326 == (int8_t) 2 || flg_y_34326 == (int8_t) 0) {\n                                                flg_x_34325 = flg_y_34326;\n                                                eta_p_34319 = eta_p_34321;\n                                                eta_p_34320 = eta_p_34322;\n                                            } else {\n                                                int64_t lifted_lambda_res_34323 = add64(eta_p_",
                                    "34319, eta_p_34321);\n                                                int64_t defunc_0_op_res_34324 = add64(eta_p_34320, eta_p_34322);\n                                                \n                                                eta_p_34319 = lifted_lambda_res_34323;\n                                                eta_p_34320 = defunc_0_op_res_34324;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)] = flg_x_34325;\n                                            flg_y_34326 = flg_x_34325;\n                                            ((volatile __local int64_t *) local_mem_34247)[(int64_t) 4 + sext_i32_i64(local_tid_34238)] = eta_p_34319;\n                                            eta_p_34321 = eta_p_34319;\n                                            ((volatile __local int64_t *) local_mem_34247)[squot64(warp_byte_offset_34245, (int64_t) 8) + sext_i32_i64(local_tid_34238)] = eta_p_34320;\n                                            eta_p_34322 = eta_p_34320;\n                                        }\n                                    }\n                                    skip_threads_34327 *= 2;\n                                }\n                            }\n                        }\n                        flag_34318 = ((__local int8_t *) local_mem_34247)[sext_i32_i64(wave_sizze_34240) - (int64_t) 1];\n                        aggr_34316 = ((__local int64_t *) local_mem_34247)[(int64_t) 4 + (sext_i32_i64(wave_sizze_34240) - (int64_t) 1)];\n                        aggr_34317 = ((__local int64_t *) local_mem_34247)[squot64(warp_byte_offset_34245, (int64_t) 8) + (sext_i32_i64(wave_sizze_34240) - (int64_t) 1)];\n                        if (flag_34318 == (int8_t) 2) {\n                            readOffset_34314 = wave_sizze_", "34240 * -1;\n                        } else if (flag_34318 == (int8_t) 1) {\n                            readOffset_34314 -= wave_sizze_34240;\n                        }\n                        if (slt8((int8_t) 0, flag_34318)) {\n                            int64_t eta_p_34328 = aggr_34316;\n                            int64_t eta_p_34329 = aggr_34317;\n                            int64_t eta_p_34330 = prefix_34309;\n                            int64_t eta_p_34331 = prefix_34310;\n                            int64_t lifted_lambda_res_34332 = add64(eta_p_34328, eta_p_34330);\n                            int64_t defunc_0_op_res_34333 = add64(eta_p_34329, eta_p_34331);\n                            \n                            prefix_34309 = lifted_lambda_res_34332;\n                            prefix_34310 = defunc_0_op_res_34333;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_34238 == 0) {\n                    if (boundary_34263 == sext_i64_i32(segscan_tblock_sizze_33567 * chunk_sizze_34222)) {\n                        int64_t eta_p_34334 = prefix_34309;\n                        int64_t eta_p_34335 = prefix_34310;\n                        int64_t eta_p_34336 = acc_34295;\n                        int64_t eta_p_34337 = acc_34296;\n                        int64_t lifted_lambda_res_34338 = add64(eta_p_34334, eta_p_34336);\n                        int64_t defunc_0_op_res_34339 = add64(eta_p_34335, eta_p_34337);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_34229)[dynamic_id_34260] = lifted_lambda_res_34338;\n                        ((volatile __global int64_t *) incprefixes_mem_34233)[dynamic_id_34260] = defunc_0_op_res_34339;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_34225)[dynamic_id_34260] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_3", "4247)[(int64_t) 4] = prefix_34309;\n                    ((__local int64_t *) local_mem_34247)[squot64(warp_byte_offset_34245, (int64_t) 8)] = prefix_34310;\n                    acc_34295 = (int64_t) 0;\n                    acc_34296 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_34260 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_34309 = ((__local int64_t *) local_mem_34247)[(int64_t) 4];\n                prefix_34310 = ((__local int64_t *) local_mem_34247)[squot64(warp_byte_offset_34245, (int64_t) 8)];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_34340;\n            int64_t eta_p_34342;\n            int64_t eta_p_34346 = prefix_34309;\n            int64_t eta_p_34348 = acc_34295;\n            int64_t eta_p_34341;\n            int64_t eta_p_34343;\n            int64_t eta_p_34347 = prefix_34310;\n            int64_t eta_p_34349 = acc_34296;\n            \n            if (slt32(local_tid_34238 * chunk_sizze_32b_34242, boundary_34263) && !block_new_sgm_34311) {\n                int64_t lifted_lambda_res_34350 = add64(eta_p_34346, eta_p_34348);\n                int64_t defunc_0_op_res_34351 = add64(eta_p_34347, eta_p_34349);\n                \n                eta_p_34340 = lifted_lambda_res_34350;\n                eta_p_34341 = defunc_0_op_res_34351;\n            } else {\n                eta_p_34340 = acc_34295;\n                eta_p_34341 = acc_34296;\n            }\n            \n            int32_t stopping_point_34352 = segsizze_compact_34264 - srem32(local_tid_34238 * chunk_sizze_32b_34242 - 1 + segsizze_compact_34264 - boundary_34263, segsizze_compact_34264);\n            \n            for (int64_t i_34353 = 0; i_34353 < chunk_sizze_34222; i_34353++) {\n                if (slt32(sext_i64_i32(i_34353), stopping_point_34352 - 1)) {\n                    eta_p_34342 = private_mem_34265[i_34353];\n                    eta_p_34343 = priv",
                                    "ate_mem_34267[i_34353];\n                    \n                    int64_t lifted_lambda_res_34344 = add64(eta_p_34340, eta_p_34342);\n                    int64_t defunc_0_op_res_34345 = add64(eta_p_34341, eta_p_34343);\n                    \n                    private_mem_34265[i_34353] = lifted_lambda_res_34344;\n                    private_mem_34267[i_34353] = defunc_0_op_res_34345;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_34354 = 0; i_34354 < chunk_sizze_34222; i_34354++) {\n                int64_t sharedIdx_34355 = sext_i32_i64(local_tid_34238) * chunk_sizze_34222 + i_34354;\n                int64_t tmp_34356 = private_mem_34265[i_34354];\n                \n                ((__local int64_t *) local_mem_34247)[sharedIdx_34355] = tmp_34356;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34357 = 0; i_34357 < chunk_sizze_34222; i_34357++) {\n                int64_t flat_idx_34358 = thd_offset_34269 + i_34357 * segscan_tblock_sizze_33567;\n                int64_t slice_34359 = m_32498;\n                int64_t gtid_33571 = flat_idx_34358;\n                int64_t remnant_34360 = flat_idx_34358 - gtid_33571;\n                \n                if (slt64(flat_idx_34358, m_32498)) {\n                    int64_t tmp_34361 = ((__local int64_t *) local_mem_34247)[flat_idx_34358 - block_offset_34261];\n                    \n                    ((__global int64_t *) mem_33848)[gtid_33571] = tmp_34361;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34362 = 0; i_34362 < chunk_sizze_34222; i_34362++) {\n                int64_t sharedIdx_34363 = sext_i32_i64(local_tid_34238) * chunk_sizze_34222 + i_34362;\n                int64_t tmp_34364 = private_mem_34267[i_34362];\n                \n                ((__local int64_t *) local_mem_34247)[sharedIdx_34363] = tmp_34364;\n            }\n       ", "     barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34365 = 0; i_34365 < chunk_sizze_34222; i_34365++) {\n                int64_t flat_idx_34366 = thd_offset_34269 + i_34365 * segscan_tblock_sizze_33567;\n                int64_t slice_34367 = m_32498;\n                int64_t gtid_33571 = flat_idx_34366;\n                int64_t remnant_34368 = flat_idx_34366 - gtid_33571;\n                \n                if (slt64(flat_idx_34366, m_32498)) {\n                    int64_t tmp_34369 = ((__local int64_t *) local_mem_34247)[flat_idx_34366 - block_offset_34261];\n                    \n                    ((__global int64_t *) mem_33850)[gtid_33571] = tmp_34369;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_33567\n    #undef chunk_sizze_34222\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_shortzigpuseq_34379_dim1, 1, 1)\nvoid inner_SMJ_shortzigpuseq_34379(__global int *global_failure, int64_t m_32502, __global unsigned char *mem_33855, __global unsigned char *mem_33857)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34381;\n    int32_t tblock_sizze_34384;\n    int32_t wave_sizze_34383;\n    int32_t block_id_34382;\n    int32_t global_tid_34380;\n    int64_t tid_34379;\n    int64_t x_33807;\n    \n    local_tid_34381 = get_local_id(0);\n    tblock_sizze_34384 = get_local_size(0);\n    wave_sizze_34383 = LOCKSTEP_WIDTH;\n    block_id_34382 = get_tblock_id(0);\n    global_tid_34380 = block_id_34382 * tblock_sizze_34384 + local_tid_34381;\n    tid_34379 = sext_i32_i64(global_tid_34380);\n    x_33807 = ((__global int64_t *) mem_33855)[m_32502];\n    ((__global int64_t *) mem_33857)[(int64_t) 0] = x_33807;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_shortzigpuseq_34385_dim1, 1, 1)\nvoid inner_SMJ_shortzigpuseq_34385(__global int *global_failure, int64_t m_32502, __global unsigned char *mem_33844, __global unsigned char *mem_33860)\n{\n    if (*global_failure >= ", "0)\n        return;\n    \n    int32_t local_tid_34387;\n    int32_t tblock_sizze_34390;\n    int32_t wave_sizze_34389;\n    int32_t block_id_34388;\n    int32_t global_tid_34386;\n    int64_t tid_34385;\n    int64_t x_33811;\n    \n    local_tid_34387 = get_local_id(0);\n    tblock_sizze_34390 = get_local_size(0);\n    wave_sizze_34389 = LOCKSTEP_WIDTH;\n    block_id_34388 = get_tblock_id(0);\n    global_tid_34386 = block_id_34388 * tblock_sizze_34390 + local_tid_34387;\n    tid_34385 = sext_i32_i64(global_tid_34386);\n    x_33811 = ((__global int64_t *) mem_33844)[m_32502];\n    ((__global int64_t *) mem_33860)[(int64_t) 0] = x_33811;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_shortzigpuseq_34391_dim1, 1, 1)\nvoid inner_SMJ_shortzigpuseq_34391(__global int *global_failure, __global unsigned char *ext_mem_33858, __global unsigned char *ext_mem_33861, __global unsigned char *mem_33867)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34393;\n    int32_t tblock_sizze_34396;\n    int32_t wave_sizze_34395;\n    int32_t block_id_34394;\n    int32_t global_tid_34392;\n    int64_t tid_34391;\n    int64_t zp_lhs_33815;\n    int64_t n_pairs_t_res_33816;\n    int64_t n_pairs_t_res_33817;\n    \n    local_tid_34393 = get_local_id(0);\n    tblock_sizze_34396 = get_local_size(0);\n    wave_sizze_34395 = LOCKSTEP_WIDTH;\n    block_id_34394 = get_tblock_id(0);\n    global_tid_34392 = block_id_34394 * tblock_sizze_34396 + local_tid_34393;\n    tid_34391 = sext_i32_i64(global_tid_34392);\n    zp_lhs_33815 = ((__global int64_t *) ext_mem_33858)[(int64_t) 0];\n    n_pairs_t_res_33816 = ((__global int64_t *) ext_mem_33861)[(int64_t) 0];\n    n_pairs_t_res_33817 = add64(zp_lhs_33815, n_pairs_t_res_33816);\n    ((__global int64_t *) mem_33867)[(int64_t) 0] = n_pairs_t_res_33817;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_shortzigpuseq_34458_dim1, 1, 1)\nvoid inner_SMJ_shortzigpuseq_34458(__global int *global_failure, int64_t loopres_32670, __global unsigned char *",
                                    "mem_param_33901, __global unsigned char *mem_param_33904, __global unsigned char *mem_param_33907, __global unsigned char *mem_33914, __global unsigned char *mem_33915, __global unsigned char *mem_33916)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34460;\n    int32_t tblock_sizze_34463;\n    int32_t wave_sizze_34462;\n    int32_t block_id_34461;\n    int32_t global_tid_34459;\n    int64_t tid_34458;\n    int16_t loopres_33819;\n    int64_t loopres_33821;\n    int64_t loopres_33823;\n    \n    local_tid_34460 = get_local_id(0);\n    tblock_sizze_34463 = get_local_size(0);\n    wave_sizze_34462 = LOCKSTEP_WIDTH;\n    block_id_34461 = get_tblock_id(0);\n    global_tid_34459 = block_id_34461 * tblock_sizze_34463 + local_tid_34460;\n    tid_34458 = sext_i32_i64(global_tid_34459);\n    loopres_33819 = ((__global int16_t *) mem_param_33901)[loopres_32670];\n    loopres_33821 = ((__global int64_t *) mem_param_33904)[loopres_32670];\n    loopres_33823 = ((__global int64_t *) mem_param_33907)[loopres_32670];\n    ((__global int16_t *) mem_33914)[(int64_t) 0] = loopres_33819;\n    ((__global int64_t *) mem_33915)[(int64_t) 0] = loopres_33821;\n    ((__global int64_t *) mem_33916)[(int64_t) 0] = loopres_33823;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL\nvoid inner_SMJ_shortzireplicate_34465(int64_t loopres_32671, int64_t replicate_n_34464, int64_t virt_num_tblocks_34470, int64_t num_tblocks_34471, __global unsigned char *mem_33914, __global unsigned char *mem_33918)\n{\n    int32_t replicate_ltid_34466;\n    int32_t tblock_sizze_34468;\n    int32_t replicate_gid_34467;\n    int32_t replicate_gtid_34465;\n    int32_t phys_tblock_id_34472;\n    int32_t iterations_34473;\n    \n    replicate_ltid_34466 = get_local_id(0);\n    tblock_sizze_34468 = get_local_size(0);\n    replicate_gid_34467 = get_tblock_id(0);\n    replicate_gtid_34465 = replicate_gid_34467 * tblock_sizze_34468 + replicate_ltid_34466;\n    phys_tblock_id_34472 = get_tblock_id(0);\n    iterations_34473 = sdiv_up32(sext", "_i64_i32(virt_num_tblocks_34470) - phys_tblock_id_34472, sext_i64_i32(num_tblocks_34471));\n    for (int32_t i_34474 = 0; i_34474 < iterations_34473; i_34474++) {\n        int32_t virt_tblock_id_34475;\n        int64_t global_tid_34476;\n        int64_t slice_34479;\n        int64_t slice_34480;\n        int64_t rep_i_34477;\n        int64_t remnant_34481;\n        int64_t rep_i_34478;\n        int64_t remnant_34482;\n        \n        virt_tblock_id_34475 = phys_tblock_id_34472 + i_34474 * sext_i64_i32(num_tblocks_34471);\n        global_tid_34476 = sext_i32_i64(virt_tblock_id_34475) * sext_i32_i64(tblock_sizze_34468) + sext_i32_i64(replicate_ltid_34466);\n        slice_34479 = (int64_t) 1;\n        slice_34480 = loopres_32671 * slice_34479;\n        rep_i_34477 = squot64(global_tid_34476, slice_34479);\n        remnant_34481 = global_tid_34476 - rep_i_34477 * slice_34479;\n        rep_i_34478 = remnant_34481;\n        remnant_34482 = remnant_34481 - rep_i_34478;\n        if (slt64(global_tid_34476, replicate_n_34464)) {\n            int16_t tmp_34483 = ((__global int16_t *) mem_33914)[rep_i_34478];\n            \n            ((__global int16_t *) mem_33918)[rep_i_34477 + rep_i_34478] = tmp_34483;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid inner_SMJ_shortzireplicate_34485(int64_t loopres_32671, int64_t replicate_n_34484, int64_t virt_num_tblocks_34490, int64_t num_tblocks_34491, __global unsigned char *mem_33915, __global unsigned char *mem_33920)\n{\n    int32_t replicate_ltid_34486;\n    int32_t tblock_sizze_34488;\n    int32_t replicate_gid_34487;\n    int32_t replicate_gtid_34485;\n    int32_t phys_tblock_id_34492;\n    int32_t iterations_34493;\n    \n    replicate_ltid_34486 = get_local_id(0);\n    tblock_sizze_34488 = get_local_size(0);\n    replicate_gid_34487 = get_tblock_id(0);\n    replicate_gtid_34485 = replicate_gid_34487 * tblock_sizze_34488 + replicate_ltid_34486;\n    phys_tblock_id_34492 = get_tblock", "_id(0);\n    iterations_34493 = sdiv_up32(sext_i64_i32(virt_num_tblocks_34490) - phys_tblock_id_34492, sext_i64_i32(num_tblocks_34491));\n    for (int32_t i_34494 = 0; i_34494 < iterations_34493; i_34494++) {\n        int32_t virt_tblock_id_34495;\n        int64_t global_tid_34496;\n        int64_t slice_34499;\n        int64_t slice_34500;\n        int64_t rep_i_34497;\n        int64_t remnant_34501;\n        int64_t rep_i_34498;\n        int64_t remnant_34502;\n        \n        virt_tblock_id_34495 = phys_tblock_id_34492 + i_34494 * sext_i64_i32(num_tblocks_34491);\n        global_tid_34496 = sext_i32_i64(virt_tblock_id_34495) * sext_i32_i64(tblock_sizze_34488) + sext_i32_i64(replicate_ltid_34486);\n        slice_34499 = (int64_t) 1;\n        slice_34500 = loopres_32671 * slice_34499;\n        rep_i_34497 = squot64(global_tid_34496, slice_34499);\n        remnant_34501 = global_tid_34496 - rep_i_34497 * slice_34499;\n        rep_i_34498 = remnant_34501;\n        remnant_34502 = remnant_34501 - rep_i_34498;\n        if (slt64(global_tid_34496, replicate_n_34484)) {\n            int64_t tmp_34503 = ((__global int64_t *) mem_33915)[rep_i_34498];\n            \n            ((__global int64_t *) mem_33920)[rep_i_34497 + rep_i_34498] = tmp_34503;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_shortzisegmap_33390_dim1, 1, 1)\nvoid inner_SMJ_shortzisegmap_33390(__global int *global_failure, int64_t nR_21781, int64_t offset_R_21785, int64_t m_32498, int64_t num_tblocks_33395, int32_t virt_num_tblocks_34204, __global unsigned char *tR_mem_33832, __global unsigned char *mem_33838, __global unsigned char *mem_33840, __global unsigned char *mem_33842, __global unsigned char *mem_33844)\n{\n    #define segmap_tblock_sizze_33393 (inner_SMJ_shortzisegmap_33390zisegmap_tblock_sizze_33393)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34206;\n    int32_t tblock_sizze_34209;\n    int32_t wave_",
                                    "sizze_34208;\n    int32_t block_id_34207;\n    int32_t global_tid_34205;\n    int64_t phys_tid_33390;\n    int32_t phys_tblock_id_34210;\n    int32_t iterations_34211;\n    \n    local_tid_34206 = get_local_id(0);\n    tblock_sizze_34209 = get_local_size(0);\n    wave_sizze_34208 = LOCKSTEP_WIDTH;\n    block_id_34207 = get_tblock_id(0);\n    global_tid_34205 = block_id_34207 * tblock_sizze_34209 + local_tid_34206;\n    phys_tid_33390 = sext_i32_i64(global_tid_34205);\n    phys_tblock_id_34210 = get_tblock_id(0);\n    iterations_34211 = sdiv_up32(virt_num_tblocks_34204 - phys_tblock_id_34210, sext_i64_i32(num_tblocks_33395));\n    for (int32_t i_34212 = 0; i_34212 < iterations_34211; i_34212++) {\n        int32_t virt_tblock_id_34213;\n        int64_t global_tid_34214;\n        int64_t slice_34215;\n        int64_t write_i_33389;\n        int64_t remnant_34216;\n        \n        virt_tblock_id_34213 = phys_tblock_id_34210 + i_34212 * sext_i64_i32(num_tblocks_33395);\n        global_tid_34214 = sext_i32_i64(virt_tblock_id_34213) * segmap_tblock_sizze_33393 + sext_i32_i64(local_tid_34206);\n        slice_34215 = nR_21781;\n        write_i_33389 = global_tid_34214;\n        remnant_34216 = global_tid_34214 - write_i_33389;\n        if (slt64(write_i_33389, nR_21781)) {\n            int16_t write_value_32519;\n            int64_t index_primexp_33806;\n            \n            write_value_32519 = ((__global int16_t *) tR_mem_33832)[write_i_33389];\n            index_primexp_33806 = add64(offset_R_21785, write_i_33389);\n            if (sle64((int64_t) 0, (int64_t) -1) && slt64((int64_t) -1, m_32498)) {\n                ((__global int16_t *) mem_33838)[(int64_t) -1] = write_value_32519;\n            }\n            if (sle64((int64_t) 0, (int64_t) -1) && slt64((int64_t) -1, m_32498)) {\n                ((__global int64_t *) mem_33840)[(int64_t) -1] = index_primexp_33806;\n            }\n            if (sle64((int64_t) 0, (int64_t) -1) && slt64((int64_t) -1, m_32498)) {\n                ((__global int64_t *) mem", "_33842)[(int64_t) -1] = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, (int64_t) -1) && slt64((int64_t) -1, m_32498)) {\n                ((__global int64_t *) mem_33844)[(int64_t) -1] = (int64_t) 0;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_33393\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_shortzisegmap_33424_dim1, 1, 1)\nvoid inner_SMJ_shortzisegmap_33424(__global int *global_failure, int64_t m_32498, __global unsigned char *mem_33848, __global unsigned char *mem_33855)\n{\n    #define segmap_tblock_sizze_33420 (inner_SMJ_shortzisegmap_33424zisegmap_tblock_sizze_33420)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34372;\n    int32_t tblock_sizze_34375;\n    int32_t wave_sizze_34374;\n    int32_t block_id_34373;\n    int32_t global_tid_34371;\n    int64_t phys_tid_33424;\n    int64_t global_tid_34376;\n    int64_t slice_34377;\n    int64_t gtid_33423;\n    int64_t remnant_34378;\n    \n    local_tid_34372 = get_local_id(0);\n    tblock_sizze_34375 = get_local_size(0);\n    wave_sizze_34374 = LOCKSTEP_WIDTH;\n    block_id_34373 = get_tblock_id(0);\n    global_tid_34371 = block_id_34373 * tblock_sizze_34375 + local_tid_34372;\n    phys_tid_33424 = sext_i32_i64(global_tid_34371);\n    global_tid_34376 = sext_i32_i64(block_id_34373) * segmap_tblock_sizze_33420 + sext_i32_i64(local_tid_34372);\n    slice_34377 = m_32498;\n    gtid_33423 = global_tid_34376;\n    remnant_34378 = global_tid_34376 - gtid_33423;\n    if (slt64(gtid_33423, m_32498)) {\n        int64_t zv_lhs_33426;\n        int64_t tmp_33427;\n        bool cond_33429;\n        int64_t lifted_lambda_res_33430;\n        \n        zv_lhs_33426 = add64((int64_t) -1, gtid_33423);\n        tmp_33427 = smod64(zv_lhs_33426, m_32498);\n        cond_33429 = gtid_33423 == (int64_t) 0;\n        if (cond_33429) {\n            lifted_lambda_res_33430 = (int64_t) 0;\n        } else {\n            int64_t lifted_lambda_res_", "33428 = ((__global int64_t *) mem_33848)[tmp_33427];\n            \n            lifted_lambda_res_33430 = lifted_lambda_res_33428;\n        }\n        ((__global int64_t *) mem_33855)[gtid_33423] = lifted_lambda_res_33430;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_33420\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_shortzisegmap_33432_dim1, 1, 1)\nvoid inner_SMJ_shortzisegmap_33432(__global int *global_failure, int64_t m_32498, int64_t lower_bound_32569, int64_t min_res_32571, int64_t j_m_i_32572, int64_t num_tblocks_33437, int32_t virt_num_tblocks_34437, __global unsigned char *mem_33838, __global unsigned char *mem_33840, __global unsigned char *mem_33842, __global unsigned char *mem_33855, __global unsigned char *mem_33884, __global unsigned char *mem_33886, __global unsigned char *mem_33888)\n{\n    #define segmap_tblock_sizze_33435 (inner_SMJ_shortzisegmap_33432zisegmap_tblock_sizze_33435)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34439;\n    int32_t tblock_sizze_34442;\n    int32_t wave_sizze_34441;\n    int32_t block_id_34440;\n    int32_t global_tid_34438;\n    int64_t phys_tid_33432;\n    int32_t phys_tblock_id_34443;\n    int32_t iterations_34444;\n    \n    local_tid_34439 = get_local_id(0);\n    tblock_sizze_34442 = get_local_size(0);\n    wave_sizze_34441 = LOCKSTEP_WIDTH;\n    block_id_34440 = get_tblock_id(0);\n    global_tid_34438 = block_id_34440 * tblock_sizze_34442 + local_tid_34439;\n    phys_tid_33432 = sext_i32_i64(global_tid_34438);\n    phys_tblock_id_34443 = get_tblock_id(0);\n    iterations_34444 = sdiv_up32(virt_num_tblocks_34437 - phys_tblock_id_34443, sext_i64_i32(num_tblocks_33437));\n    for (int32_t i_34445 = 0; i_34445 < iterations_34444; i_34445++) {\n        int32_t virt_tblock_id_34446;\n        int64_t global_tid_34447;\n        int64_t slice_34448;\n        int64_t write_i_33431;\n        int64_t remnant_34449;\n        \n        virt_tblock_id_34446 = phys_tblock_id_34443 + i_34445 * sext_i64_i32(num_tblocks_33437);\n ",
                                    "       global_tid_34447 = sext_i32_i64(virt_tblock_id_34446) * segmap_tblock_sizze_33435 + sext_i32_i64(local_tid_34439);\n        slice_34448 = m_32498;\n        write_i_33431 = global_tid_34447;\n        remnant_34449 = global_tid_34447 - write_i_33431;\n        if (slt64(write_i_33431, m_32498)) {\n            int64_t eta_p_32753;\n            int16_t write_value_32754;\n            int64_t write_value_32755;\n            int64_t write_value_32756;\n            bool cond_32757;\n            bool cond_t_res_32758;\n            bool x_32759;\n            int64_t lifted_lambda_res_32760;\n            \n            eta_p_32753 = ((__global int64_t *) mem_33855)[write_i_33431];\n            write_value_32754 = ((__global int16_t *) mem_33838)[write_i_33431];\n            write_value_32755 = ((__global int64_t *) mem_33840)[write_i_33431];\n            write_value_32756 = ((__global int64_t *) mem_33842)[write_i_33431];\n            cond_32757 = sle64(lower_bound_32569, eta_p_32753);\n            cond_t_res_32758 = slt64(eta_p_32753, min_res_32571);\n            x_32759 = cond_32757 && cond_t_res_32758;\n            if (x_32759) {\n                int64_t lifted_lambda_res_t_res_32784 = sub64(eta_p_32753, lower_bound_32569);\n                \n                lifted_lambda_res_32760 = lifted_lambda_res_t_res_32784;\n            } else {\n                lifted_lambda_res_32760 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_32760) && slt64(lifted_lambda_res_32760, j_m_i_32572)) {\n                ((__global int16_t *) mem_33884)[lifted_lambda_res_32760] = write_value_32754;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_32760) && slt64(lifted_lambda_res_32760, j_m_i_32572)) {\n                ((__global int64_t *) mem_33886)[lifted_lambda_res_32760] = write_value_32755;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_32760) && slt64(lifted_lambda_res_32760, j_m_i_32572)) {\n                ((__global int64_t *) mem_33888)[li", "fted_lambda_res_32760] = write_value_32756;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_33435\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_shortzisegmap_33440_dim1, 1, 1)\nvoid inner_SMJ_shortzisegmap_33440(__global int *global_failure, int64_t m_32498, int64_t m_32626, int64_t num_tblocks_33445, int32_t virt_num_tblocks_34399, __global unsigned char *mem_33844, __global unsigned char *mem_33850, __global unsigned char *mem_33852, __global unsigned char *mem_33855, __global unsigned char *mem_33863, __global unsigned char *mem_33865)\n{\n    #define segmap_tblock_sizze_33443 (inner_SMJ_shortzisegmap_33440zisegmap_tblock_sizze_33443)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34401;\n    int32_t tblock_sizze_34404;\n    int32_t wave_sizze_34403;\n    int32_t block_id_34402;\n    int32_t global_tid_34400;\n    int64_t phys_tid_33440;\n    int32_t phys_tblock_id_34405;\n    int32_t iterations_34406;\n    \n    local_tid_34401 = get_local_id(0);\n    tblock_sizze_34404 = get_local_size(0);\n    wave_sizze_34403 = LOCKSTEP_WIDTH;\n    block_id_34402 = get_tblock_id(0);\n    global_tid_34400 = block_id_34402 * tblock_sizze_34404 + local_tid_34401;\n    phys_tid_33440 = sext_i32_i64(global_tid_34400);\n    phys_tblock_id_34405 = get_tblock_id(0);\n    iterations_34406 = sdiv_up32(virt_num_tblocks_34399 - phys_tblock_id_34405, sext_i64_i32(num_tblocks_33445));\n    for (int32_t i_34407 = 0; i_34407 < iterations_34406; i_34407++) {\n        int32_t virt_tblock_id_34408;\n        int64_t global_tid_34409;\n        int64_t slice_34410;\n        int64_t write_i_33439;\n        int64_t remnant_34411;\n        \n        virt_tblock_id_34408 = phys_tblock_id_34405 + i_34407 * sext_i64_i32(num_tblocks_33445);\n        global_tid_34409 = sext_i32_i64(virt_tblock_id_34408) * segmap_tblock_sizze_33443 + sext_i32_i64(local_tid_34401);\n        slice_34410 = m_32498;\n        write_i_33439 = gl", "obal_tid_34409;\n        remnant_34411 = global_tid_34409 - write_i_33439;\n        if (slt64(write_i_33439, m_32498)) {\n            int64_t eta_p_32710;\n            int64_t write_value_32712;\n            int64_t write_value_32713;\n            bool cond_32714;\n            int64_t lifted_lambda_res_32715;\n            \n            eta_p_32710 = ((__global int64_t *) mem_33852)[write_i_33439];\n            write_value_32712 = ((__global int64_t *) mem_33855)[write_i_33439];\n            write_value_32713 = ((__global int64_t *) mem_33844)[write_i_33439];\n            cond_32714 = eta_p_32710 == (int64_t) 1;\n            if (cond_32714) {\n                int64_t eta_p_32711;\n                int64_t lifted_lambda_res_t_res_32789;\n                \n                eta_p_32711 = ((__global int64_t *) mem_33850)[write_i_33439];\n                lifted_lambda_res_t_res_32789 = sub64(eta_p_32711, (int64_t) 1);\n                lifted_lambda_res_32715 = lifted_lambda_res_t_res_32789;\n            } else {\n                lifted_lambda_res_32715 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_32715) && slt64(lifted_lambda_res_32715, m_32626)) {\n                ((__global int64_t *) mem_33865)[lifted_lambda_res_32715] = write_value_32712;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_32715) && slt64(lifted_lambda_res_32715, m_32626)) {\n                ((__global int64_t *) mem_33863)[lifted_lambda_res_32715] = write_value_32713;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_33443\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_shortzisegmap_33462_dim1, 1, 1)\nvoid inner_SMJ_shortzisegmap_33462(__global int *global_failure, int64_t loopres_32670, int64_t loopres_32671, __global unsigned char *mem_33913, __global unsigned char *mem_33916)\n{\n    #define segmap_tblock_sizze_33458 (inner_SMJ_shortzisegmap_33462zisegmap_tblock_sizze_33458)\n    if (*glob",
                                    "al_failure >= 0)\n        return;\n    \n    int32_t local_tid_34506;\n    int32_t tblock_sizze_34509;\n    int32_t wave_sizze_34508;\n    int32_t block_id_34507;\n    int32_t global_tid_34505;\n    int64_t phys_tid_33462;\n    int64_t global_tid_34510;\n    int64_t slice_34511;\n    int64_t gtid_33461;\n    int64_t remnant_34512;\n    \n    local_tid_34506 = get_local_id(0);\n    tblock_sizze_34509 = get_local_size(0);\n    wave_sizze_34508 = LOCKSTEP_WIDTH;\n    block_id_34507 = get_tblock_id(0);\n    global_tid_34505 = block_id_34507 * tblock_sizze_34509 + local_tid_34506;\n    phys_tid_33462 = sext_i32_i64(global_tid_34505);\n    global_tid_34510 = sext_i32_i64(block_id_34507) * segmap_tblock_sizze_33458 + sext_i32_i64(local_tid_34506);\n    slice_34511 = loopres_32671;\n    gtid_33461 = global_tid_34510;\n    remnant_34512 = global_tid_34510 - gtid_33461;\n    if (slt64(gtid_33461, loopres_32671)) {\n        int64_t loopres_33827;\n        int64_t tmp_33464;\n        \n        loopres_33827 = ((__global int64_t *) mem_33916)[(int64_t) 0];\n        tmp_33464 = add64(gtid_33461, loopres_33827);\n        ((__global int64_t *) mem_33913)[loopres_32670 + gtid_33461] = tmp_33464;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_33458\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_shortzisegscan_33388_dim1, 1, 1)\nvoid inner_SMJ_shortzisegscan_33388(__global int *global_failure, int64_t nR_21781, int64_t num_tblocks_33385, int64_t num_virt_blocks_34029, int64_t num_virt_threads_34030, __global unsigned char *mem_33836, __global unsigned char *status_flags_mem_34031, __global unsigned char *aggregates_mem_34053, __global unsigned char *incprefixes_mem_34055, __global unsigned char *global_dynid_mem_34057)\n{\n    #define segscan_tblock_sizze_33383 (inner_SMJ_shortzisegscan_33388zisegscan_tblock_sizze_33383)\n    #define chunk_sizze_34028 (inner_SMJ_shortzisegscan_33388zichunk_sizze_34028)\n    \n    volatile __local unsigned char *local_mem_34087_backing_0 = &shared_mem[0];\n    const int64_t local_mem_", "34087_backing_0_offset = 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_33383), chunk_sizze_34028 * segscan_tblock_sizze_33383 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_33383), chunk_sizze_34028 * segscan_tblock_sizze_33383 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34080;\n    int32_t tblock_sizze_34083;\n    int32_t wave_sizze_34082;\n    int32_t block_id_34081;\n    int32_t global_tid_34079;\n    int64_t phys_tid_33388;\n    int32_t chunk_sizze_32b_34084;\n    int64_t byte_offsets_34085;\n    int64_t warp_byte_offset_34086;\n    __local unsigned char *local_mem_34087;\n    int64_t trans_arr_len_34088;\n    int64_t phys_block_id_34094;\n    int64_t virtloop_bound_34095;\n    \n    local_tid_34080 = get_local_id(0);\n    tblock_sizze_34083 = get_local_size(0);\n    wave_sizze_34082 = LOCKSTEP_WIDTH;\n    block_id_34081 = get_tblock_id(0);\n    global_tid_34079 = block_id_34081 * tblock_sizze_34083 + local_tid_34080;\n    phys_tid_33388 = sext_i32_i64(global_tid_34079);\n    chunk_sizze_32b_34084 = sext_i64_i32(chunk_sizze_34028);\n    byte_offsets_34085 = segscan_tblock_sizze_33383 * (int64_t) 8;\n    warp_byte_offset_34086 = (int64_t) 288;\n    // Allocate reusable shared memory\n    { }\n    local_mem_34087 = (__local unsigned char *) local_mem_34087_backing_0;\n    trans_arr_len_34088 = chunk_sizze_34028 * segscan_tblock_sizze_33383;\n    phys_block_id_34094 = get_tblock_id(0);\n    virtloop_bound_34095 = sdiv_up64(num_virt_blocks_34029 - phys_block_id_34094, num_tblocks_33385);\n    for (int64_t virtloop_i_34096 = 0; virtloop_i_34096 < virtloop_bound_34095; virtloop_i_34096++) {\n        int64_t dynamic_id_34097;\n        int64_t block_offset_34098;\n        int64_t sgm_idx_34099;\n        int32_t boundary_34100;\n        int32_t segsizze_compact_34101;\n        int64_t private_mem_34102[chunk_sizze_34028];\n        int64_t thd_of", "fset_34104;\n        int64_t acc_34120;\n        int64_t prefix_34130;\n        bool block_new_sgm_34131;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_34080 == 0) {\n                dynamic_id_34097 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_34057)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_34087)[(int64_t) 0] = dynamic_id_34097;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_34097 == num_virt_blocks_34029 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_34057)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_34097 = ((__local int32_t *) local_mem_34087)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_34098 = dynamic_id_34097 * chunk_sizze_34028 * segscan_tblock_sizze_33383;\n        sgm_idx_34099 = smod64(block_offset_34098, nR_21781);\n        boundary_34100 = sext_i64_i32(smin64(chunk_sizze_34028 * segscan_tblock_sizze_33383, nR_21781 - sgm_idx_34099));\n        segsizze_compact_34101 = sext_i64_i32(smin64(chunk_sizze_34028 * segscan_tblock_sizze_33383, nR_21781));\n        thd_offset_34104 = block_offset_34098 + sext_i32_i64(local_tid_34080);\n        // Load and map\n        {\n            for (int64_t i_34105 = 0; i_34105 < chunk_sizze_34028; i_34105++) {\n                int64_t virt_tid_34106 = thd_offset_34104 + i_34105 * segscan_tblock_sizze_33383;\n                int64_t slice_34107 = nR_21781;\n                int64_t gtid_33387 = virt_tid_34106;\n                int64_t remnant_34108 = virt_tid_34106 - gtid_33387;\n                \n                if (slt64(virt_tid_34106, nR_21781)) {\n                    private_mem_34102[i_34105] = (",
                                    "int64_t) 0;\n                } else {\n                    private_mem_34102[i_34105] = (int64_t) 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_34109 = 0; i_34109 < chunk_sizze_34028; i_34109++) {\n                int64_t sharedIdx_34110 = sext_i32_i64(local_tid_34080) + i_34109 * segscan_tblock_sizze_33383;\n                int64_t tmp_34111 = private_mem_34102[i_34109];\n                \n                ((__local int64_t *) local_mem_34087)[sharedIdx_34110] = tmp_34111;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34112 = 0; i_34112 < chunk_sizze_34028; i_34112++) {\n                int64_t sharedIdx_34113 = sext_i32_i64(local_tid_34080) * chunk_sizze_34028 + i_34112;\n                int64_t tmp_34114 = ((__local int64_t *) local_mem_34087)[sharedIdx_34113];\n                \n                private_mem_34102[i_34112] = tmp_34114;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_34115 = 0; i_34115 < chunk_sizze_34028 - (int64_t) 1; i_34115++) {\n                int64_t eta_p_32774;\n                int64_t eta_p_32775;\n                \n                eta_p_32774 = private_mem_34102[i_34115];\n                eta_p_32775 = private_mem_34102[i_34115 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_32776 = add64(eta_p_32774, eta_p_32775);\n                \n                private_mem_34102[i_34115 + (int64_t) 1] = defunc_0_op_res_32776;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_34116 = private_mem_34102[chunk_sizze_34028 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)] = tmp_34116;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_3411", "7;\n            int64_t eta_p_34118;\n            int64_t eta_p_34121;\n            int64_t eta_p_34122;\n            bool ltid_in_bounds_34124 = slt64(sext_i32_i64(local_tid_34080), num_virt_threads_34030);\n            int32_t skip_threads_34125;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_34124) {\n                    eta_p_34118 = ((volatile __local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)];\n                    if ((local_tid_34080 - squot32(local_tid_34080, 32) * 32) == 0) {\n                        eta_p_34117 = eta_p_34118;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_34125 = 1;\n                while (slt32(skip_threads_34125, 32)) {\n                    bool thread_active_34126 = sle32(skip_threads_34125, local_tid_34080 - squot32(local_tid_34080, 32) * 32) && ltid_in_bounds_34124;\n                    \n                    if (thread_active_34126) {\n                        // read operands\n                        {\n                            eta_p_34117 = ((volatile __local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080) - sext_i32_i64(skip_threads_34125)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_34126) {\n                            int64_t defunc_0_op_res_34119 = add64(eta_p_34117, eta_p_34118);\n                            \n                            eta_p_34117 = defunc_0_op_res_34119;\n                        }\n                    }\n                    if (sle32(wave_sizze_34082, skip_threads_34125)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_34126) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_", "34087)[sext_i32_i64(local_tid_34080)] = eta_p_34117;\n                            eta_p_34118 = eta_p_34117;\n                        }\n                    }\n                    if (sle32(wave_sizze_34082, skip_threads_34125)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_34125 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_34080 - squot32(local_tid_34080, 32) * 32) == 31 && ltid_in_bounds_34124) {\n                    ((volatile __local int64_t *) local_mem_34087)[sext_i32_i64(squot32(local_tid_34080, 32))] = eta_p_34117;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_34127;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_34080, 32) == 0 && ltid_in_bounds_34124) {\n                        eta_p_34122 = ((volatile __local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)];\n                        if ((local_tid_34080 - squot32(local_tid_34080, 32) * 32) == 0) {\n                            eta_p_34121 = eta_p_34122;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_34127 = 1;\n                    while (slt32(skip_threads_34127, 32)) {\n                        bool thread_active_34128 = sle32(skip_threads_34127, local_tid_34080 - squot32(local_tid_34080, 32) * 32) && (squot32(local_tid_34080, 32) == 0 && ltid_in_bounds_34124);\n                        \n                        if (thread_active_34128) {\n                            // read operands\n                            {\n      ",
                                    "                          eta_p_34121 = ((volatile __local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080) - sext_i32_i64(skip_threads_34127)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_34128) {\n                                int64_t defunc_0_op_res_34123 = add64(eta_p_34121, eta_p_34122);\n                                \n                                eta_p_34121 = defunc_0_op_res_34123;\n                            }\n                        }\n                        if (sle32(wave_sizze_34082, skip_threads_34127)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_34128) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)] = eta_p_34121;\n                                eta_p_34122 = eta_p_34121;\n                            }\n                        }\n                        if (sle32(wave_sizze_34082, skip_threads_34127)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_34127 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_34129 = squot32(local_tid_34080, 32) == 0 || !ltid_in_bounds_34124;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_34129) {\n                        eta_p_34118 = eta_p_34117;\n                        eta_p_34117 = ((__local int64_t *) local_mem_34087)[sext_i32_i64(squot32(local_tid_34080, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n         ", "           if (!no_carry_in_34129) {\n                        int64_t defunc_0_op_res_34119 = add64(eta_p_34117, eta_p_34118);\n                        \n                        eta_p_34117 = defunc_0_op_res_34119;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_34129) {\n                        ((__local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)] = eta_p_34117;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_34080, 32) == 0 && ltid_in_bounds_34124) {\n                    ((__local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)] = eta_p_34118;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_34080 == 0) {\n                acc_34120 = ((__local int64_t *) local_mem_34087)[segscan_tblock_sizze_33383 - (int64_t) 1];\n            } else {\n                acc_34120 = ((__local int64_t *) local_mem_34087)[sext_i32_i64(local_tid_34080) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_34130 = (int64_t) 0;\n        block_new_sgm_34131 = sgm_idx_34099 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_34131 && local_tid_34080 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_34055)[dynamic_id_34097] = acc_34120;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_34031)[dynamic_id_34097] = (int8_t) 2;\n                acc_34120 = (int64_t) 0;\n            }\n            if (!block_new_sgm_34131 && slt32(local_tid_34080, wave_sizze_34082)) {\n                if (local_tid_34080 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_34053)[dynamic_id_34097] = acc_34120;\n  ", "                  mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_34031)[dynamic_id_34097] = (int8_t) 1;\n                    \n                    int8_t tmp_34132 = ((volatile __global int8_t *) status_flags_mem_34031)[dynamic_id_34097 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_34087)[(int64_t) 0] = tmp_34132;\n                }\n                mem_fence_local();\n                \n                int8_t status_34133 = ((__local int8_t *) local_mem_34087)[(int64_t) 0];\n                \n                if (status_34133 == (int8_t) 2) {\n                    if (local_tid_34080 == 0) {\n                        prefix_34130 = ((volatile __global int64_t *) incprefixes_mem_34055)[dynamic_id_34097 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_34134 = sext_i64_i32(dynamic_id_34097 - sext_i32_i64(wave_sizze_34082));\n                    \n                    while (slt32(wave_sizze_34082 * -1, readOffset_34134)) {\n                        int32_t read_i_34135 = readOffset_34134 + local_tid_34080;\n                        int64_t aggr_34136 = (int64_t) 0;\n                        int8_t flag_34137 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_34135)) {\n                            flag_34137 = ((volatile __global int8_t *) status_flags_mem_34031)[sext_i32_i64(read_i_34135)];\n                            if (flag_34137 == (int8_t) 2) {\n                                aggr_34136 = ((volatile __global int64_t *) incprefixes_mem_34055)[sext_i32_i64(read_i_34135)];\n                            } else if (flag_34137 == (int8_t) 1) {\n                                aggr_34136 = ((volatile __global int64_t *) aggregates_mem_34053)[sext_i32_i64(read_i_34135)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_34087)[(int64_t) 4 + sext_i32_i64(local_tid_34",
                                    "080)] = aggr_34136;\n                        ((__local int8_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)] = flag_34137;\n                        flag_34137 = ((__local int8_t *) local_mem_34087)[sext_i32_i64(wave_sizze_34082) - (int64_t) 1];\n                        if (slt8(flag_34137, (int8_t) 2)) {\n                            int8_t flg_x_34141;\n                            int8_t flg_y_34142;\n                            int64_t eta_p_34138;\n                            int64_t eta_p_34139;\n                            int32_t skip_threads_34143;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_34142 = ((volatile __local int8_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)];\n                                eta_p_34139 = ((volatile __local int64_t *) local_mem_34087)[(int64_t) 4 + sext_i32_i64(local_tid_34080)];\n                                if ((local_tid_34080 - squot32(local_tid_34080, 32) * 32) == 0) {\n                                    eta_p_34138 = eta_p_34139;\n                                    flg_x_34141 = flg_y_34142;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_34143 = 1;\n                                while (slt32(skip_threads_34143, 32)) {\n                                    if (sle32(skip_threads_34143, local_tid_34080 - squot32(local_tid_34080, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_34141 = ((volatile __local int8_t *) local_mem_34087)[sext_i32_i64(local_tid_34080) - sext_i32_i64(skip_threads_34143)];\n                                            eta_p_34138 = ((volatile __local int64_t *) local_mem_34087)[(int64_t) 4 + (sext_i32_i64(local_tid_3408", "0) - sext_i32_i64(skip_threads_34143))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_34142 == (int8_t) 2 || flg_y_34142 == (int8_t) 0) {\n                                                flg_x_34141 = flg_y_34142;\n                                                eta_p_34138 = eta_p_34139;\n                                            } else {\n                                                int64_t defunc_0_op_res_34140 = add64(eta_p_34138, eta_p_34139);\n                                                \n                                                eta_p_34138 = defunc_0_op_res_34140;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_34087)[sext_i32_i64(local_tid_34080)] = flg_x_34141;\n                                            flg_y_34142 = flg_x_34141;\n                                            ((volatile __local int64_t *) local_mem_34087)[(int64_t) 4 + sext_i32_i64(local_tid_34080)] = eta_p_34138;\n                                            eta_p_34139 = eta_p_34138;\n                                        }\n                                    }\n                                    skip_threads_34143 *= 2;\n                                }\n                            }\n                        }\n                        flag_34137 = ((__local int8_t *) local_mem_34087)[sext_i32_i64(wave_sizze_34082) - (int64_t) 1];\n                        aggr_34136 = ((__local int64_t *) local_mem_34087)[(int64_t) 4 + (sext_i32_i64(wave_sizze_34082) - (int64_t) 1)];\n                        if (flag_34137 == (int8_t) 2) {\n                            readOffset_34134 = wave_sizze_34082 * -1;\n                        } e", "lse if (flag_34137 == (int8_t) 1) {\n                            readOffset_34134 -= wave_sizze_34082;\n                        }\n                        if (slt8((int8_t) 0, flag_34137)) {\n                            int64_t eta_p_34144 = aggr_34136;\n                            int64_t eta_p_34145 = prefix_34130;\n                            int64_t defunc_0_op_res_34146 = add64(eta_p_34144, eta_p_34145);\n                            \n                            prefix_34130 = defunc_0_op_res_34146;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_34080 == 0) {\n                    if (boundary_34100 == sext_i64_i32(segscan_tblock_sizze_33383 * chunk_sizze_34028)) {\n                        int64_t eta_p_34147 = prefix_34130;\n                        int64_t eta_p_34148 = acc_34120;\n                        int64_t defunc_0_op_res_34149 = add64(eta_p_34147, eta_p_34148);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_34055)[dynamic_id_34097] = defunc_0_op_res_34149;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_34031)[dynamic_id_34097] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_34087)[(int64_t) 4] = prefix_34130;\n                    acc_34120 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_34097 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_34130 = ((__local int64_t *) local_mem_34087)[(int64_t) 4];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_34150;\n            int64_t eta_p_34151;\n            int64_t eta_p_34153 = prefix_34130;\n            int64_t eta_p_34154 = acc_34120;\n            \n            if (slt32(local_tid_34080 * chunk_sizze_32b_34084, boundary_34100) && ",
                                    "!block_new_sgm_34131) {\n                int64_t defunc_0_op_res_34155 = add64(eta_p_34153, eta_p_34154);\n                \n                eta_p_34150 = defunc_0_op_res_34155;\n            } else {\n                eta_p_34150 = acc_34120;\n            }\n            \n            int32_t stopping_point_34156 = segsizze_compact_34101 - srem32(local_tid_34080 * chunk_sizze_32b_34084 - 1 + segsizze_compact_34101 - boundary_34100, segsizze_compact_34101);\n            \n            for (int64_t i_34157 = 0; i_34157 < chunk_sizze_34028; i_34157++) {\n                if (slt32(sext_i64_i32(i_34157), stopping_point_34156 - 1)) {\n                    eta_p_34151 = private_mem_34102[i_34157];\n                    \n                    int64_t defunc_0_op_res_34152 = add64(eta_p_34150, eta_p_34151);\n                    \n                    private_mem_34102[i_34157] = defunc_0_op_res_34152;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_34158 = 0; i_34158 < chunk_sizze_34028; i_34158++) {\n                int64_t sharedIdx_34159 = sext_i32_i64(local_tid_34080) * chunk_sizze_34028 + i_34158;\n                int64_t tmp_34160 = private_mem_34102[i_34158];\n                \n                ((__local int64_t *) local_mem_34087)[sharedIdx_34159] = tmp_34160;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34161 = 0; i_34161 < chunk_sizze_34028; i_34161++) {\n                int64_t flat_idx_34162 = thd_offset_34104 + i_34161 * segscan_tblock_sizze_33383;\n                int64_t slice_34163 = nR_21781;\n                int64_t gtid_33387 = flat_idx_34162;\n                int64_t remnant_34164 = flat_idx_34162 - gtid_33387;\n                \n                if (slt64(flat_idx_34162, nR_21781)) {\n                    int64_t tmp_34165 = ((__local int64_t *) local_mem_34087)[flat_idx_34162 - block_offset_34098];\n                    \n                    ", "((__global int64_t *) mem_33836)[gtid_33387] = tmp_34165;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_33383\n    #undef chunk_sizze_34028\n}\nFUTHARK_KERNEL_SIZED(inner_SMJ_shortzisegscan_33404_dim1, 1, 1)\nvoid inner_SMJ_shortzisegscan_33404(__global int *global_failure, int64_t m_32498, int64_t num_tblocks_33401, int64_t num_virt_blocks_34223, int64_t num_virt_threads_34224, __global unsigned char *mem_33844, __global unsigned char *mem_33848, __global unsigned char *mem_33850, __global unsigned char *mem_33852, __global unsigned char *status_flags_mem_34225, __global unsigned char *aggregates_mem_34227, __global unsigned char *incprefixes_mem_34229, __global unsigned char *aggregates_mem_34231, __global unsigned char *incprefixes_mem_34233, __global unsigned char *global_dynid_mem_34235)\n{\n    #define segscan_tblock_sizze_33399 (inner_SMJ_shortzisegscan_33404zisegscan_tblock_sizze_33399)\n    #define chunk_sizze_34222 (inner_SMJ_shortzisegscan_33404zichunk_sizze_34222)\n    \n    volatile __local unsigned char *local_mem_34247_backing_0 = &shared_mem[0];\n    const int64_t local_mem_34247_backing_0_offset = 0 + (smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_33399, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_33399), smax64(chunk_sizze_34222 * segscan_tblock_sizze_33399 * (int64_t) 8, chunk_sizze_34222 * segscan_tblock_sizze_33399 * (int64_t) 8)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_33399, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_33399), smax64(chunk_sizze_34222 * segscan_tblock_sizze_33399 * (int64_t) 8, chunk_sizze_34222 * segscan_tblock_sizze_33399 * (int64_t) 8)), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34238;\n    int32_t tblock_sizze_34241;\n    int32_t wave_sizze", "_34240;\n    int32_t block_id_34239;\n    int32_t global_tid_34237;\n    int64_t phys_tid_33404;\n    int32_t chunk_sizze_32b_34242;\n    int64_t byte_offsets_34243;\n    int64_t byte_offsets_34244;\n    int64_t warp_byte_offset_34245;\n    int64_t warp_byte_offset_34246;\n    __local unsigned char *local_mem_34247;\n    int64_t trans_arr_len_34248;\n    int64_t phys_block_id_34257;\n    int64_t virtloop_bound_34258;\n    \n    local_tid_34238 = get_local_id(0);\n    tblock_sizze_34241 = get_local_size(0);\n    wave_sizze_34240 = LOCKSTEP_WIDTH;\n    block_id_34239 = get_tblock_id(0);\n    global_tid_34237 = block_id_34239 * tblock_sizze_34241 + local_tid_34238;\n    phys_tid_33404 = sext_i32_i64(global_tid_34237);\n    chunk_sizze_32b_34242 = sext_i64_i32(chunk_sizze_34222);\n    byte_offsets_34243 = segscan_tblock_sizze_33399 * (int64_t) 8;\n    byte_offsets_34244 = sdiv_up64(byte_offsets_34243, (int64_t) 8) * (int64_t) 8 + segscan_tblock_sizze_33399 * (int64_t) 8;\n    warp_byte_offset_34245 = (int64_t) 288;\n    warp_byte_offset_34246 = sdiv_up64(warp_byte_offset_34245, (int64_t) 8) * (int64_t) 8 + (int64_t) 256;\n    // Allocate reusable shared memory\n    { }\n    local_mem_34247 = (__local unsigned char *) local_mem_34247_backing_0;\n    trans_arr_len_34248 = chunk_sizze_34222 * segscan_tblock_sizze_33399;\n    phys_block_id_34257 = get_tblock_id(0);\n    virtloop_bound_34258 = sdiv_up64(num_virt_blocks_34223 - phys_block_id_34257, num_tblocks_33401);\n    for (int64_t virtloop_i_34259 = 0; virtloop_i_34259 < virtloop_bound_34258; virtloop_i_34259++) {\n        int64_t dynamic_id_34260;\n        int64_t block_offset_34261;\n        int64_t sgm_idx_34262;\n        int32_t boundary_34263;\n        int32_t segsizze_compact_34264;\n        int64_t private_mem_34265[chunk_sizze_34222];\n        int64_t private_mem_34267[chunk_sizze_34222];\n        int64_t thd_offset_34269;\n        int64_t acc_34295;\n        int64_t acc_34296;\n        int64_t prefix_34309;\n        int64_t prefix_34310;\n        bool blo",
                                    "ck_new_sgm_34311;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_34238 == 0) {\n                dynamic_id_34260 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_34235)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_34247)[(int64_t) 0] = dynamic_id_34260;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_34260 == num_virt_blocks_34223 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_34235)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_34260 = ((__local int32_t *) local_mem_34247)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_34261 = dynamic_id_34260 * chunk_sizze_34222 * segscan_tblock_sizze_33399;\n        sgm_idx_34262 = smod64(block_offset_34261, m_32498);\n        boundary_34263 = sext_i64_i32(smin64(chunk_sizze_34222 * segscan_tblock_sizze_33399, m_32498 - sgm_idx_34262));\n        segsizze_compact_34264 = sext_i64_i32(smin64(chunk_sizze_34222 * segscan_tblock_sizze_33399, m_32498));\n        thd_offset_34269 = block_offset_34261 + sext_i32_i64(local_tid_34238);\n        // Load and map\n        {\n            for (int64_t i_34270 = 0; i_34270 < chunk_sizze_34222; i_34270++) {\n                int64_t virt_tid_34271 = thd_offset_34269 + i_34270 * segscan_tblock_sizze_33399;\n                int64_t slice_34272 = m_32498;\n                int64_t gtid_33403 = virt_tid_34271;\n                int64_t remnant_34273 = virt_tid_34271 - gtid_33403;\n                \n                if (slt64(virt_tid_34271, m_32498)) {\n                    int64_t x_32733 = ((__global int64_t *) mem_33844)[gtid_33403];\n                    bool lifted_lambda_res_32735 = slt64", "((int64_t) 1, x_32733);\n                    int64_t defunc_0_f_res_32736 = btoi_bool_i64(lifted_lambda_res_32735);\n                    \n                    ((__global int64_t *) mem_33852)[gtid_33403] = defunc_0_f_res_32736;\n                    private_mem_34265[i_34270] = x_32733;\n                    private_mem_34267[i_34270] = defunc_0_f_res_32736;\n                } else {\n                    private_mem_34265[i_34270] = (int64_t) 0;\n                    private_mem_34267[i_34270] = (int64_t) 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_34274 = 0; i_34274 < chunk_sizze_34222; i_34274++) {\n                int64_t sharedIdx_34275 = sext_i32_i64(local_tid_34238) + i_34274 * segscan_tblock_sizze_33399;\n                int64_t tmp_34276 = private_mem_34265[i_34274];\n                \n                ((__local int64_t *) local_mem_34247)[sharedIdx_34275] = tmp_34276;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34277 = 0; i_34277 < chunk_sizze_34222; i_34277++) {\n                int64_t sharedIdx_34278 = sext_i32_i64(local_tid_34238) * chunk_sizze_34222 + i_34277;\n                int64_t tmp_34279 = ((__local int64_t *) local_mem_34247)[sharedIdx_34278];\n                \n                private_mem_34265[i_34277] = tmp_34279;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34280 = 0; i_34280 < chunk_sizze_34222; i_34280++) {\n                int64_t sharedIdx_34281 = sext_i32_i64(local_tid_34238) + i_34280 * segscan_tblock_sizze_33399;\n                int64_t tmp_34282 = private_mem_34267[i_34280];\n                \n                ((__local int64_t *) local_mem_34247)[sharedIdx_34281] = tmp_34282;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34283 = 0; i_34283 < chunk_sizze_34222; i_34283++) {\n                int64_t sharedIdx_34284 = sext_i32_i64(local_tid", "_34238) * chunk_sizze_34222 + i_34283;\n                int64_t tmp_34285 = ((__local int64_t *) local_mem_34247)[sharedIdx_34284];\n                \n                private_mem_34267[i_34283] = tmp_34285;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_34286 = 0; i_34286 < chunk_sizze_34222 - (int64_t) 1; i_34286++) {\n                int64_t eta_p_32523;\n                int64_t eta_p_32524;\n                \n                eta_p_32523 = private_mem_34265[i_34286];\n                eta_p_32524 = private_mem_34265[i_34286 + (int64_t) 1];\n                \n                int64_t eta_p_32616;\n                int64_t eta_p_32617;\n                \n                eta_p_32616 = private_mem_34267[i_34286];\n                eta_p_32617 = private_mem_34267[i_34286 + (int64_t) 1];\n                \n                int64_t lifted_lambda_res_32525 = add64(eta_p_32523, eta_p_32524);\n                int64_t defunc_0_op_res_32618 = add64(eta_p_32616, eta_p_32617);\n                \n                private_mem_34265[i_34286 + (int64_t) 1] = lifted_lambda_res_32525;\n                private_mem_34267[i_34286 + (int64_t) 1] = defunc_0_op_res_32618;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_34287 = private_mem_34265[chunk_sizze_34222 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)] = tmp_34287;\n            \n            int64_t tmp_34288 = private_mem_34267[chunk_sizze_34222 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(local_tid_34238)] = tmp_34288;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_34289;\n            int64_t eta_p_34290;\n            int64_t eta_p_34291;\n            int64_t eta_p_34292;\n            int64_t eta_p",
                                    "_34297;\n            int64_t eta_p_34298;\n            int64_t eta_p_34299;\n            int64_t eta_p_34300;\n            bool ltid_in_bounds_34303 = slt64(sext_i32_i64(local_tid_34238), num_virt_threads_34224);\n            int32_t skip_threads_34304;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_34303) {\n                    eta_p_34291 = ((volatile __local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)];\n                    eta_p_34292 = ((volatile __local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(local_tid_34238)];\n                    if ((local_tid_34238 - squot32(local_tid_34238, 32) * 32) == 0) {\n                        eta_p_34289 = eta_p_34291;\n                        eta_p_34290 = eta_p_34292;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_34304 = 1;\n                while (slt32(skip_threads_34304, 32)) {\n                    bool thread_active_34305 = sle32(skip_threads_34304, local_tid_34238 - squot32(local_tid_34238, 32) * 32) && ltid_in_bounds_34303;\n                    \n                    if (thread_active_34305) {\n                        // read operands\n                        {\n                            eta_p_34289 = ((volatile __local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238) - sext_i32_i64(skip_threads_34304)];\n                            eta_p_34290 = ((volatile __local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + (sext_i32_i64(local_tid_34238) - sext_i32_i64(skip_threads_34304))];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_34305) {\n                            int64_t lifted_lambda_res_34293 = add64(eta_p_34289, eta_p_34291);\n                            int64_t defunc_0_op_res_342", "94 = add64(eta_p_34290, eta_p_34292);\n                            \n                            eta_p_34289 = lifted_lambda_res_34293;\n                            eta_p_34290 = defunc_0_op_res_34294;\n                        }\n                    }\n                    if (sle32(wave_sizze_34240, skip_threads_34304)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_34305) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)] = eta_p_34289;\n                            eta_p_34291 = eta_p_34289;\n                            ((volatile __local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(local_tid_34238)] = eta_p_34290;\n                            eta_p_34292 = eta_p_34290;\n                        }\n                    }\n                    if (sle32(wave_sizze_34240, skip_threads_34304)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_34304 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_34238 - squot32(local_tid_34238, 32) * 32) == 31 && ltid_in_bounds_34303) {\n                    ((volatile __local int64_t *) local_mem_34247)[sext_i32_i64(squot32(local_tid_34238, 32))] = eta_p_34289;\n                    ((volatile __local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(squot32(local_tid_34238, 32))] = eta_p_34290;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_34306;\n                \n                // read input for in-block scan\n     ", "           {\n                    if (squot32(local_tid_34238, 32) == 0 && ltid_in_bounds_34303) {\n                        eta_p_34299 = ((volatile __local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)];\n                        eta_p_34300 = ((volatile __local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(local_tid_34238)];\n                        if ((local_tid_34238 - squot32(local_tid_34238, 32) * 32) == 0) {\n                            eta_p_34297 = eta_p_34299;\n                            eta_p_34298 = eta_p_34300;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_34306 = 1;\n                    while (slt32(skip_threads_34306, 32)) {\n                        bool thread_active_34307 = sle32(skip_threads_34306, local_tid_34238 - squot32(local_tid_34238, 32) * 32) && (squot32(local_tid_34238, 32) == 0 && ltid_in_bounds_34303);\n                        \n                        if (thread_active_34307) {\n                            // read operands\n                            {\n                                eta_p_34297 = ((volatile __local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238) - sext_i32_i64(skip_threads_34306)];\n                                eta_p_34298 = ((volatile __local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + (sext_i32_i64(local_tid_34238) - sext_i32_i64(skip_threads_34306))];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_34307) {\n                                int64_t lifted_lambda_res_34301 = add64(eta_p_34297, eta_p_34299);\n                                int64_t defunc_0_op_res_34302 = add64(eta_p_34298, eta_p_34300);\n                                \n                                eta_p_34297 = lifted",
                                    "_lambda_res_34301;\n                                eta_p_34298 = defunc_0_op_res_34302;\n                            }\n                        }\n                        if (sle32(wave_sizze_34240, skip_threads_34306)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_34307) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)] = eta_p_34297;\n                                eta_p_34299 = eta_p_34297;\n                                ((volatile __local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(local_tid_34238)] = eta_p_34298;\n                                eta_p_34300 = eta_p_34298;\n                            }\n                        }\n                        if (sle32(wave_sizze_34240, skip_threads_34306)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_34306 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_34308 = squot32(local_tid_34238, 32) == 0 || !ltid_in_bounds_34303;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_34308) {\n                        eta_p_34291 = eta_p_34289;\n                        eta_p_34292 = eta_p_34290;\n                        eta_p_34289 = ((__local int64_t *) local_mem_34247)[sext_i32_i64(squot32(local_tid_34238, 32)) - (int64_t) 1];\n                        eta_p_34290 = ((__local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + (sext_i32_i64(squot32(local_tid_34238, 32)) - (int64_t) 1)];\n                    }\n                }\n                // perform operation\n                ", "{\n                    if (!no_carry_in_34308) {\n                        int64_t lifted_lambda_res_34293 = add64(eta_p_34289, eta_p_34291);\n                        int64_t defunc_0_op_res_34294 = add64(eta_p_34290, eta_p_34292);\n                        \n                        eta_p_34289 = lifted_lambda_res_34293;\n                        eta_p_34290 = defunc_0_op_res_34294;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_34308) {\n                        ((__local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)] = eta_p_34289;\n                        ((__local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(local_tid_34238)] = eta_p_34290;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_34238, 32) == 0 && ltid_in_bounds_34303) {\n                    ((__local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)] = eta_p_34291;\n                    ((__local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + sext_i32_i64(local_tid_34238)] = eta_p_34292;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_34238 == 0) {\n                acc_34295 = ((__local int64_t *) local_mem_34247)[segscan_tblock_sizze_33399 - (int64_t) 1];\n                acc_34296 = ((__local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + (segscan_tblock_sizze_33399 - (int64_t) 1)];\n            } else {\n                acc_34295 = ((__local int64_t *) local_mem_34247)[sext_i32_i64(local_tid_34238) - (int64_t) 1];\n                acc_34296 = ((__local int64_t *) local_mem_34247)[squot64(byte_offsets_34243, (int64_t) 8) + (sext_i32_i64(local_tid_34238) - (int64_t) 1)];\n            }\n   ", "         barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_34309 = (int64_t) 0;\n        prefix_34310 = (int64_t) 0;\n        block_new_sgm_34311 = sgm_idx_34262 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_34311 && local_tid_34238 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_34229)[dynamic_id_34260] = acc_34295;\n                ((volatile __global int64_t *) incprefixes_mem_34233)[dynamic_id_34260] = acc_34296;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_34225)[dynamic_id_34260] = (int8_t) 2;\n                acc_34295 = (int64_t) 0;\n                acc_34296 = (int64_t) 0;\n            }\n            if (!block_new_sgm_34311 && slt32(local_tid_34238, wave_sizze_34240)) {\n                if (local_tid_34238 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_34227)[dynamic_id_34260] = acc_34295;\n                    ((volatile __global int64_t *) aggregates_mem_34231)[dynamic_id_34260] = acc_34296;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_34225)[dynamic_id_34260] = (int8_t) 1;\n                    \n                    int8_t tmp_34312 = ((volatile __global int8_t *) status_flags_mem_34225)[dynamic_id_34260 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_34247)[(int64_t) 0] = tmp_34312;\n                }\n                mem_fence_local();\n                \n                int8_t status_34313 = ((__local int8_t *) local_mem_34247)[(int64_t) 0];\n                \n                if (status_34313 == (int8_t) 2) {\n                    if (local_tid_34238 == 0) {\n                        prefix_34309 = ((volatile __global int64_t *) incprefixes_mem_34229)[dynamic_id_34260 - (int64_t) 1];\n                        prefix_34310 = ((volatile __global int64_t *) incprefixes_mem_34233)[dynamic_id_34260 - (int64_t) 1];\n              ",
                                    "      }\n                } else {\n                    int32_t readOffset_34314 = sext_i64_i32(dynamic_id_34260 - sext_i32_i64(wave_sizze_34240));\n                    \n                    while (slt32(wave_sizze_34240 * -1, readOffset_34314)) {\n                        int32_t read_i_34315 = readOffset_34314 + local_tid_34238;\n                        int64_t aggr_34316 = (int64_t) 0;\n                        int64_t aggr_34317 = (int64_t) 0;\n                        int8_t flag_34318 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_34315)) {\n                            flag_34318 = ((volatile __global int8_t *) status_flags_mem_34225)[sext_i32_i64(read_i_34315)];\n                            if (flag_34318 == (int8_t) 2) {\n                                aggr_34316 = ((volatile __global int64_t *) incprefixes_mem_34229)[sext_i32_i64(read_i_34315)];\n                                aggr_34317 = ((volatile __global int64_t *) incprefixes_mem_34233)[sext_i32_i64(read_i_34315)];\n                            } else if (flag_34318 == (int8_t) 1) {\n                                aggr_34316 = ((volatile __global int64_t *) aggregates_mem_34227)[sext_i32_i64(read_i_34315)];\n                                aggr_34317 = ((volatile __global int64_t *) aggregates_mem_34231)[sext_i32_i64(read_i_34315)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_34247)[(int64_t) 4 + sext_i32_i64(local_tid_34238)] = aggr_34316;\n                        ((__local int64_t *) local_mem_34247)[squot64(warp_byte_offset_34245, (int64_t) 8) + sext_i32_i64(local_tid_34238)] = aggr_34317;\n                        ((__local int8_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)] = flag_34318;\n                        flag_34318 = ((__local int8_t *) local_mem_34247)[sext_i32_i64(wave_sizze_34240) - (int64_t) 1];\n                        if (slt8(flag_34318, (int8_t) 2)) {\n                            int8_t flg_x_343", "25;\n                            int8_t flg_y_34326;\n                            int64_t eta_p_34319;\n                            int64_t eta_p_34320;\n                            int64_t eta_p_34321;\n                            int64_t eta_p_34322;\n                            int32_t skip_threads_34327;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_34326 = ((volatile __local int8_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)];\n                                eta_p_34321 = ((volatile __local int64_t *) local_mem_34247)[(int64_t) 4 + sext_i32_i64(local_tid_34238)];\n                                eta_p_34322 = ((volatile __local int64_t *) local_mem_34247)[squot64(warp_byte_offset_34245, (int64_t) 8) + sext_i32_i64(local_tid_34238)];\n                                if ((local_tid_34238 - squot32(local_tid_34238, 32) * 32) == 0) {\n                                    eta_p_34319 = eta_p_34321;\n                                    eta_p_34320 = eta_p_34322;\n                                    flg_x_34325 = flg_y_34326;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_34327 = 1;\n                                while (slt32(skip_threads_34327, 32)) {\n                                    if (sle32(skip_threads_34327, local_tid_34238 - squot32(local_tid_34238, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_34325 = ((volatile __local int8_t *) local_mem_34247)[sext_i32_i64(local_tid_34238) - sext_i32_i64(skip_threads_34327)];\n                                            eta_p_34319 = ((volatile __local int64_t *) local_mem_34247)[(int64_t) 4 + (sext_i32_i64(local_tid_34238) - sext_i32_i64(", "skip_threads_34327))];\n                                            eta_p_34320 = ((volatile __local int64_t *) local_mem_34247)[squot64(warp_byte_offset_34245, (int64_t) 8) + (sext_i32_i64(local_tid_34238) - sext_i32_i64(skip_threads_34327))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_34326 == (int8_t) 2 || flg_y_34326 == (int8_t) 0) {\n                                                flg_x_34325 = flg_y_34326;\n                                                eta_p_34319 = eta_p_34321;\n                                                eta_p_34320 = eta_p_34322;\n                                            } else {\n                                                int64_t lifted_lambda_res_34323 = add64(eta_p_34319, eta_p_34321);\n                                                int64_t defunc_0_op_res_34324 = add64(eta_p_34320, eta_p_34322);\n                                                \n                                                eta_p_34319 = lifted_lambda_res_34323;\n                                                eta_p_34320 = defunc_0_op_res_34324;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_34247)[sext_i32_i64(local_tid_34238)] = flg_x_34325;\n                                            flg_y_34326 = flg_x_34325;\n                                            ((volatile __local int64_t *) local_mem_34247)[(int64_t) 4 + sext_i32_i64(local_tid_34238)] = eta_p_34319;\n                                            eta_p_34321 = eta_p_34319;\n                                            ((volatile __local int64_t *) local_mem_34247)[squot64(warp_byte_offset_34245, (int64_t) 8) + sext_i32_i64(local_tid_34",
                                    "238)] = eta_p_34320;\n                                            eta_p_34322 = eta_p_34320;\n                                        }\n                                    }\n                                    skip_threads_34327 *= 2;\n                                }\n                            }\n                        }\n                        flag_34318 = ((__local int8_t *) local_mem_34247)[sext_i32_i64(wave_sizze_34240) - (int64_t) 1];\n                        aggr_34316 = ((__local int64_t *) local_mem_34247)[(int64_t) 4 + (sext_i32_i64(wave_sizze_34240) - (int64_t) 1)];\n                        aggr_34317 = ((__local int64_t *) local_mem_34247)[squot64(warp_byte_offset_34245, (int64_t) 8) + (sext_i32_i64(wave_sizze_34240) - (int64_t) 1)];\n                        if (flag_34318 == (int8_t) 2) {\n                            readOffset_34314 = wave_sizze_34240 * -1;\n                        } else if (flag_34318 == (int8_t) 1) {\n                            readOffset_34314 -= wave_sizze_34240;\n                        }\n                        if (slt8((int8_t) 0, flag_34318)) {\n                            int64_t eta_p_34328 = aggr_34316;\n                            int64_t eta_p_34329 = aggr_34317;\n                            int64_t eta_p_34330 = prefix_34309;\n                            int64_t eta_p_34331 = prefix_34310;\n                            int64_t lifted_lambda_res_34332 = add64(eta_p_34328, eta_p_34330);\n                            int64_t defunc_0_op_res_34333 = add64(eta_p_34329, eta_p_34331);\n                            \n                            prefix_34309 = lifted_lambda_res_34332;\n                            prefix_34310 = defunc_0_op_res_34333;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_34238 == 0) {\n                    if (boundary_34263 == sext_i64_i32(segscan_tblock_sizze_33399 * chunk_sizze_34222)) {\n                        int64_t eta_p_34334 ", "= prefix_34309;\n                        int64_t eta_p_34335 = prefix_34310;\n                        int64_t eta_p_34336 = acc_34295;\n                        int64_t eta_p_34337 = acc_34296;\n                        int64_t lifted_lambda_res_34338 = add64(eta_p_34334, eta_p_34336);\n                        int64_t defunc_0_op_res_34339 = add64(eta_p_34335, eta_p_34337);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_34229)[dynamic_id_34260] = lifted_lambda_res_34338;\n                        ((volatile __global int64_t *) incprefixes_mem_34233)[dynamic_id_34260] = defunc_0_op_res_34339;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_34225)[dynamic_id_34260] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_34247)[(int64_t) 4] = prefix_34309;\n                    ((__local int64_t *) local_mem_34247)[squot64(warp_byte_offset_34245, (int64_t) 8)] = prefix_34310;\n                    acc_34295 = (int64_t) 0;\n                    acc_34296 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_34260 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_34309 = ((__local int64_t *) local_mem_34247)[(int64_t) 4];\n                prefix_34310 = ((__local int64_t *) local_mem_34247)[squot64(warp_byte_offset_34245, (int64_t) 8)];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_34340;\n            int64_t eta_p_34342;\n            int64_t eta_p_34346 = prefix_34309;\n            int64_t eta_p_34348 = acc_34295;\n            int64_t eta_p_34341;\n            int64_t eta_p_34343;\n            int64_t eta_p_34347 = prefix_34310;\n            int64_t eta_p_34349 = acc_34296;\n            \n            if (slt32(local_tid_34238 * chunk_sizze_32b_34242, boundary_34263) && !block_new_sgm_34311) {\n          ", "      int64_t lifted_lambda_res_34350 = add64(eta_p_34346, eta_p_34348);\n                int64_t defunc_0_op_res_34351 = add64(eta_p_34347, eta_p_34349);\n                \n                eta_p_34340 = lifted_lambda_res_34350;\n                eta_p_34341 = defunc_0_op_res_34351;\n            } else {\n                eta_p_34340 = acc_34295;\n                eta_p_34341 = acc_34296;\n            }\n            \n            int32_t stopping_point_34352 = segsizze_compact_34264 - srem32(local_tid_34238 * chunk_sizze_32b_34242 - 1 + segsizze_compact_34264 - boundary_34263, segsizze_compact_34264);\n            \n            for (int64_t i_34353 = 0; i_34353 < chunk_sizze_34222; i_34353++) {\n                if (slt32(sext_i64_i32(i_34353), stopping_point_34352 - 1)) {\n                    eta_p_34342 = private_mem_34265[i_34353];\n                    eta_p_34343 = private_mem_34267[i_34353];\n                    \n                    int64_t lifted_lambda_res_34344 = add64(eta_p_34340, eta_p_34342);\n                    int64_t defunc_0_op_res_34345 = add64(eta_p_34341, eta_p_34343);\n                    \n                    private_mem_34265[i_34353] = lifted_lambda_res_34344;\n                    private_mem_34267[i_34353] = defunc_0_op_res_34345;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_34354 = 0; i_34354 < chunk_sizze_34222; i_34354++) {\n                int64_t sharedIdx_34355 = sext_i32_i64(local_tid_34238) * chunk_sizze_34222 + i_34354;\n                int64_t tmp_34356 = private_mem_34265[i_34354];\n                \n                ((__local int64_t *) local_mem_34247)[sharedIdx_34355] = tmp_34356;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34357 = 0; i_34357 < chunk_sizze_34222; i_34357++) {\n                int64_t flat_idx_34358 = thd_offset_34269 + i_34357 * segscan_tblock_sizze_33399;\n                int64_t slice_3",
                                    "4359 = m_32498;\n                int64_t gtid_33403 = flat_idx_34358;\n                int64_t remnant_34360 = flat_idx_34358 - gtid_33403;\n                \n                if (slt64(flat_idx_34358, m_32498)) {\n                    int64_t tmp_34361 = ((__local int64_t *) local_mem_34247)[flat_idx_34358 - block_offset_34261];\n                    \n                    ((__global int64_t *) mem_33848)[gtid_33403] = tmp_34361;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34362 = 0; i_34362 < chunk_sizze_34222; i_34362++) {\n                int64_t sharedIdx_34363 = sext_i32_i64(local_tid_34238) * chunk_sizze_34222 + i_34362;\n                int64_t tmp_34364 = private_mem_34267[i_34362];\n                \n                ((__local int64_t *) local_mem_34247)[sharedIdx_34363] = tmp_34364;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_34365 = 0; i_34365 < chunk_sizze_34222; i_34365++) {\n                int64_t flat_idx_34366 = thd_offset_34269 + i_34365 * segscan_tblock_sizze_33399;\n                int64_t slice_34367 = m_32498;\n                int64_t gtid_33403 = flat_idx_34366;\n                int64_t remnant_34368 = flat_idx_34366 - gtid_33403;\n                \n                if (slt64(flat_idx_34366, m_32498)) {\n                    int64_t tmp_34369 = ((__local int64_t *) local_mem_34247)[flat_idx_34366 - block_offset_34261];\n                    \n                    ((__global int64_t *) mem_33850)[gtid_33403] = tmp_34369;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_33399\n    #undef chunk_sizze_34222\n}\nFUTHARK_KERNEL_SIZED(max_idxzisegred_nonseg_32820_dim1, 1, 1)\nvoid max_idxzisegred_nonseg_32820(__global int *global_failure, int64_t nz2080U_31457, int64_t num_tblocks_32815, int64_t num_threads_34046, __global unsigned char *eta_p_mem_33832, __global unsigned char *mem_33834,", " __global unsigned char *counters_mem_34022, __global unsigned char *segred_tmp_mem_34044)\n{\n    #define segred_tblock_sizze_32813 (max_idxzisegred_nonseg_32820zisegred_tblock_sizze_32813)\n    #define chunk_sizze_34021 (max_idxzisegred_nonseg_32820zichunk_sizze_34021)\n    \n    volatile __local unsigned char *sync_arr_mem_34054_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_34054_backing_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i64_mem_34052_backing_0 = &shared_mem[sync_arr_mem_34054_backing_1_offset];\n    const int64_t red_arr_i64_mem_34052_backing_0_offset = sync_arr_mem_34054_backing_1_offset + ((int64_t) 8 * segred_tblock_sizze_32813 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_32813, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34048;\n    int32_t tblock_sizze_34051;\n    int32_t wave_sizze_34050;\n    int32_t block_id_34049;\n    int32_t global_tid_34047;\n    int64_t phys_tid_32820;\n    __local unsigned char *red_arr_i64_mem_34052;\n    __local unsigned char *sync_arr_mem_34054;\n    int64_t dummy_32818;\n    int64_t gtid_32819;\n    int64_t q_34056;\n    int64_t eta_p_block_res_acc_34057;\n    int64_t eta_p_31783;\n    int64_t eta_p_31784;\n    int64_t tblock_id_in_segment_34061;\n    int64_t block_base_offset_34062;\n    int32_t offset_34065;\n    int32_t skip_waves_34066;\n    int64_t eta_p_34058;\n    int64_t eta_p_34059;\n    int32_t old_counter_34067;\n    bool is_last_block_34068;\n    \n    local_tid_34048 = get_local_id(0);\n    tblock_sizze_34051 = get_local_size(0);\n    wave_sizze_34050 = LOCKSTEP_WIDTH;\n    block_id_34049 = get_tblock_id(0);\n    global_tid_34047 = block_id_34049 * tblock_sizze_34051 + local_tid_34048;\n    phys_tid_32820 = sext_i32_i64(global_tid_34047);\n    red_arr_i64_mem_34052 = (__local unsigned char *) red_arr_i64_mem_34052_backing_0;\n    sync_arr_mem_34054 = (__local unsigned char *) sync_arr_mem_34054_backing_1;\n    dummy_32818 = (int64", "_t) 0;\n    gtid_32819 = (int64_t) 0;\n    q_34056 = sdiv_up64(nz2080U_31457, sext_i32_i64(sext_i64_i32(segred_tblock_sizze_32813 * num_tblocks_32815)) * chunk_sizze_34021);\n    // ne-initialise the outer (per-block) accumulator(s)\n    {\n        eta_p_block_res_acc_34057 = (int64_t) -9223372036854775808;\n    }\n    tblock_id_in_segment_34061 = squot64(phys_tid_32820, segred_tblock_sizze_32813);\n    block_base_offset_34062 = tblock_id_in_segment_34061 * q_34056 * segred_tblock_sizze_32813;\n    for (int64_t i_34063 = 0; i_34063 < q_34056; i_34063++) {\n        int64_t block_offset_34064 = block_base_offset_34062 + i_34063 * segred_tblock_sizze_32813;\n        \n        gtid_32819 = phys_tid_32820 + num_threads_34046 * i_34063;\n        if (slt64(gtid_32819, nz2080U_31457)) {\n            // apply map function(s)\n            {\n                // apply map function\n                {\n                    int64_t x_31782 = ((__global int64_t *) eta_p_mem_33832)[gtid_32819];\n                    \n                    // load accumulator(s)\n                    {\n                        eta_p_31783 = eta_p_block_res_acc_34057;\n                    }\n                    // load next value(s)\n                    {\n                        eta_p_31784 = x_31782;\n                    }\n                    // apply reduction operator(s)\n                    {\n                        int64_t max_res_31785 = smax64(eta_p_31783, eta_p_31784);\n                        \n                        // store in accumulator(s)\n                        {\n                            eta_p_block_res_acc_34057 = max_res_31785;\n                        }\n                    }\n                }\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // store accs. prims go in lmem; non-prims in params (in global mem)\n    {\n        ((__local int64_t *) red_arr_i64_mem_34052)[sext_i32_i64(local_tid_34048)] = eta_p_block_res_acc_34057;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    skip_waves_34066 = 1;\n    o",
                                    "ffset_34065 = 0;\n    // participating threads read initial accumulator\n    {\n        if (slt32(local_tid_34048, sext_i64_i32(segred_tblock_sizze_32813))) {\n            eta_p_34058 = ((__local int64_t *) red_arr_i64_mem_34052)[sext_i32_i64(local_tid_34048 + offset_34065)];\n        }\n    }\n    offset_34065 = 1;\n    while (slt32(offset_34065, wave_sizze_34050)) {\n        if (slt32(local_tid_34048 + offset_34065, sext_i64_i32(segred_tblock_sizze_32813)) && ((local_tid_34048 - squot32(local_tid_34048, wave_sizze_34050) * wave_sizze_34050) & (2 * offset_34065 - 1)) == 0) {\n            // read array element\n            {\n                eta_p_34059 = ((volatile __local int64_t *) red_arr_i64_mem_34052)[sext_i32_i64(local_tid_34048 + offset_34065)];\n            }\n            // apply reduction operation\n            {\n                int64_t max_res_34060 = smax64(eta_p_34058, eta_p_34059);\n                \n                eta_p_34058 = max_res_34060;\n            }\n            // write result of operation\n            {\n                ((volatile __local int64_t *) red_arr_i64_mem_34052)[sext_i32_i64(local_tid_34048)] = eta_p_34058;\n            }\n        }\n        offset_34065 *= 2;\n    }\n    while (slt32(skip_waves_34066, squot32(sext_i64_i32(segred_tblock_sizze_32813) + wave_sizze_34050 - 1, wave_sizze_34050))) {\n        barrier(CLK_LOCAL_MEM_FENCE);\n        offset_34065 = skip_waves_34066 * wave_sizze_34050;\n        if (slt32(local_tid_34048 + offset_34065, sext_i64_i32(segred_tblock_sizze_32813)) && ((local_tid_34048 - squot32(local_tid_34048, wave_sizze_34050) * wave_sizze_34050) == 0 && (squot32(local_tid_34048, wave_sizze_34050) & (2 * skip_waves_34066 - 1)) == 0)) {\n            // read array element\n            {\n                eta_p_34059 = ((__local int64_t *) red_arr_i64_mem_34052)[sext_i32_i64(local_tid_34048 + offset_34065)];\n            }\n            // apply reduction operation\n            {\n                int64_t max_res_34060 = smax64(eta_p_34058, eta_p_340", "59);\n                \n                eta_p_34058 = max_res_34060;\n            }\n            // write result of operation\n            {\n                ((__local int64_t *) red_arr_i64_mem_34052)[sext_i32_i64(local_tid_34048)] = eta_p_34058;\n            }\n        }\n        skip_waves_34066 *= 2;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // thread 0 updates per-block acc(s); rest reset to ne\n    {\n        if (sext_i32_i64(local_tid_34048) == (int64_t) 0) {\n            eta_p_block_res_acc_34057 = eta_p_34058;\n        } else {\n            eta_p_block_res_acc_34057 = (int64_t) -9223372036854775808;\n        }\n    }\n    // first thread in block saves block result to global memory\n    {\n        if (local_tid_34048 == 0) {\n            ((__global int64_t *) segred_tmp_mem_34044)[sext_i32_i64(block_id_34049)] = eta_p_block_res_acc_34057;\n            mem_fence_global();\n            old_counter_34067 = atomic_add_i32_global(&((volatile __global int *) counters_mem_34022)[(int64_t) 0], (int) 1);\n            ((__local bool *) sync_arr_mem_34054)[(int64_t) 0] = old_counter_34067 == sext_i64_i32(num_tblocks_32815 - (int64_t) 1);\n        }\n    }\n    barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    is_last_block_34068 = ((__local bool *) sync_arr_mem_34054)[(int64_t) 0];\n    if (is_last_block_34068) {\n        if (local_tid_34048 == 0) {\n            old_counter_34067 = atomic_add_i32_global(&((volatile __global int *) counters_mem_34022)[(int64_t) 0], (int) sext_i64_i32((int64_t) 0 - num_tblocks_32815));\n        }\n        // read in the per-block-results\n        {\n            int64_t read_per_thread_34069 = sdiv_up64(num_tblocks_32815, segred_tblock_sizze_32813);\n            \n            eta_p_31783 = (int64_t) -9223372036854775808;\n            for (int64_t i_34070 = 0; i_34070 < read_per_thread_34069; i_34070++) {\n                int64_t block_res_id_34071 = sext_i32_i64(local_tid_34048) * read_per_thread_34069 + i_34070;\n                in", "t64_t index_of_block_res_34072 = block_res_id_34071;\n                \n                if (slt64(block_res_id_34071, num_tblocks_32815)) {\n                    eta_p_31784 = ((__global int64_t *) segred_tmp_mem_34044)[index_of_block_res_34072];\n                    \n                    int64_t max_res_31785 = smax64(eta_p_31783, eta_p_31784);\n                    \n                    eta_p_31783 = max_res_31785;\n                }\n            }\n        }\n        ((__local int64_t *) red_arr_i64_mem_34052)[sext_i32_i64(local_tid_34048)] = eta_p_31783;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // reduce the per-block results\n        {\n            int32_t offset_34073;\n            int32_t skip_waves_34074 = 1;\n            int64_t eta_p_34058;\n            int64_t eta_p_34059;\n            \n            offset_34073 = 0;\n            // participating threads read initial accumulator\n            {\n                if (slt32(local_tid_34048, sext_i64_i32(segred_tblock_sizze_32813))) {\n                    eta_p_34058 = ((__local int64_t *) red_arr_i64_mem_34052)[sext_i32_i64(local_tid_34048 + offset_34073)];\n                }\n            }\n            offset_34073 = 1;\n            while (slt32(offset_34073, wave_sizze_34050)) {\n                if (slt32(local_tid_34048 + offset_34073, sext_i64_i32(segred_tblock_sizze_32813)) && ((local_tid_34048 - squot32(local_tid_34048, wave_sizze_34050) * wave_sizze_34050) & (2 * offset_34073 - 1)) == 0) {\n                    // read array element\n                    {\n                        eta_p_34059 = ((volatile __local int64_t *) red_arr_i64_mem_34052)[sext_i32_i64(local_tid_34048 + offset_34073)];\n                    }\n                    // apply reduction operation\n                    {\n                        int64_t max_res_34060 = smax64(eta_p_34058, eta_p_34059);\n                        \n                        eta_p_34058 = max_res_34060;\n                    }\n                    // write result of operation\n                    ",
                                    "{\n                        ((volatile __local int64_t *) red_arr_i64_mem_34052)[sext_i32_i64(local_tid_34048)] = eta_p_34058;\n                    }\n                }\n                offset_34073 *= 2;\n            }\n            while (slt32(skip_waves_34074, squot32(sext_i64_i32(segred_tblock_sizze_32813) + wave_sizze_34050 - 1, wave_sizze_34050))) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                offset_34073 = skip_waves_34074 * wave_sizze_34050;\n                if (slt32(local_tid_34048 + offset_34073, sext_i64_i32(segred_tblock_sizze_32813)) && ((local_tid_34048 - squot32(local_tid_34048, wave_sizze_34050) * wave_sizze_34050) == 0 && (squot32(local_tid_34048, wave_sizze_34050) & (2 * skip_waves_34074 - 1)) == 0)) {\n                    // read array element\n                    {\n                        eta_p_34059 = ((__local int64_t *) red_arr_i64_mem_34052)[sext_i32_i64(local_tid_34048 + offset_34073)];\n                    }\n                    // apply reduction operation\n                    {\n                        int64_t max_res_34060 = smax64(eta_p_34058, eta_p_34059);\n                        \n                        eta_p_34058 = max_res_34060;\n                    }\n                    // write result of operation\n                    {\n                        ((__local int64_t *) red_arr_i64_mem_34052)[sext_i32_i64(local_tid_34048)] = eta_p_34058;\n                    }\n                }\n                skip_waves_34074 *= 2;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // and back to memory with the final result\n            {\n                if (local_tid_34048 == 0) {\n                    ((__global int64_t *) mem_33834)[(int64_t) 0] = eta_p_34058;\n                }\n            }\n        }\n    }\n    \n  error_5:\n    return;\n    #undef segred_tblock_sizze_32813\n    #undef chunk_sizze_34021\n}\nFUTHARK_KERNEL_SIZED(min_idxzisegred_nonseg_32810_dim1, 1, 1)\nvoid min_idxzisegred_nonseg_32810(__global int *global_failure, int64_", "t nz2080U_31417, int64_t num_tblocks_32805, int64_t num_threads_34046, __global unsigned char *eta_p_mem_33832, __global unsigned char *mem_33834, __global unsigned char *counters_mem_34022, __global unsigned char *segred_tmp_mem_34044)\n{\n    #define segred_tblock_sizze_32803 (min_idxzisegred_nonseg_32810zisegred_tblock_sizze_32803)\n    #define chunk_sizze_34021 (min_idxzisegred_nonseg_32810zichunk_sizze_34021)\n    \n    volatile __local unsigned char *sync_arr_mem_34054_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_34054_backing_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i64_mem_34052_backing_0 = &shared_mem[sync_arr_mem_34054_backing_1_offset];\n    const int64_t red_arr_i64_mem_34052_backing_0_offset = sync_arr_mem_34054_backing_1_offset + ((int64_t) 8 * segred_tblock_sizze_32803 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_32803, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_34048;\n    int32_t tblock_sizze_34051;\n    int32_t wave_sizze_34050;\n    int32_t block_id_34049;\n    int32_t global_tid_34047;\n    int64_t phys_tid_32810;\n    __local unsigned char *red_arr_i64_mem_34052;\n    __local unsigned char *sync_arr_mem_34054;\n    int64_t dummy_32808;\n    int64_t gtid_32809;\n    int64_t q_34056;\n    int64_t eta_p_block_res_acc_34057;\n    int64_t eta_p_31783;\n    int64_t eta_p_31784;\n    int64_t tblock_id_in_segment_34061;\n    int64_t block_base_offset_34062;\n    int32_t offset_34065;\n    int32_t skip_waves_34066;\n    int64_t eta_p_34058;\n    int64_t eta_p_34059;\n    int32_t old_counter_34067;\n    bool is_last_block_34068;\n    \n    local_tid_34048 = get_local_id(0);\n    tblock_sizze_34051 = get_local_size(0);\n    wave_sizze_34050 = LOCKSTEP_WIDTH;\n    block_id_34049 = get_tblock_id(0);\n    global_tid_34047 = block_id_34049 * tblock_sizze_34051 + local_tid_34048;\n    phys_tid_32810 = sext_i32_i64(global_tid_34047);\n    red_arr_i64_mem_34052 = (__local unsigned ", "char *) red_arr_i64_mem_34052_backing_0;\n    sync_arr_mem_34054 = (__local unsigned char *) sync_arr_mem_34054_backing_1;\n    dummy_32808 = (int64_t) 0;\n    gtid_32809 = (int64_t) 0;\n    q_34056 = sdiv_up64(nz2080U_31417, sext_i32_i64(sext_i64_i32(segred_tblock_sizze_32803 * num_tblocks_32805)) * chunk_sizze_34021);\n    // ne-initialise the outer (per-block) accumulator(s)\n    {\n        eta_p_block_res_acc_34057 = (int64_t) 9223372036854775807;\n    }\n    tblock_id_in_segment_34061 = squot64(phys_tid_32810, segred_tblock_sizze_32803);\n    block_base_offset_34062 = tblock_id_in_segment_34061 * q_34056 * segred_tblock_sizze_32803;\n    for (int64_t i_34063 = 0; i_34063 < q_34056; i_34063++) {\n        int64_t block_offset_34064 = block_base_offset_34062 + i_34063 * segred_tblock_sizze_32803;\n        \n        gtid_32809 = phys_tid_32810 + num_threads_34046 * i_34063;\n        if (slt64(gtid_32809, nz2080U_31417)) {\n            // apply map function(s)\n            {\n                // apply map function\n                {\n                    int64_t x_31782 = ((__global int64_t *) eta_p_mem_33832)[gtid_32809];\n                    \n                    // load accumulator(s)\n                    {\n                        eta_p_31783 = eta_p_block_res_acc_34057;\n                    }\n                    // load next value(s)\n                    {\n                        eta_p_31784 = x_31782;\n                    }\n                    // apply reduction operator(s)\n                    {\n                        int64_t min_res_31785 = smin64(eta_p_31783, eta_p_31784);\n                        \n                        // store in accumulator(s)\n                        {\n                            eta_p_block_res_acc_34057 = min_res_31785;\n                        }\n                    }\n                }\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // store accs. prims go in lmem; non-prims in params (in global mem)\n    {\n        ((__local int64_t *) red_arr_i",
                                    "64_mem_34052)[sext_i32_i64(local_tid_34048)] = eta_p_block_res_acc_34057;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    skip_waves_34066 = 1;\n    offset_34065 = 0;\n    // participating threads read initial accumulator\n    {\n        if (slt32(local_tid_34048, sext_i64_i32(segred_tblock_sizze_32803))) {\n            eta_p_34058 = ((__local int64_t *) red_arr_i64_mem_34052)[sext_i32_i64(local_tid_34048 + offset_34065)];\n        }\n    }\n    offset_34065 = 1;\n    while (slt32(offset_34065, wave_sizze_34050)) {\n        if (slt32(local_tid_34048 + offset_34065, sext_i64_i32(segred_tblock_sizze_32803)) && ((local_tid_34048 - squot32(local_tid_34048, wave_sizze_34050) * wave_sizze_34050) & (2 * offset_34065 - 1)) == 0) {\n            // read array element\n            {\n                eta_p_34059 = ((volatile __local int64_t *) red_arr_i64_mem_34052)[sext_i32_i64(local_tid_34048 + offset_34065)];\n            }\n            // apply reduction operation\n            {\n                int64_t min_res_34060 = smin64(eta_p_34058, eta_p_34059);\n                \n                eta_p_34058 = min_res_34060;\n            }\n            // write result of operation\n            {\n                ((volatile __local int64_t *) red_arr_i64_mem_34052)[sext_i32_i64(local_tid_34048)] = eta_p_34058;\n            }\n        }\n        offset_34065 *= 2;\n    }\n    while (slt32(skip_waves_34066, squot32(sext_i64_i32(segred_tblock_sizze_32803) + wave_sizze_34050 - 1, wave_sizze_34050))) {\n        barrier(CLK_LOCAL_MEM_FENCE);\n        offset_34065 = skip_waves_34066 * wave_sizze_34050;\n        if (slt32(local_tid_34048 + offset_34065, sext_i64_i32(segred_tblock_sizze_32803)) && ((local_tid_34048 - squot32(local_tid_34048, wave_sizze_34050) * wave_sizze_34050) == 0 && (squot32(local_tid_34048, wave_sizze_34050) & (2 * skip_waves_34066 - 1)) == 0)) {\n            // read array element\n            {\n                eta_p_34059 = ((__local int64_t *) red_arr_i64_mem_34052)[sext_i32_i64(local_tid_34048 + offset_34", "065)];\n            }\n            // apply reduction operation\n            {\n                int64_t min_res_34060 = smin64(eta_p_34058, eta_p_34059);\n                \n                eta_p_34058 = min_res_34060;\n            }\n            // write result of operation\n            {\n                ((__local int64_t *) red_arr_i64_mem_34052)[sext_i32_i64(local_tid_34048)] = eta_p_34058;\n            }\n        }\n        skip_waves_34066 *= 2;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // thread 0 updates per-block acc(s); rest reset to ne\n    {\n        if (sext_i32_i64(local_tid_34048) == (int64_t) 0) {\n            eta_p_block_res_acc_34057 = eta_p_34058;\n        } else {\n            eta_p_block_res_acc_34057 = (int64_t) 9223372036854775807;\n        }\n    }\n    // first thread in block saves block result to global memory\n    {\n        if (local_tid_34048 == 0) {\n            ((__global int64_t *) segred_tmp_mem_34044)[sext_i32_i64(block_id_34049)] = eta_p_block_res_acc_34057;\n            mem_fence_global();\n            old_counter_34067 = atomic_add_i32_global(&((volatile __global int *) counters_mem_34022)[(int64_t) 0], (int) 1);\n            ((__local bool *) sync_arr_mem_34054)[(int64_t) 0] = old_counter_34067 == sext_i64_i32(num_tblocks_32805 - (int64_t) 1);\n        }\n    }\n    barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    is_last_block_34068 = ((__local bool *) sync_arr_mem_34054)[(int64_t) 0];\n    if (is_last_block_34068) {\n        if (local_tid_34048 == 0) {\n            old_counter_34067 = atomic_add_i32_global(&((volatile __global int *) counters_mem_34022)[(int64_t) 0], (int) sext_i64_i32((int64_t) 0 - num_tblocks_32805));\n        }\n        // read in the per-block-results\n        {\n            int64_t read_per_thread_34069 = sdiv_up64(num_tblocks_32805, segred_tblock_sizze_32803);\n            \n            eta_p_31783 = (int64_t) 9223372036854775807;\n            for (int64_t i_34070 = 0; i_34070 < read_per_thread_34069", "; i_34070++) {\n                int64_t block_res_id_34071 = sext_i32_i64(local_tid_34048) * read_per_thread_34069 + i_34070;\n                int64_t index_of_block_res_34072 = block_res_id_34071;\n                \n                if (slt64(block_res_id_34071, num_tblocks_32805)) {\n                    eta_p_31784 = ((__global int64_t *) segred_tmp_mem_34044)[index_of_block_res_34072];\n                    \n                    int64_t min_res_31785 = smin64(eta_p_31783, eta_p_31784);\n                    \n                    eta_p_31783 = min_res_31785;\n                }\n            }\n        }\n        ((__local int64_t *) red_arr_i64_mem_34052)[sext_i32_i64(local_tid_34048)] = eta_p_31783;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // reduce the per-block results\n        {\n            int32_t offset_34073;\n            int32_t skip_waves_34074 = 1;\n            int64_t eta_p_34058;\n            int64_t eta_p_34059;\n            \n            offset_34073 = 0;\n            // participating threads read initial accumulator\n            {\n                if (slt32(local_tid_34048, sext_i64_i32(segred_tblock_sizze_32803))) {\n                    eta_p_34058 = ((__local int64_t *) red_arr_i64_mem_34052)[sext_i32_i64(local_tid_34048 + offset_34073)];\n                }\n            }\n            offset_34073 = 1;\n            while (slt32(offset_34073, wave_sizze_34050)) {\n                if (slt32(local_tid_34048 + offset_34073, sext_i64_i32(segred_tblock_sizze_32803)) && ((local_tid_34048 - squot32(local_tid_34048, wave_sizze_34050) * wave_sizze_34050) & (2 * offset_34073 - 1)) == 0) {\n                    // read array element\n                    {\n                        eta_p_34059 = ((volatile __local int64_t *) red_arr_i64_mem_34052)[sext_i32_i64(local_tid_34048 + offset_34073)];\n                    }\n                    // apply reduction operation\n                    {\n                        int64_t min_res_34060 = smin64(eta_p_34058, eta_p_34059);\n                        \n ",
                                    "                       eta_p_34058 = min_res_34060;\n                    }\n                    // write result of operation\n                    {\n                        ((volatile __local int64_t *) red_arr_i64_mem_34052)[sext_i32_i64(local_tid_34048)] = eta_p_34058;\n                    }\n                }\n                offset_34073 *= 2;\n            }\n            while (slt32(skip_waves_34074, squot32(sext_i64_i32(segred_tblock_sizze_32803) + wave_sizze_34050 - 1, wave_sizze_34050))) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                offset_34073 = skip_waves_34074 * wave_sizze_34050;\n                if (slt32(local_tid_34048 + offset_34073, sext_i64_i32(segred_tblock_sizze_32803)) && ((local_tid_34048 - squot32(local_tid_34048, wave_sizze_34050) * wave_sizze_34050) == 0 && (squot32(local_tid_34048, wave_sizze_34050) & (2 * skip_waves_34074 - 1)) == 0)) {\n                    // read array element\n                    {\n                        eta_p_34059 = ((__local int64_t *) red_arr_i64_mem_34052)[sext_i32_i64(local_tid_34048 + offset_34073)];\n                    }\n                    // apply reduction operation\n                    {\n                        int64_t min_res_34060 = smin64(eta_p_34058, eta_p_34059);\n                        \n                        eta_p_34058 = min_res_34060;\n                    }\n                    // write result of operation\n                    {\n                        ((__local int64_t *) red_arr_i64_mem_34052)[sext_i32_i64(local_tid_34048)] = eta_p_34058;\n                    }\n                }\n                skip_waves_34074 *= 2;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // and back to memory with the final result\n            {\n                if (local_tid_34048 == 0) {\n                    ((__global int64_t *) mem_33834)[(int64_t) 0] = eta_p_34058;\n                }\n            }\n        }\n    }\n    \n  error_5:\n    return;\n    #undef segred_tblock_sizze_32803\n    #undef chunk_siz", "ze_34021\n}\n", NULL};
// Start of gpu_prototypes.h

// Constants used for transpositions.  In principle these should be configurable.
#define TR_BLOCK_DIM 16
#define TR_TILE_DIM (TR_BLOCK_DIM*2)
#define TR_ELEMS_PER_THREAD 8

// Config stuff included in every GPU backend.
struct gpu_config {
  size_t default_block_size;
  size_t default_grid_size;
  size_t default_tile_size;
  size_t default_reg_tile_size;
  size_t default_cache;
  size_t default_shared_memory;
  size_t default_registers;
  size_t default_threshold;

  int default_block_size_changed;
  int default_grid_size_changed;
  int default_tile_size_changed;
};

// The following are dummy sizes that mean the concrete defaults
// will be set during initialisation via hardware-inspection-based
// heuristics.
struct gpu_config gpu_config_initial = {
  0
};

// Must be defined by the user.
static int gpu_macros(struct futhark_context *ctx, char*** names, int64_t** values);

static void gpu_init_log(struct futhark_context *ctx);
struct builtin_kernels* init_builtin_kernels(struct futhark_context* ctx);
void free_builtin_kernels(struct futhark_context* ctx, struct builtin_kernels* kernels);
static int gpu_free_all(struct futhark_context *ctx);

// End of gpu_prototypes.h

// Start of backends/cuda.h.

// Forward declarations.
// Invoked by setup_opencl() after the platform and device has been
// found, but before the program is loaded.  Its intended use is to
// tune constants based on the selected platform and device.
static void set_tuning_params(struct futhark_context* ctx);
static char* get_failure_msg(int failure_idx, int64_t args[]);

#define CUDA_SUCCEED_FATAL(x) cuda_api_succeed_fatal(x, #x, __FILE__, __LINE__)
#define CUDA_SUCCEED_NONFATAL(x) cuda_api_succeed_nonfatal(x, #x, __FILE__, __LINE__)
#define NVRTC_SUCCEED_FATAL(x) nvrtc_api_succeed_fatal(x, #x, __FILE__, __LINE__)
#define NVRTC_SUCCEED_NONFATAL(x) nvrtc_api_succeed_nonfatal(x, #x, __FILE__, __LINE__)
// Take care not to override an existing error.
#define CUDA_SUCCEED_OR_RETURN(e) {             \
    char *serror = CUDA_SUCCEED_NONFATAL(e);    \
    if (serror) {                               \
      if (!ctx->error) {                        \
        ctx->error = serror;                    \
      } else {                                  \
        free(serror);                           \
      }                                         \
      return bad;                               \
    }                                           \
  }

// CUDA_SUCCEED_OR_RETURN returns the value of the variable 'bad' in
// scope.  By default, it will be this one.  Create a local variable
// of some other type if needed.  This is a bit of a hack, but it
// saves effort in the code generator.
static const int bad = 1;

static inline void cuda_api_succeed_fatal(CUresult res, const char *call,
                                          const char *file, int line) {
  if (res != CUDA_SUCCESS) {
    const char *err_str;
    cuGetErrorString(res, &err_str);
    if (err_str == NULL) { err_str = "Unknown"; }
    futhark_panic(-1, "%s:%d: CUDA call\n  %s\nfailed with error code %d (%s)\n",
                  file, line, call, res, err_str);
  }
}

static char* cuda_api_succeed_nonfatal(CUresult res, const char *call,
                                       const char *file, int line) {
  if (res != CUDA_SUCCESS) {
    const char *err_str;
    cuGetErrorString(res, &err_str);
    if (err_str == NULL) { err_str = "Unknown"; }
    return msgprintf("%s:%d: CUDA call\n  %s\nfailed with error code %d (%s)\n",
                     file, line, call, res, err_str);
  } else {
    return NULL;
  }
}

static inline void nvrtc_api_succeed_fatal(nvrtcResult res, const char *call,
                                           const char *file, int line) {
  if (res != NVRTC_SUCCESS) {
    const char *err_str = nvrtcGetErrorString(res);
    futhark_panic(-1, "%s:%d: NVRTC call\n  %s\nfailed with error code %d (%s)\n",
                  file, line, call, res, err_str);
  }
}

static char* nvrtc_api_succeed_nonfatal(nvrtcResult res, const char *call,
                                        const char *file, int line) {
  if (res != NVRTC_SUCCESS) {
    const char *err_str = nvrtcGetErrorString(res);
    return msgprintf("%s:%d: NVRTC call\n  %s\nfailed with error code %d (%s)\n",
                     file, line, call, res, err_str);
  } else {
    return NULL;
  }
}

struct futhark_context_config {
  int in_use;
  int debugging;
  int profiling;
  int logging;
  char* cache_fname;
  int num_tuning_params;
  int64_t *tuning_params;
  const char** tuning_param_names;
  const char** tuning_param_vars;
  const char** tuning_param_classes;
  // Uniform fields above.

  char* program;
  int num_nvrtc_opts;
  char* *nvrtc_opts;

  char* preferred_device;
  int preferred_device_num;

  int unified_memory;

  char* dump_ptx_to;
  char* load_ptx_from;

  struct gpu_config gpu;
};

static void backend_context_config_setup(struct futhark_context_config *cfg) {
  cfg->num_nvrtc_opts = 0;
  cfg->nvrtc_opts = (char**) malloc(sizeof(char*));
  cfg->nvrtc_opts[0] = NULL;

  cfg->program = strconcat(gpu_program);

  cfg->preferred_device_num = 0;
  cfg->preferred_device = strdup("");

  cfg->dump_ptx_to = NULL;
  cfg->load_ptx_from = NULL;

  cfg->unified_memory = 2;

  cfg->gpu = gpu_config_initial;
  cfg->gpu.default_block_size = 256;
  cfg->gpu.default_tile_size = 32;
  cfg->gpu.default_reg_tile_size = 2;
  cfg->gpu.default_threshold = 32*1024;
}

static void backend_context_config_teardown(struct futhark_context_config* cfg) {
  for (int i = 0; i < cfg->num_nvrtc_opts; i++) {
    free(cfg->nvrtc_opts[i]);
  }
  free(cfg->nvrtc_opts);
  free(cfg->dump_ptx_to);
  free(cfg->load_ptx_from);
  free(cfg->preferred_device);
  free(cfg->program);
}

void futhark_context_config_add_nvrtc_option(struct futhark_context_config *cfg, const char *opt) {
  cfg->nvrtc_opts[cfg->num_nvrtc_opts] = strdup(opt);
  cfg->num_nvrtc_opts++;
  cfg->nvrtc_opts = (char **) realloc(cfg->nvrtc_opts, (cfg->num_nvrtc_opts + 1) * sizeof(char *));
  cfg->nvrtc_opts[cfg->num_nvrtc_opts] = NULL;
}

void futhark_context_config_set_device(struct futhark_context_config *cfg, const char *s) {
  int x = 0;
  if (*s == '#') {
    s++;
    while (isdigit(*s)) {
      x = x * 10 + (*s++)-'0';
    }
    // Skip trailing spaces.
    while (isspace(*s)) {
      s++;
    }
  }
  free(cfg->preferred_device);
  cfg->preferred_device = strdup(s);
  cfg->preferred_device_num = x;
}

const char* futhark_context_config_get_program(struct futhark_context_config *cfg) {
  return cfg->program;
}

void futhark_context_config_set_program(struct futhark_context_config *cfg, const char *s) {
  free(cfg->program);
  cfg->program = strdup(s);
}

void futhark_context_config_dump_ptx_to(struct futhark_context_config *cfg, const char *path) {
  free(cfg->dump_ptx_to);
  cfg->dump_ptx_to = strdup(path);
}

void futhark_context_config_load_ptx_from(struct futhark_context_config *cfg, const char *path) {
  free(cfg->load_ptx_from);
  cfg->load_ptx_from = strdup(path);
}

void futhark_context_config_set_unified_memory(struct futhark_context_config* cfg, int flag) {
  cfg->unified_memory = flag;
}

// A record of something that happened.
struct profiling_record {
  cudaEvent_t *events; // Points to two events.
  const char *name;
};

struct futhark_context {
  struct futhark_context_config* cfg;
  int detail_memory;
  int debugging;
  int profiling;
  int profiling_paused;
  int logging;
  lock_t lock;
  char *error;
  lock_t error_lock;
  FILE *log;
  struct constants *constants;
  struct free_list free_list;
  struct event_list event_list;
  int64_t peak_mem_usage_default;
  int64_t cur_mem_usage_default;
  struct program* program;
  bool program_initialised;
  // Uniform fields above.

  CUdeviceptr global_failure;
  CUdeviceptr global_failure_args;
  struct tuning_params tuning_params;
  // True if a potentially failing kernel has been enqueued.
  int32_t failure_is_an_option;
  int total_runs;
  long int total_runtime;
  int64_t peak_mem_usage_device;
  int64_t cur_mem_usage_device;

  CUdevice dev;
  CUcontext cu_ctx;
  CUmodule module;
  CUstream stream;

  struct free_list gpu_free_list;

  size_t max_thread_block_size;
  size_t max_grid_size;
  size_t max_tile_size;
  size_t max_threshold;
  size_t max_shared_memory;
  size_t max_bespoke;
  size_t max_registers;
  size_t max_cache;

  size_t lockstep_width;

  struct builtin_kernels* kernels;
};

#define CU_DEV_ATTR(x) (CU_DEVICE_ATTRIBUTE_##x)
#define device_query(dev,attrib) _device_query(dev, CU_DEV_ATTR(attrib))
static int _device_query(CUdevice dev, CUdevice_attribute attrib) {
  int val;
  CUDA_SUCCEED_FATAL(cuDeviceGetAttribute(&val, attrib, dev));
  return val;
}

#define CU_FUN_ATTR(x) (CU_FUNC_ATTRIBUTE_##x)
#define function_query(fn,attrib) _function_query(dev, CU_FUN_ATTR(attrib))
static int _function_query(CUfunction dev, CUfunction_attribute attrib) {
  int val;
  CUDA_SUCCEED_FATAL(cuFuncGetAttribute(&val, attrib, dev));
  return val;
}

static int cuda_device_setup(struct futhark_context *ctx) {
  struct futhark_context_config *cfg = ctx->cfg;
  char name[256];
  int count, chosen = -1, best_cc = -1;
  int cc_major_best = 0, cc_minor_best = 0;
  int cc_major = 0, cc_minor = 0;
  CUdevice dev;

  CUDA_SUCCEED_FATAL(cuDeviceGetCount(&count));
  if (count == 0) { return 1; }

  int num_device_matches = 0;

  // XXX: Current device selection policy is to choose the device with the
  // highest compute capability (if no preferred device is set).
  // This should maybe be changed, since greater compute capability is not
  // necessarily an indicator of better performance.
  for (int i = 0; i < count; i++) {
    CUDA_SUCCEED_FATAL(cuDeviceGet(&dev, i));

    cc_major = device_query(dev, COMPUTE_CAPABILITY_MAJOR);
    cc_minor = device_query(dev, COMPUTE_CAPABILITY_MINOR);

    CUDA_SUCCEED_FATAL(cuDeviceGetName(name, sizeof(name) - 1, dev));
    name[sizeof(name) - 1] = 0;

    if (cfg->logging) {
      fprintf(ctx->log, "Device #%d: name=\"%s\", compute capability=%d.%d\n",
              i, name, cc_major, cc_minor);
    }

    if (device_query(dev, COMPUTE_MODE) == CU_COMPUTEMODE_PROHIBITED) {
      if (cfg->logging) {
        fprintf(ctx->log, "Device #%d is compute-prohibited, ignoring\n", i);
      }
      continue;
    }

    if (best_cc == -1 || cc_major > cc_major_best ||
        (cc_major == cc_major_best && cc_minor > cc_minor_best)) {
      best_cc = i;
      cc_major_best = cc_major;
      cc_minor_best = cc_minor;
    }

    if (strstr(name, cfg->preferred_device) != NULL &&
        num_device_matches++ == cfg->preferred_device_num) {
      chosen = i;
      break;
    }
  }

  if (chosen == -1) { chosen = best_cc; }
  if (chosen == -1) { return 1; }

  if (cfg->logging) {
    fprintf(ctx->log, "Using device #%d\n", chosen);
  }

  CUDA_SUCCEED_FATAL(cuDeviceGet(&ctx->dev, chosen));
  return 0;
}

static const char *cuda_nvrtc_get_arch(CUdevice dev) {
  static struct {
    int major;
    int minor;
    const char *arch_str;
  } const x[] = {
    { 3, 0, "compute_30" },
    { 3, 2, "compute_32" },
    { 3, 5, "compute_35" },
    { 3, 7, "compute_37" },
    { 5, 0, "compute_50" },
    { 5, 2, "compute_52" },
    { 5, 3, "compute_53" },
    { 6, 0, "compute_60" },
    { 6, 1, "compute_61" },
    { 6, 2, "compute_62" },
    { 7, 0, "compute_70" },
    { 7, 2, "compute_72" },
    { 7, 5, "compute_75" },
    { 8, 0, "compute_80" },
    { 8, 6, "compute_80" },
    { 8, 7, "compute_80" }
  };

  int major = device_query(dev, COMPUTE_CAPABILITY_MAJOR);
  int minor = device_query(dev, COMPUTE_CAPABILITY_MINOR);

  int chosen = -1;
  int num_archs = sizeof(x)/sizeof(x[0]);
  for (int i = 0; i < num_archs; i++) {
    if (x[i].major < major || (x[i].major == major && x[i].minor <= minor)) {
      chosen = i;
    } else {
      break;
    }
  }

  if (chosen == -1) {
    futhark_panic(-1, "Unsupported compute capability %d.%d\n", major, minor);
  }

  if (x[chosen].major != major || x[chosen].minor != minor) {
    fprintf(stderr,
            "Warning: device compute capability is %d.%d, but newest supported by Futhark is %d.%d.\n",
            major, minor, x[chosen].major, x[chosen].minor);
  }

  return x[chosen].arch_str;
}

static void cuda_nvrtc_mk_build_options(struct futhark_context *ctx, const char *extra_opts[],
                                        char*** opts_out, size_t *n_opts) {
  int arch_set = 0, num_extra_opts;
  struct futhark_context_config *cfg = ctx->cfg;

  char** macro_names;
  int64_t* macro_vals;
  int num_macros = gpu_macros(ctx, &macro_names, &macro_vals);

  // nvrtc cannot handle multiple -arch options.  Hence, if one of the
  // extra_opts is -arch, we have to be careful not to do our usual
  // automatic generation.
  for (num_extra_opts = 0; extra_opts[num_extra_opts] != NULL; num_extra_opts++) {
    if (strstr(extra_opts[num_extra_opts], "-arch")
        == extra_opts[num_extra_opts] ||
        strstr(extra_opts[num_extra_opts], "--gpu-architecture")
        == extra_opts[num_extra_opts]) {
      arch_set = 1;
    }
  }

  size_t i = 0, n_opts_alloc = 20 + num_macros + num_extra_opts + cfg->num_tuning_params;
  char **opts = (char**) malloc(n_opts_alloc * sizeof(char *));
  if (!arch_set) {
    opts[i++] = strdup("-arch");
    opts[i++] = strdup(cuda_nvrtc_get_arch(ctx->dev));
  }
  opts[i++] = strdup("-default-device");
  if (cfg->debugging) {
    opts[i++] = strdup("-G");
    opts[i++] = strdup("-lineinfo");
  } else {
    opts[i++] = strdup("--disable-warnings");
  }
  opts[i++] = msgprintf("-D%s=%d",
                        "max_thread_block_size",
                        (int)ctx->max_thread_block_size);
  opts[i++] = msgprintf("-D%s=%d",
                        "max_shared_memory",
                        (int)ctx->max_shared_memory);
  opts[i++] = msgprintf("-D%s=%d",
                        "max_registers",
                        (int)ctx->max_registers);

  for (int j = 0; j < num_macros; j++) {
    opts[i++] = msgprintf("-D%s=%zu", macro_names[j], macro_vals[j]);
  }

  for (int j = 0; j < cfg->num_tuning_params; j++) {
    opts[i++] = msgprintf("-D%s=%zu", cfg->tuning_param_vars[j],
                          cfg->tuning_params[j]);
  }
  opts[i++] = msgprintf("-DLOCKSTEP_WIDTH=%zu", ctx->lockstep_width);
  opts[i++] = msgprintf("-DMAX_THREADS_PER_BLOCK=%zu", ctx->max_thread_block_size);

  // Time for the best lines of the code in the entire compiler.
  if (getenv("CUDA_HOME") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_HOME"));
  }
  if (getenv("CUDA_ROOT") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_ROOT"));
  }
  if (getenv("CUDA_PATH") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_PATH"));
  }
  opts[i++] = msgprintf("-I/usr/local/cuda/include");
  opts[i++] = msgprintf("-I/usr/include");

  for (int j = 0; extra_opts[j] != NULL; j++) {
    opts[i++] = strdup(extra_opts[j]);
  }

  opts[i++] = msgprintf("-DTR_BLOCK_DIM=%d", TR_BLOCK_DIM);
  opts[i++] = msgprintf("-DTR_TILE_DIM=%d", TR_TILE_DIM);
  opts[i++] = msgprintf("-DTR_ELEMS_PER_THREAD=%d", TR_ELEMS_PER_THREAD);

  free(macro_names);
  free(macro_vals);

  *n_opts = i;
  *opts_out = opts;
}

static char* cuda_nvrtc_build(const char *src, const char *opts[], size_t n_opts,
                              char **ptx) {
  nvrtcProgram prog;
  char *problem = NULL;

  problem = NVRTC_SUCCEED_NONFATAL(nvrtcCreateProgram(&prog, src, "futhark-cuda", 0, NULL, NULL));

  if (problem) {
    return problem;
  }

  nvrtcResult res = nvrtcCompileProgram(prog, n_opts, opts);
  if (res != NVRTC_SUCCESS) {
    size_t log_size;
    if (nvrtcGetProgramLogSize(prog, &log_size) == NVRTC_SUCCESS) {
      char *log = (char*) malloc(log_size);
      if (nvrtcGetProgramLog(prog, log) == NVRTC_SUCCESS) {
        problem = msgprintf("NVRTC compilation failed.\n\n%s\n", log);
      } else {
        problem = msgprintf("Could not retrieve compilation log\n");
      }
      free(log);
    }
    return problem;
  }

  size_t ptx_size;
  NVRTC_SUCCEED_FATAL(nvrtcGetPTXSize(prog, &ptx_size));
  *ptx = (char*) malloc(ptx_size);
  NVRTC_SUCCEED_FATAL(nvrtcGetPTX(prog, *ptx));

  NVRTC_SUCCEED_FATAL(nvrtcDestroyProgram(&prog));

  return NULL;
}

static void cuda_load_ptx_from_cache(struct futhark_context_config *cfg,
                                     const char *src,
                                     const char *opts[], size_t n_opts,
                                     struct cache_hash *h, const char *cache_fname,
                                     char **ptx) {
  if (cfg->logging) {
    fprintf(stderr, "Restoring cache from from %s...\n", cache_fname);
  }
  cache_hash_init(h);
  for (size_t i = 0; i < n_opts; i++) {
    cache_hash(h, opts[i], strlen(opts[i]));
  }
  cache_hash(h, src, strlen(src));
  size_t ptxsize;
  errno = 0;
  if (cache_restore(cache_fname, h, (unsigned char**)ptx, &ptxsize) != 0) {
    if (cfg->logging) {
      fprintf(stderr, "Failed to restore cache (errno: %s)\n", strerror(errno));
    }
  }
}

static void cuda_size_setup(struct futhark_context *ctx)
{
  struct futhark_context_config *cfg = ctx->cfg;
  if (cfg->gpu.default_block_size > ctx->max_thread_block_size) {
    if (cfg->gpu.default_block_size_changed) {
      fprintf(stderr,
              "Note: Device limits default block size to %zu (down from %zu).\n",
              ctx->max_thread_block_size, cfg->gpu.default_block_size);
    }
    cfg->gpu.default_block_size = ctx->max_thread_block_size;
  }
  if (cfg->gpu.default_grid_size > ctx->max_grid_size) {
    if (cfg->gpu.default_grid_size_changed) {
      fprintf(stderr,
              "Note: Device limits default grid size to %zu (down from %zu).\n",
              ctx->max_grid_size, cfg->gpu.default_grid_size);
    }
    cfg->gpu.default_grid_size = ctx->max_grid_size;
  }
  if (cfg->gpu.default_tile_size > ctx->max_tile_size) {
    if (cfg->gpu.default_tile_size_changed) {
      fprintf(stderr,
              "Note: Device limits default tile size to %zu (down from %zu).\n",
              ctx->max_tile_size, cfg->gpu.default_tile_size);
    }
    cfg->gpu.default_tile_size = ctx->max_tile_size;
  }

  if (!cfg->gpu.default_grid_size_changed) {
    cfg->gpu.default_grid_size =
      (device_query(ctx->dev, MULTIPROCESSOR_COUNT) *
       device_query(ctx->dev, MAX_THREADS_PER_MULTIPROCESSOR))
      / cfg->gpu.default_block_size;
  }

  for (int i = 0; i < cfg->num_tuning_params; i++) {
    const char *size_class = cfg->tuning_param_classes[i];
    int64_t *size_value = &cfg->tuning_params[i];
    const char* size_name = cfg->tuning_param_names[i];
    int64_t max_value = 0, default_value = 0;

    if (strstr(size_class, "thread_block_size") == size_class) {
      max_value = ctx->max_thread_block_size;
      default_value = cfg->gpu.default_block_size;
    } else if (strstr(size_class, "grid_size") == size_class) {
      max_value = ctx->max_grid_size;
      default_value = cfg->gpu.default_grid_size;
      // XXX: as a quick and dirty hack, use twice as many threads for
      // histograms by default.  We really should just be smarter
      // about sizes somehow.
      if (strstr(size_name, ".seghist_") != NULL) {
        default_value *= 2;
      }
    } else if (strstr(size_class, "tile_size") == size_class) {
      max_value = ctx->max_tile_size;
      default_value = cfg->gpu.default_tile_size;
    } else if (strstr(size_class, "reg_tile_size") == size_class) {
      max_value = 0; // No limit.
      default_value = cfg->gpu.default_reg_tile_size;
    } else if (strstr(size_class, "shared_memory") == size_class) {
      max_value = ctx->max_shared_memory;
      default_value = ctx->max_shared_memory;
    } else if (strstr(size_class, "cache") == size_class) {
      max_value = ctx->max_cache;
      default_value = ctx->max_cache;
    } else if (strstr(size_class, "threshold") == size_class) {
      // Threshold can be as large as it takes.
      default_value = cfg->gpu.default_threshold;
    } else {
      // Bespoke sizes have no limit or default.
    }

    if (*size_value == 0) {
      *size_value = default_value;
    } else if (max_value > 0 && *size_value > max_value) {
      fprintf(stderr, "Note: Device limits %s to %zu (down from %zu)\n",
              size_name, max_value, *size_value);
      *size_value = max_value;
    }
  }
}

static char* cuda_module_setup(struct futhark_context *ctx,
                               const char *src,
                               const char *extra_opts[],
                               const char* cache_fname) {
  char *ptx = NULL;
  struct futhark_context_config *cfg = ctx->cfg;

  if (cfg->load_ptx_from) {
    ptx = slurp_file(cfg->load_ptx_from, NULL);
  }

  char **opts;
  size_t n_opts;
  cuda_nvrtc_mk_build_options(ctx, extra_opts, &opts, &n_opts);

  if (cfg->logging) {
    fprintf(stderr, "NVRTC compile options:\n");
    for (size_t j = 0; j < n_opts; j++) {
      fprintf(stderr, "\t%s\n", opts[j]);
    }
    fprintf(stderr, "\n");
  }

  struct cache_hash h;
  int loaded_ptx_from_cache = 0;
  if (cache_fname != NULL) {
    cuda_load_ptx_from_cache(cfg, src, (const char**)opts, n_opts, &h, cache_fname, &ptx);

    if (ptx != NULL) {
      if (cfg->logging) {
        fprintf(stderr, "Restored PTX from cache; now loading module...\n");
      }
      if (cuModuleLoadData(&ctx->module, ptx) == CUDA_SUCCESS) {
        if (cfg->logging) {
          fprintf(stderr, "Success!\n");
        }
        loaded_ptx_from_cache = 1;
      } else {
        if (cfg->logging) {
          fprintf(stderr, "Failed!\n");
        }
        free(ptx);
        ptx = NULL;
      }
    }
  }

  if (ptx == NULL) {
    char* problem = cuda_nvrtc_build(src, (const char**)opts, n_opts, &ptx);
    if (problem != NULL) {
      return problem;
    }
  }

  if (cfg->dump_ptx_to != NULL) {
    dump_file(cfg->dump_ptx_to, ptx, strlen(ptx));
  }

  if (!loaded_ptx_from_cache) {
    CUDA_SUCCEED_FATAL(cuModuleLoadData(&ctx->module, ptx));
  }

  if (cache_fname != NULL && !loaded_ptx_from_cache) {
    if (cfg->logging) {
      fprintf(stderr, "Caching PTX in %s...\n", cache_fname);
    }
    errno = 0;
    if (cache_store(cache_fname, &h, (const unsigned char*)ptx, strlen(ptx)) != 0) {
      fprintf(stderr, "Failed to cache PTX: %s\n", strerror(errno));
    }
  }

  for (size_t i = 0; i < n_opts; i++) {
    free((char *)opts[i]);
  }
  free(opts);
  free(ptx);

  return NULL;
}

struct cuda_event {
  cudaEvent_t start;
  cudaEvent_t end;
};

static struct cuda_event* cuda_event_new(struct futhark_context* ctx) {
  if (ctx->profiling && !ctx->profiling_paused) {
    struct cuda_event* e = malloc(sizeof(struct cuda_event));
    cudaEventCreate(&e->start);
    cudaEventCreate(&e->end);
    return e;
  } else {
    return NULL;
  }
}

static int cuda_event_report(struct str_builder* sb, struct cuda_event* e) {
  float ms;
  CUresult err;
  if ((err = cuEventElapsedTime(&ms, e->start, e->end)) != CUDA_SUCCESS) {
    return err;
  }

  // CUDA provides milisecond resolution, but we want microseconds.
  str_builder(sb, ",\"duration\":%f", ms*1000);

  if ((err = cuEventDestroy(e->start)) != CUDA_SUCCESS) {
    return 1;
  }

  if ((err = cuEventDestroy(e->end)) != CUDA_SUCCESS) {
    return 1;
  }

  free(e);

  return 0;
}

int futhark_context_sync(struct futhark_context* ctx) {
  CUDA_SUCCEED_OR_RETURN(cuCtxPushCurrent(ctx->cu_ctx));
  CUDA_SUCCEED_OR_RETURN(cuCtxSynchronize());
  if (ctx->failure_is_an_option) {
    // Check for any delayed error.
    int32_t failure_idx;
    CUDA_SUCCEED_OR_RETURN(
                           cuMemcpyDtoH(&failure_idx,
                                        ctx->global_failure,
                                        sizeof(int32_t)));
    ctx->failure_is_an_option = 0;

    if (failure_idx >= 0) {
      // We have to clear global_failure so that the next entry point
      // is not considered a failure from the start.
      int32_t no_failure = -1;
      CUDA_SUCCEED_OR_RETURN(
                             cuMemcpyHtoD(ctx->global_failure,
                                          &no_failure,
                                          sizeof(int32_t)));

      int64_t args[max_failure_args+1];
      CUDA_SUCCEED_OR_RETURN(
                             cuMemcpyDtoH(&args,
                                          ctx->global_failure_args,
                                          sizeof(args)));

      ctx->error = get_failure_msg(failure_idx, args);

      return FUTHARK_PROGRAM_ERROR;
    }
  }

  CUDA_SUCCEED_OR_RETURN(cuCtxPopCurrent(&ctx->cu_ctx));
  return 0;
}

struct builtin_kernels* init_builtin_kernels(struct futhark_context* ctx);
void free_builtin_kernels(struct futhark_context* ctx, struct builtin_kernels* kernels);

int backend_context_setup(struct futhark_context* ctx) {
  ctx->failure_is_an_option = 0;
  ctx->total_runs = 0;
  ctx->total_runtime = 0;
  ctx->peak_mem_usage_device = 0;
  ctx->cur_mem_usage_device = 0;
  ctx->kernels = NULL;

  CUDA_SUCCEED_FATAL(cuInit(0));
  if (cuda_device_setup(ctx) != 0) {
    futhark_panic(-1, "No suitable CUDA device found.\n");
  }
  CUDA_SUCCEED_FATAL(cuCtxCreate(&ctx->cu_ctx, 0, ctx->dev));

  free_list_init(&ctx->gpu_free_list);

  if (ctx->cfg->unified_memory == 2) {
    ctx->cfg->unified_memory = device_query(ctx->dev, MANAGED_MEMORY);
  }

  if (ctx->cfg->logging) {
    if (ctx->cfg->unified_memory) {
      fprintf(ctx->log, "Using managed memory\n");
    } else {
      fprintf(ctx->log, "Using unmanaged memory\n");
    }
  }

  ctx->max_thread_block_size = device_query(ctx->dev, MAX_THREADS_PER_BLOCK);
  ctx->max_grid_size = device_query(ctx->dev, MAX_GRID_DIM_X);
  ctx->max_tile_size = sqrt(ctx->max_thread_block_size);
  ctx->max_threshold = 1U<<31; // No limit.
  ctx->max_bespoke = 1U<<31; // No limit.

  if (ctx->cfg->gpu.default_registers != 0) {
    ctx->max_registers = ctx->cfg->gpu.default_registers;
  } else {
    ctx->max_registers = device_query(ctx->dev, MAX_REGISTERS_PER_BLOCK);
  }

  if (ctx->cfg->gpu.default_shared_memory != 0) {
    ctx->max_shared_memory = ctx->cfg->gpu.default_shared_memory;
  } else {
    // MAX_SHARED_MEMORY_PER_BLOCK gives bogus numbers (48KiB); probably
    // for backwards compatibility.  Add _OPTIN and you seem to get the
    // right number.
    ctx->max_shared_memory = device_query(ctx->dev, MAX_SHARED_MEMORY_PER_BLOCK_OPTIN);
#if CUDART_VERSION >= 12000
    ctx->max_shared_memory -= device_query(ctx->dev, RESERVED_SHARED_MEMORY_PER_BLOCK);
#endif
  }

  if (ctx->cfg->gpu.default_cache != 0) {
    ctx->max_cache = ctx->cfg->gpu.default_cache;
  } else {
    ctx->max_cache = device_query(ctx->dev, L2_CACHE_SIZE);
  }

  ctx->lockstep_width = device_query(ctx->dev, WARP_SIZE);
  CUDA_SUCCEED_FATAL(cuStreamCreate(&ctx->stream, CU_STREAM_DEFAULT));
  cuda_size_setup(ctx);

  gpu_init_log(ctx);

  ctx->error = cuda_module_setup(ctx,
                                 ctx->cfg->program,
                                 (const char**)ctx->cfg->nvrtc_opts,
                                 ctx->cfg->cache_fname);

  if (ctx->error != NULL) {
    futhark_panic(1, "During CUDA initialisation:\n%s\n", ctx->error);
  }

  int32_t no_error = -1;
  CUDA_SUCCEED_FATAL(cuMemAlloc(&ctx->global_failure, sizeof(no_error)));
  CUDA_SUCCEED_FATAL(cuMemcpyHtoD(ctx->global_failure, &no_error, sizeof(no_error)));
  // The +1 is to avoid zero-byte allocations.
  CUDA_SUCCEED_FATAL(cuMemAlloc(&ctx->global_failure_args, sizeof(int64_t)*(max_failure_args+1)));

  if ((ctx->kernels = init_builtin_kernels(ctx)) == NULL) {
    return 1;
  }

  return 0;
}

void backend_context_teardown(struct futhark_context* ctx) {
  if (ctx->kernels != NULL) {
    free_builtin_kernels(ctx, ctx->kernels);
    cuMemFree(ctx->global_failure);
    cuMemFree(ctx->global_failure_args);
    CUDA_SUCCEED_FATAL(gpu_free_all(ctx));
    CUDA_SUCCEED_FATAL(cuStreamDestroy(ctx->stream));
    CUDA_SUCCEED_FATAL(cuModuleUnload(ctx->module));
    CUDA_SUCCEED_FATAL(cuCtxDestroy(ctx->cu_ctx));
  }
  free_list_destroy(&ctx->gpu_free_list);
}

// GPU ABSTRACTION LAYER

// Types.

typedef CUfunction gpu_kernel;
typedef CUdeviceptr gpu_mem;

static void gpu_create_kernel(struct futhark_context *ctx,
                              gpu_kernel* kernel,
                              const char* name) {
  if (ctx->debugging) {
    fprintf(ctx->log, "Creating kernel %s.\n", name);
  }
  CUDA_SUCCEED_FATAL(cuModuleGetFunction(kernel, ctx->module, name));
  // Unless the below is set, the kernel is limited to 48KiB of memory.
  CUDA_SUCCEED_FATAL(cuFuncSetAttribute(*kernel,
                                        cudaFuncAttributeMaxDynamicSharedMemorySize,
                                        ctx->max_shared_memory));
}

static void gpu_free_kernel(struct futhark_context *ctx,
                            gpu_kernel kernel) {
  (void)ctx;
  (void)kernel;
}

static int gpu_scalar_to_device(struct futhark_context* ctx,
                                gpu_mem dst, size_t offset, size_t size,
                                void *src) {
  struct cuda_event *event = cuda_event_new(ctx);
  if (event != NULL) {
    add_event(ctx,
              "copy_scalar_to_dev",
              strdup(""),
              event,
              (event_report_fn)cuda_event_report);
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
  }
  CUDA_SUCCEED_OR_RETURN(cuMemcpyHtoD(dst + offset, src, size));
  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }
  return FUTHARK_SUCCESS;
}

static int gpu_scalar_from_device(struct futhark_context* ctx,
                                  void *dst,
                                  gpu_mem src, size_t offset, size_t size) {
  struct cuda_event *event = cuda_event_new(ctx);
  if (event != NULL) {
    add_event(ctx,
              "copy_scalar_from_dev",
              strdup(""),
              event,
              (event_report_fn)cuda_event_report);
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
  }
  CUDA_SUCCEED_OR_RETURN(cuMemcpyDtoH(dst, src + offset, size));
  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }
  return FUTHARK_SUCCESS;
}

static int gpu_memcpy(struct futhark_context* ctx,
                      gpu_mem dst, int64_t dst_offset,
                      gpu_mem src, int64_t src_offset,
                      int64_t nbytes) {
  struct cuda_event *event = cuda_event_new(ctx);
  if (event != NULL) {
    add_event(ctx,
              "copy_dev_to_dev",
              strdup(""),
              event,
              (event_report_fn)cuda_event_report);
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
  }
  CUDA_SUCCEED_OR_RETURN(cuMemcpyAsync(dst+dst_offset, src+src_offset, nbytes, ctx->stream));
  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }
  return FUTHARK_SUCCESS;
}

static int memcpy_host2gpu(struct futhark_context* ctx, bool sync,
                           gpu_mem dst, int64_t dst_offset,
                           const unsigned char* src, int64_t src_offset,
                           int64_t nbytes) {
  if (nbytes > 0) {
    struct cuda_event *event = cuda_event_new(ctx);
    if (event != NULL) {
      add_event(ctx,
                "copy_host_to_dev",
                strdup(""),
                event,
                (event_report_fn)cuda_event_report);
      CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
    }
    if (sync) {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyHtoD(dst + dst_offset, src + src_offset, nbytes));
    } else {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyHtoDAsync(dst + dst_offset, src + src_offset, nbytes, ctx->stream));
    }
    if (event != NULL) {
      CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
    }
  }
  return FUTHARK_SUCCESS;
}

static int memcpy_gpu2host(struct futhark_context* ctx, bool sync,
                           unsigned char* dst, int64_t dst_offset,
                           gpu_mem src, int64_t src_offset,
                           int64_t nbytes) {
  if (nbytes > 0) {
    struct cuda_event *event = cuda_event_new(ctx);
    if (event != NULL) {
      add_event(ctx,
                "copy_dev_to_host",
                strdup(""),
                event,
                (event_report_fn)cuda_event_report);
      CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
    }
    if (sync) {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyDtoH(dst + dst_offset, src + src_offset, nbytes));
    } else {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyDtoHAsync(dst + dst_offset, src + src_offset, nbytes, ctx->stream));
    }
    if (event != NULL) {
      CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
    }
    if (sync &&
        ctx->failure_is_an_option &&
        futhark_context_sync(ctx) != 0) {
      return 1;
    }
  }
  return FUTHARK_SUCCESS;
}

static int gpu_launch_kernel(struct futhark_context* ctx,
                             gpu_kernel kernel, const char *name,
                             const int32_t grid[3],
                             const int32_t block[3],
                             unsigned int shared_mem_bytes,
                             int num_args,
                             void* args[num_args],
                             size_t args_sizes[num_args]) {
  (void) args_sizes;

  if (shared_mem_bytes > ctx->max_shared_memory) {
    set_error(ctx, msgprintf("Kernel %s with %d bytes of memory exceeds device limit of %d\n",
                             name, shared_mem_bytes, (int)ctx->max_shared_memory));
    return 1;
  }

  int64_t time_start = 0, time_end = 0;
  if (ctx->debugging) {
    time_start = get_wall_time();
  }

  struct cuda_event *event = cuda_event_new(ctx);

  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
    add_event(ctx,
              name,
              msgprintf("Kernel %s with\n"
                        "  grid=(%d,%d,%d)\n"
                        "  block=(%d,%d,%d)\n"
                        "  shared memory=%d",
                        name,
                        grid[0], grid[1], grid[2],
                        block[0], block[1], block[2],
                        shared_mem_bytes),
              event,
              (event_report_fn)cuda_event_report);
  }

  CUDA_SUCCEED_OR_RETURN
    (cuLaunchKernel(kernel,
                    grid[0], grid[1], grid[2],
                    block[0], block[1], block[2],
                    shared_mem_bytes, ctx->stream,
                    args, NULL));

  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }

  if (ctx->debugging) {
    CUDA_SUCCEED_FATAL(cuCtxSynchronize());
    time_end = get_wall_time();
    long int time_diff = time_end - time_start;
    fprintf(ctx->log, "  runtime: %ldus\n", time_diff);
  }
  if (ctx->logging) {
    fprintf(ctx->log, "\n");
  }

  return FUTHARK_SUCCESS;
}

static int gpu_alloc_actual(struct futhark_context *ctx, size_t size, gpu_mem *mem_out) {
  CUresult res;
  if (ctx->cfg->unified_memory) {
    res = cuMemAllocManaged(mem_out, size, CU_MEM_ATTACH_GLOBAL);
  } else {
    res = cuMemAlloc(mem_out, size);
  }

  if (res == CUDA_ERROR_OUT_OF_MEMORY) {
    return FUTHARK_OUT_OF_MEMORY;
  }

  CUDA_SUCCEED_OR_RETURN(res);
  return FUTHARK_SUCCESS;
}

static int gpu_free_actual(struct futhark_context *ctx, gpu_mem mem) {
  (void)ctx;
  CUDA_SUCCEED_OR_RETURN(cuMemFree(mem));
  return FUTHARK_SUCCESS;
}

// End of backends/cuda.h.

// Start of gpu.h

// Generic functions that use our tiny GPU abstraction layer.  The
// entire context must be defined before this header is included.  In
// particular we expect the following functions to be available:

static int gpu_free_actual(struct futhark_context *ctx, gpu_mem mem);
static int gpu_alloc_actual(struct futhark_context *ctx, size_t size, gpu_mem *mem_out);
int gpu_launch_kernel(struct futhark_context* ctx,
                      gpu_kernel kernel, const char *name,
                      const int32_t grid[3],
                      const int32_t block[3],
                      unsigned int shared_mem_bytes,
                      int num_args,
                      void* args[num_args],
                      size_t args_sizes[num_args]);
int gpu_memcpy(struct futhark_context* ctx,
               gpu_mem dst, int64_t dst_offset,
               gpu_mem src, int64_t src_offset,
               int64_t nbytes);
int gpu_scalar_from_device(struct futhark_context* ctx,
                           void *dst,
                           gpu_mem src, size_t offset, size_t size);
int gpu_scalar_to_device(struct futhark_context* ctx,
                         gpu_mem dst, size_t offset, size_t size,
                         void *src);
void gpu_create_kernel(struct futhark_context *ctx,
                       gpu_kernel* kernel,
                       const char* name);

static void gpu_init_log(struct futhark_context *ctx) {
  if (ctx->cfg->logging) {
    fprintf(ctx->log, "Default block size: %ld\n", (long)ctx->cfg->gpu.default_block_size);
    fprintf(ctx->log, "Default grid size: %ld\n", (long)ctx->cfg->gpu.default_grid_size);
    fprintf(ctx->log, "Default tile size: %ld\n", (long)ctx->cfg->gpu.default_tile_size);
    fprintf(ctx->log, "Default register tile size: %ld\n", (long)ctx->cfg->gpu.default_reg_tile_size);
    fprintf(ctx->log, "Default cache: %ld\n", (long)ctx->cfg->gpu.default_cache);
    fprintf(ctx->log, "Default registers: %ld\n", (long)ctx->cfg->gpu.default_registers);
    fprintf(ctx->log, "Default threshold: %ld\n", (long)ctx->cfg->gpu.default_threshold);
    fprintf(ctx->log, "Max thread block size: %ld\n", (long)ctx->max_thread_block_size);
    fprintf(ctx->log, "Max grid size: %ld\n", (long)ctx->max_grid_size);
    fprintf(ctx->log, "Max tile size: %ld\n", (long)ctx->max_tile_size);
    fprintf(ctx->log, "Max threshold: %ld\n", (long)ctx->max_threshold);
    fprintf(ctx->log, "Max shared memory: %ld\n", (long)ctx->max_shared_memory);
    fprintf(ctx->log, "Max registers: %ld\n", (long)ctx->max_registers);
    fprintf(ctx->log, "Max cache: %ld\n", (long)ctx->max_cache);
    fprintf(ctx->log, "Lockstep width: %ld\n", (long)ctx->lockstep_width);
  }
}

// Generic GPU command line options.

void futhark_context_config_set_default_thread_block_size(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_block_size = size;
  cfg->gpu.default_block_size_changed = 1;
}

void futhark_context_config_set_default_group_size(struct futhark_context_config *cfg, int size) {
  futhark_context_config_set_default_thread_block_size(cfg, size);
}

void futhark_context_config_set_default_grid_size(struct futhark_context_config *cfg, int num) {
  cfg->gpu.default_grid_size = num;
  cfg->gpu.default_grid_size_changed = 1;
}

void futhark_context_config_set_default_num_groups(struct futhark_context_config *cfg, int num) {
  futhark_context_config_set_default_grid_size(cfg, num);
}

void futhark_context_config_set_default_tile_size(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_tile_size = size;
  cfg->gpu.default_tile_size_changed = 1;
}

void futhark_context_config_set_default_reg_tile_size(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_reg_tile_size = size;
}

void futhark_context_config_set_default_cache(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_cache = size;
}

void futhark_context_config_set_default_registers(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_registers = size;
}

void futhark_context_config_set_default_threshold(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_threshold = size;
}

int futhark_context_config_set_tuning_param(struct futhark_context_config *cfg,
                                            const char *param_name,
                                            size_t new_value) {
  for (int i = 0; i < cfg->num_tuning_params; i++) {
    if (strcmp(param_name, cfg->tuning_param_names[i]) == 0) {
      cfg->tuning_params[i] = new_value;
      return 0;
    }
  }
  if (strcmp(param_name, "default_thread_block_size") == 0 ||
      strcmp(param_name, "default_group_size") == 0) {
    cfg->gpu.default_block_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_grid_size") == 0 ||
      strcmp(param_name, "default_num_groups") == 0) {
    cfg->gpu.default_grid_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_threshold") == 0) {
    cfg->gpu.default_threshold = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_tile_size") == 0) {
    cfg->gpu.default_tile_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_reg_tile_size") == 0) {
    cfg->gpu.default_reg_tile_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_cache") == 0) {
    cfg->gpu.default_cache = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_shared_memory") == 0) {
    cfg->gpu.default_shared_memory = new_value;
    return 0;
  }

  return 1;
}

// End of GPU command line optiopns.

// Max number of thead blocks we allow along the second or third
// dimension for transpositions.
#define MAX_TR_THREAD_BLOCKS 65535

struct builtin_kernels {
  // We have a lot of ways to transpose arrays.
  gpu_kernel map_transpose_1b;
  gpu_kernel map_transpose_1b_low_height;
  gpu_kernel map_transpose_1b_low_width;
  gpu_kernel map_transpose_1b_small;
  gpu_kernel map_transpose_1b_large;
  gpu_kernel map_transpose_2b;
  gpu_kernel map_transpose_2b_low_height;
  gpu_kernel map_transpose_2b_low_width;
  gpu_kernel map_transpose_2b_small;
  gpu_kernel map_transpose_2b_large;
  gpu_kernel map_transpose_4b;
  gpu_kernel map_transpose_4b_low_height;
  gpu_kernel map_transpose_4b_low_width;
  gpu_kernel map_transpose_4b_small;
  gpu_kernel map_transpose_4b_large;
  gpu_kernel map_transpose_8b;
  gpu_kernel map_transpose_8b_low_height;
  gpu_kernel map_transpose_8b_low_width;
  gpu_kernel map_transpose_8b_small;
  gpu_kernel map_transpose_8b_large;

  // And a few ways of copying.
  gpu_kernel lmad_copy_1b;
  gpu_kernel lmad_copy_2b;
  gpu_kernel lmad_copy_4b;
  gpu_kernel lmad_copy_8b;
};

struct builtin_kernels* init_builtin_kernels(struct futhark_context* ctx) {
  struct builtin_kernels *kernels = malloc(sizeof(struct builtin_kernels));
  gpu_create_kernel(ctx, &kernels->map_transpose_1b, "map_transpose_1b");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_large, "map_transpose_1b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_low_height, "map_transpose_1b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_low_width, "map_transpose_1b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_small, "map_transpose_1b_small");

  gpu_create_kernel(ctx, &kernels->map_transpose_2b, "map_transpose_2b");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_large, "map_transpose_2b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_low_height, "map_transpose_2b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_low_width, "map_transpose_2b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_small, "map_transpose_2b_small");

  gpu_create_kernel(ctx, &kernels->map_transpose_4b, "map_transpose_4b");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_large, "map_transpose_4b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_low_height, "map_transpose_4b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_low_width, "map_transpose_4b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_small, "map_transpose_4b_small");

  gpu_create_kernel(ctx, &kernels->map_transpose_8b, "map_transpose_8b");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_large, "map_transpose_8b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_low_height, "map_transpose_8b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_low_width, "map_transpose_8b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_small, "map_transpose_8b_small");

  gpu_create_kernel(ctx, &kernels->lmad_copy_1b, "lmad_copy_1b");
  gpu_create_kernel(ctx, &kernels->lmad_copy_2b, "lmad_copy_2b");
  gpu_create_kernel(ctx, &kernels->lmad_copy_4b, "lmad_copy_4b");
  gpu_create_kernel(ctx, &kernels->lmad_copy_8b, "lmad_copy_8b");

  return kernels;
}

void free_builtin_kernels(struct futhark_context* ctx, struct builtin_kernels* kernels) {
  gpu_free_kernel(ctx, kernels->map_transpose_1b);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_small);

  gpu_free_kernel(ctx, kernels->map_transpose_2b);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_small);

  gpu_free_kernel(ctx, kernels->map_transpose_4b);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_small);

  gpu_free_kernel(ctx, kernels->map_transpose_8b);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_small);

  gpu_free_kernel(ctx, kernels->lmad_copy_1b);
  gpu_free_kernel(ctx, kernels->lmad_copy_2b);
  gpu_free_kernel(ctx, kernels->lmad_copy_4b);
  gpu_free_kernel(ctx, kernels->lmad_copy_8b);

  free(kernels);
}

static int gpu_alloc(struct futhark_context *ctx, FILE *log,
                     size_t min_size, const char *tag,
                     gpu_mem *mem_out, size_t *size_out) {
  if (min_size < sizeof(int)) {
    min_size = sizeof(int);
  }

  gpu_mem* memptr;
  if (free_list_find(&ctx->gpu_free_list, min_size, tag, size_out, (fl_mem*)&memptr) == 0) {
    // Successfully found a free block.  Is it big enough?
    if (*size_out >= min_size) {
      if (ctx->cfg->debugging) {
        fprintf(log, "No need to allocate: Found a block in the free list.\n");
      }
      *mem_out = *memptr;
      free(memptr);
      return FUTHARK_SUCCESS;
    } else {
      if (ctx->cfg->debugging) {
        fprintf(log, "Found a free block, but it was too small.\n");
      }
      int error = gpu_free_actual(ctx, *memptr);
      free(memptr);
      if (error != FUTHARK_SUCCESS) {
        return error;
      }
    }
  }

  *size_out = min_size;

  // We have to allocate a new block from the driver.  If the
  // allocation does not succeed, then we might be in an out-of-memory
  // situation.  We now start freeing things from the free list until
  // we think we have freed enough that the allocation will succeed.
  // Since we don't know how far the allocation is from fitting, we
  // have to check after every deallocation.  This might be pretty
  // expensive.  Let's hope that this case is hit rarely.

  if (ctx->cfg->debugging) {
    fprintf(log, "Actually allocating the desired block.\n");
  }

  int error = gpu_alloc_actual(ctx, min_size, mem_out);

  while (error == FUTHARK_OUT_OF_MEMORY) {
    if (ctx->cfg->debugging) {
      fprintf(log, "Out of GPU memory: releasing entry from the free list...\n");
    }
    gpu_mem* memptr;
    if (free_list_first(&ctx->gpu_free_list, (fl_mem*)&memptr) == 0) {
      gpu_mem mem = *memptr;
      free(memptr);
      error = gpu_free_actual(ctx, mem);
      if (error != FUTHARK_SUCCESS) {
        return error;
      }
    } else {
      break;
    }
    error = gpu_alloc_actual(ctx, min_size, mem_out);
  }

  return error;
}

static int gpu_free(struct futhark_context *ctx,
                    gpu_mem mem, size_t size, const char *tag) {
  gpu_mem* memptr = malloc(sizeof(gpu_mem));
  *memptr = mem;
  free_list_insert(&ctx->gpu_free_list, size, (fl_mem)memptr, tag);
  return FUTHARK_SUCCESS;
}

static int gpu_free_all(struct futhark_context *ctx) {
  free_list_pack(&ctx->gpu_free_list);
  gpu_mem* memptr;
  while (free_list_first(&ctx->gpu_free_list, (fl_mem*)&memptr) == 0) {
    gpu_mem mem = *memptr;
    free(memptr);
    int error = gpu_free_actual(ctx, mem);
    if (error != FUTHARK_SUCCESS) {
      return error;
    }
  }

  return FUTHARK_SUCCESS;
}

static int gpu_map_transpose(struct futhark_context* ctx,
                             gpu_kernel kernel_default,
                             gpu_kernel kernel_low_height,
                             gpu_kernel kernel_low_width,
                             gpu_kernel kernel_small,
                             gpu_kernel kernel_large,
                             const char *name, size_t elem_size,
                             gpu_mem dst, int64_t dst_offset,
                             gpu_mem src, int64_t src_offset,
                             int64_t k, int64_t n, int64_t m) {
  int64_t mulx = TR_BLOCK_DIM / n;
  int64_t muly = TR_BLOCK_DIM / m;
  int32_t mulx32 = mulx;
  int32_t muly32 = muly;
  int32_t k32 = k;
  int32_t n32 = n;
  int32_t m32 = m;

  gpu_kernel kernel = kernel_default;
  int32_t grid[3];
  int32_t block[3];

  void* args[11];
  size_t args_sizes[11] = {
    sizeof(gpu_mem), sizeof(int64_t),
    sizeof(gpu_mem), sizeof(int64_t),
    sizeof(int32_t),
    sizeof(int32_t),
    sizeof(int32_t),
    sizeof(int32_t),
    sizeof(int32_t)
  };

  args[0] = &dst;
  args[1] = &dst_offset;
  args[2] = &src;
  args[3] = &src_offset;
  args[7] = &mulx;
  args[8] = &muly;

  if (dst_offset + k * n * m <= 2147483647L &&
      src_offset + k * n * m <= 2147483647L) {
    if (m <= TR_BLOCK_DIM/2 && n <= TR_BLOCK_DIM/2) {
      if (ctx->logging) { fprintf(ctx->log, "Using small kernel\n"); }
      kernel = kernel_small;
      grid[0] = ((k * n * m) + (TR_BLOCK_DIM*TR_BLOCK_DIM) - 1) / (TR_BLOCK_DIM*TR_BLOCK_DIM);
      grid[1] = 1;
      grid[2] = 1;
      block[0] = TR_BLOCK_DIM*TR_BLOCK_DIM;
      block[1] = 1;
      block[2] = 1;
    } else if (m <= TR_BLOCK_DIM/2 && TR_BLOCK_DIM < n) {
      if (ctx->logging) { fprintf(ctx->log, "Using low-width kernel\n"); }
      kernel = kernel_low_width;
      int64_t x_elems = m;
      int64_t y_elems = (n + muly - 1) / muly;
      grid[0] = (x_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[1] = (y_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[2] = k;
      block[0] = TR_BLOCK_DIM;
      block[1] = TR_BLOCK_DIM;
      block[2] = 1;
    } else if (n <= TR_BLOCK_DIM/2 && TR_BLOCK_DIM < m) {
      if (ctx->logging) { fprintf(ctx->log, "Using low-height kernel\n"); }
      kernel = kernel_low_height;
      int64_t x_elems = (m + mulx - 1) / mulx;
      int64_t y_elems = n;
      grid[0] = (x_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[1] = (y_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[2] = k;
      block[0] = TR_BLOCK_DIM;
      block[1] = TR_BLOCK_DIM;
      block[2] = 1;
    } else {
      if (ctx->logging) { fprintf(ctx->log, "Using default kernel\n"); }
      kernel = kernel_default;
      grid[0] = (m+TR_TILE_DIM-1)/TR_TILE_DIM;
      grid[1] = (n+TR_TILE_DIM-1)/TR_TILE_DIM;
      grid[2] = k;
      block[0] = TR_TILE_DIM;
      block[1] = TR_TILE_DIM/TR_ELEMS_PER_THREAD;
      block[2] = 1;
    }
    args[4] = &k32;
    args[5] = &m32;
    args[6] = &n32;
    args[7] = &mulx32;
    args[8] = &muly32;
  } else {
    if (ctx->logging) { fprintf(ctx->log, "Using large kernel\n"); }
    kernel = kernel_large;
    grid[0] = (m+TR_TILE_DIM-1)/TR_TILE_DIM;
    grid[1] = (n+TR_TILE_DIM-1)/TR_TILE_DIM;
    grid[2] = k;
    block[0] = TR_TILE_DIM;
    block[1] = TR_TILE_DIM/TR_ELEMS_PER_THREAD;
    block[2] = 1;
    args[4] = &k;
    args[5] = &m;
    args[6] = &n;
    args[7] = &mulx;
    args[8] = &muly;
    args_sizes[4] = sizeof(int64_t);
    args_sizes[5] = sizeof(int64_t);
    args_sizes[6] = sizeof(int64_t);
    args_sizes[7] = sizeof(int64_t);
    args_sizes[8] = sizeof(int64_t);
  }

  // Cap the number of thead blocks we launch and figure out how many
  // repeats we need alongside each dimension.
  int32_t repeat_1 = grid[1] / MAX_TR_THREAD_BLOCKS;
  int32_t repeat_2 = grid[2] / MAX_TR_THREAD_BLOCKS;
  grid[1] = repeat_1 > 0 ? MAX_TR_THREAD_BLOCKS : grid[1];
  grid[2] = repeat_2 > 0 ? MAX_TR_THREAD_BLOCKS : grid[2];
  args[9] = &repeat_1;
  args[10] = &repeat_2;
  args_sizes[9] = sizeof(repeat_1);
  args_sizes[10] = sizeof(repeat_2);

  if (ctx->logging) {
    fprintf(ctx->log, "\n");
  }

  return gpu_launch_kernel(ctx, kernel, name, grid, block,
                           TR_TILE_DIM*(TR_TILE_DIM+1)*elem_size,
                           sizeof(args)/sizeof(args[0]), args, args_sizes);
}

#define GEN_MAP_TRANSPOSE_GPU2GPU(NAME, ELEM_TYPE)                      \
  static int map_transpose_gpu2gpu_##NAME                               \
  (struct futhark_context* ctx,                                         \
   gpu_mem dst, int64_t dst_offset,                                     \
   gpu_mem src, int64_t src_offset,                                     \
   int64_t k, int64_t m, int64_t n)                                     \
  {                                                                     \
    return                                                              \
      gpu_map_transpose                                                 \
      (ctx,                                                             \
       ctx->kernels->map_transpose_##NAME,                              \
       ctx->kernels->map_transpose_##NAME##_low_height,                 \
       ctx->kernels->map_transpose_##NAME##_low_width,                  \
       ctx->kernels->map_transpose_##NAME##_small,                      \
       ctx->kernels->map_transpose_##NAME##_large,                      \
       "map_transpose_" #NAME, sizeof(ELEM_TYPE),                       \
       dst, dst_offset, src, src_offset,                                \
       k, n, m);                                                        \
  }

static int gpu_lmad_copy(struct futhark_context* ctx,
                         gpu_kernel kernel, int r,
                         gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],
                         gpu_mem src, int64_t src_offset, int64_t src_strides[r],
                         int64_t shape[r]) {
  if (r > 8) {
    set_error(ctx, strdup("Futhark runtime limitation:\nCannot copy array of greater than rank 8.\n"));
    return 1;
  }

  int64_t n = 1;
  for (int i = 0; i < r; i++) { n *= shape[i]; }

  void* args[6+(8*3)];
  size_t args_sizes[6+(8*3)];

  args[0] = &dst;
  args_sizes[0] = sizeof(gpu_mem);
  args[1] = &dst_offset;
  args_sizes[1] = sizeof(dst_offset);
  args[2] = &src;
  args_sizes[2] = sizeof(gpu_mem);
  args[3] = &src_offset;
  args_sizes[3] = sizeof(src_offset);
  args[4] = &n;
  args_sizes[4] = sizeof(n);
  args[5] = &r;
  args_sizes[5] = sizeof(r);

  int64_t zero = 0;

  for (int i = 0; i < 8; i++) {
    args_sizes[6+i*3] = sizeof(int64_t);
    args_sizes[6+i*3+1] = sizeof(int64_t);
    args_sizes[6+i*3+2] = sizeof(int64_t);
    if (i < r) {
      args[6+i*3] = &shape[i];
      args[6+i*3+1] = &dst_strides[i];
      args[6+i*3+2] = &src_strides[i];
    } else {
      args[6+i*3] = &zero;
      args[6+i*3+1] = &zero;
      args[6+i*3+2] = &zero;
    }
  }
  const size_t w = 256; // XXX: hardcoded thread block size.

  return gpu_launch_kernel(ctx, kernel, "copy_lmad_dev_to_dev",
                           (const int32_t[3]) {(n+w-1)/w,1,1},
                           (const int32_t[3]) {w,1,1},
                           0, 6+(8*3), args, args_sizes);
}

#define GEN_LMAD_COPY_ELEMENTS_GPU2GPU(NAME, ELEM_TYPE)                 \
  static int lmad_copy_elements_gpu2gpu_##NAME                          \
  (struct futhark_context* ctx,                                         \
   int r,                                                               \
   gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],             \
   gpu_mem src, int64_t src_offset, int64_t src_strides[r],             \
   int64_t shape[r]) {                                                  \
    return gpu_lmad_copy(ctx, ctx->kernels->lmad_copy_##NAME, r,        \
                         dst, dst_offset, dst_strides,                  \
                         src, src_offset, src_strides,                  \
                         shape);                                        \
  }                                                                     \

#define GEN_LMAD_COPY_GPU2GPU(NAME, ELEM_TYPE)                          \
  static int lmad_copy_gpu2gpu_##NAME                                   \
  (struct futhark_context* ctx,                                         \
   int r,                                                               \
   gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],             \
   gpu_mem src, int64_t src_offset, int64_t src_strides[r],             \
   int64_t shape[r]) {                                                  \
    log_copy(ctx, "GPU to GPU", r, dst_offset, dst_strides,             \
             src_offset, src_strides, shape);                           \
    int64_t size = 1;                                                   \
    for (int i = 0; i < r; i++) { size *= shape[i]; }                   \
    if (size == 0) { return FUTHARK_SUCCESS; }                          \
    int64_t k, n, m;                                                    \
    if (lmad_map_tr(&k, &n, &m,                                         \
                       r, dst_strides, src_strides, shape)) {           \
      log_transpose(ctx, k, n, m);                                      \
      return map_transpose_gpu2gpu_##NAME                               \
        (ctx, dst, dst_offset, src, src_offset, k, n, m);               \
    } else if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {   \
      if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}        \
      return gpu_memcpy(ctx,                                            \
                        dst, dst_offset*sizeof(ELEM_TYPE),              \
                        src, src_offset*sizeof(ELEM_TYPE),              \
                        size * sizeof(ELEM_TYPE));                      \
    } else {                                                            \
      if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}     \
      return lmad_copy_elements_gpu2gpu_##NAME                          \
        (ctx, r,                                                        \
         dst, dst_offset, dst_strides,                                  \
         src, src_offset, src_strides,                                  \
         shape);                                                        \
    }                                                                   \
  }

static int
lmad_copy_elements_host2gpu(struct futhark_context *ctx, size_t elem_size,
                            int r,
                            gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],
                            unsigned char* src, int64_t src_offset, int64_t src_strides[r],
                            int64_t shape[r]) {
  (void)ctx; (void)elem_size; (void)r;
  (void)dst; (void)dst_offset; (void)dst_strides;
  (void)src; (void)src_offset; (void)src_strides;
  (void)shape;
  set_error(ctx, strdup("Futhark runtime limitation:\nCannot copy unstructured array from host to GPU.\n"));
  return 1;
}

static int
lmad_copy_elements_gpu2host (struct futhark_context *ctx, size_t elem_size,
                             int r,
                             unsigned char* dst, int64_t dst_offset, int64_t dst_strides[r],
                             gpu_mem src, int64_t src_offset, int64_t src_strides[r],
                             int64_t shape[r]) {
  (void)ctx; (void)elem_size; (void)r;
  (void)dst; (void)dst_offset; (void)dst_strides;
  (void)src; (void)src_offset; (void)src_strides;
  (void)shape;
  set_error(ctx, strdup("Futhark runtime limitation:\nCannot copy unstructured array from GPU to host.\n"));
  return 1;
}

#define GEN_LMAD_COPY_ELEMENTS_HOSTGPU(NAME, ELEM_TYPE)                 \
  static int lmad_copy_elements_gpu2gpu_##NAME                          \
  (struct futhark_context* ctx,                                         \
   int r,                                                               \
   gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],             \
   gpu_mem src, int64_t src_offset, int64_t src_strides[r],             \
   int64_t shape[r]) {                                                  \
    return (ctx, ctx->kernels->lmad_copy_##NAME, r,                     \
                         dst, dst_offset, dst_strides,                  \
                         src, src_offset, src_strides,                  \
                         shape);                                        \
  }                                                                     \


static int lmad_copy_host2gpu(struct futhark_context* ctx, size_t elem_size, bool sync,
                              int r,
                              gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],
                              unsigned char* src, int64_t src_offset, int64_t src_strides[r],
                              int64_t shape[r]) {
  log_copy(ctx, "Host to GPU", r, dst_offset, dst_strides,
           src_offset, src_strides, shape);
  int64_t size = elem_size;
  for (int i = 0; i < r; i++) { size *= shape[i]; }
  if (size == 0) { return FUTHARK_SUCCESS; }
  int64_t k, n, m;
  if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {
    if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}
    return memcpy_host2gpu(ctx, sync,
                           dst, dst_offset*elem_size,
                           src, src_offset*elem_size,
                           size);
  } else {
    if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}
    int error;
    error = lmad_copy_elements_host2gpu
      (ctx, elem_size, r,
       dst, dst_offset, dst_strides,
       src, src_offset, src_strides,
       shape);
    if (error == 0 && sync) {
      error = futhark_context_sync(ctx);
    }
    return error;
  }
}

static int lmad_copy_gpu2host(struct futhark_context* ctx, size_t elem_size, bool sync,
                              int r,
                              unsigned char* dst, int64_t dst_offset, int64_t dst_strides[r],
                              gpu_mem src, int64_t src_offset, int64_t src_strides[r],
                              int64_t shape[r]) {
  log_copy(ctx, "Host to GPU", r, dst_offset, dst_strides,
           src_offset, src_strides, shape);
  int64_t size = elem_size;
  for (int i = 0; i < r; i++) { size *= shape[i]; }
  if (size == 0) { return FUTHARK_SUCCESS; }
  int64_t k, n, m;
  if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {
    if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}
    return memcpy_gpu2host(ctx, sync,
                           dst, dst_offset*elem_size,
                           src, src_offset*elem_size,
                           size);
  } else {
    if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}
    int error;
    error = lmad_copy_elements_gpu2host
      (ctx, elem_size, r,
       dst, dst_offset, dst_strides,
       src, src_offset, src_strides,
       shape);
    if (error == 0 && sync) {
      error = futhark_context_sync(ctx);
    }
    return error;
  }
}

GEN_MAP_TRANSPOSE_GPU2GPU(1b, uint8_t)
GEN_MAP_TRANSPOSE_GPU2GPU(2b, uint16_t)
GEN_MAP_TRANSPOSE_GPU2GPU(4b, uint32_t)
GEN_MAP_TRANSPOSE_GPU2GPU(8b, uint64_t)

GEN_LMAD_COPY_ELEMENTS_GPU2GPU(1b, uint8_t)
GEN_LMAD_COPY_ELEMENTS_GPU2GPU(2b, uint16_t)
GEN_LMAD_COPY_ELEMENTS_GPU2GPU(4b, uint32_t)
GEN_LMAD_COPY_ELEMENTS_GPU2GPU(8b, uint64_t)

GEN_LMAD_COPY_GPU2GPU(1b, uint8_t)
GEN_LMAD_COPY_GPU2GPU(2b, uint16_t)
GEN_LMAD_COPY_GPU2GPU(4b, uint32_t)
GEN_LMAD_COPY_GPU2GPU(8b, uint64_t)

// End of gpu.h

static int gpu_macros(struct futhark_context *ctx, char ***names_out, int64_t **values_out)
{
    int num_macros = 146;
    char **names = malloc(num_macros * sizeof(char *));
    int64_t *values = malloc(num_macros * sizeof(int64_t));
    
    {
        names[0] = "min_idxzisegred_nonseg_32810_dim1";
        values[0] = *ctx->tuning_params.min_idxzisegred_tblock_sizze_32802;
    }
    {
        names[1] = "min_idxzisegred_nonseg_32810zisegred_tblock_sizze_32803";
        values[1] = *ctx->tuning_params.min_idxzisegred_tblock_sizze_32802;
    }
    {
        names[2] = "min_idxzisegred_nonseg_32810zichunk_sizze_34021";
        values[2] = (int64_t) 1;
    }
    {
        names[3] = "max_idxzisegred_nonseg_32820_dim1";
        values[3] = *ctx->tuning_params.max_idxzisegred_tblock_sizze_32812;
    }
    {
        names[4] = "max_idxzisegred_nonseg_32820zisegred_tblock_sizze_32813";
        values[4] = *ctx->tuning_params.max_idxzisegred_tblock_sizze_32812;
    }
    {
        names[5] = "max_idxzisegred_nonseg_32820zichunk_sizze_34021";
        values[5] = (int64_t) 1;
    }
    {
        names[6] = "inner_SMJ_shortzisegmap_33462_dim1";
        values[6] = *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_33450;
    }
    {
        names[7] = "inner_SMJ_shortzisegmap_33462zisegmap_tblock_sizze_33458";
        values[7] = *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_33450;
    }
    {
        names[8] = "inner_SMJ_shortzigpuseq_34458_dim1";
        values[8] = (int64_t) 1;
    }
    {
        names[9] = "inner_SMJ_shortzisegmap_33432_dim1";
        values[9] = *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_33434;
    }
    {
        names[10] = "inner_SMJ_shortzisegmap_33432zisegmap_tblock_sizze_33435";
        values[10] = *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_33434;
    }
    {
        names[11] = "inner_SMJ_shortzisegmap_33440_dim1";
        values[11] = *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_33442;
    }
    {
        names[12] = "inner_SMJ_shortzisegmap_33440zisegmap_tblock_sizze_33443";
        values[12] = *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_33442;
    }
    {
        names[13] = "inner_SMJ_shortzigpuseq_34391_dim1";
        values[13] = (int64_t) 1;
    }
    {
        names[14] = "inner_SMJ_shortzigpuseq_34385_dim1";
        values[14] = (int64_t) 1;
    }
    {
        names[15] = "inner_SMJ_shortzigpuseq_34379_dim1";
        values[15] = (int64_t) 1;
    }
    {
        names[16] = "inner_SMJ_shortzisegmap_33424_dim1";
        values[16] = *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_33408;
    }
    {
        names[17] = "inner_SMJ_shortzisegmap_33424zisegmap_tblock_sizze_33420";
        values[17] = *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_33408;
    }
    {
        names[18] = "inner_SMJ_shortzisegscan_33404_dim1";
        values[18] = *ctx->tuning_params.inner_SMJ_shortzisegscan_tblock_sizze_33398;
    }
    {
        names[19] = "inner_SMJ_shortzisegscan_33404zisegscan_tblock_sizze_33399";
        values[19] = *ctx->tuning_params.inner_SMJ_shortzisegscan_tblock_sizze_33398;
    }
    {
        names[20] = "inner_SMJ_shortzisegscan_33404zichunk_sizze_34222";
        values[20] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[21] = "inner_SMJ_shortzisegmap_33390_dim1";
        values[21] = *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_33392;
    }
    {
        names[22] = "inner_SMJ_shortzisegmap_33390zisegmap_tblock_sizze_33393";
        values[22] = *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_33392;
    }
    {
        names[23] = "inner_SMJ_shortzisegscan_33388_dim1";
        values[23] = *ctx->tuning_params.inner_SMJ_shortzisegscan_tblock_sizze_33382;
    }
    {
        names[24] = "inner_SMJ_shortzisegscan_33388zisegscan_tblock_sizze_33383";
        values[24] = *ctx->tuning_params.inner_SMJ_shortzisegscan_tblock_sizze_33382;
    }
    {
        names[25] = "inner_SMJ_shortzisegscan_33388zichunk_sizze_34028";
        values[25] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[26] = "inner_SMJ_longzisegmap_33630_dim1";
        values[26] = *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_33618;
    }
    {
        names[27] = "inner_SMJ_longzisegmap_33630zisegmap_tblock_sizze_33626";
        values[27] = *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_33618;
    }
    {
        names[28] = "inner_SMJ_longzigpuseq_34438_dim1";
        values[28] = (int64_t) 1;
    }
    {
        names[29] = "inner_SMJ_longzisegmap_33600_dim1";
        values[29] = *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_33602;
    }
    {
        names[30] = "inner_SMJ_longzisegmap_33600zisegmap_tblock_sizze_33603";
        values[30] = *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_33602;
    }
    {
        names[31] = "inner_SMJ_longzisegmap_33608_dim1";
        values[31] = *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_33610;
    }
    {
        names[32] = "inner_SMJ_longzisegmap_33608zisegmap_tblock_sizze_33611";
        values[32] = *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_33610;
    }
    {
        names[33] = "inner_SMJ_longzigpuseq_34391_dim1";
        values[33] = (int64_t) 1;
    }
    {
        names[34] = "inner_SMJ_longzigpuseq_34385_dim1";
        values[34] = (int64_t) 1;
    }
    {
        names[35] = "inner_SMJ_longzigpuseq_34379_dim1";
        values[35] = (int64_t) 1;
    }
    {
        names[36] = "inner_SMJ_longzisegmap_33592_dim1";
        values[36] = *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_33576;
    }
    {
        names[37] = "inner_SMJ_longzisegmap_33592zisegmap_tblock_sizze_33588";
        values[37] = *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_33576;
    }
    {
        names[38] = "inner_SMJ_longzisegscan_33572_dim1";
        values[38] = *ctx->tuning_params.inner_SMJ_longzisegscan_tblock_sizze_33566;
    }
    {
        names[39] = "inner_SMJ_longzisegscan_33572zisegscan_tblock_sizze_33567";
        values[39] = *ctx->tuning_params.inner_SMJ_longzisegscan_tblock_sizze_33566;
    }
    {
        names[40] = "inner_SMJ_longzisegscan_33572zichunk_sizze_34222";
        values[40] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[41] = "inner_SMJ_longzisegmap_33558_dim1";
        values[41] = *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_33560;
    }
    {
        names[42] = "inner_SMJ_longzisegmap_33558zisegmap_tblock_sizze_33561";
        values[42] = *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_33560;
    }
    {
        names[43] = "inner_SMJ_longzisegscan_33556_dim1";
        values[43] = *ctx->tuning_params.inner_SMJ_longzisegscan_tblock_sizze_33550;
    }
    {
        names[44] = "inner_SMJ_longzisegscan_33556zisegscan_tblock_sizze_33551";
        values[44] = *ctx->tuning_params.inner_SMJ_longzisegscan_tblock_sizze_33550;
    }
    {
        names[45] = "inner_SMJ_longzisegscan_33556zichunk_sizze_34028";
        values[45] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[46] = "inner_SMJ_intzisegmap_33546_dim1";
        values[46] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_33534;
    }
    {
        names[47] = "inner_SMJ_intzisegmap_33546zisegmap_tblock_sizze_33542";
        values[47] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_33534;
    }
    {
        names[48] = "inner_SMJ_intzigpuseq_34438_dim1";
        values[48] = (int64_t) 1;
    }
    {
        names[49] = "inner_SMJ_intzisegmap_33516_dim1";
        values[49] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_33518;
    }
    {
        names[50] = "inner_SMJ_intzisegmap_33516zisegmap_tblock_sizze_33519";
        values[50] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_33518;
    }
    {
        names[51] = "inner_SMJ_intzisegmap_33524_dim1";
        values[51] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_33526;
    }
    {
        names[52] = "inner_SMJ_intzisegmap_33524zisegmap_tblock_sizze_33527";
        values[52] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_33526;
    }
    {
        names[53] = "inner_SMJ_intzigpuseq_34391_dim1";
        values[53] = (int64_t) 1;
    }
    {
        names[54] = "inner_SMJ_intzigpuseq_34385_dim1";
        values[54] = (int64_t) 1;
    }
    {
        names[55] = "inner_SMJ_intzigpuseq_34379_dim1";
        values[55] = (int64_t) 1;
    }
    {
        names[56] = "inner_SMJ_intzisegmap_33508_dim1";
        values[56] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_33492;
    }
    {
        names[57] = "inner_SMJ_intzisegmap_33508zisegmap_tblock_sizze_33504";
        values[57] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_33492;
    }
    {
        names[58] = "inner_SMJ_intzisegscan_33488_dim1";
        values[58] = *ctx->tuning_params.inner_SMJ_intzisegscan_tblock_sizze_33482;
    }
    {
        names[59] = "inner_SMJ_intzisegscan_33488zisegscan_tblock_sizze_33483";
        values[59] = *ctx->tuning_params.inner_SMJ_intzisegscan_tblock_sizze_33482;
    }
    {
        names[60] = "inner_SMJ_intzisegscan_33488zichunk_sizze_34222";
        values[60] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[61] = "inner_SMJ_intzisegmap_33474_dim1";
        values[61] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_33476;
    }
    {
        names[62] = "inner_SMJ_intzisegmap_33474zisegmap_tblock_sizze_33477";
        values[62] = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_33476;
    }
    {
        names[63] = "inner_SMJ_intzisegscan_33472_dim1";
        values[63] = *ctx->tuning_params.inner_SMJ_intzisegscan_tblock_sizze_33466;
    }
    {
        names[64] = "inner_SMJ_intzisegscan_33472zisegscan_tblock_sizze_33467";
        values[64] = *ctx->tuning_params.inner_SMJ_intzisegscan_tblock_sizze_33466;
    }
    {
        names[65] = "inner_SMJ_intzisegscan_33472zichunk_sizze_34028";
        values[65] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[66] = "inner_SMJ_floatzisegmap_33714_dim1";
        values[66] = *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_33702;
    }
    {
        names[67] = "inner_SMJ_floatzisegmap_33714zisegmap_tblock_sizze_33710";
        values[67] = *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_33702;
    }
    {
        names[68] = "inner_SMJ_floatzigpuseq_34458_dim1";
        values[68] = (int64_t) 1;
    }
    {
        names[69] = "inner_SMJ_floatzisegmap_33684_dim1";
        values[69] = *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_33686;
    }
    {
        names[70] = "inner_SMJ_floatzisegmap_33684zisegmap_tblock_sizze_33687";
        values[70] = *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_33686;
    }
    {
        names[71] = "inner_SMJ_floatzisegmap_33692_dim1";
        values[71] = *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_33694;
    }
    {
        names[72] = "inner_SMJ_floatzisegmap_33692zisegmap_tblock_sizze_33695";
        values[72] = *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_33694;
    }
    {
        names[73] = "inner_SMJ_floatzigpuseq_34391_dim1";
        values[73] = (int64_t) 1;
    }
    {
        names[74] = "inner_SMJ_floatzigpuseq_34385_dim1";
        values[74] = (int64_t) 1;
    }
    {
        names[75] = "inner_SMJ_floatzigpuseq_34379_dim1";
        values[75] = (int64_t) 1;
    }
    {
        names[76] = "inner_SMJ_floatzisegmap_33676_dim1";
        values[76] = *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_33660;
    }
    {
        names[77] = "inner_SMJ_floatzisegmap_33676zisegmap_tblock_sizze_33672";
        values[77] = *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_33660;
    }
    {
        names[78] = "inner_SMJ_floatzisegscan_33656_dim1";
        values[78] = *ctx->tuning_params.inner_SMJ_floatzisegscan_tblock_sizze_33650;
    }
    {
        names[79] = "inner_SMJ_floatzisegscan_33656zisegscan_tblock_sizze_33651";
        values[79] = *ctx->tuning_params.inner_SMJ_floatzisegscan_tblock_sizze_33650;
    }
    {
        names[80] = "inner_SMJ_floatzisegscan_33656zichunk_sizze_34222";
        values[80] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[81] = "inner_SMJ_floatzisegmap_33642_dim1";
        values[81] = *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_33644;
    }
    {
        names[82] = "inner_SMJ_floatzisegmap_33642zisegmap_tblock_sizze_33645";
        values[82] = *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_33644;
    }
    {
        names[83] = "inner_SMJ_floatzisegscan_33640_dim1";
        values[83] = *ctx->tuning_params.inner_SMJ_floatzisegscan_tblock_sizze_33634;
    }
    {
        names[84] = "inner_SMJ_floatzisegscan_33640zisegscan_tblock_sizze_33635";
        values[84] = *ctx->tuning_params.inner_SMJ_floatzisegscan_tblock_sizze_33634;
    }
    {
        names[85] = "inner_SMJ_floatzisegscan_33640zichunk_sizze_34028";
        values[85] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[86] = "inner_SMJ_doublezisegmap_33798_dim1";
        values[86] = *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_33786;
    }
    {
        names[87] = "inner_SMJ_doublezisegmap_33798zisegmap_tblock_sizze_33794";
        values[87] = *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_33786;
    }
    {
        names[88] = "inner_SMJ_doublezigpuseq_34458_dim1";
        values[88] = (int64_t) 1;
    }
    {
        names[89] = "inner_SMJ_doublezisegmap_33768_dim1";
        values[89] = *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_33770;
    }
    {
        names[90] = "inner_SMJ_doublezisegmap_33768zisegmap_tblock_sizze_33771";
        values[90] = *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_33770;
    }
    {
        names[91] = "inner_SMJ_doublezisegmap_33776_dim1";
        values[91] = *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_33778;
    }
    {
        names[92] = "inner_SMJ_doublezisegmap_33776zisegmap_tblock_sizze_33779";
        values[92] = *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_33778;
    }
    {
        names[93] = "inner_SMJ_doublezigpuseq_34391_dim1";
        values[93] = (int64_t) 1;
    }
    {
        names[94] = "inner_SMJ_doublezigpuseq_34385_dim1";
        values[94] = (int64_t) 1;
    }
    {
        names[95] = "inner_SMJ_doublezigpuseq_34379_dim1";
        values[95] = (int64_t) 1;
    }
    {
        names[96] = "inner_SMJ_doublezisegmap_33760_dim1";
        values[96] = *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_33744;
    }
    {
        names[97] = "inner_SMJ_doublezisegmap_33760zisegmap_tblock_sizze_33756";
        values[97] = *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_33744;
    }
    {
        names[98] = "inner_SMJ_doublezisegscan_33740_dim1";
        values[98] = *ctx->tuning_params.inner_SMJ_doublezisegscan_tblock_sizze_33734;
    }
    {
        names[99] = "inner_SMJ_doublezisegscan_33740zisegscan_tblock_sizze_33735";
        values[99] = *ctx->tuning_params.inner_SMJ_doublezisegscan_tblock_sizze_33734;
    }
    {
        names[100] = "inner_SMJ_doublezisegscan_33740zichunk_sizze_34222";
        values[100] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[101] = "inner_SMJ_doublezisegmap_33726_dim1";
        values[101] = *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_33728;
    }
    {
        names[102] = "inner_SMJ_doublezisegmap_33726zisegmap_tblock_sizze_33729";
        values[102] = *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_33728;
    }
    {
        names[103] = "inner_SMJ_doublezisegscan_33724_dim1";
        values[103] = *ctx->tuning_params.inner_SMJ_doublezisegscan_tblock_sizze_33718;
    }
    {
        names[104] = "inner_SMJ_doublezisegscan_33724zisegscan_tblock_sizze_33719";
        values[104] = *ctx->tuning_params.inner_SMJ_doublezisegscan_tblock_sizze_33718;
    }
    {
        names[105] = "inner_SMJ_doublezisegscan_33724zichunk_sizze_34028";
        values[105] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[106] = "gather_payloads_short_GFURzisegmap_33144_dim1";
        values[106] = *ctx->tuning_params.gather_payloads_short_GFURzisegmap_tblock_sizze_33122;
    }
    {
        names[107] = "gather_payloads_short_GFURzisegmap_33144zisegmap_tblock_sizze_33140";
        values[107] = *ctx->tuning_params.gather_payloads_short_GFURzisegmap_tblock_sizze_33122;
    }
    {
        names[108] = "gather_payloads_short_GFURzisegmap_33116_dim1";
        values[108] = *ctx->tuning_params.gather_payloads_short_GFURzisegmap_tblock_sizze_33104;
    }
    {
        names[109] = "gather_payloads_short_GFURzisegmap_33116zisegmap_tblock_sizze_33112";
        values[109] = *ctx->tuning_params.gather_payloads_short_GFURzisegmap_tblock_sizze_33104;
    }
    {
        names[110] = "gather_payloads_shortzisegmap_32864_dim1";
        values[110] = *ctx->tuning_params.gather_payloads_shortzisegmap_tblock_sizze_32842;
    }
    {
        names[111] = "gather_payloads_shortzisegmap_32864zisegmap_tblock_sizze_32860";
        values[111] = *ctx->tuning_params.gather_payloads_shortzisegmap_tblock_sizze_32842;
    }
    {
        names[112] = "gather_payloads_shortzisegmap_32836_dim1";
        values[112] = *ctx->tuning_params.gather_payloads_shortzisegmap_tblock_sizze_32824;
    }
    {
        names[113] = "gather_payloads_shortzisegmap_32836zisegmap_tblock_sizze_32832";
        values[113] = *ctx->tuning_params.gather_payloads_shortzisegmap_tblock_sizze_32824;
    }
    {
        names[114] = "gather_payloads_long_GFURzisegmap_33256_dim1";
        values[114] = *ctx->tuning_params.gather_payloads_long_GFURzisegmap_tblock_sizze_33234;
    }
    {
        names[115] = "gather_payloads_long_GFURzisegmap_33256zisegmap_tblock_sizze_33252";
        values[115] = *ctx->tuning_params.gather_payloads_long_GFURzisegmap_tblock_sizze_33234;
    }
    {
        names[116] = "gather_payloads_long_GFURzisegmap_33228_dim1";
        values[116] = *ctx->tuning_params.gather_payloads_long_GFURzisegmap_tblock_sizze_33216;
    }
    {
        names[117] = "gather_payloads_long_GFURzisegmap_33228zisegmap_tblock_sizze_33224";
        values[117] = *ctx->tuning_params.gather_payloads_long_GFURzisegmap_tblock_sizze_33216;
    }
    {
        names[118] = "gather_payloads_longzisegmap_32976_dim1";
        values[118] = *ctx->tuning_params.gather_payloads_longzisegmap_tblock_sizze_32954;
    }
    {
        names[119] = "gather_payloads_longzisegmap_32976zisegmap_tblock_sizze_32972";
        values[119] = *ctx->tuning_params.gather_payloads_longzisegmap_tblock_sizze_32954;
    }
    {
        names[120] = "gather_payloads_longzisegmap_32948_dim1";
        values[120] = *ctx->tuning_params.gather_payloads_longzisegmap_tblock_sizze_32936;
    }
    {
        names[121] = "gather_payloads_longzisegmap_32948zisegmap_tblock_sizze_32944";
        values[121] = *ctx->tuning_params.gather_payloads_longzisegmap_tblock_sizze_32936;
    }
    {
        names[122] = "gather_payloads_int_GFURzisegmap_33200_dim1";
        values[122] = *ctx->tuning_params.gather_payloads_int_GFURzisegmap_tblock_sizze_33178;
    }
    {
        names[123] = "gather_payloads_int_GFURzisegmap_33200zisegmap_tblock_sizze_33196";
        values[123] = *ctx->tuning_params.gather_payloads_int_GFURzisegmap_tblock_sizze_33178;
    }
    {
        names[124] = "gather_payloads_int_GFURzisegmap_33172_dim1";
        values[124] = *ctx->tuning_params.gather_payloads_int_GFURzisegmap_tblock_sizze_33160;
    }
    {
        names[125] = "gather_payloads_int_GFURzisegmap_33172zisegmap_tblock_sizze_33168";
        values[125] = *ctx->tuning_params.gather_payloads_int_GFURzisegmap_tblock_sizze_33160;
    }
    {
        names[126] = "gather_payloads_intzisegmap_32920_dim1";
        values[126] = *ctx->tuning_params.gather_payloads_intzisegmap_tblock_sizze_32898;
    }
    {
        names[127] = "gather_payloads_intzisegmap_32920zisegmap_tblock_sizze_32916";
        values[127] = *ctx->tuning_params.gather_payloads_intzisegmap_tblock_sizze_32898;
    }
    {
        names[128] = "gather_payloads_intzisegmap_32892_dim1";
        values[128] = *ctx->tuning_params.gather_payloads_intzisegmap_tblock_sizze_32880;
    }
    {
        names[129] = "gather_payloads_intzisegmap_32892zisegmap_tblock_sizze_32888";
        values[129] = *ctx->tuning_params.gather_payloads_intzisegmap_tblock_sizze_32880;
    }
    {
        names[130] = "gather_payloads_float_GFURzisegmap_33312_dim1";
        values[130] = *ctx->tuning_params.gather_payloads_float_GFURzisegmap_tblock_sizze_33290;
    }
    {
        names[131] = "gather_payloads_float_GFURzisegmap_33312zisegmap_tblock_sizze_33308";
        values[131] = *ctx->tuning_params.gather_payloads_float_GFURzisegmap_tblock_sizze_33290;
    }
    {
        names[132] = "gather_payloads_float_GFURzisegmap_33284_dim1";
        values[132] = *ctx->tuning_params.gather_payloads_float_GFURzisegmap_tblock_sizze_33272;
    }
    {
        names[133] = "gather_payloads_float_GFURzisegmap_33284zisegmap_tblock_sizze_33280";
        values[133] = *ctx->tuning_params.gather_payloads_float_GFURzisegmap_tblock_sizze_33272;
    }
    {
        names[134] = "gather_payloads_floatzisegmap_33032_dim1";
        values[134] = *ctx->tuning_params.gather_payloads_floatzisegmap_tblock_sizze_33010;
    }
    {
        names[135] = "gather_payloads_floatzisegmap_33032zisegmap_tblock_sizze_33028";
        values[135] = *ctx->tuning_params.gather_payloads_floatzisegmap_tblock_sizze_33010;
    }
    {
        names[136] = "gather_payloads_floatzisegmap_33004_dim1";
        values[136] = *ctx->tuning_params.gather_payloads_floatzisegmap_tblock_sizze_32992;
    }
    {
        names[137] = "gather_payloads_floatzisegmap_33004zisegmap_tblock_sizze_33000";
        values[137] = *ctx->tuning_params.gather_payloads_floatzisegmap_tblock_sizze_32992;
    }
    {
        names[138] = "gather_payloads_double_GFURzisegmap_33368_dim1";
        values[138] = *ctx->tuning_params.gather_payloads_double_GFURzisegmap_tblock_sizze_33346;
    }
    {
        names[139] = "gather_payloads_double_GFURzisegmap_33368zisegmap_tblock_sizze_33364";
        values[139] = *ctx->tuning_params.gather_payloads_double_GFURzisegmap_tblock_sizze_33346;
    }
    {
        names[140] = "gather_payloads_double_GFURzisegmap_33340_dim1";
        values[140] = *ctx->tuning_params.gather_payloads_double_GFURzisegmap_tblock_sizze_33328;
    }
    {
        names[141] = "gather_payloads_double_GFURzisegmap_33340zisegmap_tblock_sizze_33336";
        values[141] = *ctx->tuning_params.gather_payloads_double_GFURzisegmap_tblock_sizze_33328;
    }
    {
        names[142] = "gather_payloads_doublezisegmap_33088_dim1";
        values[142] = *ctx->tuning_params.gather_payloads_doublezisegmap_tblock_sizze_33066;
    }
    {
        names[143] = "gather_payloads_doublezisegmap_33088zisegmap_tblock_sizze_33084";
        values[143] = *ctx->tuning_params.gather_payloads_doublezisegmap_tblock_sizze_33066;
    }
    {
        names[144] = "gather_payloads_doublezisegmap_33060_dim1";
        values[144] = *ctx->tuning_params.gather_payloads_doublezisegmap_tblock_sizze_33048;
    }
    {
        names[145] = "gather_payloads_doublezisegmap_33060zisegmap_tblock_sizze_33056";
        values[145] = *ctx->tuning_params.gather_payloads_doublezisegmap_tblock_sizze_33048;
    }
    *names_out = names;
    *values_out = values;
    return num_macros;
}
static char *get_failure_msg(int failure_idx, int64_t args[])
{
    (void) args;
    switch (failure_idx) {
        
      case 0:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:34:16-37\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftbasics.fut:32:30-36:6\n   #3  ftSMJ.fut:433:5-41\n   #4  ftSMJ.fut:432:1-433:41\n", args[0], args[1]);
            break;
        }
        
      case 1:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:52:16-37\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftbasics.fut:50:30-54:6\n   #3  ftSMJ.fut:461:5-50\n   #4  ftSMJ.fut:460:1-461:50\n", args[0], args[1]);
            break;
        }
        
      case 2:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:34:16-37\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftbasics.fut:32:30-36:6\n   #3  ftSMJ.fut:430:5-41\n   #4  ftSMJ.fut:429:1-430:41\n", args[0], args[1]);
            break;
        }
        
      case 3:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:52:16-37\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftbasics.fut:50:30-54:6\n   #3  ftSMJ.fut:458:5-50\n   #4  ftSMJ.fut:457:1-458:50\n", args[0], args[1]);
            break;
        }
        
      case 4:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:34:16-37\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftbasics.fut:32:30-36:6\n   #3  ftSMJ.fut:424:5-41\n   #4  ftSMJ.fut:423:1-424:41\n", args[0], args[1]);
            break;
        }
        
      case 5:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:52:16-37\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftbasics.fut:50:30-54:6\n   #3  ftSMJ.fut:452:5-50\n   #4  ftSMJ.fut:451:1-452:50\n", args[0], args[1]);
            break;
        }
        
      case 6:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:34:16-37\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftbasics.fut:32:30-36:6\n   #3  ftSMJ.fut:427:5-41\n   #4  ftSMJ.fut:426:1-427:41\n", args[0], args[1]);
            break;
        }
        
      case 7:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:52:16-37\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftbasics.fut:50:30-54:6\n   #3  ftSMJ.fut:455:5-50\n   #4  ftSMJ.fut:454:1-455:50\n", args[0], args[1]);
            break;
        }
        
      case 8:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:34:16-37\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftbasics.fut:32:30-36:6\n   #3  ftSMJ.fut:421:5-41\n   #4  ftSMJ.fut:420:1-421:41\n", args[0], args[1]);
            break;
        }
        
      case 9:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  ftbasics.fut:52:16-37\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftbasics.fut:50:30-54:6\n   #3  ftSMJ.fut:449:5-50\n   #4  ftSMJ.fut:448:1-449:50\n", args[0], args[1]);
            break;
        }
    }
    return strdup("Unknown error.  This is a compiler bug.");
}
struct program {
    int dummy;
    gpu_kernel builtinzhiota_i64ziiota_i64_34171;
    gpu_kernel builtinzhreplicate_f32zireplicate_34417;
    gpu_kernel builtinzhreplicate_f64zireplicate_34417;
    gpu_kernel builtinzhreplicate_i16zireplicate_34417;
    gpu_kernel builtinzhreplicate_i32zireplicate_34064;
    gpu_kernel builtinzhreplicate_i64zireplicate_34188;
    gpu_kernel builtinzhreplicate_i8zireplicate_34038;
    gpu_kernel gather_payloads_doublezisegmap_33060;
    gpu_kernel gather_payloads_doublezisegmap_33088;
    gpu_kernel gather_payloads_double_GFURzisegmap_33340;
    gpu_kernel gather_payloads_double_GFURzisegmap_33368;
    gpu_kernel gather_payloads_floatzisegmap_33004;
    gpu_kernel gather_payloads_floatzisegmap_33032;
    gpu_kernel gather_payloads_float_GFURzisegmap_33284;
    gpu_kernel gather_payloads_float_GFURzisegmap_33312;
    gpu_kernel gather_payloads_intzisegmap_32892;
    gpu_kernel gather_payloads_intzisegmap_32920;
    gpu_kernel gather_payloads_int_GFURzisegmap_33172;
    gpu_kernel gather_payloads_int_GFURzisegmap_33200;
    gpu_kernel gather_payloads_longzisegmap_32948;
    gpu_kernel gather_payloads_longzisegmap_32976;
    gpu_kernel gather_payloads_long_GFURzisegmap_33228;
    gpu_kernel gather_payloads_long_GFURzisegmap_33256;
    gpu_kernel gather_payloads_shortzisegmap_32836;
    gpu_kernel gather_payloads_shortzisegmap_32864;
    gpu_kernel gather_payloads_short_GFURzisegmap_33116;
    gpu_kernel gather_payloads_short_GFURzisegmap_33144;
    gpu_kernel inner_SMJ_doublezigpuseq_34379;
    gpu_kernel inner_SMJ_doublezigpuseq_34385;
    gpu_kernel inner_SMJ_doublezigpuseq_34391;
    gpu_kernel inner_SMJ_doublezigpuseq_34458;
    gpu_kernel inner_SMJ_doublezireplicate_34465;
    gpu_kernel inner_SMJ_doublezireplicate_34485;
    gpu_kernel inner_SMJ_doublezisegmap_33726;
    gpu_kernel inner_SMJ_doublezisegmap_33760;
    gpu_kernel inner_SMJ_doublezisegmap_33768;
    gpu_kernel inner_SMJ_doublezisegmap_33776;
    gpu_kernel inner_SMJ_doublezisegmap_33798;
    gpu_kernel inner_SMJ_doublezisegscan_33724;
    gpu_kernel inner_SMJ_doublezisegscan_33740;
    gpu_kernel inner_SMJ_floatzigpuseq_34379;
    gpu_kernel inner_SMJ_floatzigpuseq_34385;
    gpu_kernel inner_SMJ_floatzigpuseq_34391;
    gpu_kernel inner_SMJ_floatzigpuseq_34458;
    gpu_kernel inner_SMJ_floatzireplicate_34465;
    gpu_kernel inner_SMJ_floatzireplicate_34485;
    gpu_kernel inner_SMJ_floatzisegmap_33642;
    gpu_kernel inner_SMJ_floatzisegmap_33676;
    gpu_kernel inner_SMJ_floatzisegmap_33684;
    gpu_kernel inner_SMJ_floatzisegmap_33692;
    gpu_kernel inner_SMJ_floatzisegmap_33714;
    gpu_kernel inner_SMJ_floatzisegscan_33640;
    gpu_kernel inner_SMJ_floatzisegscan_33656;
    gpu_kernel inner_SMJ_intzigpuseq_34379;
    gpu_kernel inner_SMJ_intzigpuseq_34385;
    gpu_kernel inner_SMJ_intzigpuseq_34391;
    gpu_kernel inner_SMJ_intzigpuseq_34438;
    gpu_kernel inner_SMJ_intzireplicate_34445;
    gpu_kernel inner_SMJ_intzireplicate_34465;
    gpu_kernel inner_SMJ_intzisegmap_33474;
    gpu_kernel inner_SMJ_intzisegmap_33508;
    gpu_kernel inner_SMJ_intzisegmap_33516;
    gpu_kernel inner_SMJ_intzisegmap_33524;
    gpu_kernel inner_SMJ_intzisegmap_33546;
    gpu_kernel inner_SMJ_intzisegscan_33472;
    gpu_kernel inner_SMJ_intzisegscan_33488;
    gpu_kernel inner_SMJ_longzigpuseq_34379;
    gpu_kernel inner_SMJ_longzigpuseq_34385;
    gpu_kernel inner_SMJ_longzigpuseq_34391;
    gpu_kernel inner_SMJ_longzigpuseq_34438;
    gpu_kernel inner_SMJ_longzireplicate_34445;
    gpu_kernel inner_SMJ_longzireplicate_34465;
    gpu_kernel inner_SMJ_longzisegmap_33558;
    gpu_kernel inner_SMJ_longzisegmap_33592;
    gpu_kernel inner_SMJ_longzisegmap_33600;
    gpu_kernel inner_SMJ_longzisegmap_33608;
    gpu_kernel inner_SMJ_longzisegmap_33630;
    gpu_kernel inner_SMJ_longzisegscan_33556;
    gpu_kernel inner_SMJ_longzisegscan_33572;
    gpu_kernel inner_SMJ_shortzigpuseq_34379;
    gpu_kernel inner_SMJ_shortzigpuseq_34385;
    gpu_kernel inner_SMJ_shortzigpuseq_34391;
    gpu_kernel inner_SMJ_shortzigpuseq_34458;
    gpu_kernel inner_SMJ_shortzireplicate_34465;
    gpu_kernel inner_SMJ_shortzireplicate_34485;
    gpu_kernel inner_SMJ_shortzisegmap_33390;
    gpu_kernel inner_SMJ_shortzisegmap_33424;
    gpu_kernel inner_SMJ_shortzisegmap_33432;
    gpu_kernel inner_SMJ_shortzisegmap_33440;
    gpu_kernel inner_SMJ_shortzisegmap_33462;
    gpu_kernel inner_SMJ_shortzisegscan_33388;
    gpu_kernel inner_SMJ_shortzisegscan_33404;
    gpu_kernel max_idxzisegred_nonseg_32820;
    gpu_kernel min_idxzisegred_nonseg_32810;
};
static void setup_program(struct futhark_context *ctx)
{
    (void) ctx;
    
    int error = 0;
    
    (void) error;
    ctx->program = malloc(sizeof(struct program));
    gpu_create_kernel(ctx, &ctx->program->builtinzhiota_i64ziiota_i64_34171, "builtinzhiota_i64ziiota_i64_34171");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_f32zireplicate_34417, "builtinzhreplicate_f32zireplicate_34417");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_f64zireplicate_34417, "builtinzhreplicate_f64zireplicate_34417");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_i16zireplicate_34417, "builtinzhreplicate_i16zireplicate_34417");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_i32zireplicate_34064, "builtinzhreplicate_i32zireplicate_34064");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_i64zireplicate_34188, "builtinzhreplicate_i64zireplicate_34188");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_i8zireplicate_34038, "builtinzhreplicate_i8zireplicate_34038");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_doublezisegmap_33060, "gather_payloads_doublezisegmap_33060");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_doublezisegmap_33088, "gather_payloads_doublezisegmap_33088");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_double_GFURzisegmap_33340, "gather_payloads_double_GFURzisegmap_33340");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_double_GFURzisegmap_33368, "gather_payloads_double_GFURzisegmap_33368");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_floatzisegmap_33004, "gather_payloads_floatzisegmap_33004");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_floatzisegmap_33032, "gather_payloads_floatzisegmap_33032");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_float_GFURzisegmap_33284, "gather_payloads_float_GFURzisegmap_33284");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_float_GFURzisegmap_33312, "gather_payloads_float_GFURzisegmap_33312");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_intzisegmap_32892, "gather_payloads_intzisegmap_32892");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_intzisegmap_32920, "gather_payloads_intzisegmap_32920");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_int_GFURzisegmap_33172, "gather_payloads_int_GFURzisegmap_33172");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_int_GFURzisegmap_33200, "gather_payloads_int_GFURzisegmap_33200");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_longzisegmap_32948, "gather_payloads_longzisegmap_32948");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_longzisegmap_32976, "gather_payloads_longzisegmap_32976");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_long_GFURzisegmap_33228, "gather_payloads_long_GFURzisegmap_33228");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_long_GFURzisegmap_33256, "gather_payloads_long_GFURzisegmap_33256");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_shortzisegmap_32836, "gather_payloads_shortzisegmap_32836");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_shortzisegmap_32864, "gather_payloads_shortzisegmap_32864");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_short_GFURzisegmap_33116, "gather_payloads_short_GFURzisegmap_33116");
    gpu_create_kernel(ctx, &ctx->program->gather_payloads_short_GFURzisegmap_33144, "gather_payloads_short_GFURzisegmap_33144");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_doublezigpuseq_34379, "inner_SMJ_doublezigpuseq_34379");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_doublezigpuseq_34385, "inner_SMJ_doublezigpuseq_34385");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_doublezigpuseq_34391, "inner_SMJ_doublezigpuseq_34391");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_doublezigpuseq_34458, "inner_SMJ_doublezigpuseq_34458");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_doublezireplicate_34465, "inner_SMJ_doublezireplicate_34465");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_doublezireplicate_34485, "inner_SMJ_doublezireplicate_34485");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_doublezisegmap_33726, "inner_SMJ_doublezisegmap_33726");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_doublezisegmap_33760, "inner_SMJ_doublezisegmap_33760");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_doublezisegmap_33768, "inner_SMJ_doublezisegmap_33768");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_doublezisegmap_33776, "inner_SMJ_doublezisegmap_33776");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_doublezisegmap_33798, "inner_SMJ_doublezisegmap_33798");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_doublezisegscan_33724, "inner_SMJ_doublezisegscan_33724");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_doublezisegscan_33740, "inner_SMJ_doublezisegscan_33740");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_floatzigpuseq_34379, "inner_SMJ_floatzigpuseq_34379");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_floatzigpuseq_34385, "inner_SMJ_floatzigpuseq_34385");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_floatzigpuseq_34391, "inner_SMJ_floatzigpuseq_34391");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_floatzigpuseq_34458, "inner_SMJ_floatzigpuseq_34458");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_floatzireplicate_34465, "inner_SMJ_floatzireplicate_34465");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_floatzireplicate_34485, "inner_SMJ_floatzireplicate_34485");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_floatzisegmap_33642, "inner_SMJ_floatzisegmap_33642");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_floatzisegmap_33676, "inner_SMJ_floatzisegmap_33676");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_floatzisegmap_33684, "inner_SMJ_floatzisegmap_33684");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_floatzisegmap_33692, "inner_SMJ_floatzisegmap_33692");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_floatzisegmap_33714, "inner_SMJ_floatzisegmap_33714");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_floatzisegscan_33640, "inner_SMJ_floatzisegscan_33640");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_floatzisegscan_33656, "inner_SMJ_floatzisegscan_33656");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzigpuseq_34379, "inner_SMJ_intzigpuseq_34379");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzigpuseq_34385, "inner_SMJ_intzigpuseq_34385");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzigpuseq_34391, "inner_SMJ_intzigpuseq_34391");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzigpuseq_34438, "inner_SMJ_intzigpuseq_34438");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzireplicate_34445, "inner_SMJ_intzireplicate_34445");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzireplicate_34465, "inner_SMJ_intzireplicate_34465");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzisegmap_33474, "inner_SMJ_intzisegmap_33474");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzisegmap_33508, "inner_SMJ_intzisegmap_33508");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzisegmap_33516, "inner_SMJ_intzisegmap_33516");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzisegmap_33524, "inner_SMJ_intzisegmap_33524");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzisegmap_33546, "inner_SMJ_intzisegmap_33546");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzisegscan_33472, "inner_SMJ_intzisegscan_33472");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_intzisegscan_33488, "inner_SMJ_intzisegscan_33488");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_longzigpuseq_34379, "inner_SMJ_longzigpuseq_34379");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_longzigpuseq_34385, "inner_SMJ_longzigpuseq_34385");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_longzigpuseq_34391, "inner_SMJ_longzigpuseq_34391");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_longzigpuseq_34438, "inner_SMJ_longzigpuseq_34438");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_longzireplicate_34445, "inner_SMJ_longzireplicate_34445");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_longzireplicate_34465, "inner_SMJ_longzireplicate_34465");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_longzisegmap_33558, "inner_SMJ_longzisegmap_33558");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_longzisegmap_33592, "inner_SMJ_longzisegmap_33592");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_longzisegmap_33600, "inner_SMJ_longzisegmap_33600");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_longzisegmap_33608, "inner_SMJ_longzisegmap_33608");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_longzisegmap_33630, "inner_SMJ_longzisegmap_33630");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_longzisegscan_33556, "inner_SMJ_longzisegscan_33556");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_longzisegscan_33572, "inner_SMJ_longzisegscan_33572");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_shortzigpuseq_34379, "inner_SMJ_shortzigpuseq_34379");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_shortzigpuseq_34385, "inner_SMJ_shortzigpuseq_34385");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_shortzigpuseq_34391, "inner_SMJ_shortzigpuseq_34391");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_shortzigpuseq_34458, "inner_SMJ_shortzigpuseq_34458");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_shortzireplicate_34465, "inner_SMJ_shortzireplicate_34465");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_shortzireplicate_34485, "inner_SMJ_shortzireplicate_34485");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_shortzisegmap_33390, "inner_SMJ_shortzisegmap_33390");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_shortzisegmap_33424, "inner_SMJ_shortzisegmap_33424");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_shortzisegmap_33432, "inner_SMJ_shortzisegmap_33432");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_shortzisegmap_33440, "inner_SMJ_shortzisegmap_33440");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_shortzisegmap_33462, "inner_SMJ_shortzisegmap_33462");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_shortzisegscan_33388, "inner_SMJ_shortzisegscan_33388");
    gpu_create_kernel(ctx, &ctx->program->inner_SMJ_shortzisegscan_33404, "inner_SMJ_shortzisegscan_33404");
    gpu_create_kernel(ctx, &ctx->program->max_idxzisegred_nonseg_32820, "max_idxzisegred_nonseg_32820");
    gpu_create_kernel(ctx, &ctx->program->min_idxzisegred_nonseg_32810, "min_idxzisegred_nonseg_32810");
}
static void teardown_program(struct futhark_context *ctx)
{
    (void) ctx;
    
    int error = 0;
    
    (void) error;
    gpu_free_kernel(ctx, ctx->program->builtinzhiota_i64ziiota_i64_34171);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_f32zireplicate_34417);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_f64zireplicate_34417);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_i16zireplicate_34417);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_i32zireplicate_34064);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_i64zireplicate_34188);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_i8zireplicate_34038);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_doublezisegmap_33060);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_doublezisegmap_33088);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_double_GFURzisegmap_33340);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_double_GFURzisegmap_33368);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_floatzisegmap_33004);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_floatzisegmap_33032);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_float_GFURzisegmap_33284);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_float_GFURzisegmap_33312);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_intzisegmap_32892);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_intzisegmap_32920);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_int_GFURzisegmap_33172);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_int_GFURzisegmap_33200);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_longzisegmap_32948);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_longzisegmap_32976);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_long_GFURzisegmap_33228);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_long_GFURzisegmap_33256);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_shortzisegmap_32836);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_shortzisegmap_32864);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_short_GFURzisegmap_33116);
    gpu_free_kernel(ctx, ctx->program->gather_payloads_short_GFURzisegmap_33144);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_doublezigpuseq_34379);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_doublezigpuseq_34385);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_doublezigpuseq_34391);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_doublezigpuseq_34458);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_doublezireplicate_34465);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_doublezireplicate_34485);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_doublezisegmap_33726);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_doublezisegmap_33760);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_doublezisegmap_33768);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_doublezisegmap_33776);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_doublezisegmap_33798);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_doublezisegscan_33724);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_doublezisegscan_33740);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_floatzigpuseq_34379);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_floatzigpuseq_34385);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_floatzigpuseq_34391);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_floatzigpuseq_34458);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_floatzireplicate_34465);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_floatzireplicate_34485);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_floatzisegmap_33642);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_floatzisegmap_33676);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_floatzisegmap_33684);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_floatzisegmap_33692);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_floatzisegmap_33714);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_floatzisegscan_33640);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_floatzisegscan_33656);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_34379);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_34385);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_34391);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_34438);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzireplicate_34445);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzireplicate_34465);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_33474);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_33508);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_33516);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_33524);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_33546);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzisegscan_33472);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_intzisegscan_33488);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_longzigpuseq_34379);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_longzigpuseq_34385);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_longzigpuseq_34391);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_longzigpuseq_34438);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_longzireplicate_34445);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_longzireplicate_34465);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_longzisegmap_33558);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_longzisegmap_33592);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_longzisegmap_33600);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_longzisegmap_33608);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_longzisegmap_33630);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_longzisegscan_33556);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_longzisegscan_33572);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_shortzigpuseq_34379);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_shortzigpuseq_34385);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_shortzigpuseq_34391);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_shortzigpuseq_34458);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_shortzireplicate_34465);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_shortzireplicate_34485);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_shortzisegmap_33390);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_shortzisegmap_33424);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_shortzisegmap_33432);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_shortzisegmap_33440);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_shortzisegmap_33462);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_shortzisegscan_33388);
    gpu_free_kernel(ctx, ctx->program->inner_SMJ_shortzisegscan_33404);
    gpu_free_kernel(ctx, ctx->program->max_idxzisegred_nonseg_32820);
    gpu_free_kernel(ctx, ctx->program->min_idxzisegred_nonseg_32810);
    free(ctx->program);
}
static void set_tuning_params(struct futhark_context *ctx)
{
    (void) ctx;
    ctx->tuning_params.builtinzhiota_i64zitblock_sizze_34175 = &ctx->cfg->tuning_params[0];
    ctx->tuning_params.builtinzhreplicate_f32zitblock_sizze_34421 = &ctx->cfg->tuning_params[1];
    ctx->tuning_params.builtinzhreplicate_f64zitblock_sizze_34421 = &ctx->cfg->tuning_params[2];
    ctx->tuning_params.builtinzhreplicate_i16zitblock_sizze_34421 = &ctx->cfg->tuning_params[3];
    ctx->tuning_params.builtinzhreplicate_i32zitblock_sizze_34068 = &ctx->cfg->tuning_params[4];
    ctx->tuning_params.builtinzhreplicate_i64zitblock_sizze_34192 = &ctx->cfg->tuning_params[5];
    ctx->tuning_params.builtinzhreplicate_i8zitblock_sizze_34042 = &ctx->cfg->tuning_params[6];
    ctx->tuning_params.gather_payloads_doublezisegmap_tblock_sizze_33048 = &ctx->cfg->tuning_params[7];
    ctx->tuning_params.gather_payloads_doublezisegmap_tblock_sizze_33066 = &ctx->cfg->tuning_params[8];
    ctx->tuning_params.gather_payloads_double_GFURzisegmap_tblock_sizze_33328 = &ctx->cfg->tuning_params[9];
    ctx->tuning_params.gather_payloads_double_GFURzisegmap_tblock_sizze_33346 = &ctx->cfg->tuning_params[10];
    ctx->tuning_params.gather_payloads_floatzisegmap_tblock_sizze_32992 = &ctx->cfg->tuning_params[11];
    ctx->tuning_params.gather_payloads_floatzisegmap_tblock_sizze_33010 = &ctx->cfg->tuning_params[12];
    ctx->tuning_params.gather_payloads_float_GFURzisegmap_tblock_sizze_33272 = &ctx->cfg->tuning_params[13];
    ctx->tuning_params.gather_payloads_float_GFURzisegmap_tblock_sizze_33290 = &ctx->cfg->tuning_params[14];
    ctx->tuning_params.gather_payloads_intzisegmap_tblock_sizze_32880 = &ctx->cfg->tuning_params[15];
    ctx->tuning_params.gather_payloads_intzisegmap_tblock_sizze_32898 = &ctx->cfg->tuning_params[16];
    ctx->tuning_params.gather_payloads_int_GFURzisegmap_tblock_sizze_33160 = &ctx->cfg->tuning_params[17];
    ctx->tuning_params.gather_payloads_int_GFURzisegmap_tblock_sizze_33178 = &ctx->cfg->tuning_params[18];
    ctx->tuning_params.gather_payloads_longzisegmap_tblock_sizze_32936 = &ctx->cfg->tuning_params[19];
    ctx->tuning_params.gather_payloads_longzisegmap_tblock_sizze_32954 = &ctx->cfg->tuning_params[20];
    ctx->tuning_params.gather_payloads_long_GFURzisegmap_tblock_sizze_33216 = &ctx->cfg->tuning_params[21];
    ctx->tuning_params.gather_payloads_long_GFURzisegmap_tblock_sizze_33234 = &ctx->cfg->tuning_params[22];
    ctx->tuning_params.gather_payloads_shortzisegmap_tblock_sizze_32824 = &ctx->cfg->tuning_params[23];
    ctx->tuning_params.gather_payloads_shortzisegmap_tblock_sizze_32842 = &ctx->cfg->tuning_params[24];
    ctx->tuning_params.gather_payloads_short_GFURzisegmap_tblock_sizze_33104 = &ctx->cfg->tuning_params[25];
    ctx->tuning_params.gather_payloads_short_GFURzisegmap_tblock_sizze_33122 = &ctx->cfg->tuning_params[26];
    ctx->tuning_params.inner_SMJ_doublezisegmap_num_tblocks_33730 = &ctx->cfg->tuning_params[27];
    ctx->tuning_params.inner_SMJ_doublezisegmap_num_tblocks_33772 = &ctx->cfg->tuning_params[28];
    ctx->tuning_params.inner_SMJ_doublezisegmap_num_tblocks_33780 = &ctx->cfg->tuning_params[29];
    ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_33728 = &ctx->cfg->tuning_params[30];
    ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_33744 = &ctx->cfg->tuning_params[31];
    ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_33770 = &ctx->cfg->tuning_params[32];
    ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_33778 = &ctx->cfg->tuning_params[33];
    ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_33786 = &ctx->cfg->tuning_params[34];
    ctx->tuning_params.inner_SMJ_doublezisegscan_num_tblocks_33720 = &ctx->cfg->tuning_params[35];
    ctx->tuning_params.inner_SMJ_doublezisegscan_num_tblocks_33736 = &ctx->cfg->tuning_params[36];
    ctx->tuning_params.inner_SMJ_doublezisegscan_tblock_sizze_33718 = &ctx->cfg->tuning_params[37];
    ctx->tuning_params.inner_SMJ_doublezisegscan_tblock_sizze_33734 = &ctx->cfg->tuning_params[38];
    ctx->tuning_params.inner_SMJ_doublezitblock_sizze_34469 = &ctx->cfg->tuning_params[39];
    ctx->tuning_params.inner_SMJ_doublezitblock_sizze_34489 = &ctx->cfg->tuning_params[40];
    ctx->tuning_params.inner_SMJ_floatzisegmap_num_tblocks_33646 = &ctx->cfg->tuning_params[41];
    ctx->tuning_params.inner_SMJ_floatzisegmap_num_tblocks_33688 = &ctx->cfg->tuning_params[42];
    ctx->tuning_params.inner_SMJ_floatzisegmap_num_tblocks_33696 = &ctx->cfg->tuning_params[43];
    ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_33644 = &ctx->cfg->tuning_params[44];
    ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_33660 = &ctx->cfg->tuning_params[45];
    ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_33686 = &ctx->cfg->tuning_params[46];
    ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_33694 = &ctx->cfg->tuning_params[47];
    ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_33702 = &ctx->cfg->tuning_params[48];
    ctx->tuning_params.inner_SMJ_floatzisegscan_num_tblocks_33636 = &ctx->cfg->tuning_params[49];
    ctx->tuning_params.inner_SMJ_floatzisegscan_num_tblocks_33652 = &ctx->cfg->tuning_params[50];
    ctx->tuning_params.inner_SMJ_floatzisegscan_tblock_sizze_33634 = &ctx->cfg->tuning_params[51];
    ctx->tuning_params.inner_SMJ_floatzisegscan_tblock_sizze_33650 = &ctx->cfg->tuning_params[52];
    ctx->tuning_params.inner_SMJ_floatzitblock_sizze_34469 = &ctx->cfg->tuning_params[53];
    ctx->tuning_params.inner_SMJ_floatzitblock_sizze_34489 = &ctx->cfg->tuning_params[54];
    ctx->tuning_params.inner_SMJ_intzisegmap_num_tblocks_33478 = &ctx->cfg->tuning_params[55];
    ctx->tuning_params.inner_SMJ_intzisegmap_num_tblocks_33520 = &ctx->cfg->tuning_params[56];
    ctx->tuning_params.inner_SMJ_intzisegmap_num_tblocks_33528 = &ctx->cfg->tuning_params[57];
    ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_33476 = &ctx->cfg->tuning_params[58];
    ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_33492 = &ctx->cfg->tuning_params[59];
    ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_33518 = &ctx->cfg->tuning_params[60];
    ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_33526 = &ctx->cfg->tuning_params[61];
    ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_33534 = &ctx->cfg->tuning_params[62];
    ctx->tuning_params.inner_SMJ_intzisegscan_num_tblocks_33468 = &ctx->cfg->tuning_params[63];
    ctx->tuning_params.inner_SMJ_intzisegscan_num_tblocks_33484 = &ctx->cfg->tuning_params[64];
    ctx->tuning_params.inner_SMJ_intzisegscan_tblock_sizze_33466 = &ctx->cfg->tuning_params[65];
    ctx->tuning_params.inner_SMJ_intzisegscan_tblock_sizze_33482 = &ctx->cfg->tuning_params[66];
    ctx->tuning_params.inner_SMJ_intzitblock_sizze_34449 = &ctx->cfg->tuning_params[67];
    ctx->tuning_params.inner_SMJ_intzitblock_sizze_34469 = &ctx->cfg->tuning_params[68];
    ctx->tuning_params.inner_SMJ_longzisegmap_num_tblocks_33562 = &ctx->cfg->tuning_params[69];
    ctx->tuning_params.inner_SMJ_longzisegmap_num_tblocks_33604 = &ctx->cfg->tuning_params[70];
    ctx->tuning_params.inner_SMJ_longzisegmap_num_tblocks_33612 = &ctx->cfg->tuning_params[71];
    ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_33560 = &ctx->cfg->tuning_params[72];
    ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_33576 = &ctx->cfg->tuning_params[73];
    ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_33602 = &ctx->cfg->tuning_params[74];
    ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_33610 = &ctx->cfg->tuning_params[75];
    ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_33618 = &ctx->cfg->tuning_params[76];
    ctx->tuning_params.inner_SMJ_longzisegscan_num_tblocks_33552 = &ctx->cfg->tuning_params[77];
    ctx->tuning_params.inner_SMJ_longzisegscan_num_tblocks_33568 = &ctx->cfg->tuning_params[78];
    ctx->tuning_params.inner_SMJ_longzisegscan_tblock_sizze_33550 = &ctx->cfg->tuning_params[79];
    ctx->tuning_params.inner_SMJ_longzisegscan_tblock_sizze_33566 = &ctx->cfg->tuning_params[80];
    ctx->tuning_params.inner_SMJ_longzitblock_sizze_34449 = &ctx->cfg->tuning_params[81];
    ctx->tuning_params.inner_SMJ_longzitblock_sizze_34469 = &ctx->cfg->tuning_params[82];
    ctx->tuning_params.inner_SMJ_shortzisegmap_num_tblocks_33394 = &ctx->cfg->tuning_params[83];
    ctx->tuning_params.inner_SMJ_shortzisegmap_num_tblocks_33436 = &ctx->cfg->tuning_params[84];
    ctx->tuning_params.inner_SMJ_shortzisegmap_num_tblocks_33444 = &ctx->cfg->tuning_params[85];
    ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_33392 = &ctx->cfg->tuning_params[86];
    ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_33408 = &ctx->cfg->tuning_params[87];
    ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_33434 = &ctx->cfg->tuning_params[88];
    ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_33442 = &ctx->cfg->tuning_params[89];
    ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_33450 = &ctx->cfg->tuning_params[90];
    ctx->tuning_params.inner_SMJ_shortzisegscan_num_tblocks_33384 = &ctx->cfg->tuning_params[91];
    ctx->tuning_params.inner_SMJ_shortzisegscan_num_tblocks_33400 = &ctx->cfg->tuning_params[92];
    ctx->tuning_params.inner_SMJ_shortzisegscan_tblock_sizze_33382 = &ctx->cfg->tuning_params[93];
    ctx->tuning_params.inner_SMJ_shortzisegscan_tblock_sizze_33398 = &ctx->cfg->tuning_params[94];
    ctx->tuning_params.inner_SMJ_shortzitblock_sizze_34469 = &ctx->cfg->tuning_params[95];
    ctx->tuning_params.inner_SMJ_shortzitblock_sizze_34489 = &ctx->cfg->tuning_params[96];
    ctx->tuning_params.max_idxzisegred_num_tblocks_32814 = &ctx->cfg->tuning_params[97];
    ctx->tuning_params.max_idxzisegred_tblock_sizze_32812 = &ctx->cfg->tuning_params[98];
    ctx->tuning_params.min_idxzisegred_num_tblocks_32804 = &ctx->cfg->tuning_params[99];
    ctx->tuning_params.min_idxzisegred_tblock_sizze_32802 = &ctx->cfg->tuning_params[100];
}
int memblock_unref_device(struct futhark_context *ctx, struct memblock_device *block, const char *desc)
{
    if (block->references != NULL) {
        *block->references -= 1;
        if (ctx->detail_memory)
            fprintf(ctx->log, "Unreferencing block %s (allocated as %s) in %s: %d references remaining.\n", desc, block->desc, "space 'device'", *block->references);
        if (*block->references == 0) {
            ctx->cur_mem_usage_device -= block->size;
            (void) gpu_free(ctx, block->mem, block->size, desc);
            free(block->references);
            if (ctx->detail_memory)
                fprintf(ctx->log, "%lld bytes freed (now allocated: %lld bytes)\n", (long long) block->size, (long long) ctx->cur_mem_usage_device);
        }
        block->references = NULL;
    }
    return 0;
}
int memblock_alloc_device(struct futhark_context *ctx, struct memblock_device *block, int64_t size, const char *desc)
{
    if (size < 0)
        futhark_panic(1, "Negative allocation of %lld bytes attempted for %s in %s.\n", (long long) size, desc, "space 'device'", ctx->cur_mem_usage_device);
    
    int ret = memblock_unref_device(ctx, block, desc);
    
    if (ret != FUTHARK_SUCCESS)
        return ret;
    if (ctx->detail_memory)
        fprintf(ctx->log, "Allocating %lld bytes for %s in %s (currently allocated: %lld bytes).\n", (long long) size, desc, "space 'device'", (long long) ctx->cur_mem_usage_device);
    (void) gpu_alloc(ctx, ctx->log, (size_t) size, desc, &block->mem, (size_t *) &size);
    if (ctx->error == NULL) {
        block->references = (int *) malloc(sizeof(int));
        *block->references = 1;
        block->size = size;
        block->desc = desc;
        
        long long new_usage = ctx->cur_mem_usage_device + size;
        
        if (ctx->detail_memory)
            fprintf(ctx->log, "Received block of %lld bytes; now allocated: %lld bytes", (long long) block->size, new_usage);
        ctx->cur_mem_usage_device = new_usage;
        if (new_usage > ctx->peak_mem_usage_device) {
            ctx->peak_mem_usage_device = new_usage;
            if (ctx->detail_memory)
                fprintf(ctx->log, " (new peak).\n");
        } else if (ctx->detail_memory)
            fprintf(ctx->log, ".\n");
        return FUTHARK_SUCCESS;
    } else {
        // We are naively assuming that any memory allocation error is due to OOM.
        lock_lock(&ctx->error_lock);
        
        char *old_error = ctx->error;
        
        ctx->error = msgprintf("Failed to allocate memory in %s.\nAttempted allocation: %12lld bytes\nCurrently allocated:  %12lld bytes\n%s", "space 'device'", (long long) size, (long long) ctx->cur_mem_usage_device, old_error);
        free(old_error);
        lock_unlock(&ctx->error_lock);
        return FUTHARK_OUT_OF_MEMORY;
    }
}
int memblock_set_device(struct futhark_context *ctx, struct memblock_device *lhs, struct memblock_device *rhs, const char *lhs_desc)
{
    int ret = memblock_unref_device(ctx, lhs, lhs_desc);
    
    if (rhs->references != NULL)
        (*rhs->references)++;
    *lhs = *rhs;
    return ret;
}
int memblock_unref(struct futhark_context *ctx, struct memblock *block, const char *desc)
{
    if (block->references != NULL) {
        *block->references -= 1;
        if (ctx->detail_memory)
            fprintf(ctx->log, "Unreferencing block %s (allocated as %s) in %s: %d references remaining.\n", desc, block->desc, "default space", *block->references);
        if (*block->references == 0) {
            ctx->cur_mem_usage_default -= block->size;
            host_free(ctx, (size_t) block->size, desc, (void *) block->mem);
            free(block->references);
            if (ctx->detail_memory)
                fprintf(ctx->log, "%lld bytes freed (now allocated: %lld bytes)\n", (long long) block->size, (long long) ctx->cur_mem_usage_default);
        }
        block->references = NULL;
    }
    return 0;
}
int memblock_alloc(struct futhark_context *ctx, struct memblock *block, int64_t size, const char *desc)
{
    if (size < 0)
        futhark_panic(1, "Negative allocation of %lld bytes attempted for %s in %s.\n", (long long) size, desc, "default space", ctx->cur_mem_usage_default);
    
    int ret = memblock_unref(ctx, block, desc);
    
    if (ret != FUTHARK_SUCCESS)
        return ret;
    if (ctx->detail_memory)
        fprintf(ctx->log, "Allocating %lld bytes for %s in %s (currently allocated: %lld bytes).\n", (long long) size, desc, "default space", (long long) ctx->cur_mem_usage_default);
    host_alloc(ctx, (size_t) size, desc, (size_t *) &size, (void *) &block->mem);
    if (ctx->error == NULL) {
        block->references = (int *) malloc(sizeof(int));
        *block->references = 1;
        block->size = size;
        block->desc = desc;
        
        long long new_usage = ctx->cur_mem_usage_default + size;
        
        if (ctx->detail_memory)
            fprintf(ctx->log, "Received block of %lld bytes; now allocated: %lld bytes", (long long) block->size, new_usage);
        ctx->cur_mem_usage_default = new_usage;
        if (new_usage > ctx->peak_mem_usage_default) {
            ctx->peak_mem_usage_default = new_usage;
            if (ctx->detail_memory)
                fprintf(ctx->log, " (new peak).\n");
        } else if (ctx->detail_memory)
            fprintf(ctx->log, ".\n");
        return FUTHARK_SUCCESS;
    } else {
        // We are naively assuming that any memory allocation error is due to OOM.
        lock_lock(&ctx->error_lock);
        
        char *old_error = ctx->error;
        
        ctx->error = msgprintf("Failed to allocate memory in %s.\nAttempted allocation: %12lld bytes\nCurrently allocated:  %12lld bytes\n%s", "default space", (long long) size, (long long) ctx->cur_mem_usage_default, old_error);
        free(old_error);
        lock_unlock(&ctx->error_lock);
        return FUTHARK_OUT_OF_MEMORY;
    }
}
int memblock_set(struct futhark_context *ctx, struct memblock *lhs, struct memblock *rhs, const char *lhs_desc)
{
    int ret = memblock_unref(ctx, lhs, lhs_desc);
    
    if (rhs->references != NULL)
        (*rhs->references)++;
    *lhs = *rhs;
    return ret;
}
char *futhark_context_report(struct futhark_context *ctx)
{
    if (futhark_context_sync(ctx) != 0)
        return NULL;
    
    struct str_builder builder;
    
    str_builder_init(&builder);
    str_builder_char(&builder, '{');
    str_builder_str(&builder, "\"memory\":{");
    str_builder(&builder, "\"space 'device'\": %lld", (long long) ctx->peak_mem_usage_device);
    str_builder_char(&builder, ',');
    str_builder(&builder, "\"default space\": %lld", (long long) ctx->peak_mem_usage_default);
    str_builder_str(&builder, "},\"events\":[");
    if (report_events_in_list(&ctx->event_list, &builder) != 0) {
        free(builder.str);
        return NULL;
    } else {
        str_builder_str(&builder, "]}");
        return builder.str;
    }
}
int futhark_context_clear_caches(struct futhark_context *ctx)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    ctx->peak_mem_usage_device = 0;
    ctx->peak_mem_usage_default = 0;
    if (ctx->error == NULL)
        gpu_free_all(ctx);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ctx->error != NULL;
}

// Start of context.h

// Internal functions.

static void set_error(struct futhark_context* ctx, char *error) {
  lock_lock(&ctx->error_lock);
  if (ctx->error == NULL) {
    ctx->error = error;
  } else {
    free(error);
  }
  lock_unlock(&ctx->error_lock);
}

// XXX: should be static, but used in ispc_util.h
void lexical_realloc_error(struct futhark_context* ctx, size_t new_size) {
  set_error(ctx,
            msgprintf("Failed to allocate memory.\nAttempted allocation: %12lld bytes\n",
                      (long long) new_size));
}

static int lexical_realloc(struct futhark_context *ctx,
                           unsigned char **ptr,
                           int64_t *old_size,
                           int64_t new_size) {
  unsigned char *new = realloc(*ptr, (size_t)new_size);
  if (new == NULL) {
    lexical_realloc_error(ctx, new_size);
    return FUTHARK_OUT_OF_MEMORY;
  } else {
    *ptr = new;
    *old_size = new_size;
    return FUTHARK_SUCCESS;
  }
}

static void free_all_in_free_list(struct futhark_context* ctx) {
  fl_mem mem;
  free_list_pack(&ctx->free_list);
  while (free_list_first(&ctx->free_list, (fl_mem*)&mem) == 0) {
    free((void*)mem);
  }
}

static int is_small_alloc(size_t size) {
  return size < 1024*1024;
}

static void host_alloc(struct futhark_context* ctx,
                       size_t size, const char* tag, size_t* size_out, void** mem_out) {
  if (is_small_alloc(size) || free_list_find(&ctx->free_list, size, tag, size_out, (fl_mem*)mem_out) != 0) {
    *size_out = size;
    *mem_out = malloc(size);
  }
}

static void host_free(struct futhark_context* ctx,
                      size_t size, const char* tag, void* mem) {
  // Small allocations are handled by malloc()s own free list.  The
  // threshold here is kind of arbitrary, but seems to work OK.
  // Larger allocations are mmap()ed/munmapped() every time, which is
  // very slow, and Futhark programs tend to use a few very large
  // allocations.
  if (is_small_alloc(size)) {
    free(mem);
  } else {
    free_list_insert(&ctx->free_list, size, (fl_mem)mem, tag);
  }
}

static void add_event(struct futhark_context* ctx,
                      const char* name,
                      char* description,
                      void* data,
                      event_report_fn f) {
  if (ctx->logging) {
    fprintf(ctx->log, "Event: %s\n%s\n", name, description);
  }
  add_event_to_list(&ctx->event_list, name, description, data, f);
}

char *futhark_context_get_error(struct futhark_context *ctx) {
  char *error = ctx->error;
  ctx->error = NULL;
  return error;
}

void futhark_context_config_set_debugging(struct futhark_context_config *cfg, int flag) {
    cfg->profiling = cfg->logging = cfg->debugging = flag;
}

void futhark_context_config_set_profiling(struct futhark_context_config *cfg, int flag) {
    cfg->profiling = flag;
}

void futhark_context_config_set_logging(struct futhark_context_config *cfg, int flag) {
    cfg->logging = flag;
}

void futhark_context_config_set_cache_file(struct futhark_context_config *cfg, const char *f) {
  cfg->cache_fname = strdup(f);
}

int futhark_get_tuning_param_count(void) {
  return num_tuning_params;
}

const char *futhark_get_tuning_param_name(int i) {
  return tuning_param_names[i];
}

const char *futhark_get_tuning_param_class(int i) {
    return tuning_param_classes[i];
}

void futhark_context_set_logging_file(struct futhark_context *ctx, FILE *f){
  ctx->log = f;
}

void futhark_context_pause_profiling(struct futhark_context *ctx) {
  ctx->profiling_paused = 1;
}

void futhark_context_unpause_profiling(struct futhark_context *ctx) {
  ctx->profiling_paused = 0;
}

struct futhark_context_config* futhark_context_config_new(void) {
  struct futhark_context_config* cfg = malloc(sizeof(struct futhark_context_config));
  if (cfg == NULL) {
    return NULL;
  }
  cfg->in_use = 0;
  cfg->debugging = 0;
  cfg->profiling = 0;
  cfg->logging = 0;
  cfg->cache_fname = NULL;
  cfg->num_tuning_params = num_tuning_params;
  cfg->tuning_params = malloc(cfg->num_tuning_params * sizeof(int64_t));
  memcpy(cfg->tuning_params, tuning_param_defaults,
         cfg->num_tuning_params * sizeof(int64_t));
  cfg->tuning_param_names = tuning_param_names;
  cfg->tuning_param_vars = tuning_param_vars;
  cfg->tuning_param_classes = tuning_param_classes;
  backend_context_config_setup(cfg);
  return cfg;
}

void futhark_context_config_free(struct futhark_context_config* cfg) {
  assert(!cfg->in_use);
  backend_context_config_teardown(cfg);
  free(cfg->cache_fname);
  free(cfg->tuning_params);
  free(cfg);
}

struct futhark_context* futhark_context_new(struct futhark_context_config* cfg) {
  struct futhark_context* ctx = malloc(sizeof(struct futhark_context));
  if (ctx == NULL) {
    return NULL;
  }
  assert(!cfg->in_use);
  ctx->cfg = cfg;
  ctx->cfg->in_use = 1;
  ctx->program_initialised = false;
  create_lock(&ctx->error_lock);
  create_lock(&ctx->lock);
  free_list_init(&ctx->free_list);
  event_list_init(&ctx->event_list);
  ctx->peak_mem_usage_default = 0;
  ctx->cur_mem_usage_default = 0;
  ctx->constants = malloc(sizeof(struct constants));
  ctx->debugging = cfg->debugging;
  ctx->logging = cfg->logging;
  ctx->detail_memory = cfg->logging;
  ctx->profiling = cfg->profiling;
  ctx->profiling_paused = 0;
  ctx->error = NULL;
  ctx->log = stderr;
  set_tuning_params(ctx);
  if (backend_context_setup(ctx) == 0) {
    setup_program(ctx);
    init_constants(ctx);
    ctx->program_initialised = true;
    (void)futhark_context_clear_caches(ctx);
    (void)futhark_context_sync(ctx);
  }
  return ctx;
}

void futhark_context_free(struct futhark_context* ctx) {
  if (ctx->program_initialised) {
    free_constants(ctx);
    teardown_program(ctx);
  }
  backend_context_teardown(ctx);
  free_all_in_free_list(ctx);
  free_list_destroy(&ctx->free_list);
  event_list_free(&ctx->event_list);
  free(ctx->constants);
  free(ctx->error);
  free_lock(&ctx->lock);
  free_lock(&ctx->error_lock);
  ctx->cfg->in_use = 0;
  free(ctx);
}

// End of context.h

// Start of copy.h

// Cache-oblivious map-transpose function.
#define GEN_MAP_TRANSPOSE(NAME, ELEM_TYPE)                              \
  static void map_transpose_##NAME                                      \
  (ELEM_TYPE* dst, ELEM_TYPE* src,                                      \
   int64_t k, int64_t m, int64_t n,                                     \
   int64_t cb, int64_t ce, int64_t rb, int64_t re)                      \
  {                                                                     \
  int32_t r = re - rb;                                                  \
  int32_t c = ce - cb;                                                  \
  if (k == 1) {                                                         \
    if (r <= 64 && c <= 64) {                                           \
      for (int64_t j = 0; j < c; j++) {                                 \
        for (int64_t i = 0; i < r; i++) {                               \
          dst[(j + cb) * n + (i + rb)] = src[(i + rb) * m + (j + cb)];  \
        }                                                               \
      }                                                                 \
    } else if (c <= r) {                                                \
      map_transpose_##NAME(dst, src, k, m, n, cb, ce, rb, rb + r/2);    \
      map_transpose_##NAME(dst, src, k, m, n, cb, ce, rb + r/2, re);    \
    } else {                                                            \
      map_transpose_##NAME(dst, src, k, m, n, cb, cb + c/2, rb, re);    \
      map_transpose_##NAME(dst, src, k, m, n, cb + c/2, ce, rb, re);    \
    }                                                                   \
  } else {                                                              \
  for (int64_t i = 0; i < k; i++) {                                     \
    map_transpose_##NAME(dst + i * m * n, src + i * m * n, 1, m, n, cb, ce, rb, re); \
  }\
} \
}

// Straightforward LMAD copy function.
#define GEN_LMAD_COPY_ELEMENTS(NAME, ELEM_TYPE)                         \
  static void lmad_copy_elements_##NAME(int r,                          \
                                        ELEM_TYPE* dst, int64_t dst_strides[r], \
                                        ELEM_TYPE *src, int64_t src_strides[r], \
                                        int64_t shape[r]) {             \
    if (r == 1) {                                                       \
      for (int i = 0; i < shape[0]; i++) {                              \
        dst[i*dst_strides[0]] = src[i*src_strides[0]];                  \
      }                                                                 \
    } else if (r > 1) {                                                 \
      for (int i = 0; i < shape[0]; i++) {                              \
        lmad_copy_elements_##NAME(r-1,                                  \
                                  dst+i*dst_strides[0], dst_strides+1,  \
                                  src+i*src_strides[0], src_strides+1,  \
                                  shape+1);                             \
      }                                                                 \
    }                                                                   \
  }                                                                     \

// Check whether this LMAD can be seen as a transposed 2D array.  This
// is done by checking every possible splitting point.
static bool lmad_is_tr(int64_t *n_out, int64_t *m_out,
                       int r,
                       const int64_t strides[r],
                       const int64_t shape[r]) {
  for (int i = 1; i < r; i++) {
    int n = 1, m = 1;
    bool ok = true;
    int64_t expected = 1;
    // Check strides before 'i'.
    for (int j = i-1; j >= 0; j--) {
      ok = ok && strides[j] == expected;
      expected *= shape[j];
      n *= shape[j];
    }
    // Check strides after 'i'.
    for (int j = r-1; j >= i; j--) {
      ok = ok && strides[j] == expected;
      expected *= shape[j];
      m *= shape[j];
    }
    if (ok) {
      *n_out = n;
      *m_out = m;
      return true;
    }
  }
  return false;
}

// This function determines whether the a 'dst' LMAD is row-major and
// 'src' LMAD is column-major.  Both LMADs are for arrays of the same
// shape.  Both LMADs are allowed to have additional dimensions "on
// top".  Essentially, this function determines whether a copy from
// 'src' to 'dst' is a "map(transpose)" that we know how to implement
// efficiently.  The LMADs can have arbitrary rank, and the main
// challenge here is checking whether the src LMAD actually
// corresponds to a 2D column-major layout by morally collapsing
// dimensions.  There is a lot of looping here, but the actual trip
// count is going to be very low in practice.
//
// Returns true if this is indeed a map(transpose), and writes the
// number of arrays, and moral array size to appropriate output
// parameters.
static bool lmad_map_tr(int64_t *num_arrays_out, int64_t *n_out, int64_t *m_out,
                        int r,
                        const int64_t dst_strides[r],
                        const int64_t src_strides[r],
                        const int64_t shape[r]) {
  int64_t rowmajor_strides[r];
  rowmajor_strides[r-1] = 1;

  for (int i = r-2; i >= 0; i--) {
    rowmajor_strides[i] = rowmajor_strides[i+1] * shape[i+1];
  }

  // map_r will be the number of mapped dimensions on top.
  int map_r = 0;
  int64_t num_arrays = 1;
  for (int i = 0; i < r; i++) {
    if (dst_strides[i] != rowmajor_strides[i] ||
        src_strides[i] != rowmajor_strides[i]) {
      break;
    } else {
      num_arrays *= shape[i];
      map_r++;
    }
  }

  *num_arrays_out = num_arrays;

  if (r==map_r) {
    return false;
  }

  if (memcmp(&rowmajor_strides[map_r],
             &dst_strides[map_r],
             sizeof(int64_t)*(r-map_r)) == 0) {
    return lmad_is_tr(n_out, m_out, r-map_r, src_strides+map_r, shape+map_r);
  } else if (memcmp(&rowmajor_strides[map_r],
                    &src_strides[map_r],
                    sizeof(int64_t)*(r-map_r)) == 0) {
    return lmad_is_tr(m_out, n_out, r-map_r, dst_strides+map_r, shape+map_r);
  }
  return false;
}

// Check if the strides correspond to row-major strides of *any*
// permutation of the shape.  This is done by recursive search with
// backtracking.  This is worst-case exponential, but hopefully the
// arrays we encounter do not have that many dimensions.
static bool lmad_contiguous_search(int checked, int64_t expected,
                                   int r,
                                   int64_t strides[r], int64_t shape[r], bool used[r]) {
  for (int i = 0; i < r; i++) {
    for (int j = 0; j < r; j++) {
      if (!used[j] && strides[j] == expected && strides[j] >= 0) {
        used[j] = true;
        if (checked+1 == r ||
            lmad_contiguous_search(checked+1, expected * shape[j], r, strides, shape, used)) {
          return true;
        }
        used[j] = false;
      }
    }
  }
  return false;
}

// Does this LMAD correspond to an array with positive strides and no
// holes?
static bool lmad_contiguous(int r, int64_t strides[r], int64_t shape[r]) {
  bool used[r];
  for (int i = 0; i < r; i++) {
    used[i] = false;
  }
  return lmad_contiguous_search(0, 1, r, strides, shape, used);
}

// Does this copy correspond to something that could be done with a
// memcpy()-like operation?  I.e. do the LMADs actually represent the
// same in-memory layout and are they contiguous?
static bool lmad_memcpyable(int r,
                            int64_t dst_strides[r], int64_t src_strides[r], int64_t shape[r]) {
  if (!lmad_contiguous(r, dst_strides, shape)) {
    return false;
  }
  for (int i = 0; i < r; i++) {
    if (dst_strides[i] != src_strides[i] && shape[i] != 1) {
      return false;
    }
  }
  return true;
}


static void log_copy(struct futhark_context* ctx,
                     const char *kind, int r,
                     int64_t dst_offset, int64_t dst_strides[r],
                     int64_t src_offset, int64_t src_strides[r],
                     int64_t shape[r]) {
  if (ctx->logging) {
    fprintf(ctx->log, "\n# Copy %s\n", kind);
    fprintf(ctx->log, "Shape: ");
    for (int i = 0; i < r; i++) { fprintf(ctx->log, "[%ld]", (long int)shape[i]); }
    fprintf(ctx->log, "\n");
    fprintf(ctx->log, "Dst offset: %ld\n", (long int)dst_offset);
    fprintf(ctx->log, "Dst strides:");
    for (int i = 0; i < r; i++) { fprintf(ctx->log, " %ld", (long int)dst_strides[i]); }
    fprintf(ctx->log, "\n");
    fprintf(ctx->log, "Src offset: %ld\n", (long int)src_offset);
    fprintf(ctx->log, "Src strides:");
    for (int i = 0; i < r; i++) { fprintf(ctx->log, " %ld", (long int)src_strides[i]); }
    fprintf(ctx->log, "\n");
  }
}

static void log_transpose(struct futhark_context* ctx,
                          int64_t k, int64_t n, int64_t m) {
  if (ctx->logging) {
    fprintf(ctx->log, "## Transpose\n");
    fprintf(ctx->log, "Arrays     : %ld\n", (long int)k);
    fprintf(ctx->log, "X elements : %ld\n", (long int)m);
    fprintf(ctx->log, "Y elements : %ld\n", (long int)n);
    fprintf(ctx->log, "\n");
  }
}

#define GEN_LMAD_COPY(NAME, ELEM_TYPE)                                  \
  static void lmad_copy_##NAME                                          \
  (struct futhark_context *ctx, int r,                                  \
   ELEM_TYPE* dst, int64_t dst_offset, int64_t dst_strides[r],          \
   ELEM_TYPE *src, int64_t src_offset, int64_t src_strides[r],          \
   int64_t shape[r]) {                                                  \
    log_copy(ctx, "CPU to CPU", r, dst_offset, dst_strides,             \
             src_offset, src_strides, shape);                           \
    int64_t size = 1;                                                   \
    for (int i = 0; i < r; i++) { size *= shape[i]; }                   \
    if (size == 0) { return; }                                          \
    int64_t k, n, m;                                                    \
    if (lmad_map_tr(&k, &n, &m,                                         \
                    r, dst_strides, src_strides, shape)) {              \
      log_transpose(ctx, k, n, m);                                      \
      map_transpose_##NAME                                              \
        (dst+dst_offset, src+src_offset, k, n, m, 0, n, 0, m);          \
    } else if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {   \
      if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}          \
      memcpy(dst+dst_offset, src+src_offset, size*sizeof(*dst));        \
    } else {                                                            \
      if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}       \
      lmad_copy_elements_##NAME                                         \
        (r,                                                             \
         dst+dst_offset, dst_strides,                                   \
         src+src_offset, src_strides, shape);                           \
    }                                                                   \
  }

GEN_MAP_TRANSPOSE(1b, uint8_t)
GEN_MAP_TRANSPOSE(2b, uint16_t)
GEN_MAP_TRANSPOSE(4b, uint32_t)
GEN_MAP_TRANSPOSE(8b, uint64_t)

GEN_LMAD_COPY_ELEMENTS(1b, uint8_t)
GEN_LMAD_COPY_ELEMENTS(2b, uint16_t)
GEN_LMAD_COPY_ELEMENTS(4b, uint32_t)
GEN_LMAD_COPY_ELEMENTS(8b, uint64_t)

GEN_LMAD_COPY(1b, uint8_t)
GEN_LMAD_COPY(2b, uint16_t)
GEN_LMAD_COPY(4b, uint32_t)
GEN_LMAD_COPY(8b, uint64_t)

// End of copy.h

#define FUTHARK_FUN_ATTR static

FUTHARK_FUN_ATTR int futrts_builtinzhiota_i64(struct futhark_context *ctx, struct memblock_device mem_34166, int64_t n_34167, int64_t x_34168, int64_t s_34169);
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_f32(struct futhark_context *ctx, struct memblock_device mem_34412, int64_t num_elems_34413, float val_34414);
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_f64(struct futhark_context *ctx, struct memblock_device mem_34412, int64_t num_elems_34413, double val_34414);
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i16(struct futhark_context *ctx, struct memblock_device mem_34412, int64_t num_elems_34413, int16_t val_34414);
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i32(struct futhark_context *ctx, struct memblock_device mem_34059, int64_t num_elems_34060, int32_t val_34061);
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i64(struct futhark_context *ctx, struct memblock_device mem_34183, int64_t num_elems_34184, int64_t val_34185);
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i8(struct futhark_context *ctx, struct memblock_device mem_34033, int64_t num_elems_34034, int8_t val_34035);
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_double(struct futhark_context *ctx, struct memblock_device *mem_out_p_34513, struct memblock_device is_mem_33832, struct memblock_device ys_mem_33833, int64_t niz2084U_29871, int64_t dz2083U_29872, int64_t incr_29873, int64_t psizze_29874);
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_double_GFUR(struct futhark_context *ctx, struct memblock_device *mem_out_p_34514, struct memblock_device preVals_mem_33832, struct memblock_device is_mem_33833, struct memblock_device ys_mem_33834, int64_t ni_31378, int64_t n_31379, int64_t incr_31380, int64_t psizze_31381);
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_float(struct futhark_context *ctx, struct memblock_device *mem_out_p_34515, struct memblock_device is_mem_33832, struct memblock_device ys_mem_33833, int64_t niz2084U_29531, int64_t dz2083U_29532, int64_t incr_29533, int64_t psizze_29534);
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_float_GFUR(struct futhark_context *ctx, struct memblock_device *mem_out_p_34516, struct memblock_device preVals_mem_33832, struct memblock_device is_mem_33833, struct memblock_device ys_mem_33834, int64_t ni_31077, int64_t n_31078, int64_t incr_31079, int64_t psizze_31080);
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_int(struct futhark_context *ctx, struct memblock_device *mem_out_p_34517, struct memblock_device is_mem_33832, struct memblock_device ys_mem_33833, int64_t niz2084U_28882, int64_t dz2083U_28883, int64_t incr_28884, int64_t psizze_28885);
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_int_GFUR(struct futhark_context *ctx, struct memblock_device *mem_out_p_34518, struct memblock_device preVals_mem_33832, struct memblock_device is_mem_33833, struct memblock_device ys_mem_33834, int64_t ni_30475, int64_t n_30476, int64_t incr_30477, int64_t psizze_30478);
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_long(struct futhark_context *ctx, struct memblock_device *mem_out_p_34519, struct memblock_device is_mem_33832, struct memblock_device ys_mem_33833, int64_t niz2084U_29191, int64_t dz2083U_29192, int64_t incr_29193, int64_t psizze_29194);
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_long_GFUR(struct futhark_context *ctx, struct memblock_device *mem_out_p_34520, struct memblock_device preVals_mem_33832, struct memblock_device is_mem_33833, struct memblock_device ys_mem_33834, int64_t ni_30776, int64_t n_30777, int64_t incr_30778, int64_t psizze_30779);
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_short(struct futhark_context *ctx, struct memblock_device *mem_out_p_34521, struct memblock_device is_mem_33832, struct memblock_device ys_mem_33833, int64_t niz2084U_28542, int64_t dz2083U_28543, int64_t incr_28544, int64_t psizze_28545);
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_short_GFUR(struct futhark_context *ctx, struct memblock_device *mem_out_p_34522, struct memblock_device preVals_mem_33832, struct memblock_device is_mem_33833, struct memblock_device ys_mem_33834, int64_t ni_30174, int64_t n_30175, int64_t incr_30176, int64_t psizze_30177);
FUTHARK_FUN_ATTR int futrts_entry_inner_SMJ_double(struct futhark_context *ctx, struct memblock_device *mem_out_p_34523, struct memblock_device *mem_out_p_34524, struct memblock_device *mem_out_p_34525, int64_t *out_prim_out_34526, struct memblock_device tR_mem_33832, struct memblock_device tS_mem_33833, int64_t nR_28192, int64_t nS_28193, int64_t offset_R_28196, int64_t offset_S_28197, int64_t partitionsPerWindow_28198, int64_t numberOfWindows_28199, int64_t extParallelism_28200, int64_t scatter_psizze_28201);
FUTHARK_FUN_ATTR int futrts_entry_inner_SMJ_float(struct futhark_context *ctx, struct memblock_device *mem_out_p_34532, struct memblock_device *mem_out_p_34533, struct memblock_device *mem_out_p_34534, int64_t *out_prim_out_34535, struct memblock_device tR_mem_33832, struct memblock_device tS_mem_33833, int64_t nR_26587, int64_t nS_26588, int64_t offset_R_26591, int64_t offset_S_26592, int64_t partitionsPerWindow_26593, int64_t numberOfWindows_26594, int64_t extParallelism_26595, int64_t scatter_psizze_26596);
FUTHARK_FUN_ATTR int futrts_entry_inner_SMJ_int(struct futhark_context *ctx, struct memblock_device *mem_out_p_34541, struct memblock_device *mem_out_p_34542, struct memblock_device *mem_out_p_34543, int64_t *out_prim_out_34544, struct memblock_device tR_mem_33832, struct memblock_device tS_mem_33833, int64_t nR_23386, int64_t nS_23387, int64_t offset_R_23390, int64_t offset_S_23391, int64_t partitionsPerWindow_23392, int64_t numberOfWindows_23393, int64_t extParallelism_23394, int64_t scatter_psizze_23395);
FUTHARK_FUN_ATTR int futrts_entry_inner_SMJ_long(struct futhark_context *ctx, struct memblock_device *mem_out_p_34550, struct memblock_device *mem_out_p_34551, struct memblock_device *mem_out_p_34552, int64_t *out_prim_out_34553, struct memblock_device tR_mem_33832, struct memblock_device tS_mem_33833, int64_t nR_24982, int64_t nS_24983, int64_t offset_R_24986, int64_t offset_S_24987, int64_t partitionsPerWindow_24988, int64_t numberOfWindows_24989, int64_t extParallelism_24990, int64_t scatter_psizze_24991);
FUTHARK_FUN_ATTR int futrts_entry_inner_SMJ_short(struct futhark_context *ctx, struct memblock_device *mem_out_p_34559, struct memblock_device *mem_out_p_34560, struct memblock_device *mem_out_p_34561, int64_t *out_prim_out_34562, struct memblock_device tR_mem_33832, struct memblock_device tS_mem_33833, int64_t nR_21781, int64_t nS_21782, int64_t offset_R_21785, int64_t offset_S_21786, int64_t partitionsPerWindow_21787, int64_t numberOfWindows_21788, int64_t extParallelism_21789, int64_t scatter_psizze_21790);
FUTHARK_FUN_ATTR int futrts_entry_max_idx(struct futhark_context *ctx, int64_t *out_prim_out_34568, struct memblock_device eta_p_mem_33832, int64_t nz2080U_31457);
FUTHARK_FUN_ATTR int futrts_entry_min_idx(struct futhark_context *ctx, int64_t *out_prim_out_34570, struct memblock_device eta_p_mem_33832, int64_t nz2080U_31417);

static int init_constants(struct futhark_context *ctx)
{
    (void) ctx;
    
    int err = 0;
    
    #define counters_mem_34022 (ctx->constants->counters_mem_34022)
    #define global_dynid_mem_34057 (ctx->constants->global_dynid_mem_34057)
    #define global_dynid_mem_34235 (ctx->constants->global_dynid_mem_34235)
    counters_mem_34022.references = NULL;
    global_dynid_mem_34057.references = NULL;
    global_dynid_mem_34235.references = NULL;
    if (memblock_alloc_device(ctx, &counters_mem_34022, (int64_t) 80, "counters_mem_34022")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_34022, (int64_t) 20, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_34022, (int64_t) 80, "counters_mem_34022")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_34022, (int64_t) 20, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_34057, (int64_t) 4, "global_dynid_mem_34057")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_34057, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_34235, (int64_t) 4, "global_dynid_mem_34235")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_34235, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_34057, (int64_t) 4, "global_dynid_mem_34057")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_34057, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_34235, (int64_t) 4, "global_dynid_mem_34235")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_34235, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_34057, (int64_t) 4, "global_dynid_mem_34057")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_34057, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_34235, (int64_t) 4, "global_dynid_mem_34235")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_34235, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_34057, (int64_t) 4, "global_dynid_mem_34057")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_34057, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_34235, (int64_t) 4, "global_dynid_mem_34235")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_34235, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_34057, (int64_t) 4, "global_dynid_mem_34057")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_34057, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_34235, (int64_t) 4, "global_dynid_mem_34235")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_34235, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    #undef counters_mem_34022
    #undef global_dynid_mem_34057
    #undef global_dynid_mem_34235
    
  cleanup:
    return err;
}
static int free_constants(struct futhark_context *ctx)
{
    (void) ctx;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_34022, "ctx->constants->counters_mem_34022") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_34057, "ctx->constants->global_dynid_mem_34057") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_34235, "ctx->constants->global_dynid_mem_34235") != 0)
        return 1;
    return 0;
}
static int gpu_kernel_builtinzhiota_i64ziiota_i64_34171(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhiota_i64ziiota_i64_34171, "builtin#iota_i64.iota_i64_34171", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_builtinzhreplicate_f32zireplicate_34417(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, float arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_f32zireplicate_34417, "builtin#replicate_f32.replicate_34417", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_builtinzhreplicate_f64zireplicate_34417(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, double arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_f64zireplicate_34417, "builtin#replicate_f64.replicate_34417", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_builtinzhreplicate_i16zireplicate_34417(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int16_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_i16zireplicate_34417, "builtin#replicate_i16.replicate_34417", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_builtinzhreplicate_i32zireplicate_34064(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int32_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_i32zireplicate_34064, "builtin#replicate_i32.replicate_34064", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_builtinzhreplicate_i64zireplicate_34188(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_i64zireplicate_34188, "builtin#replicate_i64.replicate_34188", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_builtinzhreplicate_i8zireplicate_34038(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int8_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_i8zireplicate_34038, "builtin#replicate_i8.replicate_34038", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_doublezisegmap_33060(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_doublezisegmap_33060, "gather_payloads_double.segmap_33060", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_doublezisegmap_33088(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_doublezisegmap_33088, "gather_payloads_double.segmap_33088", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_double_GFURzisegmap_33340(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_double_GFURzisegmap_33340, "gather_payloads_double_GFUR.segmap_33340", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_double_GFURzisegmap_33368(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_double_GFURzisegmap_33368, "gather_payloads_double_GFUR.segmap_33368", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_floatzisegmap_33004(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_floatzisegmap_33004, "gather_payloads_float.segmap_33004", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_floatzisegmap_33032(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_floatzisegmap_33032, "gather_payloads_float.segmap_33032", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_float_GFURzisegmap_33284(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_float_GFURzisegmap_33284, "gather_payloads_float_GFUR.segmap_33284", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_float_GFURzisegmap_33312(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_float_GFURzisegmap_33312, "gather_payloads_float_GFUR.segmap_33312", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_intzisegmap_32892(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_intzisegmap_32892, "gather_payloads_int.segmap_32892", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_intzisegmap_32920(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_intzisegmap_32920, "gather_payloads_int.segmap_32920", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_int_GFURzisegmap_33172(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_int_GFURzisegmap_33172, "gather_payloads_int_GFUR.segmap_33172", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_int_GFURzisegmap_33200(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_int_GFURzisegmap_33200, "gather_payloads_int_GFUR.segmap_33200", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_longzisegmap_32948(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_longzisegmap_32948, "gather_payloads_long.segmap_32948", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_longzisegmap_32976(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_longzisegmap_32976, "gather_payloads_long.segmap_32976", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_long_GFURzisegmap_33228(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_long_GFURzisegmap_33228, "gather_payloads_long_GFUR.segmap_33228", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_long_GFURzisegmap_33256(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_long_GFURzisegmap_33256, "gather_payloads_long_GFUR.segmap_33256", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_shortzisegmap_32836(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_shortzisegmap_32836, "gather_payloads_short.segmap_32836", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_shortzisegmap_32864(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_shortzisegmap_32864, "gather_payloads_short.segmap_32864", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_short_GFURzisegmap_33116(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_short_GFURzisegmap_33116, "gather_payloads_short_GFUR.segmap_33116", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_gather_payloads_short_GFURzisegmap_33144(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->gather_payloads_short_GFURzisegmap_33144, "gather_payloads_short_GFUR.segmap_33144", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_doublezisegscan_33724(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[10] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8};
        size_t args_sizes[10] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_doublezisegscan_33724, "inner_SMJ_double.segscan_33724", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 10, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_doublezisegmap_33726(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_doublezisegmap_33726, "inner_SMJ_double.segmap_33726", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_doublezisegscan_33740(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[15] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13};
        size_t args_sizes[15] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_doublezisegscan_33740, "inner_SMJ_double.segscan_33740", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 15, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_doublezisegmap_33760(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_doublezisegmap_33760, "inner_SMJ_double.segmap_33760", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_doublezigpuseq_34379(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_doublezigpuseq_34379, "inner_SMJ_double.gpuseq_34379", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_doublezigpuseq_34385(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_doublezigpuseq_34385, "inner_SMJ_double.gpuseq_34385", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_doublezigpuseq_34391(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, gpu_mem arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_doublezigpuseq_34391, "inner_SMJ_double.gpuseq_34391", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_doublezisegmap_33776(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_doublezisegmap_33776, "inner_SMJ_double.segmap_33776", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_doublezisegmap_33768(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int32_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_doublezisegmap_33768, "inner_SMJ_double.segmap_33768", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_doublezigpuseq_34458(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_doublezigpuseq_34458, "inner_SMJ_double.gpuseq_34458", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_doublezireplicate_34465(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_doublezireplicate_34465, "inner_SMJ_double.replicate_34465", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_doublezireplicate_34485(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_doublezireplicate_34485, "inner_SMJ_double.replicate_34485", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_doublezisegmap_33798(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_doublezisegmap_33798, "inner_SMJ_double.segmap_33798", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_floatzisegscan_33640(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[10] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8};
        size_t args_sizes[10] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_floatzisegscan_33640, "inner_SMJ_float.segscan_33640", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 10, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_floatzisegmap_33642(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_floatzisegmap_33642, "inner_SMJ_float.segmap_33642", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_floatzisegscan_33656(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[15] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13};
        size_t args_sizes[15] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_floatzisegscan_33656, "inner_SMJ_float.segscan_33656", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 15, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_floatzisegmap_33676(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_floatzisegmap_33676, "inner_SMJ_float.segmap_33676", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_floatzigpuseq_34379(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_floatzigpuseq_34379, "inner_SMJ_float.gpuseq_34379", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_floatzigpuseq_34385(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_floatzigpuseq_34385, "inner_SMJ_float.gpuseq_34385", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_floatzigpuseq_34391(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, gpu_mem arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_floatzigpuseq_34391, "inner_SMJ_float.gpuseq_34391", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_floatzisegmap_33692(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_floatzisegmap_33692, "inner_SMJ_float.segmap_33692", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_floatzisegmap_33684(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int32_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_floatzisegmap_33684, "inner_SMJ_float.segmap_33684", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_floatzigpuseq_34458(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_floatzigpuseq_34458, "inner_SMJ_float.gpuseq_34458", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_floatzireplicate_34465(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_floatzireplicate_34465, "inner_SMJ_float.replicate_34465", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_floatzireplicate_34485(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_floatzireplicate_34485, "inner_SMJ_float.replicate_34485", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_floatzisegmap_33714(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_floatzisegmap_33714, "inner_SMJ_float.segmap_33714", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzisegscan_33472(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[10] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8};
        size_t args_sizes[10] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzisegscan_33472, "inner_SMJ_int.segscan_33472", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 10, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzisegmap_33474(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_33474, "inner_SMJ_int.segmap_33474", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzisegscan_33488(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[15] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13};
        size_t args_sizes[15] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzisegscan_33488, "inner_SMJ_int.segscan_33488", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 15, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzisegmap_33508(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_33508, "inner_SMJ_int.segmap_33508", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzigpuseq_34379(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_34379, "inner_SMJ_int.gpuseq_34379", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzigpuseq_34385(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_34385, "inner_SMJ_int.gpuseq_34385", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzigpuseq_34391(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, gpu_mem arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_34391, "inner_SMJ_int.gpuseq_34391", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzisegmap_33524(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_33524, "inner_SMJ_int.segmap_33524", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzisegmap_33516(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int32_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_33516, "inner_SMJ_int.segmap_33516", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzigpuseq_34438(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzigpuseq_34438, "inner_SMJ_int.gpuseq_34438", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzireplicate_34445(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzireplicate_34445, "inner_SMJ_int.replicate_34445", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzireplicate_34465(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzireplicate_34465, "inner_SMJ_int.replicate_34465", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_intzisegmap_33546(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_intzisegmap_33546, "inner_SMJ_int.segmap_33546", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_longzisegscan_33556(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[10] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8};
        size_t args_sizes[10] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_longzisegscan_33556, "inner_SMJ_long.segscan_33556", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 10, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_longzisegmap_33558(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_longzisegmap_33558, "inner_SMJ_long.segmap_33558", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_longzisegscan_33572(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[15] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13};
        size_t args_sizes[15] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_longzisegscan_33572, "inner_SMJ_long.segscan_33572", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 15, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_longzisegmap_33592(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_longzisegmap_33592, "inner_SMJ_long.segmap_33592", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_longzigpuseq_34379(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_longzigpuseq_34379, "inner_SMJ_long.gpuseq_34379", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_longzigpuseq_34385(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_longzigpuseq_34385, "inner_SMJ_long.gpuseq_34385", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_longzigpuseq_34391(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, gpu_mem arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_longzigpuseq_34391, "inner_SMJ_long.gpuseq_34391", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_longzisegmap_33608(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_longzisegmap_33608, "inner_SMJ_long.segmap_33608", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_longzisegmap_33600(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int32_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_longzisegmap_33600, "inner_SMJ_long.segmap_33600", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_longzigpuseq_34438(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_longzigpuseq_34438, "inner_SMJ_long.gpuseq_34438", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_longzireplicate_34445(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_longzireplicate_34445, "inner_SMJ_long.replicate_34445", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_longzireplicate_34465(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_longzireplicate_34465, "inner_SMJ_long.replicate_34465", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_longzisegmap_33630(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_longzisegmap_33630, "inner_SMJ_long.segmap_33630", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_shortzisegscan_33388(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[10] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8};
        size_t args_sizes[10] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_shortzisegscan_33388, "inner_SMJ_short.segscan_33388", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 10, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_shortzisegmap_33390(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_shortzisegmap_33390, "inner_SMJ_short.segmap_33390", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_shortzisegscan_33404(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[15] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13};
        size_t args_sizes[15] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_shortzisegscan_33404, "inner_SMJ_short.segscan_33404", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 15, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_shortzisegmap_33424(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_shortzisegmap_33424, "inner_SMJ_short.segmap_33424", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_shortzigpuseq_34379(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_shortzigpuseq_34379, "inner_SMJ_short.gpuseq_34379", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_shortzigpuseq_34385(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_shortzigpuseq_34385, "inner_SMJ_short.gpuseq_34385", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_shortzigpuseq_34391(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, gpu_mem arg0, gpu_mem arg1, gpu_mem arg2)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[4] = {&ctx->global_failure, &arg0, &arg1, &arg2};
        size_t args_sizes[4] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_shortzigpuseq_34391, "inner_SMJ_short.gpuseq_34391", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 4, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_shortzisegmap_33440(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_shortzisegmap_33440, "inner_SMJ_short.segmap_33440", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_shortzisegmap_33432(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int32_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_shortzisegmap_33432, "inner_SMJ_short.segmap_33432", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_shortzigpuseq_34458(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_shortzigpuseq_34458, "inner_SMJ_short.gpuseq_34458", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_shortzireplicate_34465(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_shortzireplicate_34465, "inner_SMJ_short.replicate_34465", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_shortzireplicate_34485(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_shortzireplicate_34485, "inner_SMJ_short.replicate_34485", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_inner_SMJ_shortzisegmap_33462(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[5] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[5] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->inner_SMJ_shortzisegmap_33462, "inner_SMJ_short.segmap_33462", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 5, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_max_idxzisegred_nonseg_32820(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->max_idxzisegred_nonseg_32820, "max_idx.segred_nonseg_32820", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_min_idxzisegred_nonseg_32810(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->min_idxzisegred_nonseg_32810, "min_idx.segred_nonseg_32810", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
struct futhark_i16_1d {
    struct memblock_device mem;
    int64_t shape[1];
};
struct futhark_i16_1d *futhark_new_i16_1d(struct futhark_context *ctx, const int16_t *data, int64_t dim0)
{
    int err = 0;
    struct futhark_i16_1d *bad = NULL;
    struct futhark_i16_1d *arr = (struct futhark_i16_1d *) malloc(sizeof(struct futhark_i16_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * 2, "arr->mem"))
        err = 1;
    arr->shape[0] = dim0;
    err = memcpy_host2gpu(ctx, false, arr->mem.mem, 0, (const unsigned char *) data, 0, (size_t) dim0 * 2);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    if (err != 0) {
        free(arr);
        return bad;
    }
    return arr;
}
struct futhark_i16_1d *futhark_new_raw_i16_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0)
{
    int err = 0;
    struct futhark_i16_1d *bad = NULL;
    struct futhark_i16_1d *arr = (struct futhark_i16_1d *) malloc(sizeof(struct futhark_i16_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    arr->mem.mem = data;
    arr->shape[0] = dim0;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_i16_1d(struct futhark_context *ctx, struct futhark_i16_1d *arr)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_i16_1d(struct futhark_context *ctx, struct futhark_i16_1d *arr, int16_t *data)
{
    int err = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    err = memcpy_gpu2host(ctx, false, (unsigned char *) data, 0, arr->mem.mem, 0, (size_t) arr->shape[0] * 2);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return err;
}
int futhark_index_i16_1d(struct futhark_context *ctx, int16_t *out, struct futhark_i16_1d *arr, int64_t i0)
{
    int err = 0;
    
    if (i0 >= 0 && i0 < arr->shape[0]) {
        lock_lock(&ctx->lock);
        CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
        err = memcpy_gpu2host(ctx, false, (unsigned char *) out, 0, arr->mem.mem, 2 * (i0 * 1), 2);
        CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
        lock_unlock(&ctx->lock);
    } else {
        err = 1;
        set_error(ctx, strdup("Index out of bounds."));
    }
    return err;
}
CUdeviceptr futhark_values_raw_i16_1d(struct futhark_context *ctx, struct futhark_i16_1d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_i16_1d(struct futhark_context *ctx, struct futhark_i16_1d *arr)
{
    (void) ctx;
    return arr->shape;
}
struct futhark_i32_1d {
    struct memblock_device mem;
    int64_t shape[1];
};
struct futhark_i32_1d *futhark_new_i32_1d(struct futhark_context *ctx, const int32_t *data, int64_t dim0)
{
    int err = 0;
    struct futhark_i32_1d *bad = NULL;
    struct futhark_i32_1d *arr = (struct futhark_i32_1d *) malloc(sizeof(struct futhark_i32_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * 4, "arr->mem"))
        err = 1;
    arr->shape[0] = dim0;
    err = memcpy_host2gpu(ctx, false, arr->mem.mem, 0, (const unsigned char *) data, 0, (size_t) dim0 * 4);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    if (err != 0) {
        free(arr);
        return bad;
    }
    return arr;
}
struct futhark_i32_1d *futhark_new_raw_i32_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0)
{
    int err = 0;
    struct futhark_i32_1d *bad = NULL;
    struct futhark_i32_1d *arr = (struct futhark_i32_1d *) malloc(sizeof(struct futhark_i32_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    arr->mem.mem = data;
    arr->shape[0] = dim0;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr, int32_t *data)
{
    int err = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    err = memcpy_gpu2host(ctx, false, (unsigned char *) data, 0, arr->mem.mem, 0, (size_t) arr->shape[0] * 4);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return err;
}
int futhark_index_i32_1d(struct futhark_context *ctx, int32_t *out, struct futhark_i32_1d *arr, int64_t i0)
{
    int err = 0;
    
    if (i0 >= 0 && i0 < arr->shape[0]) {
        lock_lock(&ctx->lock);
        CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
        err = memcpy_gpu2host(ctx, false, (unsigned char *) out, 0, arr->mem.mem, 4 * (i0 * 1), 4);
        CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
        lock_unlock(&ctx->lock);
    } else {
        err = 1;
        set_error(ctx, strdup("Index out of bounds."));
    }
    return err;
}
CUdeviceptr futhark_values_raw_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr)
{
    (void) ctx;
    return arr->shape;
}
struct futhark_i64_1d {
    struct memblock_device mem;
    int64_t shape[1];
};
struct futhark_i64_1d *futhark_new_i64_1d(struct futhark_context *ctx, const int64_t *data, int64_t dim0)
{
    int err = 0;
    struct futhark_i64_1d *bad = NULL;
    struct futhark_i64_1d *arr = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * 8, "arr->mem"))
        err = 1;
    arr->shape[0] = dim0;
    err = memcpy_host2gpu(ctx, false, arr->mem.mem, 0, (const unsigned char *) data, 0, (size_t) dim0 * 8);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    if (err != 0) {
        free(arr);
        return bad;
    }
    return arr;
}
struct futhark_i64_1d *futhark_new_raw_i64_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0)
{
    int err = 0;
    struct futhark_i64_1d *bad = NULL;
    struct futhark_i64_1d *arr = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    arr->mem.mem = data;
    arr->shape[0] = dim0;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr, int64_t *data)
{
    int err = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    err = memcpy_gpu2host(ctx, false, (unsigned char *) data, 0, arr->mem.mem, 0, (size_t) arr->shape[0] * 8);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return err;
}
int futhark_index_i64_1d(struct futhark_context *ctx, int64_t *out, struct futhark_i64_1d *arr, int64_t i0)
{
    int err = 0;
    
    if (i0 >= 0 && i0 < arr->shape[0]) {
        lock_lock(&ctx->lock);
        CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
        err = memcpy_gpu2host(ctx, false, (unsigned char *) out, 0, arr->mem.mem, 8 * (i0 * 1), 8);
        CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
        lock_unlock(&ctx->lock);
    } else {
        err = 1;
        set_error(ctx, strdup("Index out of bounds."));
    }
    return err;
}
CUdeviceptr futhark_values_raw_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr)
{
    (void) ctx;
    return arr->shape;
}
struct futhark_f32_1d {
    struct memblock_device mem;
    int64_t shape[1];
};
struct futhark_f32_1d *futhark_new_f32_1d(struct futhark_context *ctx, const float *data, int64_t dim0)
{
    int err = 0;
    struct futhark_f32_1d *bad = NULL;
    struct futhark_f32_1d *arr = (struct futhark_f32_1d *) malloc(sizeof(struct futhark_f32_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * 4, "arr->mem"))
        err = 1;
    arr->shape[0] = dim0;
    err = memcpy_host2gpu(ctx, false, arr->mem.mem, 0, (const unsigned char *) data, 0, (size_t) dim0 * 4);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    if (err != 0) {
        free(arr);
        return bad;
    }
    return arr;
}
struct futhark_f32_1d *futhark_new_raw_f32_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0)
{
    int err = 0;
    struct futhark_f32_1d *bad = NULL;
    struct futhark_f32_1d *arr = (struct futhark_f32_1d *) malloc(sizeof(struct futhark_f32_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    arr->mem.mem = data;
    arr->shape[0] = dim0;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr, float *data)
{
    int err = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    err = memcpy_gpu2host(ctx, false, (unsigned char *) data, 0, arr->mem.mem, 0, (size_t) arr->shape[0] * 4);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return err;
}
int futhark_index_f32_1d(struct futhark_context *ctx, float *out, struct futhark_f32_1d *arr, int64_t i0)
{
    int err = 0;
    
    if (i0 >= 0 && i0 < arr->shape[0]) {
        lock_lock(&ctx->lock);
        CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
        err = memcpy_gpu2host(ctx, false, (unsigned char *) out, 0, arr->mem.mem, 4 * (i0 * 1), 4);
        CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
        lock_unlock(&ctx->lock);
    } else {
        err = 1;
        set_error(ctx, strdup("Index out of bounds."));
    }
    return err;
}
CUdeviceptr futhark_values_raw_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr)
{
    (void) ctx;
    return arr->shape;
}
struct futhark_f64_1d {
    struct memblock_device mem;
    int64_t shape[1];
};
struct futhark_f64_1d *futhark_new_f64_1d(struct futhark_context *ctx, const double *data, int64_t dim0)
{
    int err = 0;
    struct futhark_f64_1d *bad = NULL;
    struct futhark_f64_1d *arr = (struct futhark_f64_1d *) malloc(sizeof(struct futhark_f64_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * 8, "arr->mem"))
        err = 1;
    arr->shape[0] = dim0;
    err = memcpy_host2gpu(ctx, false, arr->mem.mem, 0, (const unsigned char *) data, 0, (size_t) dim0 * 8);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    if (err != 0) {
        free(arr);
        return bad;
    }
    return arr;
}
struct futhark_f64_1d *futhark_new_raw_f64_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0)
{
    int err = 0;
    struct futhark_f64_1d *bad = NULL;
    struct futhark_f64_1d *arr = (struct futhark_f64_1d *) malloc(sizeof(struct futhark_f64_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    arr->mem.mem = data;
    arr->shape[0] = dim0;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_f64_1d(struct futhark_context *ctx, struct futhark_f64_1d *arr)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_f64_1d(struct futhark_context *ctx, struct futhark_f64_1d *arr, double *data)
{
    int err = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    err = memcpy_gpu2host(ctx, false, (unsigned char *) data, 0, arr->mem.mem, 0, (size_t) arr->shape[0] * 8);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return err;
}
int futhark_index_f64_1d(struct futhark_context *ctx, double *out, struct futhark_f64_1d *arr, int64_t i0)
{
    int err = 0;
    
    if (i0 >= 0 && i0 < arr->shape[0]) {
        lock_lock(&ctx->lock);
        CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
        err = memcpy_gpu2host(ctx, false, (unsigned char *) out, 0, arr->mem.mem, 8 * (i0 * 1), 8);
        CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
        lock_unlock(&ctx->lock);
    } else {
        err = 1;
        set_error(ctx, strdup("Index out of bounds."));
    }
    return err;
}
CUdeviceptr futhark_values_raw_f64_1d(struct futhark_context *ctx, struct futhark_f64_1d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_f64_1d(struct futhark_context *ctx, struct futhark_f64_1d *arr)
{
    (void) ctx;
    return arr->shape;
}
struct futhark_opaque_joinPairs_short {
    struct futhark_i64_1d *v0;
    struct futhark_i64_1d *v1;
    struct futhark_i16_1d *v2;
};
int futhark_project_opaque_joinPairs_short_ix(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_short *obj)
{
    (void) ctx;
    
    struct futhark_i64_1d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_i64_1d));
    memcpy(v, obj->v0, sizeof(struct futhark_i64_1d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_project_opaque_joinPairs_short_iy(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_short *obj)
{
    (void) ctx;
    
    struct futhark_i64_1d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_i64_1d));
    memcpy(v, obj->v1, sizeof(struct futhark_i64_1d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_project_opaque_joinPairs_short_vs(struct futhark_context *ctx, struct futhark_i16_1d **out, const struct futhark_opaque_joinPairs_short *obj)
{
    (void) ctx;
    
    struct futhark_i16_1d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_i16_1d));
    memcpy(v, obj->v2, sizeof(struct futhark_i16_1d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_new_opaque_joinPairs_short(struct futhark_context *ctx, struct futhark_opaque_joinPairs_short **out, const struct futhark_i64_1d *f_ix, const struct futhark_i64_1d *f_iy, const struct futhark_i16_1d *f_vs)
{
    struct futhark_opaque_joinPairs_short *v = malloc(sizeof(struct futhark_opaque_joinPairs_short));
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    {
        v->v0 = malloc(sizeof(struct futhark_i64_1d));
        *v->v0 = *f_ix;
        (void) (*v->v0->mem.references)++;
    }
    {
        v->v1 = malloc(sizeof(struct futhark_i64_1d));
        *v->v1 = *f_iy;
        (void) (*v->v1->mem.references)++;
    }
    {
        v->v2 = malloc(sizeof(struct futhark_i16_1d));
        *v->v2 = *f_vs;
        (void) (*v->v2->mem.references)++;
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return FUTHARK_SUCCESS;
}
int futhark_free_opaque_joinPairs_short(struct futhark_context *ctx, struct futhark_opaque_joinPairs_short *obj)
{
    (void) ctx;
    
    int ret = 0, tmp;
    
    if (obj->v0 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v0)) != 0)
        ret = tmp;
    if (obj->v1 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v1)) != 0)
        ret = tmp;
    if (obj->v2 != NULL && (tmp = futhark_free_i16_1d(ctx, obj->v2)) != 0)
        ret = tmp;
    free(obj);
    return ret;
}
int futhark_store_opaque_joinPairs_short(struct futhark_context *ctx, const struct futhark_opaque_joinPairs_short *obj, void **p, size_t *n)
{
    (void) ctx;
    
    int ret = 0;
    int64_t size_0 = 7 + 1 * sizeof(int64_t) + futhark_shape_i64_1d(ctx, obj->v0)[0] * sizeof(int64_t);
    int64_t size_1 = 7 + 1 * sizeof(int64_t) + futhark_shape_i64_1d(ctx, obj->v1)[0] * sizeof(int64_t);
    int64_t size_2 = 7 + 1 * sizeof(int64_t) + futhark_shape_i16_1d(ctx, obj->v2)[0] * sizeof(int16_t);
    
    *n = size_0 + size_1 + size_2;
    if (p != NULL && *p == NULL)
        *p = malloc(*n);
    if (p != NULL) {
        unsigned char *out = *p;
        
        *out++ = 'b';
        *out++ = 2;
        *out++ = 1;
        memcpy(out, " i64", 4);
        out += 4;
        memcpy(out, futhark_shape_i64_1d(ctx, obj->v0), 1 * sizeof(int64_t));
        out += 1 * sizeof(int64_t);
        ret |= futhark_values_i64_1d(ctx, obj->v0, (void *) out);
        out += futhark_shape_i64_1d(ctx, obj->v0)[0] * sizeof(int64_t);
        *out++ = 'b';
        *out++ = 2;
        *out++ = 1;
        memcpy(out, " i64", 4);
        out += 4;
        memcpy(out, futhark_shape_i64_1d(ctx, obj->v1), 1 * sizeof(int64_t));
        out += 1 * sizeof(int64_t);
        ret |= futhark_values_i64_1d(ctx, obj->v1, (void *) out);
        out += futhark_shape_i64_1d(ctx, obj->v1)[0] * sizeof(int64_t);
        *out++ = 'b';
        *out++ = 2;
        *out++ = 1;
        memcpy(out, " i16", 4);
        out += 4;
        memcpy(out, futhark_shape_i16_1d(ctx, obj->v2), 1 * sizeof(int64_t));
        out += 1 * sizeof(int64_t);
        ret |= futhark_values_i16_1d(ctx, obj->v2, (void *) out);
        out += futhark_shape_i16_1d(ctx, obj->v2)[0] * sizeof(int16_t);
    }
    return ret;
}
struct futhark_opaque_joinPairs_short *futhark_restore_opaque_joinPairs_short(struct futhark_context *ctx, const void *p)
{
    (void) ctx;
    
    int err = 0;
    const unsigned char *src = p;
    struct futhark_opaque_joinPairs_short *obj = malloc(sizeof(struct futhark_opaque_joinPairs_short));
    int64_t shape_0[1] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 1;
    err |= memcmp(src, " i64", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_0, src, 1 * sizeof(int64_t));
        src += 1 * sizeof(int64_t);
    }
    
    const void *data_0 = src;
    
    obj->v0 = NULL;
    src += shape_0[0] * sizeof(int64_t);
    
    int64_t shape_1[1] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 1;
    err |= memcmp(src, " i64", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_1, src, 1 * sizeof(int64_t));
        src += 1 * sizeof(int64_t);
    }
    
    const void *data_1 = src;
    
    obj->v1 = NULL;
    src += shape_1[0] * sizeof(int64_t);
    
    int64_t shape_2[1] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 1;
    err |= memcmp(src, " i16", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_2, src, 1 * sizeof(int64_t));
        src += 1 * sizeof(int64_t);
    }
    
    const void *data_2 = src;
    
    obj->v2 = NULL;
    src += shape_2[0] * sizeof(int16_t);
    if (err == 0) {
        obj->v0 = futhark_new_i64_1d(ctx, data_0, shape_0[0]);
        if (obj->v0 == NULL)
            err = 1;
        obj->v1 = futhark_new_i64_1d(ctx, data_1, shape_1[0]);
        if (obj->v1 == NULL)
            err = 1;
        obj->v2 = futhark_new_i16_1d(ctx, data_2, shape_2[0]);
        if (obj->v2 == NULL)
            err = 1;
    }
    if (err != 0) {
        int ret = 0, tmp;
        
        if (obj->v0 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v0)) != 0)
            ret = tmp;
        if (obj->v1 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v1)) != 0)
            ret = tmp;
        if (obj->v2 != NULL && (tmp = futhark_free_i16_1d(ctx, obj->v2)) != 0)
            ret = tmp;
        free(obj);
        obj = NULL;
    }
    return obj;
}
struct futhark_opaque_joinPairs_int {
    struct futhark_i64_1d *v0;
    struct futhark_i64_1d *v1;
    struct futhark_i32_1d *v2;
};
int futhark_project_opaque_joinPairs_int_ix(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_int *obj)
{
    (void) ctx;
    
    struct futhark_i64_1d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_i64_1d));
    memcpy(v, obj->v0, sizeof(struct futhark_i64_1d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_project_opaque_joinPairs_int_iy(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_int *obj)
{
    (void) ctx;
    
    struct futhark_i64_1d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_i64_1d));
    memcpy(v, obj->v1, sizeof(struct futhark_i64_1d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_project_opaque_joinPairs_int_vs(struct futhark_context *ctx, struct futhark_i32_1d **out, const struct futhark_opaque_joinPairs_int *obj)
{
    (void) ctx;
    
    struct futhark_i32_1d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_i32_1d));
    memcpy(v, obj->v2, sizeof(struct futhark_i32_1d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_new_opaque_joinPairs_int(struct futhark_context *ctx, struct futhark_opaque_joinPairs_int **out, const struct futhark_i64_1d *f_ix, const struct futhark_i64_1d *f_iy, const struct futhark_i32_1d *f_vs)
{
    struct futhark_opaque_joinPairs_int *v = malloc(sizeof(struct futhark_opaque_joinPairs_int));
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    {
        v->v0 = malloc(sizeof(struct futhark_i64_1d));
        *v->v0 = *f_ix;
        (void) (*v->v0->mem.references)++;
    }
    {
        v->v1 = malloc(sizeof(struct futhark_i64_1d));
        *v->v1 = *f_iy;
        (void) (*v->v1->mem.references)++;
    }
    {
        v->v2 = malloc(sizeof(struct futhark_i32_1d));
        *v->v2 = *f_vs;
        (void) (*v->v2->mem.references)++;
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return FUTHARK_SUCCESS;
}
int futhark_free_opaque_joinPairs_int(struct futhark_context *ctx, struct futhark_opaque_joinPairs_int *obj)
{
    (void) ctx;
    
    int ret = 0, tmp;
    
    if (obj->v0 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v0)) != 0)
        ret = tmp;
    if (obj->v1 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v1)) != 0)
        ret = tmp;
    if (obj->v2 != NULL && (tmp = futhark_free_i32_1d(ctx, obj->v2)) != 0)
        ret = tmp;
    free(obj);
    return ret;
}
int futhark_store_opaque_joinPairs_int(struct futhark_context *ctx, const struct futhark_opaque_joinPairs_int *obj, void **p, size_t *n)
{
    (void) ctx;
    
    int ret = 0;
    int64_t size_0 = 7 + 1 * sizeof(int64_t) + futhark_shape_i64_1d(ctx, obj->v0)[0] * sizeof(int64_t);
    int64_t size_1 = 7 + 1 * sizeof(int64_t) + futhark_shape_i64_1d(ctx, obj->v1)[0] * sizeof(int64_t);
    int64_t size_2 = 7 + 1 * sizeof(int64_t) + futhark_shape_i32_1d(ctx, obj->v2)[0] * sizeof(int32_t);
    
    *n = size_0 + size_1 + size_2;
    if (p != NULL && *p == NULL)
        *p = malloc(*n);
    if (p != NULL) {
        unsigned char *out = *p;
        
        *out++ = 'b';
        *out++ = 2;
        *out++ = 1;
        memcpy(out, " i64", 4);
        out += 4;
        memcpy(out, futhark_shape_i64_1d(ctx, obj->v0), 1 * sizeof(int64_t));
        out += 1 * sizeof(int64_t);
        ret |= futhark_values_i64_1d(ctx, obj->v0, (void *) out);
        out += futhark_shape_i64_1d(ctx, obj->v0)[0] * sizeof(int64_t);
        *out++ = 'b';
        *out++ = 2;
        *out++ = 1;
        memcpy(out, " i64", 4);
        out += 4;
        memcpy(out, futhark_shape_i64_1d(ctx, obj->v1), 1 * sizeof(int64_t));
        out += 1 * sizeof(int64_t);
        ret |= futhark_values_i64_1d(ctx, obj->v1, (void *) out);
        out += futhark_shape_i64_1d(ctx, obj->v1)[0] * sizeof(int64_t);
        *out++ = 'b';
        *out++ = 2;
        *out++ = 1;
        memcpy(out, " i32", 4);
        out += 4;
        memcpy(out, futhark_shape_i32_1d(ctx, obj->v2), 1 * sizeof(int64_t));
        out += 1 * sizeof(int64_t);
        ret |= futhark_values_i32_1d(ctx, obj->v2, (void *) out);
        out += futhark_shape_i32_1d(ctx, obj->v2)[0] * sizeof(int32_t);
    }
    return ret;
}
struct futhark_opaque_joinPairs_int *futhark_restore_opaque_joinPairs_int(struct futhark_context *ctx, const void *p)
{
    (void) ctx;
    
    int err = 0;
    const unsigned char *src = p;
    struct futhark_opaque_joinPairs_int *obj = malloc(sizeof(struct futhark_opaque_joinPairs_int));
    int64_t shape_0[1] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 1;
    err |= memcmp(src, " i64", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_0, src, 1 * sizeof(int64_t));
        src += 1 * sizeof(int64_t);
    }
    
    const void *data_0 = src;
    
    obj->v0 = NULL;
    src += shape_0[0] * sizeof(int64_t);
    
    int64_t shape_1[1] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 1;
    err |= memcmp(src, " i64", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_1, src, 1 * sizeof(int64_t));
        src += 1 * sizeof(int64_t);
    }
    
    const void *data_1 = src;
    
    obj->v1 = NULL;
    src += shape_1[0] * sizeof(int64_t);
    
    int64_t shape_2[1] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 1;
    err |= memcmp(src, " i32", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_2, src, 1 * sizeof(int64_t));
        src += 1 * sizeof(int64_t);
    }
    
    const void *data_2 = src;
    
    obj->v2 = NULL;
    src += shape_2[0] * sizeof(int32_t);
    if (err == 0) {
        obj->v0 = futhark_new_i64_1d(ctx, data_0, shape_0[0]);
        if (obj->v0 == NULL)
            err = 1;
        obj->v1 = futhark_new_i64_1d(ctx, data_1, shape_1[0]);
        if (obj->v1 == NULL)
            err = 1;
        obj->v2 = futhark_new_i32_1d(ctx, data_2, shape_2[0]);
        if (obj->v2 == NULL)
            err = 1;
    }
    if (err != 0) {
        int ret = 0, tmp;
        
        if (obj->v0 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v0)) != 0)
            ret = tmp;
        if (obj->v1 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v1)) != 0)
            ret = tmp;
        if (obj->v2 != NULL && (tmp = futhark_free_i32_1d(ctx, obj->v2)) != 0)
            ret = tmp;
        free(obj);
        obj = NULL;
    }
    return obj;
}
struct futhark_opaque_joinPairs_long {
    struct futhark_i64_1d *v0;
    struct futhark_i64_1d *v1;
    struct futhark_i64_1d *v2;
};
int futhark_project_opaque_joinPairs_long_ix(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_long *obj)
{
    (void) ctx;
    
    struct futhark_i64_1d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_i64_1d));
    memcpy(v, obj->v0, sizeof(struct futhark_i64_1d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_project_opaque_joinPairs_long_iy(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_long *obj)
{
    (void) ctx;
    
    struct futhark_i64_1d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_i64_1d));
    memcpy(v, obj->v1, sizeof(struct futhark_i64_1d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_project_opaque_joinPairs_long_vs(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_long *obj)
{
    (void) ctx;
    
    struct futhark_i64_1d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_i64_1d));
    memcpy(v, obj->v2, sizeof(struct futhark_i64_1d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_new_opaque_joinPairs_long(struct futhark_context *ctx, struct futhark_opaque_joinPairs_long **out, const struct futhark_i64_1d *f_ix, const struct futhark_i64_1d *f_iy, const struct futhark_i64_1d *f_vs)
{
    struct futhark_opaque_joinPairs_long *v = malloc(sizeof(struct futhark_opaque_joinPairs_long));
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    {
        v->v0 = malloc(sizeof(struct futhark_i64_1d));
        *v->v0 = *f_ix;
        (void) (*v->v0->mem.references)++;
    }
    {
        v->v1 = malloc(sizeof(struct futhark_i64_1d));
        *v->v1 = *f_iy;
        (void) (*v->v1->mem.references)++;
    }
    {
        v->v2 = malloc(sizeof(struct futhark_i64_1d));
        *v->v2 = *f_vs;
        (void) (*v->v2->mem.references)++;
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return FUTHARK_SUCCESS;
}
int futhark_free_opaque_joinPairs_long(struct futhark_context *ctx, struct futhark_opaque_joinPairs_long *obj)
{
    (void) ctx;
    
    int ret = 0, tmp;
    
    if (obj->v0 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v0)) != 0)
        ret = tmp;
    if (obj->v1 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v1)) != 0)
        ret = tmp;
    if (obj->v2 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v2)) != 0)
        ret = tmp;
    free(obj);
    return ret;
}
int futhark_store_opaque_joinPairs_long(struct futhark_context *ctx, const struct futhark_opaque_joinPairs_long *obj, void **p, size_t *n)
{
    (void) ctx;
    
    int ret = 0;
    int64_t size_0 = 7 + 1 * sizeof(int64_t) + futhark_shape_i64_1d(ctx, obj->v0)[0] * sizeof(int64_t);
    int64_t size_1 = 7 + 1 * sizeof(int64_t) + futhark_shape_i64_1d(ctx, obj->v1)[0] * sizeof(int64_t);
    int64_t size_2 = 7 + 1 * sizeof(int64_t) + futhark_shape_i64_1d(ctx, obj->v2)[0] * sizeof(int64_t);
    
    *n = size_0 + size_1 + size_2;
    if (p != NULL && *p == NULL)
        *p = malloc(*n);
    if (p != NULL) {
        unsigned char *out = *p;
        
        *out++ = 'b';
        *out++ = 2;
        *out++ = 1;
        memcpy(out, " i64", 4);
        out += 4;
        memcpy(out, futhark_shape_i64_1d(ctx, obj->v0), 1 * sizeof(int64_t));
        out += 1 * sizeof(int64_t);
        ret |= futhark_values_i64_1d(ctx, obj->v0, (void *) out);
        out += futhark_shape_i64_1d(ctx, obj->v0)[0] * sizeof(int64_t);
        *out++ = 'b';
        *out++ = 2;
        *out++ = 1;
        memcpy(out, " i64", 4);
        out += 4;
        memcpy(out, futhark_shape_i64_1d(ctx, obj->v1), 1 * sizeof(int64_t));
        out += 1 * sizeof(int64_t);
        ret |= futhark_values_i64_1d(ctx, obj->v1, (void *) out);
        out += futhark_shape_i64_1d(ctx, obj->v1)[0] * sizeof(int64_t);
        *out++ = 'b';
        *out++ = 2;
        *out++ = 1;
        memcpy(out, " i64", 4);
        out += 4;
        memcpy(out, futhark_shape_i64_1d(ctx, obj->v2), 1 * sizeof(int64_t));
        out += 1 * sizeof(int64_t);
        ret |= futhark_values_i64_1d(ctx, obj->v2, (void *) out);
        out += futhark_shape_i64_1d(ctx, obj->v2)[0] * sizeof(int64_t);
    }
    return ret;
}
struct futhark_opaque_joinPairs_long *futhark_restore_opaque_joinPairs_long(struct futhark_context *ctx, const void *p)
{
    (void) ctx;
    
    int err = 0;
    const unsigned char *src = p;
    struct futhark_opaque_joinPairs_long *obj = malloc(sizeof(struct futhark_opaque_joinPairs_long));
    int64_t shape_0[1] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 1;
    err |= memcmp(src, " i64", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_0, src, 1 * sizeof(int64_t));
        src += 1 * sizeof(int64_t);
    }
    
    const void *data_0 = src;
    
    obj->v0 = NULL;
    src += shape_0[0] * sizeof(int64_t);
    
    int64_t shape_1[1] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 1;
    err |= memcmp(src, " i64", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_1, src, 1 * sizeof(int64_t));
        src += 1 * sizeof(int64_t);
    }
    
    const void *data_1 = src;
    
    obj->v1 = NULL;
    src += shape_1[0] * sizeof(int64_t);
    
    int64_t shape_2[1] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 1;
    err |= memcmp(src, " i64", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_2, src, 1 * sizeof(int64_t));
        src += 1 * sizeof(int64_t);
    }
    
    const void *data_2 = src;
    
    obj->v2 = NULL;
    src += shape_2[0] * sizeof(int64_t);
    if (err == 0) {
        obj->v0 = futhark_new_i64_1d(ctx, data_0, shape_0[0]);
        if (obj->v0 == NULL)
            err = 1;
        obj->v1 = futhark_new_i64_1d(ctx, data_1, shape_1[0]);
        if (obj->v1 == NULL)
            err = 1;
        obj->v2 = futhark_new_i64_1d(ctx, data_2, shape_2[0]);
        if (obj->v2 == NULL)
            err = 1;
    }
    if (err != 0) {
        int ret = 0, tmp;
        
        if (obj->v0 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v0)) != 0)
            ret = tmp;
        if (obj->v1 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v1)) != 0)
            ret = tmp;
        if (obj->v2 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v2)) != 0)
            ret = tmp;
        free(obj);
        obj = NULL;
    }
    return obj;
}
struct futhark_opaque_joinPairs_float {
    struct futhark_i64_1d *v0;
    struct futhark_i64_1d *v1;
    struct futhark_f32_1d *v2;
};
int futhark_project_opaque_joinPairs_float_ix(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_float *obj)
{
    (void) ctx;
    
    struct futhark_i64_1d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_i64_1d));
    memcpy(v, obj->v0, sizeof(struct futhark_i64_1d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_project_opaque_joinPairs_float_iy(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_float *obj)
{
    (void) ctx;
    
    struct futhark_i64_1d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_i64_1d));
    memcpy(v, obj->v1, sizeof(struct futhark_i64_1d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_project_opaque_joinPairs_float_vs(struct futhark_context *ctx, struct futhark_f32_1d **out, const struct futhark_opaque_joinPairs_float *obj)
{
    (void) ctx;
    
    struct futhark_f32_1d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_f32_1d));
    memcpy(v, obj->v2, sizeof(struct futhark_f32_1d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_new_opaque_joinPairs_float(struct futhark_context *ctx, struct futhark_opaque_joinPairs_float **out, const struct futhark_i64_1d *f_ix, const struct futhark_i64_1d *f_iy, const struct futhark_f32_1d *f_vs)
{
    struct futhark_opaque_joinPairs_float *v = malloc(sizeof(struct futhark_opaque_joinPairs_float));
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    {
        v->v0 = malloc(sizeof(struct futhark_i64_1d));
        *v->v0 = *f_ix;
        (void) (*v->v0->mem.references)++;
    }
    {
        v->v1 = malloc(sizeof(struct futhark_i64_1d));
        *v->v1 = *f_iy;
        (void) (*v->v1->mem.references)++;
    }
    {
        v->v2 = malloc(sizeof(struct futhark_f32_1d));
        *v->v2 = *f_vs;
        (void) (*v->v2->mem.references)++;
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return FUTHARK_SUCCESS;
}
int futhark_free_opaque_joinPairs_float(struct futhark_context *ctx, struct futhark_opaque_joinPairs_float *obj)
{
    (void) ctx;
    
    int ret = 0, tmp;
    
    if (obj->v0 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v0)) != 0)
        ret = tmp;
    if (obj->v1 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v1)) != 0)
        ret = tmp;
    if (obj->v2 != NULL && (tmp = futhark_free_f32_1d(ctx, obj->v2)) != 0)
        ret = tmp;
    free(obj);
    return ret;
}
int futhark_store_opaque_joinPairs_float(struct futhark_context *ctx, const struct futhark_opaque_joinPairs_float *obj, void **p, size_t *n)
{
    (void) ctx;
    
    int ret = 0;
    int64_t size_0 = 7 + 1 * sizeof(int64_t) + futhark_shape_i64_1d(ctx, obj->v0)[0] * sizeof(int64_t);
    int64_t size_1 = 7 + 1 * sizeof(int64_t) + futhark_shape_i64_1d(ctx, obj->v1)[0] * sizeof(int64_t);
    int64_t size_2 = 7 + 1 * sizeof(int64_t) + futhark_shape_f32_1d(ctx, obj->v2)[0] * sizeof(float);
    
    *n = size_0 + size_1 + size_2;
    if (p != NULL && *p == NULL)
        *p = malloc(*n);
    if (p != NULL) {
        unsigned char *out = *p;
        
        *out++ = 'b';
        *out++ = 2;
        *out++ = 1;
        memcpy(out, " i64", 4);
        out += 4;
        memcpy(out, futhark_shape_i64_1d(ctx, obj->v0), 1 * sizeof(int64_t));
        out += 1 * sizeof(int64_t);
        ret |= futhark_values_i64_1d(ctx, obj->v0, (void *) out);
        out += futhark_shape_i64_1d(ctx, obj->v0)[0] * sizeof(int64_t);
        *out++ = 'b';
        *out++ = 2;
        *out++ = 1;
        memcpy(out, " i64", 4);
        out += 4;
        memcpy(out, futhark_shape_i64_1d(ctx, obj->v1), 1 * sizeof(int64_t));
        out += 1 * sizeof(int64_t);
        ret |= futhark_values_i64_1d(ctx, obj->v1, (void *) out);
        out += futhark_shape_i64_1d(ctx, obj->v1)[0] * sizeof(int64_t);
        *out++ = 'b';
        *out++ = 2;
        *out++ = 1;
        memcpy(out, " f32", 4);
        out += 4;
        memcpy(out, futhark_shape_f32_1d(ctx, obj->v2), 1 * sizeof(int64_t));
        out += 1 * sizeof(int64_t);
        ret |= futhark_values_f32_1d(ctx, obj->v2, (void *) out);
        out += futhark_shape_f32_1d(ctx, obj->v2)[0] * sizeof(float);
    }
    return ret;
}
struct futhark_opaque_joinPairs_float *futhark_restore_opaque_joinPairs_float(struct futhark_context *ctx, const void *p)
{
    (void) ctx;
    
    int err = 0;
    const unsigned char *src = p;
    struct futhark_opaque_joinPairs_float *obj = malloc(sizeof(struct futhark_opaque_joinPairs_float));
    int64_t shape_0[1] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 1;
    err |= memcmp(src, " i64", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_0, src, 1 * sizeof(int64_t));
        src += 1 * sizeof(int64_t);
    }
    
    const void *data_0 = src;
    
    obj->v0 = NULL;
    src += shape_0[0] * sizeof(int64_t);
    
    int64_t shape_1[1] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 1;
    err |= memcmp(src, " i64", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_1, src, 1 * sizeof(int64_t));
        src += 1 * sizeof(int64_t);
    }
    
    const void *data_1 = src;
    
    obj->v1 = NULL;
    src += shape_1[0] * sizeof(int64_t);
    
    int64_t shape_2[1] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 1;
    err |= memcmp(src, " f32", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_2, src, 1 * sizeof(int64_t));
        src += 1 * sizeof(int64_t);
    }
    
    const void *data_2 = src;
    
    obj->v2 = NULL;
    src += shape_2[0] * sizeof(float);
    if (err == 0) {
        obj->v0 = futhark_new_i64_1d(ctx, data_0, shape_0[0]);
        if (obj->v0 == NULL)
            err = 1;
        obj->v1 = futhark_new_i64_1d(ctx, data_1, shape_1[0]);
        if (obj->v1 == NULL)
            err = 1;
        obj->v2 = futhark_new_f32_1d(ctx, data_2, shape_2[0]);
        if (obj->v2 == NULL)
            err = 1;
    }
    if (err != 0) {
        int ret = 0, tmp;
        
        if (obj->v0 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v0)) != 0)
            ret = tmp;
        if (obj->v1 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v1)) != 0)
            ret = tmp;
        if (obj->v2 != NULL && (tmp = futhark_free_f32_1d(ctx, obj->v2)) != 0)
            ret = tmp;
        free(obj);
        obj = NULL;
    }
    return obj;
}
struct futhark_opaque_joinPairs_double {
    struct futhark_i64_1d *v0;
    struct futhark_i64_1d *v1;
    struct futhark_f64_1d *v2;
};
int futhark_project_opaque_joinPairs_double_ix(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_double *obj)
{
    (void) ctx;
    
    struct futhark_i64_1d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_i64_1d));
    memcpy(v, obj->v0, sizeof(struct futhark_i64_1d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_project_opaque_joinPairs_double_iy(struct futhark_context *ctx, struct futhark_i64_1d **out, const struct futhark_opaque_joinPairs_double *obj)
{
    (void) ctx;
    
    struct futhark_i64_1d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_i64_1d));
    memcpy(v, obj->v1, sizeof(struct futhark_i64_1d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_project_opaque_joinPairs_double_vs(struct futhark_context *ctx, struct futhark_f64_1d **out, const struct futhark_opaque_joinPairs_double *obj)
{
    (void) ctx;
    
    struct futhark_f64_1d *v;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    v = malloc(sizeof(struct futhark_f64_1d));
    memcpy(v, obj->v2, sizeof(struct futhark_f64_1d));
    (void) (*v->mem.references)++;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return 0;
}
int futhark_new_opaque_joinPairs_double(struct futhark_context *ctx, struct futhark_opaque_joinPairs_double **out, const struct futhark_i64_1d *f_ix, const struct futhark_i64_1d *f_iy, const struct futhark_f64_1d *f_vs)
{
    struct futhark_opaque_joinPairs_double *v = malloc(sizeof(struct futhark_opaque_joinPairs_double));
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    {
        v->v0 = malloc(sizeof(struct futhark_i64_1d));
        *v->v0 = *f_ix;
        (void) (*v->v0->mem.references)++;
    }
    {
        v->v1 = malloc(sizeof(struct futhark_i64_1d));
        *v->v1 = *f_iy;
        (void) (*v->v1->mem.references)++;
    }
    {
        v->v2 = malloc(sizeof(struct futhark_f64_1d));
        *v->v2 = *f_vs;
        (void) (*v->v2->mem.references)++;
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    *out = v;
    return FUTHARK_SUCCESS;
}
int futhark_free_opaque_joinPairs_double(struct futhark_context *ctx, struct futhark_opaque_joinPairs_double *obj)
{
    (void) ctx;
    
    int ret = 0, tmp;
    
    if (obj->v0 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v0)) != 0)
        ret = tmp;
    if (obj->v1 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v1)) != 0)
        ret = tmp;
    if (obj->v2 != NULL && (tmp = futhark_free_f64_1d(ctx, obj->v2)) != 0)
        ret = tmp;
    free(obj);
    return ret;
}
int futhark_store_opaque_joinPairs_double(struct futhark_context *ctx, const struct futhark_opaque_joinPairs_double *obj, void **p, size_t *n)
{
    (void) ctx;
    
    int ret = 0;
    int64_t size_0 = 7 + 1 * sizeof(int64_t) + futhark_shape_i64_1d(ctx, obj->v0)[0] * sizeof(int64_t);
    int64_t size_1 = 7 + 1 * sizeof(int64_t) + futhark_shape_i64_1d(ctx, obj->v1)[0] * sizeof(int64_t);
    int64_t size_2 = 7 + 1 * sizeof(int64_t) + futhark_shape_f64_1d(ctx, obj->v2)[0] * sizeof(double);
    
    *n = size_0 + size_1 + size_2;
    if (p != NULL && *p == NULL)
        *p = malloc(*n);
    if (p != NULL) {
        unsigned char *out = *p;
        
        *out++ = 'b';
        *out++ = 2;
        *out++ = 1;
        memcpy(out, " i64", 4);
        out += 4;
        memcpy(out, futhark_shape_i64_1d(ctx, obj->v0), 1 * sizeof(int64_t));
        out += 1 * sizeof(int64_t);
        ret |= futhark_values_i64_1d(ctx, obj->v0, (void *) out);
        out += futhark_shape_i64_1d(ctx, obj->v0)[0] * sizeof(int64_t);
        *out++ = 'b';
        *out++ = 2;
        *out++ = 1;
        memcpy(out, " i64", 4);
        out += 4;
        memcpy(out, futhark_shape_i64_1d(ctx, obj->v1), 1 * sizeof(int64_t));
        out += 1 * sizeof(int64_t);
        ret |= futhark_values_i64_1d(ctx, obj->v1, (void *) out);
        out += futhark_shape_i64_1d(ctx, obj->v1)[0] * sizeof(int64_t);
        *out++ = 'b';
        *out++ = 2;
        *out++ = 1;
        memcpy(out, " f64", 4);
        out += 4;
        memcpy(out, futhark_shape_f64_1d(ctx, obj->v2), 1 * sizeof(int64_t));
        out += 1 * sizeof(int64_t);
        ret |= futhark_values_f64_1d(ctx, obj->v2, (void *) out);
        out += futhark_shape_f64_1d(ctx, obj->v2)[0] * sizeof(double);
    }
    return ret;
}
struct futhark_opaque_joinPairs_double *futhark_restore_opaque_joinPairs_double(struct futhark_context *ctx, const void *p)
{
    (void) ctx;
    
    int err = 0;
    const unsigned char *src = p;
    struct futhark_opaque_joinPairs_double *obj = malloc(sizeof(struct futhark_opaque_joinPairs_double));
    int64_t shape_0[1] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 1;
    err |= memcmp(src, " i64", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_0, src, 1 * sizeof(int64_t));
        src += 1 * sizeof(int64_t);
    }
    
    const void *data_0 = src;
    
    obj->v0 = NULL;
    src += shape_0[0] * sizeof(int64_t);
    
    int64_t shape_1[1] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 1;
    err |= memcmp(src, " i64", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_1, src, 1 * sizeof(int64_t));
        src += 1 * sizeof(int64_t);
    }
    
    const void *data_1 = src;
    
    obj->v1 = NULL;
    src += shape_1[0] * sizeof(int64_t);
    
    int64_t shape_2[1] = {0};
    
    err |= *src++ != 'b';
    err |= *src++ != 2;
    err |= *src++ != 1;
    err |= memcmp(src, " f64", 4) != 0;
    src += 4;
    if (err == 0) {
        memcpy(shape_2, src, 1 * sizeof(int64_t));
        src += 1 * sizeof(int64_t);
    }
    
    const void *data_2 = src;
    
    obj->v2 = NULL;
    src += shape_2[0] * sizeof(double);
    if (err == 0) {
        obj->v0 = futhark_new_i64_1d(ctx, data_0, shape_0[0]);
        if (obj->v0 == NULL)
            err = 1;
        obj->v1 = futhark_new_i64_1d(ctx, data_1, shape_1[0]);
        if (obj->v1 == NULL)
            err = 1;
        obj->v2 = futhark_new_f64_1d(ctx, data_2, shape_2[0]);
        if (obj->v2 == NULL)
            err = 1;
    }
    if (err != 0) {
        int ret = 0, tmp;
        
        if (obj->v0 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v0)) != 0)
            ret = tmp;
        if (obj->v1 != NULL && (tmp = futhark_free_i64_1d(ctx, obj->v1)) != 0)
            ret = tmp;
        if (obj->v2 != NULL && (tmp = futhark_free_f64_1d(ctx, obj->v2)) != 0)
            ret = tmp;
        free(obj);
        obj = NULL;
    }
    return obj;
}

FUTHARK_FUN_ATTR int futrts_builtinzhiota_i64(struct futhark_context *ctx, struct memblock_device mem_34166, int64_t n_34167, int64_t x_34168, int64_t s_34169)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
    struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
    struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
    int64_t tblock_sizze_34175;
    
    tblock_sizze_34175 = *ctx->tuning_params.builtinzhiota_i64zitblock_sizze_34175;
    
    int64_t virt_num_tblocks_34176 = sdiv_up64(n_34167, tblock_sizze_34175);
    int64_t num_tblocks_34177 = smin64(virt_num_tblocks_34176, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhiota_i64ziiota_i64_34171(ctx, num_tblocks_34177, 1, 1, tblock_sizze_34175, 1, 1, (int64_t) 0, n_34167, x_34168, s_34169, virt_num_tblocks_34176, num_tblocks_34177, mem_34166.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_f32(struct futhark_context *ctx, struct memblock_device mem_34412, int64_t num_elems_34413, float val_34414)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
    struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
    struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
    int64_t replicate_n_34416 = num_elems_34413;
    int64_t tblock_sizze_34421;
    
    tblock_sizze_34421 = *ctx->tuning_params.builtinzhreplicate_f32zitblock_sizze_34421;
    
    int64_t virt_num_tblocks_34422 = sdiv_up64(replicate_n_34416, tblock_sizze_34421);
    int64_t num_tblocks_34423 = smin64(virt_num_tblocks_34422, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_f32zireplicate_34417(ctx, num_tblocks_34423, 1, 1, tblock_sizze_34421, 1, 1, (int64_t) 0, num_elems_34413, val_34414, replicate_n_34416, virt_num_tblocks_34422, num_tblocks_34423, mem_34412.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_f64(struct futhark_context *ctx, struct memblock_device mem_34412, int64_t num_elems_34413, double val_34414)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
    struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
    struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
    int64_t replicate_n_34416 = num_elems_34413;
    int64_t tblock_sizze_34421;
    
    tblock_sizze_34421 = *ctx->tuning_params.builtinzhreplicate_f64zitblock_sizze_34421;
    
    int64_t virt_num_tblocks_34422 = sdiv_up64(replicate_n_34416, tblock_sizze_34421);
    int64_t num_tblocks_34423 = smin64(virt_num_tblocks_34422, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_f64zireplicate_34417(ctx, num_tblocks_34423, 1, 1, tblock_sizze_34421, 1, 1, (int64_t) 0, num_elems_34413, val_34414, replicate_n_34416, virt_num_tblocks_34422, num_tblocks_34423, mem_34412.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i16(struct futhark_context *ctx, struct memblock_device mem_34412, int64_t num_elems_34413, int16_t val_34414)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
    struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
    struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
    int64_t replicate_n_34416 = num_elems_34413;
    int64_t tblock_sizze_34421;
    
    tblock_sizze_34421 = *ctx->tuning_params.builtinzhreplicate_i16zitblock_sizze_34421;
    
    int64_t virt_num_tblocks_34422 = sdiv_up64(replicate_n_34416, tblock_sizze_34421);
    int64_t num_tblocks_34423 = smin64(virt_num_tblocks_34422, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_i16zireplicate_34417(ctx, num_tblocks_34423, 1, 1, tblock_sizze_34421, 1, 1, (int64_t) 0, num_elems_34413, val_34414, replicate_n_34416, virt_num_tblocks_34422, num_tblocks_34423, mem_34412.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i32(struct futhark_context *ctx, struct memblock_device mem_34059, int64_t num_elems_34060, int32_t val_34061)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
    struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
    struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
    int64_t replicate_n_34063 = num_elems_34060;
    int64_t tblock_sizze_34068;
    
    tblock_sizze_34068 = *ctx->tuning_params.builtinzhreplicate_i32zitblock_sizze_34068;
    
    int64_t virt_num_tblocks_34069 = sdiv_up64(replicate_n_34063, tblock_sizze_34068);
    int64_t num_tblocks_34070 = smin64(virt_num_tblocks_34069, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_i32zireplicate_34064(ctx, num_tblocks_34070, 1, 1, tblock_sizze_34068, 1, 1, (int64_t) 0, num_elems_34060, val_34061, replicate_n_34063, virt_num_tblocks_34069, num_tblocks_34070, mem_34059.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i64(struct futhark_context *ctx, struct memblock_device mem_34183, int64_t num_elems_34184, int64_t val_34185)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
    struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
    struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
    int64_t replicate_n_34187 = num_elems_34184;
    int64_t tblock_sizze_34192;
    
    tblock_sizze_34192 = *ctx->tuning_params.builtinzhreplicate_i64zitblock_sizze_34192;
    
    int64_t virt_num_tblocks_34193 = sdiv_up64(replicate_n_34187, tblock_sizze_34192);
    int64_t num_tblocks_34194 = smin64(virt_num_tblocks_34193, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_i64zireplicate_34188(ctx, num_tblocks_34194, 1, 1, tblock_sizze_34192, 1, 1, (int64_t) 0, num_elems_34184, val_34185, replicate_n_34187, virt_num_tblocks_34193, num_tblocks_34194, mem_34183.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i8(struct futhark_context *ctx, struct memblock_device mem_34033, int64_t num_elems_34034, int8_t val_34035)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
    struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
    struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
    int64_t replicate_n_34037 = num_elems_34034;
    int64_t tblock_sizze_34042;
    
    tblock_sizze_34042 = *ctx->tuning_params.builtinzhreplicate_i8zitblock_sizze_34042;
    
    int64_t virt_num_tblocks_34043 = sdiv_up64(replicate_n_34037, tblock_sizze_34042);
    int64_t num_tblocks_34044 = smin64(virt_num_tblocks_34043, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_i8zireplicate_34038(ctx, num_tblocks_34044, 1, 1, tblock_sizze_34042, 1, 1, (int64_t) 0, num_elems_34034, val_34035, replicate_n_34037, virt_num_tblocks_34043, num_tblocks_34044, mem_34033.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_double(struct futhark_context *ctx, struct memblock_device *mem_out_p_34513, struct memblock_device is_mem_33832, struct memblock_device ys_mem_33833, int64_t niz2084U_29871, int64_t dz2083U_29872, int64_t incr_29873, int64_t psizze_29874)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_33857;
    
    mem_33857.references = NULL;
    
    struct memblock_device mem_param_tmp_34050;
    
    mem_param_tmp_34050.references = NULL;
    
    struct memblock_device mem_param_tmp_34049;
    
    mem_param_tmp_34049.references = NULL;
    
    struct memblock_device mem_33849;
    
    mem_33849.references = NULL;
    
    struct memblock_device mem_33846;
    
    mem_33846.references = NULL;
    
    struct memblock_device mem_param_33844;
    
    mem_param_33844.references = NULL;
    
    struct memblock_device mem_param_33841;
    
    mem_param_33841.references = NULL;
    
    struct memblock_device ext_mem_33854;
    
    ext_mem_33854.references = NULL;
    
    struct memblock_device ext_mem_33855;
    
    ext_mem_33855.references = NULL;
    
    struct memblock_device mem_33838;
    
    mem_33838.references = NULL;
    
    struct memblock_device mem_33836;
    
    mem_33836.references = NULL;
    
    struct memblock_device mem_out_34019;
    
    mem_out_34019.references = NULL;
    
    struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
    struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
    struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
    int64_t bytes_33835 = (int64_t) 8 * niz2084U_29871;
    bool zzero_31850 = psizze_29874 == (int64_t) 0;
    bool nonzzero_31851 = !zzero_31850;
    bool nonzzero_cert_31852;
    
    if (!nonzzero_31851) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftbasics.fut:24:22-28\n   #1  ftSMJ.fut:433:5-41\n   #2  ftSMJ.fut:432:1-433:41\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t segmap_tblock_sizze_33056;
    
    segmap_tblock_sizze_33056 = *ctx->tuning_params.gather_payloads_doublezisegmap_tblock_sizze_33048;
    
    int64_t segmap_usable_groups_33057 = sdiv_up64(niz2084U_29871, segmap_tblock_sizze_33056);
    
    if (memblock_alloc_device(ctx, &mem_33836, bytes_33835, "mem_33836")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_34020 = sext_i64_i32(sdiv_up64(niz2084U_29871, segmap_tblock_sizze_33056));
    
    {
        err = gpu_kernel_gather_payloads_doublezisegmap_33060(ctx, segmap_usable_groups_33057, 1, 1, *ctx->tuning_params.gather_payloads_doublezisegmap_tblock_sizze_33048, 1, 1, (int64_t) 0, niz2084U_29871, incr_29873, is_mem_33832.mem, mem_33836.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t zm_lhs_31848 = add64(dz2083U_29872, psizze_29874);
    int64_t zs_lhs_31849 = sub64(zm_lhs_31848, (int64_t) 1);
    int64_t m_31853 = sdiv64(zs_lhs_31849, psizze_29874);
    
    if (memblock_alloc_device(ctx, &mem_33838, bytes_33835, "mem_33838")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_f64(ctx, mem_33838, niz2084U_29871, 0.0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    bool loop_cond_31855 = slt64((int64_t) 0, m_31853);
    int64_t segmap_tblock_sizze_33084;
    
    segmap_tblock_sizze_33084 = *ctx->tuning_params.gather_payloads_doublezisegmap_tblock_sizze_33066;
    
    int64_t segmap_usable_groups_33085 = sdiv_up_safe64(niz2084U_29871, segmap_tblock_sizze_33084);
    bool partitioned_gather_res_31856;
    int64_t partitioned_gather_res_31859;
    bool loop_while_31860;
    int64_t p_31863;
    
    if (memblock_set_device(ctx, &mem_param_33841, &mem_33836, "mem_33836") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_33844, &mem_33838, "mem_33838") != 0)
        return 1;
    loop_while_31860 = loop_cond_31855;
    p_31863 = (int64_t) 0;
    while (loop_while_31860) {
        int64_t lower_bound_31864 = mul64(psizze_29874, p_31863);
        int64_t min_arg1_31865 = add64(psizze_29874, lower_bound_31864);
        int64_t min_res_31866 = smin64(dz2083U_29872, min_arg1_31865);
        int64_t j_m_i_31867 = sub64(min_res_31866, lower_bound_31864);
        bool empty_slice_31868 = j_m_i_31867 == (int64_t) 0;
        int64_t m_31869 = sub64(j_m_i_31867, (int64_t) 1);
        int64_t i_p_m_t_s_31870 = add64(lower_bound_31864, m_31869);
        bool zzero_leq_i_p_m_t_s_31871 = sle64((int64_t) 0, i_p_m_t_s_31870);
        bool i_p_m_t_s_leq_w_31872 = slt64(i_p_m_t_s_31870, dz2083U_29872);
        bool zzero_lte_i_31873 = sle64((int64_t) 0, lower_bound_31864);
        bool i_lte_j_31874 = sle64(lower_bound_31864, min_res_31866);
        bool y_31875 = i_p_m_t_s_leq_w_31872 && zzero_lte_i_31873;
        bool y_31876 = zzero_leq_i_p_m_t_s_31871 && y_31875;
        bool forwards_ok_31877 = i_lte_j_31874 && y_31876;
        bool ok_or_empty_31878 = empty_slice_31868 || forwards_ok_31877;
        bool index_certs_31879;
        
        if (!ok_or_empty_31878) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) lower_bound_31864, ":", (long long) min_res_31866, "] out of bounds for array of shape [", (long long) dz2083U_29872, "].", "-> #0  ftbasics.fut:31:18-45\n   #1  ftSMJ.fut:433:5-41\n   #2  ftSMJ.fut:432:1-433:41\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_33846, bytes_33835, "mem_33846")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33846.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_33841.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {niz2084U_29871})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_33849, bytes_33835, "mem_33849")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_34055 = sext_i64_i32(sdiv_up64(niz2084U_29871, segmap_tblock_sizze_33084));
        
        {
            err = gpu_kernel_gather_payloads_doublezisegmap_33088(ctx, segmap_usable_groups_33085, 1, 1, *ctx->tuning_params.gather_payloads_doublezisegmap_tblock_sizze_33066, 1, 1, (int64_t) 0, niz2084U_29871, lower_bound_31864, min_res_31866, j_m_i_31867, ys_mem_33833.mem, mem_param_33841.mem, mem_param_33844.mem, mem_33849.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t tmp_31894 = add64((int64_t) 1, p_31863);
        bool loop_cond_31895 = slt64(tmp_31894, m_31853);
        
        if (memblock_set_device(ctx, &mem_param_tmp_34049, &mem_33846, "mem_33846") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_34050, &mem_33849, "mem_33849") != 0)
            return 1;
        
        bool loop_while_tmp_34051 = loop_cond_31895;
        int64_t p_tmp_34054 = tmp_31894;
        
        if (memblock_set_device(ctx, &mem_param_33841, &mem_param_tmp_34049, "mem_param_tmp_34049") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_33844, &mem_param_tmp_34050, "mem_param_tmp_34050") != 0)
            return 1;
        loop_while_31860 = loop_while_tmp_34051;
        p_31863 = p_tmp_34054;
    }
    if (memblock_set_device(ctx, &ext_mem_33855, &mem_param_33841, "mem_param_33841") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_33854, &mem_param_33844, "mem_param_33844") != 0)
        return 1;
    partitioned_gather_res_31856 = loop_while_31860;
    partitioned_gather_res_31859 = p_31863;
    if (memblock_unref_device(ctx, &mem_33836, "mem_33836") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33838, "mem_33838") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_33857, bytes_33835, "mem_33857")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33857.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_33854.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {niz2084U_29871})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_33854, "ext_mem_33854") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_34019, &mem_33857, "mem_33857") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_34513, &mem_out_34019, "mem_out_34019") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_33857, "mem_33857") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_34050, "mem_param_tmp_34050") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_34049, "mem_param_tmp_34049") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33849, "mem_33849") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33846, "mem_33846") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_33844, "mem_param_33844") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_33841, "mem_param_33841") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33854, "ext_mem_33854") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33855, "ext_mem_33855") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33838, "mem_33838") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33836, "mem_33836") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_34019, "mem_out_34019") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_double_GFUR(struct futhark_context *ctx, struct memblock_device *mem_out_p_34514, struct memblock_device preVals_mem_33832, struct memblock_device is_mem_33833, struct memblock_device ys_mem_33834, int64_t ni_31378, int64_t n_31379, int64_t incr_31380, int64_t psizze_31381)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_33856;
    
    mem_33856.references = NULL;
    
    struct memblock_device mem_param_tmp_34030;
    
    mem_param_tmp_34030.references = NULL;
    
    struct memblock_device mem_param_tmp_34029;
    
    mem_param_tmp_34029.references = NULL;
    
    struct memblock_device mem_33848;
    
    mem_33848.references = NULL;
    
    struct memblock_device mem_33845;
    
    mem_33845.references = NULL;
    
    struct memblock_device mem_param_33843;
    
    mem_param_33843.references = NULL;
    
    struct memblock_device mem_param_33840;
    
    mem_param_33840.references = NULL;
    
    struct memblock_device ext_mem_33853;
    
    ext_mem_33853.references = NULL;
    
    struct memblock_device ext_mem_33854;
    
    ext_mem_33854.references = NULL;
    
    struct memblock_device mem_33837;
    
    mem_33837.references = NULL;
    
    struct memblock_device mem_out_34019;
    
    mem_out_34019.references = NULL;
    
    struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
    struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
    struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
    int64_t bytes_33836 = (int64_t) 8 * ni_31378;
    bool zzero_31851 = psizze_31381 == (int64_t) 0;
    bool nonzzero_31852 = !zzero_31851;
    bool nonzzero_cert_31853;
    
    if (!nonzzero_31852) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftbasics.fut:43:22-28\n   #1  ftSMJ.fut:461:5-50\n   #2  ftSMJ.fut:460:1-461:50\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t segmap_tblock_sizze_33336;
    
    segmap_tblock_sizze_33336 = *ctx->tuning_params.gather_payloads_double_GFURzisegmap_tblock_sizze_33328;
    
    int64_t segmap_usable_groups_33337 = sdiv_up64(ni_31378, segmap_tblock_sizze_33336);
    
    if (memblock_alloc_device(ctx, &mem_33837, bytes_33836, "mem_33837")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_34020 = sext_i64_i32(sdiv_up64(ni_31378, segmap_tblock_sizze_33336));
    
    {
        err = gpu_kernel_gather_payloads_double_GFURzisegmap_33340(ctx, segmap_usable_groups_33337, 1, 1, *ctx->tuning_params.gather_payloads_double_GFURzisegmap_tblock_sizze_33328, 1, 1, (int64_t) 0, ni_31378, incr_31380, is_mem_33833.mem, mem_33837.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t zm_lhs_31849 = add64(n_31379, psizze_31381);
    int64_t zs_lhs_31850 = sub64(zm_lhs_31849, (int64_t) 1);
    int64_t m_31854 = sdiv64(zs_lhs_31850, psizze_31381);
    bool loop_cond_31855 = slt64((int64_t) 0, m_31854);
    int64_t segmap_tblock_sizze_33364;
    
    segmap_tblock_sizze_33364 = *ctx->tuning_params.gather_payloads_double_GFURzisegmap_tblock_sizze_33346;
    
    int64_t segmap_usable_groups_33365 = sdiv_up_safe64(ni_31378, segmap_tblock_sizze_33364);
    bool partitioned_gather_over_array_res_31856;
    int64_t partitioned_gather_over_array_res_31859;
    bool loop_while_31860;
    int64_t p_31863;
    
    if (memblock_set_device(ctx, &mem_param_33840, &mem_33837, "mem_33837") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_33843, &preVals_mem_33832, "preVals_mem_33832") != 0)
        return 1;
    loop_while_31860 = loop_cond_31855;
    p_31863 = (int64_t) 0;
    while (loop_while_31860) {
        int64_t lower_bound_31864 = mul64(psizze_31381, p_31863);
        int64_t min_arg1_31865 = add64(psizze_31381, lower_bound_31864);
        int64_t min_res_31866 = smin64(n_31379, min_arg1_31865);
        int64_t j_m_i_31867 = sub64(min_res_31866, lower_bound_31864);
        bool empty_slice_31868 = j_m_i_31867 == (int64_t) 0;
        int64_t m_31869 = sub64(j_m_i_31867, (int64_t) 1);
        int64_t i_p_m_t_s_31870 = add64(lower_bound_31864, m_31869);
        bool zzero_leq_i_p_m_t_s_31871 = sle64((int64_t) 0, i_p_m_t_s_31870);
        bool i_p_m_t_s_leq_w_31872 = slt64(i_p_m_t_s_31870, n_31379);
        bool zzero_lte_i_31873 = sle64((int64_t) 0, lower_bound_31864);
        bool i_lte_j_31874 = sle64(lower_bound_31864, min_res_31866);
        bool y_31875 = i_p_m_t_s_leq_w_31872 && zzero_lte_i_31873;
        bool y_31876 = zzero_leq_i_p_m_t_s_31871 && y_31875;
        bool forwards_ok_31877 = i_lte_j_31874 && y_31876;
        bool ok_or_empty_31878 = empty_slice_31868 || forwards_ok_31877;
        bool index_certs_31879;
        
        if (!ok_or_empty_31878) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) lower_bound_31864, ":", (long long) min_res_31866, "] out of bounds for array of shape [", (long long) n_31379, "].", "-> #0  ftbasics.fut:49:18-45\n   #1  ftSMJ.fut:461:5-50\n   #2  ftSMJ.fut:460:1-461:50\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_33845, bytes_33836, "mem_33845")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33845.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_33840.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {ni_31378})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_33848, bytes_33836, "mem_33848")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_34035 = sext_i64_i32(sdiv_up64(ni_31378, segmap_tblock_sizze_33364));
        
        {
            err = gpu_kernel_gather_payloads_double_GFURzisegmap_33368(ctx, segmap_usable_groups_33365, 1, 1, *ctx->tuning_params.gather_payloads_double_GFURzisegmap_tblock_sizze_33346, 1, 1, (int64_t) 0, ni_31378, lower_bound_31864, min_res_31866, j_m_i_31867, ys_mem_33834.mem, mem_param_33840.mem, mem_param_33843.mem, mem_33848.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t tmp_31894 = add64((int64_t) 1, p_31863);
        bool loop_cond_31895 = slt64(tmp_31894, m_31854);
        
        if (memblock_set_device(ctx, &mem_param_tmp_34029, &mem_33845, "mem_33845") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_34030, &mem_33848, "mem_33848") != 0)
            return 1;
        
        bool loop_while_tmp_34031 = loop_cond_31895;
        int64_t p_tmp_34034 = tmp_31894;
        
        if (memblock_set_device(ctx, &mem_param_33840, &mem_param_tmp_34029, "mem_param_tmp_34029") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_33843, &mem_param_tmp_34030, "mem_param_tmp_34030") != 0)
            return 1;
        loop_while_31860 = loop_while_tmp_34031;
        p_31863 = p_tmp_34034;
    }
    if (memblock_set_device(ctx, &ext_mem_33854, &mem_param_33840, "mem_param_33840") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_33853, &mem_param_33843, "mem_param_33843") != 0)
        return 1;
    partitioned_gather_over_array_res_31856 = loop_while_31860;
    partitioned_gather_over_array_res_31859 = p_31863;
    if (memblock_unref_device(ctx, &mem_33837, "mem_33837") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_33856, bytes_33836, "mem_33856")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33856.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_33853.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {ni_31378})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_33853, "ext_mem_33853") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_34019, &mem_33856, "mem_33856") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_34514, &mem_out_34019, "mem_out_34019") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_33856, "mem_33856") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_34030, "mem_param_tmp_34030") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_34029, "mem_param_tmp_34029") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33848, "mem_33848") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33845, "mem_33845") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_33843, "mem_param_33843") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_33840, "mem_param_33840") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33853, "ext_mem_33853") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33854, "ext_mem_33854") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33837, "mem_33837") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_34019, "mem_out_34019") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_float(struct futhark_context *ctx, struct memblock_device *mem_out_p_34515, struct memblock_device is_mem_33832, struct memblock_device ys_mem_33833, int64_t niz2084U_29531, int64_t dz2083U_29532, int64_t incr_29533, int64_t psizze_29534)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_33857;
    
    mem_33857.references = NULL;
    
    struct memblock_device mem_param_tmp_34050;
    
    mem_param_tmp_34050.references = NULL;
    
    struct memblock_device mem_param_tmp_34049;
    
    mem_param_tmp_34049.references = NULL;
    
    struct memblock_device mem_33849;
    
    mem_33849.references = NULL;
    
    struct memblock_device mem_33846;
    
    mem_33846.references = NULL;
    
    struct memblock_device mem_param_33844;
    
    mem_param_33844.references = NULL;
    
    struct memblock_device mem_param_33841;
    
    mem_param_33841.references = NULL;
    
    struct memblock_device ext_mem_33854;
    
    ext_mem_33854.references = NULL;
    
    struct memblock_device ext_mem_33855;
    
    ext_mem_33855.references = NULL;
    
    struct memblock_device mem_33838;
    
    mem_33838.references = NULL;
    
    struct memblock_device mem_33836;
    
    mem_33836.references = NULL;
    
    struct memblock_device mem_out_34019;
    
    mem_out_34019.references = NULL;
    
    struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
    struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
    struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
    int64_t bytes_33835 = (int64_t) 8 * niz2084U_29531;
    bool zzero_31850 = psizze_29534 == (int64_t) 0;
    bool nonzzero_31851 = !zzero_31850;
    bool nonzzero_cert_31852;
    
    if (!nonzzero_31851) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftbasics.fut:24:22-28\n   #1  ftSMJ.fut:430:5-41\n   #2  ftSMJ.fut:429:1-430:41\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_33837 = (int64_t) 4 * niz2084U_29531;
    int64_t segmap_tblock_sizze_33000;
    
    segmap_tblock_sizze_33000 = *ctx->tuning_params.gather_payloads_floatzisegmap_tblock_sizze_32992;
    
    int64_t segmap_usable_groups_33001 = sdiv_up64(niz2084U_29531, segmap_tblock_sizze_33000);
    
    if (memblock_alloc_device(ctx, &mem_33836, bytes_33835, "mem_33836")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_34020 = sext_i64_i32(sdiv_up64(niz2084U_29531, segmap_tblock_sizze_33000));
    
    {
        err = gpu_kernel_gather_payloads_floatzisegmap_33004(ctx, segmap_usable_groups_33001, 1, 1, *ctx->tuning_params.gather_payloads_floatzisegmap_tblock_sizze_32992, 1, 1, (int64_t) 0, niz2084U_29531, incr_29533, is_mem_33832.mem, mem_33836.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t zm_lhs_31848 = add64(dz2083U_29532, psizze_29534);
    int64_t zs_lhs_31849 = sub64(zm_lhs_31848, (int64_t) 1);
    int64_t m_31853 = sdiv64(zs_lhs_31849, psizze_29534);
    
    if (memblock_alloc_device(ctx, &mem_33838, bytes_33837, "mem_33838")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_f32(ctx, mem_33838, niz2084U_29531, 0.0F) != 0) {
        err = 1;
        goto cleanup;
    }
    
    bool loop_cond_31855 = slt64((int64_t) 0, m_31853);
    int64_t segmap_tblock_sizze_33028;
    
    segmap_tblock_sizze_33028 = *ctx->tuning_params.gather_payloads_floatzisegmap_tblock_sizze_33010;
    
    int64_t segmap_usable_groups_33029 = sdiv_up_safe64(niz2084U_29531, segmap_tblock_sizze_33028);
    bool partitioned_gather_res_31856;
    int64_t partitioned_gather_res_31859;
    bool loop_while_31860;
    int64_t p_31863;
    
    if (memblock_set_device(ctx, &mem_param_33841, &mem_33836, "mem_33836") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_33844, &mem_33838, "mem_33838") != 0)
        return 1;
    loop_while_31860 = loop_cond_31855;
    p_31863 = (int64_t) 0;
    while (loop_while_31860) {
        int64_t lower_bound_31864 = mul64(psizze_29534, p_31863);
        int64_t min_arg1_31865 = add64(psizze_29534, lower_bound_31864);
        int64_t min_res_31866 = smin64(dz2083U_29532, min_arg1_31865);
        int64_t j_m_i_31867 = sub64(min_res_31866, lower_bound_31864);
        bool empty_slice_31868 = j_m_i_31867 == (int64_t) 0;
        int64_t m_31869 = sub64(j_m_i_31867, (int64_t) 1);
        int64_t i_p_m_t_s_31870 = add64(lower_bound_31864, m_31869);
        bool zzero_leq_i_p_m_t_s_31871 = sle64((int64_t) 0, i_p_m_t_s_31870);
        bool i_p_m_t_s_leq_w_31872 = slt64(i_p_m_t_s_31870, dz2083U_29532);
        bool zzero_lte_i_31873 = sle64((int64_t) 0, lower_bound_31864);
        bool i_lte_j_31874 = sle64(lower_bound_31864, min_res_31866);
        bool y_31875 = i_p_m_t_s_leq_w_31872 && zzero_lte_i_31873;
        bool y_31876 = zzero_leq_i_p_m_t_s_31871 && y_31875;
        bool forwards_ok_31877 = i_lte_j_31874 && y_31876;
        bool ok_or_empty_31878 = empty_slice_31868 || forwards_ok_31877;
        bool index_certs_31879;
        
        if (!ok_or_empty_31878) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) lower_bound_31864, ":", (long long) min_res_31866, "] out of bounds for array of shape [", (long long) dz2083U_29532, "].", "-> #0  ftbasics.fut:31:18-45\n   #1  ftSMJ.fut:430:5-41\n   #2  ftSMJ.fut:429:1-430:41\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_33846, bytes_33835, "mem_33846")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33846.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_33841.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {niz2084U_29531})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_33849, bytes_33837, "mem_33849")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_34055 = sext_i64_i32(sdiv_up64(niz2084U_29531, segmap_tblock_sizze_33028));
        
        {
            err = gpu_kernel_gather_payloads_floatzisegmap_33032(ctx, segmap_usable_groups_33029, 1, 1, *ctx->tuning_params.gather_payloads_floatzisegmap_tblock_sizze_33010, 1, 1, (int64_t) 0, niz2084U_29531, lower_bound_31864, min_res_31866, j_m_i_31867, ys_mem_33833.mem, mem_param_33841.mem, mem_param_33844.mem, mem_33849.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t tmp_31894 = add64((int64_t) 1, p_31863);
        bool loop_cond_31895 = slt64(tmp_31894, m_31853);
        
        if (memblock_set_device(ctx, &mem_param_tmp_34049, &mem_33846, "mem_33846") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_34050, &mem_33849, "mem_33849") != 0)
            return 1;
        
        bool loop_while_tmp_34051 = loop_cond_31895;
        int64_t p_tmp_34054 = tmp_31894;
        
        if (memblock_set_device(ctx, &mem_param_33841, &mem_param_tmp_34049, "mem_param_tmp_34049") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_33844, &mem_param_tmp_34050, "mem_param_tmp_34050") != 0)
            return 1;
        loop_while_31860 = loop_while_tmp_34051;
        p_31863 = p_tmp_34054;
    }
    if (memblock_set_device(ctx, &ext_mem_33855, &mem_param_33841, "mem_param_33841") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_33854, &mem_param_33844, "mem_param_33844") != 0)
        return 1;
    partitioned_gather_res_31856 = loop_while_31860;
    partitioned_gather_res_31859 = p_31863;
    if (memblock_unref_device(ctx, &mem_33836, "mem_33836") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33838, "mem_33838") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_33857, bytes_33837, "mem_33857")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_33857.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_33854.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {niz2084U_29531})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_33854, "ext_mem_33854") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_34019, &mem_33857, "mem_33857") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_34515, &mem_out_34019, "mem_out_34019") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_33857, "mem_33857") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_34050, "mem_param_tmp_34050") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_34049, "mem_param_tmp_34049") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33849, "mem_33849") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33846, "mem_33846") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_33844, "mem_param_33844") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_33841, "mem_param_33841") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33854, "ext_mem_33854") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33855, "ext_mem_33855") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33838, "mem_33838") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33836, "mem_33836") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_34019, "mem_out_34019") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_float_GFUR(struct futhark_context *ctx, struct memblock_device *mem_out_p_34516, struct memblock_device preVals_mem_33832, struct memblock_device is_mem_33833, struct memblock_device ys_mem_33834, int64_t ni_31077, int64_t n_31078, int64_t incr_31079, int64_t psizze_31080)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_33856;
    
    mem_33856.references = NULL;
    
    struct memblock_device mem_param_tmp_34030;
    
    mem_param_tmp_34030.references = NULL;
    
    struct memblock_device mem_param_tmp_34029;
    
    mem_param_tmp_34029.references = NULL;
    
    struct memblock_device mem_33848;
    
    mem_33848.references = NULL;
    
    struct memblock_device mem_33845;
    
    mem_33845.references = NULL;
    
    struct memblock_device mem_param_33843;
    
    mem_param_33843.references = NULL;
    
    struct memblock_device mem_param_33840;
    
    mem_param_33840.references = NULL;
    
    struct memblock_device ext_mem_33853;
    
    ext_mem_33853.references = NULL;
    
    struct memblock_device ext_mem_33854;
    
    ext_mem_33854.references = NULL;
    
    struct memblock_device mem_33837;
    
    mem_33837.references = NULL;
    
    struct memblock_device mem_out_34019;
    
    mem_out_34019.references = NULL;
    
    struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
    struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
    struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
    int64_t bytes_33836 = (int64_t) 8 * ni_31077;
    bool zzero_31851 = psizze_31080 == (int64_t) 0;
    bool nonzzero_31852 = !zzero_31851;
    bool nonzzero_cert_31853;
    
    if (!nonzzero_31852) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftbasics.fut:43:22-28\n   #1  ftSMJ.fut:458:5-50\n   #2  ftSMJ.fut:457:1-458:50\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_33847 = (int64_t) 4 * ni_31077;
    int64_t segmap_tblock_sizze_33280;
    
    segmap_tblock_sizze_33280 = *ctx->tuning_params.gather_payloads_float_GFURzisegmap_tblock_sizze_33272;
    
    int64_t segmap_usable_groups_33281 = sdiv_up64(ni_31077, segmap_tblock_sizze_33280);
    
    if (memblock_alloc_device(ctx, &mem_33837, bytes_33836, "mem_33837")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_34020 = sext_i64_i32(sdiv_up64(ni_31077, segmap_tblock_sizze_33280));
    
    {
        err = gpu_kernel_gather_payloads_float_GFURzisegmap_33284(ctx, segmap_usable_groups_33281, 1, 1, *ctx->tuning_params.gather_payloads_float_GFURzisegmap_tblock_sizze_33272, 1, 1, (int64_t) 0, ni_31077, incr_31079, is_mem_33833.mem, mem_33837.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t zm_lhs_31849 = add64(n_31078, psizze_31080);
    int64_t zs_lhs_31850 = sub64(zm_lhs_31849, (int64_t) 1);
    int64_t m_31854 = sdiv64(zs_lhs_31850, psizze_31080);
    bool loop_cond_31855 = slt64((int64_t) 0, m_31854);
    int64_t segmap_tblock_sizze_33308;
    
    segmap_tblock_sizze_33308 = *ctx->tuning_params.gather_payloads_float_GFURzisegmap_tblock_sizze_33290;
    
    int64_t segmap_usable_groups_33309 = sdiv_up_safe64(ni_31077, segmap_tblock_sizze_33308);
    bool partitioned_gather_over_array_res_31856;
    int64_t partitioned_gather_over_array_res_31859;
    bool loop_while_31860;
    int64_t p_31863;
    
    if (memblock_set_device(ctx, &mem_param_33840, &mem_33837, "mem_33837") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_33843, &preVals_mem_33832, "preVals_mem_33832") != 0)
        return 1;
    loop_while_31860 = loop_cond_31855;
    p_31863 = (int64_t) 0;
    while (loop_while_31860) {
        int64_t lower_bound_31864 = mul64(psizze_31080, p_31863);
        int64_t min_arg1_31865 = add64(psizze_31080, lower_bound_31864);
        int64_t min_res_31866 = smin64(n_31078, min_arg1_31865);
        int64_t j_m_i_31867 = sub64(min_res_31866, lower_bound_31864);
        bool empty_slice_31868 = j_m_i_31867 == (int64_t) 0;
        int64_t m_31869 = sub64(j_m_i_31867, (int64_t) 1);
        int64_t i_p_m_t_s_31870 = add64(lower_bound_31864, m_31869);
        bool zzero_leq_i_p_m_t_s_31871 = sle64((int64_t) 0, i_p_m_t_s_31870);
        bool i_p_m_t_s_leq_w_31872 = slt64(i_p_m_t_s_31870, n_31078);
        bool zzero_lte_i_31873 = sle64((int64_t) 0, lower_bound_31864);
        bool i_lte_j_31874 = sle64(lower_bound_31864, min_res_31866);
        bool y_31875 = i_p_m_t_s_leq_w_31872 && zzero_lte_i_31873;
        bool y_31876 = zzero_leq_i_p_m_t_s_31871 && y_31875;
        bool forwards_ok_31877 = i_lte_j_31874 && y_31876;
        bool ok_or_empty_31878 = empty_slice_31868 || forwards_ok_31877;
        bool index_certs_31879;
        
        if (!ok_or_empty_31878) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) lower_bound_31864, ":", (long long) min_res_31866, "] out of bounds for array of shape [", (long long) n_31078, "].", "-> #0  ftbasics.fut:49:18-45\n   #1  ftSMJ.fut:458:5-50\n   #2  ftSMJ.fut:457:1-458:50\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_33845, bytes_33836, "mem_33845")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33845.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_33840.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {ni_31077})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_33848, bytes_33847, "mem_33848")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_34035 = sext_i64_i32(sdiv_up64(ni_31077, segmap_tblock_sizze_33308));
        
        {
            err = gpu_kernel_gather_payloads_float_GFURzisegmap_33312(ctx, segmap_usable_groups_33309, 1, 1, *ctx->tuning_params.gather_payloads_float_GFURzisegmap_tblock_sizze_33290, 1, 1, (int64_t) 0, ni_31077, lower_bound_31864, min_res_31866, j_m_i_31867, ys_mem_33834.mem, mem_param_33840.mem, mem_param_33843.mem, mem_33848.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t tmp_31894 = add64((int64_t) 1, p_31863);
        bool loop_cond_31895 = slt64(tmp_31894, m_31854);
        
        if (memblock_set_device(ctx, &mem_param_tmp_34029, &mem_33845, "mem_33845") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_34030, &mem_33848, "mem_33848") != 0)
            return 1;
        
        bool loop_while_tmp_34031 = loop_cond_31895;
        int64_t p_tmp_34034 = tmp_31894;
        
        if (memblock_set_device(ctx, &mem_param_33840, &mem_param_tmp_34029, "mem_param_tmp_34029") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_33843, &mem_param_tmp_34030, "mem_param_tmp_34030") != 0)
            return 1;
        loop_while_31860 = loop_while_tmp_34031;
        p_31863 = p_tmp_34034;
    }
    if (memblock_set_device(ctx, &ext_mem_33854, &mem_param_33840, "mem_param_33840") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_33853, &mem_param_33843, "mem_param_33843") != 0)
        return 1;
    partitioned_gather_over_array_res_31856 = loop_while_31860;
    partitioned_gather_over_array_res_31859 = p_31863;
    if (memblock_unref_device(ctx, &mem_33837, "mem_33837") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_33856, bytes_33847, "mem_33856")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_33856.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_33853.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {ni_31077})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_33853, "ext_mem_33853") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_34019, &mem_33856, "mem_33856") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_34516, &mem_out_34019, "mem_out_34019") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_33856, "mem_33856") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_34030, "mem_param_tmp_34030") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_34029, "mem_param_tmp_34029") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33848, "mem_33848") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33845, "mem_33845") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_33843, "mem_param_33843") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_33840, "mem_param_33840") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33853, "ext_mem_33853") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33854, "ext_mem_33854") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33837, "mem_33837") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_34019, "mem_out_34019") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_int(struct futhark_context *ctx, struct memblock_device *mem_out_p_34517, struct memblock_device is_mem_33832, struct memblock_device ys_mem_33833, int64_t niz2084U_28882, int64_t dz2083U_28883, int64_t incr_28884, int64_t psizze_28885)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_33857;
    
    mem_33857.references = NULL;
    
    struct memblock_device mem_param_tmp_34050;
    
    mem_param_tmp_34050.references = NULL;
    
    struct memblock_device mem_param_tmp_34049;
    
    mem_param_tmp_34049.references = NULL;
    
    struct memblock_device mem_33849;
    
    mem_33849.references = NULL;
    
    struct memblock_device mem_33846;
    
    mem_33846.references = NULL;
    
    struct memblock_device mem_param_33844;
    
    mem_param_33844.references = NULL;
    
    struct memblock_device mem_param_33841;
    
    mem_param_33841.references = NULL;
    
    struct memblock_device ext_mem_33854;
    
    ext_mem_33854.references = NULL;
    
    struct memblock_device ext_mem_33855;
    
    ext_mem_33855.references = NULL;
    
    struct memblock_device mem_33838;
    
    mem_33838.references = NULL;
    
    struct memblock_device mem_33836;
    
    mem_33836.references = NULL;
    
    struct memblock_device mem_out_34019;
    
    mem_out_34019.references = NULL;
    
    struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
    struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
    struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
    int64_t bytes_33835 = (int64_t) 8 * niz2084U_28882;
    bool zzero_31850 = psizze_28885 == (int64_t) 0;
    bool nonzzero_31851 = !zzero_31850;
    bool nonzzero_cert_31852;
    
    if (!nonzzero_31851) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftbasics.fut:24:22-28\n   #1  ftSMJ.fut:424:5-41\n   #2  ftSMJ.fut:423:1-424:41\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_33837 = (int64_t) 4 * niz2084U_28882;
    int64_t segmap_tblock_sizze_32888;
    
    segmap_tblock_sizze_32888 = *ctx->tuning_params.gather_payloads_intzisegmap_tblock_sizze_32880;
    
    int64_t segmap_usable_groups_32889 = sdiv_up64(niz2084U_28882, segmap_tblock_sizze_32888);
    
    if (memblock_alloc_device(ctx, &mem_33836, bytes_33835, "mem_33836")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_34020 = sext_i64_i32(sdiv_up64(niz2084U_28882, segmap_tblock_sizze_32888));
    
    {
        err = gpu_kernel_gather_payloads_intzisegmap_32892(ctx, segmap_usable_groups_32889, 1, 1, *ctx->tuning_params.gather_payloads_intzisegmap_tblock_sizze_32880, 1, 1, (int64_t) 0, niz2084U_28882, incr_28884, is_mem_33832.mem, mem_33836.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t zm_lhs_31848 = add64(dz2083U_28883, psizze_28885);
    int64_t zs_lhs_31849 = sub64(zm_lhs_31848, (int64_t) 1);
    int64_t m_31853 = sdiv64(zs_lhs_31849, psizze_28885);
    
    if (memblock_alloc_device(ctx, &mem_33838, bytes_33837, "mem_33838")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, mem_33838, niz2084U_28882, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    bool loop_cond_31855 = slt64((int64_t) 0, m_31853);
    int64_t segmap_tblock_sizze_32916;
    
    segmap_tblock_sizze_32916 = *ctx->tuning_params.gather_payloads_intzisegmap_tblock_sizze_32898;
    
    int64_t segmap_usable_groups_32917 = sdiv_up_safe64(niz2084U_28882, segmap_tblock_sizze_32916);
    bool partitioned_gather_res_31856;
    int64_t partitioned_gather_res_31859;
    bool loop_while_31860;
    int64_t p_31863;
    
    if (memblock_set_device(ctx, &mem_param_33841, &mem_33836, "mem_33836") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_33844, &mem_33838, "mem_33838") != 0)
        return 1;
    loop_while_31860 = loop_cond_31855;
    p_31863 = (int64_t) 0;
    while (loop_while_31860) {
        int64_t lower_bound_31864 = mul64(psizze_28885, p_31863);
        int64_t min_arg1_31865 = add64(psizze_28885, lower_bound_31864);
        int64_t min_res_31866 = smin64(dz2083U_28883, min_arg1_31865);
        int64_t j_m_i_31867 = sub64(min_res_31866, lower_bound_31864);
        bool empty_slice_31868 = j_m_i_31867 == (int64_t) 0;
        int64_t m_31869 = sub64(j_m_i_31867, (int64_t) 1);
        int64_t i_p_m_t_s_31870 = add64(lower_bound_31864, m_31869);
        bool zzero_leq_i_p_m_t_s_31871 = sle64((int64_t) 0, i_p_m_t_s_31870);
        bool i_p_m_t_s_leq_w_31872 = slt64(i_p_m_t_s_31870, dz2083U_28883);
        bool zzero_lte_i_31873 = sle64((int64_t) 0, lower_bound_31864);
        bool i_lte_j_31874 = sle64(lower_bound_31864, min_res_31866);
        bool y_31875 = i_p_m_t_s_leq_w_31872 && zzero_lte_i_31873;
        bool y_31876 = zzero_leq_i_p_m_t_s_31871 && y_31875;
        bool forwards_ok_31877 = i_lte_j_31874 && y_31876;
        bool ok_or_empty_31878 = empty_slice_31868 || forwards_ok_31877;
        bool index_certs_31879;
        
        if (!ok_or_empty_31878) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) lower_bound_31864, ":", (long long) min_res_31866, "] out of bounds for array of shape [", (long long) dz2083U_28883, "].", "-> #0  ftbasics.fut:31:18-45\n   #1  ftSMJ.fut:424:5-41\n   #2  ftSMJ.fut:423:1-424:41\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_33846, bytes_33835, "mem_33846")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33846.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_33841.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {niz2084U_28882})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_33849, bytes_33837, "mem_33849")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_34055 = sext_i64_i32(sdiv_up64(niz2084U_28882, segmap_tblock_sizze_32916));
        
        {
            err = gpu_kernel_gather_payloads_intzisegmap_32920(ctx, segmap_usable_groups_32917, 1, 1, *ctx->tuning_params.gather_payloads_intzisegmap_tblock_sizze_32898, 1, 1, (int64_t) 0, niz2084U_28882, lower_bound_31864, min_res_31866, j_m_i_31867, ys_mem_33833.mem, mem_param_33841.mem, mem_param_33844.mem, mem_33849.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t tmp_31894 = add64((int64_t) 1, p_31863);
        bool loop_cond_31895 = slt64(tmp_31894, m_31853);
        
        if (memblock_set_device(ctx, &mem_param_tmp_34049, &mem_33846, "mem_33846") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_34050, &mem_33849, "mem_33849") != 0)
            return 1;
        
        bool loop_while_tmp_34051 = loop_cond_31895;
        int64_t p_tmp_34054 = tmp_31894;
        
        if (memblock_set_device(ctx, &mem_param_33841, &mem_param_tmp_34049, "mem_param_tmp_34049") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_33844, &mem_param_tmp_34050, "mem_param_tmp_34050") != 0)
            return 1;
        loop_while_31860 = loop_while_tmp_34051;
        p_31863 = p_tmp_34054;
    }
    if (memblock_set_device(ctx, &ext_mem_33855, &mem_param_33841, "mem_param_33841") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_33854, &mem_param_33844, "mem_param_33844") != 0)
        return 1;
    partitioned_gather_res_31856 = loop_while_31860;
    partitioned_gather_res_31859 = p_31863;
    if (memblock_unref_device(ctx, &mem_33836, "mem_33836") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33838, "mem_33838") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_33857, bytes_33837, "mem_33857")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_33857.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_33854.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {niz2084U_28882})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_33854, "ext_mem_33854") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_34019, &mem_33857, "mem_33857") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_34517, &mem_out_34019, "mem_out_34019") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_33857, "mem_33857") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_34050, "mem_param_tmp_34050") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_34049, "mem_param_tmp_34049") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33849, "mem_33849") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33846, "mem_33846") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_33844, "mem_param_33844") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_33841, "mem_param_33841") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33854, "ext_mem_33854") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33855, "ext_mem_33855") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33838, "mem_33838") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33836, "mem_33836") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_34019, "mem_out_34019") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_int_GFUR(struct futhark_context *ctx, struct memblock_device *mem_out_p_34518, struct memblock_device preVals_mem_33832, struct memblock_device is_mem_33833, struct memblock_device ys_mem_33834, int64_t ni_30475, int64_t n_30476, int64_t incr_30477, int64_t psizze_30478)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_33856;
    
    mem_33856.references = NULL;
    
    struct memblock_device mem_param_tmp_34030;
    
    mem_param_tmp_34030.references = NULL;
    
    struct memblock_device mem_param_tmp_34029;
    
    mem_param_tmp_34029.references = NULL;
    
    struct memblock_device mem_33848;
    
    mem_33848.references = NULL;
    
    struct memblock_device mem_33845;
    
    mem_33845.references = NULL;
    
    struct memblock_device mem_param_33843;
    
    mem_param_33843.references = NULL;
    
    struct memblock_device mem_param_33840;
    
    mem_param_33840.references = NULL;
    
    struct memblock_device ext_mem_33853;
    
    ext_mem_33853.references = NULL;
    
    struct memblock_device ext_mem_33854;
    
    ext_mem_33854.references = NULL;
    
    struct memblock_device mem_33837;
    
    mem_33837.references = NULL;
    
    struct memblock_device mem_out_34019;
    
    mem_out_34019.references = NULL;
    
    struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
    struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
    struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
    int64_t bytes_33836 = (int64_t) 8 * ni_30475;
    bool zzero_31851 = psizze_30478 == (int64_t) 0;
    bool nonzzero_31852 = !zzero_31851;
    bool nonzzero_cert_31853;
    
    if (!nonzzero_31852) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftbasics.fut:43:22-28\n   #1  ftSMJ.fut:452:5-50\n   #2  ftSMJ.fut:451:1-452:50\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_33847 = (int64_t) 4 * ni_30475;
    int64_t segmap_tblock_sizze_33168;
    
    segmap_tblock_sizze_33168 = *ctx->tuning_params.gather_payloads_int_GFURzisegmap_tblock_sizze_33160;
    
    int64_t segmap_usable_groups_33169 = sdiv_up64(ni_30475, segmap_tblock_sizze_33168);
    
    if (memblock_alloc_device(ctx, &mem_33837, bytes_33836, "mem_33837")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_34020 = sext_i64_i32(sdiv_up64(ni_30475, segmap_tblock_sizze_33168));
    
    {
        err = gpu_kernel_gather_payloads_int_GFURzisegmap_33172(ctx, segmap_usable_groups_33169, 1, 1, *ctx->tuning_params.gather_payloads_int_GFURzisegmap_tblock_sizze_33160, 1, 1, (int64_t) 0, ni_30475, incr_30477, is_mem_33833.mem, mem_33837.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t zm_lhs_31849 = add64(n_30476, psizze_30478);
    int64_t zs_lhs_31850 = sub64(zm_lhs_31849, (int64_t) 1);
    int64_t m_31854 = sdiv64(zs_lhs_31850, psizze_30478);
    bool loop_cond_31855 = slt64((int64_t) 0, m_31854);
    int64_t segmap_tblock_sizze_33196;
    
    segmap_tblock_sizze_33196 = *ctx->tuning_params.gather_payloads_int_GFURzisegmap_tblock_sizze_33178;
    
    int64_t segmap_usable_groups_33197 = sdiv_up_safe64(ni_30475, segmap_tblock_sizze_33196);
    bool partitioned_gather_over_array_res_31856;
    int64_t partitioned_gather_over_array_res_31859;
    bool loop_while_31860;
    int64_t p_31863;
    
    if (memblock_set_device(ctx, &mem_param_33840, &mem_33837, "mem_33837") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_33843, &preVals_mem_33832, "preVals_mem_33832") != 0)
        return 1;
    loop_while_31860 = loop_cond_31855;
    p_31863 = (int64_t) 0;
    while (loop_while_31860) {
        int64_t lower_bound_31864 = mul64(psizze_30478, p_31863);
        int64_t min_arg1_31865 = add64(psizze_30478, lower_bound_31864);
        int64_t min_res_31866 = smin64(n_30476, min_arg1_31865);
        int64_t j_m_i_31867 = sub64(min_res_31866, lower_bound_31864);
        bool empty_slice_31868 = j_m_i_31867 == (int64_t) 0;
        int64_t m_31869 = sub64(j_m_i_31867, (int64_t) 1);
        int64_t i_p_m_t_s_31870 = add64(lower_bound_31864, m_31869);
        bool zzero_leq_i_p_m_t_s_31871 = sle64((int64_t) 0, i_p_m_t_s_31870);
        bool i_p_m_t_s_leq_w_31872 = slt64(i_p_m_t_s_31870, n_30476);
        bool zzero_lte_i_31873 = sle64((int64_t) 0, lower_bound_31864);
        bool i_lte_j_31874 = sle64(lower_bound_31864, min_res_31866);
        bool y_31875 = i_p_m_t_s_leq_w_31872 && zzero_lte_i_31873;
        bool y_31876 = zzero_leq_i_p_m_t_s_31871 && y_31875;
        bool forwards_ok_31877 = i_lte_j_31874 && y_31876;
        bool ok_or_empty_31878 = empty_slice_31868 || forwards_ok_31877;
        bool index_certs_31879;
        
        if (!ok_or_empty_31878) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) lower_bound_31864, ":", (long long) min_res_31866, "] out of bounds for array of shape [", (long long) n_30476, "].", "-> #0  ftbasics.fut:49:18-45\n   #1  ftSMJ.fut:452:5-50\n   #2  ftSMJ.fut:451:1-452:50\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_33845, bytes_33836, "mem_33845")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33845.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_33840.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {ni_30475})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_33848, bytes_33847, "mem_33848")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_34035 = sext_i64_i32(sdiv_up64(ni_30475, segmap_tblock_sizze_33196));
        
        {
            err = gpu_kernel_gather_payloads_int_GFURzisegmap_33200(ctx, segmap_usable_groups_33197, 1, 1, *ctx->tuning_params.gather_payloads_int_GFURzisegmap_tblock_sizze_33178, 1, 1, (int64_t) 0, ni_30475, lower_bound_31864, min_res_31866, j_m_i_31867, ys_mem_33834.mem, mem_param_33840.mem, mem_param_33843.mem, mem_33848.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t tmp_31894 = add64((int64_t) 1, p_31863);
        bool loop_cond_31895 = slt64(tmp_31894, m_31854);
        
        if (memblock_set_device(ctx, &mem_param_tmp_34029, &mem_33845, "mem_33845") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_34030, &mem_33848, "mem_33848") != 0)
            return 1;
        
        bool loop_while_tmp_34031 = loop_cond_31895;
        int64_t p_tmp_34034 = tmp_31894;
        
        if (memblock_set_device(ctx, &mem_param_33840, &mem_param_tmp_34029, "mem_param_tmp_34029") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_33843, &mem_param_tmp_34030, "mem_param_tmp_34030") != 0)
            return 1;
        loop_while_31860 = loop_while_tmp_34031;
        p_31863 = p_tmp_34034;
    }
    if (memblock_set_device(ctx, &ext_mem_33854, &mem_param_33840, "mem_param_33840") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_33853, &mem_param_33843, "mem_param_33843") != 0)
        return 1;
    partitioned_gather_over_array_res_31856 = loop_while_31860;
    partitioned_gather_over_array_res_31859 = p_31863;
    if (memblock_unref_device(ctx, &mem_33837, "mem_33837") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_33856, bytes_33847, "mem_33856")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_33856.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_33853.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {ni_30475})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_33853, "ext_mem_33853") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_34019, &mem_33856, "mem_33856") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_34518, &mem_out_34019, "mem_out_34019") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_33856, "mem_33856") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_34030, "mem_param_tmp_34030") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_34029, "mem_param_tmp_34029") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33848, "mem_33848") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33845, "mem_33845") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_33843, "mem_param_33843") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_33840, "mem_param_33840") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33853, "ext_mem_33853") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33854, "ext_mem_33854") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33837, "mem_33837") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_34019, "mem_out_34019") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_long(struct futhark_context *ctx, struct memblock_device *mem_out_p_34519, struct memblock_device is_mem_33832, struct memblock_device ys_mem_33833, int64_t niz2084U_29191, int64_t dz2083U_29192, int64_t incr_29193, int64_t psizze_29194)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_33857;
    
    mem_33857.references = NULL;
    
    struct memblock_device mem_param_tmp_34050;
    
    mem_param_tmp_34050.references = NULL;
    
    struct memblock_device mem_param_tmp_34049;
    
    mem_param_tmp_34049.references = NULL;
    
    struct memblock_device mem_33849;
    
    mem_33849.references = NULL;
    
    struct memblock_device mem_33846;
    
    mem_33846.references = NULL;
    
    struct memblock_device mem_param_33844;
    
    mem_param_33844.references = NULL;
    
    struct memblock_device mem_param_33841;
    
    mem_param_33841.references = NULL;
    
    struct memblock_device ext_mem_33854;
    
    ext_mem_33854.references = NULL;
    
    struct memblock_device ext_mem_33855;
    
    ext_mem_33855.references = NULL;
    
    struct memblock_device mem_33838;
    
    mem_33838.references = NULL;
    
    struct memblock_device mem_33836;
    
    mem_33836.references = NULL;
    
    struct memblock_device mem_out_34019;
    
    mem_out_34019.references = NULL;
    
    struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
    struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
    struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
    int64_t bytes_33835 = (int64_t) 8 * niz2084U_29191;
    bool zzero_31850 = psizze_29194 == (int64_t) 0;
    bool nonzzero_31851 = !zzero_31850;
    bool nonzzero_cert_31852;
    
    if (!nonzzero_31851) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftbasics.fut:24:22-28\n   #1  ftSMJ.fut:427:5-41\n   #2  ftSMJ.fut:426:1-427:41\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t segmap_tblock_sizze_32944;
    
    segmap_tblock_sizze_32944 = *ctx->tuning_params.gather_payloads_longzisegmap_tblock_sizze_32936;
    
    int64_t segmap_usable_groups_32945 = sdiv_up64(niz2084U_29191, segmap_tblock_sizze_32944);
    
    if (memblock_alloc_device(ctx, &mem_33836, bytes_33835, "mem_33836")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_34020 = sext_i64_i32(sdiv_up64(niz2084U_29191, segmap_tblock_sizze_32944));
    
    {
        err = gpu_kernel_gather_payloads_longzisegmap_32948(ctx, segmap_usable_groups_32945, 1, 1, *ctx->tuning_params.gather_payloads_longzisegmap_tblock_sizze_32936, 1, 1, (int64_t) 0, niz2084U_29191, incr_29193, is_mem_33832.mem, mem_33836.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t zm_lhs_31848 = add64(dz2083U_29192, psizze_29194);
    int64_t zs_lhs_31849 = sub64(zm_lhs_31848, (int64_t) 1);
    int64_t m_31853 = sdiv64(zs_lhs_31849, psizze_29194);
    
    if (memblock_alloc_device(ctx, &mem_33838, bytes_33835, "mem_33838")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_33838, niz2084U_29191, (int64_t) 0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    bool loop_cond_31855 = slt64((int64_t) 0, m_31853);
    int64_t segmap_tblock_sizze_32972;
    
    segmap_tblock_sizze_32972 = *ctx->tuning_params.gather_payloads_longzisegmap_tblock_sizze_32954;
    
    int64_t segmap_usable_groups_32973 = sdiv_up_safe64(niz2084U_29191, segmap_tblock_sizze_32972);
    bool partitioned_gather_res_31856;
    int64_t partitioned_gather_res_31859;
    bool loop_while_31860;
    int64_t p_31863;
    
    if (memblock_set_device(ctx, &mem_param_33841, &mem_33836, "mem_33836") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_33844, &mem_33838, "mem_33838") != 0)
        return 1;
    loop_while_31860 = loop_cond_31855;
    p_31863 = (int64_t) 0;
    while (loop_while_31860) {
        int64_t lower_bound_31864 = mul64(psizze_29194, p_31863);
        int64_t min_arg1_31865 = add64(psizze_29194, lower_bound_31864);
        int64_t min_res_31866 = smin64(dz2083U_29192, min_arg1_31865);
        int64_t j_m_i_31867 = sub64(min_res_31866, lower_bound_31864);
        bool empty_slice_31868 = j_m_i_31867 == (int64_t) 0;
        int64_t m_31869 = sub64(j_m_i_31867, (int64_t) 1);
        int64_t i_p_m_t_s_31870 = add64(lower_bound_31864, m_31869);
        bool zzero_leq_i_p_m_t_s_31871 = sle64((int64_t) 0, i_p_m_t_s_31870);
        bool i_p_m_t_s_leq_w_31872 = slt64(i_p_m_t_s_31870, dz2083U_29192);
        bool zzero_lte_i_31873 = sle64((int64_t) 0, lower_bound_31864);
        bool i_lte_j_31874 = sle64(lower_bound_31864, min_res_31866);
        bool y_31875 = i_p_m_t_s_leq_w_31872 && zzero_lte_i_31873;
        bool y_31876 = zzero_leq_i_p_m_t_s_31871 && y_31875;
        bool forwards_ok_31877 = i_lte_j_31874 && y_31876;
        bool ok_or_empty_31878 = empty_slice_31868 || forwards_ok_31877;
        bool index_certs_31879;
        
        if (!ok_or_empty_31878) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) lower_bound_31864, ":", (long long) min_res_31866, "] out of bounds for array of shape [", (long long) dz2083U_29192, "].", "-> #0  ftbasics.fut:31:18-45\n   #1  ftSMJ.fut:427:5-41\n   #2  ftSMJ.fut:426:1-427:41\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_33846, bytes_33835, "mem_33846")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33846.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_33841.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {niz2084U_29191})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_33849, bytes_33835, "mem_33849")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_34055 = sext_i64_i32(sdiv_up64(niz2084U_29191, segmap_tblock_sizze_32972));
        
        {
            err = gpu_kernel_gather_payloads_longzisegmap_32976(ctx, segmap_usable_groups_32973, 1, 1, *ctx->tuning_params.gather_payloads_longzisegmap_tblock_sizze_32954, 1, 1, (int64_t) 0, niz2084U_29191, lower_bound_31864, min_res_31866, j_m_i_31867, ys_mem_33833.mem, mem_param_33841.mem, mem_param_33844.mem, mem_33849.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t tmp_31894 = add64((int64_t) 1, p_31863);
        bool loop_cond_31895 = slt64(tmp_31894, m_31853);
        
        if (memblock_set_device(ctx, &mem_param_tmp_34049, &mem_33846, "mem_33846") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_34050, &mem_33849, "mem_33849") != 0)
            return 1;
        
        bool loop_while_tmp_34051 = loop_cond_31895;
        int64_t p_tmp_34054 = tmp_31894;
        
        if (memblock_set_device(ctx, &mem_param_33841, &mem_param_tmp_34049, "mem_param_tmp_34049") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_33844, &mem_param_tmp_34050, "mem_param_tmp_34050") != 0)
            return 1;
        loop_while_31860 = loop_while_tmp_34051;
        p_31863 = p_tmp_34054;
    }
    if (memblock_set_device(ctx, &ext_mem_33855, &mem_param_33841, "mem_param_33841") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_33854, &mem_param_33844, "mem_param_33844") != 0)
        return 1;
    partitioned_gather_res_31856 = loop_while_31860;
    partitioned_gather_res_31859 = p_31863;
    if (memblock_unref_device(ctx, &mem_33836, "mem_33836") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33838, "mem_33838") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_33857, bytes_33835, "mem_33857")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33857.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_33854.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {niz2084U_29191})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_33854, "ext_mem_33854") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_34019, &mem_33857, "mem_33857") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_34519, &mem_out_34019, "mem_out_34019") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_33857, "mem_33857") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_34050, "mem_param_tmp_34050") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_34049, "mem_param_tmp_34049") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33849, "mem_33849") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33846, "mem_33846") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_33844, "mem_param_33844") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_33841, "mem_param_33841") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33854, "ext_mem_33854") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33855, "ext_mem_33855") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33838, "mem_33838") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33836, "mem_33836") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_34019, "mem_out_34019") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_long_GFUR(struct futhark_context *ctx, struct memblock_device *mem_out_p_34520, struct memblock_device preVals_mem_33832, struct memblock_device is_mem_33833, struct memblock_device ys_mem_33834, int64_t ni_30776, int64_t n_30777, int64_t incr_30778, int64_t psizze_30779)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_33856;
    
    mem_33856.references = NULL;
    
    struct memblock_device mem_param_tmp_34030;
    
    mem_param_tmp_34030.references = NULL;
    
    struct memblock_device mem_param_tmp_34029;
    
    mem_param_tmp_34029.references = NULL;
    
    struct memblock_device mem_33848;
    
    mem_33848.references = NULL;
    
    struct memblock_device mem_33845;
    
    mem_33845.references = NULL;
    
    struct memblock_device mem_param_33843;
    
    mem_param_33843.references = NULL;
    
    struct memblock_device mem_param_33840;
    
    mem_param_33840.references = NULL;
    
    struct memblock_device ext_mem_33853;
    
    ext_mem_33853.references = NULL;
    
    struct memblock_device ext_mem_33854;
    
    ext_mem_33854.references = NULL;
    
    struct memblock_device mem_33837;
    
    mem_33837.references = NULL;
    
    struct memblock_device mem_out_34019;
    
    mem_out_34019.references = NULL;
    
    struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
    struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
    struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
    int64_t bytes_33836 = (int64_t) 8 * ni_30776;
    bool zzero_31851 = psizze_30779 == (int64_t) 0;
    bool nonzzero_31852 = !zzero_31851;
    bool nonzzero_cert_31853;
    
    if (!nonzzero_31852) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftbasics.fut:43:22-28\n   #1  ftSMJ.fut:455:5-50\n   #2  ftSMJ.fut:454:1-455:50\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t segmap_tblock_sizze_33224;
    
    segmap_tblock_sizze_33224 = *ctx->tuning_params.gather_payloads_long_GFURzisegmap_tblock_sizze_33216;
    
    int64_t segmap_usable_groups_33225 = sdiv_up64(ni_30776, segmap_tblock_sizze_33224);
    
    if (memblock_alloc_device(ctx, &mem_33837, bytes_33836, "mem_33837")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_34020 = sext_i64_i32(sdiv_up64(ni_30776, segmap_tblock_sizze_33224));
    
    {
        err = gpu_kernel_gather_payloads_long_GFURzisegmap_33228(ctx, segmap_usable_groups_33225, 1, 1, *ctx->tuning_params.gather_payloads_long_GFURzisegmap_tblock_sizze_33216, 1, 1, (int64_t) 0, ni_30776, incr_30778, is_mem_33833.mem, mem_33837.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t zm_lhs_31849 = add64(n_30777, psizze_30779);
    int64_t zs_lhs_31850 = sub64(zm_lhs_31849, (int64_t) 1);
    int64_t m_31854 = sdiv64(zs_lhs_31850, psizze_30779);
    bool loop_cond_31855 = slt64((int64_t) 0, m_31854);
    int64_t segmap_tblock_sizze_33252;
    
    segmap_tblock_sizze_33252 = *ctx->tuning_params.gather_payloads_long_GFURzisegmap_tblock_sizze_33234;
    
    int64_t segmap_usable_groups_33253 = sdiv_up_safe64(ni_30776, segmap_tblock_sizze_33252);
    bool partitioned_gather_over_array_res_31856;
    int64_t partitioned_gather_over_array_res_31859;
    bool loop_while_31860;
    int64_t p_31863;
    
    if (memblock_set_device(ctx, &mem_param_33840, &mem_33837, "mem_33837") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_33843, &preVals_mem_33832, "preVals_mem_33832") != 0)
        return 1;
    loop_while_31860 = loop_cond_31855;
    p_31863 = (int64_t) 0;
    while (loop_while_31860) {
        int64_t lower_bound_31864 = mul64(psizze_30779, p_31863);
        int64_t min_arg1_31865 = add64(psizze_30779, lower_bound_31864);
        int64_t min_res_31866 = smin64(n_30777, min_arg1_31865);
        int64_t j_m_i_31867 = sub64(min_res_31866, lower_bound_31864);
        bool empty_slice_31868 = j_m_i_31867 == (int64_t) 0;
        int64_t m_31869 = sub64(j_m_i_31867, (int64_t) 1);
        int64_t i_p_m_t_s_31870 = add64(lower_bound_31864, m_31869);
        bool zzero_leq_i_p_m_t_s_31871 = sle64((int64_t) 0, i_p_m_t_s_31870);
        bool i_p_m_t_s_leq_w_31872 = slt64(i_p_m_t_s_31870, n_30777);
        bool zzero_lte_i_31873 = sle64((int64_t) 0, lower_bound_31864);
        bool i_lte_j_31874 = sle64(lower_bound_31864, min_res_31866);
        bool y_31875 = i_p_m_t_s_leq_w_31872 && zzero_lte_i_31873;
        bool y_31876 = zzero_leq_i_p_m_t_s_31871 && y_31875;
        bool forwards_ok_31877 = i_lte_j_31874 && y_31876;
        bool ok_or_empty_31878 = empty_slice_31868 || forwards_ok_31877;
        bool index_certs_31879;
        
        if (!ok_or_empty_31878) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) lower_bound_31864, ":", (long long) min_res_31866, "] out of bounds for array of shape [", (long long) n_30777, "].", "-> #0  ftbasics.fut:49:18-45\n   #1  ftSMJ.fut:455:5-50\n   #2  ftSMJ.fut:454:1-455:50\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_33845, bytes_33836, "mem_33845")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33845.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_33840.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {ni_30776})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_33848, bytes_33836, "mem_33848")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_34035 = sext_i64_i32(sdiv_up64(ni_30776, segmap_tblock_sizze_33252));
        
        {
            err = gpu_kernel_gather_payloads_long_GFURzisegmap_33256(ctx, segmap_usable_groups_33253, 1, 1, *ctx->tuning_params.gather_payloads_long_GFURzisegmap_tblock_sizze_33234, 1, 1, (int64_t) 0, ni_30776, lower_bound_31864, min_res_31866, j_m_i_31867, ys_mem_33834.mem, mem_param_33840.mem, mem_param_33843.mem, mem_33848.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t tmp_31894 = add64((int64_t) 1, p_31863);
        bool loop_cond_31895 = slt64(tmp_31894, m_31854);
        
        if (memblock_set_device(ctx, &mem_param_tmp_34029, &mem_33845, "mem_33845") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_34030, &mem_33848, "mem_33848") != 0)
            return 1;
        
        bool loop_while_tmp_34031 = loop_cond_31895;
        int64_t p_tmp_34034 = tmp_31894;
        
        if (memblock_set_device(ctx, &mem_param_33840, &mem_param_tmp_34029, "mem_param_tmp_34029") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_33843, &mem_param_tmp_34030, "mem_param_tmp_34030") != 0)
            return 1;
        loop_while_31860 = loop_while_tmp_34031;
        p_31863 = p_tmp_34034;
    }
    if (memblock_set_device(ctx, &ext_mem_33854, &mem_param_33840, "mem_param_33840") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_33853, &mem_param_33843, "mem_param_33843") != 0)
        return 1;
    partitioned_gather_over_array_res_31856 = loop_while_31860;
    partitioned_gather_over_array_res_31859 = p_31863;
    if (memblock_unref_device(ctx, &mem_33837, "mem_33837") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_33856, bytes_33836, "mem_33856")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33856.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_33853.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {ni_30776})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_33853, "ext_mem_33853") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_34019, &mem_33856, "mem_33856") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_34520, &mem_out_34019, "mem_out_34019") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_33856, "mem_33856") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_34030, "mem_param_tmp_34030") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_34029, "mem_param_tmp_34029") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33848, "mem_33848") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33845, "mem_33845") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_33843, "mem_param_33843") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_33840, "mem_param_33840") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33853, "ext_mem_33853") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33854, "ext_mem_33854") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33837, "mem_33837") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_34019, "mem_out_34019") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_short(struct futhark_context *ctx, struct memblock_device *mem_out_p_34521, struct memblock_device is_mem_33832, struct memblock_device ys_mem_33833, int64_t niz2084U_28542, int64_t dz2083U_28543, int64_t incr_28544, int64_t psizze_28545)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_33857;
    
    mem_33857.references = NULL;
    
    struct memblock_device mem_param_tmp_34050;
    
    mem_param_tmp_34050.references = NULL;
    
    struct memblock_device mem_param_tmp_34049;
    
    mem_param_tmp_34049.references = NULL;
    
    struct memblock_device mem_33849;
    
    mem_33849.references = NULL;
    
    struct memblock_device mem_33846;
    
    mem_33846.references = NULL;
    
    struct memblock_device mem_param_33844;
    
    mem_param_33844.references = NULL;
    
    struct memblock_device mem_param_33841;
    
    mem_param_33841.references = NULL;
    
    struct memblock_device ext_mem_33854;
    
    ext_mem_33854.references = NULL;
    
    struct memblock_device ext_mem_33855;
    
    ext_mem_33855.references = NULL;
    
    struct memblock_device mem_33838;
    
    mem_33838.references = NULL;
    
    struct memblock_device mem_33836;
    
    mem_33836.references = NULL;
    
    struct memblock_device mem_out_34019;
    
    mem_out_34019.references = NULL;
    
    struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
    struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
    struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
    int64_t bytes_33835 = (int64_t) 8 * niz2084U_28542;
    bool zzero_31850 = psizze_28545 == (int64_t) 0;
    bool nonzzero_31851 = !zzero_31850;
    bool nonzzero_cert_31852;
    
    if (!nonzzero_31851) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftbasics.fut:24:22-28\n   #1  ftSMJ.fut:421:5-41\n   #2  ftSMJ.fut:420:1-421:41\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_33837 = (int64_t) 2 * niz2084U_28542;
    int64_t segmap_tblock_sizze_32832;
    
    segmap_tblock_sizze_32832 = *ctx->tuning_params.gather_payloads_shortzisegmap_tblock_sizze_32824;
    
    int64_t segmap_usable_groups_32833 = sdiv_up64(niz2084U_28542, segmap_tblock_sizze_32832);
    
    if (memblock_alloc_device(ctx, &mem_33836, bytes_33835, "mem_33836")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_34020 = sext_i64_i32(sdiv_up64(niz2084U_28542, segmap_tblock_sizze_32832));
    
    {
        err = gpu_kernel_gather_payloads_shortzisegmap_32836(ctx, segmap_usable_groups_32833, 1, 1, *ctx->tuning_params.gather_payloads_shortzisegmap_tblock_sizze_32824, 1, 1, (int64_t) 0, niz2084U_28542, incr_28544, is_mem_33832.mem, mem_33836.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t zm_lhs_31848 = add64(dz2083U_28543, psizze_28545);
    int64_t zs_lhs_31849 = sub64(zm_lhs_31848, (int64_t) 1);
    int64_t m_31853 = sdiv64(zs_lhs_31849, psizze_28545);
    
    if (memblock_alloc_device(ctx, &mem_33838, bytes_33837, "mem_33838")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i16(ctx, mem_33838, niz2084U_28542, (int16_t) 0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    bool loop_cond_31855 = slt64((int64_t) 0, m_31853);
    int64_t segmap_tblock_sizze_32860;
    
    segmap_tblock_sizze_32860 = *ctx->tuning_params.gather_payloads_shortzisegmap_tblock_sizze_32842;
    
    int64_t segmap_usable_groups_32861 = sdiv_up_safe64(niz2084U_28542, segmap_tblock_sizze_32860);
    bool partitioned_gather_res_31856;
    int64_t partitioned_gather_res_31859;
    bool loop_while_31860;
    int64_t p_31863;
    
    if (memblock_set_device(ctx, &mem_param_33841, &mem_33836, "mem_33836") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_33844, &mem_33838, "mem_33838") != 0)
        return 1;
    loop_while_31860 = loop_cond_31855;
    p_31863 = (int64_t) 0;
    while (loop_while_31860) {
        int64_t lower_bound_31864 = mul64(psizze_28545, p_31863);
        int64_t min_arg1_31865 = add64(psizze_28545, lower_bound_31864);
        int64_t min_res_31866 = smin64(dz2083U_28543, min_arg1_31865);
        int64_t j_m_i_31867 = sub64(min_res_31866, lower_bound_31864);
        bool empty_slice_31868 = j_m_i_31867 == (int64_t) 0;
        int64_t m_31869 = sub64(j_m_i_31867, (int64_t) 1);
        int64_t i_p_m_t_s_31870 = add64(lower_bound_31864, m_31869);
        bool zzero_leq_i_p_m_t_s_31871 = sle64((int64_t) 0, i_p_m_t_s_31870);
        bool i_p_m_t_s_leq_w_31872 = slt64(i_p_m_t_s_31870, dz2083U_28543);
        bool zzero_lte_i_31873 = sle64((int64_t) 0, lower_bound_31864);
        bool i_lte_j_31874 = sle64(lower_bound_31864, min_res_31866);
        bool y_31875 = i_p_m_t_s_leq_w_31872 && zzero_lte_i_31873;
        bool y_31876 = zzero_leq_i_p_m_t_s_31871 && y_31875;
        bool forwards_ok_31877 = i_lte_j_31874 && y_31876;
        bool ok_or_empty_31878 = empty_slice_31868 || forwards_ok_31877;
        bool index_certs_31879;
        
        if (!ok_or_empty_31878) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) lower_bound_31864, ":", (long long) min_res_31866, "] out of bounds for array of shape [", (long long) dz2083U_28543, "].", "-> #0  ftbasics.fut:31:18-45\n   #1  ftSMJ.fut:421:5-41\n   #2  ftSMJ.fut:420:1-421:41\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_33846, bytes_33835, "mem_33846")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33846.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_33841.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {niz2084U_28542})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_33849, bytes_33837, "mem_33849")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_34055 = sext_i64_i32(sdiv_up64(niz2084U_28542, segmap_tblock_sizze_32860));
        
        {
            err = gpu_kernel_gather_payloads_shortzisegmap_32864(ctx, segmap_usable_groups_32861, 1, 1, *ctx->tuning_params.gather_payloads_shortzisegmap_tblock_sizze_32842, 1, 1, (int64_t) 0, niz2084U_28542, lower_bound_31864, min_res_31866, j_m_i_31867, ys_mem_33833.mem, mem_param_33841.mem, mem_param_33844.mem, mem_33849.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t tmp_31894 = add64((int64_t) 1, p_31863);
        bool loop_cond_31895 = slt64(tmp_31894, m_31853);
        
        if (memblock_set_device(ctx, &mem_param_tmp_34049, &mem_33846, "mem_33846") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_34050, &mem_33849, "mem_33849") != 0)
            return 1;
        
        bool loop_while_tmp_34051 = loop_cond_31895;
        int64_t p_tmp_34054 = tmp_31894;
        
        if (memblock_set_device(ctx, &mem_param_33841, &mem_param_tmp_34049, "mem_param_tmp_34049") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_33844, &mem_param_tmp_34050, "mem_param_tmp_34050") != 0)
            return 1;
        loop_while_31860 = loop_while_tmp_34051;
        p_31863 = p_tmp_34054;
    }
    if (memblock_set_device(ctx, &ext_mem_33855, &mem_param_33841, "mem_param_33841") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_33854, &mem_param_33844, "mem_param_33844") != 0)
        return 1;
    partitioned_gather_res_31856 = loop_while_31860;
    partitioned_gather_res_31859 = p_31863;
    if (memblock_unref_device(ctx, &mem_33836, "mem_33836") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33838, "mem_33838") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_33857, bytes_33837, "mem_33857")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_2b(ctx, 1, mem_33857.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_33854.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {niz2084U_28542})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_33854, "ext_mem_33854") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_34019, &mem_33857, "mem_33857") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_34521, &mem_out_34019, "mem_out_34019") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_33857, "mem_33857") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_34050, "mem_param_tmp_34050") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_34049, "mem_param_tmp_34049") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33849, "mem_33849") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33846, "mem_33846") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_33844, "mem_param_33844") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_33841, "mem_param_33841") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33854, "ext_mem_33854") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33855, "ext_mem_33855") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33838, "mem_33838") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33836, "mem_33836") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_34019, "mem_out_34019") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_gather_payloads_short_GFUR(struct futhark_context *ctx, struct memblock_device *mem_out_p_34522, struct memblock_device preVals_mem_33832, struct memblock_device is_mem_33833, struct memblock_device ys_mem_33834, int64_t ni_30174, int64_t n_30175, int64_t incr_30176, int64_t psizze_30177)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_33856;
    
    mem_33856.references = NULL;
    
    struct memblock_device mem_param_tmp_34030;
    
    mem_param_tmp_34030.references = NULL;
    
    struct memblock_device mem_param_tmp_34029;
    
    mem_param_tmp_34029.references = NULL;
    
    struct memblock_device mem_33848;
    
    mem_33848.references = NULL;
    
    struct memblock_device mem_33845;
    
    mem_33845.references = NULL;
    
    struct memblock_device mem_param_33843;
    
    mem_param_33843.references = NULL;
    
    struct memblock_device mem_param_33840;
    
    mem_param_33840.references = NULL;
    
    struct memblock_device ext_mem_33853;
    
    ext_mem_33853.references = NULL;
    
    struct memblock_device ext_mem_33854;
    
    ext_mem_33854.references = NULL;
    
    struct memblock_device mem_33837;
    
    mem_33837.references = NULL;
    
    struct memblock_device mem_out_34019;
    
    mem_out_34019.references = NULL;
    
    struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
    struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
    struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
    int64_t bytes_33836 = (int64_t) 8 * ni_30174;
    bool zzero_31851 = psizze_30177 == (int64_t) 0;
    bool nonzzero_31852 = !zzero_31851;
    bool nonzzero_cert_31853;
    
    if (!nonzzero_31852) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftbasics.fut:43:22-28\n   #1  ftSMJ.fut:449:5-50\n   #2  ftSMJ.fut:448:1-449:50\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_33847 = (int64_t) 2 * ni_30174;
    int64_t segmap_tblock_sizze_33112;
    
    segmap_tblock_sizze_33112 = *ctx->tuning_params.gather_payloads_short_GFURzisegmap_tblock_sizze_33104;
    
    int64_t segmap_usable_groups_33113 = sdiv_up64(ni_30174, segmap_tblock_sizze_33112);
    
    if (memblock_alloc_device(ctx, &mem_33837, bytes_33836, "mem_33837")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_34020 = sext_i64_i32(sdiv_up64(ni_30174, segmap_tblock_sizze_33112));
    
    {
        err = gpu_kernel_gather_payloads_short_GFURzisegmap_33116(ctx, segmap_usable_groups_33113, 1, 1, *ctx->tuning_params.gather_payloads_short_GFURzisegmap_tblock_sizze_33104, 1, 1, (int64_t) 0, ni_30174, incr_30176, is_mem_33833.mem, mem_33837.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t zm_lhs_31849 = add64(n_30175, psizze_30177);
    int64_t zs_lhs_31850 = sub64(zm_lhs_31849, (int64_t) 1);
    int64_t m_31854 = sdiv64(zs_lhs_31850, psizze_30177);
    bool loop_cond_31855 = slt64((int64_t) 0, m_31854);
    int64_t segmap_tblock_sizze_33140;
    
    segmap_tblock_sizze_33140 = *ctx->tuning_params.gather_payloads_short_GFURzisegmap_tblock_sizze_33122;
    
    int64_t segmap_usable_groups_33141 = sdiv_up_safe64(ni_30174, segmap_tblock_sizze_33140);
    bool partitioned_gather_over_array_res_31856;
    int64_t partitioned_gather_over_array_res_31859;
    bool loop_while_31860;
    int64_t p_31863;
    
    if (memblock_set_device(ctx, &mem_param_33840, &mem_33837, "mem_33837") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_33843, &preVals_mem_33832, "preVals_mem_33832") != 0)
        return 1;
    loop_while_31860 = loop_cond_31855;
    p_31863 = (int64_t) 0;
    while (loop_while_31860) {
        int64_t lower_bound_31864 = mul64(psizze_30177, p_31863);
        int64_t min_arg1_31865 = add64(psizze_30177, lower_bound_31864);
        int64_t min_res_31866 = smin64(n_30175, min_arg1_31865);
        int64_t j_m_i_31867 = sub64(min_res_31866, lower_bound_31864);
        bool empty_slice_31868 = j_m_i_31867 == (int64_t) 0;
        int64_t m_31869 = sub64(j_m_i_31867, (int64_t) 1);
        int64_t i_p_m_t_s_31870 = add64(lower_bound_31864, m_31869);
        bool zzero_leq_i_p_m_t_s_31871 = sle64((int64_t) 0, i_p_m_t_s_31870);
        bool i_p_m_t_s_leq_w_31872 = slt64(i_p_m_t_s_31870, n_30175);
        bool zzero_lte_i_31873 = sle64((int64_t) 0, lower_bound_31864);
        bool i_lte_j_31874 = sle64(lower_bound_31864, min_res_31866);
        bool y_31875 = i_p_m_t_s_leq_w_31872 && zzero_lte_i_31873;
        bool y_31876 = zzero_leq_i_p_m_t_s_31871 && y_31875;
        bool forwards_ok_31877 = i_lte_j_31874 && y_31876;
        bool ok_or_empty_31878 = empty_slice_31868 || forwards_ok_31877;
        bool index_certs_31879;
        
        if (!ok_or_empty_31878) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) lower_bound_31864, ":", (long long) min_res_31866, "] out of bounds for array of shape [", (long long) n_30175, "].", "-> #0  ftbasics.fut:49:18-45\n   #1  ftSMJ.fut:449:5-50\n   #2  ftSMJ.fut:448:1-449:50\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_33845, bytes_33836, "mem_33845")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33845.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_33840.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {ni_30174})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_33848, bytes_33847, "mem_33848")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_34035 = sext_i64_i32(sdiv_up64(ni_30174, segmap_tblock_sizze_33140));
        
        {
            err = gpu_kernel_gather_payloads_short_GFURzisegmap_33144(ctx, segmap_usable_groups_33141, 1, 1, *ctx->tuning_params.gather_payloads_short_GFURzisegmap_tblock_sizze_33122, 1, 1, (int64_t) 0, ni_30174, lower_bound_31864, min_res_31866, j_m_i_31867, ys_mem_33834.mem, mem_param_33840.mem, mem_param_33843.mem, mem_33848.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t tmp_31894 = add64((int64_t) 1, p_31863);
        bool loop_cond_31895 = slt64(tmp_31894, m_31854);
        
        if (memblock_set_device(ctx, &mem_param_tmp_34029, &mem_33845, "mem_33845") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_34030, &mem_33848, "mem_33848") != 0)
            return 1;
        
        bool loop_while_tmp_34031 = loop_cond_31895;
        int64_t p_tmp_34034 = tmp_31894;
        
        if (memblock_set_device(ctx, &mem_param_33840, &mem_param_tmp_34029, "mem_param_tmp_34029") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_33843, &mem_param_tmp_34030, "mem_param_tmp_34030") != 0)
            return 1;
        loop_while_31860 = loop_while_tmp_34031;
        p_31863 = p_tmp_34034;
    }
    if (memblock_set_device(ctx, &ext_mem_33854, &mem_param_33840, "mem_param_33840") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_33853, &mem_param_33843, "mem_param_33843") != 0)
        return 1;
    partitioned_gather_over_array_res_31856 = loop_while_31860;
    partitioned_gather_over_array_res_31859 = p_31863;
    if (memblock_unref_device(ctx, &mem_33837, "mem_33837") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_33856, bytes_33847, "mem_33856")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_2b(ctx, 1, mem_33856.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_33853.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {ni_30174})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_33853, "ext_mem_33853") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_34019, &mem_33856, "mem_33856") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_34522, &mem_out_34019, "mem_out_34019") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_33856, "mem_33856") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_34030, "mem_param_tmp_34030") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_34029, "mem_param_tmp_34029") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33848, "mem_33848") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33845, "mem_33845") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_33843, "mem_param_33843") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_33840, "mem_param_33840") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33853, "ext_mem_33853") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33854, "ext_mem_33854") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33837, "mem_33837") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_34019, "mem_out_34019") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_inner_SMJ_double(struct futhark_context *ctx, struct memblock_device *mem_out_p_34523, struct memblock_device *mem_out_p_34524, struct memblock_device *mem_out_p_34525, int64_t *out_prim_out_34526, struct memblock_device tR_mem_33832, struct memblock_device tS_mem_33833, int64_t nR_28192, int64_t nS_28193, int64_t offset_R_28196, int64_t offset_S_28197, int64_t partitionsPerWindow_28198, int64_t numberOfWindows_28199, int64_t extParallelism_28200, int64_t scatter_psizze_28201)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_33938;
    
    mem_33938.references = NULL;
    
    struct memblock_device mem_33936;
    
    mem_33936.references = NULL;
    
    struct memblock_device mem_33934;
    
    mem_33934.references = NULL;
    
    struct memblock_device mem_param_tmp_34452;
    
    mem_param_tmp_34452.references = NULL;
    
    struct memblock_device mem_param_tmp_34451;
    
    mem_param_tmp_34451.references = NULL;
    
    struct memblock_device mem_param_tmp_34450;
    
    mem_param_tmp_34450.references = NULL;
    
    struct memblock_device mem_33920;
    
    mem_33920.references = NULL;
    
    struct memblock_device mem_33918;
    
    mem_33918.references = NULL;
    
    struct memblock_device mem_33913;
    
    mem_33913.references = NULL;
    
    struct memblock_device mem_33911;
    
    mem_33911.references = NULL;
    
    struct memblock_device mem_33909;
    
    mem_33909.references = NULL;
    
    struct memblock_device mem_param_33907;
    
    mem_param_33907.references = NULL;
    
    struct memblock_device mem_param_33904;
    
    mem_param_33904.references = NULL;
    
    struct memblock_device mem_param_33901;
    
    mem_param_33901.references = NULL;
    
    struct memblock_device ext_mem_33930;
    
    ext_mem_33930.references = NULL;
    
    struct memblock_device ext_mem_33931;
    
    ext_mem_33931.references = NULL;
    
    struct memblock_device ext_mem_33932;
    
    ext_mem_33932.references = NULL;
    
    struct memblock_device mem_33916;
    
    mem_33916.references = NULL;
    
    struct memblock_device mem_33915;
    
    mem_33915.references = NULL;
    
    struct memblock_device mem_33914;
    
    mem_33914.references = NULL;
    
    struct memblock_device mem_33888;
    
    mem_33888.references = NULL;
    
    struct memblock_device mem_33886;
    
    mem_33886.references = NULL;
    
    struct memblock_device mem_33884;
    
    mem_33884.references = NULL;
    
    struct memblock_device mem_33873;
    
    mem_33873.references = NULL;
    
    struct memblock_device mem_33871;
    
    mem_33871.references = NULL;
    
    struct memblock_device mem_33869;
    
    mem_33869.references = NULL;
    
    struct memblock_device mem_33865;
    
    mem_33865.references = NULL;
    
    struct memblock_device mem_33863;
    
    mem_33863.references = NULL;
    
    struct memblock_device mem_33867;
    
    mem_33867.references = NULL;
    
    struct memblock_device mem_33859;
    
    mem_33859.references = NULL;
    
    struct memblock_device mem_33860;
    
    mem_33860.references = NULL;
    
    struct memblock_device ext_mem_33861;
    
    ext_mem_33861.references = NULL;
    
    struct memblock_device mem_33856;
    
    mem_33856.references = NULL;
    
    struct memblock_device mem_33857;
    
    mem_33857.references = NULL;
    
    struct memblock_device ext_mem_33858;
    
    ext_mem_33858.references = NULL;
    
    struct memblock_device mem_33855;
    
    mem_33855.references = NULL;
    
    struct memblock_device incprefixes_mem_34233;
    
    incprefixes_mem_34233.references = NULL;
    
    struct memblock_device aggregates_mem_34231;
    
    aggregates_mem_34231.references = NULL;
    
    struct memblock_device incprefixes_mem_34229;
    
    incprefixes_mem_34229.references = NULL;
    
    struct memblock_device aggregates_mem_34227;
    
    aggregates_mem_34227.references = NULL;
    
    struct memblock_device status_flags_mem_34225;
    
    status_flags_mem_34225.references = NULL;
    
    struct memblock_device mem_33852;
    
    mem_33852.references = NULL;
    
    struct memblock_device mem_33850;
    
    mem_33850.references = NULL;
    
    struct memblock_device mem_33848;
    
    mem_33848.references = NULL;
    
    struct memblock_device mem_33844;
    
    mem_33844.references = NULL;
    
    struct memblock_device mem_33842;
    
    mem_33842.references = NULL;
    
    struct memblock_device mem_33840;
    
    mem_33840.references = NULL;
    
    struct memblock_device mem_33838;
    
    mem_33838.references = NULL;
    
    struct memblock_device incprefixes_mem_34055;
    
    incprefixes_mem_34055.references = NULL;
    
    struct memblock_device aggregates_mem_34053;
    
    aggregates_mem_34053.references = NULL;
    
    struct memblock_device status_flags_mem_34031;
    
    status_flags_mem_34031.references = NULL;
    
    struct memblock_device mem_33836;
    
    mem_33836.references = NULL;
    
    struct memblock_device mem_out_34021;
    
    mem_out_34021.references = NULL;
    
    struct memblock_device mem_out_34020;
    
    mem_out_34020.references = NULL;
    
    struct memblock_device mem_out_34019;
    
    mem_out_34019.references = NULL;
    
    struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
    struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
    struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
    int64_t prim_out_34022;
    int64_t rng_32477 = add64(nR_28192, offset_R_28196);
    bool bounds_invalid_upwards_32478 = slt64(rng_32477, offset_R_28196);
    bool valid_32479 = !bounds_invalid_upwards_32478;
    bool range_valid_c_32480;
    
    if (!valid_32479) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) offset_R_28196, "..<", (long long) rng_32477, " is invalid.", "-> #0  ftbasics.fut:11:25-40\n   #1  ftSMJ.fut:328:15-43\n   #2  ftSMJ.fut:405:133-136\n   #3  ftSMJ.fut:394:1-405:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t tmp_32490 = sub64(nR_28192, (int64_t) 1);
    bool y_32492 = slt64(tmp_32490, nR_28192);
    bool x_32491 = sle64((int64_t) 0, tmp_32490);
    bool bounds_check_32493 = x_32491 && y_32492;
    bool cond_32488 = nR_28192 == (int64_t) 0;
    bool protect_assert_disj_32494 = cond_32488 || bounds_check_32493;
    bool index_certs_32495;
    
    if (!protect_assert_disj_32494) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) tmp_32490, "] out of bounds for array of shape [", (long long) nR_28192, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:328:7-329:73\n   #3  ftSMJ.fut:405:133-136\n   #4  ftSMJ.fut:394:1-405:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    bool x_32489 = !cond_32488;
    int64_t m_f_res_32496;
    
    if (x_32489) {
        int64_t bytes_33835 = (int64_t) 8 * nR_28192;
        int64_t segscan_tblock_sizze_33719;
        
        segscan_tblock_sizze_33719 = *ctx->tuning_params.inner_SMJ_doublezisegscan_tblock_sizze_33718;
        
        int64_t num_tblocks_33721;
        int64_t max_num_tblocks_34023;
        
        max_num_tblocks_34023 = *ctx->tuning_params.inner_SMJ_doublezisegscan_num_tblocks_33720;
        num_tblocks_33721 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nR_28192, segscan_tblock_sizze_33719), max_num_tblocks_34023)));
        if (memblock_alloc_device(ctx, &mem_33836, bytes_33835, "mem_33836")) {
            err = 1;
            goto cleanup;
        }
        if (slt64((int64_t) 0, nR_28192)) {
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegScan");
            
            int64_t shared_memory_34024;
            
            shared_memory_34024 = ctx->max_shared_memory;
            
            int64_t thread_block_sizze_34025;
            
            thread_block_sizze_34025 = ctx->max_thread_block_size;
            
            int64_t registers_34026;
            
            registers_34026 = ctx->max_registers;
            
            int64_t thread_block_sizze_34027;
            
            thread_block_sizze_34027 = ctx->max_thread_block_size;
            
            int64_t chunk_sizze_34028 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_34024, thread_block_sizze_34025), (int64_t) 8), squot64(squot64(registers_34026, thread_block_sizze_34027) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
            int64_t num_virt_blocks_34029 = sdiv_up64(nR_28192, segscan_tblock_sizze_33719 * chunk_sizze_34028);
            int64_t num_virt_threads_34030 = num_virt_blocks_34029 * segscan_tblock_sizze_33719;
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_34028, '\n');
            if (memblock_alloc_device(ctx, &status_flags_mem_34031, num_virt_blocks_34029, "status_flags_mem_34031")) {
                err = 1;
                goto cleanup;
            }
            if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_34031, num_virt_blocks_34029, (int8_t) 0) != 0) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &aggregates_mem_34053, (int64_t) 8 * num_virt_blocks_34029, "aggregates_mem_34053")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &incprefixes_mem_34055, (int64_t) 8 * num_virt_blocks_34029, "incprefixes_mem_34055")) {
                err = 1;
                goto cleanup;
            }
            {
                err = gpu_kernel_inner_SMJ_doublezisegscan_33724(ctx, num_tblocks_33721, 1, 1, *ctx->tuning_params.inner_SMJ_doublezisegscan_tblock_sizze_33718, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_33719), chunk_sizze_34028 * segscan_tblock_sizze_33719 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_33719), chunk_sizze_34028 * segscan_tblock_sizze_33719 * (int64_t) 8), (int64_t) 8), (int64_t) 8), nR_28192, num_tblocks_33721, num_virt_blocks_34029, num_virt_threads_34030, mem_33836.mem, status_flags_mem_34031.mem, aggregates_mem_34053.mem, incprefixes_mem_34055.mem, global_dynid_mem_34057.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
        }
        
        int64_t read_res_34527;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_34527, mem_33836.mem, tmp_32490 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_32780 = read_res_34527;
        
        if (memblock_unref_device(ctx, &mem_33836, "mem_33836") != 0)
            return 1;
        m_f_res_32496 = x_32780;
    } else {
        m_f_res_32496 = (int64_t) 0;
    }
    
    int64_t m_32498;
    
    if (cond_32488) {
        m_32498 = (int64_t) 0;
    } else {
        m_32498 = m_f_res_32496;
    }
    
    bool eq_x_zz_32499 = (int64_t) 0 == m_f_res_32496;
    bool p_and_eq_x_y_32500 = x_32489 && eq_x_zz_32499;
    bool empty_slice_32501 = cond_32488 || p_and_eq_x_y_32500;
    int64_t m_32502 = sub64(m_32498, (int64_t) 1);
    bool zzero_leq_i_p_m_t_s_32503 = sle64((int64_t) 0, m_32502);
    bool i_p_m_t_s_leq_w_32504 = slt64(m_32502, nR_28192);
    bool i_lte_j_32505 = sle64((int64_t) 0, m_32498);
    bool y_32506 = zzero_leq_i_p_m_t_s_32503 && i_p_m_t_s_leq_w_32504;
    bool forwards_ok_32507 = i_lte_j_32505 && y_32506;
    bool ok_or_empty_32508 = empty_slice_32501 || forwards_ok_32507;
    bool index_certs_32509;
    
    if (!ok_or_empty_32508) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_32498, "] out of bounds for array of shape [", (long long) nR_28192, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:328:7-329:73\n   #3  ftSMJ.fut:405:133-136\n   #4  ftSMJ.fut:394:1-405:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_33837 = (int64_t) 8 * m_32498;
    
    if (memblock_alloc_device(ctx, &mem_33838, bytes_33837, "mem_33838")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33838.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, tR_mem_33832.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_32498})) != 0)
        goto cleanup;
    if (memblock_alloc_device(ctx, &mem_33840, bytes_33837, "mem_33840")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhiota_i64(ctx, mem_33840, m_32498, offset_R_28196, (int64_t) 1) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33842, bytes_33837, "mem_33842")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_33842, m_32498, (int64_t) -1) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33844, bytes_33837, "mem_33844")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_33844, m_32498, (int64_t) 0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t segmap_tblock_sizze_33729;
    
    segmap_tblock_sizze_33729 = *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_33728;
    
    int64_t num_tblocks_33731;
    int64_t max_num_tblocks_34203;
    
    max_num_tblocks_34203 = *ctx->tuning_params.inner_SMJ_doublezisegmap_num_tblocks_33730;
    num_tblocks_33731 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nR_28192, segmap_tblock_sizze_33729), max_num_tblocks_34203)));
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_34204 = sext_i64_i32(sdiv_up64(nR_28192, segmap_tblock_sizze_33729));
    
    {
        err = gpu_kernel_inner_SMJ_doublezisegmap_33726(ctx, num_tblocks_33731, 1, 1, *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_33728, 1, 1, (int64_t) 0, nR_28192, offset_R_28196, m_32498, num_tblocks_33731, virt_num_tblocks_34204, tR_mem_33832.mem, mem_33838.mem, mem_33840.mem, mem_33842.mem, mem_33844.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t segscan_tblock_sizze_33735;
    
    segscan_tblock_sizze_33735 = *ctx->tuning_params.inner_SMJ_doublezisegscan_tblock_sizze_33734;
    
    int64_t num_tblocks_33737;
    int64_t max_num_tblocks_34217;
    
    max_num_tblocks_34217 = *ctx->tuning_params.inner_SMJ_doublezisegscan_num_tblocks_33736;
    num_tblocks_33737 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_32498, segscan_tblock_sizze_33735), max_num_tblocks_34217)));
    if (memblock_alloc_device(ctx, &mem_33848, bytes_33837, "mem_33848")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33850, bytes_33837, "mem_33850")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33852, bytes_33837, "mem_33852")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, m_32498)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_34218;
        
        shared_memory_34218 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_34219;
        
        thread_block_sizze_34219 = ctx->max_thread_block_size;
        
        int64_t registers_34220;
        
        registers_34220 = ctx->max_registers;
        
        int64_t thread_block_sizze_34221;
        
        thread_block_sizze_34221 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_34222 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_34218, thread_block_sizze_34219), (int64_t) 8), squot64(squot64(registers_34220, thread_block_sizze_34221) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
        int64_t num_virt_blocks_34223 = sdiv_up64(m_32498, segscan_tblock_sizze_33735 * chunk_sizze_34222);
        int64_t num_virt_threads_34224 = num_virt_blocks_34223 * segscan_tblock_sizze_33735;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_34222, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_34225, num_virt_blocks_34223, "status_flags_mem_34225")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_34225, num_virt_blocks_34223, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_34227, (int64_t) 8 * num_virt_blocks_34223, "aggregates_mem_34227")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_34229, (int64_t) 8 * num_virt_blocks_34223, "incprefixes_mem_34229")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_34231, (int64_t) 8 * num_virt_blocks_34223, "aggregates_mem_34231")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_34233, (int64_t) 8 * num_virt_blocks_34223, "incprefixes_mem_34233")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_doublezisegscan_33740(ctx, num_tblocks_33737, 1, 1, *ctx->tuning_params.inner_SMJ_doublezisegscan_tblock_sizze_33734, 1, 1, smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_33735, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_33735), smax64(chunk_sizze_34222 * segscan_tblock_sizze_33735 * (int64_t) 8, chunk_sizze_34222 * segscan_tblock_sizze_33735 * (int64_t) 8)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_33735, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_33735), smax64(chunk_sizze_34222 * segscan_tblock_sizze_33735 * (int64_t) 8, chunk_sizze_34222 * segscan_tblock_sizze_33735 * (int64_t) 8)), (int64_t) 8), (int64_t) 8), m_32498, num_tblocks_33737, num_virt_blocks_34223, num_virt_threads_34224, mem_33844.mem, mem_33848.mem, mem_33850.mem, mem_33852.mem, status_flags_mem_34225.mem, aggregates_mem_34227.mem, incprefixes_mem_34229.mem, aggregates_mem_34231.mem, incprefixes_mem_34233.mem, global_dynid_mem_34235.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    
    int64_t segmap_tblock_sizze_33756;
    
    segmap_tblock_sizze_33756 = *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_33744;
    
    int64_t segmap_usable_groups_33757 = sdiv_up64(m_32498, segmap_tblock_sizze_33756);
    
    if (memblock_alloc_device(ctx, &mem_33855, bytes_33837, "mem_33855")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_34370 = sext_i64_i32(sdiv_up64(m_32498, segmap_tblock_sizze_33756));
    
    {
        err = gpu_kernel_inner_SMJ_doublezisegmap_33760(ctx, segmap_usable_groups_33757, 1, 1, *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_33744, 1, 1, (int64_t) 0, m_32498, mem_33848.mem, mem_33855.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_33848, "mem_33848") != 0)
        return 1;
    
    bool cond_32537 = slt64((int64_t) 0, m_32498);
    bool y_32538 = slt64(m_32502, m_32498);
    bool bounds_check_32539 = zzero_leq_i_p_m_t_s_32503 && y_32538;
    bool loop_not_taken_32540 = !cond_32537;
    bool protect_assert_disj_32541 = bounds_check_32539 || loop_not_taken_32540;
    bool index_certs_32542;
    
    if (!protect_assert_disj_32541) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) m_32502, "] out of bounds for array of shape [", (long long) m_32498, "].", "-> #0  ftSMJ.fut:285:10-41\n   #1  ftSMJ.fut:328:7-329:73\n   #2  ftSMJ.fut:405:133-136\n   #3  ftSMJ.fut:394:1-405:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    if (cond_32537) {
        if (memblock_alloc_device(ctx, &mem_33857, (int64_t) 8, "mem_33857")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_doublezigpuseq_34379(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, m_32502, mem_33855.mem, mem_33857.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_33858, &mem_33857, "mem_33857") != 0)
            return 1;
    } else {
        if (memblock_alloc_device(ctx, &mem_33856, (int64_t) 8, "mem_33856")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i64(ctx, mem_33856, (int64_t) 1, (int64_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_33858, &mem_33856, "mem_33856") != 0)
            return 1;
    }
    if (cond_32537) {
        if (memblock_alloc_device(ctx, &mem_33860, (int64_t) 8, "mem_33860")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_doublezigpuseq_34385(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, m_32502, mem_33844.mem, mem_33860.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_33861, &mem_33860, "mem_33860") != 0)
            return 1;
    } else {
        if (memblock_alloc_device(ctx, &mem_33859, (int64_t) 8, "mem_33859")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i64(ctx, mem_33859, (int64_t) 1, (int64_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_33861, &mem_33859, "mem_33859") != 0)
            return 1;
    }
    
    bool zzero_32554 = scatter_psizze_28201 == (int64_t) 0;
    bool nonzzero_32555 = !zzero_32554;
    bool nonzzero_cert_32556;
    
    if (!nonzzero_32555) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftbasics.fut:66:23-29\n   #1  ftSMJ.fut:328:7-329:73\n   #2  ftSMJ.fut:405:133-136\n   #3  ftSMJ.fut:394:1-405:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    bool x_32621 = !empty_slice_32501;
    bool protect_assert_disj_32622 = empty_slice_32501 || bounds_check_32539;
    bool index_certs_32623;
    
    if (!protect_assert_disj_32622) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) m_32502, "] out of bounds for array of shape [", (long long) m_32498, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:328:7-329:73\n   #3  ftSMJ.fut:405:133-136\n   #4  ftSMJ.fut:394:1-405:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t m_f_res_32624;
    
    if (x_32621) {
        int64_t read_res_34528;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_34528, mem_33850.mem, m_32502 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_32788 = read_res_34528;
        
        m_f_res_32624 = x_32788;
    } else {
        m_f_res_32624 = (int64_t) 0;
    }
    
    int64_t m_32626;
    
    if (empty_slice_32501) {
        m_32626 = (int64_t) 0;
    } else {
        m_32626 = m_f_res_32624;
    }
    
    int64_t m_32636 = sub64(m_32626, (int64_t) 1);
    bool i_p_m_t_s_leq_w_32638 = slt64(m_32636, m_32498);
    bool zzero_leq_i_p_m_t_s_32637 = sle64((int64_t) 0, m_32636);
    bool y_32640 = zzero_leq_i_p_m_t_s_32637 && i_p_m_t_s_leq_w_32638;
    bool i_lte_j_32639 = sle64((int64_t) 0, m_32626);
    bool forwards_ok_32641 = i_lte_j_32639 && y_32640;
    bool eq_x_zz_32633 = (int64_t) 0 == m_f_res_32624;
    bool p_and_eq_x_y_32634 = x_32621 && eq_x_zz_32633;
    bool empty_slice_32635 = empty_slice_32501 || p_and_eq_x_y_32634;
    bool ok_or_empty_32642 = empty_slice_32635 || forwards_ok_32641;
    bool index_certs_32643;
    
    if (!ok_or_empty_32642) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_32626, "] out of bounds for array of shape [", (long long) m_32498, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:328:7-329:73\n   #3  ftSMJ.fut:405:133-136\n   #4  ftSMJ.fut:394:1-405:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_33862 = (int64_t) 8 * m_32626;
    
    if (memblock_alloc_device(ctx, &mem_33867, (int64_t) 8, "mem_33867")) {
        err = 1;
        goto cleanup;
    }
    {
        err = gpu_kernel_inner_SMJ_doublezigpuseq_34391(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, ext_mem_33858.mem, ext_mem_33861.mem, mem_33867.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (memblock_unref_device(ctx, &ext_mem_33858, "ext_mem_33858") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_33861, "ext_mem_33861") != 0)
        return 1;
    
    int64_t n_pairs_t_res_32547;
    
    if (cond_32537) {
        int64_t read_res_34529;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_34529, mem_33867.mem, (int64_t) 0 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_33830 = read_res_34529;
        
        n_pairs_t_res_32547 = x_33830;
    } else {
        n_pairs_t_res_32547 = (int64_t) 0;
    }
    if (memblock_unref_device(ctx, &mem_33867, "mem_33867") != 0)
        return 1;
    
    int64_t n_pairs_32548;
    
    if (cond_32537) {
        n_pairs_32548 = n_pairs_t_res_32547;
    } else {
        n_pairs_32548 = (int64_t) 0;
    }
    
    int64_t bytes_33868 = (int64_t) 8 * n_pairs_32548;
    int64_t segmap_tblock_sizze_33771;
    
    segmap_tblock_sizze_33771 = *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_33770;
    
    int64_t num_tblocks_33773;
    int64_t max_num_tblocks_34397;
    
    max_num_tblocks_34397 = *ctx->tuning_params.inner_SMJ_doublezisegmap_num_tblocks_33772;
    num_tblocks_33773 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_32498, segmap_tblock_sizze_33771), max_num_tblocks_34397)));
    if (memblock_alloc_device(ctx, &mem_33863, bytes_33862, "mem_33863")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33863.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_33844.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_32626})) != 0)
        goto cleanup;
    if (memblock_alloc_device(ctx, &mem_33865, bytes_33862, "mem_33865")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33865.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_33855.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_32626})) != 0)
        goto cleanup;
    
    int64_t segmap_tblock_sizze_33779;
    
    segmap_tblock_sizze_33779 = *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_33778;
    
    int64_t num_tblocks_33781;
    int64_t max_num_tblocks_34398;
    
    max_num_tblocks_34398 = *ctx->tuning_params.inner_SMJ_doublezisegmap_num_tblocks_33780;
    num_tblocks_33781 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_32498, segmap_tblock_sizze_33779), max_num_tblocks_34398)));
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_34399 = sext_i64_i32(sdiv_up64(m_32498, segmap_tblock_sizze_33779));
    
    {
        err = gpu_kernel_inner_SMJ_doublezisegmap_33776(ctx, num_tblocks_33781, 1, 1, *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_33778, 1, 1, (int64_t) 0, m_32498, m_32626, num_tblocks_33781, virt_num_tblocks_34399, mem_33844.mem, mem_33850.mem, mem_33852.mem, mem_33855.mem, mem_33863.mem, mem_33865.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_33844, "mem_33844") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33850, "mem_33850") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33852, "mem_33852") != 0)
        return 1;
    
    bool cond_32653 = slt64((int64_t) 0, m_32626);
    int64_t segmap_tblock_sizze_33794;
    
    segmap_tblock_sizze_33794 = *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_33786;
    if (memblock_alloc_device(ctx, &mem_33869, bytes_33868, "mem_33869")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_f64(ctx, mem_33869, n_pairs_32548, 0.0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33871, bytes_33868, "mem_33871")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_33871, n_pairs_32548, (int64_t) -1) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33873, bytes_33868, "mem_33873")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_33873, n_pairs_32548, (int64_t) -1) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t zm_lhs_32552 = add64(scatter_psizze_28201, n_pairs_32548);
    int64_t zs_lhs_32553 = sub64(zm_lhs_32552, (int64_t) 1);
    int64_t m_32557 = sdiv64(zs_lhs_32553, scatter_psizze_28201);
    bool loop_cond_32558 = slt64((int64_t) 0, m_32557);
    bool partitioned_scatter_res_32559;
    int64_t partitioned_scatter_res_32563;
    bool loop_while_32564;
    int64_t p_32568;
    
    loop_while_32564 = loop_cond_32558;
    p_32568 = (int64_t) 0;
    while (loop_while_32564) {
        int64_t lower_bound_32569 = mul64(scatter_psizze_28201, p_32568);
        int64_t min_arg1_32570 = add64(scatter_psizze_28201, lower_bound_32569);
        int64_t min_res_32571 = smin64(n_pairs_32548, min_arg1_32570);
        int64_t j_m_i_32572 = sub64(min_res_32571, lower_bound_32569);
        bool empty_slice_32573 = j_m_i_32572 == (int64_t) 0;
        int64_t m_32574 = sub64(j_m_i_32572, (int64_t) 1);
        int64_t i_p_m_t_s_32575 = add64(lower_bound_32569, m_32574);
        bool zzero_leq_i_p_m_t_s_32576 = sle64((int64_t) 0, i_p_m_t_s_32575);
        bool i_p_m_t_s_leq_w_32577 = slt64(i_p_m_t_s_32575, n_pairs_32548);
        bool zzero_lte_i_32578 = sle64((int64_t) 0, lower_bound_32569);
        bool i_lte_j_32579 = sle64(lower_bound_32569, min_res_32571);
        bool y_32580 = i_p_m_t_s_leq_w_32577 && zzero_lte_i_32578;
        bool y_32581 = zzero_leq_i_p_m_t_s_32576 && y_32580;
        bool forwards_ok_32582 = i_lte_j_32579 && y_32581;
        bool ok_or_empty_32583 = empty_slice_32573 || forwards_ok_32582;
        bool index_certs_32584;
        
        if (!ok_or_empty_32583) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) lower_bound_32569, ":", (long long) min_res_32571, "] out of bounds for array of shape [", (long long) n_pairs_32548, "].", "-> #0  ftbasics.fut:72:25-56\n   #1  ftSMJ.fut:328:7-329:73\n   #2  ftSMJ.fut:405:133-136\n   #3  ftSMJ.fut:394:1-405:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t bytes_33883 = (int64_t) 8 * j_m_i_32572;
        
        if (memblock_alloc_device(ctx, &mem_33884, bytes_33883, "mem_33884")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33884.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_33869.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_32569, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_32572})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_33886, bytes_33883, "mem_33886")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33886.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_33871.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_32569, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_32572})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_33888, bytes_33883, "mem_33888")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33888.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_33873.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_32569, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_32572})) != 0)
            goto cleanup;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_34437 = sext_i64_i32(sdiv_up64(m_32498, segmap_tblock_sizze_33771));
        
        {
            err = gpu_kernel_inner_SMJ_doublezisegmap_33768(ctx, num_tblocks_33773, 1, 1, *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_33770, 1, 1, (int64_t) 0, m_32498, lower_bound_32569, min_res_32571, j_m_i_32572, num_tblocks_33773, virt_num_tblocks_34437, mem_33838.mem, mem_33840.mem, mem_33842.mem, mem_33855.mem, mem_33884.mem, mem_33886.mem, mem_33888.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t tmp_32598 = add64((int64_t) 1, p_32568);
        
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33869.mem, lower_bound_32569, (int64_t []) {(int64_t) 1}, mem_33884.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_32572})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_33884, "mem_33884") != 0)
            return 1;
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33871.mem, lower_bound_32569, (int64_t []) {(int64_t) 1}, mem_33886.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_32572})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_33886, "mem_33886") != 0)
            return 1;
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33873.mem, lower_bound_32569, (int64_t []) {(int64_t) 1}, mem_33888.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_32572})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_33888, "mem_33888") != 0)
            return 1;
        
        bool loop_cond_32609 = slt64(tmp_32598, m_32557);
        bool loop_while_tmp_34432 = loop_cond_32609;
        int64_t p_tmp_34436 = tmp_32598;
        
        loop_while_32564 = loop_while_tmp_34432;
        p_32568 = p_tmp_34436;
    }
    partitioned_scatter_res_32559 = loop_while_32564;
    partitioned_scatter_res_32563 = p_32568;
    if (memblock_unref_device(ctx, &mem_33838, "mem_33838") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33840, "mem_33840") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33842, "mem_33842") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33855, "mem_33855") != 0)
        return 1;
    
    bool loop_cond_t_res_32654 = slt64(m_32498, n_pairs_32548);
    bool x_32655 = cond_32653 && loop_cond_t_res_32654;
    
    if (memblock_alloc_device(ctx, &mem_33914, (int64_t) 8, "mem_33914")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33915, (int64_t) 8, "mem_33915")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33916, (int64_t) 8, "mem_33916")) {
        err = 1;
        goto cleanup;
    }
    
    bool joinTups_to_joinPairs_InnerJoin_res_32656;
    int64_t joinTups_to_joinPairs_InnerJoin_res_32660;
    bool loop_while_32661;
    int64_t p_32665;
    
    if (memblock_set_device(ctx, &mem_param_33901, &mem_33869, "mem_33869") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_33904, &mem_33871, "mem_33871") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_33907, &mem_33873, "mem_33873") != 0)
        return 1;
    loop_while_32661 = x_32655;
    p_32665 = (int64_t) 0;
    while (loop_while_32661) {
        bool x_32666 = sle64((int64_t) 0, p_32665);
        bool y_32667 = slt64(p_32665, m_32626);
        bool bounds_check_32668 = x_32666 && y_32667;
        bool index_certs_32669;
        
        if (!bounds_check_32668) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) p_32665, "] out of bounds for array of shape [", (long long) m_32626, "].", "-> #0  ftSMJ.fut:300:13-42\n   #1  ftSMJ.fut:328:7-329:73\n   #2  ftSMJ.fut:405:133-136\n   #3  ftSMJ.fut:394:1-405:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t read_res_34530;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_34530, mem_33865.mem, p_32665 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t loopres_32670 = read_res_34530;
        int64_t read_res_34531;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_34531, mem_33863.mem, p_32665 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t loopres_32671 = read_res_34531;
        bool x_32672 = sle64((int64_t) 0, loopres_32670);
        bool y_32673 = slt64(loopres_32670, n_pairs_32548);
        bool bounds_check_32674 = x_32672 && y_32673;
        bool index_certs_32675;
        
        if (!bounds_check_32674) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) loopres_32670, "] out of bounds for array of shape [", (long long) n_pairs_32548, "].", "-> #0  ftSMJ.fut:302:52-61\n   #1  ftSMJ.fut:328:7-329:73\n   #2  ftSMJ.fut:405:133-136\n   #3  ftSMJ.fut:394:1-405:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t tmp_32686 = add64(loopres_32670, loopres_32671);
        bool empty_slice_32690 = loopres_32671 == (int64_t) 0;
        int64_t m_32691 = sub64(loopres_32671, (int64_t) 1);
        int64_t i_p_m_t_s_32692 = add64(loopres_32670, m_32691);
        bool zzero_leq_i_p_m_t_s_32693 = sle64((int64_t) 0, i_p_m_t_s_32692);
        bool i_p_m_t_s_leq_w_32694 = slt64(i_p_m_t_s_32692, n_pairs_32548);
        bool i_lte_j_32695 = sle64(loopres_32670, tmp_32686);
        bool y_32696 = x_32672 && i_p_m_t_s_leq_w_32694;
        bool y_32697 = zzero_leq_i_p_m_t_s_32693 && y_32696;
        bool forwards_ok_32698 = i_lte_j_32695 && y_32697;
        bool ok_or_empty_32699 = empty_slice_32690 || forwards_ok_32698;
        bool index_certs_32700;
        
        if (!ok_or_empty_32699) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) loopres_32670, ":", (long long) tmp_32686, "] out of bounds for array of shape [", (long long) n_pairs_32548, "].", "-> #0  ftSMJ.fut:306:14-55\n   #1  ftSMJ.fut:328:7-329:73\n   #2  ftSMJ.fut:405:133-136\n   #3  ftSMJ.fut:394:1-405:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t bytes_33917 = (int64_t) 8 * loopres_32671;
        int64_t segmap_usable_groups_33795 = sdiv_up64(loopres_32671, segmap_tblock_sizze_33794);
        int64_t tmp_32685 = add64((int64_t) 1, p_32665);
        
        if (memblock_alloc_device(ctx, &mem_33909, bytes_33868, "mem_33909")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33909.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_33901.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_32548})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_33911, bytes_33868, "mem_33911")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33911.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_33904.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_32548})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_33913, bytes_33868, "mem_33913")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33913.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_33907.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_32548})) != 0)
            goto cleanup;
        
        bool cond_32704 = slt64(tmp_32685, m_32626);
        bool x_32705 = loop_cond_t_res_32654 && cond_32704;
        
        {
            err = gpu_kernel_inner_SMJ_doublezigpuseq_34458(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, loopres_32670, mem_param_33901.mem, mem_param_33904.mem, mem_param_33907.mem, mem_33914.mem, mem_33915.mem, mem_33916.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_33918, bytes_33917, "mem_33918")) {
            err = 1;
            goto cleanup;
        }
        
        int64_t replicate_n_34464 = loopres_32671;
        int64_t tblock_sizze_34469;
        
        tblock_sizze_34469 = *ctx->tuning_params.inner_SMJ_doublezitblock_sizze_34469;
        
        int64_t virt_num_tblocks_34470 = sdiv_up64(replicate_n_34464, tblock_sizze_34469);
        int64_t num_tblocks_34471 = smin64(virt_num_tblocks_34470, (int64_t) 1048576);
        
        {
            err = gpu_kernel_inner_SMJ_doublezireplicate_34465(ctx, num_tblocks_34471, 1, 1, tblock_sizze_34469, 1, 1, (int64_t) 0, loopres_32671, replicate_n_34464, virt_num_tblocks_34470, num_tblocks_34471, mem_33914.mem, mem_33918.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_33920, bytes_33917, "mem_33920")) {
            err = 1;
            goto cleanup;
        }
        
        int64_t replicate_n_34484 = loopres_32671;
        int64_t tblock_sizze_34489;
        
        tblock_sizze_34489 = *ctx->tuning_params.inner_SMJ_doublezitblock_sizze_34489;
        
        int64_t virt_num_tblocks_34490 = sdiv_up64(replicate_n_34484, tblock_sizze_34489);
        int64_t num_tblocks_34491 = smin64(virt_num_tblocks_34490, (int64_t) 1048576);
        
        {
            err = gpu_kernel_inner_SMJ_doublezireplicate_34485(ctx, num_tblocks_34491, 1, 1, tblock_sizze_34489, 1, 1, (int64_t) 0, loopres_32671, replicate_n_34484, virt_num_tblocks_34490, num_tblocks_34491, mem_33915.mem, mem_33920.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_34504 = sext_i64_i32(sdiv_up64(loopres_32671, segmap_tblock_sizze_33794));
        
        {
            err = gpu_kernel_inner_SMJ_doublezisegmap_33798(ctx, segmap_usable_groups_33795, 1, 1, *ctx->tuning_params.inner_SMJ_doublezisegmap_tblock_sizze_33786, 1, 1, (int64_t) 0, loopres_32670, loopres_32671, mem_33913.mem, mem_33916.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33909.mem, loopres_32670, (int64_t []) {(int64_t) 1}, mem_33918.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {loopres_32671})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_33918, "mem_33918") != 0)
            return 1;
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33911.mem, loopres_32670, (int64_t []) {(int64_t) 1}, mem_33920.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {loopres_32671})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_33920, "mem_33920") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_34450, &mem_33909, "mem_33909") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_34451, &mem_33911, "mem_33911") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_34452, &mem_33913, "mem_33913") != 0)
            return 1;
        
        bool loop_while_tmp_34453 = x_32705;
        int64_t p_tmp_34457 = tmp_32685;
        
        if (memblock_set_device(ctx, &mem_param_33901, &mem_param_tmp_34450, "mem_param_tmp_34450") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_33904, &mem_param_tmp_34451, "mem_param_tmp_34451") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_33907, &mem_param_tmp_34452, "mem_param_tmp_34452") != 0)
            return 1;
        loop_while_32661 = loop_while_tmp_34453;
        p_32665 = p_tmp_34457;
    }
    if (memblock_set_device(ctx, &ext_mem_33932, &mem_param_33901, "mem_param_33901") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_33931, &mem_param_33904, "mem_param_33904") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_33930, &mem_param_33907, "mem_param_33907") != 0)
        return 1;
    joinTups_to_joinPairs_InnerJoin_res_32656 = loop_while_32661;
    joinTups_to_joinPairs_InnerJoin_res_32660 = p_32665;
    if (memblock_unref_device(ctx, &mem_33863, "mem_33863") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33865, "mem_33865") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33869, "mem_33869") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33871, "mem_33871") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33873, "mem_33873") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33914, "mem_33914") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33915, "mem_33915") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33916, "mem_33916") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_33934, bytes_33868, "mem_33934")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33934.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_33932.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_32548})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_33932, "ext_mem_33932") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_33936, bytes_33868, "mem_33936")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33936.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_33931.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_32548})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_33931, "ext_mem_33931") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_33938, bytes_33868, "mem_33938")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33938.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_33930.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_32548})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_33930, "ext_mem_33930") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_34019, &mem_33936, "mem_33936") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_34020, &mem_33938, "mem_33938") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_34021, &mem_33934, "mem_33934") != 0)
        return 1;
    prim_out_34022 = n_pairs_32548;
    if (memblock_set_device(ctx, &*mem_out_p_34523, &mem_out_34019, "mem_out_34019") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_34524, &mem_out_34020, "mem_out_34020") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_34525, &mem_out_34021, "mem_out_34021") != 0)
        return 1;
    *out_prim_out_34526 = prim_out_34022;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_33938, "mem_33938") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33936, "mem_33936") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33934, "mem_33934") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_34452, "mem_param_tmp_34452") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_34451, "mem_param_tmp_34451") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_34450, "mem_param_tmp_34450") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33920, "mem_33920") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33918, "mem_33918") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33913, "mem_33913") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33911, "mem_33911") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33909, "mem_33909") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_33907, "mem_param_33907") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_33904, "mem_param_33904") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_33901, "mem_param_33901") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33930, "ext_mem_33930") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33931, "ext_mem_33931") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33932, "ext_mem_33932") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33916, "mem_33916") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33915, "mem_33915") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33914, "mem_33914") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33888, "mem_33888") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33886, "mem_33886") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33884, "mem_33884") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33873, "mem_33873") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33871, "mem_33871") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33869, "mem_33869") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33865, "mem_33865") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33863, "mem_33863") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33867, "mem_33867") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33859, "mem_33859") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33860, "mem_33860") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33861, "ext_mem_33861") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33856, "mem_33856") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33857, "mem_33857") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33858, "ext_mem_33858") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33855, "mem_33855") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_34233, "incprefixes_mem_34233") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_34231, "aggregates_mem_34231") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_34229, "incprefixes_mem_34229") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_34227, "aggregates_mem_34227") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_34225, "status_flags_mem_34225") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33852, "mem_33852") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33850, "mem_33850") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33848, "mem_33848") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33844, "mem_33844") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33842, "mem_33842") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33840, "mem_33840") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33838, "mem_33838") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_34055, "incprefixes_mem_34055") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_34053, "aggregates_mem_34053") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_34031, "status_flags_mem_34031") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33836, "mem_33836") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_34021, "mem_out_34021") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_34020, "mem_out_34020") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_34019, "mem_out_34019") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_inner_SMJ_float(struct futhark_context *ctx, struct memblock_device *mem_out_p_34532, struct memblock_device *mem_out_p_34533, struct memblock_device *mem_out_p_34534, int64_t *out_prim_out_34535, struct memblock_device tR_mem_33832, struct memblock_device tS_mem_33833, int64_t nR_26587, int64_t nS_26588, int64_t offset_R_26591, int64_t offset_S_26592, int64_t partitionsPerWindow_26593, int64_t numberOfWindows_26594, int64_t extParallelism_26595, int64_t scatter_psizze_26596)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_33938;
    
    mem_33938.references = NULL;
    
    struct memblock_device mem_33936;
    
    mem_33936.references = NULL;
    
    struct memblock_device mem_33934;
    
    mem_33934.references = NULL;
    
    struct memblock_device mem_param_tmp_34452;
    
    mem_param_tmp_34452.references = NULL;
    
    struct memblock_device mem_param_tmp_34451;
    
    mem_param_tmp_34451.references = NULL;
    
    struct memblock_device mem_param_tmp_34450;
    
    mem_param_tmp_34450.references = NULL;
    
    struct memblock_device mem_33920;
    
    mem_33920.references = NULL;
    
    struct memblock_device mem_33918;
    
    mem_33918.references = NULL;
    
    struct memblock_device mem_33913;
    
    mem_33913.references = NULL;
    
    struct memblock_device mem_33911;
    
    mem_33911.references = NULL;
    
    struct memblock_device mem_33909;
    
    mem_33909.references = NULL;
    
    struct memblock_device mem_param_33907;
    
    mem_param_33907.references = NULL;
    
    struct memblock_device mem_param_33904;
    
    mem_param_33904.references = NULL;
    
    struct memblock_device mem_param_33901;
    
    mem_param_33901.references = NULL;
    
    struct memblock_device ext_mem_33930;
    
    ext_mem_33930.references = NULL;
    
    struct memblock_device ext_mem_33931;
    
    ext_mem_33931.references = NULL;
    
    struct memblock_device ext_mem_33932;
    
    ext_mem_33932.references = NULL;
    
    struct memblock_device mem_33916;
    
    mem_33916.references = NULL;
    
    struct memblock_device mem_33915;
    
    mem_33915.references = NULL;
    
    struct memblock_device mem_33914;
    
    mem_33914.references = NULL;
    
    struct memblock_device mem_33888;
    
    mem_33888.references = NULL;
    
    struct memblock_device mem_33886;
    
    mem_33886.references = NULL;
    
    struct memblock_device mem_33884;
    
    mem_33884.references = NULL;
    
    struct memblock_device mem_33873;
    
    mem_33873.references = NULL;
    
    struct memblock_device mem_33871;
    
    mem_33871.references = NULL;
    
    struct memblock_device mem_33869;
    
    mem_33869.references = NULL;
    
    struct memblock_device mem_33865;
    
    mem_33865.references = NULL;
    
    struct memblock_device mem_33863;
    
    mem_33863.references = NULL;
    
    struct memblock_device mem_33867;
    
    mem_33867.references = NULL;
    
    struct memblock_device mem_33859;
    
    mem_33859.references = NULL;
    
    struct memblock_device mem_33860;
    
    mem_33860.references = NULL;
    
    struct memblock_device ext_mem_33861;
    
    ext_mem_33861.references = NULL;
    
    struct memblock_device mem_33856;
    
    mem_33856.references = NULL;
    
    struct memblock_device mem_33857;
    
    mem_33857.references = NULL;
    
    struct memblock_device ext_mem_33858;
    
    ext_mem_33858.references = NULL;
    
    struct memblock_device mem_33855;
    
    mem_33855.references = NULL;
    
    struct memblock_device incprefixes_mem_34233;
    
    incprefixes_mem_34233.references = NULL;
    
    struct memblock_device aggregates_mem_34231;
    
    aggregates_mem_34231.references = NULL;
    
    struct memblock_device incprefixes_mem_34229;
    
    incprefixes_mem_34229.references = NULL;
    
    struct memblock_device aggregates_mem_34227;
    
    aggregates_mem_34227.references = NULL;
    
    struct memblock_device status_flags_mem_34225;
    
    status_flags_mem_34225.references = NULL;
    
    struct memblock_device mem_33852;
    
    mem_33852.references = NULL;
    
    struct memblock_device mem_33850;
    
    mem_33850.references = NULL;
    
    struct memblock_device mem_33848;
    
    mem_33848.references = NULL;
    
    struct memblock_device mem_33844;
    
    mem_33844.references = NULL;
    
    struct memblock_device mem_33842;
    
    mem_33842.references = NULL;
    
    struct memblock_device mem_33840;
    
    mem_33840.references = NULL;
    
    struct memblock_device mem_33838;
    
    mem_33838.references = NULL;
    
    struct memblock_device incprefixes_mem_34055;
    
    incprefixes_mem_34055.references = NULL;
    
    struct memblock_device aggregates_mem_34053;
    
    aggregates_mem_34053.references = NULL;
    
    struct memblock_device status_flags_mem_34031;
    
    status_flags_mem_34031.references = NULL;
    
    struct memblock_device mem_33836;
    
    mem_33836.references = NULL;
    
    struct memblock_device mem_out_34021;
    
    mem_out_34021.references = NULL;
    
    struct memblock_device mem_out_34020;
    
    mem_out_34020.references = NULL;
    
    struct memblock_device mem_out_34019;
    
    mem_out_34019.references = NULL;
    
    struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
    struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
    struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
    int64_t prim_out_34022;
    int64_t rng_32477 = add64(nR_26587, offset_R_26591);
    bool bounds_invalid_upwards_32478 = slt64(rng_32477, offset_R_26591);
    bool valid_32479 = !bounds_invalid_upwards_32478;
    bool range_valid_c_32480;
    
    if (!valid_32479) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) offset_R_26591, "..<", (long long) rng_32477, " is invalid.", "-> #0  ftbasics.fut:11:25-40\n   #1  ftSMJ.fut:328:15-43\n   #2  ftSMJ.fut:392:133-136\n   #3  ftSMJ.fut:381:1-392:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t tmp_32490 = sub64(nR_26587, (int64_t) 1);
    bool y_32492 = slt64(tmp_32490, nR_26587);
    bool x_32491 = sle64((int64_t) 0, tmp_32490);
    bool bounds_check_32493 = x_32491 && y_32492;
    bool cond_32488 = nR_26587 == (int64_t) 0;
    bool protect_assert_disj_32494 = cond_32488 || bounds_check_32493;
    bool index_certs_32495;
    
    if (!protect_assert_disj_32494) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) tmp_32490, "] out of bounds for array of shape [", (long long) nR_26587, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:328:7-329:73\n   #3  ftSMJ.fut:392:133-136\n   #4  ftSMJ.fut:381:1-392:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    bool x_32489 = !cond_32488;
    int64_t m_f_res_32496;
    
    if (x_32489) {
        int64_t bytes_33835 = (int64_t) 8 * nR_26587;
        int64_t segscan_tblock_sizze_33635;
        
        segscan_tblock_sizze_33635 = *ctx->tuning_params.inner_SMJ_floatzisegscan_tblock_sizze_33634;
        
        int64_t num_tblocks_33637;
        int64_t max_num_tblocks_34023;
        
        max_num_tblocks_34023 = *ctx->tuning_params.inner_SMJ_floatzisegscan_num_tblocks_33636;
        num_tblocks_33637 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nR_26587, segscan_tblock_sizze_33635), max_num_tblocks_34023)));
        if (memblock_alloc_device(ctx, &mem_33836, bytes_33835, "mem_33836")) {
            err = 1;
            goto cleanup;
        }
        if (slt64((int64_t) 0, nR_26587)) {
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegScan");
            
            int64_t shared_memory_34024;
            
            shared_memory_34024 = ctx->max_shared_memory;
            
            int64_t thread_block_sizze_34025;
            
            thread_block_sizze_34025 = ctx->max_thread_block_size;
            
            int64_t registers_34026;
            
            registers_34026 = ctx->max_registers;
            
            int64_t thread_block_sizze_34027;
            
            thread_block_sizze_34027 = ctx->max_thread_block_size;
            
            int64_t chunk_sizze_34028 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_34024, thread_block_sizze_34025), (int64_t) 8), squot64(squot64(registers_34026, thread_block_sizze_34027) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
            int64_t num_virt_blocks_34029 = sdiv_up64(nR_26587, segscan_tblock_sizze_33635 * chunk_sizze_34028);
            int64_t num_virt_threads_34030 = num_virt_blocks_34029 * segscan_tblock_sizze_33635;
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_34028, '\n');
            if (memblock_alloc_device(ctx, &status_flags_mem_34031, num_virt_blocks_34029, "status_flags_mem_34031")) {
                err = 1;
                goto cleanup;
            }
            if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_34031, num_virt_blocks_34029, (int8_t) 0) != 0) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &aggregates_mem_34053, (int64_t) 8 * num_virt_blocks_34029, "aggregates_mem_34053")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &incprefixes_mem_34055, (int64_t) 8 * num_virt_blocks_34029, "incprefixes_mem_34055")) {
                err = 1;
                goto cleanup;
            }
            {
                err = gpu_kernel_inner_SMJ_floatzisegscan_33640(ctx, num_tblocks_33637, 1, 1, *ctx->tuning_params.inner_SMJ_floatzisegscan_tblock_sizze_33634, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_33635), chunk_sizze_34028 * segscan_tblock_sizze_33635 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_33635), chunk_sizze_34028 * segscan_tblock_sizze_33635 * (int64_t) 8), (int64_t) 8), (int64_t) 8), nR_26587, num_tblocks_33637, num_virt_blocks_34029, num_virt_threads_34030, mem_33836.mem, status_flags_mem_34031.mem, aggregates_mem_34053.mem, incprefixes_mem_34055.mem, global_dynid_mem_34057.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
        }
        
        int64_t read_res_34536;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_34536, mem_33836.mem, tmp_32490 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_32780 = read_res_34536;
        
        if (memblock_unref_device(ctx, &mem_33836, "mem_33836") != 0)
            return 1;
        m_f_res_32496 = x_32780;
    } else {
        m_f_res_32496 = (int64_t) 0;
    }
    
    int64_t m_32498;
    
    if (cond_32488) {
        m_32498 = (int64_t) 0;
    } else {
        m_32498 = m_f_res_32496;
    }
    
    bool eq_x_zz_32499 = (int64_t) 0 == m_f_res_32496;
    bool p_and_eq_x_y_32500 = x_32489 && eq_x_zz_32499;
    bool empty_slice_32501 = cond_32488 || p_and_eq_x_y_32500;
    int64_t m_32502 = sub64(m_32498, (int64_t) 1);
    bool zzero_leq_i_p_m_t_s_32503 = sle64((int64_t) 0, m_32502);
    bool i_p_m_t_s_leq_w_32504 = slt64(m_32502, nR_26587);
    bool i_lte_j_32505 = sle64((int64_t) 0, m_32498);
    bool y_32506 = zzero_leq_i_p_m_t_s_32503 && i_p_m_t_s_leq_w_32504;
    bool forwards_ok_32507 = i_lte_j_32505 && y_32506;
    bool ok_or_empty_32508 = empty_slice_32501 || forwards_ok_32507;
    bool index_certs_32509;
    
    if (!ok_or_empty_32508) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_32498, "] out of bounds for array of shape [", (long long) nR_26587, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:328:7-329:73\n   #3  ftSMJ.fut:392:133-136\n   #4  ftSMJ.fut:381:1-392:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_33837 = (int64_t) 4 * m_32498;
    
    if (memblock_alloc_device(ctx, &mem_33838, bytes_33837, "mem_33838")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_33838.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, tR_mem_33832.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_32498})) != 0)
        goto cleanup;
    
    int64_t bytes_33839 = (int64_t) 8 * m_32498;
    
    if (memblock_alloc_device(ctx, &mem_33840, bytes_33839, "mem_33840")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhiota_i64(ctx, mem_33840, m_32498, offset_R_26591, (int64_t) 1) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33842, bytes_33839, "mem_33842")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_33842, m_32498, (int64_t) -1) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33844, bytes_33839, "mem_33844")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_33844, m_32498, (int64_t) 0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t segmap_tblock_sizze_33645;
    
    segmap_tblock_sizze_33645 = *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_33644;
    
    int64_t num_tblocks_33647;
    int64_t max_num_tblocks_34203;
    
    max_num_tblocks_34203 = *ctx->tuning_params.inner_SMJ_floatzisegmap_num_tblocks_33646;
    num_tblocks_33647 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nR_26587, segmap_tblock_sizze_33645), max_num_tblocks_34203)));
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_34204 = sext_i64_i32(sdiv_up64(nR_26587, segmap_tblock_sizze_33645));
    
    {
        err = gpu_kernel_inner_SMJ_floatzisegmap_33642(ctx, num_tblocks_33647, 1, 1, *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_33644, 1, 1, (int64_t) 0, nR_26587, offset_R_26591, m_32498, num_tblocks_33647, virt_num_tblocks_34204, tR_mem_33832.mem, mem_33838.mem, mem_33840.mem, mem_33842.mem, mem_33844.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t segscan_tblock_sizze_33651;
    
    segscan_tblock_sizze_33651 = *ctx->tuning_params.inner_SMJ_floatzisegscan_tblock_sizze_33650;
    
    int64_t num_tblocks_33653;
    int64_t max_num_tblocks_34217;
    
    max_num_tblocks_34217 = *ctx->tuning_params.inner_SMJ_floatzisegscan_num_tblocks_33652;
    num_tblocks_33653 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_32498, segscan_tblock_sizze_33651), max_num_tblocks_34217)));
    if (memblock_alloc_device(ctx, &mem_33848, bytes_33839, "mem_33848")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33850, bytes_33839, "mem_33850")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33852, bytes_33839, "mem_33852")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, m_32498)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_34218;
        
        shared_memory_34218 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_34219;
        
        thread_block_sizze_34219 = ctx->max_thread_block_size;
        
        int64_t registers_34220;
        
        registers_34220 = ctx->max_registers;
        
        int64_t thread_block_sizze_34221;
        
        thread_block_sizze_34221 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_34222 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_34218, thread_block_sizze_34219), (int64_t) 8), squot64(squot64(registers_34220, thread_block_sizze_34221) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
        int64_t num_virt_blocks_34223 = sdiv_up64(m_32498, segscan_tblock_sizze_33651 * chunk_sizze_34222);
        int64_t num_virt_threads_34224 = num_virt_blocks_34223 * segscan_tblock_sizze_33651;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_34222, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_34225, num_virt_blocks_34223, "status_flags_mem_34225")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_34225, num_virt_blocks_34223, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_34227, (int64_t) 8 * num_virt_blocks_34223, "aggregates_mem_34227")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_34229, (int64_t) 8 * num_virt_blocks_34223, "incprefixes_mem_34229")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_34231, (int64_t) 8 * num_virt_blocks_34223, "aggregates_mem_34231")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_34233, (int64_t) 8 * num_virt_blocks_34223, "incprefixes_mem_34233")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_floatzisegscan_33656(ctx, num_tblocks_33653, 1, 1, *ctx->tuning_params.inner_SMJ_floatzisegscan_tblock_sizze_33650, 1, 1, smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_33651, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_33651), smax64(chunk_sizze_34222 * segscan_tblock_sizze_33651 * (int64_t) 8, chunk_sizze_34222 * segscan_tblock_sizze_33651 * (int64_t) 8)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_33651, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_33651), smax64(chunk_sizze_34222 * segscan_tblock_sizze_33651 * (int64_t) 8, chunk_sizze_34222 * segscan_tblock_sizze_33651 * (int64_t) 8)), (int64_t) 8), (int64_t) 8), m_32498, num_tblocks_33653, num_virt_blocks_34223, num_virt_threads_34224, mem_33844.mem, mem_33848.mem, mem_33850.mem, mem_33852.mem, status_flags_mem_34225.mem, aggregates_mem_34227.mem, incprefixes_mem_34229.mem, aggregates_mem_34231.mem, incprefixes_mem_34233.mem, global_dynid_mem_34235.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    
    int64_t segmap_tblock_sizze_33672;
    
    segmap_tblock_sizze_33672 = *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_33660;
    
    int64_t segmap_usable_groups_33673 = sdiv_up64(m_32498, segmap_tblock_sizze_33672);
    
    if (memblock_alloc_device(ctx, &mem_33855, bytes_33839, "mem_33855")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_34370 = sext_i64_i32(sdiv_up64(m_32498, segmap_tblock_sizze_33672));
    
    {
        err = gpu_kernel_inner_SMJ_floatzisegmap_33676(ctx, segmap_usable_groups_33673, 1, 1, *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_33660, 1, 1, (int64_t) 0, m_32498, mem_33848.mem, mem_33855.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_33848, "mem_33848") != 0)
        return 1;
    
    bool cond_32537 = slt64((int64_t) 0, m_32498);
    bool y_32538 = slt64(m_32502, m_32498);
    bool bounds_check_32539 = zzero_leq_i_p_m_t_s_32503 && y_32538;
    bool loop_not_taken_32540 = !cond_32537;
    bool protect_assert_disj_32541 = bounds_check_32539 || loop_not_taken_32540;
    bool index_certs_32542;
    
    if (!protect_assert_disj_32541) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) m_32502, "] out of bounds for array of shape [", (long long) m_32498, "].", "-> #0  ftSMJ.fut:285:10-41\n   #1  ftSMJ.fut:328:7-329:73\n   #2  ftSMJ.fut:392:133-136\n   #3  ftSMJ.fut:381:1-392:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    if (cond_32537) {
        if (memblock_alloc_device(ctx, &mem_33857, (int64_t) 8, "mem_33857")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_floatzigpuseq_34379(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, m_32502, mem_33855.mem, mem_33857.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_33858, &mem_33857, "mem_33857") != 0)
            return 1;
    } else {
        if (memblock_alloc_device(ctx, &mem_33856, (int64_t) 8, "mem_33856")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i64(ctx, mem_33856, (int64_t) 1, (int64_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_33858, &mem_33856, "mem_33856") != 0)
            return 1;
    }
    if (cond_32537) {
        if (memblock_alloc_device(ctx, &mem_33860, (int64_t) 8, "mem_33860")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_floatzigpuseq_34385(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, m_32502, mem_33844.mem, mem_33860.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_33861, &mem_33860, "mem_33860") != 0)
            return 1;
    } else {
        if (memblock_alloc_device(ctx, &mem_33859, (int64_t) 8, "mem_33859")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i64(ctx, mem_33859, (int64_t) 1, (int64_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_33861, &mem_33859, "mem_33859") != 0)
            return 1;
    }
    
    bool zzero_32554 = scatter_psizze_26596 == (int64_t) 0;
    bool nonzzero_32555 = !zzero_32554;
    bool nonzzero_cert_32556;
    
    if (!nonzzero_32555) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftbasics.fut:66:23-29\n   #1  ftSMJ.fut:328:7-329:73\n   #2  ftSMJ.fut:392:133-136\n   #3  ftSMJ.fut:381:1-392:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    bool x_32621 = !empty_slice_32501;
    bool protect_assert_disj_32622 = empty_slice_32501 || bounds_check_32539;
    bool index_certs_32623;
    
    if (!protect_assert_disj_32622) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) m_32502, "] out of bounds for array of shape [", (long long) m_32498, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:328:7-329:73\n   #3  ftSMJ.fut:392:133-136\n   #4  ftSMJ.fut:381:1-392:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t m_f_res_32624;
    
    if (x_32621) {
        int64_t read_res_34537;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_34537, mem_33850.mem, m_32502 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_32788 = read_res_34537;
        
        m_f_res_32624 = x_32788;
    } else {
        m_f_res_32624 = (int64_t) 0;
    }
    
    int64_t m_32626;
    
    if (empty_slice_32501) {
        m_32626 = (int64_t) 0;
    } else {
        m_32626 = m_f_res_32624;
    }
    
    int64_t m_32636 = sub64(m_32626, (int64_t) 1);
    bool i_p_m_t_s_leq_w_32638 = slt64(m_32636, m_32498);
    bool zzero_leq_i_p_m_t_s_32637 = sle64((int64_t) 0, m_32636);
    bool y_32640 = zzero_leq_i_p_m_t_s_32637 && i_p_m_t_s_leq_w_32638;
    bool i_lte_j_32639 = sle64((int64_t) 0, m_32626);
    bool forwards_ok_32641 = i_lte_j_32639 && y_32640;
    bool eq_x_zz_32633 = (int64_t) 0 == m_f_res_32624;
    bool p_and_eq_x_y_32634 = x_32621 && eq_x_zz_32633;
    bool empty_slice_32635 = empty_slice_32501 || p_and_eq_x_y_32634;
    bool ok_or_empty_32642 = empty_slice_32635 || forwards_ok_32641;
    bool index_certs_32643;
    
    if (!ok_or_empty_32642) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_32626, "] out of bounds for array of shape [", (long long) m_32498, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:328:7-329:73\n   #3  ftSMJ.fut:392:133-136\n   #4  ftSMJ.fut:381:1-392:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_33862 = (int64_t) 8 * m_32626;
    
    if (memblock_alloc_device(ctx, &mem_33867, (int64_t) 8, "mem_33867")) {
        err = 1;
        goto cleanup;
    }
    {
        err = gpu_kernel_inner_SMJ_floatzigpuseq_34391(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, ext_mem_33858.mem, ext_mem_33861.mem, mem_33867.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (memblock_unref_device(ctx, &ext_mem_33858, "ext_mem_33858") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_33861, "ext_mem_33861") != 0)
        return 1;
    
    int64_t n_pairs_t_res_32547;
    
    if (cond_32537) {
        int64_t read_res_34538;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_34538, mem_33867.mem, (int64_t) 0 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_33830 = read_res_34538;
        
        n_pairs_t_res_32547 = x_33830;
    } else {
        n_pairs_t_res_32547 = (int64_t) 0;
    }
    if (memblock_unref_device(ctx, &mem_33867, "mem_33867") != 0)
        return 1;
    
    int64_t n_pairs_32548;
    
    if (cond_32537) {
        n_pairs_32548 = n_pairs_t_res_32547;
    } else {
        n_pairs_32548 = (int64_t) 0;
    }
    
    int64_t bytes_33868 = (int64_t) 4 * n_pairs_32548;
    int64_t bytes_33870 = (int64_t) 8 * n_pairs_32548;
    int64_t segmap_tblock_sizze_33687;
    
    segmap_tblock_sizze_33687 = *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_33686;
    
    int64_t num_tblocks_33689;
    int64_t max_num_tblocks_34397;
    
    max_num_tblocks_34397 = *ctx->tuning_params.inner_SMJ_floatzisegmap_num_tblocks_33688;
    num_tblocks_33689 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_32498, segmap_tblock_sizze_33687), max_num_tblocks_34397)));
    if (memblock_alloc_device(ctx, &mem_33863, bytes_33862, "mem_33863")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33863.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_33844.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_32626})) != 0)
        goto cleanup;
    if (memblock_alloc_device(ctx, &mem_33865, bytes_33862, "mem_33865")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33865.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_33855.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_32626})) != 0)
        goto cleanup;
    
    int64_t segmap_tblock_sizze_33695;
    
    segmap_tblock_sizze_33695 = *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_33694;
    
    int64_t num_tblocks_33697;
    int64_t max_num_tblocks_34398;
    
    max_num_tblocks_34398 = *ctx->tuning_params.inner_SMJ_floatzisegmap_num_tblocks_33696;
    num_tblocks_33697 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_32498, segmap_tblock_sizze_33695), max_num_tblocks_34398)));
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_34399 = sext_i64_i32(sdiv_up64(m_32498, segmap_tblock_sizze_33695));
    
    {
        err = gpu_kernel_inner_SMJ_floatzisegmap_33692(ctx, num_tblocks_33697, 1, 1, *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_33694, 1, 1, (int64_t) 0, m_32498, m_32626, num_tblocks_33697, virt_num_tblocks_34399, mem_33844.mem, mem_33850.mem, mem_33852.mem, mem_33855.mem, mem_33863.mem, mem_33865.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_33844, "mem_33844") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33850, "mem_33850") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33852, "mem_33852") != 0)
        return 1;
    
    bool cond_32653 = slt64((int64_t) 0, m_32626);
    int64_t segmap_tblock_sizze_33710;
    
    segmap_tblock_sizze_33710 = *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_33702;
    if (memblock_alloc_device(ctx, &mem_33869, bytes_33868, "mem_33869")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_f32(ctx, mem_33869, n_pairs_32548, 0.0F) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33871, bytes_33870, "mem_33871")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_33871, n_pairs_32548, (int64_t) -1) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33873, bytes_33870, "mem_33873")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_33873, n_pairs_32548, (int64_t) -1) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t zm_lhs_32552 = add64(scatter_psizze_26596, n_pairs_32548);
    int64_t zs_lhs_32553 = sub64(zm_lhs_32552, (int64_t) 1);
    int64_t m_32557 = sdiv64(zs_lhs_32553, scatter_psizze_26596);
    bool loop_cond_32558 = slt64((int64_t) 0, m_32557);
    bool partitioned_scatter_res_32559;
    int64_t partitioned_scatter_res_32563;
    bool loop_while_32564;
    int64_t p_32568;
    
    loop_while_32564 = loop_cond_32558;
    p_32568 = (int64_t) 0;
    while (loop_while_32564) {
        int64_t lower_bound_32569 = mul64(scatter_psizze_26596, p_32568);
        int64_t min_arg1_32570 = add64(scatter_psizze_26596, lower_bound_32569);
        int64_t min_res_32571 = smin64(n_pairs_32548, min_arg1_32570);
        int64_t j_m_i_32572 = sub64(min_res_32571, lower_bound_32569);
        bool empty_slice_32573 = j_m_i_32572 == (int64_t) 0;
        int64_t m_32574 = sub64(j_m_i_32572, (int64_t) 1);
        int64_t i_p_m_t_s_32575 = add64(lower_bound_32569, m_32574);
        bool zzero_leq_i_p_m_t_s_32576 = sle64((int64_t) 0, i_p_m_t_s_32575);
        bool i_p_m_t_s_leq_w_32577 = slt64(i_p_m_t_s_32575, n_pairs_32548);
        bool zzero_lte_i_32578 = sle64((int64_t) 0, lower_bound_32569);
        bool i_lte_j_32579 = sle64(lower_bound_32569, min_res_32571);
        bool y_32580 = i_p_m_t_s_leq_w_32577 && zzero_lte_i_32578;
        bool y_32581 = zzero_leq_i_p_m_t_s_32576 && y_32580;
        bool forwards_ok_32582 = i_lte_j_32579 && y_32581;
        bool ok_or_empty_32583 = empty_slice_32573 || forwards_ok_32582;
        bool index_certs_32584;
        
        if (!ok_or_empty_32583) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) lower_bound_32569, ":", (long long) min_res_32571, "] out of bounds for array of shape [", (long long) n_pairs_32548, "].", "-> #0  ftbasics.fut:72:25-56\n   #1  ftSMJ.fut:328:7-329:73\n   #2  ftSMJ.fut:392:133-136\n   #3  ftSMJ.fut:381:1-392:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t bytes_33883 = (int64_t) 4 * j_m_i_32572;
        int64_t bytes_33885 = (int64_t) 8 * j_m_i_32572;
        
        if (memblock_alloc_device(ctx, &mem_33884, bytes_33883, "mem_33884")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_33884.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_33869.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_32569, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_32572})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_33886, bytes_33885, "mem_33886")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33886.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_33871.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_32569, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_32572})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_33888, bytes_33885, "mem_33888")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33888.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_33873.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_32569, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_32572})) != 0)
            goto cleanup;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_34437 = sext_i64_i32(sdiv_up64(m_32498, segmap_tblock_sizze_33687));
        
        {
            err = gpu_kernel_inner_SMJ_floatzisegmap_33684(ctx, num_tblocks_33689, 1, 1, *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_33686, 1, 1, (int64_t) 0, m_32498, lower_bound_32569, min_res_32571, j_m_i_32572, num_tblocks_33689, virt_num_tblocks_34437, mem_33838.mem, mem_33840.mem, mem_33842.mem, mem_33855.mem, mem_33884.mem, mem_33886.mem, mem_33888.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t tmp_32598 = add64((int64_t) 1, p_32568);
        
        if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_33869.mem, lower_bound_32569, (int64_t []) {(int64_t) 1}, mem_33884.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_32572})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_33884, "mem_33884") != 0)
            return 1;
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33871.mem, lower_bound_32569, (int64_t []) {(int64_t) 1}, mem_33886.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_32572})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_33886, "mem_33886") != 0)
            return 1;
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33873.mem, lower_bound_32569, (int64_t []) {(int64_t) 1}, mem_33888.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_32572})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_33888, "mem_33888") != 0)
            return 1;
        
        bool loop_cond_32609 = slt64(tmp_32598, m_32557);
        bool loop_while_tmp_34432 = loop_cond_32609;
        int64_t p_tmp_34436 = tmp_32598;
        
        loop_while_32564 = loop_while_tmp_34432;
        p_32568 = p_tmp_34436;
    }
    partitioned_scatter_res_32559 = loop_while_32564;
    partitioned_scatter_res_32563 = p_32568;
    if (memblock_unref_device(ctx, &mem_33838, "mem_33838") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33840, "mem_33840") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33842, "mem_33842") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33855, "mem_33855") != 0)
        return 1;
    
    bool loop_cond_t_res_32654 = slt64(m_32498, n_pairs_32548);
    bool x_32655 = cond_32653 && loop_cond_t_res_32654;
    
    if (memblock_alloc_device(ctx, &mem_33914, (int64_t) 4, "mem_33914")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33915, (int64_t) 8, "mem_33915")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33916, (int64_t) 8, "mem_33916")) {
        err = 1;
        goto cleanup;
    }
    
    bool joinTups_to_joinPairs_InnerJoin_res_32656;
    int64_t joinTups_to_joinPairs_InnerJoin_res_32660;
    bool loop_while_32661;
    int64_t p_32665;
    
    if (memblock_set_device(ctx, &mem_param_33901, &mem_33869, "mem_33869") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_33904, &mem_33871, "mem_33871") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_33907, &mem_33873, "mem_33873") != 0)
        return 1;
    loop_while_32661 = x_32655;
    p_32665 = (int64_t) 0;
    while (loop_while_32661) {
        bool x_32666 = sle64((int64_t) 0, p_32665);
        bool y_32667 = slt64(p_32665, m_32626);
        bool bounds_check_32668 = x_32666 && y_32667;
        bool index_certs_32669;
        
        if (!bounds_check_32668) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) p_32665, "] out of bounds for array of shape [", (long long) m_32626, "].", "-> #0  ftSMJ.fut:300:13-42\n   #1  ftSMJ.fut:328:7-329:73\n   #2  ftSMJ.fut:392:133-136\n   #3  ftSMJ.fut:381:1-392:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t read_res_34539;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_34539, mem_33865.mem, p_32665 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t loopres_32670 = read_res_34539;
        int64_t read_res_34540;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_34540, mem_33863.mem, p_32665 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t loopres_32671 = read_res_34540;
        bool x_32672 = sle64((int64_t) 0, loopres_32670);
        bool y_32673 = slt64(loopres_32670, n_pairs_32548);
        bool bounds_check_32674 = x_32672 && y_32673;
        bool index_certs_32675;
        
        if (!bounds_check_32674) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) loopres_32670, "] out of bounds for array of shape [", (long long) n_pairs_32548, "].", "-> #0  ftSMJ.fut:302:52-61\n   #1  ftSMJ.fut:328:7-329:73\n   #2  ftSMJ.fut:392:133-136\n   #3  ftSMJ.fut:381:1-392:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t tmp_32686 = add64(loopres_32670, loopres_32671);
        bool empty_slice_32690 = loopres_32671 == (int64_t) 0;
        int64_t m_32691 = sub64(loopres_32671, (int64_t) 1);
        int64_t i_p_m_t_s_32692 = add64(loopres_32670, m_32691);
        bool zzero_leq_i_p_m_t_s_32693 = sle64((int64_t) 0, i_p_m_t_s_32692);
        bool i_p_m_t_s_leq_w_32694 = slt64(i_p_m_t_s_32692, n_pairs_32548);
        bool i_lte_j_32695 = sle64(loopres_32670, tmp_32686);
        bool y_32696 = x_32672 && i_p_m_t_s_leq_w_32694;
        bool y_32697 = zzero_leq_i_p_m_t_s_32693 && y_32696;
        bool forwards_ok_32698 = i_lte_j_32695 && y_32697;
        bool ok_or_empty_32699 = empty_slice_32690 || forwards_ok_32698;
        bool index_certs_32700;
        
        if (!ok_or_empty_32699) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) loopres_32670, ":", (long long) tmp_32686, "] out of bounds for array of shape [", (long long) n_pairs_32548, "].", "-> #0  ftSMJ.fut:306:14-55\n   #1  ftSMJ.fut:328:7-329:73\n   #2  ftSMJ.fut:392:133-136\n   #3  ftSMJ.fut:381:1-392:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t bytes_33917 = (int64_t) 4 * loopres_32671;
        int64_t bytes_33919 = (int64_t) 8 * loopres_32671;
        int64_t segmap_usable_groups_33711 = sdiv_up64(loopres_32671, segmap_tblock_sizze_33710);
        int64_t tmp_32685 = add64((int64_t) 1, p_32665);
        
        if (memblock_alloc_device(ctx, &mem_33909, bytes_33868, "mem_33909")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_33909.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_33901.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_32548})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_33911, bytes_33870, "mem_33911")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33911.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_33904.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_32548})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_33913, bytes_33870, "mem_33913")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33913.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_33907.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_32548})) != 0)
            goto cleanup;
        
        bool cond_32704 = slt64(tmp_32685, m_32626);
        bool x_32705 = loop_cond_t_res_32654 && cond_32704;
        
        {
            err = gpu_kernel_inner_SMJ_floatzigpuseq_34458(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, loopres_32670, mem_param_33901.mem, mem_param_33904.mem, mem_param_33907.mem, mem_33914.mem, mem_33915.mem, mem_33916.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_33918, bytes_33917, "mem_33918")) {
            err = 1;
            goto cleanup;
        }
        
        int64_t replicate_n_34464 = loopres_32671;
        int64_t tblock_sizze_34469;
        
        tblock_sizze_34469 = *ctx->tuning_params.inner_SMJ_floatzitblock_sizze_34469;
        
        int64_t virt_num_tblocks_34470 = sdiv_up64(replicate_n_34464, tblock_sizze_34469);
        int64_t num_tblocks_34471 = smin64(virt_num_tblocks_34470, (int64_t) 1048576);
        
        {
            err = gpu_kernel_inner_SMJ_floatzireplicate_34465(ctx, num_tblocks_34471, 1, 1, tblock_sizze_34469, 1, 1, (int64_t) 0, loopres_32671, replicate_n_34464, virt_num_tblocks_34470, num_tblocks_34471, mem_33914.mem, mem_33918.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_33920, bytes_33919, "mem_33920")) {
            err = 1;
            goto cleanup;
        }
        
        int64_t replicate_n_34484 = loopres_32671;
        int64_t tblock_sizze_34489;
        
        tblock_sizze_34489 = *ctx->tuning_params.inner_SMJ_floatzitblock_sizze_34489;
        
        int64_t virt_num_tblocks_34490 = sdiv_up64(replicate_n_34484, tblock_sizze_34489);
        int64_t num_tblocks_34491 = smin64(virt_num_tblocks_34490, (int64_t) 1048576);
        
        {
            err = gpu_kernel_inner_SMJ_floatzireplicate_34485(ctx, num_tblocks_34491, 1, 1, tblock_sizze_34489, 1, 1, (int64_t) 0, loopres_32671, replicate_n_34484, virt_num_tblocks_34490, num_tblocks_34491, mem_33915.mem, mem_33920.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_34504 = sext_i64_i32(sdiv_up64(loopres_32671, segmap_tblock_sizze_33710));
        
        {
            err = gpu_kernel_inner_SMJ_floatzisegmap_33714(ctx, segmap_usable_groups_33711, 1, 1, *ctx->tuning_params.inner_SMJ_floatzisegmap_tblock_sizze_33702, 1, 1, (int64_t) 0, loopres_32670, loopres_32671, mem_33913.mem, mem_33916.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_33909.mem, loopres_32670, (int64_t []) {(int64_t) 1}, mem_33918.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {loopres_32671})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_33918, "mem_33918") != 0)
            return 1;
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33911.mem, loopres_32670, (int64_t []) {(int64_t) 1}, mem_33920.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {loopres_32671})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_33920, "mem_33920") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_34450, &mem_33909, "mem_33909") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_34451, &mem_33911, "mem_33911") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_34452, &mem_33913, "mem_33913") != 0)
            return 1;
        
        bool loop_while_tmp_34453 = x_32705;
        int64_t p_tmp_34457 = tmp_32685;
        
        if (memblock_set_device(ctx, &mem_param_33901, &mem_param_tmp_34450, "mem_param_tmp_34450") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_33904, &mem_param_tmp_34451, "mem_param_tmp_34451") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_33907, &mem_param_tmp_34452, "mem_param_tmp_34452") != 0)
            return 1;
        loop_while_32661 = loop_while_tmp_34453;
        p_32665 = p_tmp_34457;
    }
    if (memblock_set_device(ctx, &ext_mem_33932, &mem_param_33901, "mem_param_33901") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_33931, &mem_param_33904, "mem_param_33904") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_33930, &mem_param_33907, "mem_param_33907") != 0)
        return 1;
    joinTups_to_joinPairs_InnerJoin_res_32656 = loop_while_32661;
    joinTups_to_joinPairs_InnerJoin_res_32660 = p_32665;
    if (memblock_unref_device(ctx, &mem_33863, "mem_33863") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33865, "mem_33865") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33869, "mem_33869") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33871, "mem_33871") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33873, "mem_33873") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33914, "mem_33914") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33915, "mem_33915") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33916, "mem_33916") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_33934, bytes_33868, "mem_33934")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_33934.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_33932.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_32548})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_33932, "ext_mem_33932") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_33936, bytes_33870, "mem_33936")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33936.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_33931.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_32548})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_33931, "ext_mem_33931") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_33938, bytes_33870, "mem_33938")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33938.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_33930.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_32548})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_33930, "ext_mem_33930") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_34019, &mem_33936, "mem_33936") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_34020, &mem_33938, "mem_33938") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_34021, &mem_33934, "mem_33934") != 0)
        return 1;
    prim_out_34022 = n_pairs_32548;
    if (memblock_set_device(ctx, &*mem_out_p_34532, &mem_out_34019, "mem_out_34019") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_34533, &mem_out_34020, "mem_out_34020") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_34534, &mem_out_34021, "mem_out_34021") != 0)
        return 1;
    *out_prim_out_34535 = prim_out_34022;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_33938, "mem_33938") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33936, "mem_33936") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33934, "mem_33934") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_34452, "mem_param_tmp_34452") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_34451, "mem_param_tmp_34451") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_34450, "mem_param_tmp_34450") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33920, "mem_33920") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33918, "mem_33918") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33913, "mem_33913") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33911, "mem_33911") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33909, "mem_33909") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_33907, "mem_param_33907") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_33904, "mem_param_33904") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_33901, "mem_param_33901") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33930, "ext_mem_33930") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33931, "ext_mem_33931") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33932, "ext_mem_33932") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33916, "mem_33916") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33915, "mem_33915") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33914, "mem_33914") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33888, "mem_33888") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33886, "mem_33886") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33884, "mem_33884") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33873, "mem_33873") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33871, "mem_33871") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33869, "mem_33869") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33865, "mem_33865") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33863, "mem_33863") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33867, "mem_33867") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33859, "mem_33859") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33860, "mem_33860") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33861, "ext_mem_33861") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33856, "mem_33856") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33857, "mem_33857") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33858, "ext_mem_33858") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33855, "mem_33855") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_34233, "incprefixes_mem_34233") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_34231, "aggregates_mem_34231") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_34229, "incprefixes_mem_34229") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_34227, "aggregates_mem_34227") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_34225, "status_flags_mem_34225") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33852, "mem_33852") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33850, "mem_33850") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33848, "mem_33848") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33844, "mem_33844") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33842, "mem_33842") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33840, "mem_33840") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33838, "mem_33838") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_34055, "incprefixes_mem_34055") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_34053, "aggregates_mem_34053") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_34031, "status_flags_mem_34031") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33836, "mem_33836") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_34021, "mem_out_34021") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_34020, "mem_out_34020") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_34019, "mem_out_34019") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_inner_SMJ_int(struct futhark_context *ctx, struct memblock_device *mem_out_p_34541, struct memblock_device *mem_out_p_34542, struct memblock_device *mem_out_p_34543, int64_t *out_prim_out_34544, struct memblock_device tR_mem_33832, struct memblock_device tS_mem_33833, int64_t nR_23386, int64_t nS_23387, int64_t offset_R_23390, int64_t offset_S_23391, int64_t partitionsPerWindow_23392, int64_t numberOfWindows_23393, int64_t extParallelism_23394, int64_t scatter_psizze_23395)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_33938;
    
    mem_33938.references = NULL;
    
    struct memblock_device mem_33936;
    
    mem_33936.references = NULL;
    
    struct memblock_device mem_33934;
    
    mem_33934.references = NULL;
    
    struct memblock_device mem_param_tmp_34432;
    
    mem_param_tmp_34432.references = NULL;
    
    struct memblock_device mem_param_tmp_34431;
    
    mem_param_tmp_34431.references = NULL;
    
    struct memblock_device mem_param_tmp_34430;
    
    mem_param_tmp_34430.references = NULL;
    
    struct memblock_device mem_33920;
    
    mem_33920.references = NULL;
    
    struct memblock_device mem_33918;
    
    mem_33918.references = NULL;
    
    struct memblock_device mem_33913;
    
    mem_33913.references = NULL;
    
    struct memblock_device mem_33911;
    
    mem_33911.references = NULL;
    
    struct memblock_device mem_33909;
    
    mem_33909.references = NULL;
    
    struct memblock_device mem_param_33907;
    
    mem_param_33907.references = NULL;
    
    struct memblock_device mem_param_33904;
    
    mem_param_33904.references = NULL;
    
    struct memblock_device mem_param_33901;
    
    mem_param_33901.references = NULL;
    
    struct memblock_device ext_mem_33930;
    
    ext_mem_33930.references = NULL;
    
    struct memblock_device ext_mem_33931;
    
    ext_mem_33931.references = NULL;
    
    struct memblock_device ext_mem_33932;
    
    ext_mem_33932.references = NULL;
    
    struct memblock_device mem_33916;
    
    mem_33916.references = NULL;
    
    struct memblock_device mem_33915;
    
    mem_33915.references = NULL;
    
    struct memblock_device mem_33914;
    
    mem_33914.references = NULL;
    
    struct memblock_device mem_33888;
    
    mem_33888.references = NULL;
    
    struct memblock_device mem_33886;
    
    mem_33886.references = NULL;
    
    struct memblock_device mem_33884;
    
    mem_33884.references = NULL;
    
    struct memblock_device mem_33873;
    
    mem_33873.references = NULL;
    
    struct memblock_device mem_33871;
    
    mem_33871.references = NULL;
    
    struct memblock_device mem_33869;
    
    mem_33869.references = NULL;
    
    struct memblock_device mem_33865;
    
    mem_33865.references = NULL;
    
    struct memblock_device mem_33863;
    
    mem_33863.references = NULL;
    
    struct memblock_device mem_33867;
    
    mem_33867.references = NULL;
    
    struct memblock_device mem_33859;
    
    mem_33859.references = NULL;
    
    struct memblock_device mem_33860;
    
    mem_33860.references = NULL;
    
    struct memblock_device ext_mem_33861;
    
    ext_mem_33861.references = NULL;
    
    struct memblock_device mem_33856;
    
    mem_33856.references = NULL;
    
    struct memblock_device mem_33857;
    
    mem_33857.references = NULL;
    
    struct memblock_device ext_mem_33858;
    
    ext_mem_33858.references = NULL;
    
    struct memblock_device mem_33855;
    
    mem_33855.references = NULL;
    
    struct memblock_device incprefixes_mem_34233;
    
    incprefixes_mem_34233.references = NULL;
    
    struct memblock_device aggregates_mem_34231;
    
    aggregates_mem_34231.references = NULL;
    
    struct memblock_device incprefixes_mem_34229;
    
    incprefixes_mem_34229.references = NULL;
    
    struct memblock_device aggregates_mem_34227;
    
    aggregates_mem_34227.references = NULL;
    
    struct memblock_device status_flags_mem_34225;
    
    status_flags_mem_34225.references = NULL;
    
    struct memblock_device mem_33852;
    
    mem_33852.references = NULL;
    
    struct memblock_device mem_33850;
    
    mem_33850.references = NULL;
    
    struct memblock_device mem_33848;
    
    mem_33848.references = NULL;
    
    struct memblock_device mem_33844;
    
    mem_33844.references = NULL;
    
    struct memblock_device mem_33842;
    
    mem_33842.references = NULL;
    
    struct memblock_device mem_33840;
    
    mem_33840.references = NULL;
    
    struct memblock_device mem_33838;
    
    mem_33838.references = NULL;
    
    struct memblock_device incprefixes_mem_34055;
    
    incprefixes_mem_34055.references = NULL;
    
    struct memblock_device aggregates_mem_34053;
    
    aggregates_mem_34053.references = NULL;
    
    struct memblock_device status_flags_mem_34031;
    
    status_flags_mem_34031.references = NULL;
    
    struct memblock_device mem_33836;
    
    mem_33836.references = NULL;
    
    struct memblock_device mem_out_34021;
    
    mem_out_34021.references = NULL;
    
    struct memblock_device mem_out_34020;
    
    mem_out_34020.references = NULL;
    
    struct memblock_device mem_out_34019;
    
    mem_out_34019.references = NULL;
    
    struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
    struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
    struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
    int64_t prim_out_34022;
    int64_t rng_32477 = add64(nR_23386, offset_R_23390);
    bool bounds_invalid_upwards_32478 = slt64(rng_32477, offset_R_23390);
    bool valid_32479 = !bounds_invalid_upwards_32478;
    bool range_valid_c_32480;
    
    if (!valid_32479) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) offset_R_23390, "..<", (long long) rng_32477, " is invalid.", "-> #0  ftbasics.fut:11:25-40\n   #1  ftSMJ.fut:328:15-43\n   #2  ftSMJ.fut:366:133-136\n   #3  ftSMJ.fut:355:1-366:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t tmp_32490 = sub64(nR_23386, (int64_t) 1);
    bool y_32492 = slt64(tmp_32490, nR_23386);
    bool x_32491 = sle64((int64_t) 0, tmp_32490);
    bool bounds_check_32493 = x_32491 && y_32492;
    bool cond_32488 = nR_23386 == (int64_t) 0;
    bool protect_assert_disj_32494 = cond_32488 || bounds_check_32493;
    bool index_certs_32495;
    
    if (!protect_assert_disj_32494) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) tmp_32490, "] out of bounds for array of shape [", (long long) nR_23386, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:328:7-329:73\n   #3  ftSMJ.fut:366:133-136\n   #4  ftSMJ.fut:355:1-366:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    bool x_32489 = !cond_32488;
    int64_t m_f_res_32496;
    
    if (x_32489) {
        int64_t bytes_33835 = (int64_t) 8 * nR_23386;
        int64_t segscan_tblock_sizze_33467;
        
        segscan_tblock_sizze_33467 = *ctx->tuning_params.inner_SMJ_intzisegscan_tblock_sizze_33466;
        
        int64_t num_tblocks_33469;
        int64_t max_num_tblocks_34023;
        
        max_num_tblocks_34023 = *ctx->tuning_params.inner_SMJ_intzisegscan_num_tblocks_33468;
        num_tblocks_33469 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nR_23386, segscan_tblock_sizze_33467), max_num_tblocks_34023)));
        if (memblock_alloc_device(ctx, &mem_33836, bytes_33835, "mem_33836")) {
            err = 1;
            goto cleanup;
        }
        if (slt64((int64_t) 0, nR_23386)) {
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegScan");
            
            int64_t shared_memory_34024;
            
            shared_memory_34024 = ctx->max_shared_memory;
            
            int64_t thread_block_sizze_34025;
            
            thread_block_sizze_34025 = ctx->max_thread_block_size;
            
            int64_t registers_34026;
            
            registers_34026 = ctx->max_registers;
            
            int64_t thread_block_sizze_34027;
            
            thread_block_sizze_34027 = ctx->max_thread_block_size;
            
            int64_t chunk_sizze_34028 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_34024, thread_block_sizze_34025), (int64_t) 8), squot64(squot64(registers_34026, thread_block_sizze_34027) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
            int64_t num_virt_blocks_34029 = sdiv_up64(nR_23386, segscan_tblock_sizze_33467 * chunk_sizze_34028);
            int64_t num_virt_threads_34030 = num_virt_blocks_34029 * segscan_tblock_sizze_33467;
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_34028, '\n');
            if (memblock_alloc_device(ctx, &status_flags_mem_34031, num_virt_blocks_34029, "status_flags_mem_34031")) {
                err = 1;
                goto cleanup;
            }
            if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_34031, num_virt_blocks_34029, (int8_t) 0) != 0) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &aggregates_mem_34053, (int64_t) 8 * num_virt_blocks_34029, "aggregates_mem_34053")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &incprefixes_mem_34055, (int64_t) 8 * num_virt_blocks_34029, "incprefixes_mem_34055")) {
                err = 1;
                goto cleanup;
            }
            {
                err = gpu_kernel_inner_SMJ_intzisegscan_33472(ctx, num_tblocks_33469, 1, 1, *ctx->tuning_params.inner_SMJ_intzisegscan_tblock_sizze_33466, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_33467), chunk_sizze_34028 * segscan_tblock_sizze_33467 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_33467), chunk_sizze_34028 * segscan_tblock_sizze_33467 * (int64_t) 8), (int64_t) 8), (int64_t) 8), nR_23386, num_tblocks_33469, num_virt_blocks_34029, num_virt_threads_34030, mem_33836.mem, status_flags_mem_34031.mem, aggregates_mem_34053.mem, incprefixes_mem_34055.mem, global_dynid_mem_34057.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
        }
        
        int64_t read_res_34545;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_34545, mem_33836.mem, tmp_32490 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_32780 = read_res_34545;
        
        if (memblock_unref_device(ctx, &mem_33836, "mem_33836") != 0)
            return 1;
        m_f_res_32496 = x_32780;
    } else {
        m_f_res_32496 = (int64_t) 0;
    }
    
    int64_t m_32498;
    
    if (cond_32488) {
        m_32498 = (int64_t) 0;
    } else {
        m_32498 = m_f_res_32496;
    }
    
    bool eq_x_zz_32499 = (int64_t) 0 == m_f_res_32496;
    bool p_and_eq_x_y_32500 = x_32489 && eq_x_zz_32499;
    bool empty_slice_32501 = cond_32488 || p_and_eq_x_y_32500;
    int64_t m_32502 = sub64(m_32498, (int64_t) 1);
    bool zzero_leq_i_p_m_t_s_32503 = sle64((int64_t) 0, m_32502);
    bool i_p_m_t_s_leq_w_32504 = slt64(m_32502, nR_23386);
    bool i_lte_j_32505 = sle64((int64_t) 0, m_32498);
    bool y_32506 = zzero_leq_i_p_m_t_s_32503 && i_p_m_t_s_leq_w_32504;
    bool forwards_ok_32507 = i_lte_j_32505 && y_32506;
    bool ok_or_empty_32508 = empty_slice_32501 || forwards_ok_32507;
    bool index_certs_32509;
    
    if (!ok_or_empty_32508) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_32498, "] out of bounds for array of shape [", (long long) nR_23386, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:328:7-329:73\n   #3  ftSMJ.fut:366:133-136\n   #4  ftSMJ.fut:355:1-366:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_33837 = (int64_t) 4 * m_32498;
    
    if (memblock_alloc_device(ctx, &mem_33838, bytes_33837, "mem_33838")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_33838.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, tR_mem_33832.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_32498})) != 0)
        goto cleanup;
    
    int64_t bytes_33839 = (int64_t) 8 * m_32498;
    
    if (memblock_alloc_device(ctx, &mem_33840, bytes_33839, "mem_33840")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhiota_i64(ctx, mem_33840, m_32498, offset_R_23390, (int64_t) 1) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33842, bytes_33839, "mem_33842")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_33842, m_32498, (int64_t) -1) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33844, bytes_33839, "mem_33844")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_33844, m_32498, (int64_t) 0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t segmap_tblock_sizze_33477;
    
    segmap_tblock_sizze_33477 = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_33476;
    
    int64_t num_tblocks_33479;
    int64_t max_num_tblocks_34203;
    
    max_num_tblocks_34203 = *ctx->tuning_params.inner_SMJ_intzisegmap_num_tblocks_33478;
    num_tblocks_33479 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nR_23386, segmap_tblock_sizze_33477), max_num_tblocks_34203)));
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_34204 = sext_i64_i32(sdiv_up64(nR_23386, segmap_tblock_sizze_33477));
    
    {
        err = gpu_kernel_inner_SMJ_intzisegmap_33474(ctx, num_tblocks_33479, 1, 1, *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_33476, 1, 1, (int64_t) 0, nR_23386, offset_R_23390, m_32498, num_tblocks_33479, virt_num_tblocks_34204, tR_mem_33832.mem, mem_33838.mem, mem_33840.mem, mem_33842.mem, mem_33844.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t segscan_tblock_sizze_33483;
    
    segscan_tblock_sizze_33483 = *ctx->tuning_params.inner_SMJ_intzisegscan_tblock_sizze_33482;
    
    int64_t num_tblocks_33485;
    int64_t max_num_tblocks_34217;
    
    max_num_tblocks_34217 = *ctx->tuning_params.inner_SMJ_intzisegscan_num_tblocks_33484;
    num_tblocks_33485 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_32498, segscan_tblock_sizze_33483), max_num_tblocks_34217)));
    if (memblock_alloc_device(ctx, &mem_33848, bytes_33839, "mem_33848")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33850, bytes_33839, "mem_33850")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33852, bytes_33839, "mem_33852")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, m_32498)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_34218;
        
        shared_memory_34218 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_34219;
        
        thread_block_sizze_34219 = ctx->max_thread_block_size;
        
        int64_t registers_34220;
        
        registers_34220 = ctx->max_registers;
        
        int64_t thread_block_sizze_34221;
        
        thread_block_sizze_34221 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_34222 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_34218, thread_block_sizze_34219), (int64_t) 8), squot64(squot64(registers_34220, thread_block_sizze_34221) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
        int64_t num_virt_blocks_34223 = sdiv_up64(m_32498, segscan_tblock_sizze_33483 * chunk_sizze_34222);
        int64_t num_virt_threads_34224 = num_virt_blocks_34223 * segscan_tblock_sizze_33483;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_34222, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_34225, num_virt_blocks_34223, "status_flags_mem_34225")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_34225, num_virt_blocks_34223, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_34227, (int64_t) 8 * num_virt_blocks_34223, "aggregates_mem_34227")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_34229, (int64_t) 8 * num_virt_blocks_34223, "incprefixes_mem_34229")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_34231, (int64_t) 8 * num_virt_blocks_34223, "aggregates_mem_34231")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_34233, (int64_t) 8 * num_virt_blocks_34223, "incprefixes_mem_34233")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_intzisegscan_33488(ctx, num_tblocks_33485, 1, 1, *ctx->tuning_params.inner_SMJ_intzisegscan_tblock_sizze_33482, 1, 1, smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_33483, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_33483), smax64(chunk_sizze_34222 * segscan_tblock_sizze_33483 * (int64_t) 8, chunk_sizze_34222 * segscan_tblock_sizze_33483 * (int64_t) 8)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_33483, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_33483), smax64(chunk_sizze_34222 * segscan_tblock_sizze_33483 * (int64_t) 8, chunk_sizze_34222 * segscan_tblock_sizze_33483 * (int64_t) 8)), (int64_t) 8), (int64_t) 8), m_32498, num_tblocks_33485, num_virt_blocks_34223, num_virt_threads_34224, mem_33844.mem, mem_33848.mem, mem_33850.mem, mem_33852.mem, status_flags_mem_34225.mem, aggregates_mem_34227.mem, incprefixes_mem_34229.mem, aggregates_mem_34231.mem, incprefixes_mem_34233.mem, global_dynid_mem_34235.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    
    int64_t segmap_tblock_sizze_33504;
    
    segmap_tblock_sizze_33504 = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_33492;
    
    int64_t segmap_usable_groups_33505 = sdiv_up64(m_32498, segmap_tblock_sizze_33504);
    
    if (memblock_alloc_device(ctx, &mem_33855, bytes_33839, "mem_33855")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_34370 = sext_i64_i32(sdiv_up64(m_32498, segmap_tblock_sizze_33504));
    
    {
        err = gpu_kernel_inner_SMJ_intzisegmap_33508(ctx, segmap_usable_groups_33505, 1, 1, *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_33492, 1, 1, (int64_t) 0, m_32498, mem_33848.mem, mem_33855.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_33848, "mem_33848") != 0)
        return 1;
    
    bool cond_32537 = slt64((int64_t) 0, m_32498);
    bool y_32538 = slt64(m_32502, m_32498);
    bool bounds_check_32539 = zzero_leq_i_p_m_t_s_32503 && y_32538;
    bool loop_not_taken_32540 = !cond_32537;
    bool protect_assert_disj_32541 = bounds_check_32539 || loop_not_taken_32540;
    bool index_certs_32542;
    
    if (!protect_assert_disj_32541) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) m_32502, "] out of bounds for array of shape [", (long long) m_32498, "].", "-> #0  ftSMJ.fut:285:10-41\n   #1  ftSMJ.fut:328:7-329:73\n   #2  ftSMJ.fut:366:133-136\n   #3  ftSMJ.fut:355:1-366:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    if (cond_32537) {
        if (memblock_alloc_device(ctx, &mem_33857, (int64_t) 8, "mem_33857")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_intzigpuseq_34379(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, m_32502, mem_33855.mem, mem_33857.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_33858, &mem_33857, "mem_33857") != 0)
            return 1;
    } else {
        if (memblock_alloc_device(ctx, &mem_33856, (int64_t) 8, "mem_33856")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i64(ctx, mem_33856, (int64_t) 1, (int64_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_33858, &mem_33856, "mem_33856") != 0)
            return 1;
    }
    if (cond_32537) {
        if (memblock_alloc_device(ctx, &mem_33860, (int64_t) 8, "mem_33860")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_intzigpuseq_34385(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, m_32502, mem_33844.mem, mem_33860.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_33861, &mem_33860, "mem_33860") != 0)
            return 1;
    } else {
        if (memblock_alloc_device(ctx, &mem_33859, (int64_t) 8, "mem_33859")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i64(ctx, mem_33859, (int64_t) 1, (int64_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_33861, &mem_33859, "mem_33859") != 0)
            return 1;
    }
    
    bool zzero_32554 = scatter_psizze_23395 == (int64_t) 0;
    bool nonzzero_32555 = !zzero_32554;
    bool nonzzero_cert_32556;
    
    if (!nonzzero_32555) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftbasics.fut:66:23-29\n   #1  ftSMJ.fut:328:7-329:73\n   #2  ftSMJ.fut:366:133-136\n   #3  ftSMJ.fut:355:1-366:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    bool x_32621 = !empty_slice_32501;
    bool protect_assert_disj_32622 = empty_slice_32501 || bounds_check_32539;
    bool index_certs_32623;
    
    if (!protect_assert_disj_32622) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) m_32502, "] out of bounds for array of shape [", (long long) m_32498, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:328:7-329:73\n   #3  ftSMJ.fut:366:133-136\n   #4  ftSMJ.fut:355:1-366:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t m_f_res_32624;
    
    if (x_32621) {
        int64_t read_res_34546;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_34546, mem_33850.mem, m_32502 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_32788 = read_res_34546;
        
        m_f_res_32624 = x_32788;
    } else {
        m_f_res_32624 = (int64_t) 0;
    }
    
    int64_t m_32626;
    
    if (empty_slice_32501) {
        m_32626 = (int64_t) 0;
    } else {
        m_32626 = m_f_res_32624;
    }
    
    int64_t m_32636 = sub64(m_32626, (int64_t) 1);
    bool i_p_m_t_s_leq_w_32638 = slt64(m_32636, m_32498);
    bool zzero_leq_i_p_m_t_s_32637 = sle64((int64_t) 0, m_32636);
    bool y_32640 = zzero_leq_i_p_m_t_s_32637 && i_p_m_t_s_leq_w_32638;
    bool i_lte_j_32639 = sle64((int64_t) 0, m_32626);
    bool forwards_ok_32641 = i_lte_j_32639 && y_32640;
    bool eq_x_zz_32633 = (int64_t) 0 == m_f_res_32624;
    bool p_and_eq_x_y_32634 = x_32621 && eq_x_zz_32633;
    bool empty_slice_32635 = empty_slice_32501 || p_and_eq_x_y_32634;
    bool ok_or_empty_32642 = empty_slice_32635 || forwards_ok_32641;
    bool index_certs_32643;
    
    if (!ok_or_empty_32642) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_32626, "] out of bounds for array of shape [", (long long) m_32498, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:328:7-329:73\n   #3  ftSMJ.fut:366:133-136\n   #4  ftSMJ.fut:355:1-366:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_33862 = (int64_t) 8 * m_32626;
    
    if (memblock_alloc_device(ctx, &mem_33867, (int64_t) 8, "mem_33867")) {
        err = 1;
        goto cleanup;
    }
    {
        err = gpu_kernel_inner_SMJ_intzigpuseq_34391(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, ext_mem_33858.mem, ext_mem_33861.mem, mem_33867.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (memblock_unref_device(ctx, &ext_mem_33858, "ext_mem_33858") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_33861, "ext_mem_33861") != 0)
        return 1;
    
    int64_t n_pairs_t_res_32547;
    
    if (cond_32537) {
        int64_t read_res_34547;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_34547, mem_33867.mem, (int64_t) 0 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_33830 = read_res_34547;
        
        n_pairs_t_res_32547 = x_33830;
    } else {
        n_pairs_t_res_32547 = (int64_t) 0;
    }
    if (memblock_unref_device(ctx, &mem_33867, "mem_33867") != 0)
        return 1;
    
    int64_t n_pairs_32548;
    
    if (cond_32537) {
        n_pairs_32548 = n_pairs_t_res_32547;
    } else {
        n_pairs_32548 = (int64_t) 0;
    }
    
    int64_t bytes_33868 = (int64_t) 4 * n_pairs_32548;
    int64_t bytes_33870 = (int64_t) 8 * n_pairs_32548;
    int64_t segmap_tblock_sizze_33519;
    
    segmap_tblock_sizze_33519 = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_33518;
    
    int64_t num_tblocks_33521;
    int64_t max_num_tblocks_34397;
    
    max_num_tblocks_34397 = *ctx->tuning_params.inner_SMJ_intzisegmap_num_tblocks_33520;
    num_tblocks_33521 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_32498, segmap_tblock_sizze_33519), max_num_tblocks_34397)));
    if (memblock_alloc_device(ctx, &mem_33863, bytes_33862, "mem_33863")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33863.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_33844.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_32626})) != 0)
        goto cleanup;
    if (memblock_alloc_device(ctx, &mem_33865, bytes_33862, "mem_33865")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33865.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_33855.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_32626})) != 0)
        goto cleanup;
    
    int64_t segmap_tblock_sizze_33527;
    
    segmap_tblock_sizze_33527 = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_33526;
    
    int64_t num_tblocks_33529;
    int64_t max_num_tblocks_34398;
    
    max_num_tblocks_34398 = *ctx->tuning_params.inner_SMJ_intzisegmap_num_tblocks_33528;
    num_tblocks_33529 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_32498, segmap_tblock_sizze_33527), max_num_tblocks_34398)));
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_34399 = sext_i64_i32(sdiv_up64(m_32498, segmap_tblock_sizze_33527));
    
    {
        err = gpu_kernel_inner_SMJ_intzisegmap_33524(ctx, num_tblocks_33529, 1, 1, *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_33526, 1, 1, (int64_t) 0, m_32498, m_32626, num_tblocks_33529, virt_num_tblocks_34399, mem_33844.mem, mem_33850.mem, mem_33852.mem, mem_33855.mem, mem_33863.mem, mem_33865.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_33844, "mem_33844") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33850, "mem_33850") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33852, "mem_33852") != 0)
        return 1;
    
    bool cond_32653 = slt64((int64_t) 0, m_32626);
    int64_t segmap_tblock_sizze_33542;
    
    segmap_tblock_sizze_33542 = *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_33534;
    if (memblock_alloc_device(ctx, &mem_33869, bytes_33868, "mem_33869")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, mem_33869, n_pairs_32548, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33871, bytes_33870, "mem_33871")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_33871, n_pairs_32548, (int64_t) -1) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33873, bytes_33870, "mem_33873")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_33873, n_pairs_32548, (int64_t) -1) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t zm_lhs_32552 = add64(scatter_psizze_23395, n_pairs_32548);
    int64_t zs_lhs_32553 = sub64(zm_lhs_32552, (int64_t) 1);
    int64_t m_32557 = sdiv64(zs_lhs_32553, scatter_psizze_23395);
    bool loop_cond_32558 = slt64((int64_t) 0, m_32557);
    bool partitioned_scatter_res_32559;
    int64_t partitioned_scatter_res_32563;
    bool loop_while_32564;
    int64_t p_32568;
    
    loop_while_32564 = loop_cond_32558;
    p_32568 = (int64_t) 0;
    while (loop_while_32564) {
        int64_t lower_bound_32569 = mul64(scatter_psizze_23395, p_32568);
        int64_t min_arg1_32570 = add64(scatter_psizze_23395, lower_bound_32569);
        int64_t min_res_32571 = smin64(n_pairs_32548, min_arg1_32570);
        int64_t j_m_i_32572 = sub64(min_res_32571, lower_bound_32569);
        bool empty_slice_32573 = j_m_i_32572 == (int64_t) 0;
        int64_t m_32574 = sub64(j_m_i_32572, (int64_t) 1);
        int64_t i_p_m_t_s_32575 = add64(lower_bound_32569, m_32574);
        bool zzero_leq_i_p_m_t_s_32576 = sle64((int64_t) 0, i_p_m_t_s_32575);
        bool i_p_m_t_s_leq_w_32577 = slt64(i_p_m_t_s_32575, n_pairs_32548);
        bool zzero_lte_i_32578 = sle64((int64_t) 0, lower_bound_32569);
        bool i_lte_j_32579 = sle64(lower_bound_32569, min_res_32571);
        bool y_32580 = i_p_m_t_s_leq_w_32577 && zzero_lte_i_32578;
        bool y_32581 = zzero_leq_i_p_m_t_s_32576 && y_32580;
        bool forwards_ok_32582 = i_lte_j_32579 && y_32581;
        bool ok_or_empty_32583 = empty_slice_32573 || forwards_ok_32582;
        bool index_certs_32584;
        
        if (!ok_or_empty_32583) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) lower_bound_32569, ":", (long long) min_res_32571, "] out of bounds for array of shape [", (long long) n_pairs_32548, "].", "-> #0  ftbasics.fut:72:25-56\n   #1  ftSMJ.fut:328:7-329:73\n   #2  ftSMJ.fut:366:133-136\n   #3  ftSMJ.fut:355:1-366:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t bytes_33883 = (int64_t) 4 * j_m_i_32572;
        int64_t bytes_33885 = (int64_t) 8 * j_m_i_32572;
        
        if (memblock_alloc_device(ctx, &mem_33884, bytes_33883, "mem_33884")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_33884.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_33869.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_32569, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_32572})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_33886, bytes_33885, "mem_33886")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33886.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_33871.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_32569, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_32572})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_33888, bytes_33885, "mem_33888")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33888.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_33873.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_32569, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_32572})) != 0)
            goto cleanup;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_34417 = sext_i64_i32(sdiv_up64(m_32498, segmap_tblock_sizze_33519));
        
        {
            err = gpu_kernel_inner_SMJ_intzisegmap_33516(ctx, num_tblocks_33521, 1, 1, *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_33518, 1, 1, (int64_t) 0, m_32498, lower_bound_32569, min_res_32571, j_m_i_32572, num_tblocks_33521, virt_num_tblocks_34417, mem_33838.mem, mem_33840.mem, mem_33842.mem, mem_33855.mem, mem_33884.mem, mem_33886.mem, mem_33888.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t tmp_32598 = add64((int64_t) 1, p_32568);
        
        if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_33869.mem, lower_bound_32569, (int64_t []) {(int64_t) 1}, mem_33884.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_32572})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_33884, "mem_33884") != 0)
            return 1;
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33871.mem, lower_bound_32569, (int64_t []) {(int64_t) 1}, mem_33886.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_32572})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_33886, "mem_33886") != 0)
            return 1;
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33873.mem, lower_bound_32569, (int64_t []) {(int64_t) 1}, mem_33888.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_32572})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_33888, "mem_33888") != 0)
            return 1;
        
        bool loop_cond_32609 = slt64(tmp_32598, m_32557);
        bool loop_while_tmp_34412 = loop_cond_32609;
        int64_t p_tmp_34416 = tmp_32598;
        
        loop_while_32564 = loop_while_tmp_34412;
        p_32568 = p_tmp_34416;
    }
    partitioned_scatter_res_32559 = loop_while_32564;
    partitioned_scatter_res_32563 = p_32568;
    if (memblock_unref_device(ctx, &mem_33838, "mem_33838") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33840, "mem_33840") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33842, "mem_33842") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33855, "mem_33855") != 0)
        return 1;
    
    bool loop_cond_t_res_32654 = slt64(m_32498, n_pairs_32548);
    bool x_32655 = cond_32653 && loop_cond_t_res_32654;
    
    if (memblock_alloc_device(ctx, &mem_33914, (int64_t) 4, "mem_33914")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33915, (int64_t) 8, "mem_33915")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33916, (int64_t) 8, "mem_33916")) {
        err = 1;
        goto cleanup;
    }
    
    bool joinTups_to_joinPairs_InnerJoin_res_32656;
    int64_t joinTups_to_joinPairs_InnerJoin_res_32660;
    bool loop_while_32661;
    int64_t p_32665;
    
    if (memblock_set_device(ctx, &mem_param_33901, &mem_33869, "mem_33869") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_33904, &mem_33871, "mem_33871") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_33907, &mem_33873, "mem_33873") != 0)
        return 1;
    loop_while_32661 = x_32655;
    p_32665 = (int64_t) 0;
    while (loop_while_32661) {
        bool x_32666 = sle64((int64_t) 0, p_32665);
        bool y_32667 = slt64(p_32665, m_32626);
        bool bounds_check_32668 = x_32666 && y_32667;
        bool index_certs_32669;
        
        if (!bounds_check_32668) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) p_32665, "] out of bounds for array of shape [", (long long) m_32626, "].", "-> #0  ftSMJ.fut:300:13-42\n   #1  ftSMJ.fut:328:7-329:73\n   #2  ftSMJ.fut:366:133-136\n   #3  ftSMJ.fut:355:1-366:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t read_res_34548;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_34548, mem_33865.mem, p_32665 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t loopres_32670 = read_res_34548;
        int64_t read_res_34549;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_34549, mem_33863.mem, p_32665 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t loopres_32671 = read_res_34549;
        bool x_32672 = sle64((int64_t) 0, loopres_32670);
        bool y_32673 = slt64(loopres_32670, n_pairs_32548);
        bool bounds_check_32674 = x_32672 && y_32673;
        bool index_certs_32675;
        
        if (!bounds_check_32674) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) loopres_32670, "] out of bounds for array of shape [", (long long) n_pairs_32548, "].", "-> #0  ftSMJ.fut:302:52-61\n   #1  ftSMJ.fut:328:7-329:73\n   #2  ftSMJ.fut:366:133-136\n   #3  ftSMJ.fut:355:1-366:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t tmp_32686 = add64(loopres_32670, loopres_32671);
        bool empty_slice_32690 = loopres_32671 == (int64_t) 0;
        int64_t m_32691 = sub64(loopres_32671, (int64_t) 1);
        int64_t i_p_m_t_s_32692 = add64(loopres_32670, m_32691);
        bool zzero_leq_i_p_m_t_s_32693 = sle64((int64_t) 0, i_p_m_t_s_32692);
        bool i_p_m_t_s_leq_w_32694 = slt64(i_p_m_t_s_32692, n_pairs_32548);
        bool i_lte_j_32695 = sle64(loopres_32670, tmp_32686);
        bool y_32696 = x_32672 && i_p_m_t_s_leq_w_32694;
        bool y_32697 = zzero_leq_i_p_m_t_s_32693 && y_32696;
        bool forwards_ok_32698 = i_lte_j_32695 && y_32697;
        bool ok_or_empty_32699 = empty_slice_32690 || forwards_ok_32698;
        bool index_certs_32700;
        
        if (!ok_or_empty_32699) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) loopres_32670, ":", (long long) tmp_32686, "] out of bounds for array of shape [", (long long) n_pairs_32548, "].", "-> #0  ftSMJ.fut:306:14-55\n   #1  ftSMJ.fut:328:7-329:73\n   #2  ftSMJ.fut:366:133-136\n   #3  ftSMJ.fut:355:1-366:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t bytes_33917 = (int64_t) 4 * loopres_32671;
        int64_t bytes_33919 = (int64_t) 8 * loopres_32671;
        int64_t segmap_usable_groups_33543 = sdiv_up64(loopres_32671, segmap_tblock_sizze_33542);
        int64_t tmp_32685 = add64((int64_t) 1, p_32665);
        
        if (memblock_alloc_device(ctx, &mem_33909, bytes_33868, "mem_33909")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_33909.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_33901.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_32548})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_33911, bytes_33870, "mem_33911")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33911.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_33904.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_32548})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_33913, bytes_33870, "mem_33913")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33913.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_33907.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_32548})) != 0)
            goto cleanup;
        
        bool cond_32704 = slt64(tmp_32685, m_32626);
        bool x_32705 = loop_cond_t_res_32654 && cond_32704;
        
        {
            err = gpu_kernel_inner_SMJ_intzigpuseq_34438(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, loopres_32670, mem_param_33901.mem, mem_param_33904.mem, mem_param_33907.mem, mem_33914.mem, mem_33915.mem, mem_33916.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_33918, bytes_33917, "mem_33918")) {
            err = 1;
            goto cleanup;
        }
        
        int64_t replicate_n_34444 = loopres_32671;
        int64_t tblock_sizze_34449;
        
        tblock_sizze_34449 = *ctx->tuning_params.inner_SMJ_intzitblock_sizze_34449;
        
        int64_t virt_num_tblocks_34450 = sdiv_up64(replicate_n_34444, tblock_sizze_34449);
        int64_t num_tblocks_34451 = smin64(virt_num_tblocks_34450, (int64_t) 1048576);
        
        {
            err = gpu_kernel_inner_SMJ_intzireplicate_34445(ctx, num_tblocks_34451, 1, 1, tblock_sizze_34449, 1, 1, (int64_t) 0, loopres_32671, replicate_n_34444, virt_num_tblocks_34450, num_tblocks_34451, mem_33914.mem, mem_33918.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_33920, bytes_33919, "mem_33920")) {
            err = 1;
            goto cleanup;
        }
        
        int64_t replicate_n_34464 = loopres_32671;
        int64_t tblock_sizze_34469;
        
        tblock_sizze_34469 = *ctx->tuning_params.inner_SMJ_intzitblock_sizze_34469;
        
        int64_t virt_num_tblocks_34470 = sdiv_up64(replicate_n_34464, tblock_sizze_34469);
        int64_t num_tblocks_34471 = smin64(virt_num_tblocks_34470, (int64_t) 1048576);
        
        {
            err = gpu_kernel_inner_SMJ_intzireplicate_34465(ctx, num_tblocks_34471, 1, 1, tblock_sizze_34469, 1, 1, (int64_t) 0, loopres_32671, replicate_n_34464, virt_num_tblocks_34470, num_tblocks_34471, mem_33915.mem, mem_33920.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_34484 = sext_i64_i32(sdiv_up64(loopres_32671, segmap_tblock_sizze_33542));
        
        {
            err = gpu_kernel_inner_SMJ_intzisegmap_33546(ctx, segmap_usable_groups_33543, 1, 1, *ctx->tuning_params.inner_SMJ_intzisegmap_tblock_sizze_33534, 1, 1, (int64_t) 0, loopres_32670, loopres_32671, mem_33913.mem, mem_33916.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_33909.mem, loopres_32670, (int64_t []) {(int64_t) 1}, mem_33918.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {loopres_32671})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_33918, "mem_33918") != 0)
            return 1;
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33911.mem, loopres_32670, (int64_t []) {(int64_t) 1}, mem_33920.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {loopres_32671})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_33920, "mem_33920") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_34430, &mem_33909, "mem_33909") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_34431, &mem_33911, "mem_33911") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_34432, &mem_33913, "mem_33913") != 0)
            return 1;
        
        bool loop_while_tmp_34433 = x_32705;
        int64_t p_tmp_34437 = tmp_32685;
        
        if (memblock_set_device(ctx, &mem_param_33901, &mem_param_tmp_34430, "mem_param_tmp_34430") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_33904, &mem_param_tmp_34431, "mem_param_tmp_34431") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_33907, &mem_param_tmp_34432, "mem_param_tmp_34432") != 0)
            return 1;
        loop_while_32661 = loop_while_tmp_34433;
        p_32665 = p_tmp_34437;
    }
    if (memblock_set_device(ctx, &ext_mem_33932, &mem_param_33901, "mem_param_33901") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_33931, &mem_param_33904, "mem_param_33904") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_33930, &mem_param_33907, "mem_param_33907") != 0)
        return 1;
    joinTups_to_joinPairs_InnerJoin_res_32656 = loop_while_32661;
    joinTups_to_joinPairs_InnerJoin_res_32660 = p_32665;
    if (memblock_unref_device(ctx, &mem_33863, "mem_33863") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33865, "mem_33865") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33869, "mem_33869") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33871, "mem_33871") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33873, "mem_33873") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33914, "mem_33914") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33915, "mem_33915") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33916, "mem_33916") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_33934, bytes_33868, "mem_33934")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_33934.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_33932.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_32548})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_33932, "ext_mem_33932") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_33936, bytes_33870, "mem_33936")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33936.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_33931.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_32548})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_33931, "ext_mem_33931") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_33938, bytes_33870, "mem_33938")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33938.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_33930.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_32548})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_33930, "ext_mem_33930") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_34019, &mem_33936, "mem_33936") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_34020, &mem_33938, "mem_33938") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_34021, &mem_33934, "mem_33934") != 0)
        return 1;
    prim_out_34022 = n_pairs_32548;
    if (memblock_set_device(ctx, &*mem_out_p_34541, &mem_out_34019, "mem_out_34019") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_34542, &mem_out_34020, "mem_out_34020") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_34543, &mem_out_34021, "mem_out_34021") != 0)
        return 1;
    *out_prim_out_34544 = prim_out_34022;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_33938, "mem_33938") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33936, "mem_33936") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33934, "mem_33934") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_34432, "mem_param_tmp_34432") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_34431, "mem_param_tmp_34431") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_34430, "mem_param_tmp_34430") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33920, "mem_33920") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33918, "mem_33918") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33913, "mem_33913") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33911, "mem_33911") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33909, "mem_33909") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_33907, "mem_param_33907") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_33904, "mem_param_33904") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_33901, "mem_param_33901") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33930, "ext_mem_33930") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33931, "ext_mem_33931") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33932, "ext_mem_33932") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33916, "mem_33916") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33915, "mem_33915") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33914, "mem_33914") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33888, "mem_33888") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33886, "mem_33886") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33884, "mem_33884") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33873, "mem_33873") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33871, "mem_33871") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33869, "mem_33869") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33865, "mem_33865") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33863, "mem_33863") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33867, "mem_33867") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33859, "mem_33859") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33860, "mem_33860") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33861, "ext_mem_33861") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33856, "mem_33856") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33857, "mem_33857") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33858, "ext_mem_33858") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33855, "mem_33855") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_34233, "incprefixes_mem_34233") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_34231, "aggregates_mem_34231") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_34229, "incprefixes_mem_34229") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_34227, "aggregates_mem_34227") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_34225, "status_flags_mem_34225") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33852, "mem_33852") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33850, "mem_33850") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33848, "mem_33848") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33844, "mem_33844") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33842, "mem_33842") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33840, "mem_33840") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33838, "mem_33838") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_34055, "incprefixes_mem_34055") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_34053, "aggregates_mem_34053") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_34031, "status_flags_mem_34031") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33836, "mem_33836") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_34021, "mem_out_34021") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_34020, "mem_out_34020") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_34019, "mem_out_34019") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_inner_SMJ_long(struct futhark_context *ctx, struct memblock_device *mem_out_p_34550, struct memblock_device *mem_out_p_34551, struct memblock_device *mem_out_p_34552, int64_t *out_prim_out_34553, struct memblock_device tR_mem_33832, struct memblock_device tS_mem_33833, int64_t nR_24982, int64_t nS_24983, int64_t offset_R_24986, int64_t offset_S_24987, int64_t partitionsPerWindow_24988, int64_t numberOfWindows_24989, int64_t extParallelism_24990, int64_t scatter_psizze_24991)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_33938;
    
    mem_33938.references = NULL;
    
    struct memblock_device mem_33936;
    
    mem_33936.references = NULL;
    
    struct memblock_device mem_33934;
    
    mem_33934.references = NULL;
    
    struct memblock_device mem_param_tmp_34432;
    
    mem_param_tmp_34432.references = NULL;
    
    struct memblock_device mem_param_tmp_34431;
    
    mem_param_tmp_34431.references = NULL;
    
    struct memblock_device mem_param_tmp_34430;
    
    mem_param_tmp_34430.references = NULL;
    
    struct memblock_device mem_33920;
    
    mem_33920.references = NULL;
    
    struct memblock_device mem_33918;
    
    mem_33918.references = NULL;
    
    struct memblock_device mem_33913;
    
    mem_33913.references = NULL;
    
    struct memblock_device mem_33911;
    
    mem_33911.references = NULL;
    
    struct memblock_device mem_33909;
    
    mem_33909.references = NULL;
    
    struct memblock_device mem_param_33907;
    
    mem_param_33907.references = NULL;
    
    struct memblock_device mem_param_33904;
    
    mem_param_33904.references = NULL;
    
    struct memblock_device mem_param_33901;
    
    mem_param_33901.references = NULL;
    
    struct memblock_device ext_mem_33930;
    
    ext_mem_33930.references = NULL;
    
    struct memblock_device ext_mem_33931;
    
    ext_mem_33931.references = NULL;
    
    struct memblock_device ext_mem_33932;
    
    ext_mem_33932.references = NULL;
    
    struct memblock_device mem_33916;
    
    mem_33916.references = NULL;
    
    struct memblock_device mem_33915;
    
    mem_33915.references = NULL;
    
    struct memblock_device mem_33914;
    
    mem_33914.references = NULL;
    
    struct memblock_device mem_33888;
    
    mem_33888.references = NULL;
    
    struct memblock_device mem_33886;
    
    mem_33886.references = NULL;
    
    struct memblock_device mem_33884;
    
    mem_33884.references = NULL;
    
    struct memblock_device mem_33873;
    
    mem_33873.references = NULL;
    
    struct memblock_device mem_33871;
    
    mem_33871.references = NULL;
    
    struct memblock_device mem_33869;
    
    mem_33869.references = NULL;
    
    struct memblock_device mem_33865;
    
    mem_33865.references = NULL;
    
    struct memblock_device mem_33863;
    
    mem_33863.references = NULL;
    
    struct memblock_device mem_33867;
    
    mem_33867.references = NULL;
    
    struct memblock_device mem_33859;
    
    mem_33859.references = NULL;
    
    struct memblock_device mem_33860;
    
    mem_33860.references = NULL;
    
    struct memblock_device ext_mem_33861;
    
    ext_mem_33861.references = NULL;
    
    struct memblock_device mem_33856;
    
    mem_33856.references = NULL;
    
    struct memblock_device mem_33857;
    
    mem_33857.references = NULL;
    
    struct memblock_device ext_mem_33858;
    
    ext_mem_33858.references = NULL;
    
    struct memblock_device mem_33855;
    
    mem_33855.references = NULL;
    
    struct memblock_device incprefixes_mem_34233;
    
    incprefixes_mem_34233.references = NULL;
    
    struct memblock_device aggregates_mem_34231;
    
    aggregates_mem_34231.references = NULL;
    
    struct memblock_device incprefixes_mem_34229;
    
    incprefixes_mem_34229.references = NULL;
    
    struct memblock_device aggregates_mem_34227;
    
    aggregates_mem_34227.references = NULL;
    
    struct memblock_device status_flags_mem_34225;
    
    status_flags_mem_34225.references = NULL;
    
    struct memblock_device mem_33852;
    
    mem_33852.references = NULL;
    
    struct memblock_device mem_33850;
    
    mem_33850.references = NULL;
    
    struct memblock_device mem_33848;
    
    mem_33848.references = NULL;
    
    struct memblock_device mem_33844;
    
    mem_33844.references = NULL;
    
    struct memblock_device mem_33842;
    
    mem_33842.references = NULL;
    
    struct memblock_device mem_33840;
    
    mem_33840.references = NULL;
    
    struct memblock_device mem_33838;
    
    mem_33838.references = NULL;
    
    struct memblock_device incprefixes_mem_34055;
    
    incprefixes_mem_34055.references = NULL;
    
    struct memblock_device aggregates_mem_34053;
    
    aggregates_mem_34053.references = NULL;
    
    struct memblock_device status_flags_mem_34031;
    
    status_flags_mem_34031.references = NULL;
    
    struct memblock_device mem_33836;
    
    mem_33836.references = NULL;
    
    struct memblock_device mem_out_34021;
    
    mem_out_34021.references = NULL;
    
    struct memblock_device mem_out_34020;
    
    mem_out_34020.references = NULL;
    
    struct memblock_device mem_out_34019;
    
    mem_out_34019.references = NULL;
    
    struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
    struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
    struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
    int64_t prim_out_34022;
    int64_t rng_32477 = add64(nR_24982, offset_R_24986);
    bool bounds_invalid_upwards_32478 = slt64(rng_32477, offset_R_24986);
    bool valid_32479 = !bounds_invalid_upwards_32478;
    bool range_valid_c_32480;
    
    if (!valid_32479) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) offset_R_24986, "..<", (long long) rng_32477, " is invalid.", "-> #0  ftbasics.fut:11:25-40\n   #1  ftSMJ.fut:328:15-43\n   #2  ftSMJ.fut:379:133-136\n   #3  ftSMJ.fut:368:1-379:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t tmp_32490 = sub64(nR_24982, (int64_t) 1);
    bool y_32492 = slt64(tmp_32490, nR_24982);
    bool x_32491 = sle64((int64_t) 0, tmp_32490);
    bool bounds_check_32493 = x_32491 && y_32492;
    bool cond_32488 = nR_24982 == (int64_t) 0;
    bool protect_assert_disj_32494 = cond_32488 || bounds_check_32493;
    bool index_certs_32495;
    
    if (!protect_assert_disj_32494) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) tmp_32490, "] out of bounds for array of shape [", (long long) nR_24982, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:328:7-329:73\n   #3  ftSMJ.fut:379:133-136\n   #4  ftSMJ.fut:368:1-379:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    bool x_32489 = !cond_32488;
    int64_t m_f_res_32496;
    
    if (x_32489) {
        int64_t bytes_33835 = (int64_t) 8 * nR_24982;
        int64_t segscan_tblock_sizze_33551;
        
        segscan_tblock_sizze_33551 = *ctx->tuning_params.inner_SMJ_longzisegscan_tblock_sizze_33550;
        
        int64_t num_tblocks_33553;
        int64_t max_num_tblocks_34023;
        
        max_num_tblocks_34023 = *ctx->tuning_params.inner_SMJ_longzisegscan_num_tblocks_33552;
        num_tblocks_33553 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nR_24982, segscan_tblock_sizze_33551), max_num_tblocks_34023)));
        if (memblock_alloc_device(ctx, &mem_33836, bytes_33835, "mem_33836")) {
            err = 1;
            goto cleanup;
        }
        if (slt64((int64_t) 0, nR_24982)) {
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegScan");
            
            int64_t shared_memory_34024;
            
            shared_memory_34024 = ctx->max_shared_memory;
            
            int64_t thread_block_sizze_34025;
            
            thread_block_sizze_34025 = ctx->max_thread_block_size;
            
            int64_t registers_34026;
            
            registers_34026 = ctx->max_registers;
            
            int64_t thread_block_sizze_34027;
            
            thread_block_sizze_34027 = ctx->max_thread_block_size;
            
            int64_t chunk_sizze_34028 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_34024, thread_block_sizze_34025), (int64_t) 8), squot64(squot64(registers_34026, thread_block_sizze_34027) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
            int64_t num_virt_blocks_34029 = sdiv_up64(nR_24982, segscan_tblock_sizze_33551 * chunk_sizze_34028);
            int64_t num_virt_threads_34030 = num_virt_blocks_34029 * segscan_tblock_sizze_33551;
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_34028, '\n');
            if (memblock_alloc_device(ctx, &status_flags_mem_34031, num_virt_blocks_34029, "status_flags_mem_34031")) {
                err = 1;
                goto cleanup;
            }
            if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_34031, num_virt_blocks_34029, (int8_t) 0) != 0) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &aggregates_mem_34053, (int64_t) 8 * num_virt_blocks_34029, "aggregates_mem_34053")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &incprefixes_mem_34055, (int64_t) 8 * num_virt_blocks_34029, "incprefixes_mem_34055")) {
                err = 1;
                goto cleanup;
            }
            {
                err = gpu_kernel_inner_SMJ_longzisegscan_33556(ctx, num_tblocks_33553, 1, 1, *ctx->tuning_params.inner_SMJ_longzisegscan_tblock_sizze_33550, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_33551), chunk_sizze_34028 * segscan_tblock_sizze_33551 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_33551), chunk_sizze_34028 * segscan_tblock_sizze_33551 * (int64_t) 8), (int64_t) 8), (int64_t) 8), nR_24982, num_tblocks_33553, num_virt_blocks_34029, num_virt_threads_34030, mem_33836.mem, status_flags_mem_34031.mem, aggregates_mem_34053.mem, incprefixes_mem_34055.mem, global_dynid_mem_34057.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
        }
        
        int64_t read_res_34554;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_34554, mem_33836.mem, tmp_32490 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_32780 = read_res_34554;
        
        if (memblock_unref_device(ctx, &mem_33836, "mem_33836") != 0)
            return 1;
        m_f_res_32496 = x_32780;
    } else {
        m_f_res_32496 = (int64_t) 0;
    }
    
    int64_t m_32498;
    
    if (cond_32488) {
        m_32498 = (int64_t) 0;
    } else {
        m_32498 = m_f_res_32496;
    }
    
    bool eq_x_zz_32499 = (int64_t) 0 == m_f_res_32496;
    bool p_and_eq_x_y_32500 = x_32489 && eq_x_zz_32499;
    bool empty_slice_32501 = cond_32488 || p_and_eq_x_y_32500;
    int64_t m_32502 = sub64(m_32498, (int64_t) 1);
    bool zzero_leq_i_p_m_t_s_32503 = sle64((int64_t) 0, m_32502);
    bool i_p_m_t_s_leq_w_32504 = slt64(m_32502, nR_24982);
    bool i_lte_j_32505 = sle64((int64_t) 0, m_32498);
    bool y_32506 = zzero_leq_i_p_m_t_s_32503 && i_p_m_t_s_leq_w_32504;
    bool forwards_ok_32507 = i_lte_j_32505 && y_32506;
    bool ok_or_empty_32508 = empty_slice_32501 || forwards_ok_32507;
    bool index_certs_32509;
    
    if (!ok_or_empty_32508) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_32498, "] out of bounds for array of shape [", (long long) nR_24982, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:328:7-329:73\n   #3  ftSMJ.fut:379:133-136\n   #4  ftSMJ.fut:368:1-379:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_33837 = (int64_t) 8 * m_32498;
    
    if (memblock_alloc_device(ctx, &mem_33838, bytes_33837, "mem_33838")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33838.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, tR_mem_33832.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_32498})) != 0)
        goto cleanup;
    if (memblock_alloc_device(ctx, &mem_33840, bytes_33837, "mem_33840")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhiota_i64(ctx, mem_33840, m_32498, offset_R_24986, (int64_t) 1) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33842, bytes_33837, "mem_33842")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_33842, m_32498, (int64_t) -1) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33844, bytes_33837, "mem_33844")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_33844, m_32498, (int64_t) 0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t segmap_tblock_sizze_33561;
    
    segmap_tblock_sizze_33561 = *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_33560;
    
    int64_t num_tblocks_33563;
    int64_t max_num_tblocks_34203;
    
    max_num_tblocks_34203 = *ctx->tuning_params.inner_SMJ_longzisegmap_num_tblocks_33562;
    num_tblocks_33563 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nR_24982, segmap_tblock_sizze_33561), max_num_tblocks_34203)));
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_34204 = sext_i64_i32(sdiv_up64(nR_24982, segmap_tblock_sizze_33561));
    
    {
        err = gpu_kernel_inner_SMJ_longzisegmap_33558(ctx, num_tblocks_33563, 1, 1, *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_33560, 1, 1, (int64_t) 0, nR_24982, offset_R_24986, m_32498, num_tblocks_33563, virt_num_tblocks_34204, tR_mem_33832.mem, mem_33838.mem, mem_33840.mem, mem_33842.mem, mem_33844.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t segscan_tblock_sizze_33567;
    
    segscan_tblock_sizze_33567 = *ctx->tuning_params.inner_SMJ_longzisegscan_tblock_sizze_33566;
    
    int64_t num_tblocks_33569;
    int64_t max_num_tblocks_34217;
    
    max_num_tblocks_34217 = *ctx->tuning_params.inner_SMJ_longzisegscan_num_tblocks_33568;
    num_tblocks_33569 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_32498, segscan_tblock_sizze_33567), max_num_tblocks_34217)));
    if (memblock_alloc_device(ctx, &mem_33848, bytes_33837, "mem_33848")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33850, bytes_33837, "mem_33850")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33852, bytes_33837, "mem_33852")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, m_32498)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_34218;
        
        shared_memory_34218 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_34219;
        
        thread_block_sizze_34219 = ctx->max_thread_block_size;
        
        int64_t registers_34220;
        
        registers_34220 = ctx->max_registers;
        
        int64_t thread_block_sizze_34221;
        
        thread_block_sizze_34221 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_34222 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_34218, thread_block_sizze_34219), (int64_t) 8), squot64(squot64(registers_34220, thread_block_sizze_34221) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
        int64_t num_virt_blocks_34223 = sdiv_up64(m_32498, segscan_tblock_sizze_33567 * chunk_sizze_34222);
        int64_t num_virt_threads_34224 = num_virt_blocks_34223 * segscan_tblock_sizze_33567;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_34222, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_34225, num_virt_blocks_34223, "status_flags_mem_34225")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_34225, num_virt_blocks_34223, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_34227, (int64_t) 8 * num_virt_blocks_34223, "aggregates_mem_34227")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_34229, (int64_t) 8 * num_virt_blocks_34223, "incprefixes_mem_34229")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_34231, (int64_t) 8 * num_virt_blocks_34223, "aggregates_mem_34231")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_34233, (int64_t) 8 * num_virt_blocks_34223, "incprefixes_mem_34233")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_longzisegscan_33572(ctx, num_tblocks_33569, 1, 1, *ctx->tuning_params.inner_SMJ_longzisegscan_tblock_sizze_33566, 1, 1, smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_33567, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_33567), smax64(chunk_sizze_34222 * segscan_tblock_sizze_33567 * (int64_t) 8, chunk_sizze_34222 * segscan_tblock_sizze_33567 * (int64_t) 8)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_33567, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_33567), smax64(chunk_sizze_34222 * segscan_tblock_sizze_33567 * (int64_t) 8, chunk_sizze_34222 * segscan_tblock_sizze_33567 * (int64_t) 8)), (int64_t) 8), (int64_t) 8), m_32498, num_tblocks_33569, num_virt_blocks_34223, num_virt_threads_34224, mem_33844.mem, mem_33848.mem, mem_33850.mem, mem_33852.mem, status_flags_mem_34225.mem, aggregates_mem_34227.mem, incprefixes_mem_34229.mem, aggregates_mem_34231.mem, incprefixes_mem_34233.mem, global_dynid_mem_34235.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    
    int64_t segmap_tblock_sizze_33588;
    
    segmap_tblock_sizze_33588 = *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_33576;
    
    int64_t segmap_usable_groups_33589 = sdiv_up64(m_32498, segmap_tblock_sizze_33588);
    
    if (memblock_alloc_device(ctx, &mem_33855, bytes_33837, "mem_33855")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_34370 = sext_i64_i32(sdiv_up64(m_32498, segmap_tblock_sizze_33588));
    
    {
        err = gpu_kernel_inner_SMJ_longzisegmap_33592(ctx, segmap_usable_groups_33589, 1, 1, *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_33576, 1, 1, (int64_t) 0, m_32498, mem_33848.mem, mem_33855.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_33848, "mem_33848") != 0)
        return 1;
    
    bool cond_32537 = slt64((int64_t) 0, m_32498);
    bool y_32538 = slt64(m_32502, m_32498);
    bool bounds_check_32539 = zzero_leq_i_p_m_t_s_32503 && y_32538;
    bool loop_not_taken_32540 = !cond_32537;
    bool protect_assert_disj_32541 = bounds_check_32539 || loop_not_taken_32540;
    bool index_certs_32542;
    
    if (!protect_assert_disj_32541) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) m_32502, "] out of bounds for array of shape [", (long long) m_32498, "].", "-> #0  ftSMJ.fut:285:10-41\n   #1  ftSMJ.fut:328:7-329:73\n   #2  ftSMJ.fut:379:133-136\n   #3  ftSMJ.fut:368:1-379:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    if (cond_32537) {
        if (memblock_alloc_device(ctx, &mem_33857, (int64_t) 8, "mem_33857")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_longzigpuseq_34379(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, m_32502, mem_33855.mem, mem_33857.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_33858, &mem_33857, "mem_33857") != 0)
            return 1;
    } else {
        if (memblock_alloc_device(ctx, &mem_33856, (int64_t) 8, "mem_33856")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i64(ctx, mem_33856, (int64_t) 1, (int64_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_33858, &mem_33856, "mem_33856") != 0)
            return 1;
    }
    if (cond_32537) {
        if (memblock_alloc_device(ctx, &mem_33860, (int64_t) 8, "mem_33860")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_longzigpuseq_34385(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, m_32502, mem_33844.mem, mem_33860.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_33861, &mem_33860, "mem_33860") != 0)
            return 1;
    } else {
        if (memblock_alloc_device(ctx, &mem_33859, (int64_t) 8, "mem_33859")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i64(ctx, mem_33859, (int64_t) 1, (int64_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_33861, &mem_33859, "mem_33859") != 0)
            return 1;
    }
    
    bool zzero_32554 = scatter_psizze_24991 == (int64_t) 0;
    bool nonzzero_32555 = !zzero_32554;
    bool nonzzero_cert_32556;
    
    if (!nonzzero_32555) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftbasics.fut:66:23-29\n   #1  ftSMJ.fut:328:7-329:73\n   #2  ftSMJ.fut:379:133-136\n   #3  ftSMJ.fut:368:1-379:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    bool x_32621 = !empty_slice_32501;
    bool protect_assert_disj_32622 = empty_slice_32501 || bounds_check_32539;
    bool index_certs_32623;
    
    if (!protect_assert_disj_32622) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) m_32502, "] out of bounds for array of shape [", (long long) m_32498, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:328:7-329:73\n   #3  ftSMJ.fut:379:133-136\n   #4  ftSMJ.fut:368:1-379:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t m_f_res_32624;
    
    if (x_32621) {
        int64_t read_res_34555;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_34555, mem_33850.mem, m_32502 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_32788 = read_res_34555;
        
        m_f_res_32624 = x_32788;
    } else {
        m_f_res_32624 = (int64_t) 0;
    }
    
    int64_t m_32626;
    
    if (empty_slice_32501) {
        m_32626 = (int64_t) 0;
    } else {
        m_32626 = m_f_res_32624;
    }
    
    int64_t m_32636 = sub64(m_32626, (int64_t) 1);
    bool i_p_m_t_s_leq_w_32638 = slt64(m_32636, m_32498);
    bool zzero_leq_i_p_m_t_s_32637 = sle64((int64_t) 0, m_32636);
    bool y_32640 = zzero_leq_i_p_m_t_s_32637 && i_p_m_t_s_leq_w_32638;
    bool i_lte_j_32639 = sle64((int64_t) 0, m_32626);
    bool forwards_ok_32641 = i_lte_j_32639 && y_32640;
    bool eq_x_zz_32633 = (int64_t) 0 == m_f_res_32624;
    bool p_and_eq_x_y_32634 = x_32621 && eq_x_zz_32633;
    bool empty_slice_32635 = empty_slice_32501 || p_and_eq_x_y_32634;
    bool ok_or_empty_32642 = empty_slice_32635 || forwards_ok_32641;
    bool index_certs_32643;
    
    if (!ok_or_empty_32642) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_32626, "] out of bounds for array of shape [", (long long) m_32498, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:328:7-329:73\n   #3  ftSMJ.fut:379:133-136\n   #4  ftSMJ.fut:368:1-379:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_33862 = (int64_t) 8 * m_32626;
    
    if (memblock_alloc_device(ctx, &mem_33867, (int64_t) 8, "mem_33867")) {
        err = 1;
        goto cleanup;
    }
    {
        err = gpu_kernel_inner_SMJ_longzigpuseq_34391(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, ext_mem_33858.mem, ext_mem_33861.mem, mem_33867.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (memblock_unref_device(ctx, &ext_mem_33858, "ext_mem_33858") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_33861, "ext_mem_33861") != 0)
        return 1;
    
    int64_t n_pairs_t_res_32547;
    
    if (cond_32537) {
        int64_t read_res_34556;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_34556, mem_33867.mem, (int64_t) 0 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_33830 = read_res_34556;
        
        n_pairs_t_res_32547 = x_33830;
    } else {
        n_pairs_t_res_32547 = (int64_t) 0;
    }
    if (memblock_unref_device(ctx, &mem_33867, "mem_33867") != 0)
        return 1;
    
    int64_t n_pairs_32548;
    
    if (cond_32537) {
        n_pairs_32548 = n_pairs_t_res_32547;
    } else {
        n_pairs_32548 = (int64_t) 0;
    }
    
    int64_t bytes_33868 = (int64_t) 8 * n_pairs_32548;
    int64_t segmap_tblock_sizze_33603;
    
    segmap_tblock_sizze_33603 = *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_33602;
    
    int64_t num_tblocks_33605;
    int64_t max_num_tblocks_34397;
    
    max_num_tblocks_34397 = *ctx->tuning_params.inner_SMJ_longzisegmap_num_tblocks_33604;
    num_tblocks_33605 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_32498, segmap_tblock_sizze_33603), max_num_tblocks_34397)));
    if (memblock_alloc_device(ctx, &mem_33863, bytes_33862, "mem_33863")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33863.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_33844.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_32626})) != 0)
        goto cleanup;
    if (memblock_alloc_device(ctx, &mem_33865, bytes_33862, "mem_33865")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33865.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_33855.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_32626})) != 0)
        goto cleanup;
    
    int64_t segmap_tblock_sizze_33611;
    
    segmap_tblock_sizze_33611 = *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_33610;
    
    int64_t num_tblocks_33613;
    int64_t max_num_tblocks_34398;
    
    max_num_tblocks_34398 = *ctx->tuning_params.inner_SMJ_longzisegmap_num_tblocks_33612;
    num_tblocks_33613 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_32498, segmap_tblock_sizze_33611), max_num_tblocks_34398)));
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_34399 = sext_i64_i32(sdiv_up64(m_32498, segmap_tblock_sizze_33611));
    
    {
        err = gpu_kernel_inner_SMJ_longzisegmap_33608(ctx, num_tblocks_33613, 1, 1, *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_33610, 1, 1, (int64_t) 0, m_32498, m_32626, num_tblocks_33613, virt_num_tblocks_34399, mem_33844.mem, mem_33850.mem, mem_33852.mem, mem_33855.mem, mem_33863.mem, mem_33865.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_33844, "mem_33844") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33850, "mem_33850") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33852, "mem_33852") != 0)
        return 1;
    
    bool cond_32653 = slt64((int64_t) 0, m_32626);
    int64_t segmap_tblock_sizze_33626;
    
    segmap_tblock_sizze_33626 = *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_33618;
    if (memblock_alloc_device(ctx, &mem_33869, bytes_33868, "mem_33869")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_33869, n_pairs_32548, (int64_t) 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33871, bytes_33868, "mem_33871")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_33871, n_pairs_32548, (int64_t) -1) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33873, bytes_33868, "mem_33873")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_33873, n_pairs_32548, (int64_t) -1) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t zm_lhs_32552 = add64(scatter_psizze_24991, n_pairs_32548);
    int64_t zs_lhs_32553 = sub64(zm_lhs_32552, (int64_t) 1);
    int64_t m_32557 = sdiv64(zs_lhs_32553, scatter_psizze_24991);
    bool loop_cond_32558 = slt64((int64_t) 0, m_32557);
    bool partitioned_scatter_res_32559;
    int64_t partitioned_scatter_res_32563;
    bool loop_while_32564;
    int64_t p_32568;
    
    loop_while_32564 = loop_cond_32558;
    p_32568 = (int64_t) 0;
    while (loop_while_32564) {
        int64_t lower_bound_32569 = mul64(scatter_psizze_24991, p_32568);
        int64_t min_arg1_32570 = add64(scatter_psizze_24991, lower_bound_32569);
        int64_t min_res_32571 = smin64(n_pairs_32548, min_arg1_32570);
        int64_t j_m_i_32572 = sub64(min_res_32571, lower_bound_32569);
        bool empty_slice_32573 = j_m_i_32572 == (int64_t) 0;
        int64_t m_32574 = sub64(j_m_i_32572, (int64_t) 1);
        int64_t i_p_m_t_s_32575 = add64(lower_bound_32569, m_32574);
        bool zzero_leq_i_p_m_t_s_32576 = sle64((int64_t) 0, i_p_m_t_s_32575);
        bool i_p_m_t_s_leq_w_32577 = slt64(i_p_m_t_s_32575, n_pairs_32548);
        bool zzero_lte_i_32578 = sle64((int64_t) 0, lower_bound_32569);
        bool i_lte_j_32579 = sle64(lower_bound_32569, min_res_32571);
        bool y_32580 = i_p_m_t_s_leq_w_32577 && zzero_lte_i_32578;
        bool y_32581 = zzero_leq_i_p_m_t_s_32576 && y_32580;
        bool forwards_ok_32582 = i_lte_j_32579 && y_32581;
        bool ok_or_empty_32583 = empty_slice_32573 || forwards_ok_32582;
        bool index_certs_32584;
        
        if (!ok_or_empty_32583) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) lower_bound_32569, ":", (long long) min_res_32571, "] out of bounds for array of shape [", (long long) n_pairs_32548, "].", "-> #0  ftbasics.fut:72:25-56\n   #1  ftSMJ.fut:328:7-329:73\n   #2  ftSMJ.fut:379:133-136\n   #3  ftSMJ.fut:368:1-379:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t bytes_33883 = (int64_t) 8 * j_m_i_32572;
        
        if (memblock_alloc_device(ctx, &mem_33884, bytes_33883, "mem_33884")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33884.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_33869.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_32569, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_32572})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_33886, bytes_33883, "mem_33886")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33886.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_33871.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_32569, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_32572})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_33888, bytes_33883, "mem_33888")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33888.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_33873.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_32569, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_32572})) != 0)
            goto cleanup;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_34417 = sext_i64_i32(sdiv_up64(m_32498, segmap_tblock_sizze_33603));
        
        {
            err = gpu_kernel_inner_SMJ_longzisegmap_33600(ctx, num_tblocks_33605, 1, 1, *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_33602, 1, 1, (int64_t) 0, m_32498, lower_bound_32569, min_res_32571, j_m_i_32572, num_tblocks_33605, virt_num_tblocks_34417, mem_33838.mem, mem_33840.mem, mem_33842.mem, mem_33855.mem, mem_33884.mem, mem_33886.mem, mem_33888.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t tmp_32598 = add64((int64_t) 1, p_32568);
        
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33869.mem, lower_bound_32569, (int64_t []) {(int64_t) 1}, mem_33884.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_32572})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_33884, "mem_33884") != 0)
            return 1;
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33871.mem, lower_bound_32569, (int64_t []) {(int64_t) 1}, mem_33886.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_32572})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_33886, "mem_33886") != 0)
            return 1;
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33873.mem, lower_bound_32569, (int64_t []) {(int64_t) 1}, mem_33888.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_32572})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_33888, "mem_33888") != 0)
            return 1;
        
        bool loop_cond_32609 = slt64(tmp_32598, m_32557);
        bool loop_while_tmp_34412 = loop_cond_32609;
        int64_t p_tmp_34416 = tmp_32598;
        
        loop_while_32564 = loop_while_tmp_34412;
        p_32568 = p_tmp_34416;
    }
    partitioned_scatter_res_32559 = loop_while_32564;
    partitioned_scatter_res_32563 = p_32568;
    if (memblock_unref_device(ctx, &mem_33838, "mem_33838") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33840, "mem_33840") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33842, "mem_33842") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33855, "mem_33855") != 0)
        return 1;
    
    bool loop_cond_t_res_32654 = slt64(m_32498, n_pairs_32548);
    bool x_32655 = cond_32653 && loop_cond_t_res_32654;
    
    if (memblock_alloc_device(ctx, &mem_33914, (int64_t) 8, "mem_33914")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33915, (int64_t) 8, "mem_33915")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33916, (int64_t) 8, "mem_33916")) {
        err = 1;
        goto cleanup;
    }
    
    bool joinTups_to_joinPairs_InnerJoin_res_32656;
    int64_t joinTups_to_joinPairs_InnerJoin_res_32660;
    bool loop_while_32661;
    int64_t p_32665;
    
    if (memblock_set_device(ctx, &mem_param_33901, &mem_33869, "mem_33869") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_33904, &mem_33871, "mem_33871") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_33907, &mem_33873, "mem_33873") != 0)
        return 1;
    loop_while_32661 = x_32655;
    p_32665 = (int64_t) 0;
    while (loop_while_32661) {
        bool x_32666 = sle64((int64_t) 0, p_32665);
        bool y_32667 = slt64(p_32665, m_32626);
        bool bounds_check_32668 = x_32666 && y_32667;
        bool index_certs_32669;
        
        if (!bounds_check_32668) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) p_32665, "] out of bounds for array of shape [", (long long) m_32626, "].", "-> #0  ftSMJ.fut:300:13-42\n   #1  ftSMJ.fut:328:7-329:73\n   #2  ftSMJ.fut:379:133-136\n   #3  ftSMJ.fut:368:1-379:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t read_res_34557;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_34557, mem_33865.mem, p_32665 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t loopres_32670 = read_res_34557;
        int64_t read_res_34558;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_34558, mem_33863.mem, p_32665 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t loopres_32671 = read_res_34558;
        bool x_32672 = sle64((int64_t) 0, loopres_32670);
        bool y_32673 = slt64(loopres_32670, n_pairs_32548);
        bool bounds_check_32674 = x_32672 && y_32673;
        bool index_certs_32675;
        
        if (!bounds_check_32674) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) loopres_32670, "] out of bounds for array of shape [", (long long) n_pairs_32548, "].", "-> #0  ftSMJ.fut:302:52-61\n   #1  ftSMJ.fut:328:7-329:73\n   #2  ftSMJ.fut:379:133-136\n   #3  ftSMJ.fut:368:1-379:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t tmp_32686 = add64(loopres_32670, loopres_32671);
        bool empty_slice_32690 = loopres_32671 == (int64_t) 0;
        int64_t m_32691 = sub64(loopres_32671, (int64_t) 1);
        int64_t i_p_m_t_s_32692 = add64(loopres_32670, m_32691);
        bool zzero_leq_i_p_m_t_s_32693 = sle64((int64_t) 0, i_p_m_t_s_32692);
        bool i_p_m_t_s_leq_w_32694 = slt64(i_p_m_t_s_32692, n_pairs_32548);
        bool i_lte_j_32695 = sle64(loopres_32670, tmp_32686);
        bool y_32696 = x_32672 && i_p_m_t_s_leq_w_32694;
        bool y_32697 = zzero_leq_i_p_m_t_s_32693 && y_32696;
        bool forwards_ok_32698 = i_lte_j_32695 && y_32697;
        bool ok_or_empty_32699 = empty_slice_32690 || forwards_ok_32698;
        bool index_certs_32700;
        
        if (!ok_or_empty_32699) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) loopres_32670, ":", (long long) tmp_32686, "] out of bounds for array of shape [", (long long) n_pairs_32548, "].", "-> #0  ftSMJ.fut:306:14-55\n   #1  ftSMJ.fut:328:7-329:73\n   #2  ftSMJ.fut:379:133-136\n   #3  ftSMJ.fut:368:1-379:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t bytes_33917 = (int64_t) 8 * loopres_32671;
        int64_t segmap_usable_groups_33627 = sdiv_up64(loopres_32671, segmap_tblock_sizze_33626);
        int64_t tmp_32685 = add64((int64_t) 1, p_32665);
        
        if (memblock_alloc_device(ctx, &mem_33909, bytes_33868, "mem_33909")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33909.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_33901.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_32548})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_33911, bytes_33868, "mem_33911")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33911.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_33904.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_32548})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_33913, bytes_33868, "mem_33913")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33913.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_33907.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_32548})) != 0)
            goto cleanup;
        
        bool cond_32704 = slt64(tmp_32685, m_32626);
        bool x_32705 = loop_cond_t_res_32654 && cond_32704;
        
        {
            err = gpu_kernel_inner_SMJ_longzigpuseq_34438(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, loopres_32670, mem_param_33901.mem, mem_param_33904.mem, mem_param_33907.mem, mem_33914.mem, mem_33915.mem, mem_33916.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_33918, bytes_33917, "mem_33918")) {
            err = 1;
            goto cleanup;
        }
        
        int64_t replicate_n_34444 = loopres_32671;
        int64_t tblock_sizze_34449;
        
        tblock_sizze_34449 = *ctx->tuning_params.inner_SMJ_longzitblock_sizze_34449;
        
        int64_t virt_num_tblocks_34450 = sdiv_up64(replicate_n_34444, tblock_sizze_34449);
        int64_t num_tblocks_34451 = smin64(virt_num_tblocks_34450, (int64_t) 1048576);
        
        {
            err = gpu_kernel_inner_SMJ_longzireplicate_34445(ctx, num_tblocks_34451, 1, 1, tblock_sizze_34449, 1, 1, (int64_t) 0, loopres_32671, replicate_n_34444, virt_num_tblocks_34450, num_tblocks_34451, mem_33914.mem, mem_33918.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_33920, bytes_33917, "mem_33920")) {
            err = 1;
            goto cleanup;
        }
        
        int64_t replicate_n_34464 = loopres_32671;
        int64_t tblock_sizze_34469;
        
        tblock_sizze_34469 = *ctx->tuning_params.inner_SMJ_longzitblock_sizze_34469;
        
        int64_t virt_num_tblocks_34470 = sdiv_up64(replicate_n_34464, tblock_sizze_34469);
        int64_t num_tblocks_34471 = smin64(virt_num_tblocks_34470, (int64_t) 1048576);
        
        {
            err = gpu_kernel_inner_SMJ_longzireplicate_34465(ctx, num_tblocks_34471, 1, 1, tblock_sizze_34469, 1, 1, (int64_t) 0, loopres_32671, replicate_n_34464, virt_num_tblocks_34470, num_tblocks_34471, mem_33915.mem, mem_33920.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_34484 = sext_i64_i32(sdiv_up64(loopres_32671, segmap_tblock_sizze_33626));
        
        {
            err = gpu_kernel_inner_SMJ_longzisegmap_33630(ctx, segmap_usable_groups_33627, 1, 1, *ctx->tuning_params.inner_SMJ_longzisegmap_tblock_sizze_33618, 1, 1, (int64_t) 0, loopres_32670, loopres_32671, mem_33913.mem, mem_33916.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33909.mem, loopres_32670, (int64_t []) {(int64_t) 1}, mem_33918.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {loopres_32671})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_33918, "mem_33918") != 0)
            return 1;
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33911.mem, loopres_32670, (int64_t []) {(int64_t) 1}, mem_33920.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {loopres_32671})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_33920, "mem_33920") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_34430, &mem_33909, "mem_33909") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_34431, &mem_33911, "mem_33911") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_34432, &mem_33913, "mem_33913") != 0)
            return 1;
        
        bool loop_while_tmp_34433 = x_32705;
        int64_t p_tmp_34437 = tmp_32685;
        
        if (memblock_set_device(ctx, &mem_param_33901, &mem_param_tmp_34430, "mem_param_tmp_34430") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_33904, &mem_param_tmp_34431, "mem_param_tmp_34431") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_33907, &mem_param_tmp_34432, "mem_param_tmp_34432") != 0)
            return 1;
        loop_while_32661 = loop_while_tmp_34433;
        p_32665 = p_tmp_34437;
    }
    if (memblock_set_device(ctx, &ext_mem_33932, &mem_param_33901, "mem_param_33901") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_33931, &mem_param_33904, "mem_param_33904") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_33930, &mem_param_33907, "mem_param_33907") != 0)
        return 1;
    joinTups_to_joinPairs_InnerJoin_res_32656 = loop_while_32661;
    joinTups_to_joinPairs_InnerJoin_res_32660 = p_32665;
    if (memblock_unref_device(ctx, &mem_33863, "mem_33863") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33865, "mem_33865") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33869, "mem_33869") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33871, "mem_33871") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33873, "mem_33873") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33914, "mem_33914") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33915, "mem_33915") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33916, "mem_33916") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_33934, bytes_33868, "mem_33934")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33934.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_33932.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_32548})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_33932, "ext_mem_33932") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_33936, bytes_33868, "mem_33936")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33936.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_33931.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_32548})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_33931, "ext_mem_33931") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_33938, bytes_33868, "mem_33938")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33938.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_33930.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_32548})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_33930, "ext_mem_33930") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_34019, &mem_33936, "mem_33936") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_34020, &mem_33938, "mem_33938") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_34021, &mem_33934, "mem_33934") != 0)
        return 1;
    prim_out_34022 = n_pairs_32548;
    if (memblock_set_device(ctx, &*mem_out_p_34550, &mem_out_34019, "mem_out_34019") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_34551, &mem_out_34020, "mem_out_34020") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_34552, &mem_out_34021, "mem_out_34021") != 0)
        return 1;
    *out_prim_out_34553 = prim_out_34022;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_33938, "mem_33938") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33936, "mem_33936") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33934, "mem_33934") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_34432, "mem_param_tmp_34432") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_34431, "mem_param_tmp_34431") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_34430, "mem_param_tmp_34430") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33920, "mem_33920") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33918, "mem_33918") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33913, "mem_33913") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33911, "mem_33911") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33909, "mem_33909") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_33907, "mem_param_33907") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_33904, "mem_param_33904") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_33901, "mem_param_33901") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33930, "ext_mem_33930") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33931, "ext_mem_33931") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33932, "ext_mem_33932") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33916, "mem_33916") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33915, "mem_33915") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33914, "mem_33914") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33888, "mem_33888") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33886, "mem_33886") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33884, "mem_33884") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33873, "mem_33873") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33871, "mem_33871") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33869, "mem_33869") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33865, "mem_33865") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33863, "mem_33863") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33867, "mem_33867") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33859, "mem_33859") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33860, "mem_33860") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33861, "ext_mem_33861") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33856, "mem_33856") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33857, "mem_33857") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33858, "ext_mem_33858") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33855, "mem_33855") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_34233, "incprefixes_mem_34233") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_34231, "aggregates_mem_34231") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_34229, "incprefixes_mem_34229") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_34227, "aggregates_mem_34227") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_34225, "status_flags_mem_34225") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33852, "mem_33852") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33850, "mem_33850") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33848, "mem_33848") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33844, "mem_33844") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33842, "mem_33842") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33840, "mem_33840") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33838, "mem_33838") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_34055, "incprefixes_mem_34055") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_34053, "aggregates_mem_34053") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_34031, "status_flags_mem_34031") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33836, "mem_33836") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_34021, "mem_out_34021") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_34020, "mem_out_34020") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_34019, "mem_out_34019") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_inner_SMJ_short(struct futhark_context *ctx, struct memblock_device *mem_out_p_34559, struct memblock_device *mem_out_p_34560, struct memblock_device *mem_out_p_34561, int64_t *out_prim_out_34562, struct memblock_device tR_mem_33832, struct memblock_device tS_mem_33833, int64_t nR_21781, int64_t nS_21782, int64_t offset_R_21785, int64_t offset_S_21786, int64_t partitionsPerWindow_21787, int64_t numberOfWindows_21788, int64_t extParallelism_21789, int64_t scatter_psizze_21790)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_33938;
    
    mem_33938.references = NULL;
    
    struct memblock_device mem_33936;
    
    mem_33936.references = NULL;
    
    struct memblock_device mem_33934;
    
    mem_33934.references = NULL;
    
    struct memblock_device mem_param_tmp_34452;
    
    mem_param_tmp_34452.references = NULL;
    
    struct memblock_device mem_param_tmp_34451;
    
    mem_param_tmp_34451.references = NULL;
    
    struct memblock_device mem_param_tmp_34450;
    
    mem_param_tmp_34450.references = NULL;
    
    struct memblock_device mem_33920;
    
    mem_33920.references = NULL;
    
    struct memblock_device mem_33918;
    
    mem_33918.references = NULL;
    
    struct memblock_device mem_33913;
    
    mem_33913.references = NULL;
    
    struct memblock_device mem_33911;
    
    mem_33911.references = NULL;
    
    struct memblock_device mem_33909;
    
    mem_33909.references = NULL;
    
    struct memblock_device mem_param_33907;
    
    mem_param_33907.references = NULL;
    
    struct memblock_device mem_param_33904;
    
    mem_param_33904.references = NULL;
    
    struct memblock_device mem_param_33901;
    
    mem_param_33901.references = NULL;
    
    struct memblock_device ext_mem_33930;
    
    ext_mem_33930.references = NULL;
    
    struct memblock_device ext_mem_33931;
    
    ext_mem_33931.references = NULL;
    
    struct memblock_device ext_mem_33932;
    
    ext_mem_33932.references = NULL;
    
    struct memblock_device mem_33916;
    
    mem_33916.references = NULL;
    
    struct memblock_device mem_33915;
    
    mem_33915.references = NULL;
    
    struct memblock_device mem_33914;
    
    mem_33914.references = NULL;
    
    struct memblock_device mem_33888;
    
    mem_33888.references = NULL;
    
    struct memblock_device mem_33886;
    
    mem_33886.references = NULL;
    
    struct memblock_device mem_33884;
    
    mem_33884.references = NULL;
    
    struct memblock_device mem_33873;
    
    mem_33873.references = NULL;
    
    struct memblock_device mem_33871;
    
    mem_33871.references = NULL;
    
    struct memblock_device mem_33869;
    
    mem_33869.references = NULL;
    
    struct memblock_device mem_33865;
    
    mem_33865.references = NULL;
    
    struct memblock_device mem_33863;
    
    mem_33863.references = NULL;
    
    struct memblock_device mem_33867;
    
    mem_33867.references = NULL;
    
    struct memblock_device mem_33859;
    
    mem_33859.references = NULL;
    
    struct memblock_device mem_33860;
    
    mem_33860.references = NULL;
    
    struct memblock_device ext_mem_33861;
    
    ext_mem_33861.references = NULL;
    
    struct memblock_device mem_33856;
    
    mem_33856.references = NULL;
    
    struct memblock_device mem_33857;
    
    mem_33857.references = NULL;
    
    struct memblock_device ext_mem_33858;
    
    ext_mem_33858.references = NULL;
    
    struct memblock_device mem_33855;
    
    mem_33855.references = NULL;
    
    struct memblock_device incprefixes_mem_34233;
    
    incprefixes_mem_34233.references = NULL;
    
    struct memblock_device aggregates_mem_34231;
    
    aggregates_mem_34231.references = NULL;
    
    struct memblock_device incprefixes_mem_34229;
    
    incprefixes_mem_34229.references = NULL;
    
    struct memblock_device aggregates_mem_34227;
    
    aggregates_mem_34227.references = NULL;
    
    struct memblock_device status_flags_mem_34225;
    
    status_flags_mem_34225.references = NULL;
    
    struct memblock_device mem_33852;
    
    mem_33852.references = NULL;
    
    struct memblock_device mem_33850;
    
    mem_33850.references = NULL;
    
    struct memblock_device mem_33848;
    
    mem_33848.references = NULL;
    
    struct memblock_device mem_33844;
    
    mem_33844.references = NULL;
    
    struct memblock_device mem_33842;
    
    mem_33842.references = NULL;
    
    struct memblock_device mem_33840;
    
    mem_33840.references = NULL;
    
    struct memblock_device mem_33838;
    
    mem_33838.references = NULL;
    
    struct memblock_device incprefixes_mem_34055;
    
    incprefixes_mem_34055.references = NULL;
    
    struct memblock_device aggregates_mem_34053;
    
    aggregates_mem_34053.references = NULL;
    
    struct memblock_device status_flags_mem_34031;
    
    status_flags_mem_34031.references = NULL;
    
    struct memblock_device mem_33836;
    
    mem_33836.references = NULL;
    
    struct memblock_device mem_out_34021;
    
    mem_out_34021.references = NULL;
    
    struct memblock_device mem_out_34020;
    
    mem_out_34020.references = NULL;
    
    struct memblock_device mem_out_34019;
    
    mem_out_34019.references = NULL;
    
    struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
    struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
    struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
    int64_t prim_out_34022;
    int64_t rng_32477 = add64(nR_21781, offset_R_21785);
    bool bounds_invalid_upwards_32478 = slt64(rng_32477, offset_R_21785);
    bool valid_32479 = !bounds_invalid_upwards_32478;
    bool range_valid_c_32480;
    
    if (!valid_32479) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) offset_R_21785, "..<", (long long) rng_32477, " is invalid.", "-> #0  ftbasics.fut:11:25-40\n   #1  ftSMJ.fut:328:15-43\n   #2  ftSMJ.fut:353:133-136\n   #3  ftSMJ.fut:342:1-353:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t tmp_32490 = sub64(nR_21781, (int64_t) 1);
    bool y_32492 = slt64(tmp_32490, nR_21781);
    bool x_32491 = sle64((int64_t) 0, tmp_32490);
    bool bounds_check_32493 = x_32491 && y_32492;
    bool cond_32488 = nR_21781 == (int64_t) 0;
    bool protect_assert_disj_32494 = cond_32488 || bounds_check_32493;
    bool index_certs_32495;
    
    if (!protect_assert_disj_32494) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) tmp_32490, "] out of bounds for array of shape [", (long long) nR_21781, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:328:7-329:73\n   #3  ftSMJ.fut:353:133-136\n   #4  ftSMJ.fut:342:1-353:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    bool x_32489 = !cond_32488;
    int64_t m_f_res_32496;
    
    if (x_32489) {
        int64_t bytes_33835 = (int64_t) 8 * nR_21781;
        int64_t segscan_tblock_sizze_33383;
        
        segscan_tblock_sizze_33383 = *ctx->tuning_params.inner_SMJ_shortzisegscan_tblock_sizze_33382;
        
        int64_t num_tblocks_33385;
        int64_t max_num_tblocks_34023;
        
        max_num_tblocks_34023 = *ctx->tuning_params.inner_SMJ_shortzisegscan_num_tblocks_33384;
        num_tblocks_33385 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nR_21781, segscan_tblock_sizze_33383), max_num_tblocks_34023)));
        if (memblock_alloc_device(ctx, &mem_33836, bytes_33835, "mem_33836")) {
            err = 1;
            goto cleanup;
        }
        if (slt64((int64_t) 0, nR_21781)) {
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegScan");
            
            int64_t shared_memory_34024;
            
            shared_memory_34024 = ctx->max_shared_memory;
            
            int64_t thread_block_sizze_34025;
            
            thread_block_sizze_34025 = ctx->max_thread_block_size;
            
            int64_t registers_34026;
            
            registers_34026 = ctx->max_registers;
            
            int64_t thread_block_sizze_34027;
            
            thread_block_sizze_34027 = ctx->max_thread_block_size;
            
            int64_t chunk_sizze_34028 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_34024, thread_block_sizze_34025), (int64_t) 8), squot64(squot64(registers_34026, thread_block_sizze_34027) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
            int64_t num_virt_blocks_34029 = sdiv_up64(nR_21781, segscan_tblock_sizze_33383 * chunk_sizze_34028);
            int64_t num_virt_threads_34030 = num_virt_blocks_34029 * segscan_tblock_sizze_33383;
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_34028, '\n');
            if (memblock_alloc_device(ctx, &status_flags_mem_34031, num_virt_blocks_34029, "status_flags_mem_34031")) {
                err = 1;
                goto cleanup;
            }
            if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_34031, num_virt_blocks_34029, (int8_t) 0) != 0) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &aggregates_mem_34053, (int64_t) 8 * num_virt_blocks_34029, "aggregates_mem_34053")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &incprefixes_mem_34055, (int64_t) 8 * num_virt_blocks_34029, "incprefixes_mem_34055")) {
                err = 1;
                goto cleanup;
            }
            {
                err = gpu_kernel_inner_SMJ_shortzisegscan_33388(ctx, num_tblocks_33385, 1, 1, *ctx->tuning_params.inner_SMJ_shortzisegscan_tblock_sizze_33382, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_33383), chunk_sizze_34028 * segscan_tblock_sizze_33383 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_33383), chunk_sizze_34028 * segscan_tblock_sizze_33383 * (int64_t) 8), (int64_t) 8), (int64_t) 8), nR_21781, num_tblocks_33385, num_virt_blocks_34029, num_virt_threads_34030, mem_33836.mem, status_flags_mem_34031.mem, aggregates_mem_34053.mem, incprefixes_mem_34055.mem, global_dynid_mem_34057.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
        }
        
        int64_t read_res_34563;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_34563, mem_33836.mem, tmp_32490 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_32780 = read_res_34563;
        
        if (memblock_unref_device(ctx, &mem_33836, "mem_33836") != 0)
            return 1;
        m_f_res_32496 = x_32780;
    } else {
        m_f_res_32496 = (int64_t) 0;
    }
    
    int64_t m_32498;
    
    if (cond_32488) {
        m_32498 = (int64_t) 0;
    } else {
        m_32498 = m_f_res_32496;
    }
    
    bool eq_x_zz_32499 = (int64_t) 0 == m_f_res_32496;
    bool p_and_eq_x_y_32500 = x_32489 && eq_x_zz_32499;
    bool empty_slice_32501 = cond_32488 || p_and_eq_x_y_32500;
    int64_t m_32502 = sub64(m_32498, (int64_t) 1);
    bool zzero_leq_i_p_m_t_s_32503 = sle64((int64_t) 0, m_32502);
    bool i_p_m_t_s_leq_w_32504 = slt64(m_32502, nR_21781);
    bool i_lte_j_32505 = sle64((int64_t) 0, m_32498);
    bool y_32506 = zzero_leq_i_p_m_t_s_32503 && i_p_m_t_s_leq_w_32504;
    bool forwards_ok_32507 = i_lte_j_32505 && y_32506;
    bool ok_or_empty_32508 = empty_slice_32501 || forwards_ok_32507;
    bool index_certs_32509;
    
    if (!ok_or_empty_32508) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_32498, "] out of bounds for array of shape [", (long long) nR_21781, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:328:7-329:73\n   #3  ftSMJ.fut:353:133-136\n   #4  ftSMJ.fut:342:1-353:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_33837 = (int64_t) 2 * m_32498;
    
    if (memblock_alloc_device(ctx, &mem_33838, bytes_33837, "mem_33838")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_2b(ctx, 1, mem_33838.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, tR_mem_33832.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_32498})) != 0)
        goto cleanup;
    
    int64_t bytes_33839 = (int64_t) 8 * m_32498;
    
    if (memblock_alloc_device(ctx, &mem_33840, bytes_33839, "mem_33840")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhiota_i64(ctx, mem_33840, m_32498, offset_R_21785, (int64_t) 1) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33842, bytes_33839, "mem_33842")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_33842, m_32498, (int64_t) -1) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33844, bytes_33839, "mem_33844")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_33844, m_32498, (int64_t) 0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t segmap_tblock_sizze_33393;
    
    segmap_tblock_sizze_33393 = *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_33392;
    
    int64_t num_tblocks_33395;
    int64_t max_num_tblocks_34203;
    
    max_num_tblocks_34203 = *ctx->tuning_params.inner_SMJ_shortzisegmap_num_tblocks_33394;
    num_tblocks_33395 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nR_21781, segmap_tblock_sizze_33393), max_num_tblocks_34203)));
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_34204 = sext_i64_i32(sdiv_up64(nR_21781, segmap_tblock_sizze_33393));
    
    {
        err = gpu_kernel_inner_SMJ_shortzisegmap_33390(ctx, num_tblocks_33395, 1, 1, *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_33392, 1, 1, (int64_t) 0, nR_21781, offset_R_21785, m_32498, num_tblocks_33395, virt_num_tblocks_34204, tR_mem_33832.mem, mem_33838.mem, mem_33840.mem, mem_33842.mem, mem_33844.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t segscan_tblock_sizze_33399;
    
    segscan_tblock_sizze_33399 = *ctx->tuning_params.inner_SMJ_shortzisegscan_tblock_sizze_33398;
    
    int64_t num_tblocks_33401;
    int64_t max_num_tblocks_34217;
    
    max_num_tblocks_34217 = *ctx->tuning_params.inner_SMJ_shortzisegscan_num_tblocks_33400;
    num_tblocks_33401 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_32498, segscan_tblock_sizze_33399), max_num_tblocks_34217)));
    if (memblock_alloc_device(ctx, &mem_33848, bytes_33839, "mem_33848")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33850, bytes_33839, "mem_33850")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33852, bytes_33839, "mem_33852")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, m_32498)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_34218;
        
        shared_memory_34218 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_34219;
        
        thread_block_sizze_34219 = ctx->max_thread_block_size;
        
        int64_t registers_34220;
        
        registers_34220 = ctx->max_registers;
        
        int64_t thread_block_sizze_34221;
        
        thread_block_sizze_34221 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_34222 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_34218, thread_block_sizze_34219), (int64_t) 8), squot64(squot64(registers_34220, thread_block_sizze_34221) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
        int64_t num_virt_blocks_34223 = sdiv_up64(m_32498, segscan_tblock_sizze_33399 * chunk_sizze_34222);
        int64_t num_virt_threads_34224 = num_virt_blocks_34223 * segscan_tblock_sizze_33399;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_34222, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_34225, num_virt_blocks_34223, "status_flags_mem_34225")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_34225, num_virt_blocks_34223, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_34227, (int64_t) 8 * num_virt_blocks_34223, "aggregates_mem_34227")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_34229, (int64_t) 8 * num_virt_blocks_34223, "incprefixes_mem_34229")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_34231, (int64_t) 8 * num_virt_blocks_34223, "aggregates_mem_34231")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_34233, (int64_t) 8 * num_virt_blocks_34223, "incprefixes_mem_34233")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_shortzisegscan_33404(ctx, num_tblocks_33401, 1, 1, *ctx->tuning_params.inner_SMJ_shortzisegscan_tblock_sizze_33398, 1, 1, smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_33399, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_33399), smax64(chunk_sizze_34222 * segscan_tblock_sizze_33399 * (int64_t) 8, chunk_sizze_34222 * segscan_tblock_sizze_33399 * (int64_t) 8)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 544, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_33399, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_33399), smax64(chunk_sizze_34222 * segscan_tblock_sizze_33399 * (int64_t) 8, chunk_sizze_34222 * segscan_tblock_sizze_33399 * (int64_t) 8)), (int64_t) 8), (int64_t) 8), m_32498, num_tblocks_33401, num_virt_blocks_34223, num_virt_threads_34224, mem_33844.mem, mem_33848.mem, mem_33850.mem, mem_33852.mem, status_flags_mem_34225.mem, aggregates_mem_34227.mem, incprefixes_mem_34229.mem, aggregates_mem_34231.mem, incprefixes_mem_34233.mem, global_dynid_mem_34235.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    
    int64_t segmap_tblock_sizze_33420;
    
    segmap_tblock_sizze_33420 = *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_33408;
    
    int64_t segmap_usable_groups_33421 = sdiv_up64(m_32498, segmap_tblock_sizze_33420);
    
    if (memblock_alloc_device(ctx, &mem_33855, bytes_33839, "mem_33855")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_34370 = sext_i64_i32(sdiv_up64(m_32498, segmap_tblock_sizze_33420));
    
    {
        err = gpu_kernel_inner_SMJ_shortzisegmap_33424(ctx, segmap_usable_groups_33421, 1, 1, *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_33408, 1, 1, (int64_t) 0, m_32498, mem_33848.mem, mem_33855.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_33848, "mem_33848") != 0)
        return 1;
    
    bool cond_32537 = slt64((int64_t) 0, m_32498);
    bool y_32538 = slt64(m_32502, m_32498);
    bool bounds_check_32539 = zzero_leq_i_p_m_t_s_32503 && y_32538;
    bool loop_not_taken_32540 = !cond_32537;
    bool protect_assert_disj_32541 = bounds_check_32539 || loop_not_taken_32540;
    bool index_certs_32542;
    
    if (!protect_assert_disj_32541) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) m_32502, "] out of bounds for array of shape [", (long long) m_32498, "].", "-> #0  ftSMJ.fut:285:10-41\n   #1  ftSMJ.fut:328:7-329:73\n   #2  ftSMJ.fut:353:133-136\n   #3  ftSMJ.fut:342:1-353:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    if (cond_32537) {
        if (memblock_alloc_device(ctx, &mem_33857, (int64_t) 8, "mem_33857")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_shortzigpuseq_34379(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, m_32502, mem_33855.mem, mem_33857.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_33858, &mem_33857, "mem_33857") != 0)
            return 1;
    } else {
        if (memblock_alloc_device(ctx, &mem_33856, (int64_t) 8, "mem_33856")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i64(ctx, mem_33856, (int64_t) 1, (int64_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_33858, &mem_33856, "mem_33856") != 0)
            return 1;
    }
    if (cond_32537) {
        if (memblock_alloc_device(ctx, &mem_33860, (int64_t) 8, "mem_33860")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_inner_SMJ_shortzigpuseq_34385(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, m_32502, mem_33844.mem, mem_33860.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_33861, &mem_33860, "mem_33860") != 0)
            return 1;
    } else {
        if (memblock_alloc_device(ctx, &mem_33859, (int64_t) 8, "mem_33859")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i64(ctx, mem_33859, (int64_t) 1, (int64_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_set_device(ctx, &ext_mem_33861, &mem_33859, "mem_33859") != 0)
            return 1;
    }
    
    bool zzero_32554 = scatter_psizze_21790 == (int64_t) 0;
    bool nonzzero_32555 = !zzero_32554;
    bool nonzzero_cert_32556;
    
    if (!nonzzero_32555) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "division by zero", "-> #0  ftbasics.fut:66:23-29\n   #1  ftSMJ.fut:328:7-329:73\n   #2  ftSMJ.fut:353:133-136\n   #3  ftSMJ.fut:342:1-353:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    bool x_32621 = !empty_slice_32501;
    bool protect_assert_disj_32622 = empty_slice_32501 || bounds_check_32539;
    bool index_certs_32623;
    
    if (!protect_assert_disj_32622) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) m_32502, "] out of bounds for array of shape [", (long long) m_32498, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:328:7-329:73\n   #3  ftSMJ.fut:353:133-136\n   #4  ftSMJ.fut:342:1-353:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t m_f_res_32624;
    
    if (x_32621) {
        int64_t read_res_34564;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_34564, mem_33850.mem, m_32502 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_32788 = read_res_34564;
        
        m_f_res_32624 = x_32788;
    } else {
        m_f_res_32624 = (int64_t) 0;
    }
    
    int64_t m_32626;
    
    if (empty_slice_32501) {
        m_32626 = (int64_t) 0;
    } else {
        m_32626 = m_f_res_32624;
    }
    
    int64_t m_32636 = sub64(m_32626, (int64_t) 1);
    bool i_p_m_t_s_leq_w_32638 = slt64(m_32636, m_32498);
    bool zzero_leq_i_p_m_t_s_32637 = sle64((int64_t) 0, m_32636);
    bool y_32640 = zzero_leq_i_p_m_t_s_32637 && i_p_m_t_s_leq_w_32638;
    bool i_lte_j_32639 = sle64((int64_t) 0, m_32626);
    bool forwards_ok_32641 = i_lte_j_32639 && y_32640;
    bool eq_x_zz_32633 = (int64_t) 0 == m_f_res_32624;
    bool p_and_eq_x_y_32634 = x_32621 && eq_x_zz_32633;
    bool empty_slice_32635 = empty_slice_32501 || p_and_eq_x_y_32634;
    bool ok_or_empty_32642 = empty_slice_32635 || forwards_ok_32641;
    bool index_certs_32643;
    
    if (!ok_or_empty_32642) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_32626, "] out of bounds for array of shape [", (long long) m_32498, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n   #2  ftSMJ.fut:328:7-329:73\n   #3  ftSMJ.fut:353:133-136\n   #4  ftSMJ.fut:342:1-353:136\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_33862 = (int64_t) 8 * m_32626;
    
    if (memblock_alloc_device(ctx, &mem_33867, (int64_t) 8, "mem_33867")) {
        err = 1;
        goto cleanup;
    }
    {
        err = gpu_kernel_inner_SMJ_shortzigpuseq_34391(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, ext_mem_33858.mem, ext_mem_33861.mem, mem_33867.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (memblock_unref_device(ctx, &ext_mem_33858, "ext_mem_33858") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_33861, "ext_mem_33861") != 0)
        return 1;
    
    int64_t n_pairs_t_res_32547;
    
    if (cond_32537) {
        int64_t read_res_34565;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_34565, mem_33867.mem, (int64_t) 0 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_33830 = read_res_34565;
        
        n_pairs_t_res_32547 = x_33830;
    } else {
        n_pairs_t_res_32547 = (int64_t) 0;
    }
    if (memblock_unref_device(ctx, &mem_33867, "mem_33867") != 0)
        return 1;
    
    int64_t n_pairs_32548;
    
    if (cond_32537) {
        n_pairs_32548 = n_pairs_t_res_32547;
    } else {
        n_pairs_32548 = (int64_t) 0;
    }
    
    int64_t bytes_33868 = (int64_t) 2 * n_pairs_32548;
    int64_t bytes_33870 = (int64_t) 8 * n_pairs_32548;
    int64_t segmap_tblock_sizze_33435;
    
    segmap_tblock_sizze_33435 = *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_33434;
    
    int64_t num_tblocks_33437;
    int64_t max_num_tblocks_34397;
    
    max_num_tblocks_34397 = *ctx->tuning_params.inner_SMJ_shortzisegmap_num_tblocks_33436;
    num_tblocks_33437 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_32498, segmap_tblock_sizze_33435), max_num_tblocks_34397)));
    if (memblock_alloc_device(ctx, &mem_33863, bytes_33862, "mem_33863")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33863.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_33844.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_32626})) != 0)
        goto cleanup;
    if (memblock_alloc_device(ctx, &mem_33865, bytes_33862, "mem_33865")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33865.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_33855.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_32626})) != 0)
        goto cleanup;
    
    int64_t segmap_tblock_sizze_33443;
    
    segmap_tblock_sizze_33443 = *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_33442;
    
    int64_t num_tblocks_33445;
    int64_t max_num_tblocks_34398;
    
    max_num_tblocks_34398 = *ctx->tuning_params.inner_SMJ_shortzisegmap_num_tblocks_33444;
    num_tblocks_33445 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_32498, segmap_tblock_sizze_33443), max_num_tblocks_34398)));
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_34399 = sext_i64_i32(sdiv_up64(m_32498, segmap_tblock_sizze_33443));
    
    {
        err = gpu_kernel_inner_SMJ_shortzisegmap_33440(ctx, num_tblocks_33445, 1, 1, *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_33442, 1, 1, (int64_t) 0, m_32498, m_32626, num_tblocks_33445, virt_num_tblocks_34399, mem_33844.mem, mem_33850.mem, mem_33852.mem, mem_33855.mem, mem_33863.mem, mem_33865.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_33844, "mem_33844") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33850, "mem_33850") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33852, "mem_33852") != 0)
        return 1;
    
    bool cond_32653 = slt64((int64_t) 0, m_32626);
    int64_t segmap_tblock_sizze_33458;
    
    segmap_tblock_sizze_33458 = *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_33450;
    if (memblock_alloc_device(ctx, &mem_33869, bytes_33868, "mem_33869")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i16(ctx, mem_33869, n_pairs_32548, (int16_t) 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33871, bytes_33870, "mem_33871")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_33871, n_pairs_32548, (int64_t) -1) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33873, bytes_33870, "mem_33873")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_33873, n_pairs_32548, (int64_t) -1) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t zm_lhs_32552 = add64(scatter_psizze_21790, n_pairs_32548);
    int64_t zs_lhs_32553 = sub64(zm_lhs_32552, (int64_t) 1);
    int64_t m_32557 = sdiv64(zs_lhs_32553, scatter_psizze_21790);
    bool loop_cond_32558 = slt64((int64_t) 0, m_32557);
    bool partitioned_scatter_res_32559;
    int64_t partitioned_scatter_res_32563;
    bool loop_while_32564;
    int64_t p_32568;
    
    loop_while_32564 = loop_cond_32558;
    p_32568 = (int64_t) 0;
    while (loop_while_32564) {
        int64_t lower_bound_32569 = mul64(scatter_psizze_21790, p_32568);
        int64_t min_arg1_32570 = add64(scatter_psizze_21790, lower_bound_32569);
        int64_t min_res_32571 = smin64(n_pairs_32548, min_arg1_32570);
        int64_t j_m_i_32572 = sub64(min_res_32571, lower_bound_32569);
        bool empty_slice_32573 = j_m_i_32572 == (int64_t) 0;
        int64_t m_32574 = sub64(j_m_i_32572, (int64_t) 1);
        int64_t i_p_m_t_s_32575 = add64(lower_bound_32569, m_32574);
        bool zzero_leq_i_p_m_t_s_32576 = sle64((int64_t) 0, i_p_m_t_s_32575);
        bool i_p_m_t_s_leq_w_32577 = slt64(i_p_m_t_s_32575, n_pairs_32548);
        bool zzero_lte_i_32578 = sle64((int64_t) 0, lower_bound_32569);
        bool i_lte_j_32579 = sle64(lower_bound_32569, min_res_32571);
        bool y_32580 = i_p_m_t_s_leq_w_32577 && zzero_lte_i_32578;
        bool y_32581 = zzero_leq_i_p_m_t_s_32576 && y_32580;
        bool forwards_ok_32582 = i_lte_j_32579 && y_32581;
        bool ok_or_empty_32583 = empty_slice_32573 || forwards_ok_32582;
        bool index_certs_32584;
        
        if (!ok_or_empty_32583) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) lower_bound_32569, ":", (long long) min_res_32571, "] out of bounds for array of shape [", (long long) n_pairs_32548, "].", "-> #0  ftbasics.fut:72:25-56\n   #1  ftSMJ.fut:328:7-329:73\n   #2  ftSMJ.fut:353:133-136\n   #3  ftSMJ.fut:342:1-353:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t bytes_33883 = (int64_t) 2 * j_m_i_32572;
        int64_t bytes_33885 = (int64_t) 8 * j_m_i_32572;
        
        if (memblock_alloc_device(ctx, &mem_33884, bytes_33883, "mem_33884")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_2b(ctx, 1, mem_33884.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_33869.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_32569, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_32572})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_33886, bytes_33885, "mem_33886")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33886.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_33871.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_32569, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_32572})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_33888, bytes_33885, "mem_33888")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33888.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_33873.mem, (int64_t) 0 + (int64_t) 1 * lower_bound_32569, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_32572})) != 0)
            goto cleanup;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_34437 = sext_i64_i32(sdiv_up64(m_32498, segmap_tblock_sizze_33435));
        
        {
            err = gpu_kernel_inner_SMJ_shortzisegmap_33432(ctx, num_tblocks_33437, 1, 1, *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_33434, 1, 1, (int64_t) 0, m_32498, lower_bound_32569, min_res_32571, j_m_i_32572, num_tblocks_33437, virt_num_tblocks_34437, mem_33838.mem, mem_33840.mem, mem_33842.mem, mem_33855.mem, mem_33884.mem, mem_33886.mem, mem_33888.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t tmp_32598 = add64((int64_t) 1, p_32568);
        
        if ((err = lmad_copy_gpu2gpu_2b(ctx, 1, mem_33869.mem, lower_bound_32569, (int64_t []) {(int64_t) 1}, mem_33884.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_32572})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_33884, "mem_33884") != 0)
            return 1;
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33871.mem, lower_bound_32569, (int64_t []) {(int64_t) 1}, mem_33886.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_32572})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_33886, "mem_33886") != 0)
            return 1;
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33873.mem, lower_bound_32569, (int64_t []) {(int64_t) 1}, mem_33888.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {j_m_i_32572})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_33888, "mem_33888") != 0)
            return 1;
        
        bool loop_cond_32609 = slt64(tmp_32598, m_32557);
        bool loop_while_tmp_34432 = loop_cond_32609;
        int64_t p_tmp_34436 = tmp_32598;
        
        loop_while_32564 = loop_while_tmp_34432;
        p_32568 = p_tmp_34436;
    }
    partitioned_scatter_res_32559 = loop_while_32564;
    partitioned_scatter_res_32563 = p_32568;
    if (memblock_unref_device(ctx, &mem_33838, "mem_33838") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33840, "mem_33840") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33842, "mem_33842") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33855, "mem_33855") != 0)
        return 1;
    
    bool loop_cond_t_res_32654 = slt64(m_32498, n_pairs_32548);
    bool x_32655 = cond_32653 && loop_cond_t_res_32654;
    
    if (memblock_alloc_device(ctx, &mem_33914, (int64_t) 2, "mem_33914")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33915, (int64_t) 8, "mem_33915")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_33916, (int64_t) 8, "mem_33916")) {
        err = 1;
        goto cleanup;
    }
    
    bool joinTups_to_joinPairs_InnerJoin_res_32656;
    int64_t joinTups_to_joinPairs_InnerJoin_res_32660;
    bool loop_while_32661;
    int64_t p_32665;
    
    if (memblock_set_device(ctx, &mem_param_33901, &mem_33869, "mem_33869") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_33904, &mem_33871, "mem_33871") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_33907, &mem_33873, "mem_33873") != 0)
        return 1;
    loop_while_32661 = x_32655;
    p_32665 = (int64_t) 0;
    while (loop_while_32661) {
        bool x_32666 = sle64((int64_t) 0, p_32665);
        bool y_32667 = slt64(p_32665, m_32626);
        bool bounds_check_32668 = x_32666 && y_32667;
        bool index_certs_32669;
        
        if (!bounds_check_32668) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) p_32665, "] out of bounds for array of shape [", (long long) m_32626, "].", "-> #0  ftSMJ.fut:300:13-42\n   #1  ftSMJ.fut:328:7-329:73\n   #2  ftSMJ.fut:353:133-136\n   #3  ftSMJ.fut:342:1-353:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t read_res_34566;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_34566, mem_33865.mem, p_32665 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t loopres_32670 = read_res_34566;
        int64_t read_res_34567;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_34567, mem_33863.mem, p_32665 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t loopres_32671 = read_res_34567;
        bool x_32672 = sle64((int64_t) 0, loopres_32670);
        bool y_32673 = slt64(loopres_32670, n_pairs_32548);
        bool bounds_check_32674 = x_32672 && y_32673;
        bool index_certs_32675;
        
        if (!bounds_check_32674) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) loopres_32670, "] out of bounds for array of shape [", (long long) n_pairs_32548, "].", "-> #0  ftSMJ.fut:302:52-61\n   #1  ftSMJ.fut:328:7-329:73\n   #2  ftSMJ.fut:353:133-136\n   #3  ftSMJ.fut:342:1-353:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t tmp_32686 = add64(loopres_32670, loopres_32671);
        bool empty_slice_32690 = loopres_32671 == (int64_t) 0;
        int64_t m_32691 = sub64(loopres_32671, (int64_t) 1);
        int64_t i_p_m_t_s_32692 = add64(loopres_32670, m_32691);
        bool zzero_leq_i_p_m_t_s_32693 = sle64((int64_t) 0, i_p_m_t_s_32692);
        bool i_p_m_t_s_leq_w_32694 = slt64(i_p_m_t_s_32692, n_pairs_32548);
        bool i_lte_j_32695 = sle64(loopres_32670, tmp_32686);
        bool y_32696 = x_32672 && i_p_m_t_s_leq_w_32694;
        bool y_32697 = zzero_leq_i_p_m_t_s_32693 && y_32696;
        bool forwards_ok_32698 = i_lte_j_32695 && y_32697;
        bool ok_or_empty_32699 = empty_slice_32690 || forwards_ok_32698;
        bool index_certs_32700;
        
        if (!ok_or_empty_32699) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) loopres_32670, ":", (long long) tmp_32686, "] out of bounds for array of shape [", (long long) n_pairs_32548, "].", "-> #0  ftSMJ.fut:306:14-55\n   #1  ftSMJ.fut:328:7-329:73\n   #2  ftSMJ.fut:353:133-136\n   #3  ftSMJ.fut:342:1-353:136\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t bytes_33917 = (int64_t) 2 * loopres_32671;
        int64_t bytes_33919 = (int64_t) 8 * loopres_32671;
        int64_t segmap_usable_groups_33459 = sdiv_up64(loopres_32671, segmap_tblock_sizze_33458);
        int64_t tmp_32685 = add64((int64_t) 1, p_32665);
        
        if (memblock_alloc_device(ctx, &mem_33909, bytes_33868, "mem_33909")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_2b(ctx, 1, mem_33909.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_33901.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_32548})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_33911, bytes_33870, "mem_33911")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33911.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_33904.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_32548})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_33913, bytes_33870, "mem_33913")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33913.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_33907.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_32548})) != 0)
            goto cleanup;
        
        bool cond_32704 = slt64(tmp_32685, m_32626);
        bool x_32705 = loop_cond_t_res_32654 && cond_32704;
        
        {
            err = gpu_kernel_inner_SMJ_shortzigpuseq_34458(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, loopres_32670, mem_param_33901.mem, mem_param_33904.mem, mem_param_33907.mem, mem_33914.mem, mem_33915.mem, mem_33916.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_33918, bytes_33917, "mem_33918")) {
            err = 1;
            goto cleanup;
        }
        
        int64_t replicate_n_34464 = loopres_32671;
        int64_t tblock_sizze_34469;
        
        tblock_sizze_34469 = *ctx->tuning_params.inner_SMJ_shortzitblock_sizze_34469;
        
        int64_t virt_num_tblocks_34470 = sdiv_up64(replicate_n_34464, tblock_sizze_34469);
        int64_t num_tblocks_34471 = smin64(virt_num_tblocks_34470, (int64_t) 1048576);
        
        {
            err = gpu_kernel_inner_SMJ_shortzireplicate_34465(ctx, num_tblocks_34471, 1, 1, tblock_sizze_34469, 1, 1, (int64_t) 0, loopres_32671, replicate_n_34464, virt_num_tblocks_34470, num_tblocks_34471, mem_33914.mem, mem_33918.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_33920, bytes_33919, "mem_33920")) {
            err = 1;
            goto cleanup;
        }
        
        int64_t replicate_n_34484 = loopres_32671;
        int64_t tblock_sizze_34489;
        
        tblock_sizze_34489 = *ctx->tuning_params.inner_SMJ_shortzitblock_sizze_34489;
        
        int64_t virt_num_tblocks_34490 = sdiv_up64(replicate_n_34484, tblock_sizze_34489);
        int64_t num_tblocks_34491 = smin64(virt_num_tblocks_34490, (int64_t) 1048576);
        
        {
            err = gpu_kernel_inner_SMJ_shortzireplicate_34485(ctx, num_tblocks_34491, 1, 1, tblock_sizze_34489, 1, 1, (int64_t) 0, loopres_32671, replicate_n_34484, virt_num_tblocks_34490, num_tblocks_34491, mem_33915.mem, mem_33920.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_34504 = sext_i64_i32(sdiv_up64(loopres_32671, segmap_tblock_sizze_33458));
        
        {
            err = gpu_kernel_inner_SMJ_shortzisegmap_33462(ctx, segmap_usable_groups_33459, 1, 1, *ctx->tuning_params.inner_SMJ_shortzisegmap_tblock_sizze_33450, 1, 1, (int64_t) 0, loopres_32670, loopres_32671, mem_33913.mem, mem_33916.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if ((err = lmad_copy_gpu2gpu_2b(ctx, 1, mem_33909.mem, loopres_32670, (int64_t []) {(int64_t) 1}, mem_33918.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {loopres_32671})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_33918, "mem_33918") != 0)
            return 1;
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33911.mem, loopres_32670, (int64_t []) {(int64_t) 1}, mem_33920.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {loopres_32671})) != 0)
            goto cleanup;
        if (memblock_unref_device(ctx, &mem_33920, "mem_33920") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_34450, &mem_33909, "mem_33909") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_34451, &mem_33911, "mem_33911") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_34452, &mem_33913, "mem_33913") != 0)
            return 1;
        
        bool loop_while_tmp_34453 = x_32705;
        int64_t p_tmp_34457 = tmp_32685;
        
        if (memblock_set_device(ctx, &mem_param_33901, &mem_param_tmp_34450, "mem_param_tmp_34450") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_33904, &mem_param_tmp_34451, "mem_param_tmp_34451") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_33907, &mem_param_tmp_34452, "mem_param_tmp_34452") != 0)
            return 1;
        loop_while_32661 = loop_while_tmp_34453;
        p_32665 = p_tmp_34457;
    }
    if (memblock_set_device(ctx, &ext_mem_33932, &mem_param_33901, "mem_param_33901") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_33931, &mem_param_33904, "mem_param_33904") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_33930, &mem_param_33907, "mem_param_33907") != 0)
        return 1;
    joinTups_to_joinPairs_InnerJoin_res_32656 = loop_while_32661;
    joinTups_to_joinPairs_InnerJoin_res_32660 = p_32665;
    if (memblock_unref_device(ctx, &mem_33863, "mem_33863") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33865, "mem_33865") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33869, "mem_33869") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33871, "mem_33871") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33873, "mem_33873") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33914, "mem_33914") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33915, "mem_33915") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_33916, "mem_33916") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_33934, bytes_33868, "mem_33934")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_2b(ctx, 1, mem_33934.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_33932.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_32548})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_33932, "ext_mem_33932") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_33936, bytes_33870, "mem_33936")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33936.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_33931.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_32548})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_33931, "ext_mem_33931") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_33938, bytes_33870, "mem_33938")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_33938.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, ext_mem_33930.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_pairs_32548})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_33930, "ext_mem_33930") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_34019, &mem_33936, "mem_33936") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_34020, &mem_33938, "mem_33938") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_34021, &mem_33934, "mem_33934") != 0)
        return 1;
    prim_out_34022 = n_pairs_32548;
    if (memblock_set_device(ctx, &*mem_out_p_34559, &mem_out_34019, "mem_out_34019") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_34560, &mem_out_34020, "mem_out_34020") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_34561, &mem_out_34021, "mem_out_34021") != 0)
        return 1;
    *out_prim_out_34562 = prim_out_34022;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_33938, "mem_33938") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33936, "mem_33936") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33934, "mem_33934") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_34452, "mem_param_tmp_34452") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_34451, "mem_param_tmp_34451") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_34450, "mem_param_tmp_34450") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33920, "mem_33920") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33918, "mem_33918") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33913, "mem_33913") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33911, "mem_33911") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33909, "mem_33909") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_33907, "mem_param_33907") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_33904, "mem_param_33904") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_33901, "mem_param_33901") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33930, "ext_mem_33930") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33931, "ext_mem_33931") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33932, "ext_mem_33932") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33916, "mem_33916") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33915, "mem_33915") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33914, "mem_33914") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33888, "mem_33888") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33886, "mem_33886") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33884, "mem_33884") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33873, "mem_33873") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33871, "mem_33871") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33869, "mem_33869") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33865, "mem_33865") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33863, "mem_33863") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33867, "mem_33867") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33859, "mem_33859") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33860, "mem_33860") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33861, "ext_mem_33861") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33856, "mem_33856") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33857, "mem_33857") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_33858, "ext_mem_33858") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33855, "mem_33855") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_34233, "incprefixes_mem_34233") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_34231, "aggregates_mem_34231") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_34229, "incprefixes_mem_34229") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_34227, "aggregates_mem_34227") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_34225, "status_flags_mem_34225") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33852, "mem_33852") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33850, "mem_33850") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33848, "mem_33848") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33844, "mem_33844") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33842, "mem_33842") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33840, "mem_33840") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33838, "mem_33838") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_34055, "incprefixes_mem_34055") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_34053, "aggregates_mem_34053") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_34031, "status_flags_mem_34031") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33836, "mem_33836") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_34021, "mem_out_34021") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_34020, "mem_out_34020") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_34019, "mem_out_34019") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_max_idx(struct futhark_context *ctx, int64_t *out_prim_out_34568, struct memblock_device eta_p_mem_33832, int64_t nz2080U_31457)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device segred_tmp_mem_34044;
    
    segred_tmp_mem_34044.references = NULL;
    
    struct memblock_device mem_33834;
    
    mem_33834.references = NULL;
    
    struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
    struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
    struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
    int64_t prim_out_34019;
    int64_t segred_tblock_sizze_32813;
    
    segred_tblock_sizze_32813 = *ctx->tuning_params.max_idxzisegred_tblock_sizze_32812;
    
    int64_t num_tblocks_32815;
    int64_t max_num_tblocks_34020;
    
    max_num_tblocks_34020 = *ctx->tuning_params.max_idxzisegred_num_tblocks_32814;
    num_tblocks_32815 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nz2080U_31457, segred_tblock_sizze_32813), max_num_tblocks_34020)));
    if (memblock_alloc_device(ctx, &mem_33834, (int64_t) 8, "mem_33834")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegRed");
    
    int64_t chunk_sizze_34021 = (int64_t) 1;
    
    if (memblock_alloc_device(ctx, &segred_tmp_mem_34044, (int64_t) 8 * num_tblocks_32815, "segred_tmp_mem_34044")) {
        err = 1;
        goto cleanup;
    }
    
    int64_t num_threads_34046 = num_tblocks_32815 * segred_tblock_sizze_32813;
    
    {
        err = gpu_kernel_max_idxzisegred_nonseg_32820(ctx, num_tblocks_32815, 1, 1, *ctx->tuning_params.max_idxzisegred_tblock_sizze_32812, 1, 1, 8 + ((int64_t) 8 * segred_tblock_sizze_32813 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_32813, (int64_t) 8), (int64_t) 8)), nz2080U_31457, num_tblocks_32815, num_threads_34046, eta_p_mem_33832.mem, mem_33834.mem, counters_mem_34022.mem, segred_tmp_mem_34044.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t read_res_34569;
    
    if ((err = gpu_scalar_from_device(ctx, &read_res_34569, mem_33834.mem, (int64_t) 0 * sizeof(int64_t), sizeof(int64_t))) != 0)
        goto cleanup;
    if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t defunc_0_reduce_res_32709 = read_res_34569;
    
    if (memblock_unref_device(ctx, &mem_33834, "mem_33834") != 0)
        return 1;
    prim_out_34019 = defunc_0_reduce_res_32709;
    *out_prim_out_34568 = prim_out_34019;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &segred_tmp_mem_34044, "segred_tmp_mem_34044") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33834, "mem_33834") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_min_idx(struct futhark_context *ctx, int64_t *out_prim_out_34570, struct memblock_device eta_p_mem_33832, int64_t nz2080U_31417)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device segred_tmp_mem_34044;
    
    segred_tmp_mem_34044.references = NULL;
    
    struct memblock_device mem_33834;
    
    mem_33834.references = NULL;
    
    struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
    struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
    struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
    int64_t prim_out_34019;
    int64_t segred_tblock_sizze_32803;
    
    segred_tblock_sizze_32803 = *ctx->tuning_params.min_idxzisegred_tblock_sizze_32802;
    
    int64_t num_tblocks_32805;
    int64_t max_num_tblocks_34020;
    
    max_num_tblocks_34020 = *ctx->tuning_params.min_idxzisegred_num_tblocks_32804;
    num_tblocks_32805 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nz2080U_31417, segred_tblock_sizze_32803), max_num_tblocks_34020)));
    if (memblock_alloc_device(ctx, &mem_33834, (int64_t) 8, "mem_33834")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegRed");
    
    int64_t chunk_sizze_34021 = (int64_t) 1;
    
    if (memblock_alloc_device(ctx, &segred_tmp_mem_34044, (int64_t) 8 * num_tblocks_32805, "segred_tmp_mem_34044")) {
        err = 1;
        goto cleanup;
    }
    
    int64_t num_threads_34046 = num_tblocks_32805 * segred_tblock_sizze_32803;
    
    {
        err = gpu_kernel_min_idxzisegred_nonseg_32810(ctx, num_tblocks_32805, 1, 1, *ctx->tuning_params.min_idxzisegred_tblock_sizze_32802, 1, 1, 8 + ((int64_t) 8 * segred_tblock_sizze_32803 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_32803, (int64_t) 8), (int64_t) 8)), nz2080U_31417, num_tblocks_32805, num_threads_34046, eta_p_mem_33832.mem, mem_33834.mem, counters_mem_34022.mem, segred_tmp_mem_34044.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t read_res_34571;
    
    if ((err = gpu_scalar_from_device(ctx, &read_res_34571, mem_33834.mem, (int64_t) 0 * sizeof(int64_t), sizeof(int64_t))) != 0)
        goto cleanup;
    if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t defunc_0_reduce_res_32709 = read_res_34571;
    
    if (memblock_unref_device(ctx, &mem_33834, "mem_33834") != 0)
        return 1;
    prim_out_34019 = defunc_0_reduce_res_32709;
    *out_prim_out_34570 = prim_out_34019;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &segred_tmp_mem_34044, "segred_tmp_mem_34044") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_33834, "mem_33834") != 0)
            return 1;
    }
    return err;
}

int futhark_entry_gather_payloads_double(struct futhark_context *ctx, struct futhark_f64_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_i64_1d *in2, const struct futhark_f64_1d *in3)
{
    int64_t niz2084U_29871 = (int64_t) 0;
    int64_t dz2083U_29872 = (int64_t) 0;
    int64_t incr_29873 = (int64_t) 0;
    int64_t psizze_29874 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_34019;
    
    mem_out_34019.references = NULL;
    
    struct memblock_device ys_mem_33833;
    
    ys_mem_33833.references = NULL;
    
    struct memblock_device is_mem_33832;
    
    is_mem_33832.references = NULL;
    incr_29873 = in0;
    psizze_29874 = in1;
    is_mem_33832 = in2->mem;
    niz2084U_29871 = in2->shape[0];
    ys_mem_33833 = in3->mem;
    dz2083U_29872 = in3->shape[0];
    if (!(niz2084U_29871 == in2->shape[0] && dz2083U_29872 == in3->shape[0])) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_gather_payloads_double(ctx, &mem_out_34019, is_mem_33832, ys_mem_33833, niz2084U_29871, dz2083U_29872, incr_29873, psizze_29874);
        if (ret == 0) {
            struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
            struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
            struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
            
            assert((*out0 = (struct futhark_f64_1d *) malloc(sizeof(struct futhark_f64_1d))) != NULL);
            (*out0)->mem = mem_out_34019;
            (*out0)->shape[0] = niz2084U_29871;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_gather_payloads_double_GFUR(struct futhark_context *ctx, struct futhark_f64_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_f64_1d *in2, const struct futhark_i64_1d *in3, const struct futhark_f64_1d *in4)
{
    int64_t ni_31378 = (int64_t) 0;
    int64_t n_31379 = (int64_t) 0;
    int64_t incr_31380 = (int64_t) 0;
    int64_t psizze_31381 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_34019;
    
    mem_out_34019.references = NULL;
    
    struct memblock_device ys_mem_33834;
    
    ys_mem_33834.references = NULL;
    
    struct memblock_device is_mem_33833;
    
    is_mem_33833.references = NULL;
    
    struct memblock_device preVals_mem_33832;
    
    preVals_mem_33832.references = NULL;
    incr_31380 = in0;
    psizze_31381 = in1;
    preVals_mem_33832 = in2->mem;
    ni_31378 = in2->shape[0];
    is_mem_33833 = in3->mem;
    ni_31378 = in3->shape[0];
    ys_mem_33834 = in4->mem;
    n_31379 = in4->shape[0];
    if (!(ni_31378 == in2->shape[0] && (ni_31378 == in3->shape[0] && n_31379 == in4->shape[0]))) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_gather_payloads_double_GFUR(ctx, &mem_out_34019, preVals_mem_33832, is_mem_33833, ys_mem_33834, ni_31378, n_31379, incr_31380, psizze_31381);
        if (ret == 0) {
            struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
            struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
            struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
            
            assert((*out0 = (struct futhark_f64_1d *) malloc(sizeof(struct futhark_f64_1d))) != NULL);
            (*out0)->mem = mem_out_34019;
            (*out0)->shape[0] = ni_31378;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_gather_payloads_float(struct futhark_context *ctx, struct futhark_f32_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_i64_1d *in2, const struct futhark_f32_1d *in3)
{
    int64_t niz2084U_29531 = (int64_t) 0;
    int64_t dz2083U_29532 = (int64_t) 0;
    int64_t incr_29533 = (int64_t) 0;
    int64_t psizze_29534 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_34019;
    
    mem_out_34019.references = NULL;
    
    struct memblock_device ys_mem_33833;
    
    ys_mem_33833.references = NULL;
    
    struct memblock_device is_mem_33832;
    
    is_mem_33832.references = NULL;
    incr_29533 = in0;
    psizze_29534 = in1;
    is_mem_33832 = in2->mem;
    niz2084U_29531 = in2->shape[0];
    ys_mem_33833 = in3->mem;
    dz2083U_29532 = in3->shape[0];
    if (!(niz2084U_29531 == in2->shape[0] && dz2083U_29532 == in3->shape[0])) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_gather_payloads_float(ctx, &mem_out_34019, is_mem_33832, ys_mem_33833, niz2084U_29531, dz2083U_29532, incr_29533, psizze_29534);
        if (ret == 0) {
            struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
            struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
            struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
            
            assert((*out0 = (struct futhark_f32_1d *) malloc(sizeof(struct futhark_f32_1d))) != NULL);
            (*out0)->mem = mem_out_34019;
            (*out0)->shape[0] = niz2084U_29531;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_gather_payloads_float_GFUR(struct futhark_context *ctx, struct futhark_f32_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_f32_1d *in2, const struct futhark_i64_1d *in3, const struct futhark_f32_1d *in4)
{
    int64_t ni_31077 = (int64_t) 0;
    int64_t n_31078 = (int64_t) 0;
    int64_t incr_31079 = (int64_t) 0;
    int64_t psizze_31080 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_34019;
    
    mem_out_34019.references = NULL;
    
    struct memblock_device ys_mem_33834;
    
    ys_mem_33834.references = NULL;
    
    struct memblock_device is_mem_33833;
    
    is_mem_33833.references = NULL;
    
    struct memblock_device preVals_mem_33832;
    
    preVals_mem_33832.references = NULL;
    incr_31079 = in0;
    psizze_31080 = in1;
    preVals_mem_33832 = in2->mem;
    ni_31077 = in2->shape[0];
    is_mem_33833 = in3->mem;
    ni_31077 = in3->shape[0];
    ys_mem_33834 = in4->mem;
    n_31078 = in4->shape[0];
    if (!(ni_31077 == in2->shape[0] && (ni_31077 == in3->shape[0] && n_31078 == in4->shape[0]))) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_gather_payloads_float_GFUR(ctx, &mem_out_34019, preVals_mem_33832, is_mem_33833, ys_mem_33834, ni_31077, n_31078, incr_31079, psizze_31080);
        if (ret == 0) {
            struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
            struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
            struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
            
            assert((*out0 = (struct futhark_f32_1d *) malloc(sizeof(struct futhark_f32_1d))) != NULL);
            (*out0)->mem = mem_out_34019;
            (*out0)->shape[0] = ni_31077;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_gather_payloads_int(struct futhark_context *ctx, struct futhark_i32_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_i64_1d *in2, const struct futhark_i32_1d *in3)
{
    int64_t niz2084U_28882 = (int64_t) 0;
    int64_t dz2083U_28883 = (int64_t) 0;
    int64_t incr_28884 = (int64_t) 0;
    int64_t psizze_28885 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_34019;
    
    mem_out_34019.references = NULL;
    
    struct memblock_device ys_mem_33833;
    
    ys_mem_33833.references = NULL;
    
    struct memblock_device is_mem_33832;
    
    is_mem_33832.references = NULL;
    incr_28884 = in0;
    psizze_28885 = in1;
    is_mem_33832 = in2->mem;
    niz2084U_28882 = in2->shape[0];
    ys_mem_33833 = in3->mem;
    dz2083U_28883 = in3->shape[0];
    if (!(niz2084U_28882 == in2->shape[0] && dz2083U_28883 == in3->shape[0])) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_gather_payloads_int(ctx, &mem_out_34019, is_mem_33832, ys_mem_33833, niz2084U_28882, dz2083U_28883, incr_28884, psizze_28885);
        if (ret == 0) {
            struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
            struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
            struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
            
            assert((*out0 = (struct futhark_i32_1d *) malloc(sizeof(struct futhark_i32_1d))) != NULL);
            (*out0)->mem = mem_out_34019;
            (*out0)->shape[0] = niz2084U_28882;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_gather_payloads_int_GFUR(struct futhark_context *ctx, struct futhark_i32_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_i32_1d *in2, const struct futhark_i64_1d *in3, const struct futhark_i32_1d *in4)
{
    int64_t ni_30475 = (int64_t) 0;
    int64_t n_30476 = (int64_t) 0;
    int64_t incr_30477 = (int64_t) 0;
    int64_t psizze_30478 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_34019;
    
    mem_out_34019.references = NULL;
    
    struct memblock_device ys_mem_33834;
    
    ys_mem_33834.references = NULL;
    
    struct memblock_device is_mem_33833;
    
    is_mem_33833.references = NULL;
    
    struct memblock_device preVals_mem_33832;
    
    preVals_mem_33832.references = NULL;
    incr_30477 = in0;
    psizze_30478 = in1;
    preVals_mem_33832 = in2->mem;
    ni_30475 = in2->shape[0];
    is_mem_33833 = in3->mem;
    ni_30475 = in3->shape[0];
    ys_mem_33834 = in4->mem;
    n_30476 = in4->shape[0];
    if (!(ni_30475 == in2->shape[0] && (ni_30475 == in3->shape[0] && n_30476 == in4->shape[0]))) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_gather_payloads_int_GFUR(ctx, &mem_out_34019, preVals_mem_33832, is_mem_33833, ys_mem_33834, ni_30475, n_30476, incr_30477, psizze_30478);
        if (ret == 0) {
            struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
            struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
            struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
            
            assert((*out0 = (struct futhark_i32_1d *) malloc(sizeof(struct futhark_i32_1d))) != NULL);
            (*out0)->mem = mem_out_34019;
            (*out0)->shape[0] = ni_30475;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_gather_payloads_long(struct futhark_context *ctx, struct futhark_i64_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_i64_1d *in2, const struct futhark_i64_1d *in3)
{
    int64_t niz2084U_29191 = (int64_t) 0;
    int64_t dz2083U_29192 = (int64_t) 0;
    int64_t incr_29193 = (int64_t) 0;
    int64_t psizze_29194 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_34019;
    
    mem_out_34019.references = NULL;
    
    struct memblock_device ys_mem_33833;
    
    ys_mem_33833.references = NULL;
    
    struct memblock_device is_mem_33832;
    
    is_mem_33832.references = NULL;
    incr_29193 = in0;
    psizze_29194 = in1;
    is_mem_33832 = in2->mem;
    niz2084U_29191 = in2->shape[0];
    ys_mem_33833 = in3->mem;
    dz2083U_29192 = in3->shape[0];
    if (!(niz2084U_29191 == in2->shape[0] && dz2083U_29192 == in3->shape[0])) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_gather_payloads_long(ctx, &mem_out_34019, is_mem_33832, ys_mem_33833, niz2084U_29191, dz2083U_29192, incr_29193, psizze_29194);
        if (ret == 0) {
            struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
            struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
            struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
            
            assert((*out0 = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d))) != NULL);
            (*out0)->mem = mem_out_34019;
            (*out0)->shape[0] = niz2084U_29191;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_gather_payloads_long_GFUR(struct futhark_context *ctx, struct futhark_i64_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_i64_1d *in2, const struct futhark_i64_1d *in3, const struct futhark_i64_1d *in4)
{
    int64_t ni_30776 = (int64_t) 0;
    int64_t n_30777 = (int64_t) 0;
    int64_t incr_30778 = (int64_t) 0;
    int64_t psizze_30779 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_34019;
    
    mem_out_34019.references = NULL;
    
    struct memblock_device ys_mem_33834;
    
    ys_mem_33834.references = NULL;
    
    struct memblock_device is_mem_33833;
    
    is_mem_33833.references = NULL;
    
    struct memblock_device preVals_mem_33832;
    
    preVals_mem_33832.references = NULL;
    incr_30778 = in0;
    psizze_30779 = in1;
    preVals_mem_33832 = in2->mem;
    ni_30776 = in2->shape[0];
    is_mem_33833 = in3->mem;
    ni_30776 = in3->shape[0];
    ys_mem_33834 = in4->mem;
    n_30777 = in4->shape[0];
    if (!(ni_30776 == in2->shape[0] && (ni_30776 == in3->shape[0] && n_30777 == in4->shape[0]))) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_gather_payloads_long_GFUR(ctx, &mem_out_34019, preVals_mem_33832, is_mem_33833, ys_mem_33834, ni_30776, n_30777, incr_30778, psizze_30779);
        if (ret == 0) {
            struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
            struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
            struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
            
            assert((*out0 = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d))) != NULL);
            (*out0)->mem = mem_out_34019;
            (*out0)->shape[0] = ni_30776;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_gather_payloads_short(struct futhark_context *ctx, struct futhark_i16_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_i64_1d *in2, const struct futhark_i16_1d *in3)
{
    int64_t niz2084U_28542 = (int64_t) 0;
    int64_t dz2083U_28543 = (int64_t) 0;
    int64_t incr_28544 = (int64_t) 0;
    int64_t psizze_28545 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_34019;
    
    mem_out_34019.references = NULL;
    
    struct memblock_device ys_mem_33833;
    
    ys_mem_33833.references = NULL;
    
    struct memblock_device is_mem_33832;
    
    is_mem_33832.references = NULL;
    incr_28544 = in0;
    psizze_28545 = in1;
    is_mem_33832 = in2->mem;
    niz2084U_28542 = in2->shape[0];
    ys_mem_33833 = in3->mem;
    dz2083U_28543 = in3->shape[0];
    if (!(niz2084U_28542 == in2->shape[0] && dz2083U_28543 == in3->shape[0])) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_gather_payloads_short(ctx, &mem_out_34019, is_mem_33832, ys_mem_33833, niz2084U_28542, dz2083U_28543, incr_28544, psizze_28545);
        if (ret == 0) {
            struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
            struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
            struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
            
            assert((*out0 = (struct futhark_i16_1d *) malloc(sizeof(struct futhark_i16_1d))) != NULL);
            (*out0)->mem = mem_out_34019;
            (*out0)->shape[0] = niz2084U_28542;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_gather_payloads_short_GFUR(struct futhark_context *ctx, struct futhark_i16_1d **out0, const int64_t in0, const int64_t in1, const struct futhark_i16_1d *in2, const struct futhark_i64_1d *in3, const struct futhark_i16_1d *in4)
{
    int64_t ni_30174 = (int64_t) 0;
    int64_t n_30175 = (int64_t) 0;
    int64_t incr_30176 = (int64_t) 0;
    int64_t psizze_30177 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_34019;
    
    mem_out_34019.references = NULL;
    
    struct memblock_device ys_mem_33834;
    
    ys_mem_33834.references = NULL;
    
    struct memblock_device is_mem_33833;
    
    is_mem_33833.references = NULL;
    
    struct memblock_device preVals_mem_33832;
    
    preVals_mem_33832.references = NULL;
    incr_30176 = in0;
    psizze_30177 = in1;
    preVals_mem_33832 = in2->mem;
    ni_30174 = in2->shape[0];
    is_mem_33833 = in3->mem;
    ni_30174 = in3->shape[0];
    ys_mem_33834 = in4->mem;
    n_30175 = in4->shape[0];
    if (!(ni_30174 == in2->shape[0] && (ni_30174 == in3->shape[0] && n_30175 == in4->shape[0]))) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_gather_payloads_short_GFUR(ctx, &mem_out_34019, preVals_mem_33832, is_mem_33833, ys_mem_33834, ni_30174, n_30175, incr_30176, psizze_30177);
        if (ret == 0) {
            struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
            struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
            struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
            
            assert((*out0 = (struct futhark_i16_1d *) malloc(sizeof(struct futhark_i16_1d))) != NULL);
            (*out0)->mem = mem_out_34019;
            (*out0)->shape[0] = ni_30174;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_inner_SMJ_double(struct futhark_context *ctx, struct futhark_opaque_joinPairs_double **out0, const struct futhark_f64_1d *in0, const struct futhark_f64_1d *in1, const int64_t in2, const int64_t in3, const int64_t in4, const int64_t in5, const int64_t in6, const int64_t in7)
{
    int64_t nR_28192 = (int64_t) 0;
    int64_t nS_28193 = (int64_t) 0;
    int64_t offset_R_28196 = (int64_t) 0;
    int64_t offset_S_28197 = (int64_t) 0;
    int64_t partitionsPerWindow_28198 = (int64_t) 0;
    int64_t numberOfWindows_28199 = (int64_t) 0;
    int64_t extParallelism_28200 = (int64_t) 0;
    int64_t scatter_psizze_28201 = (int64_t) 0;
    int64_t prim_out_34022 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_34021;
    
    mem_out_34021.references = NULL;
    
    struct memblock_device mem_out_34020;
    
    mem_out_34020.references = NULL;
    
    struct memblock_device mem_out_34019;
    
    mem_out_34019.references = NULL;
    
    struct memblock_device tS_mem_33833;
    
    tS_mem_33833.references = NULL;
    
    struct memblock_device tR_mem_33832;
    
    tR_mem_33832.references = NULL;
    tR_mem_33832 = in0->mem;
    nR_28192 = in0->shape[0];
    tS_mem_33833 = in1->mem;
    nS_28193 = in1->shape[0];
    offset_R_28196 = in2;
    offset_S_28197 = in3;
    partitionsPerWindow_28198 = in4;
    numberOfWindows_28199 = in5;
    extParallelism_28200 = in6;
    scatter_psizze_28201 = in7;
    if (!(nR_28192 == in0->shape[0] && nS_28193 == in1->shape[0])) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_inner_SMJ_double(ctx, &mem_out_34019, &mem_out_34020, &mem_out_34021, &prim_out_34022, tR_mem_33832, tS_mem_33833, nR_28192, nS_28193, offset_R_28196, offset_S_28197, partitionsPerWindow_28198, numberOfWindows_28199, extParallelism_28200, scatter_psizze_28201);
        if (ret == 0) {
            struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
            struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
            struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
            
            assert((*out0 = (struct futhark_opaque_joinPairs_double *) malloc(sizeof(struct futhark_opaque_joinPairs_double))) != NULL);
            assert(((*out0)->v0 = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d))) != NULL);
            (*out0)->v0->mem = mem_out_34019;
            (*out0)->v0->shape[0] = prim_out_34022;
            assert(((*out0)->v1 = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d))) != NULL);
            (*out0)->v1->mem = mem_out_34020;
            (*out0)->v1->shape[0] = prim_out_34022;
            assert(((*out0)->v2 = (struct futhark_f64_1d *) malloc(sizeof(struct futhark_f64_1d))) != NULL);
            (*out0)->v2->mem = mem_out_34021;
            (*out0)->v2->shape[0] = prim_out_34022;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_inner_SMJ_float(struct futhark_context *ctx, struct futhark_opaque_joinPairs_float **out0, const struct futhark_f32_1d *in0, const struct futhark_f32_1d *in1, const int64_t in2, const int64_t in3, const int64_t in4, const int64_t in5, const int64_t in6, const int64_t in7)
{
    int64_t nR_26587 = (int64_t) 0;
    int64_t nS_26588 = (int64_t) 0;
    int64_t offset_R_26591 = (int64_t) 0;
    int64_t offset_S_26592 = (int64_t) 0;
    int64_t partitionsPerWindow_26593 = (int64_t) 0;
    int64_t numberOfWindows_26594 = (int64_t) 0;
    int64_t extParallelism_26595 = (int64_t) 0;
    int64_t scatter_psizze_26596 = (int64_t) 0;
    int64_t prim_out_34022 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_34021;
    
    mem_out_34021.references = NULL;
    
    struct memblock_device mem_out_34020;
    
    mem_out_34020.references = NULL;
    
    struct memblock_device mem_out_34019;
    
    mem_out_34019.references = NULL;
    
    struct memblock_device tS_mem_33833;
    
    tS_mem_33833.references = NULL;
    
    struct memblock_device tR_mem_33832;
    
    tR_mem_33832.references = NULL;
    tR_mem_33832 = in0->mem;
    nR_26587 = in0->shape[0];
    tS_mem_33833 = in1->mem;
    nS_26588 = in1->shape[0];
    offset_R_26591 = in2;
    offset_S_26592 = in3;
    partitionsPerWindow_26593 = in4;
    numberOfWindows_26594 = in5;
    extParallelism_26595 = in6;
    scatter_psizze_26596 = in7;
    if (!(nR_26587 == in0->shape[0] && nS_26588 == in1->shape[0])) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_inner_SMJ_float(ctx, &mem_out_34019, &mem_out_34020, &mem_out_34021, &prim_out_34022, tR_mem_33832, tS_mem_33833, nR_26587, nS_26588, offset_R_26591, offset_S_26592, partitionsPerWindow_26593, numberOfWindows_26594, extParallelism_26595, scatter_psizze_26596);
        if (ret == 0) {
            struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
            struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
            struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
            
            assert((*out0 = (struct futhark_opaque_joinPairs_float *) malloc(sizeof(struct futhark_opaque_joinPairs_float))) != NULL);
            assert(((*out0)->v0 = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d))) != NULL);
            (*out0)->v0->mem = mem_out_34019;
            (*out0)->v0->shape[0] = prim_out_34022;
            assert(((*out0)->v1 = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d))) != NULL);
            (*out0)->v1->mem = mem_out_34020;
            (*out0)->v1->shape[0] = prim_out_34022;
            assert(((*out0)->v2 = (struct futhark_f32_1d *) malloc(sizeof(struct futhark_f32_1d))) != NULL);
            (*out0)->v2->mem = mem_out_34021;
            (*out0)->v2->shape[0] = prim_out_34022;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_inner_SMJ_int(struct futhark_context *ctx, struct futhark_opaque_joinPairs_int **out0, const struct futhark_i32_1d *in0, const struct futhark_i32_1d *in1, const int64_t in2, const int64_t in3, const int64_t in4, const int64_t in5, const int64_t in6, const int64_t in7)
{
    int64_t nR_23386 = (int64_t) 0;
    int64_t nS_23387 = (int64_t) 0;
    int64_t offset_R_23390 = (int64_t) 0;
    int64_t offset_S_23391 = (int64_t) 0;
    int64_t partitionsPerWindow_23392 = (int64_t) 0;
    int64_t numberOfWindows_23393 = (int64_t) 0;
    int64_t extParallelism_23394 = (int64_t) 0;
    int64_t scatter_psizze_23395 = (int64_t) 0;
    int64_t prim_out_34022 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_34021;
    
    mem_out_34021.references = NULL;
    
    struct memblock_device mem_out_34020;
    
    mem_out_34020.references = NULL;
    
    struct memblock_device mem_out_34019;
    
    mem_out_34019.references = NULL;
    
    struct memblock_device tS_mem_33833;
    
    tS_mem_33833.references = NULL;
    
    struct memblock_device tR_mem_33832;
    
    tR_mem_33832.references = NULL;
    tR_mem_33832 = in0->mem;
    nR_23386 = in0->shape[0];
    tS_mem_33833 = in1->mem;
    nS_23387 = in1->shape[0];
    offset_R_23390 = in2;
    offset_S_23391 = in3;
    partitionsPerWindow_23392 = in4;
    numberOfWindows_23393 = in5;
    extParallelism_23394 = in6;
    scatter_psizze_23395 = in7;
    if (!(nR_23386 == in0->shape[0] && nS_23387 == in1->shape[0])) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_inner_SMJ_int(ctx, &mem_out_34019, &mem_out_34020, &mem_out_34021, &prim_out_34022, tR_mem_33832, tS_mem_33833, nR_23386, nS_23387, offset_R_23390, offset_S_23391, partitionsPerWindow_23392, numberOfWindows_23393, extParallelism_23394, scatter_psizze_23395);
        if (ret == 0) {
            struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
            struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
            struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
            
            assert((*out0 = (struct futhark_opaque_joinPairs_int *) malloc(sizeof(struct futhark_opaque_joinPairs_int))) != NULL);
            assert(((*out0)->v0 = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d))) != NULL);
            (*out0)->v0->mem = mem_out_34019;
            (*out0)->v0->shape[0] = prim_out_34022;
            assert(((*out0)->v1 = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d))) != NULL);
            (*out0)->v1->mem = mem_out_34020;
            (*out0)->v1->shape[0] = prim_out_34022;
            assert(((*out0)->v2 = (struct futhark_i32_1d *) malloc(sizeof(struct futhark_i32_1d))) != NULL);
            (*out0)->v2->mem = mem_out_34021;
            (*out0)->v2->shape[0] = prim_out_34022;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_inner_SMJ_long(struct futhark_context *ctx, struct futhark_opaque_joinPairs_long **out0, const struct futhark_i64_1d *in0, const struct futhark_i64_1d *in1, const int64_t in2, const int64_t in3, const int64_t in4, const int64_t in5, const int64_t in6, const int64_t in7)
{
    int64_t nR_24982 = (int64_t) 0;
    int64_t nS_24983 = (int64_t) 0;
    int64_t offset_R_24986 = (int64_t) 0;
    int64_t offset_S_24987 = (int64_t) 0;
    int64_t partitionsPerWindow_24988 = (int64_t) 0;
    int64_t numberOfWindows_24989 = (int64_t) 0;
    int64_t extParallelism_24990 = (int64_t) 0;
    int64_t scatter_psizze_24991 = (int64_t) 0;
    int64_t prim_out_34022 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_34021;
    
    mem_out_34021.references = NULL;
    
    struct memblock_device mem_out_34020;
    
    mem_out_34020.references = NULL;
    
    struct memblock_device mem_out_34019;
    
    mem_out_34019.references = NULL;
    
    struct memblock_device tS_mem_33833;
    
    tS_mem_33833.references = NULL;
    
    struct memblock_device tR_mem_33832;
    
    tR_mem_33832.references = NULL;
    tR_mem_33832 = in0->mem;
    nR_24982 = in0->shape[0];
    tS_mem_33833 = in1->mem;
    nS_24983 = in1->shape[0];
    offset_R_24986 = in2;
    offset_S_24987 = in3;
    partitionsPerWindow_24988 = in4;
    numberOfWindows_24989 = in5;
    extParallelism_24990 = in6;
    scatter_psizze_24991 = in7;
    if (!(nR_24982 == in0->shape[0] && nS_24983 == in1->shape[0])) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_inner_SMJ_long(ctx, &mem_out_34019, &mem_out_34020, &mem_out_34021, &prim_out_34022, tR_mem_33832, tS_mem_33833, nR_24982, nS_24983, offset_R_24986, offset_S_24987, partitionsPerWindow_24988, numberOfWindows_24989, extParallelism_24990, scatter_psizze_24991);
        if (ret == 0) {
            struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
            struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
            struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
            
            assert((*out0 = (struct futhark_opaque_joinPairs_long *) malloc(sizeof(struct futhark_opaque_joinPairs_long))) != NULL);
            assert(((*out0)->v0 = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d))) != NULL);
            (*out0)->v0->mem = mem_out_34019;
            (*out0)->v0->shape[0] = prim_out_34022;
            assert(((*out0)->v1 = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d))) != NULL);
            (*out0)->v1->mem = mem_out_34020;
            (*out0)->v1->shape[0] = prim_out_34022;
            assert(((*out0)->v2 = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d))) != NULL);
            (*out0)->v2->mem = mem_out_34021;
            (*out0)->v2->shape[0] = prim_out_34022;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_inner_SMJ_short(struct futhark_context *ctx, struct futhark_opaque_joinPairs_short **out0, const struct futhark_i16_1d *in0, const struct futhark_i16_1d *in1, const int64_t in2, const int64_t in3, const int64_t in4, const int64_t in5, const int64_t in6, const int64_t in7)
{
    int64_t nR_21781 = (int64_t) 0;
    int64_t nS_21782 = (int64_t) 0;
    int64_t offset_R_21785 = (int64_t) 0;
    int64_t offset_S_21786 = (int64_t) 0;
    int64_t partitionsPerWindow_21787 = (int64_t) 0;
    int64_t numberOfWindows_21788 = (int64_t) 0;
    int64_t extParallelism_21789 = (int64_t) 0;
    int64_t scatter_psizze_21790 = (int64_t) 0;
    int64_t prim_out_34022 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_34021;
    
    mem_out_34021.references = NULL;
    
    struct memblock_device mem_out_34020;
    
    mem_out_34020.references = NULL;
    
    struct memblock_device mem_out_34019;
    
    mem_out_34019.references = NULL;
    
    struct memblock_device tS_mem_33833;
    
    tS_mem_33833.references = NULL;
    
    struct memblock_device tR_mem_33832;
    
    tR_mem_33832.references = NULL;
    tR_mem_33832 = in0->mem;
    nR_21781 = in0->shape[0];
    tS_mem_33833 = in1->mem;
    nS_21782 = in1->shape[0];
    offset_R_21785 = in2;
    offset_S_21786 = in3;
    partitionsPerWindow_21787 = in4;
    numberOfWindows_21788 = in5;
    extParallelism_21789 = in6;
    scatter_psizze_21790 = in7;
    if (!(nR_21781 == in0->shape[0] && nS_21782 == in1->shape[0])) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_inner_SMJ_short(ctx, &mem_out_34019, &mem_out_34020, &mem_out_34021, &prim_out_34022, tR_mem_33832, tS_mem_33833, nR_21781, nS_21782, offset_R_21785, offset_S_21786, partitionsPerWindow_21787, numberOfWindows_21788, extParallelism_21789, scatter_psizze_21790);
        if (ret == 0) {
            struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
            struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
            struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
            
            assert((*out0 = (struct futhark_opaque_joinPairs_short *) malloc(sizeof(struct futhark_opaque_joinPairs_short))) != NULL);
            assert(((*out0)->v0 = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d))) != NULL);
            (*out0)->v0->mem = mem_out_34019;
            (*out0)->v0->shape[0] = prim_out_34022;
            assert(((*out0)->v1 = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d))) != NULL);
            (*out0)->v1->mem = mem_out_34020;
            (*out0)->v1->shape[0] = prim_out_34022;
            assert(((*out0)->v2 = (struct futhark_i16_1d *) malloc(sizeof(struct futhark_i16_1d))) != NULL);
            (*out0)->v2->mem = mem_out_34021;
            (*out0)->v2->shape[0] = prim_out_34022;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_max_idx(struct futhark_context *ctx, int64_t *out0, const struct futhark_i64_1d *in0)
{
    int64_t nz2080U_31457 = (int64_t) 0;
    int64_t prim_out_34019 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device eta_p_mem_33832;
    
    eta_p_mem_33832.references = NULL;
    eta_p_mem_33832 = in0->mem;
    nz2080U_31457 = in0->shape[0];
    if (!(nz2080U_31457 == in0->shape[0])) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_max_idx(ctx, &prim_out_34019, eta_p_mem_33832, nz2080U_31457);
        if (ret == 0) {
            struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
            struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
            struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
            
            *out0 = prim_out_34019;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_min_idx(struct futhark_context *ctx, int64_t *out0, const struct futhark_i64_1d *in0)
{
    int64_t nz2080U_31417 = (int64_t) 0;
    int64_t prim_out_34019 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device eta_p_mem_33832;
    
    eta_p_mem_33832.references = NULL;
    eta_p_mem_33832 = in0->mem;
    nz2080U_31417 = in0->shape[0];
    if (!(nz2080U_31417 == in0->shape[0])) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_min_idx(ctx, &prim_out_34019, eta_p_mem_33832, nz2080U_31417);
        if (ret == 0) {
            struct memblock_device counters_mem_34022 = ctx->constants->counters_mem_34022;
            struct memblock_device global_dynid_mem_34057 = ctx->constants->global_dynid_mem_34057;
            struct memblock_device global_dynid_mem_34235 = ctx->constants->global_dynid_mem_34235;
            
            *out0 = prim_out_34019;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
  
